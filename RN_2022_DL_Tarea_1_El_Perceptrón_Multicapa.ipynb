{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChristianIES/Redes_Neuronales/blob/main/RN_2022_DL_Tarea_1_El_Perceptr%C3%B3n_Multicapa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRDO4iB7SCEc"
      },
      "source": [
        "# Tarea 1 - El Perceptrón Multicapa como modelo de regresión\n",
        "\n",
        "- Nombre: Valentina Bastidas S.\n",
        "- Programa: Doctorado en Estadística\n",
        "\n",
        "\n",
        "- Nombre: Christian Araya M.\n",
        "- Programa: Doctorado en Estadística\n",
        "\n",
        "\n",
        "- Nombre: \n",
        "- Programa: \n",
        "\n",
        "\n",
        "En la presente tarea se estudiará las capacidades y dificultades del Perceptrón Multicapa (MLP) como modelo de aprendizaje estadístico."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hx-ZlqMoSCEg"
      },
      "source": [
        "**Ingresar los Toolbox utilizados en este Notebook**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eGygDih6SCEj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import explained_variance_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.stats import pearsonr\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "from matplotlib import cm\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model"
      ],
      "metadata": {
        "id": "DzR5DktIsP9H"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaHgJF71SCEm"
      },
      "source": [
        "En esta tarea Ud. deberá construir un modelo de MLP para aproximar una superficie en el espacio $\\mathbb{R}^3$\n",
        "\n",
        "La superficie que se va a aproximar con la red neuronal será la siguiente:\n",
        "\n",
        "$$z =  3\\cdot (1-x)^2\\cdot e^{-x^2 - (y+1)^2} - 10\\cdot (\\frac{1}{5}x - x^3 - y^5)\\cdot e^{-x^2-y^2} - \\frac{1}{3}\\cdot e^{-(x+1)^2 - y^2} $$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xp0ewHqWSCEn"
      },
      "source": [
        "1. Generar una función que dado el valor de $x$ e $y$ calcule $z$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ElI0TU-7SCEo"
      },
      "outputs": [],
      "source": [
        "def funcion(XX,YY):\n",
        "  return 3*((1-XX)**2)*np.exp(-XX**2-(XY+1)**2)-10*(XX/5-XX**3-XY**5)*np.exp(-XX**2-XY**2)-(1/3)*np.exp(-(XX+1)**2-XY**2)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgTcEMrYSCEp"
      },
      "source": [
        "2. Realizar el gráfico de la superficie en el rango $[-3,3]\\times [-3,3]$. (https://matplotlib.org/mpl_toolkits/mplot3d/tutorial.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1ndWlNcwSCEr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "bfad7383-979a-4b30-f28b-44444831aa5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0x7f8492591f90>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "XX = np.arange(-3, 3, 1)\n",
        "XY = np.arange(-3, 3, 1)\n",
        "XX, XY = np.meshgrid(XX, XY)\n",
        "Z = funcion(XX,XY)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = Axes3D(fig)\n",
        "ax.plot_surface(XX, XY, Z, rstride=1, cstride=1, cmap=cm.viridis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jO7e3mKpSCEs"
      },
      "source": [
        "3. Generar de forma aleatoria 10000 datos $(x,y,z)$ con distribución uniforme en el rango $[-3,3]\\times [-3,3]$. Realizar un gráfico de dispersión de los puntos. Considerar este cojunto como conjunto de entrenamiento. Luego, generar de forma aleatoria otros 10000 datos para el conjunto de test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oD-CXoM7SCEt"
      },
      "outputs": [],
      "source": [
        "#Generación de Datos Aleatorios:\n",
        "\n",
        "x = np.random.uniform(-3,3,10000)\n",
        "y = np.random.uniform(-3,3,10000)\n",
        "z=3*((1-x)**2)*np.exp(-x**2-(y+1)**2)-10*(x/5-x**3-y**5)*np.exp(-x**2-y**2)-(1/3)*np.exp(-(x+1)**2-y**2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Gráficos de Dispersión:\n",
        "fig, dis = plt.subplots(1,2,figsize=(10,5))\n",
        "dis[0].plot(x, z,'.')\n",
        "dis[1].plot(y, z,'.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "h0DooWD0w2KS",
        "outputId": "d9868a47-fbb4-400f-fe29-8fa63a01c44d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f848f7fa710>]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0p0exVsSCEv"
      },
      "source": [
        "4. Generar una nueva variable $V$ a la cual se le introduce un ruido gaussiano con desviación estándar de $0.05$, es decir:\n",
        "\n",
        "$$v = z + \\epsilon$$\n",
        "\n",
        "donde $\\epsilon \\sim {\\cal N}(0, \\sigma_{\\epsilon}^2)$, $\\sigma_{\\epsilon}=0.7$\n",
        "\n",
        "Realizar el grafico de dispersión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RQ89RReiSCEw"
      },
      "outputs": [],
      "source": [
        "#Generación de ruido gaussiano:\n",
        "e = np.random.normal(0,0.05,10000)\n",
        "v=z+e"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Gráficos de Dispersión:\n",
        "fig, dis = plt.subplots(1,2,figsize=(10,5))\n",
        "dis[0].plot(x, v,'.')\n",
        "dis[1].plot(y, v,'.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "rk1v4q4VySOb",
        "outputId": "b4d0a936-b996-4992-fc3d-366b6f990034"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f848f6ecd10>]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#086F0C'>Como se puede apreciar, la distorsión que incorpora el ruido gaussiano no modifica drásticamente la relación que existe entre las variables y \"z\", el valor de la función, debido principalmente a la desviación estándar pequeña para la componente de ruido.</font>\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "oVfmXE_vydHO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sda9AhmWSCEz"
      },
      "source": [
        "5. **Estudio sobre el Sobreajuste y la Capacidad de Aprendizaje:** Diseñar e Implentar una red neuronal MLP con el fin de que pueda aprender la variable $V$, teniendo como entrada las variables $X$ e $Y$. \n",
        "\n",
        "Calcular la raíz del error cuadrático medio del modelo con respecto a $V$, tanto para el conjunto de entrenamiento como el de test. Ajustar el modelo hasta obtener un error con el conjunto de entrenamiento muy cercano a cero."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Fe17AqDBSCE1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b4c5ed7-f47c-4ecb-f585-65e72e2ab4c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-2.28954535,  2.79633011],\n",
              "       [ 2.67440654, -0.9270821 ],\n",
              "       [ 2.31410036,  2.77215351],\n",
              "       ...,\n",
              "       [-0.87443395, -2.59709223],\n",
              "       [-0.21540206,  1.91974987],\n",
              "       [ 0.72613068, -1.14624206]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#Preparación de datos (incluye escalamiento):\n",
        "X = np.vstack((x,y)).T\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "Z = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "JwLgk6bo12_u"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Conjunto de entrenamiento y de prueba:\n",
        "\n",
        "#Z: datos\n",
        "#z: valor de la función original\n",
        "\n",
        "Z_train, Z_test, z_train, z_test = train_test_split(Z,z,test_size=0.3)"
      ],
      "metadata": {
        "id": "L_ARHlpw16Ke"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Modelo de Perceptrón Multicapa (MLP):\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(100, input_dim=2, activation='sigmoid'))\n",
        "model.add(Dense(20, activation='sigmoid'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "model.compile(loss='mean_squared_error', \n",
        "              optimizer='adam', metrics=['mean_absolute_error', 'mean_squared_error'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeM1-Y7Y2uuh",
        "outputId": "da7d1e52-548e-4d12-8997-1b93efda022f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 100)               300       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 20)                2020      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,341\n",
            "Trainable params: 2,341\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ajuste:\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=1000)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)"
      ],
      "metadata": {
        "id": "ViLvINMx4qLD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(Z_train, z_train, epochs=1000, batch_size=20, validation_split=0.3, shuffle=True, verbose=True, callbacks=[es,mc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMaTLHCT4xZc",
        "outputId": "617d4549-3371-4720-f422-af01feefc33b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 3.7505 - mean_absolute_error: 1.2507 - mean_squared_error: 3.7505\n",
            "Epoch 1: val_loss improved from inf to 3.55475, saving model to best_model.h5\n",
            "245/245 [==============================] - 2s 3ms/step - loss: 3.7280 - mean_absolute_error: 1.2480 - mean_squared_error: 3.7280 - val_loss: 3.5547 - val_mean_absolute_error: 1.1952 - val_mean_squared_error: 3.5547\n",
            "Epoch 2/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 3.6329 - mean_absolute_error: 1.2201 - mean_squared_error: 3.6329\n",
            "Epoch 2: val_loss improved from 3.55475 to 3.43251, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.6296 - mean_absolute_error: 1.2199 - mean_squared_error: 3.6296 - val_loss: 3.4325 - val_mean_absolute_error: 1.1357 - val_mean_squared_error: 3.4325\n",
            "Epoch 3/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 3.4632 - mean_absolute_error: 1.1894 - mean_squared_error: 3.4632\n",
            "Epoch 3: val_loss improved from 3.43251 to 3.23502, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.4632 - mean_absolute_error: 1.1894 - mean_squared_error: 3.4632 - val_loss: 3.2350 - val_mean_absolute_error: 1.1706 - val_mean_squared_error: 3.2350\n",
            "Epoch 4/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 3.3051 - mean_absolute_error: 1.1931 - mean_squared_error: 3.3051\n",
            "Epoch 4: val_loss improved from 3.23502 to 3.06537, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.2632 - mean_absolute_error: 1.1895 - mean_squared_error: 3.2632 - val_loss: 3.0654 - val_mean_absolute_error: 1.1731 - val_mean_squared_error: 3.0654\n",
            "Epoch 5/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 3.1661 - mean_absolute_error: 1.2231 - mean_squared_error: 3.1661\n",
            "Epoch 5: val_loss improved from 3.06537 to 3.01568, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1731 - mean_absolute_error: 1.2256 - mean_squared_error: 3.1731 - val_loss: 3.0157 - val_mean_absolute_error: 1.2099 - val_mean_squared_error: 3.0157\n",
            "Epoch 6/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 3.1413 - mean_absolute_error: 1.2517 - mean_squared_error: 3.1413\n",
            "Epoch 6: val_loss improved from 3.01568 to 3.01256, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1369 - mean_absolute_error: 1.2512 - mean_squared_error: 3.1369 - val_loss: 3.0126 - val_mean_absolute_error: 1.2353 - val_mean_squared_error: 3.0126\n",
            "Epoch 7/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 3.1259 - mean_absolute_error: 1.2634 - mean_squared_error: 3.1259\n",
            "Epoch 7: val_loss improved from 3.01256 to 3.00399, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1219 - mean_absolute_error: 1.2634 - mean_squared_error: 3.1219 - val_loss: 3.0040 - val_mean_absolute_error: 1.2421 - val_mean_squared_error: 3.0040\n",
            "Epoch 8/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 3.1745 - mean_absolute_error: 1.2863 - mean_squared_error: 3.1745\n",
            "Epoch 8: val_loss did not improve from 3.00399\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1452 - mean_absolute_error: 1.2781 - mean_squared_error: 3.1452 - val_loss: 3.0048 - val_mean_absolute_error: 1.2411 - val_mean_squared_error: 3.0048\n",
            "Epoch 9/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 3.1170 - mean_absolute_error: 1.2717 - mean_squared_error: 3.1170\n",
            "Epoch 9: val_loss did not improve from 3.00399\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1310 - mean_absolute_error: 1.2734 - mean_squared_error: 3.1310 - val_loss: 3.0521 - val_mean_absolute_error: 1.2587 - val_mean_squared_error: 3.0521\n",
            "Epoch 10/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 3.1242 - mean_absolute_error: 1.2708 - mean_squared_error: 3.1242\n",
            "Epoch 10: val_loss did not improve from 3.00399\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1297 - mean_absolute_error: 1.2719 - mean_squared_error: 3.1297 - val_loss: 3.0362 - val_mean_absolute_error: 1.2559 - val_mean_squared_error: 3.0362\n",
            "Epoch 11/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 3.1418 - mean_absolute_error: 1.2755 - mean_squared_error: 3.1418\n",
            "Epoch 11: val_loss did not improve from 3.00399\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1263 - mean_absolute_error: 1.2729 - mean_squared_error: 3.1263 - val_loss: 3.0207 - val_mean_absolute_error: 1.2522 - val_mean_squared_error: 3.0207\n",
            "Epoch 12/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 3.1309 - mean_absolute_error: 1.2712 - mean_squared_error: 3.1309\n",
            "Epoch 12: val_loss improved from 3.00399 to 2.99635, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1186 - mean_absolute_error: 1.2696 - mean_squared_error: 3.1186 - val_loss: 2.9964 - val_mean_absolute_error: 1.2471 - val_mean_squared_error: 2.9964\n",
            "Epoch 13/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 3.1111 - mean_absolute_error: 1.2699 - mean_squared_error: 3.1111\n",
            "Epoch 13: val_loss improved from 2.99635 to 2.99227, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1180 - mean_absolute_error: 1.2714 - mean_squared_error: 3.1180 - val_loss: 2.9923 - val_mean_absolute_error: 1.2453 - val_mean_squared_error: 2.9923\n",
            "Epoch 14/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 3.1352 - mean_absolute_error: 1.2815 - mean_squared_error: 3.1352\n",
            "Epoch 14: val_loss did not improve from 2.99227\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1223 - mean_absolute_error: 1.2783 - mean_squared_error: 3.1223 - val_loss: 2.9961 - val_mean_absolute_error: 1.2458 - val_mean_squared_error: 2.9961\n",
            "Epoch 15/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 3.1018 - mean_absolute_error: 1.2662 - mean_squared_error: 3.1018\n",
            "Epoch 15: val_loss did not improve from 2.99227\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1101 - mean_absolute_error: 1.2675 - mean_squared_error: 3.1101 - val_loss: 2.9945 - val_mean_absolute_error: 1.2447 - val_mean_squared_error: 2.9945\n",
            "Epoch 16/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 3.0946 - mean_absolute_error: 1.2684 - mean_squared_error: 3.0946\n",
            "Epoch 16: val_loss improved from 2.99227 to 2.98576, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1077 - mean_absolute_error: 1.2716 - mean_squared_error: 3.1077 - val_loss: 2.9858 - val_mean_absolute_error: 1.2454 - val_mean_squared_error: 2.9858\n",
            "Epoch 17/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 3.1311 - mean_absolute_error: 1.2742 - mean_squared_error: 3.1311\n",
            "Epoch 17: val_loss did not improve from 2.98576\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1079 - mean_absolute_error: 1.2714 - mean_squared_error: 3.1079 - val_loss: 2.9971 - val_mean_absolute_error: 1.2525 - val_mean_squared_error: 2.9971\n",
            "Epoch 18/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 3.0957 - mean_absolute_error: 1.2731 - mean_squared_error: 3.0957\n",
            "Epoch 18: val_loss did not improve from 2.98576\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0962 - mean_absolute_error: 1.2729 - mean_squared_error: 3.0962 - val_loss: 2.9958 - val_mean_absolute_error: 1.2514 - val_mean_squared_error: 2.9958\n",
            "Epoch 19/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 3.0470 - mean_absolute_error: 1.2580 - mean_squared_error: 3.0470\n",
            "Epoch 19: val_loss did not improve from 2.98576\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0902 - mean_absolute_error: 1.2663 - mean_squared_error: 3.0902 - val_loss: 3.0128 - val_mean_absolute_error: 1.2603 - val_mean_squared_error: 3.0128\n",
            "Epoch 20/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 3.1086 - mean_absolute_error: 1.2720 - mean_squared_error: 3.1086\n",
            "Epoch 20: val_loss improved from 2.98576 to 2.98361, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0935 - mean_absolute_error: 1.2704 - mean_squared_error: 3.0935 - val_loss: 2.9836 - val_mean_absolute_error: 1.2531 - val_mean_squared_error: 2.9836\n",
            "Epoch 21/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 3.0926 - mean_absolute_error: 1.2731 - mean_squared_error: 3.0926\n",
            "Epoch 21: val_loss did not improve from 2.98361\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0812 - mean_absolute_error: 1.2731 - mean_squared_error: 3.0812 - val_loss: 3.0046 - val_mean_absolute_error: 1.2590 - val_mean_squared_error: 3.0046\n",
            "Epoch 22/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 3.0699 - mean_absolute_error: 1.2662 - mean_squared_error: 3.0699\n",
            "Epoch 22: val_loss improved from 2.98361 to 2.95822, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0754 - mean_absolute_error: 1.2669 - mean_squared_error: 3.0754 - val_loss: 2.9582 - val_mean_absolute_error: 1.2458 - val_mean_squared_error: 2.9582\n",
            "Epoch 23/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 3.0640 - mean_absolute_error: 1.2666 - mean_squared_error: 3.0640\n",
            "Epoch 23: val_loss improved from 2.95822 to 2.94870, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0640 - mean_absolute_error: 1.2666 - mean_squared_error: 3.0640 - val_loss: 2.9487 - val_mean_absolute_error: 1.2422 - val_mean_squared_error: 2.9487\n",
            "Epoch 24/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 3.0603 - mean_absolute_error: 1.2661 - mean_squared_error: 3.0603\n",
            "Epoch 24: val_loss did not improve from 2.94870\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0591 - mean_absolute_error: 1.2675 - mean_squared_error: 3.0591 - val_loss: 2.9502 - val_mean_absolute_error: 1.2389 - val_mean_squared_error: 2.9502\n",
            "Epoch 25/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 3.0596 - mean_absolute_error: 1.2650 - mean_squared_error: 3.0596\n",
            "Epoch 25: val_loss improved from 2.94870 to 2.93077, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0445 - mean_absolute_error: 1.2623 - mean_squared_error: 3.0445 - val_loss: 2.9308 - val_mean_absolute_error: 1.2414 - val_mean_squared_error: 2.9308\n",
            "Epoch 26/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 3.0009 - mean_absolute_error: 1.2552 - mean_squared_error: 3.0009\n",
            "Epoch 26: val_loss improved from 2.93077 to 2.91971, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0295 - mean_absolute_error: 1.2603 - mean_squared_error: 3.0295 - val_loss: 2.9197 - val_mean_absolute_error: 1.2432 - val_mean_squared_error: 2.9197\n",
            "Epoch 27/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 3.0228 - mean_absolute_error: 1.2658 - mean_squared_error: 3.0228\n",
            "Epoch 27: val_loss improved from 2.91971 to 2.90339, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0249 - mean_absolute_error: 1.2664 - mean_squared_error: 3.0249 - val_loss: 2.9034 - val_mean_absolute_error: 1.2323 - val_mean_squared_error: 2.9034\n",
            "Epoch 28/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.9968 - mean_absolute_error: 1.2569 - mean_squared_error: 2.9968\n",
            "Epoch 28: val_loss improved from 2.90339 to 2.88837, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0039 - mean_absolute_error: 1.2569 - mean_squared_error: 3.0039 - val_loss: 2.8884 - val_mean_absolute_error: 1.2287 - val_mean_squared_error: 2.8884\n",
            "Epoch 29/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.9860 - mean_absolute_error: 1.2507 - mean_squared_error: 2.9860\n",
            "Epoch 29: val_loss improved from 2.88837 to 2.86857, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9815 - mean_absolute_error: 1.2507 - mean_squared_error: 2.9815 - val_loss: 2.8686 - val_mean_absolute_error: 1.2332 - val_mean_squared_error: 2.8686\n",
            "Epoch 30/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.9519 - mean_absolute_error: 1.2441 - mean_squared_error: 2.9519\n",
            "Epoch 30: val_loss improved from 2.86857 to 2.85093, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9519 - mean_absolute_error: 1.2441 - mean_squared_error: 2.9519 - val_loss: 2.8509 - val_mean_absolute_error: 1.2329 - val_mean_squared_error: 2.8509\n",
            "Epoch 31/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.9075 - mean_absolute_error: 1.2348 - mean_squared_error: 2.9075\n",
            "Epoch 31: val_loss improved from 2.85093 to 2.81136, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9203 - mean_absolute_error: 1.2372 - mean_squared_error: 2.9203 - val_loss: 2.8114 - val_mean_absolute_error: 1.2157 - val_mean_squared_error: 2.8114\n",
            "Epoch 32/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 2.8344 - mean_absolute_error: 1.2184 - mean_squared_error: 2.8344\n",
            "Epoch 32: val_loss improved from 2.81136 to 2.78472, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8785 - mean_absolute_error: 1.2270 - mean_squared_error: 2.8785 - val_loss: 2.7847 - val_mean_absolute_error: 1.2205 - val_mean_squared_error: 2.7847\n",
            "Epoch 33/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.8318 - mean_absolute_error: 1.2183 - mean_squared_error: 2.8318\n",
            "Epoch 33: val_loss improved from 2.78472 to 2.72553, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8355 - mean_absolute_error: 1.2192 - mean_squared_error: 2.8355 - val_loss: 2.7255 - val_mean_absolute_error: 1.1924 - val_mean_squared_error: 2.7255\n",
            "Epoch 34/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.7821 - mean_absolute_error: 1.2005 - mean_squared_error: 2.7821\n",
            "Epoch 34: val_loss improved from 2.72553 to 2.67662, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7830 - mean_absolute_error: 1.2018 - mean_squared_error: 2.7830 - val_loss: 2.6766 - val_mean_absolute_error: 1.1831 - val_mean_squared_error: 2.6766\n",
            "Epoch 35/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.7284 - mean_absolute_error: 1.1859 - mean_squared_error: 2.7284\n",
            "Epoch 35: val_loss improved from 2.67662 to 2.61240, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7082 - mean_absolute_error: 1.1816 - mean_squared_error: 2.7082 - val_loss: 2.6124 - val_mean_absolute_error: 1.1587 - val_mean_squared_error: 2.6124\n",
            "Epoch 36/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.6369 - mean_absolute_error: 1.1558 - mean_squared_error: 2.6369\n",
            "Epoch 36: val_loss improved from 2.61240 to 2.53872, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6355 - mean_absolute_error: 1.1558 - mean_squared_error: 2.6355 - val_loss: 2.5387 - val_mean_absolute_error: 1.1409 - val_mean_squared_error: 2.5387\n",
            "Epoch 37/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 2.5341 - mean_absolute_error: 1.1294 - mean_squared_error: 2.5341\n",
            "Epoch 37: val_loss improved from 2.53872 to 2.46854, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5552 - mean_absolute_error: 1.1311 - mean_squared_error: 2.5552 - val_loss: 2.4685 - val_mean_absolute_error: 1.1043 - val_mean_squared_error: 2.4685\n",
            "Epoch 38/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.5006 - mean_absolute_error: 1.1059 - mean_squared_error: 2.5006\n",
            "Epoch 38: val_loss improved from 2.46854 to 2.39531, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.4718 - mean_absolute_error: 1.1002 - mean_squared_error: 2.4718 - val_loss: 2.3953 - val_mean_absolute_error: 1.0905 - val_mean_squared_error: 2.3953\n",
            "Epoch 39/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.3886 - mean_absolute_error: 1.0759 - mean_squared_error: 2.3886\n",
            "Epoch 39: val_loss improved from 2.39531 to 2.33922, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3970 - mean_absolute_error: 1.0781 - mean_squared_error: 2.3970 - val_loss: 2.3392 - val_mean_absolute_error: 1.0562 - val_mean_squared_error: 2.3392\n",
            "Epoch 40/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.3207 - mean_absolute_error: 1.0483 - mean_squared_error: 2.3207\n",
            "Epoch 40: val_loss improved from 2.33922 to 2.26237, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3207 - mean_absolute_error: 1.0483 - mean_squared_error: 2.3207 - val_loss: 2.2624 - val_mean_absolute_error: 1.0471 - val_mean_squared_error: 2.2624\n",
            "Epoch 41/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.2533 - mean_absolute_error: 1.0272 - mean_squared_error: 2.2533\n",
            "Epoch 41: val_loss improved from 2.26237 to 2.20463, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2573 - mean_absolute_error: 1.0282 - mean_squared_error: 2.2573 - val_loss: 2.2046 - val_mean_absolute_error: 1.0145 - val_mean_squared_error: 2.2046\n",
            "Epoch 42/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.1900 - mean_absolute_error: 1.0065 - mean_squared_error: 2.1900\n",
            "Epoch 42: val_loss improved from 2.20463 to 2.16880, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1900 - mean_absolute_error: 1.0065 - mean_squared_error: 2.1900 - val_loss: 2.1688 - val_mean_absolute_error: 1.0051 - val_mean_squared_error: 2.1688\n",
            "Epoch 43/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.1278 - mean_absolute_error: 0.9859 - mean_squared_error: 2.1278\n",
            "Epoch 43: val_loss improved from 2.16880 to 2.09876, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1278 - mean_absolute_error: 0.9859 - mean_squared_error: 2.1278 - val_loss: 2.0988 - val_mean_absolute_error: 0.9736 - val_mean_squared_error: 2.0988\n",
            "Epoch 44/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.0640 - mean_absolute_error: 0.9629 - mean_squared_error: 2.0640\n",
            "Epoch 44: val_loss improved from 2.09876 to 2.04122, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0757 - mean_absolute_error: 0.9661 - mean_squared_error: 2.0757 - val_loss: 2.0412 - val_mean_absolute_error: 0.9454 - val_mean_squared_error: 2.0412\n",
            "Epoch 45/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.9928 - mean_absolute_error: 0.9399 - mean_squared_error: 1.9928\n",
            "Epoch 45: val_loss improved from 2.04122 to 2.01214, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0125 - mean_absolute_error: 0.9421 - mean_squared_error: 2.0125 - val_loss: 2.0121 - val_mean_absolute_error: 0.9480 - val_mean_squared_error: 2.0121\n",
            "Epoch 46/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.9726 - mean_absolute_error: 0.9279 - mean_squared_error: 1.9726\n",
            "Epoch 46: val_loss improved from 2.01214 to 1.97505, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9726 - mean_absolute_error: 0.9279 - mean_squared_error: 1.9726 - val_loss: 1.9750 - val_mean_absolute_error: 0.9103 - val_mean_squared_error: 1.9750\n",
            "Epoch 47/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.9298 - mean_absolute_error: 0.9095 - mean_squared_error: 1.9298\n",
            "Epoch 47: val_loss improved from 1.97505 to 1.95014, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9398 - mean_absolute_error: 0.9149 - mean_squared_error: 1.9398 - val_loss: 1.9501 - val_mean_absolute_error: 0.9231 - val_mean_squared_error: 1.9501\n",
            "Epoch 48/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.9363 - mean_absolute_error: 0.9150 - mean_squared_error: 1.9363\n",
            "Epoch 48: val_loss improved from 1.95014 to 1.93272, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9202 - mean_absolute_error: 0.9103 - mean_squared_error: 1.9202 - val_loss: 1.9327 - val_mean_absolute_error: 0.9131 - val_mean_squared_error: 1.9327\n",
            "Epoch 49/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.9058 - mean_absolute_error: 0.9042 - mean_squared_error: 1.9058\n",
            "Epoch 49: val_loss improved from 1.93272 to 1.92327, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9050 - mean_absolute_error: 0.9040 - mean_squared_error: 1.9050 - val_loss: 1.9233 - val_mean_absolute_error: 0.9047 - val_mean_squared_error: 1.9233\n",
            "Epoch 50/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.8987 - mean_absolute_error: 0.9017 - mean_squared_error: 1.8987\n",
            "Epoch 50: val_loss did not improve from 1.92327\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8900 - mean_absolute_error: 0.8993 - mean_squared_error: 1.8900 - val_loss: 1.9305 - val_mean_absolute_error: 0.9091 - val_mean_squared_error: 1.9305\n",
            "Epoch 51/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.8881 - mean_absolute_error: 0.8996 - mean_squared_error: 1.8881\n",
            "Epoch 51: val_loss improved from 1.92327 to 1.91359, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8864 - mean_absolute_error: 0.8991 - mean_squared_error: 1.8864 - val_loss: 1.9136 - val_mean_absolute_error: 0.9072 - val_mean_squared_error: 1.9136\n",
            "Epoch 52/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.8787 - mean_absolute_error: 0.8957 - mean_squared_error: 1.8787\n",
            "Epoch 52: val_loss did not improve from 1.91359\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8756 - mean_absolute_error: 0.8949 - mean_squared_error: 1.8756 - val_loss: 1.9151 - val_mean_absolute_error: 0.9042 - val_mean_squared_error: 1.9151\n",
            "Epoch 53/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.8789 - mean_absolute_error: 0.8957 - mean_squared_error: 1.8789\n",
            "Epoch 53: val_loss improved from 1.91359 to 1.91006, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8747 - mean_absolute_error: 0.8946 - mean_squared_error: 1.8747 - val_loss: 1.9101 - val_mean_absolute_error: 0.9063 - val_mean_squared_error: 1.9101\n",
            "Epoch 54/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.8688 - mean_absolute_error: 0.8919 - mean_squared_error: 1.8688\n",
            "Epoch 54: val_loss improved from 1.91006 to 1.90415, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8678 - mean_absolute_error: 0.8911 - mean_squared_error: 1.8678 - val_loss: 1.9041 - val_mean_absolute_error: 0.9030 - val_mean_squared_error: 1.9041\n",
            "Epoch 55/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.8743 - mean_absolute_error: 0.8940 - mean_squared_error: 1.8743\n",
            "Epoch 55: val_loss improved from 1.90415 to 1.89160, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8702 - mean_absolute_error: 0.8925 - mean_squared_error: 1.8702 - val_loss: 1.8916 - val_mean_absolute_error: 0.8951 - val_mean_squared_error: 1.8916\n",
            "Epoch 56/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.8363 - mean_absolute_error: 0.8804 - mean_squared_error: 1.8363\n",
            "Epoch 56: val_loss did not improve from 1.89160\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8585 - mean_absolute_error: 0.8867 - mean_squared_error: 1.8585 - val_loss: 1.9072 - val_mean_absolute_error: 0.9065 - val_mean_squared_error: 1.9072\n",
            "Epoch 57/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.8289 - mean_absolute_error: 0.8795 - mean_squared_error: 1.8289\n",
            "Epoch 57: val_loss improved from 1.89160 to 1.88492, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8534 - mean_absolute_error: 0.8852 - mean_squared_error: 1.8534 - val_loss: 1.8849 - val_mean_absolute_error: 0.8924 - val_mean_squared_error: 1.8849\n",
            "Epoch 58/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.8512 - mean_absolute_error: 0.8846 - mean_squared_error: 1.8512\n",
            "Epoch 58: val_loss improved from 1.88492 to 1.88117, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8524 - mean_absolute_error: 0.8852 - mean_squared_error: 1.8524 - val_loss: 1.8812 - val_mean_absolute_error: 0.8917 - val_mean_squared_error: 1.8812\n",
            "Epoch 59/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.8348 - mean_absolute_error: 0.8768 - mean_squared_error: 1.8348\n",
            "Epoch 59: val_loss improved from 1.88117 to 1.87927, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8406 - mean_absolute_error: 0.8789 - mean_squared_error: 1.8406 - val_loss: 1.8793 - val_mean_absolute_error: 0.8872 - val_mean_squared_error: 1.8793\n",
            "Epoch 60/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.8379 - mean_absolute_error: 0.8787 - mean_squared_error: 1.8379\n",
            "Epoch 60: val_loss improved from 1.87927 to 1.86984, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8365 - mean_absolute_error: 0.8786 - mean_squared_error: 1.8365 - val_loss: 1.8698 - val_mean_absolute_error: 0.8859 - val_mean_squared_error: 1.8698\n",
            "Epoch 61/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.8337 - mean_absolute_error: 0.8776 - mean_squared_error: 1.8337\n",
            "Epoch 61: val_loss did not improve from 1.86984\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8292 - mean_absolute_error: 0.8775 - mean_squared_error: 1.8292 - val_loss: 1.8717 - val_mean_absolute_error: 0.8898 - val_mean_squared_error: 1.8717\n",
            "Epoch 62/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.8263 - mean_absolute_error: 0.8770 - mean_squared_error: 1.8263\n",
            "Epoch 62: val_loss improved from 1.86984 to 1.86777, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8231 - mean_absolute_error: 0.8767 - mean_squared_error: 1.8231 - val_loss: 1.8678 - val_mean_absolute_error: 0.8843 - val_mean_squared_error: 1.8678\n",
            "Epoch 63/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.8032 - mean_absolute_error: 0.8657 - mean_squared_error: 1.8032\n",
            "Epoch 63: val_loss improved from 1.86777 to 1.85984, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8172 - mean_absolute_error: 0.8712 - mean_squared_error: 1.8172 - val_loss: 1.8598 - val_mean_absolute_error: 0.8879 - val_mean_squared_error: 1.8598\n",
            "Epoch 64/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.8340 - mean_absolute_error: 0.8789 - mean_squared_error: 1.8340\n",
            "Epoch 64: val_loss did not improve from 1.85984\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8124 - mean_absolute_error: 0.8724 - mean_squared_error: 1.8124 - val_loss: 1.8609 - val_mean_absolute_error: 0.8867 - val_mean_squared_error: 1.8609\n",
            "Epoch 65/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.8114 - mean_absolute_error: 0.8703 - mean_squared_error: 1.8114\n",
            "Epoch 65: val_loss improved from 1.85984 to 1.84154, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8054 - mean_absolute_error: 0.8682 - mean_squared_error: 1.8054 - val_loss: 1.8415 - val_mean_absolute_error: 0.8808 - val_mean_squared_error: 1.8415\n",
            "Epoch 66/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.7845 - mean_absolute_error: 0.8634 - mean_squared_error: 1.7845\n",
            "Epoch 66: val_loss improved from 1.84154 to 1.83547, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7983 - mean_absolute_error: 0.8681 - mean_squared_error: 1.7983 - val_loss: 1.8355 - val_mean_absolute_error: 0.8770 - val_mean_squared_error: 1.8355\n",
            "Epoch 67/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.7722 - mean_absolute_error: 0.8577 - mean_squared_error: 1.7722\n",
            "Epoch 67: val_loss did not improve from 1.83547\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7926 - mean_absolute_error: 0.8649 - mean_squared_error: 1.7926 - val_loss: 1.8399 - val_mean_absolute_error: 0.8842 - val_mean_squared_error: 1.8399\n",
            "Epoch 68/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.7803 - mean_absolute_error: 0.8619 - mean_squared_error: 1.7803\n",
            "Epoch 68: val_loss did not improve from 1.83547\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7859 - mean_absolute_error: 0.8641 - mean_squared_error: 1.7859 - val_loss: 1.8368 - val_mean_absolute_error: 0.8844 - val_mean_squared_error: 1.8368\n",
            "Epoch 69/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.7780 - mean_absolute_error: 0.8611 - mean_squared_error: 1.7780\n",
            "Epoch 69: val_loss improved from 1.83547 to 1.81629, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7778 - mean_absolute_error: 0.8615 - mean_squared_error: 1.7778 - val_loss: 1.8163 - val_mean_absolute_error: 0.8705 - val_mean_squared_error: 1.8163\n",
            "Epoch 70/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.7759 - mean_absolute_error: 0.8589 - mean_squared_error: 1.7759\n",
            "Epoch 70: val_loss did not improve from 1.81629\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7660 - mean_absolute_error: 0.8562 - mean_squared_error: 1.7660 - val_loss: 1.8293 - val_mean_absolute_error: 0.8838 - val_mean_squared_error: 1.8293\n",
            "Epoch 71/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.7672 - mean_absolute_error: 0.8584 - mean_squared_error: 1.7672\n",
            "Epoch 71: val_loss improved from 1.81629 to 1.81148, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7597 - mean_absolute_error: 0.8574 - mean_squared_error: 1.7597 - val_loss: 1.8115 - val_mean_absolute_error: 0.8789 - val_mean_squared_error: 1.8115\n",
            "Epoch 72/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.7338 - mean_absolute_error: 0.8505 - mean_squared_error: 1.7338\n",
            "Epoch 72: val_loss improved from 1.81148 to 1.80622, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7507 - mean_absolute_error: 0.8546 - mean_squared_error: 1.7507 - val_loss: 1.8062 - val_mean_absolute_error: 0.8758 - val_mean_squared_error: 1.8062\n",
            "Epoch 73/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.7305 - mean_absolute_error: 0.8514 - mean_squared_error: 1.7305\n",
            "Epoch 73: val_loss improved from 1.80622 to 1.79120, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7384 - mean_absolute_error: 0.8522 - mean_squared_error: 1.7384 - val_loss: 1.7912 - val_mean_absolute_error: 0.8711 - val_mean_squared_error: 1.7912\n",
            "Epoch 74/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.7556 - mean_absolute_error: 0.8571 - mean_squared_error: 1.7556\n",
            "Epoch 74: val_loss improved from 1.79120 to 1.77169, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7379 - mean_absolute_error: 0.8526 - mean_squared_error: 1.7379 - val_loss: 1.7717 - val_mean_absolute_error: 0.8619 - val_mean_squared_error: 1.7717\n",
            "Epoch 75/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.6913 - mean_absolute_error: 0.8395 - mean_squared_error: 1.6913\n",
            "Epoch 75: val_loss improved from 1.77169 to 1.76675, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7223 - mean_absolute_error: 0.8472 - mean_squared_error: 1.7223 - val_loss: 1.7667 - val_mean_absolute_error: 0.8618 - val_mean_squared_error: 1.7667\n",
            "Epoch 76/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.7279 - mean_absolute_error: 0.8467 - mean_squared_error: 1.7279\n",
            "Epoch 76: val_loss improved from 1.76675 to 1.75078, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7120 - mean_absolute_error: 0.8432 - mean_squared_error: 1.7120 - val_loss: 1.7508 - val_mean_absolute_error: 0.8587 - val_mean_squared_error: 1.7508\n",
            "Epoch 77/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 1.6795 - mean_absolute_error: 0.8367 - mean_squared_error: 1.6795\n",
            "Epoch 77: val_loss improved from 1.75078 to 1.74644, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7002 - mean_absolute_error: 0.8434 - mean_squared_error: 1.7002 - val_loss: 1.7464 - val_mean_absolute_error: 0.8606 - val_mean_squared_error: 1.7464\n",
            "Epoch 78/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.6970 - mean_absolute_error: 0.8438 - mean_squared_error: 1.6970\n",
            "Epoch 78: val_loss improved from 1.74644 to 1.73305, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6962 - mean_absolute_error: 0.8426 - mean_squared_error: 1.6962 - val_loss: 1.7331 - val_mean_absolute_error: 0.8544 - val_mean_squared_error: 1.7331\n",
            "Epoch 79/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.6911 - mean_absolute_error: 0.8424 - mean_squared_error: 1.6911\n",
            "Epoch 79: val_loss improved from 1.73305 to 1.73159, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6864 - mean_absolute_error: 0.8391 - mean_squared_error: 1.6864 - val_loss: 1.7316 - val_mean_absolute_error: 0.8595 - val_mean_squared_error: 1.7316\n",
            "Epoch 80/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.6747 - mean_absolute_error: 0.8392 - mean_squared_error: 1.6747\n",
            "Epoch 80: val_loss improved from 1.73159 to 1.72031, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6718 - mean_absolute_error: 0.8380 - mean_squared_error: 1.6718 - val_loss: 1.7203 - val_mean_absolute_error: 0.8498 - val_mean_squared_error: 1.7203\n",
            "Epoch 81/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.6369 - mean_absolute_error: 0.8292 - mean_squared_error: 1.6369\n",
            "Epoch 81: val_loss improved from 1.72031 to 1.70628, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6594 - mean_absolute_error: 0.8339 - mean_squared_error: 1.6594 - val_loss: 1.7063 - val_mean_absolute_error: 0.8543 - val_mean_squared_error: 1.7063\n",
            "Epoch 82/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.6739 - mean_absolute_error: 0.8402 - mean_squared_error: 1.6739\n",
            "Epoch 82: val_loss improved from 1.70628 to 1.70396, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6503 - mean_absolute_error: 0.8324 - mean_squared_error: 1.6503 - val_loss: 1.7040 - val_mean_absolute_error: 0.8556 - val_mean_squared_error: 1.7040\n",
            "Epoch 83/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.6473 - mean_absolute_error: 0.8326 - mean_squared_error: 1.6473\n",
            "Epoch 83: val_loss improved from 1.70396 to 1.68289, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6423 - mean_absolute_error: 0.8319 - mean_squared_error: 1.6423 - val_loss: 1.6829 - val_mean_absolute_error: 0.8492 - val_mean_squared_error: 1.6829\n",
            "Epoch 84/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.6386 - mean_absolute_error: 0.8312 - mean_squared_error: 1.6386\n",
            "Epoch 84: val_loss did not improve from 1.68289\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6276 - mean_absolute_error: 0.8283 - mean_squared_error: 1.6276 - val_loss: 1.6831 - val_mean_absolute_error: 0.8439 - val_mean_squared_error: 1.6831\n",
            "Epoch 85/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.6291 - mean_absolute_error: 0.8273 - mean_squared_error: 1.6291\n",
            "Epoch 85: val_loss improved from 1.68289 to 1.65143, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6142 - mean_absolute_error: 0.8241 - mean_squared_error: 1.6142 - val_loss: 1.6514 - val_mean_absolute_error: 0.8340 - val_mean_squared_error: 1.6514\n",
            "Epoch 86/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.6086 - mean_absolute_error: 0.8230 - mean_squared_error: 1.6086\n",
            "Epoch 86: val_loss did not improve from 1.65143\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.5999 - mean_absolute_error: 0.8206 - mean_squared_error: 1.5999 - val_loss: 1.6531 - val_mean_absolute_error: 0.8495 - val_mean_squared_error: 1.6531\n",
            "Epoch 87/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.5871 - mean_absolute_error: 0.8216 - mean_squared_error: 1.5871\n",
            "Epoch 87: val_loss improved from 1.65143 to 1.62017, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.5815 - mean_absolute_error: 0.8205 - mean_squared_error: 1.5815 - val_loss: 1.6202 - val_mean_absolute_error: 0.8360 - val_mean_squared_error: 1.6202\n",
            "Epoch 88/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.5697 - mean_absolute_error: 0.8207 - mean_squared_error: 1.5697\n",
            "Epoch 88: val_loss improved from 1.62017 to 1.60122, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5672 - mean_absolute_error: 0.8198 - mean_squared_error: 1.5672 - val_loss: 1.6012 - val_mean_absolute_error: 0.8277 - val_mean_squared_error: 1.6012\n",
            "Epoch 89/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.5168 - mean_absolute_error: 0.8042 - mean_squared_error: 1.5168\n",
            "Epoch 89: val_loss improved from 1.60122 to 1.58123, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5450 - mean_absolute_error: 0.8119 - mean_squared_error: 1.5450 - val_loss: 1.5812 - val_mean_absolute_error: 0.8261 - val_mean_squared_error: 1.5812\n",
            "Epoch 90/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.5247 - mean_absolute_error: 0.8073 - mean_squared_error: 1.5247\n",
            "Epoch 90: val_loss improved from 1.58123 to 1.56313, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5268 - mean_absolute_error: 0.8077 - mean_squared_error: 1.5268 - val_loss: 1.5631 - val_mean_absolute_error: 0.8207 - val_mean_squared_error: 1.5631\n",
            "Epoch 91/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.5086 - mean_absolute_error: 0.8086 - mean_squared_error: 1.5086\n",
            "Epoch 91: val_loss improved from 1.56313 to 1.54139, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5070 - mean_absolute_error: 0.8072 - mean_squared_error: 1.5070 - val_loss: 1.5414 - val_mean_absolute_error: 0.8175 - val_mean_squared_error: 1.5414\n",
            "Epoch 92/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.4884 - mean_absolute_error: 0.8011 - mean_squared_error: 1.4884\n",
            "Epoch 92: val_loss did not improve from 1.54139\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4847 - mean_absolute_error: 0.8007 - mean_squared_error: 1.4847 - val_loss: 1.5443 - val_mean_absolute_error: 0.8417 - val_mean_squared_error: 1.5443\n",
            "Epoch 93/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.4532 - mean_absolute_error: 0.7949 - mean_squared_error: 1.4532\n",
            "Epoch 93: val_loss improved from 1.54139 to 1.48035, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4594 - mean_absolute_error: 0.7976 - mean_squared_error: 1.4594 - val_loss: 1.4803 - val_mean_absolute_error: 0.8141 - val_mean_squared_error: 1.4803\n",
            "Epoch 94/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.4333 - mean_absolute_error: 0.7910 - mean_squared_error: 1.4333\n",
            "Epoch 94: val_loss improved from 1.48035 to 1.45952, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4240 - mean_absolute_error: 0.7886 - mean_squared_error: 1.4240 - val_loss: 1.4595 - val_mean_absolute_error: 0.8004 - val_mean_squared_error: 1.4595\n",
            "Epoch 95/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.3839 - mean_absolute_error: 0.7750 - mean_squared_error: 1.3839\n",
            "Epoch 95: val_loss improved from 1.45952 to 1.42897, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3908 - mean_absolute_error: 0.7777 - mean_squared_error: 1.3908 - val_loss: 1.4290 - val_mean_absolute_error: 0.8036 - val_mean_squared_error: 1.4290\n",
            "Epoch 96/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.3433 - mean_absolute_error: 0.7695 - mean_squared_error: 1.3433\n",
            "Epoch 96: val_loss improved from 1.42897 to 1.37142, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3553 - mean_absolute_error: 0.7717 - mean_squared_error: 1.3553 - val_loss: 1.3714 - val_mean_absolute_error: 0.7714 - val_mean_squared_error: 1.3714\n",
            "Epoch 97/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.3165 - mean_absolute_error: 0.7547 - mean_squared_error: 1.3165\n",
            "Epoch 97: val_loss improved from 1.37142 to 1.33176, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3173 - mean_absolute_error: 0.7548 - mean_squared_error: 1.3173 - val_loss: 1.3318 - val_mean_absolute_error: 0.7684 - val_mean_squared_error: 1.3318\n",
            "Epoch 98/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.2877 - mean_absolute_error: 0.7514 - mean_squared_error: 1.2877\n",
            "Epoch 98: val_loss improved from 1.33176 to 1.28422, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 6ms/step - loss: 1.2831 - mean_absolute_error: 0.7498 - mean_squared_error: 1.2831 - val_loss: 1.2842 - val_mean_absolute_error: 0.7585 - val_mean_squared_error: 1.2842\n",
            "Epoch 99/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.2250 - mean_absolute_error: 0.7325 - mean_squared_error: 1.2250\n",
            "Epoch 99: val_loss improved from 1.28422 to 1.24637, saving model to best_model.h5\n",
            "245/245 [==============================] - 2s 6ms/step - loss: 1.2279 - mean_absolute_error: 0.7332 - mean_squared_error: 1.2279 - val_loss: 1.2464 - val_mean_absolute_error: 0.7476 - val_mean_squared_error: 1.2464\n",
            "Epoch 100/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.1872 - mean_absolute_error: 0.7206 - mean_squared_error: 1.1872\n",
            "Epoch 100: val_loss improved from 1.24637 to 1.19612, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1873 - mean_absolute_error: 0.7213 - mean_squared_error: 1.1873 - val_loss: 1.1961 - val_mean_absolute_error: 0.7245 - val_mean_squared_error: 1.1961\n",
            "Epoch 101/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.1241 - mean_absolute_error: 0.7032 - mean_squared_error: 1.1241\n",
            "Epoch 101: val_loss improved from 1.19612 to 1.16627, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1310 - mean_absolute_error: 0.7052 - mean_squared_error: 1.1310 - val_loss: 1.1663 - val_mean_absolute_error: 0.7285 - val_mean_squared_error: 1.1663\n",
            "Epoch 102/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.0861 - mean_absolute_error: 0.6926 - mean_squared_error: 1.0861\n",
            "Epoch 102: val_loss improved from 1.16627 to 1.09364, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0795 - mean_absolute_error: 0.6888 - mean_squared_error: 1.0795 - val_loss: 1.0936 - val_mean_absolute_error: 0.6900 - val_mean_squared_error: 1.0936\n",
            "Epoch 103/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.0359 - mean_absolute_error: 0.6736 - mean_squared_error: 1.0359\n",
            "Epoch 103: val_loss improved from 1.09364 to 1.08035, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0365 - mean_absolute_error: 0.6742 - mean_squared_error: 1.0365 - val_loss: 1.0803 - val_mean_absolute_error: 0.7059 - val_mean_squared_error: 1.0803\n",
            "Epoch 104/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.9876 - mean_absolute_error: 0.6585 - mean_squared_error: 0.9876\n",
            "Epoch 104: val_loss improved from 1.08035 to 0.98921, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9884 - mean_absolute_error: 0.6580 - mean_squared_error: 0.9884 - val_loss: 0.9892 - val_mean_absolute_error: 0.6599 - val_mean_squared_error: 0.9892\n",
            "Epoch 105/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.9346 - mean_absolute_error: 0.6388 - mean_squared_error: 0.9346\n",
            "Epoch 105: val_loss improved from 0.98921 to 0.95289, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9351 - mean_absolute_error: 0.6394 - mean_squared_error: 0.9351 - val_loss: 0.9529 - val_mean_absolute_error: 0.6491 - val_mean_squared_error: 0.9529\n",
            "Epoch 106/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 0.8866 - mean_absolute_error: 0.6238 - mean_squared_error: 0.8866\n",
            "Epoch 106: val_loss improved from 0.95289 to 0.90469, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8899 - mean_absolute_error: 0.6246 - mean_squared_error: 0.8899 - val_loss: 0.9047 - val_mean_absolute_error: 0.6332 - val_mean_squared_error: 0.9047\n",
            "Epoch 107/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.8455 - mean_absolute_error: 0.6112 - mean_squared_error: 0.8455\n",
            "Epoch 107: val_loss improved from 0.90469 to 0.86435, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8463 - mean_absolute_error: 0.6114 - mean_squared_error: 0.8463 - val_loss: 0.8644 - val_mean_absolute_error: 0.6097 - val_mean_squared_error: 0.8644\n",
            "Epoch 108/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.8103 - mean_absolute_error: 0.5997 - mean_squared_error: 0.8103\n",
            "Epoch 108: val_loss improved from 0.86435 to 0.83573, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8099 - mean_absolute_error: 0.5997 - mean_squared_error: 0.8099 - val_loss: 0.8357 - val_mean_absolute_error: 0.6131 - val_mean_squared_error: 0.8357\n",
            "Epoch 109/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.7778 - mean_absolute_error: 0.5934 - mean_squared_error: 0.7778\n",
            "Epoch 109: val_loss improved from 0.83573 to 0.81464, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.7782 - mean_absolute_error: 0.5933 - mean_squared_error: 0.7782 - val_loss: 0.8146 - val_mean_absolute_error: 0.6042 - val_mean_squared_error: 0.8146\n",
            "Epoch 110/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.7522 - mean_absolute_error: 0.5857 - mean_squared_error: 0.7522\n",
            "Epoch 110: val_loss improved from 0.81464 to 0.78802, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.7525 - mean_absolute_error: 0.5861 - mean_squared_error: 0.7525 - val_loss: 0.7880 - val_mean_absolute_error: 0.6007 - val_mean_squared_error: 0.7880\n",
            "Epoch 111/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.7250 - mean_absolute_error: 0.5803 - mean_squared_error: 0.7250\n",
            "Epoch 111: val_loss improved from 0.78802 to 0.76308, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.7205 - mean_absolute_error: 0.5787 - mean_squared_error: 0.7205 - val_loss: 0.7631 - val_mean_absolute_error: 0.5851 - val_mean_squared_error: 0.7631\n",
            "Epoch 112/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.6990 - mean_absolute_error: 0.5685 - mean_squared_error: 0.6990\n",
            "Epoch 112: val_loss improved from 0.76308 to 0.72776, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6987 - mean_absolute_error: 0.5692 - mean_squared_error: 0.6987 - val_loss: 0.7278 - val_mean_absolute_error: 0.5807 - val_mean_squared_error: 0.7278\n",
            "Epoch 113/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.6672 - mean_absolute_error: 0.5584 - mean_squared_error: 0.6672\n",
            "Epoch 113: val_loss improved from 0.72776 to 0.72013, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6679 - mean_absolute_error: 0.5580 - mean_squared_error: 0.6679 - val_loss: 0.7201 - val_mean_absolute_error: 0.5872 - val_mean_squared_error: 0.7201\n",
            "Epoch 114/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.6412 - mean_absolute_error: 0.5491 - mean_squared_error: 0.6412\n",
            "Epoch 114: val_loss improved from 0.72013 to 0.68906, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6469 - mean_absolute_error: 0.5522 - mean_squared_error: 0.6469 - val_loss: 0.6891 - val_mean_absolute_error: 0.5665 - val_mean_squared_error: 0.6891\n",
            "Epoch 115/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.6255 - mean_absolute_error: 0.5426 - mean_squared_error: 0.6255\n",
            "Epoch 115: val_loss improved from 0.68906 to 0.67339, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6251 - mean_absolute_error: 0.5426 - mean_squared_error: 0.6251 - val_loss: 0.6734 - val_mean_absolute_error: 0.5688 - val_mean_squared_error: 0.6734\n",
            "Epoch 116/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.5983 - mean_absolute_error: 0.5338 - mean_squared_error: 0.5983\n",
            "Epoch 116: val_loss improved from 0.67339 to 0.63706, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6025 - mean_absolute_error: 0.5353 - mean_squared_error: 0.6025 - val_loss: 0.6371 - val_mean_absolute_error: 0.5465 - val_mean_squared_error: 0.6371\n",
            "Epoch 117/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.5847 - mean_absolute_error: 0.5264 - mean_squared_error: 0.5847\n",
            "Epoch 117: val_loss improved from 0.63706 to 0.62306, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5847 - mean_absolute_error: 0.5272 - mean_squared_error: 0.5847 - val_loss: 0.6231 - val_mean_absolute_error: 0.5376 - val_mean_squared_error: 0.6231\n",
            "Epoch 118/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.5654 - mean_absolute_error: 0.5159 - mean_squared_error: 0.5654\n",
            "Epoch 118: val_loss improved from 0.62306 to 0.58565, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5631 - mean_absolute_error: 0.5157 - mean_squared_error: 0.5631 - val_loss: 0.5856 - val_mean_absolute_error: 0.5227 - val_mean_squared_error: 0.5856\n",
            "Epoch 119/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.5460 - mean_absolute_error: 0.5097 - mean_squared_error: 0.5460\n",
            "Epoch 119: val_loss improved from 0.58565 to 0.57548, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5448 - mean_absolute_error: 0.5091 - mean_squared_error: 0.5448 - val_loss: 0.5755 - val_mean_absolute_error: 0.5114 - val_mean_squared_error: 0.5755\n",
            "Epoch 120/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 0.5266 - mean_absolute_error: 0.4991 - mean_squared_error: 0.5266\n",
            "Epoch 120: val_loss improved from 0.57548 to 0.54551, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5230 - mean_absolute_error: 0.4963 - mean_squared_error: 0.5230 - val_loss: 0.5455 - val_mean_absolute_error: 0.5051 - val_mean_squared_error: 0.5455\n",
            "Epoch 121/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.5032 - mean_absolute_error: 0.4886 - mean_squared_error: 0.5032\n",
            "Epoch 121: val_loss improved from 0.54551 to 0.53358, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5051 - mean_absolute_error: 0.4892 - mean_squared_error: 0.5051 - val_loss: 0.5336 - val_mean_absolute_error: 0.4960 - val_mean_squared_error: 0.5336\n",
            "Epoch 122/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.4832 - mean_absolute_error: 0.4775 - mean_squared_error: 0.4832\n",
            "Epoch 122: val_loss improved from 0.53358 to 0.50752, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4853 - mean_absolute_error: 0.4788 - mean_squared_error: 0.4853 - val_loss: 0.5075 - val_mean_absolute_error: 0.4905 - val_mean_squared_error: 0.5075\n",
            "Epoch 123/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.4689 - mean_absolute_error: 0.4719 - mean_squared_error: 0.4689\n",
            "Epoch 123: val_loss improved from 0.50752 to 0.49665, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4676 - mean_absolute_error: 0.4719 - mean_squared_error: 0.4676 - val_loss: 0.4967 - val_mean_absolute_error: 0.4916 - val_mean_squared_error: 0.4967\n",
            "Epoch 124/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.4529 - mean_absolute_error: 0.4616 - mean_squared_error: 0.4529\n",
            "Epoch 124: val_loss improved from 0.49665 to 0.47309, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4502 - mean_absolute_error: 0.4608 - mean_squared_error: 0.4502 - val_loss: 0.4731 - val_mean_absolute_error: 0.4744 - val_mean_squared_error: 0.4731\n",
            "Epoch 125/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.4330 - mean_absolute_error: 0.4551 - mean_squared_error: 0.4330\n",
            "Epoch 125: val_loss improved from 0.47309 to 0.46016, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4340 - mean_absolute_error: 0.4556 - mean_squared_error: 0.4340 - val_loss: 0.4602 - val_mean_absolute_error: 0.4722 - val_mean_squared_error: 0.4602\n",
            "Epoch 126/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.4150 - mean_absolute_error: 0.4457 - mean_squared_error: 0.4150\n",
            "Epoch 126: val_loss improved from 0.46016 to 0.42830, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4145 - mean_absolute_error: 0.4462 - mean_squared_error: 0.4145 - val_loss: 0.4283 - val_mean_absolute_error: 0.4461 - val_mean_squared_error: 0.4283\n",
            "Epoch 127/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.4042 - mean_absolute_error: 0.4386 - mean_squared_error: 0.4042\n",
            "Epoch 127: val_loss improved from 0.42830 to 0.41238, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4001 - mean_absolute_error: 0.4370 - mean_squared_error: 0.4001 - val_loss: 0.4124 - val_mean_absolute_error: 0.4432 - val_mean_squared_error: 0.4124\n",
            "Epoch 128/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.3848 - mean_absolute_error: 0.4268 - mean_squared_error: 0.3848\n",
            "Epoch 128: val_loss improved from 0.41238 to 0.40160, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.3843 - mean_absolute_error: 0.4281 - mean_squared_error: 0.3843 - val_loss: 0.4016 - val_mean_absolute_error: 0.4460 - val_mean_squared_error: 0.4016\n",
            "Epoch 129/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.3680 - mean_absolute_error: 0.4215 - mean_squared_error: 0.3680\n",
            "Epoch 129: val_loss improved from 0.40160 to 0.38134, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.3715 - mean_absolute_error: 0.4235 - mean_squared_error: 0.3715 - val_loss: 0.3813 - val_mean_absolute_error: 0.4262 - val_mean_squared_error: 0.3813\n",
            "Epoch 130/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.3495 - mean_absolute_error: 0.4098 - mean_squared_error: 0.3495\n",
            "Epoch 130: val_loss improved from 0.38134 to 0.36663, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.3541 - mean_absolute_error: 0.4126 - mean_squared_error: 0.3541 - val_loss: 0.3666 - val_mean_absolute_error: 0.4167 - val_mean_squared_error: 0.3666\n",
            "Epoch 131/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.3446 - mean_absolute_error: 0.4072 - mean_squared_error: 0.3446\n",
            "Epoch 131: val_loss improved from 0.36663 to 0.35686, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.3428 - mean_absolute_error: 0.4067 - mean_squared_error: 0.3428 - val_loss: 0.3569 - val_mean_absolute_error: 0.4173 - val_mean_squared_error: 0.3569\n",
            "Epoch 132/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.3345 - mean_absolute_error: 0.4039 - mean_squared_error: 0.3345\n",
            "Epoch 132: val_loss did not improve from 0.35686\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.3340 - mean_absolute_error: 0.4034 - mean_squared_error: 0.3340 - val_loss: 0.3578 - val_mean_absolute_error: 0.4205 - val_mean_squared_error: 0.3578\n",
            "Epoch 133/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.3229 - mean_absolute_error: 0.3966 - mean_squared_error: 0.3229\n",
            "Epoch 133: val_loss improved from 0.35686 to 0.33709, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.3241 - mean_absolute_error: 0.3975 - mean_squared_error: 0.3241 - val_loss: 0.3371 - val_mean_absolute_error: 0.4083 - val_mean_squared_error: 0.3371\n",
            "Epoch 134/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.3145 - mean_absolute_error: 0.3943 - mean_squared_error: 0.3145\n",
            "Epoch 134: val_loss improved from 0.33709 to 0.32608, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.3137 - mean_absolute_error: 0.3938 - mean_squared_error: 0.3137 - val_loss: 0.3261 - val_mean_absolute_error: 0.3926 - val_mean_squared_error: 0.3261\n",
            "Epoch 135/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.3027 - mean_absolute_error: 0.3857 - mean_squared_error: 0.3027\n",
            "Epoch 135: val_loss improved from 0.32608 to 0.32367, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.3042 - mean_absolute_error: 0.3875 - mean_squared_error: 0.3042 - val_loss: 0.3237 - val_mean_absolute_error: 0.3974 - val_mean_squared_error: 0.3237\n",
            "Epoch 136/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.2947 - mean_absolute_error: 0.3832 - mean_squared_error: 0.2947\n",
            "Epoch 136: val_loss improved from 0.32367 to 0.30909, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.2957 - mean_absolute_error: 0.3839 - mean_squared_error: 0.2957 - val_loss: 0.3091 - val_mean_absolute_error: 0.3928 - val_mean_squared_error: 0.3091\n",
            "Epoch 137/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.2909 - mean_absolute_error: 0.3801 - mean_squared_error: 0.2909\n",
            "Epoch 137: val_loss did not improve from 0.30909\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.2885 - mean_absolute_error: 0.3790 - mean_squared_error: 0.2885 - val_loss: 0.3097 - val_mean_absolute_error: 0.3987 - val_mean_squared_error: 0.3097\n",
            "Epoch 138/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.2847 - mean_absolute_error: 0.3771 - mean_squared_error: 0.2847\n",
            "Epoch 138: val_loss improved from 0.30909 to 0.28801, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.2806 - mean_absolute_error: 0.3745 - mean_squared_error: 0.2806 - val_loss: 0.2880 - val_mean_absolute_error: 0.3759 - val_mean_squared_error: 0.2880\n",
            "Epoch 139/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.2741 - mean_absolute_error: 0.3695 - mean_squared_error: 0.2741\n",
            "Epoch 139: val_loss improved from 0.28801 to 0.28166, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.2728 - mean_absolute_error: 0.3694 - mean_squared_error: 0.2728 - val_loss: 0.2817 - val_mean_absolute_error: 0.3799 - val_mean_squared_error: 0.2817\n",
            "Epoch 140/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.2678 - mean_absolute_error: 0.3686 - mean_squared_error: 0.2678\n",
            "Epoch 140: val_loss improved from 0.28166 to 0.27151, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.2665 - mean_absolute_error: 0.3678 - mean_squared_error: 0.2665 - val_loss: 0.2715 - val_mean_absolute_error: 0.3708 - val_mean_squared_error: 0.2715\n",
            "Epoch 141/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.2577 - mean_absolute_error: 0.3615 - mean_squared_error: 0.2577\n",
            "Epoch 141: val_loss did not improve from 0.27151\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.2567 - mean_absolute_error: 0.3611 - mean_squared_error: 0.2567 - val_loss: 0.2780 - val_mean_absolute_error: 0.3687 - val_mean_squared_error: 0.2780\n",
            "Epoch 142/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 0.2541 - mean_absolute_error: 0.3596 - mean_squared_error: 0.2541\n",
            "Epoch 142: val_loss improved from 0.27151 to 0.26217, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.2523 - mean_absolute_error: 0.3578 - mean_squared_error: 0.2523 - val_loss: 0.2622 - val_mean_absolute_error: 0.3656 - val_mean_squared_error: 0.2622\n",
            "Epoch 143/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.2482 - mean_absolute_error: 0.3584 - mean_squared_error: 0.2482\n",
            "Epoch 143: val_loss improved from 0.26217 to 0.25443, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.2478 - mean_absolute_error: 0.3582 - mean_squared_error: 0.2478 - val_loss: 0.2544 - val_mean_absolute_error: 0.3626 - val_mean_squared_error: 0.2544\n",
            "Epoch 144/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.2422 - mean_absolute_error: 0.3538 - mean_squared_error: 0.2422\n",
            "Epoch 144: val_loss did not improve from 0.25443\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.2419 - mean_absolute_error: 0.3529 - mean_squared_error: 0.2419 - val_loss: 0.2633 - val_mean_absolute_error: 0.3649 - val_mean_squared_error: 0.2633\n",
            "Epoch 145/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.2362 - mean_absolute_error: 0.3479 - mean_squared_error: 0.2362\n",
            "Epoch 145: val_loss improved from 0.25443 to 0.24793, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.2363 - mean_absolute_error: 0.3480 - mean_squared_error: 0.2363 - val_loss: 0.2479 - val_mean_absolute_error: 0.3578 - val_mean_squared_error: 0.2479\n",
            "Epoch 146/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.2292 - mean_absolute_error: 0.3451 - mean_squared_error: 0.2292\n",
            "Epoch 146: val_loss improved from 0.24793 to 0.24390, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.2320 - mean_absolute_error: 0.3464 - mean_squared_error: 0.2320 - val_loss: 0.2439 - val_mean_absolute_error: 0.3607 - val_mean_squared_error: 0.2439\n",
            "Epoch 147/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.2263 - mean_absolute_error: 0.3441 - mean_squared_error: 0.2263\n",
            "Epoch 147: val_loss improved from 0.24390 to 0.24041, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.2262 - mean_absolute_error: 0.3435 - mean_squared_error: 0.2262 - val_loss: 0.2404 - val_mean_absolute_error: 0.3493 - val_mean_squared_error: 0.2404\n",
            "Epoch 148/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.2211 - mean_absolute_error: 0.3414 - mean_squared_error: 0.2211\n",
            "Epoch 148: val_loss improved from 0.24041 to 0.23319, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.2231 - mean_absolute_error: 0.3417 - mean_squared_error: 0.2231 - val_loss: 0.2332 - val_mean_absolute_error: 0.3463 - val_mean_squared_error: 0.2332\n",
            "Epoch 149/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.2201 - mean_absolute_error: 0.3391 - mean_squared_error: 0.2201\n",
            "Epoch 149: val_loss did not improve from 0.23319\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.2195 - mean_absolute_error: 0.3391 - mean_squared_error: 0.2195 - val_loss: 0.2395 - val_mean_absolute_error: 0.3562 - val_mean_squared_error: 0.2395\n",
            "Epoch 150/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.2164 - mean_absolute_error: 0.3356 - mean_squared_error: 0.2164\n",
            "Epoch 150: val_loss did not improve from 0.23319\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.2163 - mean_absolute_error: 0.3353 - mean_squared_error: 0.2163 - val_loss: 0.2432 - val_mean_absolute_error: 0.3531 - val_mean_squared_error: 0.2432\n",
            "Epoch 151/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.2141 - mean_absolute_error: 0.3354 - mean_squared_error: 0.2141\n",
            "Epoch 151: val_loss improved from 0.23319 to 0.23139, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.2139 - mean_absolute_error: 0.3351 - mean_squared_error: 0.2139 - val_loss: 0.2314 - val_mean_absolute_error: 0.3464 - val_mean_squared_error: 0.2314\n",
            "Epoch 152/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.2094 - mean_absolute_error: 0.3307 - mean_squared_error: 0.2094\n",
            "Epoch 152: val_loss improved from 0.23139 to 0.22831, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.2096 - mean_absolute_error: 0.3315 - mean_squared_error: 0.2096 - val_loss: 0.2283 - val_mean_absolute_error: 0.3426 - val_mean_squared_error: 0.2283\n",
            "Epoch 153/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.2090 - mean_absolute_error: 0.3305 - mean_squared_error: 0.2090\n",
            "Epoch 153: val_loss improved from 0.22831 to 0.21883, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.2088 - mean_absolute_error: 0.3307 - mean_squared_error: 0.2088 - val_loss: 0.2188 - val_mean_absolute_error: 0.3378 - val_mean_squared_error: 0.2188\n",
            "Epoch 154/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.2050 - mean_absolute_error: 0.3289 - mean_squared_error: 0.2050\n",
            "Epoch 154: val_loss did not improve from 0.21883\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2055 - mean_absolute_error: 0.3298 - mean_squared_error: 0.2055 - val_loss: 0.2197 - val_mean_absolute_error: 0.3376 - val_mean_squared_error: 0.2197\n",
            "Epoch 155/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.2072 - mean_absolute_error: 0.3296 - mean_squared_error: 0.2072\n",
            "Epoch 155: val_loss improved from 0.21883 to 0.21322, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.2070 - mean_absolute_error: 0.3297 - mean_squared_error: 0.2070 - val_loss: 0.2132 - val_mean_absolute_error: 0.3368 - val_mean_squared_error: 0.2132\n",
            "Epoch 156/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.2008 - mean_absolute_error: 0.3256 - mean_squared_error: 0.2008\n",
            "Epoch 156: val_loss did not improve from 0.21322\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2001 - mean_absolute_error: 0.3253 - mean_squared_error: 0.2001 - val_loss: 0.2171 - val_mean_absolute_error: 0.3390 - val_mean_squared_error: 0.2171\n",
            "Epoch 157/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.2005 - mean_absolute_error: 0.3265 - mean_squared_error: 0.2005\n",
            "Epoch 157: val_loss did not improve from 0.21322\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2030 - mean_absolute_error: 0.3276 - mean_squared_error: 0.2030 - val_loss: 0.2195 - val_mean_absolute_error: 0.3362 - val_mean_squared_error: 0.2195\n",
            "Epoch 158/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.1958 - mean_absolute_error: 0.3224 - mean_squared_error: 0.1958\n",
            "Epoch 158: val_loss improved from 0.21322 to 0.21047, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1974 - mean_absolute_error: 0.3234 - mean_squared_error: 0.1974 - val_loss: 0.2105 - val_mean_absolute_error: 0.3338 - val_mean_squared_error: 0.2105\n",
            "Epoch 159/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.1941 - mean_absolute_error: 0.3211 - mean_squared_error: 0.1941\n",
            "Epoch 159: val_loss improved from 0.21047 to 0.20715, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1954 - mean_absolute_error: 0.3218 - mean_squared_error: 0.1954 - val_loss: 0.2071 - val_mean_absolute_error: 0.3286 - val_mean_squared_error: 0.2071\n",
            "Epoch 160/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 0.1951 - mean_absolute_error: 0.3215 - mean_squared_error: 0.1951\n",
            "Epoch 160: val_loss improved from 0.20715 to 0.20640, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1940 - mean_absolute_error: 0.3210 - mean_squared_error: 0.1940 - val_loss: 0.2064 - val_mean_absolute_error: 0.3284 - val_mean_squared_error: 0.2064\n",
            "Epoch 161/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.1922 - mean_absolute_error: 0.3203 - mean_squared_error: 0.1922\n",
            "Epoch 161: val_loss did not improve from 0.20640\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.1922 - mean_absolute_error: 0.3203 - mean_squared_error: 0.1922 - val_loss: 0.2105 - val_mean_absolute_error: 0.3293 - val_mean_squared_error: 0.2105\n",
            "Epoch 162/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.1912 - mean_absolute_error: 0.3195 - mean_squared_error: 0.1912\n",
            "Epoch 162: val_loss did not improve from 0.20640\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.1903 - mean_absolute_error: 0.3185 - mean_squared_error: 0.1903 - val_loss: 0.2094 - val_mean_absolute_error: 0.3310 - val_mean_squared_error: 0.2094\n",
            "Epoch 163/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.1915 - mean_absolute_error: 0.3190 - mean_squared_error: 0.1915\n",
            "Epoch 163: val_loss did not improve from 0.20640\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1902 - mean_absolute_error: 0.3179 - mean_squared_error: 0.1902 - val_loss: 0.2085 - val_mean_absolute_error: 0.3385 - val_mean_squared_error: 0.2085\n",
            "Epoch 164/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.1896 - mean_absolute_error: 0.3188 - mean_squared_error: 0.1896\n",
            "Epoch 164: val_loss improved from 0.20640 to 0.19965, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1880 - mean_absolute_error: 0.3179 - mean_squared_error: 0.1880 - val_loss: 0.1997 - val_mean_absolute_error: 0.3258 - val_mean_squared_error: 0.1997\n",
            "Epoch 165/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.1855 - mean_absolute_error: 0.3162 - mean_squared_error: 0.1855\n",
            "Epoch 165: val_loss did not improve from 0.19965\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1850 - mean_absolute_error: 0.3154 - mean_squared_error: 0.1850 - val_loss: 0.2017 - val_mean_absolute_error: 0.3248 - val_mean_squared_error: 0.2017\n",
            "Epoch 166/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.1865 - mean_absolute_error: 0.3170 - mean_squared_error: 0.1865\n",
            "Epoch 166: val_loss did not improve from 0.19965\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1863 - mean_absolute_error: 0.3169 - mean_squared_error: 0.1863 - val_loss: 0.2032 - val_mean_absolute_error: 0.3265 - val_mean_squared_error: 0.2032\n",
            "Epoch 167/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.1856 - mean_absolute_error: 0.3126 - mean_squared_error: 0.1856\n",
            "Epoch 167: val_loss did not improve from 0.19965\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1853 - mean_absolute_error: 0.3135 - mean_squared_error: 0.1853 - val_loss: 0.2122 - val_mean_absolute_error: 0.3468 - val_mean_squared_error: 0.2122\n",
            "Epoch 168/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.1818 - mean_absolute_error: 0.3136 - mean_squared_error: 0.1818\n",
            "Epoch 168: val_loss improved from 0.19965 to 0.19865, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1822 - mean_absolute_error: 0.3139 - mean_squared_error: 0.1822 - val_loss: 0.1986 - val_mean_absolute_error: 0.3254 - val_mean_squared_error: 0.1986\n",
            "Epoch 169/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.1804 - mean_absolute_error: 0.3116 - mean_squared_error: 0.1804\n",
            "Epoch 169: val_loss did not improve from 0.19865\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1809 - mean_absolute_error: 0.3107 - mean_squared_error: 0.1809 - val_loss: 0.2010 - val_mean_absolute_error: 0.3295 - val_mean_squared_error: 0.2010\n",
            "Epoch 170/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.1814 - mean_absolute_error: 0.3124 - mean_squared_error: 0.1814\n",
            "Epoch 170: val_loss improved from 0.19865 to 0.19718, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1809 - mean_absolute_error: 0.3119 - mean_squared_error: 0.1809 - val_loss: 0.1972 - val_mean_absolute_error: 0.3260 - val_mean_squared_error: 0.1972\n",
            "Epoch 171/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.1792 - mean_absolute_error: 0.3093 - mean_squared_error: 0.1792\n",
            "Epoch 171: val_loss improved from 0.19718 to 0.19133, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1785 - mean_absolute_error: 0.3094 - mean_squared_error: 0.1785 - val_loss: 0.1913 - val_mean_absolute_error: 0.3178 - val_mean_squared_error: 0.1913\n",
            "Epoch 172/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.1759 - mean_absolute_error: 0.3095 - mean_squared_error: 0.1759\n",
            "Epoch 172: val_loss did not improve from 0.19133\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1771 - mean_absolute_error: 0.3102 - mean_squared_error: 0.1771 - val_loss: 0.2029 - val_mean_absolute_error: 0.3340 - val_mean_squared_error: 0.2029\n",
            "Epoch 173/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.1791 - mean_absolute_error: 0.3117 - mean_squared_error: 0.1791\n",
            "Epoch 173: val_loss did not improve from 0.19133\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1799 - mean_absolute_error: 0.3130 - mean_squared_error: 0.1799 - val_loss: 0.1986 - val_mean_absolute_error: 0.3320 - val_mean_squared_error: 0.1986\n",
            "Epoch 174/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.1751 - mean_absolute_error: 0.3075 - mean_squared_error: 0.1751\n",
            "Epoch 174: val_loss did not improve from 0.19133\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1732 - mean_absolute_error: 0.3064 - mean_squared_error: 0.1732 - val_loss: 0.1943 - val_mean_absolute_error: 0.3151 - val_mean_squared_error: 0.1943\n",
            "Epoch 175/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.1721 - mean_absolute_error: 0.3037 - mean_squared_error: 0.1721\n",
            "Epoch 175: val_loss improved from 0.19133 to 0.18838, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1741 - mean_absolute_error: 0.3053 - mean_squared_error: 0.1741 - val_loss: 0.1884 - val_mean_absolute_error: 0.3160 - val_mean_squared_error: 0.1884\n",
            "Epoch 176/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.1710 - mean_absolute_error: 0.3044 - mean_squared_error: 0.1710\n",
            "Epoch 176: val_loss did not improve from 0.18838\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1726 - mean_absolute_error: 0.3055 - mean_squared_error: 0.1726 - val_loss: 0.2003 - val_mean_absolute_error: 0.3243 - val_mean_squared_error: 0.2003\n",
            "Epoch 177/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.1719 - mean_absolute_error: 0.3041 - mean_squared_error: 0.1719\n",
            "Epoch 177: val_loss improved from 0.18838 to 0.18634, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1721 - mean_absolute_error: 0.3046 - mean_squared_error: 0.1721 - val_loss: 0.1863 - val_mean_absolute_error: 0.3175 - val_mean_squared_error: 0.1863\n",
            "Epoch 178/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.1699 - mean_absolute_error: 0.3026 - mean_squared_error: 0.1699\n",
            "Epoch 178: val_loss did not improve from 0.18634\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1686 - mean_absolute_error: 0.3024 - mean_squared_error: 0.1686 - val_loss: 0.1883 - val_mean_absolute_error: 0.3210 - val_mean_squared_error: 0.1883\n",
            "Epoch 179/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.1673 - mean_absolute_error: 0.3020 - mean_squared_error: 0.1673\n",
            "Epoch 179: val_loss improved from 0.18634 to 0.18027, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1659 - mean_absolute_error: 0.3006 - mean_squared_error: 0.1659 - val_loss: 0.1803 - val_mean_absolute_error: 0.3105 - val_mean_squared_error: 0.1803\n",
            "Epoch 180/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.1622 - mean_absolute_error: 0.2968 - mean_squared_error: 0.1622\n",
            "Epoch 180: val_loss did not improve from 0.18027\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1628 - mean_absolute_error: 0.2972 - mean_squared_error: 0.1628 - val_loss: 0.1842 - val_mean_absolute_error: 0.3138 - val_mean_squared_error: 0.1842\n",
            "Epoch 181/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.1616 - mean_absolute_error: 0.2969 - mean_squared_error: 0.1616\n",
            "Epoch 181: val_loss improved from 0.18027 to 0.17986, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1618 - mean_absolute_error: 0.2971 - mean_squared_error: 0.1618 - val_loss: 0.1799 - val_mean_absolute_error: 0.3121 - val_mean_squared_error: 0.1799\n",
            "Epoch 182/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.1617 - mean_absolute_error: 0.2966 - mean_squared_error: 0.1617\n",
            "Epoch 182: val_loss did not improve from 0.17986\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1617 - mean_absolute_error: 0.2966 - mean_squared_error: 0.1617 - val_loss: 0.1833 - val_mean_absolute_error: 0.3126 - val_mean_squared_error: 0.1833\n",
            "Epoch 183/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 0.1579 - mean_absolute_error: 0.2960 - mean_squared_error: 0.1579\n",
            "Epoch 183: val_loss improved from 0.17986 to 0.17818, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1591 - mean_absolute_error: 0.2964 - mean_squared_error: 0.1591 - val_loss: 0.1782 - val_mean_absolute_error: 0.3096 - val_mean_squared_error: 0.1782\n",
            "Epoch 184/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.1574 - mean_absolute_error: 0.2931 - mean_squared_error: 0.1574\n",
            "Epoch 184: val_loss improved from 0.17818 to 0.17256, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1576 - mean_absolute_error: 0.2930 - mean_squared_error: 0.1576 - val_loss: 0.1726 - val_mean_absolute_error: 0.3067 - val_mean_squared_error: 0.1726\n",
            "Epoch 185/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.1530 - mean_absolute_error: 0.2895 - mean_squared_error: 0.1530\n",
            "Epoch 185: val_loss improved from 0.17256 to 0.16941, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1544 - mean_absolute_error: 0.2908 - mean_squared_error: 0.1544 - val_loss: 0.1694 - val_mean_absolute_error: 0.3061 - val_mean_squared_error: 0.1694\n",
            "Epoch 186/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.1561 - mean_absolute_error: 0.2936 - mean_squared_error: 0.1561\n",
            "Epoch 186: val_loss did not improve from 0.16941\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1557 - mean_absolute_error: 0.2932 - mean_squared_error: 0.1557 - val_loss: 0.1748 - val_mean_absolute_error: 0.3127 - val_mean_squared_error: 0.1748\n",
            "Epoch 187/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.1514 - mean_absolute_error: 0.2887 - mean_squared_error: 0.1514\n",
            "Epoch 187: val_loss did not improve from 0.16941\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1517 - mean_absolute_error: 0.2888 - mean_squared_error: 0.1517 - val_loss: 0.1723 - val_mean_absolute_error: 0.3041 - val_mean_squared_error: 0.1723\n",
            "Epoch 188/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.1530 - mean_absolute_error: 0.2915 - mean_squared_error: 0.1530\n",
            "Epoch 188: val_loss improved from 0.16941 to 0.16118, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1509 - mean_absolute_error: 0.2890 - mean_squared_error: 0.1509 - val_loss: 0.1612 - val_mean_absolute_error: 0.2961 - val_mean_squared_error: 0.1612\n",
            "Epoch 189/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.1497 - mean_absolute_error: 0.2874 - mean_squared_error: 0.1497\n",
            "Epoch 189: val_loss did not improve from 0.16118\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1484 - mean_absolute_error: 0.2871 - mean_squared_error: 0.1484 - val_loss: 0.1654 - val_mean_absolute_error: 0.2989 - val_mean_squared_error: 0.1654\n",
            "Epoch 190/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.1475 - mean_absolute_error: 0.2844 - mean_squared_error: 0.1475\n",
            "Epoch 190: val_loss did not improve from 0.16118\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1471 - mean_absolute_error: 0.2841 - mean_squared_error: 0.1471 - val_loss: 0.1637 - val_mean_absolute_error: 0.2998 - val_mean_squared_error: 0.1637\n",
            "Epoch 191/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.1447 - mean_absolute_error: 0.2846 - mean_squared_error: 0.1447\n",
            "Epoch 191: val_loss did not improve from 0.16118\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1458 - mean_absolute_error: 0.2852 - mean_squared_error: 0.1458 - val_loss: 0.1645 - val_mean_absolute_error: 0.2987 - val_mean_squared_error: 0.1645\n",
            "Epoch 192/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.1428 - mean_absolute_error: 0.2820 - mean_squared_error: 0.1428\n",
            "Epoch 192: val_loss improved from 0.16118 to 0.15031, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1426 - mean_absolute_error: 0.2818 - mean_squared_error: 0.1426 - val_loss: 0.1503 - val_mean_absolute_error: 0.2884 - val_mean_squared_error: 0.1503\n",
            "Epoch 193/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.1407 - mean_absolute_error: 0.2805 - mean_squared_error: 0.1407\n",
            "Epoch 193: val_loss did not improve from 0.15031\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1417 - mean_absolute_error: 0.2811 - mean_squared_error: 0.1417 - val_loss: 0.1541 - val_mean_absolute_error: 0.2938 - val_mean_squared_error: 0.1541\n",
            "Epoch 194/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.1403 - mean_absolute_error: 0.2805 - mean_squared_error: 0.1403\n",
            "Epoch 194: val_loss did not improve from 0.15031\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1403 - mean_absolute_error: 0.2804 - mean_squared_error: 0.1403 - val_loss: 0.1548 - val_mean_absolute_error: 0.2902 - val_mean_squared_error: 0.1548\n",
            "Epoch 195/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.1395 - mean_absolute_error: 0.2797 - mean_squared_error: 0.1395\n",
            "Epoch 195: val_loss did not improve from 0.15031\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1404 - mean_absolute_error: 0.2804 - mean_squared_error: 0.1404 - val_loss: 0.1607 - val_mean_absolute_error: 0.2970 - val_mean_squared_error: 0.1607\n",
            "Epoch 196/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.1372 - mean_absolute_error: 0.2772 - mean_squared_error: 0.1372\n",
            "Epoch 196: val_loss did not improve from 0.15031\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1379 - mean_absolute_error: 0.2781 - mean_squared_error: 0.1379 - val_loss: 0.1607 - val_mean_absolute_error: 0.2966 - val_mean_squared_error: 0.1607\n",
            "Epoch 197/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.1352 - mean_absolute_error: 0.2738 - mean_squared_error: 0.1352\n",
            "Epoch 197: val_loss improved from 0.15031 to 0.14627, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1338 - mean_absolute_error: 0.2728 - mean_squared_error: 0.1338 - val_loss: 0.1463 - val_mean_absolute_error: 0.2877 - val_mean_squared_error: 0.1463\n",
            "Epoch 198/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.1331 - mean_absolute_error: 0.2733 - mean_squared_error: 0.1331\n",
            "Epoch 198: val_loss did not improve from 0.14627\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1331 - mean_absolute_error: 0.2728 - mean_squared_error: 0.1331 - val_loss: 0.1517 - val_mean_absolute_error: 0.2853 - val_mean_squared_error: 0.1517\n",
            "Epoch 199/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.1321 - mean_absolute_error: 0.2725 - mean_squared_error: 0.1321\n",
            "Epoch 199: val_loss did not improve from 0.14627\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1320 - mean_absolute_error: 0.2719 - mean_squared_error: 0.1320 - val_loss: 0.1497 - val_mean_absolute_error: 0.2838 - val_mean_squared_error: 0.1497\n",
            "Epoch 200/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.1308 - mean_absolute_error: 0.2718 - mean_squared_error: 0.1308\n",
            "Epoch 200: val_loss did not improve from 0.14627\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1304 - mean_absolute_error: 0.2714 - mean_squared_error: 0.1304 - val_loss: 0.1546 - val_mean_absolute_error: 0.2934 - val_mean_squared_error: 0.1546\n",
            "Epoch 201/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 0.1306 - mean_absolute_error: 0.2701 - mean_squared_error: 0.1306\n",
            "Epoch 201: val_loss improved from 0.14627 to 0.14397, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1284 - mean_absolute_error: 0.2679 - mean_squared_error: 0.1284 - val_loss: 0.1440 - val_mean_absolute_error: 0.2833 - val_mean_squared_error: 0.1440\n",
            "Epoch 202/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.1283 - mean_absolute_error: 0.2699 - mean_squared_error: 0.1283\n",
            "Epoch 202: val_loss did not improve from 0.14397\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1284 - mean_absolute_error: 0.2699 - mean_squared_error: 0.1284 - val_loss: 0.1453 - val_mean_absolute_error: 0.2858 - val_mean_squared_error: 0.1453\n",
            "Epoch 203/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.1247 - mean_absolute_error: 0.2658 - mean_squared_error: 0.1247\n",
            "Epoch 203: val_loss improved from 0.14397 to 0.13660, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1256 - mean_absolute_error: 0.2664 - mean_squared_error: 0.1256 - val_loss: 0.1366 - val_mean_absolute_error: 0.2753 - val_mean_squared_error: 0.1366\n",
            "Epoch 204/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.1250 - mean_absolute_error: 0.2650 - mean_squared_error: 0.1250\n",
            "Epoch 204: val_loss improved from 0.13660 to 0.13580, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1251 - mean_absolute_error: 0.2652 - mean_squared_error: 0.1251 - val_loss: 0.1358 - val_mean_absolute_error: 0.2738 - val_mean_squared_error: 0.1358\n",
            "Epoch 205/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.1221 - mean_absolute_error: 0.2646 - mean_squared_error: 0.1221\n",
            "Epoch 205: val_loss improved from 0.13580 to 0.13479, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1217 - mean_absolute_error: 0.2633 - mean_squared_error: 0.1217 - val_loss: 0.1348 - val_mean_absolute_error: 0.2695 - val_mean_squared_error: 0.1348\n",
            "Epoch 206/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.1196 - mean_absolute_error: 0.2606 - mean_squared_error: 0.1196\n",
            "Epoch 206: val_loss improved from 0.13479 to 0.13070, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1194 - mean_absolute_error: 0.2603 - mean_squared_error: 0.1194 - val_loss: 0.1307 - val_mean_absolute_error: 0.2722 - val_mean_squared_error: 0.1307\n",
            "Epoch 207/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.1213 - mean_absolute_error: 0.2632 - mean_squared_error: 0.1213\n",
            "Epoch 207: val_loss did not improve from 0.13070\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1212 - mean_absolute_error: 0.2630 - mean_squared_error: 0.1212 - val_loss: 0.1324 - val_mean_absolute_error: 0.2695 - val_mean_squared_error: 0.1324\n",
            "Epoch 208/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.1186 - mean_absolute_error: 0.2594 - mean_squared_error: 0.1186\n",
            "Epoch 208: val_loss did not improve from 0.13070\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1182 - mean_absolute_error: 0.2593 - mean_squared_error: 0.1182 - val_loss: 0.1374 - val_mean_absolute_error: 0.2771 - val_mean_squared_error: 0.1374\n",
            "Epoch 209/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.1170 - mean_absolute_error: 0.2589 - mean_squared_error: 0.1170\n",
            "Epoch 209: val_loss did not improve from 0.13070\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1177 - mean_absolute_error: 0.2595 - mean_squared_error: 0.1177 - val_loss: 0.1310 - val_mean_absolute_error: 0.2674 - val_mean_squared_error: 0.1310\n",
            "Epoch 210/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.1164 - mean_absolute_error: 0.2585 - mean_squared_error: 0.1164\n",
            "Epoch 210: val_loss improved from 0.13070 to 0.12886, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1158 - mean_absolute_error: 0.2579 - mean_squared_error: 0.1158 - val_loss: 0.1289 - val_mean_absolute_error: 0.2719 - val_mean_squared_error: 0.1289\n",
            "Epoch 211/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.1147 - mean_absolute_error: 0.2561 - mean_squared_error: 0.1147\n",
            "Epoch 211: val_loss improved from 0.12886 to 0.12881, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1146 - mean_absolute_error: 0.2562 - mean_squared_error: 0.1146 - val_loss: 0.1288 - val_mean_absolute_error: 0.2715 - val_mean_squared_error: 0.1288\n",
            "Epoch 212/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.1143 - mean_absolute_error: 0.2564 - mean_squared_error: 0.1143\n",
            "Epoch 212: val_loss did not improve from 0.12881\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1131 - mean_absolute_error: 0.2551 - mean_squared_error: 0.1131 - val_loss: 0.1295 - val_mean_absolute_error: 0.2680 - val_mean_squared_error: 0.1295\n",
            "Epoch 213/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 0.1132 - mean_absolute_error: 0.2547 - mean_squared_error: 0.1132\n",
            "Epoch 213: val_loss improved from 0.12881 to 0.12528, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1116 - mean_absolute_error: 0.2531 - mean_squared_error: 0.1116 - val_loss: 0.1253 - val_mean_absolute_error: 0.2646 - val_mean_squared_error: 0.1253\n",
            "Epoch 214/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.1125 - mean_absolute_error: 0.2550 - mean_squared_error: 0.1125\n",
            "Epoch 214: val_loss improved from 0.12528 to 0.12455, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1129 - mean_absolute_error: 0.2554 - mean_squared_error: 0.1129 - val_loss: 0.1245 - val_mean_absolute_error: 0.2635 - val_mean_squared_error: 0.1245\n",
            "Epoch 215/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.1101 - mean_absolute_error: 0.2525 - mean_squared_error: 0.1101\n",
            "Epoch 215: val_loss did not improve from 0.12455\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1101 - mean_absolute_error: 0.2525 - mean_squared_error: 0.1101 - val_loss: 0.1255 - val_mean_absolute_error: 0.2634 - val_mean_squared_error: 0.1255\n",
            "Epoch 216/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.1102 - mean_absolute_error: 0.2537 - mean_squared_error: 0.1102\n",
            "Epoch 216: val_loss improved from 0.12455 to 0.12133, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1101 - mean_absolute_error: 0.2537 - mean_squared_error: 0.1101 - val_loss: 0.1213 - val_mean_absolute_error: 0.2644 - val_mean_squared_error: 0.1213\n",
            "Epoch 217/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.1078 - mean_absolute_error: 0.2507 - mean_squared_error: 0.1078\n",
            "Epoch 217: val_loss did not improve from 0.12133\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1073 - mean_absolute_error: 0.2498 - mean_squared_error: 0.1073 - val_loss: 0.1231 - val_mean_absolute_error: 0.2661 - val_mean_squared_error: 0.1231\n",
            "Epoch 218/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 0.1078 - mean_absolute_error: 0.2507 - mean_squared_error: 0.1078\n",
            "Epoch 218: val_loss improved from 0.12133 to 0.11670, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1070 - mean_absolute_error: 0.2496 - mean_squared_error: 0.1070 - val_loss: 0.1167 - val_mean_absolute_error: 0.2574 - val_mean_squared_error: 0.1167\n",
            "Epoch 219/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.1040 - mean_absolute_error: 0.2455 - mean_squared_error: 0.1040\n",
            "Epoch 219: val_loss did not improve from 0.11670\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1040 - mean_absolute_error: 0.2455 - mean_squared_error: 0.1040 - val_loss: 0.1169 - val_mean_absolute_error: 0.2620 - val_mean_squared_error: 0.1169\n",
            "Epoch 220/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.1059 - mean_absolute_error: 0.2495 - mean_squared_error: 0.1059\n",
            "Epoch 220: val_loss improved from 0.11670 to 0.11654, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1053 - mean_absolute_error: 0.2490 - mean_squared_error: 0.1053 - val_loss: 0.1165 - val_mean_absolute_error: 0.2574 - val_mean_squared_error: 0.1165\n",
            "Epoch 221/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.1047 - mean_absolute_error: 0.2483 - mean_squared_error: 0.1047\n",
            "Epoch 221: val_loss did not improve from 0.11654\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1041 - mean_absolute_error: 0.2476 - mean_squared_error: 0.1041 - val_loss: 0.1177 - val_mean_absolute_error: 0.2574 - val_mean_squared_error: 0.1177\n",
            "Epoch 222/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.1036 - mean_absolute_error: 0.2478 - mean_squared_error: 0.1036\n",
            "Epoch 222: val_loss improved from 0.11654 to 0.11654, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1028 - mean_absolute_error: 0.2469 - mean_squared_error: 0.1028 - val_loss: 0.1165 - val_mean_absolute_error: 0.2551 - val_mean_squared_error: 0.1165\n",
            "Epoch 223/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.1017 - mean_absolute_error: 0.2450 - mean_squared_error: 0.1017\n",
            "Epoch 223: val_loss did not improve from 0.11654\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1018 - mean_absolute_error: 0.2451 - mean_squared_error: 0.1018 - val_loss: 0.1174 - val_mean_absolute_error: 0.2628 - val_mean_squared_error: 0.1174\n",
            "Epoch 224/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.1039 - mean_absolute_error: 0.2484 - mean_squared_error: 0.1039\n",
            "Epoch 224: val_loss improved from 0.11654 to 0.11114, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1026 - mean_absolute_error: 0.2468 - mean_squared_error: 0.1026 - val_loss: 0.1111 - val_mean_absolute_error: 0.2509 - val_mean_squared_error: 0.1111\n",
            "Epoch 225/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.1002 - mean_absolute_error: 0.2426 - mean_squared_error: 0.1002\n",
            "Epoch 225: val_loss did not improve from 0.11114\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1001 - mean_absolute_error: 0.2424 - mean_squared_error: 0.1001 - val_loss: 0.1137 - val_mean_absolute_error: 0.2591 - val_mean_squared_error: 0.1137\n",
            "Epoch 226/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 0.1004 - mean_absolute_error: 0.2448 - mean_squared_error: 0.1004\n",
            "Epoch 226: val_loss did not improve from 0.11114\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1003 - mean_absolute_error: 0.2439 - mean_squared_error: 0.1003 - val_loss: 0.1153 - val_mean_absolute_error: 0.2573 - val_mean_squared_error: 0.1153\n",
            "Epoch 227/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.0986 - mean_absolute_error: 0.2428 - mean_squared_error: 0.0986\n",
            "Epoch 227: val_loss improved from 0.11114 to 0.10966, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0989 - mean_absolute_error: 0.2429 - mean_squared_error: 0.0989 - val_loss: 0.1097 - val_mean_absolute_error: 0.2542 - val_mean_squared_error: 0.1097\n",
            "Epoch 228/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.0981 - mean_absolute_error: 0.2415 - mean_squared_error: 0.0981\n",
            "Epoch 228: val_loss improved from 0.10966 to 0.10964, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0977 - mean_absolute_error: 0.2412 - mean_squared_error: 0.0977 - val_loss: 0.1096 - val_mean_absolute_error: 0.2495 - val_mean_squared_error: 0.1096\n",
            "Epoch 229/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.0945 - mean_absolute_error: 0.2375 - mean_squared_error: 0.0945\n",
            "Epoch 229: val_loss improved from 0.10964 to 0.10801, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0959 - mean_absolute_error: 0.2391 - mean_squared_error: 0.0959 - val_loss: 0.1080 - val_mean_absolute_error: 0.2527 - val_mean_squared_error: 0.1080\n",
            "Epoch 230/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0977 - mean_absolute_error: 0.2414 - mean_squared_error: 0.0977\n",
            "Epoch 230: val_loss did not improve from 0.10801\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0972 - mean_absolute_error: 0.2411 - mean_squared_error: 0.0972 - val_loss: 0.1121 - val_mean_absolute_error: 0.2624 - val_mean_squared_error: 0.1121\n",
            "Epoch 231/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0952 - mean_absolute_error: 0.2395 - mean_squared_error: 0.0952\n",
            "Epoch 231: val_loss improved from 0.10801 to 0.10489, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0952 - mean_absolute_error: 0.2393 - mean_squared_error: 0.0952 - val_loss: 0.1049 - val_mean_absolute_error: 0.2463 - val_mean_squared_error: 0.1049\n",
            "Epoch 232/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0934 - mean_absolute_error: 0.2365 - mean_squared_error: 0.0934\n",
            "Epoch 232: val_loss did not improve from 0.10489\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0933 - mean_absolute_error: 0.2358 - mean_squared_error: 0.0933 - val_loss: 0.1102 - val_mean_absolute_error: 0.2549 - val_mean_squared_error: 0.1102\n",
            "Epoch 233/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0949 - mean_absolute_error: 0.2368 - mean_squared_error: 0.0949\n",
            "Epoch 233: val_loss improved from 0.10489 to 0.10258, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0942 - mean_absolute_error: 0.2360 - mean_squared_error: 0.0942 - val_loss: 0.1026 - val_mean_absolute_error: 0.2492 - val_mean_squared_error: 0.1026\n",
            "Epoch 234/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 0.0919 - mean_absolute_error: 0.2342 - mean_squared_error: 0.0919\n",
            "Epoch 234: val_loss did not improve from 0.10258\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0917 - mean_absolute_error: 0.2342 - mean_squared_error: 0.0917 - val_loss: 0.1075 - val_mean_absolute_error: 0.2514 - val_mean_squared_error: 0.1075\n",
            "Epoch 235/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0904 - mean_absolute_error: 0.2324 - mean_squared_error: 0.0904\n",
            "Epoch 235: val_loss did not improve from 0.10258\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0904 - mean_absolute_error: 0.2326 - mean_squared_error: 0.0904 - val_loss: 0.1027 - val_mean_absolute_error: 0.2469 - val_mean_squared_error: 0.1027\n",
            "Epoch 236/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0901 - mean_absolute_error: 0.2318 - mean_squared_error: 0.0901\n",
            "Epoch 236: val_loss improved from 0.10258 to 0.09949, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0904 - mean_absolute_error: 0.2323 - mean_squared_error: 0.0904 - val_loss: 0.0995 - val_mean_absolute_error: 0.2469 - val_mean_squared_error: 0.0995\n",
            "Epoch 237/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0921 - mean_absolute_error: 0.2368 - mean_squared_error: 0.0921\n",
            "Epoch 237: val_loss did not improve from 0.09949\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0921 - mean_absolute_error: 0.2368 - mean_squared_error: 0.0921 - val_loss: 0.1034 - val_mean_absolute_error: 0.2452 - val_mean_squared_error: 0.1034\n",
            "Epoch 238/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 0.0891 - mean_absolute_error: 0.2320 - mean_squared_error: 0.0891\n",
            "Epoch 238: val_loss did not improve from 0.09949\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0888 - mean_absolute_error: 0.2316 - mean_squared_error: 0.0888 - val_loss: 0.1041 - val_mean_absolute_error: 0.2421 - val_mean_squared_error: 0.1041\n",
            "Epoch 239/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0896 - mean_absolute_error: 0.2332 - mean_squared_error: 0.0896\n",
            "Epoch 239: val_loss did not improve from 0.09949\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0894 - mean_absolute_error: 0.2330 - mean_squared_error: 0.0894 - val_loss: 0.1030 - val_mean_absolute_error: 0.2447 - val_mean_squared_error: 0.1030\n",
            "Epoch 240/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0875 - mean_absolute_error: 0.2300 - mean_squared_error: 0.0875\n",
            "Epoch 240: val_loss did not improve from 0.09949\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0879 - mean_absolute_error: 0.2307 - mean_squared_error: 0.0879 - val_loss: 0.1055 - val_mean_absolute_error: 0.2554 - val_mean_squared_error: 0.1055\n",
            "Epoch 241/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0871 - mean_absolute_error: 0.2289 - mean_squared_error: 0.0871\n",
            "Epoch 241: val_loss did not improve from 0.09949\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0871 - mean_absolute_error: 0.2294 - mean_squared_error: 0.0871 - val_loss: 0.1024 - val_mean_absolute_error: 0.2487 - val_mean_squared_error: 0.1024\n",
            "Epoch 242/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0871 - mean_absolute_error: 0.2300 - mean_squared_error: 0.0871\n",
            "Epoch 242: val_loss improved from 0.09949 to 0.09641, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0870 - mean_absolute_error: 0.2300 - mean_squared_error: 0.0870 - val_loss: 0.0964 - val_mean_absolute_error: 0.2386 - val_mean_squared_error: 0.0964\n",
            "Epoch 243/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0858 - mean_absolute_error: 0.2280 - mean_squared_error: 0.0858\n",
            "Epoch 243: val_loss improved from 0.09641 to 0.09217, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0857 - mean_absolute_error: 0.2275 - mean_squared_error: 0.0857 - val_loss: 0.0922 - val_mean_absolute_error: 0.2310 - val_mean_squared_error: 0.0922\n",
            "Epoch 244/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0858 - mean_absolute_error: 0.2280 - mean_squared_error: 0.0858\n",
            "Epoch 244: val_loss did not improve from 0.09217\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0858 - mean_absolute_error: 0.2280 - mean_squared_error: 0.0858 - val_loss: 0.0927 - val_mean_absolute_error: 0.2341 - val_mean_squared_error: 0.0927\n",
            "Epoch 245/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0879 - mean_absolute_error: 0.2306 - mean_squared_error: 0.0879\n",
            "Epoch 245: val_loss did not improve from 0.09217\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0877 - mean_absolute_error: 0.2304 - mean_squared_error: 0.0877 - val_loss: 0.0978 - val_mean_absolute_error: 0.2426 - val_mean_squared_error: 0.0978\n",
            "Epoch 246/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0860 - mean_absolute_error: 0.2292 - mean_squared_error: 0.0860\n",
            "Epoch 246: val_loss did not improve from 0.09217\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0859 - mean_absolute_error: 0.2292 - mean_squared_error: 0.0859 - val_loss: 0.0923 - val_mean_absolute_error: 0.2317 - val_mean_squared_error: 0.0923\n",
            "Epoch 247/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.0827 - mean_absolute_error: 0.2237 - mean_squared_error: 0.0827\n",
            "Epoch 247: val_loss improved from 0.09217 to 0.09050, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0824 - mean_absolute_error: 0.2236 - mean_squared_error: 0.0824 - val_loss: 0.0905 - val_mean_absolute_error: 0.2345 - val_mean_squared_error: 0.0905\n",
            "Epoch 248/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.0833 - mean_absolute_error: 0.2256 - mean_squared_error: 0.0833\n",
            "Epoch 248: val_loss did not improve from 0.09050\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0830 - mean_absolute_error: 0.2252 - mean_squared_error: 0.0830 - val_loss: 0.0909 - val_mean_absolute_error: 0.2319 - val_mean_squared_error: 0.0909\n",
            "Epoch 249/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0827 - mean_absolute_error: 0.2246 - mean_squared_error: 0.0827\n",
            "Epoch 249: val_loss did not improve from 0.09050\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0827 - mean_absolute_error: 0.2246 - mean_squared_error: 0.0827 - val_loss: 0.0929 - val_mean_absolute_error: 0.2373 - val_mean_squared_error: 0.0929\n",
            "Epoch 250/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0813 - mean_absolute_error: 0.2235 - mean_squared_error: 0.0813\n",
            "Epoch 250: val_loss did not improve from 0.09050\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0811 - mean_absolute_error: 0.2231 - mean_squared_error: 0.0811 - val_loss: 0.0919 - val_mean_absolute_error: 0.2365 - val_mean_squared_error: 0.0919\n",
            "Epoch 251/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0810 - mean_absolute_error: 0.2219 - mean_squared_error: 0.0810\n",
            "Epoch 251: val_loss improved from 0.09050 to 0.08798, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0814 - mean_absolute_error: 0.2223 - mean_squared_error: 0.0814 - val_loss: 0.0880 - val_mean_absolute_error: 0.2319 - val_mean_squared_error: 0.0880\n",
            "Epoch 252/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.0808 - mean_absolute_error: 0.2224 - mean_squared_error: 0.0808\n",
            "Epoch 252: val_loss did not improve from 0.08798\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0803 - mean_absolute_error: 0.2215 - mean_squared_error: 0.0803 - val_loss: 0.0887 - val_mean_absolute_error: 0.2323 - val_mean_squared_error: 0.0887\n",
            "Epoch 253/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0799 - mean_absolute_error: 0.2213 - mean_squared_error: 0.0799\n",
            "Epoch 253: val_loss improved from 0.08798 to 0.08533, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0798 - mean_absolute_error: 0.2211 - mean_squared_error: 0.0798 - val_loss: 0.0853 - val_mean_absolute_error: 0.2254 - val_mean_squared_error: 0.0853\n",
            "Epoch 254/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.0798 - mean_absolute_error: 0.2211 - mean_squared_error: 0.0798\n",
            "Epoch 254: val_loss did not improve from 0.08533\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0802 - mean_absolute_error: 0.2212 - mean_squared_error: 0.0802 - val_loss: 0.0873 - val_mean_absolute_error: 0.2309 - val_mean_squared_error: 0.0873\n",
            "Epoch 255/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0788 - mean_absolute_error: 0.2200 - mean_squared_error: 0.0788\n",
            "Epoch 255: val_loss did not improve from 0.08533\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0789 - mean_absolute_error: 0.2203 - mean_squared_error: 0.0789 - val_loss: 0.0883 - val_mean_absolute_error: 0.2272 - val_mean_squared_error: 0.0883\n",
            "Epoch 256/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0796 - mean_absolute_error: 0.2211 - mean_squared_error: 0.0796\n",
            "Epoch 256: val_loss did not improve from 0.08533\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0796 - mean_absolute_error: 0.2211 - mean_squared_error: 0.0796 - val_loss: 0.0885 - val_mean_absolute_error: 0.2287 - val_mean_squared_error: 0.0885\n",
            "Epoch 257/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0775 - mean_absolute_error: 0.2181 - mean_squared_error: 0.0775\n",
            "Epoch 257: val_loss improved from 0.08533 to 0.08356, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0772 - mean_absolute_error: 0.2178 - mean_squared_error: 0.0772 - val_loss: 0.0836 - val_mean_absolute_error: 0.2287 - val_mean_squared_error: 0.0836\n",
            "Epoch 258/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0772 - mean_absolute_error: 0.2178 - mean_squared_error: 0.0772\n",
            "Epoch 258: val_loss did not improve from 0.08356\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0771 - mean_absolute_error: 0.2180 - mean_squared_error: 0.0771 - val_loss: 0.0844 - val_mean_absolute_error: 0.2277 - val_mean_squared_error: 0.0844\n",
            "Epoch 259/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.0779 - mean_absolute_error: 0.2191 - mean_squared_error: 0.0779\n",
            "Epoch 259: val_loss did not improve from 0.08356\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0780 - mean_absolute_error: 0.2196 - mean_squared_error: 0.0780 - val_loss: 0.0858 - val_mean_absolute_error: 0.2327 - val_mean_squared_error: 0.0858\n",
            "Epoch 260/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.0760 - mean_absolute_error: 0.2178 - mean_squared_error: 0.0760\n",
            "Epoch 260: val_loss improved from 0.08356 to 0.08070, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0762 - mean_absolute_error: 0.2173 - mean_squared_error: 0.0762 - val_loss: 0.0807 - val_mean_absolute_error: 0.2219 - val_mean_squared_error: 0.0807\n",
            "Epoch 261/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 0.0760 - mean_absolute_error: 0.2164 - mean_squared_error: 0.0760\n",
            "Epoch 261: val_loss did not improve from 0.08070\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0755 - mean_absolute_error: 0.2157 - mean_squared_error: 0.0755 - val_loss: 0.0812 - val_mean_absolute_error: 0.2241 - val_mean_squared_error: 0.0812\n",
            "Epoch 262/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0769 - mean_absolute_error: 0.2173 - mean_squared_error: 0.0769\n",
            "Epoch 262: val_loss did not improve from 0.08070\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0769 - mean_absolute_error: 0.2174 - mean_squared_error: 0.0769 - val_loss: 0.0835 - val_mean_absolute_error: 0.2250 - val_mean_squared_error: 0.0835\n",
            "Epoch 263/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0738 - mean_absolute_error: 0.2124 - mean_squared_error: 0.0738\n",
            "Epoch 263: val_loss did not improve from 0.08070\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0735 - mean_absolute_error: 0.2120 - mean_squared_error: 0.0735 - val_loss: 0.0834 - val_mean_absolute_error: 0.2248 - val_mean_squared_error: 0.0834\n",
            "Epoch 264/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0736 - mean_absolute_error: 0.2132 - mean_squared_error: 0.0736\n",
            "Epoch 264: val_loss improved from 0.08070 to 0.07828, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0736 - mean_absolute_error: 0.2132 - mean_squared_error: 0.0736 - val_loss: 0.0783 - val_mean_absolute_error: 0.2180 - val_mean_squared_error: 0.0783\n",
            "Epoch 265/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0727 - mean_absolute_error: 0.2110 - mean_squared_error: 0.0727\n",
            "Epoch 265: val_loss did not improve from 0.07828\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0726 - mean_absolute_error: 0.2111 - mean_squared_error: 0.0726 - val_loss: 0.0798 - val_mean_absolute_error: 0.2240 - val_mean_squared_error: 0.0798\n",
            "Epoch 266/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0745 - mean_absolute_error: 0.2144 - mean_squared_error: 0.0745\n",
            "Epoch 266: val_loss did not improve from 0.07828\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0742 - mean_absolute_error: 0.2141 - mean_squared_error: 0.0742 - val_loss: 0.0783 - val_mean_absolute_error: 0.2225 - val_mean_squared_error: 0.0783\n",
            "Epoch 267/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0717 - mean_absolute_error: 0.2101 - mean_squared_error: 0.0717\n",
            "Epoch 267: val_loss did not improve from 0.07828\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0716 - mean_absolute_error: 0.2100 - mean_squared_error: 0.0716 - val_loss: 0.0810 - val_mean_absolute_error: 0.2244 - val_mean_squared_error: 0.0810\n",
            "Epoch 268/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.0726 - mean_absolute_error: 0.2116 - mean_squared_error: 0.0726\n",
            "Epoch 268: val_loss did not improve from 0.07828\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0727 - mean_absolute_error: 0.2117 - mean_squared_error: 0.0727 - val_loss: 0.0816 - val_mean_absolute_error: 0.2264 - val_mean_squared_error: 0.0816\n",
            "Epoch 269/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0737 - mean_absolute_error: 0.2137 - mean_squared_error: 0.0737\n",
            "Epoch 269: val_loss did not improve from 0.07828\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0726 - mean_absolute_error: 0.2118 - mean_squared_error: 0.0726 - val_loss: 0.0825 - val_mean_absolute_error: 0.2190 - val_mean_squared_error: 0.0825\n",
            "Epoch 270/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.0709 - mean_absolute_error: 0.2093 - mean_squared_error: 0.0709\n",
            "Epoch 270: val_loss improved from 0.07828 to 0.07601, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0712 - mean_absolute_error: 0.2097 - mean_squared_error: 0.0712 - val_loss: 0.0760 - val_mean_absolute_error: 0.2192 - val_mean_squared_error: 0.0760\n",
            "Epoch 271/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0709 - mean_absolute_error: 0.2087 - mean_squared_error: 0.0709\n",
            "Epoch 271: val_loss did not improve from 0.07601\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0713 - mean_absolute_error: 0.2095 - mean_squared_error: 0.0713 - val_loss: 0.0862 - val_mean_absolute_error: 0.2243 - val_mean_squared_error: 0.0862\n",
            "Epoch 272/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0700 - mean_absolute_error: 0.2078 - mean_squared_error: 0.0700\n",
            "Epoch 272: val_loss did not improve from 0.07601\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0699 - mean_absolute_error: 0.2077 - mean_squared_error: 0.0699 - val_loss: 0.0806 - val_mean_absolute_error: 0.2221 - val_mean_squared_error: 0.0806\n",
            "Epoch 273/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0688 - mean_absolute_error: 0.2061 - mean_squared_error: 0.0688\n",
            "Epoch 273: val_loss did not improve from 0.07601\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0689 - mean_absolute_error: 0.2061 - mean_squared_error: 0.0689 - val_loss: 0.0763 - val_mean_absolute_error: 0.2186 - val_mean_squared_error: 0.0763\n",
            "Epoch 274/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0690 - mean_absolute_error: 0.2062 - mean_squared_error: 0.0690\n",
            "Epoch 274: val_loss did not improve from 0.07601\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0695 - mean_absolute_error: 0.2070 - mean_squared_error: 0.0695 - val_loss: 0.0771 - val_mean_absolute_error: 0.2193 - val_mean_squared_error: 0.0771\n",
            "Epoch 275/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0693 - mean_absolute_error: 0.2070 - mean_squared_error: 0.0693\n",
            "Epoch 275: val_loss improved from 0.07601 to 0.07462, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0688 - mean_absolute_error: 0.2063 - mean_squared_error: 0.0688 - val_loss: 0.0746 - val_mean_absolute_error: 0.2142 - val_mean_squared_error: 0.0746\n",
            "Epoch 276/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0695 - mean_absolute_error: 0.2083 - mean_squared_error: 0.0695\n",
            "Epoch 276: val_loss improved from 0.07462 to 0.07194, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0696 - mean_absolute_error: 0.2086 - mean_squared_error: 0.0696 - val_loss: 0.0719 - val_mean_absolute_error: 0.2131 - val_mean_squared_error: 0.0719\n",
            "Epoch 277/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0677 - mean_absolute_error: 0.2042 - mean_squared_error: 0.0677\n",
            "Epoch 277: val_loss did not improve from 0.07194\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0678 - mean_absolute_error: 0.2045 - mean_squared_error: 0.0678 - val_loss: 0.0793 - val_mean_absolute_error: 0.2248 - val_mean_squared_error: 0.0793\n",
            "Epoch 278/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0682 - mean_absolute_error: 0.2064 - mean_squared_error: 0.0682\n",
            "Epoch 278: val_loss did not improve from 0.07194\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0685 - mean_absolute_error: 0.2067 - mean_squared_error: 0.0685 - val_loss: 0.0726 - val_mean_absolute_error: 0.2136 - val_mean_squared_error: 0.0726\n",
            "Epoch 279/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.2043 - mean_squared_error: 0.0674\n",
            "Epoch 279: val_loss improved from 0.07194 to 0.06993, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0673 - mean_absolute_error: 0.2041 - mean_squared_error: 0.0673 - val_loss: 0.0699 - val_mean_absolute_error: 0.2086 - val_mean_squared_error: 0.0699\n",
            "Epoch 280/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.2042 - mean_squared_error: 0.0669\n",
            "Epoch 280: val_loss did not improve from 0.06993\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0672 - mean_absolute_error: 0.2043 - mean_squared_error: 0.0672 - val_loss: 0.0737 - val_mean_absolute_error: 0.2152 - val_mean_squared_error: 0.0737\n",
            "Epoch 281/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0668 - mean_absolute_error: 0.2044 - mean_squared_error: 0.0668\n",
            "Epoch 281: val_loss did not improve from 0.06993\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0667 - mean_absolute_error: 0.2042 - mean_squared_error: 0.0667 - val_loss: 0.0703 - val_mean_absolute_error: 0.2091 - val_mean_squared_error: 0.0703\n",
            "Epoch 282/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.2046 - mean_squared_error: 0.0670\n",
            "Epoch 282: val_loss did not improve from 0.06993\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0669 - mean_absolute_error: 0.2048 - mean_squared_error: 0.0669 - val_loss: 0.0747 - val_mean_absolute_error: 0.2176 - val_mean_squared_error: 0.0747\n",
            "Epoch 283/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 0.0667 - mean_absolute_error: 0.2036 - mean_squared_error: 0.0667\n",
            "Epoch 283: val_loss did not improve from 0.06993\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0663 - mean_absolute_error: 0.2036 - mean_squared_error: 0.0663 - val_loss: 0.0716 - val_mean_absolute_error: 0.2074 - val_mean_squared_error: 0.0716\n",
            "Epoch 284/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.0663 - mean_absolute_error: 0.2028 - mean_squared_error: 0.0663\n",
            "Epoch 284: val_loss did not improve from 0.06993\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0660 - mean_absolute_error: 0.2025 - mean_squared_error: 0.0660 - val_loss: 0.0700 - val_mean_absolute_error: 0.2084 - val_mean_squared_error: 0.0700\n",
            "Epoch 285/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0656 - mean_absolute_error: 0.2026 - mean_squared_error: 0.0656\n",
            "Epoch 285: val_loss did not improve from 0.06993\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0656 - mean_absolute_error: 0.2024 - mean_squared_error: 0.0656 - val_loss: 0.0702 - val_mean_absolute_error: 0.2078 - val_mean_squared_error: 0.0702\n",
            "Epoch 286/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0657 - mean_absolute_error: 0.2017 - mean_squared_error: 0.0657\n",
            "Epoch 286: val_loss improved from 0.06993 to 0.06729, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0657 - mean_absolute_error: 0.2017 - mean_squared_error: 0.0657 - val_loss: 0.0673 - val_mean_absolute_error: 0.2043 - val_mean_squared_error: 0.0673\n",
            "Epoch 287/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0633 - mean_absolute_error: 0.1988 - mean_squared_error: 0.0633\n",
            "Epoch 287: val_loss did not improve from 0.06729\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0632 - mean_absolute_error: 0.1986 - mean_squared_error: 0.0632 - val_loss: 0.0722 - val_mean_absolute_error: 0.2094 - val_mean_squared_error: 0.0722\n",
            "Epoch 288/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.0632 - mean_absolute_error: 0.1977 - mean_squared_error: 0.0632\n",
            "Epoch 288: val_loss did not improve from 0.06729\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0638 - mean_absolute_error: 0.1985 - mean_squared_error: 0.0638 - val_loss: 0.0697 - val_mean_absolute_error: 0.2099 - val_mean_squared_error: 0.0697\n",
            "Epoch 289/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0644 - mean_absolute_error: 0.1993 - mean_squared_error: 0.0644\n",
            "Epoch 289: val_loss did not improve from 0.06729\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0644 - mean_absolute_error: 0.1992 - mean_squared_error: 0.0644 - val_loss: 0.0716 - val_mean_absolute_error: 0.2123 - val_mean_squared_error: 0.0716\n",
            "Epoch 290/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0628 - mean_absolute_error: 0.1984 - mean_squared_error: 0.0628\n",
            "Epoch 290: val_loss did not improve from 0.06729\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0628 - mean_absolute_error: 0.1981 - mean_squared_error: 0.0628 - val_loss: 0.0741 - val_mean_absolute_error: 0.2093 - val_mean_squared_error: 0.0741\n",
            "Epoch 291/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0621 - mean_absolute_error: 0.1963 - mean_squared_error: 0.0621\n",
            "Epoch 291: val_loss did not improve from 0.06729\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0620 - mean_absolute_error: 0.1960 - mean_squared_error: 0.0620 - val_loss: 0.0705 - val_mean_absolute_error: 0.2107 - val_mean_squared_error: 0.0705\n",
            "Epoch 292/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0636 - mean_absolute_error: 0.1987 - mean_squared_error: 0.0636\n",
            "Epoch 292: val_loss improved from 0.06729 to 0.06552, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0636 - mean_absolute_error: 0.1987 - mean_squared_error: 0.0636 - val_loss: 0.0655 - val_mean_absolute_error: 0.2016 - val_mean_squared_error: 0.0655\n",
            "Epoch 293/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0624 - mean_absolute_error: 0.1966 - mean_squared_error: 0.0624\n",
            "Epoch 293: val_loss did not improve from 0.06552\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0631 - mean_absolute_error: 0.1977 - mean_squared_error: 0.0631 - val_loss: 0.0690 - val_mean_absolute_error: 0.2041 - val_mean_squared_error: 0.0690\n",
            "Epoch 294/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0621 - mean_absolute_error: 0.1960 - mean_squared_error: 0.0621\n",
            "Epoch 294: val_loss improved from 0.06552 to 0.06523, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0621 - mean_absolute_error: 0.1961 - mean_squared_error: 0.0621 - val_loss: 0.0652 - val_mean_absolute_error: 0.2008 - val_mean_squared_error: 0.0652\n",
            "Epoch 295/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0616 - mean_absolute_error: 0.1962 - mean_squared_error: 0.0616\n",
            "Epoch 295: val_loss did not improve from 0.06523\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0616 - mean_absolute_error: 0.1962 - mean_squared_error: 0.0616 - val_loss: 0.0669 - val_mean_absolute_error: 0.2040 - val_mean_squared_error: 0.0669\n",
            "Epoch 296/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0622 - mean_absolute_error: 0.1972 - mean_squared_error: 0.0622\n",
            "Epoch 296: val_loss improved from 0.06523 to 0.06367, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0622 - mean_absolute_error: 0.1972 - mean_squared_error: 0.0622 - val_loss: 0.0637 - val_mean_absolute_error: 0.1996 - val_mean_squared_error: 0.0637\n",
            "Epoch 297/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0621 - mean_absolute_error: 0.1970 - mean_squared_error: 0.0621\n",
            "Epoch 297: val_loss did not improve from 0.06367\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0615 - mean_absolute_error: 0.1962 - mean_squared_error: 0.0615 - val_loss: 0.0640 - val_mean_absolute_error: 0.1983 - val_mean_squared_error: 0.0640\n",
            "Epoch 298/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0613 - mean_absolute_error: 0.1956 - mean_squared_error: 0.0613\n",
            "Epoch 298: val_loss did not improve from 0.06367\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0611 - mean_absolute_error: 0.1955 - mean_squared_error: 0.0611 - val_loss: 0.0644 - val_mean_absolute_error: 0.1949 - val_mean_squared_error: 0.0644\n",
            "Epoch 299/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0608 - mean_absolute_error: 0.1951 - mean_squared_error: 0.0608\n",
            "Epoch 299: val_loss improved from 0.06367 to 0.06232, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0611 - mean_absolute_error: 0.1956 - mean_squared_error: 0.0611 - val_loss: 0.0623 - val_mean_absolute_error: 0.1921 - val_mean_squared_error: 0.0623\n",
            "Epoch 300/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.0596 - mean_absolute_error: 0.1925 - mean_squared_error: 0.0596\n",
            "Epoch 300: val_loss did not improve from 0.06232\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0597 - mean_absolute_error: 0.1925 - mean_squared_error: 0.0597 - val_loss: 0.0627 - val_mean_absolute_error: 0.1935 - val_mean_squared_error: 0.0627\n",
            "Epoch 301/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0609 - mean_absolute_error: 0.1950 - mean_squared_error: 0.0609\n",
            "Epoch 301: val_loss improved from 0.06232 to 0.06198, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0609 - mean_absolute_error: 0.1950 - mean_squared_error: 0.0609 - val_loss: 0.0620 - val_mean_absolute_error: 0.1960 - val_mean_squared_error: 0.0620\n",
            "Epoch 302/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0595 - mean_absolute_error: 0.1922 - mean_squared_error: 0.0595\n",
            "Epoch 302: val_loss did not improve from 0.06198\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0594 - mean_absolute_error: 0.1920 - mean_squared_error: 0.0594 - val_loss: 0.0631 - val_mean_absolute_error: 0.1942 - val_mean_squared_error: 0.0631\n",
            "Epoch 303/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0592 - mean_absolute_error: 0.1916 - mean_squared_error: 0.0592\n",
            "Epoch 303: val_loss did not improve from 0.06198\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0592 - mean_absolute_error: 0.1917 - mean_squared_error: 0.0592 - val_loss: 0.0623 - val_mean_absolute_error: 0.1946 - val_mean_squared_error: 0.0623\n",
            "Epoch 304/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.0593 - mean_absolute_error: 0.1920 - mean_squared_error: 0.0593\n",
            "Epoch 304: val_loss did not improve from 0.06198\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0596 - mean_absolute_error: 0.1922 - mean_squared_error: 0.0596 - val_loss: 0.0625 - val_mean_absolute_error: 0.1957 - val_mean_squared_error: 0.0625\n",
            "Epoch 305/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0584 - mean_absolute_error: 0.1912 - mean_squared_error: 0.0584\n",
            "Epoch 305: val_loss did not improve from 0.06198\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0584 - mean_absolute_error: 0.1914 - mean_squared_error: 0.0584 - val_loss: 0.0625 - val_mean_absolute_error: 0.1965 - val_mean_squared_error: 0.0625\n",
            "Epoch 306/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.0591 - mean_absolute_error: 0.1909 - mean_squared_error: 0.0591\n",
            "Epoch 306: val_loss did not improve from 0.06198\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0588 - mean_absolute_error: 0.1908 - mean_squared_error: 0.0588 - val_loss: 0.0622 - val_mean_absolute_error: 0.1940 - val_mean_squared_error: 0.0622\n",
            "Epoch 307/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0570 - mean_absolute_error: 0.1880 - mean_squared_error: 0.0570\n",
            "Epoch 307: val_loss improved from 0.06198 to 0.05970, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0572 - mean_absolute_error: 0.1884 - mean_squared_error: 0.0572 - val_loss: 0.0597 - val_mean_absolute_error: 0.1938 - val_mean_squared_error: 0.0597\n",
            "Epoch 308/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0577 - mean_absolute_error: 0.1898 - mean_squared_error: 0.0577\n",
            "Epoch 308: val_loss did not improve from 0.05970\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0577 - mean_absolute_error: 0.1897 - mean_squared_error: 0.0577 - val_loss: 0.0623 - val_mean_absolute_error: 0.1955 - val_mean_squared_error: 0.0623\n",
            "Epoch 309/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0578 - mean_absolute_error: 0.1899 - mean_squared_error: 0.0578\n",
            "Epoch 309: val_loss did not improve from 0.05970\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0578 - mean_absolute_error: 0.1898 - mean_squared_error: 0.0578 - val_loss: 0.0609 - val_mean_absolute_error: 0.1929 - val_mean_squared_error: 0.0609\n",
            "Epoch 310/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0572 - mean_absolute_error: 0.1879 - mean_squared_error: 0.0572\n",
            "Epoch 310: val_loss did not improve from 0.05970\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0568 - mean_absolute_error: 0.1875 - mean_squared_error: 0.0568 - val_loss: 0.0622 - val_mean_absolute_error: 0.1908 - val_mean_squared_error: 0.0622\n",
            "Epoch 311/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0566 - mean_absolute_error: 0.1871 - mean_squared_error: 0.0566\n",
            "Epoch 311: val_loss improved from 0.05970 to 0.05909, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0566 - mean_absolute_error: 0.1871 - mean_squared_error: 0.0566 - val_loss: 0.0591 - val_mean_absolute_error: 0.1929 - val_mean_squared_error: 0.0591\n",
            "Epoch 312/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0558 - mean_absolute_error: 0.1861 - mean_squared_error: 0.0558\n",
            "Epoch 312: val_loss did not improve from 0.05909\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0560 - mean_absolute_error: 0.1863 - mean_squared_error: 0.0560 - val_loss: 0.0658 - val_mean_absolute_error: 0.2017 - val_mean_squared_error: 0.0658\n",
            "Epoch 313/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0565 - mean_absolute_error: 0.1867 - mean_squared_error: 0.0565\n",
            "Epoch 313: val_loss did not improve from 0.05909\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0568 - mean_absolute_error: 0.1874 - mean_squared_error: 0.0568 - val_loss: 0.0607 - val_mean_absolute_error: 0.1937 - val_mean_squared_error: 0.0607\n",
            "Epoch 314/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0564 - mean_absolute_error: 0.1870 - mean_squared_error: 0.0564\n",
            "Epoch 314: val_loss did not improve from 0.05909\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0563 - mean_absolute_error: 0.1870 - mean_squared_error: 0.0563 - val_loss: 0.0620 - val_mean_absolute_error: 0.1975 - val_mean_squared_error: 0.0620\n",
            "Epoch 315/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0562 - mean_absolute_error: 0.1863 - mean_squared_error: 0.0562\n",
            "Epoch 315: val_loss did not improve from 0.05909\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0562 - mean_absolute_error: 0.1864 - mean_squared_error: 0.0562 - val_loss: 0.0602 - val_mean_absolute_error: 0.1930 - val_mean_squared_error: 0.0602\n",
            "Epoch 316/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.0568 - mean_absolute_error: 0.1878 - mean_squared_error: 0.0568\n",
            "Epoch 316: val_loss improved from 0.05909 to 0.05699, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0565 - mean_absolute_error: 0.1874 - mean_squared_error: 0.0565 - val_loss: 0.0570 - val_mean_absolute_error: 0.1886 - val_mean_squared_error: 0.0570\n",
            "Epoch 317/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.0550 - mean_absolute_error: 0.1854 - mean_squared_error: 0.0550\n",
            "Epoch 317: val_loss did not improve from 0.05699\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0551 - mean_absolute_error: 0.1853 - mean_squared_error: 0.0551 - val_loss: 0.0625 - val_mean_absolute_error: 0.1960 - val_mean_squared_error: 0.0625\n",
            "Epoch 318/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.0550 - mean_absolute_error: 0.1842 - mean_squared_error: 0.0550\n",
            "Epoch 318: val_loss improved from 0.05699 to 0.05615, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0550 - mean_absolute_error: 0.1838 - mean_squared_error: 0.0550 - val_loss: 0.0562 - val_mean_absolute_error: 0.1873 - val_mean_squared_error: 0.0562\n",
            "Epoch 319/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0552 - mean_absolute_error: 0.1847 - mean_squared_error: 0.0552\n",
            "Epoch 319: val_loss did not improve from 0.05615\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0554 - mean_absolute_error: 0.1848 - mean_squared_error: 0.0554 - val_loss: 0.0599 - val_mean_absolute_error: 0.1888 - val_mean_squared_error: 0.0599\n",
            "Epoch 320/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0544 - mean_absolute_error: 0.1841 - mean_squared_error: 0.0544\n",
            "Epoch 320: val_loss did not improve from 0.05615\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0544 - mean_absolute_error: 0.1842 - mean_squared_error: 0.0544 - val_loss: 0.0582 - val_mean_absolute_error: 0.1848 - val_mean_squared_error: 0.0582\n",
            "Epoch 321/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0545 - mean_absolute_error: 0.1832 - mean_squared_error: 0.0545\n",
            "Epoch 321: val_loss did not improve from 0.05615\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0547 - mean_absolute_error: 0.1838 - mean_squared_error: 0.0547 - val_loss: 0.0598 - val_mean_absolute_error: 0.1937 - val_mean_squared_error: 0.0598\n",
            "Epoch 322/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0546 - mean_absolute_error: 0.1843 - mean_squared_error: 0.0546\n",
            "Epoch 322: val_loss did not improve from 0.05615\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0546 - mean_absolute_error: 0.1844 - mean_squared_error: 0.0546 - val_loss: 0.0596 - val_mean_absolute_error: 0.1914 - val_mean_squared_error: 0.0596\n",
            "Epoch 323/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.0541 - mean_absolute_error: 0.1833 - mean_squared_error: 0.0541\n",
            "Epoch 323: val_loss did not improve from 0.05615\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0540 - mean_absolute_error: 0.1833 - mean_squared_error: 0.0540 - val_loss: 0.0669 - val_mean_absolute_error: 0.2013 - val_mean_squared_error: 0.0669\n",
            "Epoch 324/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0525 - mean_absolute_error: 0.1807 - mean_squared_error: 0.0525\n",
            "Epoch 324: val_loss did not improve from 0.05615\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0523 - mean_absolute_error: 0.1803 - mean_squared_error: 0.0523 - val_loss: 0.0632 - val_mean_absolute_error: 0.1909 - val_mean_squared_error: 0.0632\n",
            "Epoch 325/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0545 - mean_absolute_error: 0.1833 - mean_squared_error: 0.0545\n",
            "Epoch 325: val_loss improved from 0.05615 to 0.05595, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0546 - mean_absolute_error: 0.1829 - mean_squared_error: 0.0546 - val_loss: 0.0560 - val_mean_absolute_error: 0.1861 - val_mean_squared_error: 0.0560\n",
            "Epoch 326/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0538 - mean_absolute_error: 0.1821 - mean_squared_error: 0.0538\n",
            "Epoch 326: val_loss improved from 0.05595 to 0.05534, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0538 - mean_absolute_error: 0.1820 - mean_squared_error: 0.0538 - val_loss: 0.0553 - val_mean_absolute_error: 0.1829 - val_mean_squared_error: 0.0553\n",
            "Epoch 327/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0523 - mean_absolute_error: 0.1795 - mean_squared_error: 0.0523\n",
            "Epoch 327: val_loss improved from 0.05534 to 0.05518, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0522 - mean_absolute_error: 0.1792 - mean_squared_error: 0.0522 - val_loss: 0.0552 - val_mean_absolute_error: 0.1838 - val_mean_squared_error: 0.0552\n",
            "Epoch 328/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0518 - mean_absolute_error: 0.1783 - mean_squared_error: 0.0518\n",
            "Epoch 328: val_loss did not improve from 0.05518\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0519 - mean_absolute_error: 0.1783 - mean_squared_error: 0.0519 - val_loss: 0.0559 - val_mean_absolute_error: 0.1824 - val_mean_squared_error: 0.0559\n",
            "Epoch 329/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0525 - mean_absolute_error: 0.1801 - mean_squared_error: 0.0525\n",
            "Epoch 329: val_loss did not improve from 0.05518\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0528 - mean_absolute_error: 0.1802 - mean_squared_error: 0.0528 - val_loss: 0.0556 - val_mean_absolute_error: 0.1820 - val_mean_squared_error: 0.0556\n",
            "Epoch 330/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0520 - mean_absolute_error: 0.1797 - mean_squared_error: 0.0520\n",
            "Epoch 330: val_loss did not improve from 0.05518\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0523 - mean_absolute_error: 0.1800 - mean_squared_error: 0.0523 - val_loss: 0.0592 - val_mean_absolute_error: 0.1918 - val_mean_squared_error: 0.0592\n",
            "Epoch 331/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0528 - mean_absolute_error: 0.1808 - mean_squared_error: 0.0528\n",
            "Epoch 331: val_loss did not improve from 0.05518\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0529 - mean_absolute_error: 0.1807 - mean_squared_error: 0.0529 - val_loss: 0.0658 - val_mean_absolute_error: 0.1998 - val_mean_squared_error: 0.0658\n",
            "Epoch 332/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.0512 - mean_absolute_error: 0.1777 - mean_squared_error: 0.0512\n",
            "Epoch 332: val_loss did not improve from 0.05518\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0513 - mean_absolute_error: 0.1780 - mean_squared_error: 0.0513 - val_loss: 0.0570 - val_mean_absolute_error: 0.1875 - val_mean_squared_error: 0.0570\n",
            "Epoch 333/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0524 - mean_absolute_error: 0.1799 - mean_squared_error: 0.0524\n",
            "Epoch 333: val_loss did not improve from 0.05518\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0524 - mean_absolute_error: 0.1799 - mean_squared_error: 0.0524 - val_loss: 0.0579 - val_mean_absolute_error: 0.1894 - val_mean_squared_error: 0.0579\n",
            "Epoch 334/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0517 - mean_absolute_error: 0.1782 - mean_squared_error: 0.0517\n",
            "Epoch 334: val_loss improved from 0.05518 to 0.05388, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0519 - mean_absolute_error: 0.1784 - mean_squared_error: 0.0519 - val_loss: 0.0539 - val_mean_absolute_error: 0.1826 - val_mean_squared_error: 0.0539\n",
            "Epoch 335/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0515 - mean_absolute_error: 0.1782 - mean_squared_error: 0.0515\n",
            "Epoch 335: val_loss did not improve from 0.05388\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0514 - mean_absolute_error: 0.1783 - mean_squared_error: 0.0514 - val_loss: 0.0569 - val_mean_absolute_error: 0.1856 - val_mean_squared_error: 0.0569\n",
            "Epoch 336/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.0498 - mean_absolute_error: 0.1753 - mean_squared_error: 0.0498\n",
            "Epoch 336: val_loss did not improve from 0.05388\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0501 - mean_absolute_error: 0.1757 - mean_squared_error: 0.0501 - val_loss: 0.0551 - val_mean_absolute_error: 0.1807 - val_mean_squared_error: 0.0551\n",
            "Epoch 337/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0522 - mean_absolute_error: 0.1789 - mean_squared_error: 0.0522\n",
            "Epoch 337: val_loss improved from 0.05388 to 0.05183, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0520 - mean_absolute_error: 0.1788 - mean_squared_error: 0.0520 - val_loss: 0.0518 - val_mean_absolute_error: 0.1784 - val_mean_squared_error: 0.0518\n",
            "Epoch 338/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0512 - mean_absolute_error: 0.1764 - mean_squared_error: 0.0512\n",
            "Epoch 338: val_loss did not improve from 0.05183\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0509 - mean_absolute_error: 0.1760 - mean_squared_error: 0.0509 - val_loss: 0.0535 - val_mean_absolute_error: 0.1806 - val_mean_squared_error: 0.0535\n",
            "Epoch 339/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0523 - mean_absolute_error: 0.1784 - mean_squared_error: 0.0523\n",
            "Epoch 339: val_loss did not improve from 0.05183\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0526 - mean_absolute_error: 0.1790 - mean_squared_error: 0.0526 - val_loss: 0.0553 - val_mean_absolute_error: 0.1839 - val_mean_squared_error: 0.0553\n",
            "Epoch 340/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0507 - mean_absolute_error: 0.1761 - mean_squared_error: 0.0507\n",
            "Epoch 340: val_loss did not improve from 0.05183\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0506 - mean_absolute_error: 0.1760 - mean_squared_error: 0.0506 - val_loss: 0.0525 - val_mean_absolute_error: 0.1810 - val_mean_squared_error: 0.0525\n",
            "Epoch 341/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.0507 - mean_absolute_error: 0.1768 - mean_squared_error: 0.0507\n",
            "Epoch 341: val_loss did not improve from 0.05183\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0506 - mean_absolute_error: 0.1767 - mean_squared_error: 0.0506 - val_loss: 0.0572 - val_mean_absolute_error: 0.1893 - val_mean_squared_error: 0.0572\n",
            "Epoch 342/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.0504 - mean_absolute_error: 0.1752 - mean_squared_error: 0.0504\n",
            "Epoch 342: val_loss improved from 0.05183 to 0.05056, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0504 - mean_absolute_error: 0.1752 - mean_squared_error: 0.0504 - val_loss: 0.0506 - val_mean_absolute_error: 0.1760 - val_mean_squared_error: 0.0506\n",
            "Epoch 343/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0486 - mean_absolute_error: 0.1726 - mean_squared_error: 0.0486\n",
            "Epoch 343: val_loss did not improve from 0.05056\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0488 - mean_absolute_error: 0.1730 - mean_squared_error: 0.0488 - val_loss: 0.0572 - val_mean_absolute_error: 0.1855 - val_mean_squared_error: 0.0572\n",
            "Epoch 344/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0505 - mean_absolute_error: 0.1748 - mean_squared_error: 0.0505\n",
            "Epoch 344: val_loss did not improve from 0.05056\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0502 - mean_absolute_error: 0.1745 - mean_squared_error: 0.0502 - val_loss: 0.0510 - val_mean_absolute_error: 0.1743 - val_mean_squared_error: 0.0510\n",
            "Epoch 345/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0490 - mean_absolute_error: 0.1733 - mean_squared_error: 0.0490\n",
            "Epoch 345: val_loss did not improve from 0.05056\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0488 - mean_absolute_error: 0.1731 - mean_squared_error: 0.0488 - val_loss: 0.0512 - val_mean_absolute_error: 0.1772 - val_mean_squared_error: 0.0512\n",
            "Epoch 346/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0493 - mean_absolute_error: 0.1734 - mean_squared_error: 0.0493\n",
            "Epoch 346: val_loss did not improve from 0.05056\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0493 - mean_absolute_error: 0.1735 - mean_squared_error: 0.0493 - val_loss: 0.0608 - val_mean_absolute_error: 0.1936 - val_mean_squared_error: 0.0608\n",
            "Epoch 347/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0482 - mean_absolute_error: 0.1724 - mean_squared_error: 0.0482\n",
            "Epoch 347: val_loss did not improve from 0.05056\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0480 - mean_absolute_error: 0.1721 - mean_squared_error: 0.0480 - val_loss: 0.0565 - val_mean_absolute_error: 0.1817 - val_mean_squared_error: 0.0565\n",
            "Epoch 348/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0495 - mean_absolute_error: 0.1738 - mean_squared_error: 0.0495\n",
            "Epoch 348: val_loss improved from 0.05056 to 0.05021, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0492 - mean_absolute_error: 0.1731 - mean_squared_error: 0.0492 - val_loss: 0.0502 - val_mean_absolute_error: 0.1761 - val_mean_squared_error: 0.0502\n",
            "Epoch 349/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0494 - mean_absolute_error: 0.1738 - mean_squared_error: 0.0494\n",
            "Epoch 349: val_loss did not improve from 0.05021\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0492 - mean_absolute_error: 0.1734 - mean_squared_error: 0.0492 - val_loss: 0.0526 - val_mean_absolute_error: 0.1793 - val_mean_squared_error: 0.0526\n",
            "Epoch 350/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0483 - mean_absolute_error: 0.1724 - mean_squared_error: 0.0483\n",
            "Epoch 350: val_loss did not improve from 0.05021\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0482 - mean_absolute_error: 0.1724 - mean_squared_error: 0.0482 - val_loss: 0.0505 - val_mean_absolute_error: 0.1748 - val_mean_squared_error: 0.0505\n",
            "Epoch 351/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0482 - mean_absolute_error: 0.1717 - mean_squared_error: 0.0482\n",
            "Epoch 351: val_loss improved from 0.05021 to 0.04933, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0481 - mean_absolute_error: 0.1713 - mean_squared_error: 0.0481 - val_loss: 0.0493 - val_mean_absolute_error: 0.1738 - val_mean_squared_error: 0.0493\n",
            "Epoch 352/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.0480 - mean_absolute_error: 0.1718 - mean_squared_error: 0.0480\n",
            "Epoch 352: val_loss did not improve from 0.04933\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0476 - mean_absolute_error: 0.1712 - mean_squared_error: 0.0476 - val_loss: 0.0519 - val_mean_absolute_error: 0.1746 - val_mean_squared_error: 0.0519\n",
            "Epoch 353/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0485 - mean_absolute_error: 0.1720 - mean_squared_error: 0.0485\n",
            "Epoch 353: val_loss did not improve from 0.04933\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0483 - mean_absolute_error: 0.1718 - mean_squared_error: 0.0483 - val_loss: 0.0501 - val_mean_absolute_error: 0.1744 - val_mean_squared_error: 0.0501\n",
            "Epoch 354/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 0.0475 - mean_absolute_error: 0.1695 - mean_squared_error: 0.0475\n",
            "Epoch 354: val_loss did not improve from 0.04933\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0473 - mean_absolute_error: 0.1693 - mean_squared_error: 0.0473 - val_loss: 0.0494 - val_mean_absolute_error: 0.1725 - val_mean_squared_error: 0.0494\n",
            "Epoch 355/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0476 - mean_absolute_error: 0.1710 - mean_squared_error: 0.0476\n",
            "Epoch 355: val_loss did not improve from 0.04933\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0478 - mean_absolute_error: 0.1712 - mean_squared_error: 0.0478 - val_loss: 0.0494 - val_mean_absolute_error: 0.1764 - val_mean_squared_error: 0.0494\n",
            "Epoch 356/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0473 - mean_absolute_error: 0.1709 - mean_squared_error: 0.0473\n",
            "Epoch 356: val_loss improved from 0.04933 to 0.04812, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0473 - mean_absolute_error: 0.1707 - mean_squared_error: 0.0473 - val_loss: 0.0481 - val_mean_absolute_error: 0.1707 - val_mean_squared_error: 0.0481\n",
            "Epoch 357/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.0470 - mean_absolute_error: 0.1695 - mean_squared_error: 0.0470\n",
            "Epoch 357: val_loss did not improve from 0.04812\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0473 - mean_absolute_error: 0.1703 - mean_squared_error: 0.0473 - val_loss: 0.0503 - val_mean_absolute_error: 0.1783 - val_mean_squared_error: 0.0503\n",
            "Epoch 358/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0458 - mean_absolute_error: 0.1665 - mean_squared_error: 0.0458\n",
            "Epoch 358: val_loss did not improve from 0.04812\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0456 - mean_absolute_error: 0.1663 - mean_squared_error: 0.0456 - val_loss: 0.0514 - val_mean_absolute_error: 0.1758 - val_mean_squared_error: 0.0514\n",
            "Epoch 359/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0486 - mean_absolute_error: 0.1716 - mean_squared_error: 0.0486\n",
            "Epoch 359: val_loss improved from 0.04812 to 0.04764, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0485 - mean_absolute_error: 0.1716 - mean_squared_error: 0.0485 - val_loss: 0.0476 - val_mean_absolute_error: 0.1696 - val_mean_squared_error: 0.0476\n",
            "Epoch 360/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0467 - mean_absolute_error: 0.1686 - mean_squared_error: 0.0467\n",
            "Epoch 360: val_loss did not improve from 0.04764\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0468 - mean_absolute_error: 0.1688 - mean_squared_error: 0.0468 - val_loss: 0.0501 - val_mean_absolute_error: 0.1742 - val_mean_squared_error: 0.0501\n",
            "Epoch 361/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0457 - mean_absolute_error: 0.1676 - mean_squared_error: 0.0457\n",
            "Epoch 361: val_loss did not improve from 0.04764\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0458 - mean_absolute_error: 0.1676 - mean_squared_error: 0.0458 - val_loss: 0.0520 - val_mean_absolute_error: 0.1754 - val_mean_squared_error: 0.0520\n",
            "Epoch 362/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0465 - mean_absolute_error: 0.1682 - mean_squared_error: 0.0465\n",
            "Epoch 362: val_loss did not improve from 0.04764\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0465 - mean_absolute_error: 0.1679 - mean_squared_error: 0.0465 - val_loss: 0.0485 - val_mean_absolute_error: 0.1699 - val_mean_squared_error: 0.0485\n",
            "Epoch 363/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0468 - mean_absolute_error: 0.1689 - mean_squared_error: 0.0468\n",
            "Epoch 363: val_loss did not improve from 0.04764\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0467 - mean_absolute_error: 0.1684 - mean_squared_error: 0.0467 - val_loss: 0.0493 - val_mean_absolute_error: 0.1721 - val_mean_squared_error: 0.0493\n",
            "Epoch 364/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0462 - mean_absolute_error: 0.1680 - mean_squared_error: 0.0462\n",
            "Epoch 364: val_loss improved from 0.04764 to 0.04733, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0460 - mean_absolute_error: 0.1676 - mean_squared_error: 0.0460 - val_loss: 0.0473 - val_mean_absolute_error: 0.1695 - val_mean_squared_error: 0.0473\n",
            "Epoch 365/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0471 - mean_absolute_error: 0.1699 - mean_squared_error: 0.0471\n",
            "Epoch 365: val_loss did not improve from 0.04733\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0471 - mean_absolute_error: 0.1699 - mean_squared_error: 0.0471 - val_loss: 0.0513 - val_mean_absolute_error: 0.1773 - val_mean_squared_error: 0.0513\n",
            "Epoch 366/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0465 - mean_absolute_error: 0.1681 - mean_squared_error: 0.0465\n",
            "Epoch 366: val_loss did not improve from 0.04733\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0464 - mean_absolute_error: 0.1681 - mean_squared_error: 0.0464 - val_loss: 0.0497 - val_mean_absolute_error: 0.1730 - val_mean_squared_error: 0.0497\n",
            "Epoch 367/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0468 - mean_absolute_error: 0.1691 - mean_squared_error: 0.0468\n",
            "Epoch 367: val_loss did not improve from 0.04733\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0467 - mean_absolute_error: 0.1685 - mean_squared_error: 0.0467 - val_loss: 0.0497 - val_mean_absolute_error: 0.1680 - val_mean_squared_error: 0.0497\n",
            "Epoch 368/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0458 - mean_absolute_error: 0.1666 - mean_squared_error: 0.0458\n",
            "Epoch 368: val_loss did not improve from 0.04733\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0458 - mean_absolute_error: 0.1666 - mean_squared_error: 0.0458 - val_loss: 0.0481 - val_mean_absolute_error: 0.1704 - val_mean_squared_error: 0.0481\n",
            "Epoch 369/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0457 - mean_absolute_error: 0.1673 - mean_squared_error: 0.0457\n",
            "Epoch 369: val_loss improved from 0.04733 to 0.04677, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0456 - mean_absolute_error: 0.1670 - mean_squared_error: 0.0456 - val_loss: 0.0468 - val_mean_absolute_error: 0.1690 - val_mean_squared_error: 0.0468\n",
            "Epoch 370/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.0444 - mean_absolute_error: 0.1640 - mean_squared_error: 0.0444\n",
            "Epoch 370: val_loss did not improve from 0.04677\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0450 - mean_absolute_error: 0.1649 - mean_squared_error: 0.0450 - val_loss: 0.0534 - val_mean_absolute_error: 0.1790 - val_mean_squared_error: 0.0534\n",
            "Epoch 371/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0450 - mean_absolute_error: 0.1650 - mean_squared_error: 0.0450\n",
            "Epoch 371: val_loss did not improve from 0.04677\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0449 - mean_absolute_error: 0.1648 - mean_squared_error: 0.0449 - val_loss: 0.0477 - val_mean_absolute_error: 0.1662 - val_mean_squared_error: 0.0477\n",
            "Epoch 372/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0450 - mean_absolute_error: 0.1649 - mean_squared_error: 0.0450\n",
            "Epoch 372: val_loss improved from 0.04677 to 0.04436, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0450 - mean_absolute_error: 0.1647 - mean_squared_error: 0.0450 - val_loss: 0.0444 - val_mean_absolute_error: 0.1627 - val_mean_squared_error: 0.0444\n",
            "Epoch 373/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0440 - mean_absolute_error: 0.1633 - mean_squared_error: 0.0440\n",
            "Epoch 373: val_loss did not improve from 0.04436\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0442 - mean_absolute_error: 0.1636 - mean_squared_error: 0.0442 - val_loss: 0.0494 - val_mean_absolute_error: 0.1758 - val_mean_squared_error: 0.0494\n",
            "Epoch 374/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0444 - mean_absolute_error: 0.1646 - mean_squared_error: 0.0444\n",
            "Epoch 374: val_loss did not improve from 0.04436\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0446 - mean_absolute_error: 0.1649 - mean_squared_error: 0.0446 - val_loss: 0.0451 - val_mean_absolute_error: 0.1661 - val_mean_squared_error: 0.0451\n",
            "Epoch 375/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0448 - mean_absolute_error: 0.1658 - mean_squared_error: 0.0448\n",
            "Epoch 375: val_loss did not improve from 0.04436\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0446 - mean_absolute_error: 0.1655 - mean_squared_error: 0.0446 - val_loss: 0.0496 - val_mean_absolute_error: 0.1748 - val_mean_squared_error: 0.0496\n",
            "Epoch 376/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0455 - mean_absolute_error: 0.1670 - mean_squared_error: 0.0455\n",
            "Epoch 376: val_loss did not improve from 0.04436\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0453 - mean_absolute_error: 0.1665 - mean_squared_error: 0.0453 - val_loss: 0.0460 - val_mean_absolute_error: 0.1631 - val_mean_squared_error: 0.0460\n",
            "Epoch 377/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0434 - mean_absolute_error: 0.1627 - mean_squared_error: 0.0434\n",
            "Epoch 377: val_loss did not improve from 0.04436\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0436 - mean_absolute_error: 0.1630 - mean_squared_error: 0.0436 - val_loss: 0.0463 - val_mean_absolute_error: 0.1686 - val_mean_squared_error: 0.0463\n",
            "Epoch 378/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0439 - mean_absolute_error: 0.1628 - mean_squared_error: 0.0439\n",
            "Epoch 378: val_loss did not improve from 0.04436\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0438 - mean_absolute_error: 0.1627 - mean_squared_error: 0.0438 - val_loss: 0.0468 - val_mean_absolute_error: 0.1660 - val_mean_squared_error: 0.0468\n",
            "Epoch 379/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.0438 - mean_absolute_error: 0.1630 - mean_squared_error: 0.0438\n",
            "Epoch 379: val_loss improved from 0.04436 to 0.04431, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0436 - mean_absolute_error: 0.1625 - mean_squared_error: 0.0436 - val_loss: 0.0443 - val_mean_absolute_error: 0.1638 - val_mean_squared_error: 0.0443\n",
            "Epoch 380/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0437 - mean_absolute_error: 0.1626 - mean_squared_error: 0.0437\n",
            "Epoch 380: val_loss did not improve from 0.04431\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0437 - mean_absolute_error: 0.1629 - mean_squared_error: 0.0437 - val_loss: 0.0505 - val_mean_absolute_error: 0.1774 - val_mean_squared_error: 0.0505\n",
            "Epoch 381/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0438 - mean_absolute_error: 0.1637 - mean_squared_error: 0.0438\n",
            "Epoch 381: val_loss improved from 0.04431 to 0.04409, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0438 - mean_absolute_error: 0.1637 - mean_squared_error: 0.0438 - val_loss: 0.0441 - val_mean_absolute_error: 0.1652 - val_mean_squared_error: 0.0441\n",
            "Epoch 382/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0439 - mean_absolute_error: 0.1635 - mean_squared_error: 0.0439\n",
            "Epoch 382: val_loss did not improve from 0.04409\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0438 - mean_absolute_error: 0.1632 - mean_squared_error: 0.0438 - val_loss: 0.0456 - val_mean_absolute_error: 0.1650 - val_mean_squared_error: 0.0456\n",
            "Epoch 383/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0436 - mean_absolute_error: 0.1616 - mean_squared_error: 0.0436\n",
            "Epoch 383: val_loss did not improve from 0.04409\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0435 - mean_absolute_error: 0.1616 - mean_squared_error: 0.0435 - val_loss: 0.0477 - val_mean_absolute_error: 0.1702 - val_mean_squared_error: 0.0477\n",
            "Epoch 384/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.0436 - mean_absolute_error: 0.1621 - mean_squared_error: 0.0436\n",
            "Epoch 384: val_loss did not improve from 0.04409\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0436 - mean_absolute_error: 0.1623 - mean_squared_error: 0.0436 - val_loss: 0.0447 - val_mean_absolute_error: 0.1653 - val_mean_squared_error: 0.0447\n",
            "Epoch 385/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0442 - mean_absolute_error: 0.1628 - mean_squared_error: 0.0442\n",
            "Epoch 385: val_loss did not improve from 0.04409\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0442 - mean_absolute_error: 0.1628 - mean_squared_error: 0.0442 - val_loss: 0.0445 - val_mean_absolute_error: 0.1630 - val_mean_squared_error: 0.0445\n",
            "Epoch 386/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0422 - mean_absolute_error: 0.1600 - mean_squared_error: 0.0422\n",
            "Epoch 386: val_loss did not improve from 0.04409\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0423 - mean_absolute_error: 0.1600 - mean_squared_error: 0.0423 - val_loss: 0.0451 - val_mean_absolute_error: 0.1599 - val_mean_squared_error: 0.0451\n",
            "Epoch 387/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0423 - mean_absolute_error: 0.1598 - mean_squared_error: 0.0423\n",
            "Epoch 387: val_loss did not improve from 0.04409\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0424 - mean_absolute_error: 0.1602 - mean_squared_error: 0.0424 - val_loss: 0.0490 - val_mean_absolute_error: 0.1748 - val_mean_squared_error: 0.0490\n",
            "Epoch 388/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0427 - mean_absolute_error: 0.1606 - mean_squared_error: 0.0427\n",
            "Epoch 388: val_loss improved from 0.04409 to 0.04253, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0430 - mean_absolute_error: 0.1611 - mean_squared_error: 0.0430 - val_loss: 0.0425 - val_mean_absolute_error: 0.1592 - val_mean_squared_error: 0.0425\n",
            "Epoch 389/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0424 - mean_absolute_error: 0.1603 - mean_squared_error: 0.0424\n",
            "Epoch 389: val_loss improved from 0.04253 to 0.04237, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0423 - mean_absolute_error: 0.1601 - mean_squared_error: 0.0423 - val_loss: 0.0424 - val_mean_absolute_error: 0.1602 - val_mean_squared_error: 0.0424\n",
            "Epoch 390/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0411 - mean_absolute_error: 0.1584 - mean_squared_error: 0.0411\n",
            "Epoch 390: val_loss did not improve from 0.04237\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0414 - mean_absolute_error: 0.1587 - mean_squared_error: 0.0414 - val_loss: 0.0438 - val_mean_absolute_error: 0.1644 - val_mean_squared_error: 0.0438\n",
            "Epoch 391/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.0414 - mean_absolute_error: 0.1585 - mean_squared_error: 0.0414\n",
            "Epoch 391: val_loss improved from 0.04237 to 0.04143, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0415 - mean_absolute_error: 0.1589 - mean_squared_error: 0.0415 - val_loss: 0.0414 - val_mean_absolute_error: 0.1577 - val_mean_squared_error: 0.0414\n",
            "Epoch 392/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0421 - mean_absolute_error: 0.1605 - mean_squared_error: 0.0421\n",
            "Epoch 392: val_loss did not improve from 0.04143\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0421 - mean_absolute_error: 0.1606 - mean_squared_error: 0.0421 - val_loss: 0.0443 - val_mean_absolute_error: 0.1633 - val_mean_squared_error: 0.0443\n",
            "Epoch 393/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0417 - mean_absolute_error: 0.1588 - mean_squared_error: 0.0417\n",
            "Epoch 393: val_loss did not improve from 0.04143\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0417 - mean_absolute_error: 0.1588 - mean_squared_error: 0.0417 - val_loss: 0.0429 - val_mean_absolute_error: 0.1647 - val_mean_squared_error: 0.0429\n",
            "Epoch 394/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0423 - mean_absolute_error: 0.1605 - mean_squared_error: 0.0423\n",
            "Epoch 394: val_loss did not improve from 0.04143\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0424 - mean_absolute_error: 0.1607 - mean_squared_error: 0.0424 - val_loss: 0.0440 - val_mean_absolute_error: 0.1651 - val_mean_squared_error: 0.0440\n",
            "Epoch 395/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0410 - mean_absolute_error: 0.1583 - mean_squared_error: 0.0410\n",
            "Epoch 395: val_loss did not improve from 0.04143\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0410 - mean_absolute_error: 0.1581 - mean_squared_error: 0.0410 - val_loss: 0.0420 - val_mean_absolute_error: 0.1619 - val_mean_squared_error: 0.0420\n",
            "Epoch 396/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0411 - mean_absolute_error: 0.1571 - mean_squared_error: 0.0411\n",
            "Epoch 396: val_loss did not improve from 0.04143\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0411 - mean_absolute_error: 0.1572 - mean_squared_error: 0.0411 - val_loss: 0.0438 - val_mean_absolute_error: 0.1631 - val_mean_squared_error: 0.0438\n",
            "Epoch 397/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0412 - mean_absolute_error: 0.1578 - mean_squared_error: 0.0412\n",
            "Epoch 397: val_loss improved from 0.04143 to 0.04061, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0412 - mean_absolute_error: 0.1579 - mean_squared_error: 0.0412 - val_loss: 0.0406 - val_mean_absolute_error: 0.1555 - val_mean_squared_error: 0.0406\n",
            "Epoch 398/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0413 - mean_absolute_error: 0.1572 - mean_squared_error: 0.0413\n",
            "Epoch 398: val_loss did not improve from 0.04061\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0411 - mean_absolute_error: 0.1572 - mean_squared_error: 0.0411 - val_loss: 0.0427 - val_mean_absolute_error: 0.1596 - val_mean_squared_error: 0.0427\n",
            "Epoch 399/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0403 - mean_absolute_error: 0.1565 - mean_squared_error: 0.0403\n",
            "Epoch 399: val_loss did not improve from 0.04061\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0403 - mean_absolute_error: 0.1564 - mean_squared_error: 0.0403 - val_loss: 0.0425 - val_mean_absolute_error: 0.1605 - val_mean_squared_error: 0.0425\n",
            "Epoch 400/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.0402 - mean_absolute_error: 0.1558 - mean_squared_error: 0.0402\n",
            "Epoch 400: val_loss improved from 0.04061 to 0.04017, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0401 - mean_absolute_error: 0.1558 - mean_squared_error: 0.0401 - val_loss: 0.0402 - val_mean_absolute_error: 0.1552 - val_mean_squared_error: 0.0402\n",
            "Epoch 401/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.0398 - mean_absolute_error: 0.1551 - mean_squared_error: 0.0398\n",
            "Epoch 401: val_loss did not improve from 0.04017\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0399 - mean_absolute_error: 0.1553 - mean_squared_error: 0.0399 - val_loss: 0.0420 - val_mean_absolute_error: 0.1605 - val_mean_squared_error: 0.0420\n",
            "Epoch 402/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0400 - mean_absolute_error: 0.1556 - mean_squared_error: 0.0400\n",
            "Epoch 402: val_loss improved from 0.04017 to 0.03968, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0402 - mean_absolute_error: 0.1560 - mean_squared_error: 0.0402 - val_loss: 0.0397 - val_mean_absolute_error: 0.1524 - val_mean_squared_error: 0.0397\n",
            "Epoch 403/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0400 - mean_absolute_error: 0.1552 - mean_squared_error: 0.0400\n",
            "Epoch 403: val_loss did not improve from 0.03968\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0400 - mean_absolute_error: 0.1552 - mean_squared_error: 0.0400 - val_loss: 0.0422 - val_mean_absolute_error: 0.1596 - val_mean_squared_error: 0.0422\n",
            "Epoch 404/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0403 - mean_absolute_error: 0.1556 - mean_squared_error: 0.0403\n",
            "Epoch 404: val_loss did not improve from 0.03968\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0403 - mean_absolute_error: 0.1555 - mean_squared_error: 0.0403 - val_loss: 0.0411 - val_mean_absolute_error: 0.1543 - val_mean_squared_error: 0.0411\n",
            "Epoch 405/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.0406 - mean_absolute_error: 0.1567 - mean_squared_error: 0.0406\n",
            "Epoch 405: val_loss did not improve from 0.03968\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0401 - mean_absolute_error: 0.1558 - mean_squared_error: 0.0401 - val_loss: 0.0429 - val_mean_absolute_error: 0.1620 - val_mean_squared_error: 0.0429\n",
            "Epoch 406/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0384 - mean_absolute_error: 0.1522 - mean_squared_error: 0.0384\n",
            "Epoch 406: val_loss did not improve from 0.03968\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0385 - mean_absolute_error: 0.1523 - mean_squared_error: 0.0385 - val_loss: 0.0408 - val_mean_absolute_error: 0.1566 - val_mean_squared_error: 0.0408\n",
            "Epoch 407/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0406 - mean_absolute_error: 0.1579 - mean_squared_error: 0.0406\n",
            "Epoch 407: val_loss did not improve from 0.03968\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0405 - mean_absolute_error: 0.1577 - mean_squared_error: 0.0405 - val_loss: 0.0422 - val_mean_absolute_error: 0.1592 - val_mean_squared_error: 0.0422\n",
            "Epoch 408/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.0400 - mean_absolute_error: 0.1558 - mean_squared_error: 0.0400\n",
            "Epoch 408: val_loss did not improve from 0.03968\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0399 - mean_absolute_error: 0.1552 - mean_squared_error: 0.0399 - val_loss: 0.0404 - val_mean_absolute_error: 0.1582 - val_mean_squared_error: 0.0404\n",
            "Epoch 409/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0392 - mean_absolute_error: 0.1536 - mean_squared_error: 0.0392\n",
            "Epoch 409: val_loss did not improve from 0.03968\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0392 - mean_absolute_error: 0.1539 - mean_squared_error: 0.0392 - val_loss: 0.0408 - val_mean_absolute_error: 0.1584 - val_mean_squared_error: 0.0408\n",
            "Epoch 410/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.0388 - mean_absolute_error: 0.1534 - mean_squared_error: 0.0388\n",
            "Epoch 410: val_loss did not improve from 0.03968\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0390 - mean_absolute_error: 0.1534 - mean_squared_error: 0.0390 - val_loss: 0.0416 - val_mean_absolute_error: 0.1579 - val_mean_squared_error: 0.0416\n",
            "Epoch 411/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0391 - mean_absolute_error: 0.1532 - mean_squared_error: 0.0391\n",
            "Epoch 411: val_loss did not improve from 0.03968\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0390 - mean_absolute_error: 0.1532 - mean_squared_error: 0.0390 - val_loss: 0.0400 - val_mean_absolute_error: 0.1562 - val_mean_squared_error: 0.0400\n",
            "Epoch 412/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.0393 - mean_absolute_error: 0.1535 - mean_squared_error: 0.0393\n",
            "Epoch 412: val_loss improved from 0.03968 to 0.03927, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0394 - mean_absolute_error: 0.1536 - mean_squared_error: 0.0394 - val_loss: 0.0393 - val_mean_absolute_error: 0.1560 - val_mean_squared_error: 0.0393\n",
            "Epoch 413/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0398 - mean_absolute_error: 0.1559 - mean_squared_error: 0.0398\n",
            "Epoch 413: val_loss did not improve from 0.03927\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0395 - mean_absolute_error: 0.1550 - mean_squared_error: 0.0395 - val_loss: 0.0399 - val_mean_absolute_error: 0.1543 - val_mean_squared_error: 0.0399\n",
            "Epoch 414/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.0380 - mean_absolute_error: 0.1511 - mean_squared_error: 0.0380\n",
            "Epoch 414: val_loss improved from 0.03927 to 0.03862, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0382 - mean_absolute_error: 0.1519 - mean_squared_error: 0.0382 - val_loss: 0.0386 - val_mean_absolute_error: 0.1519 - val_mean_squared_error: 0.0386\n",
            "Epoch 415/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0380 - mean_absolute_error: 0.1514 - mean_squared_error: 0.0380\n",
            "Epoch 415: val_loss improved from 0.03862 to 0.03853, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0380 - mean_absolute_error: 0.1515 - mean_squared_error: 0.0380 - val_loss: 0.0385 - val_mean_absolute_error: 0.1533 - val_mean_squared_error: 0.0385\n",
            "Epoch 416/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.0382 - mean_absolute_error: 0.1515 - mean_squared_error: 0.0382\n",
            "Epoch 416: val_loss did not improve from 0.03853\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0379 - mean_absolute_error: 0.1512 - mean_squared_error: 0.0379 - val_loss: 0.0417 - val_mean_absolute_error: 0.1577 - val_mean_squared_error: 0.0417\n",
            "Epoch 417/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0385 - mean_absolute_error: 0.1525 - mean_squared_error: 0.0385\n",
            "Epoch 417: val_loss did not improve from 0.03853\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0385 - mean_absolute_error: 0.1524 - mean_squared_error: 0.0385 - val_loss: 0.0410 - val_mean_absolute_error: 0.1584 - val_mean_squared_error: 0.0410\n",
            "Epoch 418/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0381 - mean_absolute_error: 0.1512 - mean_squared_error: 0.0381\n",
            "Epoch 418: val_loss improved from 0.03853 to 0.03828, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0380 - mean_absolute_error: 0.1514 - mean_squared_error: 0.0380 - val_loss: 0.0383 - val_mean_absolute_error: 0.1523 - val_mean_squared_error: 0.0383\n",
            "Epoch 419/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.0379 - mean_absolute_error: 0.1512 - mean_squared_error: 0.0379\n",
            "Epoch 419: val_loss did not improve from 0.03828\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0380 - mean_absolute_error: 0.1516 - mean_squared_error: 0.0380 - val_loss: 0.0402 - val_mean_absolute_error: 0.1565 - val_mean_squared_error: 0.0402\n",
            "Epoch 420/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0378 - mean_absolute_error: 0.1517 - mean_squared_error: 0.0378\n",
            "Epoch 420: val_loss did not improve from 0.03828\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0378 - mean_absolute_error: 0.1518 - mean_squared_error: 0.0378 - val_loss: 0.0386 - val_mean_absolute_error: 0.1492 - val_mean_squared_error: 0.0386\n",
            "Epoch 421/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0390 - mean_absolute_error: 0.1531 - mean_squared_error: 0.0390\n",
            "Epoch 421: val_loss improved from 0.03828 to 0.03681, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0390 - mean_absolute_error: 0.1531 - mean_squared_error: 0.0390 - val_loss: 0.0368 - val_mean_absolute_error: 0.1479 - val_mean_squared_error: 0.0368\n",
            "Epoch 422/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0374 - mean_absolute_error: 0.1512 - mean_squared_error: 0.0374\n",
            "Epoch 422: val_loss did not improve from 0.03681\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0375 - mean_absolute_error: 0.1512 - mean_squared_error: 0.0375 - val_loss: 0.0388 - val_mean_absolute_error: 0.1552 - val_mean_squared_error: 0.0388\n",
            "Epoch 423/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0369 - mean_absolute_error: 0.1493 - mean_squared_error: 0.0369\n",
            "Epoch 423: val_loss did not improve from 0.03681\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0369 - mean_absolute_error: 0.1491 - mean_squared_error: 0.0369 - val_loss: 0.0394 - val_mean_absolute_error: 0.1536 - val_mean_squared_error: 0.0394\n",
            "Epoch 424/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.0376 - mean_absolute_error: 0.1503 - mean_squared_error: 0.0376\n",
            "Epoch 424: val_loss did not improve from 0.03681\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0376 - mean_absolute_error: 0.1502 - mean_squared_error: 0.0376 - val_loss: 0.0379 - val_mean_absolute_error: 0.1510 - val_mean_squared_error: 0.0379\n",
            "Epoch 425/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0366 - mean_absolute_error: 0.1486 - mean_squared_error: 0.0366\n",
            "Epoch 425: val_loss improved from 0.03681 to 0.03584, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0364 - mean_absolute_error: 0.1481 - mean_squared_error: 0.0364 - val_loss: 0.0358 - val_mean_absolute_error: 0.1459 - val_mean_squared_error: 0.0358\n",
            "Epoch 426/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0368 - mean_absolute_error: 0.1486 - mean_squared_error: 0.0368\n",
            "Epoch 426: val_loss did not improve from 0.03584\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0367 - mean_absolute_error: 0.1485 - mean_squared_error: 0.0367 - val_loss: 0.0375 - val_mean_absolute_error: 0.1499 - val_mean_squared_error: 0.0375\n",
            "Epoch 427/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0374 - mean_absolute_error: 0.1509 - mean_squared_error: 0.0374\n",
            "Epoch 427: val_loss did not improve from 0.03584\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0373 - mean_absolute_error: 0.1509 - mean_squared_error: 0.0373 - val_loss: 0.0374 - val_mean_absolute_error: 0.1505 - val_mean_squared_error: 0.0374\n",
            "Epoch 428/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0375 - mean_absolute_error: 0.1499 - mean_squared_error: 0.0375\n",
            "Epoch 428: val_loss did not improve from 0.03584\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0375 - mean_absolute_error: 0.1502 - mean_squared_error: 0.0375 - val_loss: 0.0372 - val_mean_absolute_error: 0.1513 - val_mean_squared_error: 0.0372\n",
            "Epoch 429/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.0359 - mean_absolute_error: 0.1469 - mean_squared_error: 0.0359\n",
            "Epoch 429: val_loss did not improve from 0.03584\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0358 - mean_absolute_error: 0.1469 - mean_squared_error: 0.0358 - val_loss: 0.0395 - val_mean_absolute_error: 0.1570 - val_mean_squared_error: 0.0395\n",
            "Epoch 430/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0367 - mean_absolute_error: 0.1489 - mean_squared_error: 0.0367\n",
            "Epoch 430: val_loss improved from 0.03584 to 0.03521, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0368 - mean_absolute_error: 0.1489 - mean_squared_error: 0.0368 - val_loss: 0.0352 - val_mean_absolute_error: 0.1461 - val_mean_squared_error: 0.0352\n",
            "Epoch 431/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0360 - mean_absolute_error: 0.1478 - mean_squared_error: 0.0360\n",
            "Epoch 431: val_loss did not improve from 0.03521\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0361 - mean_absolute_error: 0.1480 - mean_squared_error: 0.0361 - val_loss: 0.0465 - val_mean_absolute_error: 0.1674 - val_mean_squared_error: 0.0465\n",
            "Epoch 432/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0372 - mean_absolute_error: 0.1491 - mean_squared_error: 0.0372\n",
            "Epoch 432: val_loss did not improve from 0.03521\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0370 - mean_absolute_error: 0.1490 - mean_squared_error: 0.0370 - val_loss: 0.0356 - val_mean_absolute_error: 0.1474 - val_mean_squared_error: 0.0356\n",
            "Epoch 433/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0354 - mean_absolute_error: 0.1461 - mean_squared_error: 0.0354\n",
            "Epoch 433: val_loss improved from 0.03521 to 0.03467, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0354 - mean_absolute_error: 0.1460 - mean_squared_error: 0.0354 - val_loss: 0.0347 - val_mean_absolute_error: 0.1455 - val_mean_squared_error: 0.0347\n",
            "Epoch 434/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0354 - mean_absolute_error: 0.1464 - mean_squared_error: 0.0354\n",
            "Epoch 434: val_loss improved from 0.03467 to 0.03406, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0354 - mean_absolute_error: 0.1464 - mean_squared_error: 0.0354 - val_loss: 0.0341 - val_mean_absolute_error: 0.1440 - val_mean_squared_error: 0.0341\n",
            "Epoch 435/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0360 - mean_absolute_error: 0.1474 - mean_squared_error: 0.0360\n",
            "Epoch 435: val_loss did not improve from 0.03406\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0360 - mean_absolute_error: 0.1474 - mean_squared_error: 0.0360 - val_loss: 0.0356 - val_mean_absolute_error: 0.1473 - val_mean_squared_error: 0.0356\n",
            "Epoch 436/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.0368 - mean_absolute_error: 0.1494 - mean_squared_error: 0.0368\n",
            "Epoch 436: val_loss did not improve from 0.03406\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0370 - mean_absolute_error: 0.1494 - mean_squared_error: 0.0370 - val_loss: 0.0384 - val_mean_absolute_error: 0.1525 - val_mean_squared_error: 0.0384\n",
            "Epoch 437/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0354 - mean_absolute_error: 0.1467 - mean_squared_error: 0.0354\n",
            "Epoch 437: val_loss did not improve from 0.03406\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0355 - mean_absolute_error: 0.1468 - mean_squared_error: 0.0355 - val_loss: 0.0367 - val_mean_absolute_error: 0.1463 - val_mean_squared_error: 0.0367\n",
            "Epoch 438/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0357 - mean_absolute_error: 0.1473 - mean_squared_error: 0.0357\n",
            "Epoch 438: val_loss did not improve from 0.03406\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0356 - mean_absolute_error: 0.1470 - mean_squared_error: 0.0356 - val_loss: 0.0346 - val_mean_absolute_error: 0.1455 - val_mean_squared_error: 0.0346\n",
            "Epoch 439/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0360 - mean_absolute_error: 0.1472 - mean_squared_error: 0.0360\n",
            "Epoch 439: val_loss did not improve from 0.03406\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0357 - mean_absolute_error: 0.1467 - mean_squared_error: 0.0357 - val_loss: 0.0356 - val_mean_absolute_error: 0.1443 - val_mean_squared_error: 0.0356\n",
            "Epoch 440/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0359 - mean_absolute_error: 0.1467 - mean_squared_error: 0.0359\n",
            "Epoch 440: val_loss did not improve from 0.03406\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0357 - mean_absolute_error: 0.1463 - mean_squared_error: 0.0357 - val_loss: 0.0375 - val_mean_absolute_error: 0.1488 - val_mean_squared_error: 0.0375\n",
            "Epoch 441/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.0347 - mean_absolute_error: 0.1449 - mean_squared_error: 0.0347\n",
            "Epoch 441: val_loss improved from 0.03406 to 0.03394, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0349 - mean_absolute_error: 0.1452 - mean_squared_error: 0.0349 - val_loss: 0.0339 - val_mean_absolute_error: 0.1453 - val_mean_squared_error: 0.0339\n",
            "Epoch 442/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.0347 - mean_absolute_error: 0.1445 - mean_squared_error: 0.0347\n",
            "Epoch 442: val_loss did not improve from 0.03394\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0348 - mean_absolute_error: 0.1450 - mean_squared_error: 0.0348 - val_loss: 0.0341 - val_mean_absolute_error: 0.1423 - val_mean_squared_error: 0.0341\n",
            "Epoch 443/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0349 - mean_absolute_error: 0.1460 - mean_squared_error: 0.0349\n",
            "Epoch 443: val_loss did not improve from 0.03394\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0347 - mean_absolute_error: 0.1456 - mean_squared_error: 0.0347 - val_loss: 0.0362 - val_mean_absolute_error: 0.1456 - val_mean_squared_error: 0.0362\n",
            "Epoch 444/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.0334 - mean_absolute_error: 0.1424 - mean_squared_error: 0.0334\n",
            "Epoch 444: val_loss improved from 0.03394 to 0.03342, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0336 - mean_absolute_error: 0.1426 - mean_squared_error: 0.0336 - val_loss: 0.0334 - val_mean_absolute_error: 0.1429 - val_mean_squared_error: 0.0334\n",
            "Epoch 445/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0347 - mean_absolute_error: 0.1449 - mean_squared_error: 0.0347\n",
            "Epoch 445: val_loss did not improve from 0.03342\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0345 - mean_absolute_error: 0.1446 - mean_squared_error: 0.0345 - val_loss: 0.0339 - val_mean_absolute_error: 0.1438 - val_mean_squared_error: 0.0339\n",
            "Epoch 446/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0344 - mean_absolute_error: 0.1437 - mean_squared_error: 0.0344\n",
            "Epoch 446: val_loss did not improve from 0.03342\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0345 - mean_absolute_error: 0.1438 - mean_squared_error: 0.0345 - val_loss: 0.0342 - val_mean_absolute_error: 0.1453 - val_mean_squared_error: 0.0342\n",
            "Epoch 447/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0346 - mean_absolute_error: 0.1449 - mean_squared_error: 0.0346\n",
            "Epoch 447: val_loss did not improve from 0.03342\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0346 - mean_absolute_error: 0.1451 - mean_squared_error: 0.0346 - val_loss: 0.0351 - val_mean_absolute_error: 0.1468 - val_mean_squared_error: 0.0351\n",
            "Epoch 448/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0338 - mean_absolute_error: 0.1436 - mean_squared_error: 0.0338\n",
            "Epoch 448: val_loss did not improve from 0.03342\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0337 - mean_absolute_error: 0.1433 - mean_squared_error: 0.0337 - val_loss: 0.0334 - val_mean_absolute_error: 0.1406 - val_mean_squared_error: 0.0334\n",
            "Epoch 449/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0345 - mean_absolute_error: 0.1453 - mean_squared_error: 0.0345\n",
            "Epoch 449: val_loss did not improve from 0.03342\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0343 - mean_absolute_error: 0.1448 - mean_squared_error: 0.0343 - val_loss: 0.0353 - val_mean_absolute_error: 0.1498 - val_mean_squared_error: 0.0353\n",
            "Epoch 450/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0341 - mean_absolute_error: 0.1434 - mean_squared_error: 0.0341\n",
            "Epoch 450: val_loss improved from 0.03342 to 0.03156, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0340 - mean_absolute_error: 0.1432 - mean_squared_error: 0.0340 - val_loss: 0.0316 - val_mean_absolute_error: 0.1376 - val_mean_squared_error: 0.0316\n",
            "Epoch 451/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0326 - mean_absolute_error: 0.1408 - mean_squared_error: 0.0326\n",
            "Epoch 451: val_loss did not improve from 0.03156\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0326 - mean_absolute_error: 0.1407 - mean_squared_error: 0.0326 - val_loss: 0.0326 - val_mean_absolute_error: 0.1377 - val_mean_squared_error: 0.0326\n",
            "Epoch 452/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0334 - mean_absolute_error: 0.1420 - mean_squared_error: 0.0334\n",
            "Epoch 452: val_loss did not improve from 0.03156\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0339 - mean_absolute_error: 0.1431 - mean_squared_error: 0.0339 - val_loss: 0.0398 - val_mean_absolute_error: 0.1538 - val_mean_squared_error: 0.0398\n",
            "Epoch 453/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0334 - mean_absolute_error: 0.1423 - mean_squared_error: 0.0334\n",
            "Epoch 453: val_loss did not improve from 0.03156\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0337 - mean_absolute_error: 0.1430 - mean_squared_error: 0.0337 - val_loss: 0.0335 - val_mean_absolute_error: 0.1408 - val_mean_squared_error: 0.0335\n",
            "Epoch 454/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0326 - mean_absolute_error: 0.1412 - mean_squared_error: 0.0326\n",
            "Epoch 454: val_loss did not improve from 0.03156\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0326 - mean_absolute_error: 0.1412 - mean_squared_error: 0.0326 - val_loss: 0.0335 - val_mean_absolute_error: 0.1436 - val_mean_squared_error: 0.0335\n",
            "Epoch 455/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0334 - mean_absolute_error: 0.1417 - mean_squared_error: 0.0334\n",
            "Epoch 455: val_loss did not improve from 0.03156\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0334 - mean_absolute_error: 0.1419 - mean_squared_error: 0.0334 - val_loss: 0.0330 - val_mean_absolute_error: 0.1419 - val_mean_squared_error: 0.0330\n",
            "Epoch 456/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.0317 - mean_absolute_error: 0.1380 - mean_squared_error: 0.0317\n",
            "Epoch 456: val_loss did not improve from 0.03156\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0321 - mean_absolute_error: 0.1389 - mean_squared_error: 0.0321 - val_loss: 0.0328 - val_mean_absolute_error: 0.1404 - val_mean_squared_error: 0.0328\n",
            "Epoch 457/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0325 - mean_absolute_error: 0.1407 - mean_squared_error: 0.0325\n",
            "Epoch 457: val_loss did not improve from 0.03156\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0328 - mean_absolute_error: 0.1412 - mean_squared_error: 0.0328 - val_loss: 0.0347 - val_mean_absolute_error: 0.1489 - val_mean_squared_error: 0.0347\n",
            "Epoch 458/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.0333 - mean_absolute_error: 0.1421 - mean_squared_error: 0.0333\n",
            "Epoch 458: val_loss improved from 0.03156 to 0.03027, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0331 - mean_absolute_error: 0.1417 - mean_squared_error: 0.0331 - val_loss: 0.0303 - val_mean_absolute_error: 0.1366 - val_mean_squared_error: 0.0303\n",
            "Epoch 459/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0325 - mean_absolute_error: 0.1402 - mean_squared_error: 0.0325\n",
            "Epoch 459: val_loss did not improve from 0.03027\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0325 - mean_absolute_error: 0.1402 - mean_squared_error: 0.0325 - val_loss: 0.0325 - val_mean_absolute_error: 0.1410 - val_mean_squared_error: 0.0325\n",
            "Epoch 460/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.0321 - mean_absolute_error: 0.1396 - mean_squared_error: 0.0321\n",
            "Epoch 460: val_loss did not improve from 0.03027\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0318 - mean_absolute_error: 0.1388 - mean_squared_error: 0.0318 - val_loss: 0.0335 - val_mean_absolute_error: 0.1426 - val_mean_squared_error: 0.0335\n",
            "Epoch 461/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0329 - mean_absolute_error: 0.1411 - mean_squared_error: 0.0329\n",
            "Epoch 461: val_loss did not improve from 0.03027\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0328 - mean_absolute_error: 0.1409 - mean_squared_error: 0.0328 - val_loss: 0.0327 - val_mean_absolute_error: 0.1398 - val_mean_squared_error: 0.0327\n",
            "Epoch 462/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0320 - mean_absolute_error: 0.1395 - mean_squared_error: 0.0320\n",
            "Epoch 462: val_loss did not improve from 0.03027\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0321 - mean_absolute_error: 0.1398 - mean_squared_error: 0.0321 - val_loss: 0.0324 - val_mean_absolute_error: 0.1405 - val_mean_squared_error: 0.0324\n",
            "Epoch 463/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0319 - mean_absolute_error: 0.1386 - mean_squared_error: 0.0319\n",
            "Epoch 463: val_loss did not improve from 0.03027\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0320 - mean_absolute_error: 0.1387 - mean_squared_error: 0.0320 - val_loss: 0.0349 - val_mean_absolute_error: 0.1443 - val_mean_squared_error: 0.0349\n",
            "Epoch 464/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0316 - mean_absolute_error: 0.1379 - mean_squared_error: 0.0316\n",
            "Epoch 464: val_loss did not improve from 0.03027\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0312 - mean_absolute_error: 0.1371 - mean_squared_error: 0.0312 - val_loss: 0.0315 - val_mean_absolute_error: 0.1379 - val_mean_squared_error: 0.0315\n",
            "Epoch 465/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0315 - mean_absolute_error: 0.1380 - mean_squared_error: 0.0315\n",
            "Epoch 465: val_loss improved from 0.03027 to 0.02932, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0318 - mean_absolute_error: 0.1385 - mean_squared_error: 0.0318 - val_loss: 0.0293 - val_mean_absolute_error: 0.1332 - val_mean_squared_error: 0.0293\n",
            "Epoch 466/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0316 - mean_absolute_error: 0.1383 - mean_squared_error: 0.0316\n",
            "Epoch 466: val_loss did not improve from 0.02932\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0317 - mean_absolute_error: 0.1383 - mean_squared_error: 0.0317 - val_loss: 0.0320 - val_mean_absolute_error: 0.1394 - val_mean_squared_error: 0.0320\n",
            "Epoch 467/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0309 - mean_absolute_error: 0.1365 - mean_squared_error: 0.0309\n",
            "Epoch 467: val_loss improved from 0.02932 to 0.02931, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0306 - mean_absolute_error: 0.1358 - mean_squared_error: 0.0306 - val_loss: 0.0293 - val_mean_absolute_error: 0.1324 - val_mean_squared_error: 0.0293\n",
            "Epoch 468/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0317 - mean_absolute_error: 0.1385 - mean_squared_error: 0.0317\n",
            "Epoch 468: val_loss did not improve from 0.02931\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0317 - mean_absolute_error: 0.1383 - mean_squared_error: 0.0317 - val_loss: 0.0316 - val_mean_absolute_error: 0.1374 - val_mean_squared_error: 0.0316\n",
            "Epoch 469/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0308 - mean_absolute_error: 0.1366 - mean_squared_error: 0.0308\n",
            "Epoch 469: val_loss did not improve from 0.02931\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0308 - mean_absolute_error: 0.1367 - mean_squared_error: 0.0308 - val_loss: 0.0324 - val_mean_absolute_error: 0.1415 - val_mean_squared_error: 0.0324\n",
            "Epoch 470/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0318 - mean_absolute_error: 0.1392 - mean_squared_error: 0.0318\n",
            "Epoch 470: val_loss did not improve from 0.02931\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0318 - mean_absolute_error: 0.1392 - mean_squared_error: 0.0318 - val_loss: 0.0373 - val_mean_absolute_error: 0.1495 - val_mean_squared_error: 0.0373\n",
            "Epoch 471/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0307 - mean_absolute_error: 0.1367 - mean_squared_error: 0.0307\n",
            "Epoch 471: val_loss did not improve from 0.02931\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0309 - mean_absolute_error: 0.1372 - mean_squared_error: 0.0309 - val_loss: 0.0307 - val_mean_absolute_error: 0.1352 - val_mean_squared_error: 0.0307\n",
            "Epoch 472/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0318 - mean_absolute_error: 0.1381 - mean_squared_error: 0.0318\n",
            "Epoch 472: val_loss did not improve from 0.02931\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0315 - mean_absolute_error: 0.1374 - mean_squared_error: 0.0315 - val_loss: 0.0306 - val_mean_absolute_error: 0.1360 - val_mean_squared_error: 0.0306\n",
            "Epoch 473/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0300 - mean_absolute_error: 0.1354 - mean_squared_error: 0.0300\n",
            "Epoch 473: val_loss did not improve from 0.02931\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0302 - mean_absolute_error: 0.1356 - mean_squared_error: 0.0302 - val_loss: 0.0295 - val_mean_absolute_error: 0.1357 - val_mean_squared_error: 0.0295\n",
            "Epoch 474/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0310 - mean_absolute_error: 0.1363 - mean_squared_error: 0.0310\n",
            "Epoch 474: val_loss did not improve from 0.02931\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0309 - mean_absolute_error: 0.1362 - mean_squared_error: 0.0309 - val_loss: 0.0311 - val_mean_absolute_error: 0.1371 - val_mean_squared_error: 0.0311\n",
            "Epoch 475/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0309 - mean_absolute_error: 0.1369 - mean_squared_error: 0.0309\n",
            "Epoch 475: val_loss did not improve from 0.02931\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0309 - mean_absolute_error: 0.1368 - mean_squared_error: 0.0309 - val_loss: 0.0325 - val_mean_absolute_error: 0.1386 - val_mean_squared_error: 0.0325\n",
            "Epoch 476/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0294 - mean_absolute_error: 0.1332 - mean_squared_error: 0.0294\n",
            "Epoch 476: val_loss did not improve from 0.02931\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0295 - mean_absolute_error: 0.1333 - mean_squared_error: 0.0295 - val_loss: 0.0323 - val_mean_absolute_error: 0.1350 - val_mean_squared_error: 0.0323\n",
            "Epoch 477/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0303 - mean_absolute_error: 0.1344 - mean_squared_error: 0.0303\n",
            "Epoch 477: val_loss did not improve from 0.02931\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0302 - mean_absolute_error: 0.1343 - mean_squared_error: 0.0302 - val_loss: 0.0309 - val_mean_absolute_error: 0.1383 - val_mean_squared_error: 0.0309\n",
            "Epoch 478/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0305 - mean_absolute_error: 0.1369 - mean_squared_error: 0.0305\n",
            "Epoch 478: val_loss did not improve from 0.02931\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0305 - mean_absolute_error: 0.1369 - mean_squared_error: 0.0305 - val_loss: 0.0296 - val_mean_absolute_error: 0.1333 - val_mean_squared_error: 0.0296\n",
            "Epoch 479/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0288 - mean_absolute_error: 0.1321 - mean_squared_error: 0.0288\n",
            "Epoch 479: val_loss did not improve from 0.02931\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0287 - mean_absolute_error: 0.1319 - mean_squared_error: 0.0287 - val_loss: 0.0293 - val_mean_absolute_error: 0.1347 - val_mean_squared_error: 0.0293\n",
            "Epoch 480/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0297 - mean_absolute_error: 0.1344 - mean_squared_error: 0.0297\n",
            "Epoch 480: val_loss improved from 0.02931 to 0.02777, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0296 - mean_absolute_error: 0.1345 - mean_squared_error: 0.0296 - val_loss: 0.0278 - val_mean_absolute_error: 0.1297 - val_mean_squared_error: 0.0278\n",
            "Epoch 481/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0297 - mean_absolute_error: 0.1340 - mean_squared_error: 0.0297\n",
            "Epoch 481: val_loss did not improve from 0.02777\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0299 - mean_absolute_error: 0.1344 - mean_squared_error: 0.0299 - val_loss: 0.0360 - val_mean_absolute_error: 0.1468 - val_mean_squared_error: 0.0360\n",
            "Epoch 482/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0285 - mean_absolute_error: 0.1313 - mean_squared_error: 0.0285\n",
            "Epoch 482: val_loss did not improve from 0.02777\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0288 - mean_absolute_error: 0.1320 - mean_squared_error: 0.0288 - val_loss: 0.0305 - val_mean_absolute_error: 0.1338 - val_mean_squared_error: 0.0305\n",
            "Epoch 483/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.0300 - mean_absolute_error: 0.1347 - mean_squared_error: 0.0300\n",
            "Epoch 483: val_loss did not improve from 0.02777\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0302 - mean_absolute_error: 0.1354 - mean_squared_error: 0.0302 - val_loss: 0.0300 - val_mean_absolute_error: 0.1371 - val_mean_squared_error: 0.0300\n",
            "Epoch 484/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0292 - mean_absolute_error: 0.1338 - mean_squared_error: 0.0292\n",
            "Epoch 484: val_loss improved from 0.02777 to 0.02764, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0291 - mean_absolute_error: 0.1336 - mean_squared_error: 0.0291 - val_loss: 0.0276 - val_mean_absolute_error: 0.1289 - val_mean_squared_error: 0.0276\n",
            "Epoch 485/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0292 - mean_absolute_error: 0.1333 - mean_squared_error: 0.0292\n",
            "Epoch 485: val_loss did not improve from 0.02764\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0292 - mean_absolute_error: 0.1332 - mean_squared_error: 0.0292 - val_loss: 0.0346 - val_mean_absolute_error: 0.1473 - val_mean_squared_error: 0.0346\n",
            "Epoch 486/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0291 - mean_absolute_error: 0.1329 - mean_squared_error: 0.0291\n",
            "Epoch 486: val_loss did not improve from 0.02764\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0291 - mean_absolute_error: 0.1328 - mean_squared_error: 0.0291 - val_loss: 0.0287 - val_mean_absolute_error: 0.1293 - val_mean_squared_error: 0.0287\n",
            "Epoch 487/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0278 - mean_absolute_error: 0.1302 - mean_squared_error: 0.0278\n",
            "Epoch 487: val_loss improved from 0.02764 to 0.02696, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0277 - mean_absolute_error: 0.1300 - mean_squared_error: 0.0277 - val_loss: 0.0270 - val_mean_absolute_error: 0.1283 - val_mean_squared_error: 0.0270\n",
            "Epoch 488/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0287 - mean_absolute_error: 0.1327 - mean_squared_error: 0.0287\n",
            "Epoch 488: val_loss did not improve from 0.02696\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0286 - mean_absolute_error: 0.1326 - mean_squared_error: 0.0286 - val_loss: 0.0284 - val_mean_absolute_error: 0.1310 - val_mean_squared_error: 0.0284\n",
            "Epoch 489/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0280 - mean_absolute_error: 0.1295 - mean_squared_error: 0.0280\n",
            "Epoch 489: val_loss did not improve from 0.02696\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0284 - mean_absolute_error: 0.1305 - mean_squared_error: 0.0284 - val_loss: 0.0310 - val_mean_absolute_error: 0.1399 - val_mean_squared_error: 0.0310\n",
            "Epoch 490/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0283 - mean_absolute_error: 0.1307 - mean_squared_error: 0.0283\n",
            "Epoch 490: val_loss did not improve from 0.02696\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0282 - mean_absolute_error: 0.1305 - mean_squared_error: 0.0282 - val_loss: 0.0304 - val_mean_absolute_error: 0.1356 - val_mean_squared_error: 0.0304\n",
            "Epoch 491/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0289 - mean_absolute_error: 0.1322 - mean_squared_error: 0.0289\n",
            "Epoch 491: val_loss did not improve from 0.02696\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0287 - mean_absolute_error: 0.1315 - mean_squared_error: 0.0287 - val_loss: 0.0290 - val_mean_absolute_error: 0.1280 - val_mean_squared_error: 0.0290\n",
            "Epoch 492/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0284 - mean_absolute_error: 0.1319 - mean_squared_error: 0.0284\n",
            "Epoch 492: val_loss did not improve from 0.02696\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0284 - mean_absolute_error: 0.1319 - mean_squared_error: 0.0284 - val_loss: 0.0281 - val_mean_absolute_error: 0.1300 - val_mean_squared_error: 0.0281\n",
            "Epoch 493/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0286 - mean_absolute_error: 0.1321 - mean_squared_error: 0.0286\n",
            "Epoch 493: val_loss did not improve from 0.02696\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0284 - mean_absolute_error: 0.1314 - mean_squared_error: 0.0284 - val_loss: 0.0273 - val_mean_absolute_error: 0.1295 - val_mean_squared_error: 0.0273\n",
            "Epoch 494/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.0287 - mean_absolute_error: 0.1317 - mean_squared_error: 0.0287\n",
            "Epoch 494: val_loss improved from 0.02696 to 0.02666, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0286 - mean_absolute_error: 0.1317 - mean_squared_error: 0.0286 - val_loss: 0.0267 - val_mean_absolute_error: 0.1263 - val_mean_squared_error: 0.0267\n",
            "Epoch 495/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0270 - mean_absolute_error: 0.1273 - mean_squared_error: 0.0270\n",
            "Epoch 495: val_loss did not improve from 0.02666\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0272 - mean_absolute_error: 0.1276 - mean_squared_error: 0.0272 - val_loss: 0.0292 - val_mean_absolute_error: 0.1295 - val_mean_squared_error: 0.0292\n",
            "Epoch 496/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0273 - mean_absolute_error: 0.1288 - mean_squared_error: 0.0273\n",
            "Epoch 496: val_loss did not improve from 0.02666\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0272 - mean_absolute_error: 0.1285 - mean_squared_error: 0.0272 - val_loss: 0.0277 - val_mean_absolute_error: 0.1297 - val_mean_squared_error: 0.0277\n",
            "Epoch 497/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0276 - mean_absolute_error: 0.1299 - mean_squared_error: 0.0276\n",
            "Epoch 497: val_loss improved from 0.02666 to 0.02664, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0277 - mean_absolute_error: 0.1299 - mean_squared_error: 0.0277 - val_loss: 0.0266 - val_mean_absolute_error: 0.1260 - val_mean_squared_error: 0.0266\n",
            "Epoch 498/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0275 - mean_absolute_error: 0.1289 - mean_squared_error: 0.0275\n",
            "Epoch 498: val_loss improved from 0.02664 to 0.02659, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0274 - mean_absolute_error: 0.1288 - mean_squared_error: 0.0274 - val_loss: 0.0266 - val_mean_absolute_error: 0.1280 - val_mean_squared_error: 0.0266\n",
            "Epoch 499/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0266 - mean_absolute_error: 0.1269 - mean_squared_error: 0.0266\n",
            "Epoch 499: val_loss did not improve from 0.02659\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0266 - mean_absolute_error: 0.1269 - mean_squared_error: 0.0266 - val_loss: 0.0295 - val_mean_absolute_error: 0.1352 - val_mean_squared_error: 0.0295\n",
            "Epoch 500/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0273 - mean_absolute_error: 0.1285 - mean_squared_error: 0.0273\n",
            "Epoch 500: val_loss improved from 0.02659 to 0.02590, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0272 - mean_absolute_error: 0.1280 - mean_squared_error: 0.0272 - val_loss: 0.0259 - val_mean_absolute_error: 0.1242 - val_mean_squared_error: 0.0259\n",
            "Epoch 501/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0267 - mean_absolute_error: 0.1277 - mean_squared_error: 0.0267\n",
            "Epoch 501: val_loss did not improve from 0.02590\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0268 - mean_absolute_error: 0.1280 - mean_squared_error: 0.0268 - val_loss: 0.0263 - val_mean_absolute_error: 0.1251 - val_mean_squared_error: 0.0263\n",
            "Epoch 502/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0274 - mean_absolute_error: 0.1280 - mean_squared_error: 0.0274\n",
            "Epoch 502: val_loss did not improve from 0.02590\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0272 - mean_absolute_error: 0.1275 - mean_squared_error: 0.0272 - val_loss: 0.0301 - val_mean_absolute_error: 0.1322 - val_mean_squared_error: 0.0301\n",
            "Epoch 503/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0269 - mean_absolute_error: 0.1276 - mean_squared_error: 0.0269\n",
            "Epoch 503: val_loss did not improve from 0.02590\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0270 - mean_absolute_error: 0.1276 - mean_squared_error: 0.0270 - val_loss: 0.0262 - val_mean_absolute_error: 0.1247 - val_mean_squared_error: 0.0262\n",
            "Epoch 504/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0267 - mean_absolute_error: 0.1265 - mean_squared_error: 0.0267\n",
            "Epoch 504: val_loss did not improve from 0.02590\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0267 - mean_absolute_error: 0.1265 - mean_squared_error: 0.0267 - val_loss: 0.0309 - val_mean_absolute_error: 0.1340 - val_mean_squared_error: 0.0309\n",
            "Epoch 505/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.0273 - mean_absolute_error: 0.1288 - mean_squared_error: 0.0273\n",
            "Epoch 505: val_loss did not improve from 0.02590\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0273 - mean_absolute_error: 0.1286 - mean_squared_error: 0.0273 - val_loss: 0.0270 - val_mean_absolute_error: 0.1266 - val_mean_squared_error: 0.0270\n",
            "Epoch 506/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0265 - mean_absolute_error: 0.1262 - mean_squared_error: 0.0265\n",
            "Epoch 506: val_loss did not improve from 0.02590\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0266 - mean_absolute_error: 0.1263 - mean_squared_error: 0.0266 - val_loss: 0.0332 - val_mean_absolute_error: 0.1404 - val_mean_squared_error: 0.0332\n",
            "Epoch 507/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0264 - mean_absolute_error: 0.1269 - mean_squared_error: 0.0264\n",
            "Epoch 507: val_loss did not improve from 0.02590\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0265 - mean_absolute_error: 0.1272 - mean_squared_error: 0.0265 - val_loss: 0.0273 - val_mean_absolute_error: 0.1302 - val_mean_squared_error: 0.0273\n",
            "Epoch 508/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0253 - mean_absolute_error: 0.1237 - mean_squared_error: 0.0253\n",
            "Epoch 508: val_loss did not improve from 0.02590\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0254 - mean_absolute_error: 0.1237 - mean_squared_error: 0.0254 - val_loss: 0.0343 - val_mean_absolute_error: 0.1431 - val_mean_squared_error: 0.0343\n",
            "Epoch 509/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0260 - mean_absolute_error: 0.1257 - mean_squared_error: 0.0260\n",
            "Epoch 509: val_loss did not improve from 0.02590\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0260 - mean_absolute_error: 0.1257 - mean_squared_error: 0.0260 - val_loss: 0.0314 - val_mean_absolute_error: 0.1389 - val_mean_squared_error: 0.0314\n",
            "Epoch 510/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0258 - mean_absolute_error: 0.1229 - mean_squared_error: 0.0258\n",
            "Epoch 510: val_loss improved from 0.02590 to 0.02511, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0260 - mean_absolute_error: 0.1234 - mean_squared_error: 0.0260 - val_loss: 0.0251 - val_mean_absolute_error: 0.1214 - val_mean_squared_error: 0.0251\n",
            "Epoch 511/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0260 - mean_absolute_error: 0.1252 - mean_squared_error: 0.0260\n",
            "Epoch 511: val_loss did not improve from 0.02511\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0260 - mean_absolute_error: 0.1249 - mean_squared_error: 0.0260 - val_loss: 0.0300 - val_mean_absolute_error: 0.1307 - val_mean_squared_error: 0.0300\n",
            "Epoch 512/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.0256 - mean_absolute_error: 0.1240 - mean_squared_error: 0.0256\n",
            "Epoch 512: val_loss improved from 0.02511 to 0.02347, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0255 - mean_absolute_error: 0.1239 - mean_squared_error: 0.0255 - val_loss: 0.0235 - val_mean_absolute_error: 0.1196 - val_mean_squared_error: 0.0235\n",
            "Epoch 513/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0255 - mean_absolute_error: 0.1242 - mean_squared_error: 0.0255\n",
            "Epoch 513: val_loss did not improve from 0.02347\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0256 - mean_absolute_error: 0.1246 - mean_squared_error: 0.0256 - val_loss: 0.0278 - val_mean_absolute_error: 0.1321 - val_mean_squared_error: 0.0278\n",
            "Epoch 514/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.0263 - mean_absolute_error: 0.1259 - mean_squared_error: 0.0263\n",
            "Epoch 514: val_loss did not improve from 0.02347\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0263 - mean_absolute_error: 0.1257 - mean_squared_error: 0.0263 - val_loss: 0.0274 - val_mean_absolute_error: 0.1278 - val_mean_squared_error: 0.0274\n",
            "Epoch 515/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0255 - mean_absolute_error: 0.1233 - mean_squared_error: 0.0255\n",
            "Epoch 515: val_loss did not improve from 0.02347\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0254 - mean_absolute_error: 0.1230 - mean_squared_error: 0.0254 - val_loss: 0.0245 - val_mean_absolute_error: 0.1210 - val_mean_squared_error: 0.0245\n",
            "Epoch 516/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0254 - mean_absolute_error: 0.1243 - mean_squared_error: 0.0254\n",
            "Epoch 516: val_loss did not improve from 0.02347\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0254 - mean_absolute_error: 0.1241 - mean_squared_error: 0.0254 - val_loss: 0.0250 - val_mean_absolute_error: 0.1227 - val_mean_squared_error: 0.0250\n",
            "Epoch 517/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0253 - mean_absolute_error: 0.1228 - mean_squared_error: 0.0253\n",
            "Epoch 517: val_loss did not improve from 0.02347\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0252 - mean_absolute_error: 0.1224 - mean_squared_error: 0.0252 - val_loss: 0.0276 - val_mean_absolute_error: 0.1270 - val_mean_squared_error: 0.0276\n",
            "Epoch 518/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.0252 - mean_absolute_error: 0.1230 - mean_squared_error: 0.0252\n",
            "Epoch 518: val_loss did not improve from 0.02347\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0253 - mean_absolute_error: 0.1230 - mean_squared_error: 0.0253 - val_loss: 0.0265 - val_mean_absolute_error: 0.1262 - val_mean_squared_error: 0.0265\n",
            "Epoch 519/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0253 - mean_absolute_error: 0.1238 - mean_squared_error: 0.0253\n",
            "Epoch 519: val_loss did not improve from 0.02347\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0252 - mean_absolute_error: 0.1233 - mean_squared_error: 0.0252 - val_loss: 0.0291 - val_mean_absolute_error: 0.1301 - val_mean_squared_error: 0.0291\n",
            "Epoch 520/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0250 - mean_absolute_error: 0.1226 - mean_squared_error: 0.0250\n",
            "Epoch 520: val_loss did not improve from 0.02347\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0249 - mean_absolute_error: 0.1226 - mean_squared_error: 0.0249 - val_loss: 0.0242 - val_mean_absolute_error: 0.1203 - val_mean_squared_error: 0.0242\n",
            "Epoch 521/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0252 - mean_absolute_error: 0.1232 - mean_squared_error: 0.0252\n",
            "Epoch 521: val_loss did not improve from 0.02347\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0252 - mean_absolute_error: 0.1232 - mean_squared_error: 0.0252 - val_loss: 0.0394 - val_mean_absolute_error: 0.1547 - val_mean_squared_error: 0.0394\n",
            "Epoch 522/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0255 - mean_absolute_error: 0.1238 - mean_squared_error: 0.0255\n",
            "Epoch 522: val_loss did not improve from 0.02347\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0255 - mean_absolute_error: 0.1236 - mean_squared_error: 0.0255 - val_loss: 0.0263 - val_mean_absolute_error: 0.1238 - val_mean_squared_error: 0.0263\n",
            "Epoch 523/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0245 - mean_absolute_error: 0.1215 - mean_squared_error: 0.0245\n",
            "Epoch 523: val_loss did not improve from 0.02347\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0245 - mean_absolute_error: 0.1215 - mean_squared_error: 0.0245 - val_loss: 0.0243 - val_mean_absolute_error: 0.1203 - val_mean_squared_error: 0.0243\n",
            "Epoch 524/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0247 - mean_absolute_error: 0.1224 - mean_squared_error: 0.0247\n",
            "Epoch 524: val_loss did not improve from 0.02347\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0249 - mean_absolute_error: 0.1226 - mean_squared_error: 0.0249 - val_loss: 0.0276 - val_mean_absolute_error: 0.1321 - val_mean_squared_error: 0.0276\n",
            "Epoch 525/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0242 - mean_absolute_error: 0.1212 - mean_squared_error: 0.0242\n",
            "Epoch 525: val_loss did not improve from 0.02347\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0242 - mean_absolute_error: 0.1211 - mean_squared_error: 0.0242 - val_loss: 0.0253 - val_mean_absolute_error: 0.1245 - val_mean_squared_error: 0.0253\n",
            "Epoch 526/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0240 - mean_absolute_error: 0.1190 - mean_squared_error: 0.0240\n",
            "Epoch 526: val_loss improved from 0.02347 to 0.02284, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0239 - mean_absolute_error: 0.1187 - mean_squared_error: 0.0239 - val_loss: 0.0228 - val_mean_absolute_error: 0.1171 - val_mean_squared_error: 0.0228\n",
            "Epoch 527/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.0238 - mean_absolute_error: 0.1188 - mean_squared_error: 0.0238\n",
            "Epoch 527: val_loss did not improve from 0.02284\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0240 - mean_absolute_error: 0.1192 - mean_squared_error: 0.0240 - val_loss: 0.0238 - val_mean_absolute_error: 0.1191 - val_mean_squared_error: 0.0238\n",
            "Epoch 528/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0248 - mean_absolute_error: 0.1215 - mean_squared_error: 0.0248\n",
            "Epoch 528: val_loss did not improve from 0.02284\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0246 - mean_absolute_error: 0.1209 - mean_squared_error: 0.0246 - val_loss: 0.0259 - val_mean_absolute_error: 0.1216 - val_mean_squared_error: 0.0259\n",
            "Epoch 529/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0237 - mean_absolute_error: 0.1188 - mean_squared_error: 0.0237\n",
            "Epoch 529: val_loss did not improve from 0.02284\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0237 - mean_absolute_error: 0.1186 - mean_squared_error: 0.0237 - val_loss: 0.0282 - val_mean_absolute_error: 0.1282 - val_mean_squared_error: 0.0282\n",
            "Epoch 530/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0240 - mean_absolute_error: 0.1200 - mean_squared_error: 0.0240\n",
            "Epoch 530: val_loss did not improve from 0.02284\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0241 - mean_absolute_error: 0.1202 - mean_squared_error: 0.0241 - val_loss: 0.0245 - val_mean_absolute_error: 0.1223 - val_mean_squared_error: 0.0245\n",
            "Epoch 531/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0245 - mean_absolute_error: 0.1213 - mean_squared_error: 0.0245\n",
            "Epoch 531: val_loss improved from 0.02284 to 0.02258, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0246 - mean_absolute_error: 0.1215 - mean_squared_error: 0.0246 - val_loss: 0.0226 - val_mean_absolute_error: 0.1141 - val_mean_squared_error: 0.0226\n",
            "Epoch 532/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0232 - mean_absolute_error: 0.1186 - mean_squared_error: 0.0232\n",
            "Epoch 532: val_loss did not improve from 0.02258\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0232 - mean_absolute_error: 0.1186 - mean_squared_error: 0.0232 - val_loss: 0.0235 - val_mean_absolute_error: 0.1186 - val_mean_squared_error: 0.0235\n",
            "Epoch 533/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0240 - mean_absolute_error: 0.1202 - mean_squared_error: 0.0240\n",
            "Epoch 533: val_loss did not improve from 0.02258\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0241 - mean_absolute_error: 0.1204 - mean_squared_error: 0.0241 - val_loss: 0.0237 - val_mean_absolute_error: 0.1185 - val_mean_squared_error: 0.0237\n",
            "Epoch 534/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0245 - mean_absolute_error: 0.1210 - mean_squared_error: 0.0245\n",
            "Epoch 534: val_loss did not improve from 0.02258\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0245 - mean_absolute_error: 0.1209 - mean_squared_error: 0.0245 - val_loss: 0.0241 - val_mean_absolute_error: 0.1195 - val_mean_squared_error: 0.0241\n",
            "Epoch 535/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0228 - mean_absolute_error: 0.1168 - mean_squared_error: 0.0228\n",
            "Epoch 535: val_loss did not improve from 0.02258\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0229 - mean_absolute_error: 0.1170 - mean_squared_error: 0.0229 - val_loss: 0.0236 - val_mean_absolute_error: 0.1187 - val_mean_squared_error: 0.0236\n",
            "Epoch 536/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.0239 - mean_absolute_error: 0.1194 - mean_squared_error: 0.0239\n",
            "Epoch 536: val_loss did not improve from 0.02258\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0241 - mean_absolute_error: 0.1202 - mean_squared_error: 0.0241 - val_loss: 0.0245 - val_mean_absolute_error: 0.1206 - val_mean_squared_error: 0.0245\n",
            "Epoch 537/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0233 - mean_absolute_error: 0.1181 - mean_squared_error: 0.0233\n",
            "Epoch 537: val_loss did not improve from 0.02258\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0233 - mean_absolute_error: 0.1181 - mean_squared_error: 0.0233 - val_loss: 0.0230 - val_mean_absolute_error: 0.1171 - val_mean_squared_error: 0.0230\n",
            "Epoch 538/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0228 - mean_absolute_error: 0.1169 - mean_squared_error: 0.0228\n",
            "Epoch 538: val_loss did not improve from 0.02258\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0230 - mean_absolute_error: 0.1172 - mean_squared_error: 0.0230 - val_loss: 0.0252 - val_mean_absolute_error: 0.1225 - val_mean_squared_error: 0.0252\n",
            "Epoch 539/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0235 - mean_absolute_error: 0.1187 - mean_squared_error: 0.0235\n",
            "Epoch 539: val_loss did not improve from 0.02258\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0234 - mean_absolute_error: 0.1185 - mean_squared_error: 0.0234 - val_loss: 0.0230 - val_mean_absolute_error: 0.1189 - val_mean_squared_error: 0.0230\n",
            "Epoch 540/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0239 - mean_absolute_error: 0.1192 - mean_squared_error: 0.0239\n",
            "Epoch 540: val_loss did not improve from 0.02258\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0238 - mean_absolute_error: 0.1188 - mean_squared_error: 0.0238 - val_loss: 0.0250 - val_mean_absolute_error: 0.1203 - val_mean_squared_error: 0.0250\n",
            "Epoch 541/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.0229 - mean_absolute_error: 0.1168 - mean_squared_error: 0.0229\n",
            "Epoch 541: val_loss improved from 0.02258 to 0.02192, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0229 - mean_absolute_error: 0.1169 - mean_squared_error: 0.0229 - val_loss: 0.0219 - val_mean_absolute_error: 0.1166 - val_mean_squared_error: 0.0219\n",
            "Epoch 542/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0232 - mean_absolute_error: 0.1174 - mean_squared_error: 0.0232\n",
            "Epoch 542: val_loss improved from 0.02192 to 0.02162, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0231 - mean_absolute_error: 0.1170 - mean_squared_error: 0.0231 - val_loss: 0.0216 - val_mean_absolute_error: 0.1135 - val_mean_squared_error: 0.0216\n",
            "Epoch 543/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0233 - mean_absolute_error: 0.1183 - mean_squared_error: 0.0233\n",
            "Epoch 543: val_loss did not improve from 0.02162\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0232 - mean_absolute_error: 0.1179 - mean_squared_error: 0.0232 - val_loss: 0.0233 - val_mean_absolute_error: 0.1176 - val_mean_squared_error: 0.0233\n",
            "Epoch 544/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0229 - mean_absolute_error: 0.1163 - mean_squared_error: 0.0229\n",
            "Epoch 544: val_loss did not improve from 0.02162\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0230 - mean_absolute_error: 0.1166 - mean_squared_error: 0.0230 - val_loss: 0.0225 - val_mean_absolute_error: 0.1177 - val_mean_squared_error: 0.0225\n",
            "Epoch 545/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0239 - mean_absolute_error: 0.1191 - mean_squared_error: 0.0239\n",
            "Epoch 545: val_loss did not improve from 0.02162\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0237 - mean_absolute_error: 0.1189 - mean_squared_error: 0.0237 - val_loss: 0.0233 - val_mean_absolute_error: 0.1190 - val_mean_squared_error: 0.0233\n",
            "Epoch 546/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0225 - mean_absolute_error: 0.1157 - mean_squared_error: 0.0225\n",
            "Epoch 546: val_loss did not improve from 0.02162\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0223 - mean_absolute_error: 0.1149 - mean_squared_error: 0.0223 - val_loss: 0.0263 - val_mean_absolute_error: 0.1203 - val_mean_squared_error: 0.0263\n",
            "Epoch 547/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0227 - mean_absolute_error: 0.1157 - mean_squared_error: 0.0227\n",
            "Epoch 547: val_loss improved from 0.02162 to 0.02127, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0227 - mean_absolute_error: 0.1157 - mean_squared_error: 0.0227 - val_loss: 0.0213 - val_mean_absolute_error: 0.1124 - val_mean_squared_error: 0.0213\n",
            "Epoch 548/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0223 - mean_absolute_error: 0.1152 - mean_squared_error: 0.0223\n",
            "Epoch 548: val_loss did not improve from 0.02127\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0223 - mean_absolute_error: 0.1152 - mean_squared_error: 0.0223 - val_loss: 0.0281 - val_mean_absolute_error: 0.1277 - val_mean_squared_error: 0.0281\n",
            "Epoch 549/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0224 - mean_absolute_error: 0.1150 - mean_squared_error: 0.0224\n",
            "Epoch 549: val_loss did not improve from 0.02127\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0225 - mean_absolute_error: 0.1152 - mean_squared_error: 0.0225 - val_loss: 0.0229 - val_mean_absolute_error: 0.1151 - val_mean_squared_error: 0.0229\n",
            "Epoch 550/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0221 - mean_absolute_error: 0.1143 - mean_squared_error: 0.0221\n",
            "Epoch 550: val_loss did not improve from 0.02127\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0220 - mean_absolute_error: 0.1144 - mean_squared_error: 0.0220 - val_loss: 0.0220 - val_mean_absolute_error: 0.1150 - val_mean_squared_error: 0.0220\n",
            "Epoch 551/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0224 - mean_absolute_error: 0.1149 - mean_squared_error: 0.0224\n",
            "Epoch 551: val_loss did not improve from 0.02127\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0223 - mean_absolute_error: 0.1150 - mean_squared_error: 0.0223 - val_loss: 0.0225 - val_mean_absolute_error: 0.1173 - val_mean_squared_error: 0.0225\n",
            "Epoch 552/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0234 - mean_absolute_error: 0.1177 - mean_squared_error: 0.0234\n",
            "Epoch 552: val_loss did not improve from 0.02127\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0235 - mean_absolute_error: 0.1178 - mean_squared_error: 0.0235 - val_loss: 0.0220 - val_mean_absolute_error: 0.1121 - val_mean_squared_error: 0.0220\n",
            "Epoch 553/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0220 - mean_absolute_error: 0.1141 - mean_squared_error: 0.0220\n",
            "Epoch 553: val_loss did not improve from 0.02127\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0221 - mean_absolute_error: 0.1143 - mean_squared_error: 0.0221 - val_loss: 0.0213 - val_mean_absolute_error: 0.1136 - val_mean_squared_error: 0.0213\n",
            "Epoch 554/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0223 - mean_absolute_error: 0.1152 - mean_squared_error: 0.0223\n",
            "Epoch 554: val_loss improved from 0.02127 to 0.02075, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0224 - mean_absolute_error: 0.1154 - mean_squared_error: 0.0224 - val_loss: 0.0208 - val_mean_absolute_error: 0.1093 - val_mean_squared_error: 0.0208\n",
            "Epoch 555/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.0223 - mean_absolute_error: 0.1150 - mean_squared_error: 0.0223\n",
            "Epoch 555: val_loss did not improve from 0.02075\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0222 - mean_absolute_error: 0.1147 - mean_squared_error: 0.0222 - val_loss: 0.0215 - val_mean_absolute_error: 0.1137 - val_mean_squared_error: 0.0215\n",
            "Epoch 556/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0222 - mean_absolute_error: 0.1155 - mean_squared_error: 0.0222\n",
            "Epoch 556: val_loss did not improve from 0.02075\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0221 - mean_absolute_error: 0.1154 - mean_squared_error: 0.0221 - val_loss: 0.0232 - val_mean_absolute_error: 0.1178 - val_mean_squared_error: 0.0232\n",
            "Epoch 557/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0221 - mean_absolute_error: 0.1143 - mean_squared_error: 0.0221\n",
            "Epoch 557: val_loss did not improve from 0.02075\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0221 - mean_absolute_error: 0.1145 - mean_squared_error: 0.0221 - val_loss: 0.0236 - val_mean_absolute_error: 0.1205 - val_mean_squared_error: 0.0236\n",
            "Epoch 558/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0226 - mean_absolute_error: 0.1159 - mean_squared_error: 0.0226\n",
            "Epoch 558: val_loss improved from 0.02075 to 0.02061, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0226 - mean_absolute_error: 0.1158 - mean_squared_error: 0.0226 - val_loss: 0.0206 - val_mean_absolute_error: 0.1099 - val_mean_squared_error: 0.0206\n",
            "Epoch 559/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0217 - mean_absolute_error: 0.1131 - mean_squared_error: 0.0217\n",
            "Epoch 559: val_loss improved from 0.02061 to 0.02049, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0218 - mean_absolute_error: 0.1133 - mean_squared_error: 0.0218 - val_loss: 0.0205 - val_mean_absolute_error: 0.1105 - val_mean_squared_error: 0.0205\n",
            "Epoch 560/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0221 - mean_absolute_error: 0.1149 - mean_squared_error: 0.0221\n",
            "Epoch 560: val_loss did not improve from 0.02049\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0220 - mean_absolute_error: 0.1149 - mean_squared_error: 0.0220 - val_loss: 0.0263 - val_mean_absolute_error: 0.1263 - val_mean_squared_error: 0.0263\n",
            "Epoch 561/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0220 - mean_absolute_error: 0.1146 - mean_squared_error: 0.0220\n",
            "Epoch 561: val_loss improved from 0.02049 to 0.02032, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0220 - mean_absolute_error: 0.1146 - mean_squared_error: 0.0220 - val_loss: 0.0203 - val_mean_absolute_error: 0.1103 - val_mean_squared_error: 0.0203\n",
            "Epoch 562/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0215 - mean_absolute_error: 0.1134 - mean_squared_error: 0.0215\n",
            "Epoch 562: val_loss did not improve from 0.02032\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0214 - mean_absolute_error: 0.1131 - mean_squared_error: 0.0214 - val_loss: 0.0214 - val_mean_absolute_error: 0.1112 - val_mean_squared_error: 0.0214\n",
            "Epoch 563/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.0215 - mean_absolute_error: 0.1129 - mean_squared_error: 0.0215\n",
            "Epoch 563: val_loss did not improve from 0.02032\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0215 - mean_absolute_error: 0.1128 - mean_squared_error: 0.0215 - val_loss: 0.0255 - val_mean_absolute_error: 0.1217 - val_mean_squared_error: 0.0255\n",
            "Epoch 564/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0218 - mean_absolute_error: 0.1134 - mean_squared_error: 0.0218\n",
            "Epoch 564: val_loss did not improve from 0.02032\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0218 - mean_absolute_error: 0.1134 - mean_squared_error: 0.0218 - val_loss: 0.0229 - val_mean_absolute_error: 0.1155 - val_mean_squared_error: 0.0229\n",
            "Epoch 565/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0218 - mean_absolute_error: 0.1134 - mean_squared_error: 0.0218\n",
            "Epoch 565: val_loss did not improve from 0.02032\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0216 - mean_absolute_error: 0.1131 - mean_squared_error: 0.0216 - val_loss: 0.0211 - val_mean_absolute_error: 0.1124 - val_mean_squared_error: 0.0211\n",
            "Epoch 566/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0216 - mean_absolute_error: 0.1127 - mean_squared_error: 0.0216\n",
            "Epoch 566: val_loss improved from 0.02032 to 0.02020, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0215 - mean_absolute_error: 0.1128 - mean_squared_error: 0.0215 - val_loss: 0.0202 - val_mean_absolute_error: 0.1083 - val_mean_squared_error: 0.0202\n",
            "Epoch 567/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0223 - mean_absolute_error: 0.1145 - mean_squared_error: 0.0223\n",
            "Epoch 567: val_loss improved from 0.02020 to 0.02015, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0223 - mean_absolute_error: 0.1146 - mean_squared_error: 0.0223 - val_loss: 0.0202 - val_mean_absolute_error: 0.1090 - val_mean_squared_error: 0.0202\n",
            "Epoch 568/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0213 - mean_absolute_error: 0.1120 - mean_squared_error: 0.0213\n",
            "Epoch 568: val_loss did not improve from 0.02015\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0213 - mean_absolute_error: 0.1120 - mean_squared_error: 0.0213 - val_loss: 0.0227 - val_mean_absolute_error: 0.1162 - val_mean_squared_error: 0.0227\n",
            "Epoch 569/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.0220 - mean_absolute_error: 0.1137 - mean_squared_error: 0.0220\n",
            "Epoch 569: val_loss did not improve from 0.02015\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0217 - mean_absolute_error: 0.1131 - mean_squared_error: 0.0217 - val_loss: 0.0216 - val_mean_absolute_error: 0.1141 - val_mean_squared_error: 0.0216\n",
            "Epoch 570/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0216 - mean_absolute_error: 0.1129 - mean_squared_error: 0.0216\n",
            "Epoch 570: val_loss improved from 0.02015 to 0.01949, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0216 - mean_absolute_error: 0.1129 - mean_squared_error: 0.0216 - val_loss: 0.0195 - val_mean_absolute_error: 0.1079 - val_mean_squared_error: 0.0195\n",
            "Epoch 571/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0210 - mean_absolute_error: 0.1111 - mean_squared_error: 0.0210\n",
            "Epoch 571: val_loss did not improve from 0.01949\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0210 - mean_absolute_error: 0.1111 - mean_squared_error: 0.0210 - val_loss: 0.0199 - val_mean_absolute_error: 0.1099 - val_mean_squared_error: 0.0199\n",
            "Epoch 572/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0205 - mean_absolute_error: 0.1097 - mean_squared_error: 0.0205\n",
            "Epoch 572: val_loss did not improve from 0.01949\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0208 - mean_absolute_error: 0.1103 - mean_squared_error: 0.0208 - val_loss: 0.0204 - val_mean_absolute_error: 0.1090 - val_mean_squared_error: 0.0204\n",
            "Epoch 573/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0210 - mean_absolute_error: 0.1112 - mean_squared_error: 0.0210\n",
            "Epoch 573: val_loss did not improve from 0.01949\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0209 - mean_absolute_error: 0.1110 - mean_squared_error: 0.0209 - val_loss: 0.0221 - val_mean_absolute_error: 0.1110 - val_mean_squared_error: 0.0221\n",
            "Epoch 574/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0207 - mean_absolute_error: 0.1100 - mean_squared_error: 0.0207\n",
            "Epoch 574: val_loss did not improve from 0.01949\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0206 - mean_absolute_error: 0.1096 - mean_squared_error: 0.0206 - val_loss: 0.0205 - val_mean_absolute_error: 0.1088 - val_mean_squared_error: 0.0205\n",
            "Epoch 575/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0202 - mean_absolute_error: 0.1086 - mean_squared_error: 0.0202\n",
            "Epoch 575: val_loss improved from 0.01949 to 0.01935, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0203 - mean_absolute_error: 0.1087 - mean_squared_error: 0.0203 - val_loss: 0.0194 - val_mean_absolute_error: 0.1083 - val_mean_squared_error: 0.0194\n",
            "Epoch 576/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0214 - mean_absolute_error: 0.1125 - mean_squared_error: 0.0214\n",
            "Epoch 576: val_loss improved from 0.01935 to 0.01930, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0213 - mean_absolute_error: 0.1123 - mean_squared_error: 0.0213 - val_loss: 0.0193 - val_mean_absolute_error: 0.1068 - val_mean_squared_error: 0.0193\n",
            "Epoch 577/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0212 - mean_absolute_error: 0.1114 - mean_squared_error: 0.0212\n",
            "Epoch 577: val_loss did not improve from 0.01930\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0211 - mean_absolute_error: 0.1114 - mean_squared_error: 0.0211 - val_loss: 0.0212 - val_mean_absolute_error: 0.1128 - val_mean_squared_error: 0.0212\n",
            "Epoch 578/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0205 - mean_absolute_error: 0.1097 - mean_squared_error: 0.0205\n",
            "Epoch 578: val_loss did not improve from 0.01930\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0206 - mean_absolute_error: 0.1100 - mean_squared_error: 0.0206 - val_loss: 0.0208 - val_mean_absolute_error: 0.1114 - val_mean_squared_error: 0.0208\n",
            "Epoch 579/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0208 - mean_absolute_error: 0.1103 - mean_squared_error: 0.0208\n",
            "Epoch 579: val_loss did not improve from 0.01930\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0209 - mean_absolute_error: 0.1100 - mean_squared_error: 0.0209 - val_loss: 0.0220 - val_mean_absolute_error: 0.1139 - val_mean_squared_error: 0.0220\n",
            "Epoch 580/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0203 - mean_absolute_error: 0.1092 - mean_squared_error: 0.0203\n",
            "Epoch 580: val_loss did not improve from 0.01930\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0207 - mean_absolute_error: 0.1101 - mean_squared_error: 0.0207 - val_loss: 0.0209 - val_mean_absolute_error: 0.1094 - val_mean_squared_error: 0.0209\n",
            "Epoch 581/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.0210 - mean_absolute_error: 0.1111 - mean_squared_error: 0.0210\n",
            "Epoch 581: val_loss did not improve from 0.01930\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0211 - mean_absolute_error: 0.1113 - mean_squared_error: 0.0211 - val_loss: 0.0236 - val_mean_absolute_error: 0.1177 - val_mean_squared_error: 0.0236\n",
            "Epoch 582/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.0203 - mean_absolute_error: 0.1093 - mean_squared_error: 0.0203\n",
            "Epoch 582: val_loss did not improve from 0.01930\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0203 - mean_absolute_error: 0.1093 - mean_squared_error: 0.0203 - val_loss: 0.0204 - val_mean_absolute_error: 0.1111 - val_mean_squared_error: 0.0204\n",
            "Epoch 583/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0196 - mean_absolute_error: 0.1073 - mean_squared_error: 0.0196\n",
            "Epoch 583: val_loss did not improve from 0.01930\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0196 - mean_absolute_error: 0.1073 - mean_squared_error: 0.0196 - val_loss: 0.0203 - val_mean_absolute_error: 0.1069 - val_mean_squared_error: 0.0203\n",
            "Epoch 584/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0206 - mean_absolute_error: 0.1102 - mean_squared_error: 0.0206\n",
            "Epoch 584: val_loss did not improve from 0.01930\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0207 - mean_absolute_error: 0.1105 - mean_squared_error: 0.0207 - val_loss: 0.0221 - val_mean_absolute_error: 0.1161 - val_mean_squared_error: 0.0221\n",
            "Epoch 585/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0199 - mean_absolute_error: 0.1073 - mean_squared_error: 0.0199\n",
            "Epoch 585: val_loss did not improve from 0.01930\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0199 - mean_absolute_error: 0.1074 - mean_squared_error: 0.0199 - val_loss: 0.0201 - val_mean_absolute_error: 0.1086 - val_mean_squared_error: 0.0201\n",
            "Epoch 586/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0204 - mean_absolute_error: 0.1097 - mean_squared_error: 0.0204\n",
            "Epoch 586: val_loss did not improve from 0.01930\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0204 - mean_absolute_error: 0.1098 - mean_squared_error: 0.0204 - val_loss: 0.0209 - val_mean_absolute_error: 0.1113 - val_mean_squared_error: 0.0209\n",
            "Epoch 587/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0201 - mean_absolute_error: 0.1090 - mean_squared_error: 0.0201\n",
            "Epoch 587: val_loss did not improve from 0.01930\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0202 - mean_absolute_error: 0.1092 - mean_squared_error: 0.0202 - val_loss: 0.0207 - val_mean_absolute_error: 0.1092 - val_mean_squared_error: 0.0207\n",
            "Epoch 588/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0196 - mean_absolute_error: 0.1073 - mean_squared_error: 0.0196\n",
            "Epoch 588: val_loss did not improve from 0.01930\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0196 - mean_absolute_error: 0.1073 - mean_squared_error: 0.0196 - val_loss: 0.0199 - val_mean_absolute_error: 0.1048 - val_mean_squared_error: 0.0199\n",
            "Epoch 589/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0196 - mean_absolute_error: 0.1075 - mean_squared_error: 0.0196\n",
            "Epoch 589: val_loss did not improve from 0.01930\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0196 - mean_absolute_error: 0.1074 - mean_squared_error: 0.0196 - val_loss: 0.0226 - val_mean_absolute_error: 0.1118 - val_mean_squared_error: 0.0226\n",
            "Epoch 590/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0200 - mean_absolute_error: 0.1084 - mean_squared_error: 0.0200\n",
            "Epoch 590: val_loss did not improve from 0.01930\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0199 - mean_absolute_error: 0.1083 - mean_squared_error: 0.0199 - val_loss: 0.0217 - val_mean_absolute_error: 0.1122 - val_mean_squared_error: 0.0217\n",
            "Epoch 591/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0203 - mean_absolute_error: 0.1090 - mean_squared_error: 0.0203\n",
            "Epoch 591: val_loss did not improve from 0.01930\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0204 - mean_absolute_error: 0.1096 - mean_squared_error: 0.0204 - val_loss: 0.0249 - val_mean_absolute_error: 0.1219 - val_mean_squared_error: 0.0249\n",
            "Epoch 592/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0200 - mean_absolute_error: 0.1082 - mean_squared_error: 0.0200\n",
            "Epoch 592: val_loss improved from 0.01930 to 0.01894, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0201 - mean_absolute_error: 0.1085 - mean_squared_error: 0.0201 - val_loss: 0.0189 - val_mean_absolute_error: 0.1055 - val_mean_squared_error: 0.0189\n",
            "Epoch 593/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0195 - mean_absolute_error: 0.1062 - mean_squared_error: 0.0195\n",
            "Epoch 593: val_loss improved from 0.01894 to 0.01864, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0195 - mean_absolute_error: 0.1062 - mean_squared_error: 0.0195 - val_loss: 0.0186 - val_mean_absolute_error: 0.1032 - val_mean_squared_error: 0.0186\n",
            "Epoch 594/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0194 - mean_absolute_error: 0.1062 - mean_squared_error: 0.0194\n",
            "Epoch 594: val_loss did not improve from 0.01864\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0193 - mean_absolute_error: 0.1065 - mean_squared_error: 0.0193 - val_loss: 0.0192 - val_mean_absolute_error: 0.1069 - val_mean_squared_error: 0.0192\n",
            "Epoch 595/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0193 - mean_absolute_error: 0.1063 - mean_squared_error: 0.0193\n",
            "Epoch 595: val_loss did not improve from 0.01864\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0194 - mean_absolute_error: 0.1067 - mean_squared_error: 0.0194 - val_loss: 0.0189 - val_mean_absolute_error: 0.1045 - val_mean_squared_error: 0.0189\n",
            "Epoch 596/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0193 - mean_absolute_error: 0.1060 - mean_squared_error: 0.0193\n",
            "Epoch 596: val_loss did not improve from 0.01864\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0194 - mean_absolute_error: 0.1062 - mean_squared_error: 0.0194 - val_loss: 0.0204 - val_mean_absolute_error: 0.1102 - val_mean_squared_error: 0.0204\n",
            "Epoch 597/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0195 - mean_absolute_error: 0.1074 - mean_squared_error: 0.0195\n",
            "Epoch 597: val_loss did not improve from 0.01864\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0194 - mean_absolute_error: 0.1071 - mean_squared_error: 0.0194 - val_loss: 0.0192 - val_mean_absolute_error: 0.1059 - val_mean_squared_error: 0.0192\n",
            "Epoch 598/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0191 - mean_absolute_error: 0.1053 - mean_squared_error: 0.0191\n",
            "Epoch 598: val_loss improved from 0.01864 to 0.01858, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0191 - mean_absolute_error: 0.1053 - mean_squared_error: 0.0191 - val_loss: 0.0186 - val_mean_absolute_error: 0.1010 - val_mean_squared_error: 0.0186\n",
            "Epoch 599/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0191 - mean_absolute_error: 0.1052 - mean_squared_error: 0.0191\n",
            "Epoch 599: val_loss did not improve from 0.01858\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0191 - mean_absolute_error: 0.1051 - mean_squared_error: 0.0191 - val_loss: 0.0187 - val_mean_absolute_error: 0.1055 - val_mean_squared_error: 0.0187\n",
            "Epoch 600/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0192 - mean_absolute_error: 0.1055 - mean_squared_error: 0.0192\n",
            "Epoch 600: val_loss did not improve from 0.01858\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0191 - mean_absolute_error: 0.1054 - mean_squared_error: 0.0191 - val_loss: 0.0203 - val_mean_absolute_error: 0.1077 - val_mean_squared_error: 0.0203\n",
            "Epoch 601/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0192 - mean_absolute_error: 0.1061 - mean_squared_error: 0.0192\n",
            "Epoch 601: val_loss did not improve from 0.01858\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0192 - mean_absolute_error: 0.1058 - mean_squared_error: 0.0192 - val_loss: 0.0188 - val_mean_absolute_error: 0.1023 - val_mean_squared_error: 0.0188\n",
            "Epoch 602/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0197 - mean_absolute_error: 0.1072 - mean_squared_error: 0.0197\n",
            "Epoch 602: val_loss improved from 0.01858 to 0.01778, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0197 - mean_absolute_error: 0.1072 - mean_squared_error: 0.0197 - val_loss: 0.0178 - val_mean_absolute_error: 0.1008 - val_mean_squared_error: 0.0178\n",
            "Epoch 603/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0191 - mean_absolute_error: 0.1057 - mean_squared_error: 0.0191\n",
            "Epoch 603: val_loss did not improve from 0.01778\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0191 - mean_absolute_error: 0.1057 - mean_squared_error: 0.0191 - val_loss: 0.0192 - val_mean_absolute_error: 0.1034 - val_mean_squared_error: 0.0192\n",
            "Epoch 604/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0195 - mean_absolute_error: 0.1068 - mean_squared_error: 0.0195\n",
            "Epoch 604: val_loss improved from 0.01778 to 0.01727, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0194 - mean_absolute_error: 0.1063 - mean_squared_error: 0.0194 - val_loss: 0.0173 - val_mean_absolute_error: 0.1006 - val_mean_squared_error: 0.0173\n",
            "Epoch 605/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0193 - mean_absolute_error: 0.1056 - mean_squared_error: 0.0193\n",
            "Epoch 605: val_loss did not improve from 0.01727\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0191 - mean_absolute_error: 0.1048 - mean_squared_error: 0.0191 - val_loss: 0.0184 - val_mean_absolute_error: 0.1032 - val_mean_squared_error: 0.0184\n",
            "Epoch 606/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0189 - mean_absolute_error: 0.1040 - mean_squared_error: 0.0189\n",
            "Epoch 606: val_loss did not improve from 0.01727\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0190 - mean_absolute_error: 0.1046 - mean_squared_error: 0.0190 - val_loss: 0.0191 - val_mean_absolute_error: 0.1041 - val_mean_squared_error: 0.0191\n",
            "Epoch 607/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0193 - mean_absolute_error: 0.1062 - mean_squared_error: 0.0193\n",
            "Epoch 607: val_loss did not improve from 0.01727\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0192 - mean_absolute_error: 0.1061 - mean_squared_error: 0.0192 - val_loss: 0.0200 - val_mean_absolute_error: 0.1095 - val_mean_squared_error: 0.0200\n",
            "Epoch 608/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0188 - mean_absolute_error: 0.1050 - mean_squared_error: 0.0188\n",
            "Epoch 608: val_loss did not improve from 0.01727\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0188 - mean_absolute_error: 0.1050 - mean_squared_error: 0.0188 - val_loss: 0.0176 - val_mean_absolute_error: 0.0991 - val_mean_squared_error: 0.0176\n",
            "Epoch 609/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0190 - mean_absolute_error: 0.1050 - mean_squared_error: 0.0190\n",
            "Epoch 609: val_loss improved from 0.01727 to 0.01707, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0187 - mean_absolute_error: 0.1042 - mean_squared_error: 0.0187 - val_loss: 0.0171 - val_mean_absolute_error: 0.0992 - val_mean_squared_error: 0.0171\n",
            "Epoch 610/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.0193 - mean_absolute_error: 0.1053 - mean_squared_error: 0.0193\n",
            "Epoch 610: val_loss did not improve from 0.01707\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0189 - mean_absolute_error: 0.1045 - mean_squared_error: 0.0189 - val_loss: 0.0182 - val_mean_absolute_error: 0.1015 - val_mean_squared_error: 0.0182\n",
            "Epoch 611/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.0182 - mean_absolute_error: 0.1029 - mean_squared_error: 0.0182\n",
            "Epoch 611: val_loss did not improve from 0.01707\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0182 - mean_absolute_error: 0.1030 - mean_squared_error: 0.0182 - val_loss: 0.0195 - val_mean_absolute_error: 0.1060 - val_mean_squared_error: 0.0195\n",
            "Epoch 612/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0184 - mean_absolute_error: 0.1026 - mean_squared_error: 0.0184\n",
            "Epoch 612: val_loss did not improve from 0.01707\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0184 - mean_absolute_error: 0.1026 - mean_squared_error: 0.0184 - val_loss: 0.0190 - val_mean_absolute_error: 0.1035 - val_mean_squared_error: 0.0190\n",
            "Epoch 613/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0186 - mean_absolute_error: 0.1039 - mean_squared_error: 0.0186\n",
            "Epoch 613: val_loss did not improve from 0.01707\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0186 - mean_absolute_error: 0.1039 - mean_squared_error: 0.0186 - val_loss: 0.0238 - val_mean_absolute_error: 0.1193 - val_mean_squared_error: 0.0238\n",
            "Epoch 614/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.0191 - mean_absolute_error: 0.1057 - mean_squared_error: 0.0191\n",
            "Epoch 614: val_loss did not improve from 0.01707\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0190 - mean_absolute_error: 0.1052 - mean_squared_error: 0.0190 - val_loss: 0.0178 - val_mean_absolute_error: 0.1017 - val_mean_squared_error: 0.0178\n",
            "Epoch 615/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0186 - mean_absolute_error: 0.1042 - mean_squared_error: 0.0186\n",
            "Epoch 615: val_loss did not improve from 0.01707\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0185 - mean_absolute_error: 0.1039 - mean_squared_error: 0.0185 - val_loss: 0.0209 - val_mean_absolute_error: 0.1094 - val_mean_squared_error: 0.0209\n",
            "Epoch 616/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0182 - mean_absolute_error: 0.1023 - mean_squared_error: 0.0182\n",
            "Epoch 616: val_loss did not improve from 0.01707\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0182 - mean_absolute_error: 0.1023 - mean_squared_error: 0.0182 - val_loss: 0.0187 - val_mean_absolute_error: 0.1030 - val_mean_squared_error: 0.0187\n",
            "Epoch 617/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0192 - mean_absolute_error: 0.1049 - mean_squared_error: 0.0192\n",
            "Epoch 617: val_loss improved from 0.01707 to 0.01644, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0190 - mean_absolute_error: 0.1045 - mean_squared_error: 0.0190 - val_loss: 0.0164 - val_mean_absolute_error: 0.0967 - val_mean_squared_error: 0.0164\n",
            "Epoch 618/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0176 - mean_absolute_error: 0.1014 - mean_squared_error: 0.0176\n",
            "Epoch 618: val_loss did not improve from 0.01644\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0177 - mean_absolute_error: 0.1014 - mean_squared_error: 0.0177 - val_loss: 0.0169 - val_mean_absolute_error: 0.0994 - val_mean_squared_error: 0.0169\n",
            "Epoch 619/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0183 - mean_absolute_error: 0.1028 - mean_squared_error: 0.0183\n",
            "Epoch 619: val_loss did not improve from 0.01644\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0184 - mean_absolute_error: 0.1030 - mean_squared_error: 0.0184 - val_loss: 0.0182 - val_mean_absolute_error: 0.1035 - val_mean_squared_error: 0.0182\n",
            "Epoch 620/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.0183 - mean_absolute_error: 0.1030 - mean_squared_error: 0.0183\n",
            "Epoch 620: val_loss did not improve from 0.01644\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0186 - mean_absolute_error: 0.1035 - mean_squared_error: 0.0186 - val_loss: 0.0182 - val_mean_absolute_error: 0.1053 - val_mean_squared_error: 0.0182\n",
            "Epoch 621/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0186 - mean_absolute_error: 0.1040 - mean_squared_error: 0.0186\n",
            "Epoch 621: val_loss improved from 0.01644 to 0.01630, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0185 - mean_absolute_error: 0.1040 - mean_squared_error: 0.0185 - val_loss: 0.0163 - val_mean_absolute_error: 0.0963 - val_mean_squared_error: 0.0163\n",
            "Epoch 622/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.0183 - mean_absolute_error: 0.1027 - mean_squared_error: 0.0183\n",
            "Epoch 622: val_loss did not improve from 0.01630\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0181 - mean_absolute_error: 0.1025 - mean_squared_error: 0.0181 - val_loss: 0.0176 - val_mean_absolute_error: 0.0990 - val_mean_squared_error: 0.0176\n",
            "Epoch 623/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0179 - mean_absolute_error: 0.1014 - mean_squared_error: 0.0179\n",
            "Epoch 623: val_loss did not improve from 0.01630\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0179 - mean_absolute_error: 0.1014 - mean_squared_error: 0.0179 - val_loss: 0.0194 - val_mean_absolute_error: 0.1053 - val_mean_squared_error: 0.0194\n",
            "Epoch 624/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0177 - mean_absolute_error: 0.1010 - mean_squared_error: 0.0177\n",
            "Epoch 624: val_loss did not improve from 0.01630\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0177 - mean_absolute_error: 0.1008 - mean_squared_error: 0.0177 - val_loss: 0.0172 - val_mean_absolute_error: 0.0999 - val_mean_squared_error: 0.0172\n",
            "Epoch 625/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0180 - mean_absolute_error: 0.1022 - mean_squared_error: 0.0180\n",
            "Epoch 625: val_loss did not improve from 0.01630\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0180 - mean_absolute_error: 0.1018 - mean_squared_error: 0.0180 - val_loss: 0.0180 - val_mean_absolute_error: 0.0990 - val_mean_squared_error: 0.0180\n",
            "Epoch 626/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0175 - mean_absolute_error: 0.1009 - mean_squared_error: 0.0175\n",
            "Epoch 626: val_loss did not improve from 0.01630\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0177 - mean_absolute_error: 0.1014 - mean_squared_error: 0.0177 - val_loss: 0.0291 - val_mean_absolute_error: 0.1290 - val_mean_squared_error: 0.0291\n",
            "Epoch 627/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0175 - mean_absolute_error: 0.1004 - mean_squared_error: 0.0175\n",
            "Epoch 627: val_loss did not improve from 0.01630\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0175 - mean_absolute_error: 0.1003 - mean_squared_error: 0.0175 - val_loss: 0.0175 - val_mean_absolute_error: 0.1018 - val_mean_squared_error: 0.0175\n",
            "Epoch 628/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0179 - mean_absolute_error: 0.1013 - mean_squared_error: 0.0179\n",
            "Epoch 628: val_loss did not improve from 0.01630\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0178 - mean_absolute_error: 0.1009 - mean_squared_error: 0.0178 - val_loss: 0.0164 - val_mean_absolute_error: 0.0947 - val_mean_squared_error: 0.0164\n",
            "Epoch 629/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0174 - mean_absolute_error: 0.1000 - mean_squared_error: 0.0174\n",
            "Epoch 629: val_loss improved from 0.01630 to 0.01586, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0174 - mean_absolute_error: 0.1000 - mean_squared_error: 0.0174 - val_loss: 0.0159 - val_mean_absolute_error: 0.0954 - val_mean_squared_error: 0.0159\n",
            "Epoch 630/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0178 - mean_absolute_error: 0.1009 - mean_squared_error: 0.0178\n",
            "Epoch 630: val_loss did not improve from 0.01586\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0177 - mean_absolute_error: 0.1008 - mean_squared_error: 0.0177 - val_loss: 0.0188 - val_mean_absolute_error: 0.1017 - val_mean_squared_error: 0.0188\n",
            "Epoch 631/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0170 - mean_absolute_error: 0.0987 - mean_squared_error: 0.0170\n",
            "Epoch 631: val_loss did not improve from 0.01586\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0172 - mean_absolute_error: 0.0993 - mean_squared_error: 0.0172 - val_loss: 0.0205 - val_mean_absolute_error: 0.1089 - val_mean_squared_error: 0.0205\n",
            "Epoch 632/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0177 - mean_absolute_error: 0.1006 - mean_squared_error: 0.0177\n",
            "Epoch 632: val_loss improved from 0.01586 to 0.01578, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0176 - mean_absolute_error: 0.1004 - mean_squared_error: 0.0176 - val_loss: 0.0158 - val_mean_absolute_error: 0.0953 - val_mean_squared_error: 0.0158\n",
            "Epoch 633/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0175 - mean_absolute_error: 0.1002 - mean_squared_error: 0.0175\n",
            "Epoch 633: val_loss did not improve from 0.01578\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0175 - mean_absolute_error: 0.1002 - mean_squared_error: 0.0175 - val_loss: 0.0179 - val_mean_absolute_error: 0.1019 - val_mean_squared_error: 0.0179\n",
            "Epoch 634/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0175 - mean_absolute_error: 0.1004 - mean_squared_error: 0.0175\n",
            "Epoch 634: val_loss did not improve from 0.01578\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0175 - mean_absolute_error: 0.1004 - mean_squared_error: 0.0175 - val_loss: 0.0200 - val_mean_absolute_error: 0.1075 - val_mean_squared_error: 0.0200\n",
            "Epoch 635/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0178 - mean_absolute_error: 0.1015 - mean_squared_error: 0.0178\n",
            "Epoch 635: val_loss did not improve from 0.01578\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0181 - mean_absolute_error: 0.1022 - mean_squared_error: 0.0181 - val_loss: 0.0160 - val_mean_absolute_error: 0.0967 - val_mean_squared_error: 0.0160\n",
            "Epoch 636/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0173 - mean_absolute_error: 0.0996 - mean_squared_error: 0.0173\n",
            "Epoch 636: val_loss did not improve from 0.01578\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0173 - mean_absolute_error: 0.0996 - mean_squared_error: 0.0173 - val_loss: 0.0209 - val_mean_absolute_error: 0.1100 - val_mean_squared_error: 0.0209\n",
            "Epoch 637/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0168 - mean_absolute_error: 0.0986 - mean_squared_error: 0.0168\n",
            "Epoch 637: val_loss did not improve from 0.01578\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0167 - mean_absolute_error: 0.0985 - mean_squared_error: 0.0167 - val_loss: 0.0177 - val_mean_absolute_error: 0.0993 - val_mean_squared_error: 0.0177\n",
            "Epoch 638/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0172 - mean_absolute_error: 0.0990 - mean_squared_error: 0.0172\n",
            "Epoch 638: val_loss did not improve from 0.01578\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0172 - mean_absolute_error: 0.0988 - mean_squared_error: 0.0172 - val_loss: 0.0167 - val_mean_absolute_error: 0.0980 - val_mean_squared_error: 0.0167\n",
            "Epoch 639/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0174 - mean_absolute_error: 0.0997 - mean_squared_error: 0.0174\n",
            "Epoch 639: val_loss did not improve from 0.01578\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0174 - mean_absolute_error: 0.0998 - mean_squared_error: 0.0174 - val_loss: 0.0162 - val_mean_absolute_error: 0.0962 - val_mean_squared_error: 0.0162\n",
            "Epoch 640/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0165 - mean_absolute_error: 0.0978 - mean_squared_error: 0.0165\n",
            "Epoch 640: val_loss did not improve from 0.01578\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0165 - mean_absolute_error: 0.0978 - mean_squared_error: 0.0165 - val_loss: 0.0161 - val_mean_absolute_error: 0.0969 - val_mean_squared_error: 0.0161\n",
            "Epoch 641/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0172 - mean_absolute_error: 0.0992 - mean_squared_error: 0.0172\n",
            "Epoch 641: val_loss improved from 0.01578 to 0.01501, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0171 - mean_absolute_error: 0.0989 - mean_squared_error: 0.0171 - val_loss: 0.0150 - val_mean_absolute_error: 0.0944 - val_mean_squared_error: 0.0150\n",
            "Epoch 642/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.0178 - mean_absolute_error: 0.1012 - mean_squared_error: 0.0178\n",
            "Epoch 642: val_loss did not improve from 0.01501\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0175 - mean_absolute_error: 0.1006 - mean_squared_error: 0.0175 - val_loss: 0.0168 - val_mean_absolute_error: 0.0974 - val_mean_squared_error: 0.0168\n",
            "Epoch 643/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0169 - mean_absolute_error: 0.0983 - mean_squared_error: 0.0169\n",
            "Epoch 643: val_loss did not improve from 0.01501\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0169 - mean_absolute_error: 0.0983 - mean_squared_error: 0.0169 - val_loss: 0.0157 - val_mean_absolute_error: 0.0960 - val_mean_squared_error: 0.0157\n",
            "Epoch 644/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0164 - mean_absolute_error: 0.0965 - mean_squared_error: 0.0164\n",
            "Epoch 644: val_loss did not improve from 0.01501\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0164 - mean_absolute_error: 0.0965 - mean_squared_error: 0.0164 - val_loss: 0.0158 - val_mean_absolute_error: 0.0953 - val_mean_squared_error: 0.0158\n",
            "Epoch 645/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0170 - mean_absolute_error: 0.0994 - mean_squared_error: 0.0170\n",
            "Epoch 645: val_loss did not improve from 0.01501\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0170 - mean_absolute_error: 0.0991 - mean_squared_error: 0.0170 - val_loss: 0.0187 - val_mean_absolute_error: 0.1029 - val_mean_squared_error: 0.0187\n",
            "Epoch 646/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0172 - mean_absolute_error: 0.0986 - mean_squared_error: 0.0172\n",
            "Epoch 646: val_loss did not improve from 0.01501\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0171 - mean_absolute_error: 0.0986 - mean_squared_error: 0.0171 - val_loss: 0.0171 - val_mean_absolute_error: 0.0981 - val_mean_squared_error: 0.0171\n",
            "Epoch 647/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.0167 - mean_absolute_error: 0.0978 - mean_squared_error: 0.0167\n",
            "Epoch 647: val_loss did not improve from 0.01501\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0167 - mean_absolute_error: 0.0977 - mean_squared_error: 0.0167 - val_loss: 0.0167 - val_mean_absolute_error: 0.0982 - val_mean_squared_error: 0.0167\n",
            "Epoch 648/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0163 - mean_absolute_error: 0.0963 - mean_squared_error: 0.0163\n",
            "Epoch 648: val_loss did not improve from 0.01501\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0163 - mean_absolute_error: 0.0965 - mean_squared_error: 0.0163 - val_loss: 0.0172 - val_mean_absolute_error: 0.0988 - val_mean_squared_error: 0.0172\n",
            "Epoch 649/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0165 - mean_absolute_error: 0.0974 - mean_squared_error: 0.0165\n",
            "Epoch 649: val_loss did not improve from 0.01501\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0165 - mean_absolute_error: 0.0970 - mean_squared_error: 0.0165 - val_loss: 0.0163 - val_mean_absolute_error: 0.0957 - val_mean_squared_error: 0.0163\n",
            "Epoch 650/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.0168 - mean_absolute_error: 0.0978 - mean_squared_error: 0.0168\n",
            "Epoch 650: val_loss did not improve from 0.01501\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0168 - mean_absolute_error: 0.0977 - mean_squared_error: 0.0168 - val_loss: 0.0173 - val_mean_absolute_error: 0.1006 - val_mean_squared_error: 0.0173\n",
            "Epoch 651/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0171 - mean_absolute_error: 0.0987 - mean_squared_error: 0.0171\n",
            "Epoch 651: val_loss improved from 0.01501 to 0.01497, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0170 - mean_absolute_error: 0.0986 - mean_squared_error: 0.0170 - val_loss: 0.0150 - val_mean_absolute_error: 0.0917 - val_mean_squared_error: 0.0150\n",
            "Epoch 652/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0164 - mean_absolute_error: 0.0973 - mean_squared_error: 0.0164\n",
            "Epoch 652: val_loss did not improve from 0.01497\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0163 - mean_absolute_error: 0.0970 - mean_squared_error: 0.0163 - val_loss: 0.0156 - val_mean_absolute_error: 0.0954 - val_mean_squared_error: 0.0156\n",
            "Epoch 653/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0166 - mean_absolute_error: 0.0975 - mean_squared_error: 0.0166\n",
            "Epoch 653: val_loss did not improve from 0.01497\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0165 - mean_absolute_error: 0.0974 - mean_squared_error: 0.0165 - val_loss: 0.0179 - val_mean_absolute_error: 0.1031 - val_mean_squared_error: 0.0179\n",
            "Epoch 654/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0169 - mean_absolute_error: 0.0982 - mean_squared_error: 0.0169\n",
            "Epoch 654: val_loss improved from 0.01497 to 0.01427, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0169 - mean_absolute_error: 0.0981 - mean_squared_error: 0.0169 - val_loss: 0.0143 - val_mean_absolute_error: 0.0893 - val_mean_squared_error: 0.0143\n",
            "Epoch 655/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.0168 - mean_absolute_error: 0.0978 - mean_squared_error: 0.0168\n",
            "Epoch 655: val_loss did not improve from 0.01427\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0167 - mean_absolute_error: 0.0975 - mean_squared_error: 0.0167 - val_loss: 0.0155 - val_mean_absolute_error: 0.0945 - val_mean_squared_error: 0.0155\n",
            "Epoch 656/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0173 - mean_absolute_error: 0.0991 - mean_squared_error: 0.0173\n",
            "Epoch 656: val_loss did not improve from 0.01427\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0173 - mean_absolute_error: 0.0989 - mean_squared_error: 0.0173 - val_loss: 0.0147 - val_mean_absolute_error: 0.0923 - val_mean_squared_error: 0.0147\n",
            "Epoch 657/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.0159 - mean_absolute_error: 0.0952 - mean_squared_error: 0.0159\n",
            "Epoch 657: val_loss did not improve from 0.01427\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0159 - mean_absolute_error: 0.0951 - mean_squared_error: 0.0159 - val_loss: 0.0162 - val_mean_absolute_error: 0.0961 - val_mean_squared_error: 0.0162\n",
            "Epoch 658/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0162 - mean_absolute_error: 0.0958 - mean_squared_error: 0.0162\n",
            "Epoch 658: val_loss improved from 0.01427 to 0.01421, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0162 - mean_absolute_error: 0.0956 - mean_squared_error: 0.0162 - val_loss: 0.0142 - val_mean_absolute_error: 0.0902 - val_mean_squared_error: 0.0142\n",
            "Epoch 659/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0162 - mean_absolute_error: 0.0965 - mean_squared_error: 0.0162\n",
            "Epoch 659: val_loss did not improve from 0.01421\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0163 - mean_absolute_error: 0.0965 - mean_squared_error: 0.0163 - val_loss: 0.0147 - val_mean_absolute_error: 0.0927 - val_mean_squared_error: 0.0147\n",
            "Epoch 660/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.0162 - mean_absolute_error: 0.0958 - mean_squared_error: 0.0162\n",
            "Epoch 660: val_loss did not improve from 0.01421\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0165 - mean_absolute_error: 0.0964 - mean_squared_error: 0.0165 - val_loss: 0.0165 - val_mean_absolute_error: 0.0951 - val_mean_squared_error: 0.0165\n",
            "Epoch 661/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0162 - mean_absolute_error: 0.0963 - mean_squared_error: 0.0162\n",
            "Epoch 661: val_loss did not improve from 0.01421\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0162 - mean_absolute_error: 0.0963 - mean_squared_error: 0.0162 - val_loss: 0.0171 - val_mean_absolute_error: 0.0971 - val_mean_squared_error: 0.0171\n",
            "Epoch 662/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0166 - mean_absolute_error: 0.0978 - mean_squared_error: 0.0166\n",
            "Epoch 662: val_loss did not improve from 0.01421\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0166 - mean_absolute_error: 0.0979 - mean_squared_error: 0.0166 - val_loss: 0.0155 - val_mean_absolute_error: 0.0927 - val_mean_squared_error: 0.0155\n",
            "Epoch 663/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0157 - mean_absolute_error: 0.0941 - mean_squared_error: 0.0157\n",
            "Epoch 663: val_loss did not improve from 0.01421\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0157 - mean_absolute_error: 0.0942 - mean_squared_error: 0.0157 - val_loss: 0.0146 - val_mean_absolute_error: 0.0928 - val_mean_squared_error: 0.0146\n",
            "Epoch 664/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0167 - mean_absolute_error: 0.0974 - mean_squared_error: 0.0167\n",
            "Epoch 664: val_loss did not improve from 0.01421\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0167 - mean_absolute_error: 0.0974 - mean_squared_error: 0.0167 - val_loss: 0.0173 - val_mean_absolute_error: 0.0974 - val_mean_squared_error: 0.0173\n",
            "Epoch 665/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0156 - mean_absolute_error: 0.0949 - mean_squared_error: 0.0156\n",
            "Epoch 665: val_loss did not improve from 0.01421\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0156 - mean_absolute_error: 0.0945 - mean_squared_error: 0.0156 - val_loss: 0.0158 - val_mean_absolute_error: 0.0914 - val_mean_squared_error: 0.0158\n",
            "Epoch 666/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0169 - mean_absolute_error: 0.0980 - mean_squared_error: 0.0169\n",
            "Epoch 666: val_loss did not improve from 0.01421\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0168 - mean_absolute_error: 0.0980 - mean_squared_error: 0.0168 - val_loss: 0.0183 - val_mean_absolute_error: 0.1020 - val_mean_squared_error: 0.0183\n",
            "Epoch 667/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0160 - mean_absolute_error: 0.0944 - mean_squared_error: 0.0160\n",
            "Epoch 667: val_loss did not improve from 0.01421\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0159 - mean_absolute_error: 0.0942 - mean_squared_error: 0.0159 - val_loss: 0.0143 - val_mean_absolute_error: 0.0893 - val_mean_squared_error: 0.0143\n",
            "Epoch 668/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0154 - mean_absolute_error: 0.0931 - mean_squared_error: 0.0154\n",
            "Epoch 668: val_loss did not improve from 0.01421\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0154 - mean_absolute_error: 0.0934 - mean_squared_error: 0.0154 - val_loss: 0.0160 - val_mean_absolute_error: 0.0967 - val_mean_squared_error: 0.0160\n",
            "Epoch 669/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0158 - mean_absolute_error: 0.0946 - mean_squared_error: 0.0158\n",
            "Epoch 669: val_loss did not improve from 0.01421\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0158 - mean_absolute_error: 0.0946 - mean_squared_error: 0.0158 - val_loss: 0.0151 - val_mean_absolute_error: 0.0934 - val_mean_squared_error: 0.0151\n",
            "Epoch 670/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0158 - mean_absolute_error: 0.0946 - mean_squared_error: 0.0158\n",
            "Epoch 670: val_loss did not improve from 0.01421\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0159 - mean_absolute_error: 0.0950 - mean_squared_error: 0.0159 - val_loss: 0.0208 - val_mean_absolute_error: 0.1115 - val_mean_squared_error: 0.0208\n",
            "Epoch 671/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0155 - mean_absolute_error: 0.0937 - mean_squared_error: 0.0155\n",
            "Epoch 671: val_loss did not improve from 0.01421\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0156 - mean_absolute_error: 0.0938 - mean_squared_error: 0.0156 - val_loss: 0.0188 - val_mean_absolute_error: 0.1045 - val_mean_squared_error: 0.0188\n",
            "Epoch 672/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0160 - mean_absolute_error: 0.0957 - mean_squared_error: 0.0160\n",
            "Epoch 672: val_loss did not improve from 0.01421\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0160 - mean_absolute_error: 0.0958 - mean_squared_error: 0.0160 - val_loss: 0.0157 - val_mean_absolute_error: 0.0949 - val_mean_squared_error: 0.0157\n",
            "Epoch 673/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0161 - mean_absolute_error: 0.0964 - mean_squared_error: 0.0161\n",
            "Epoch 673: val_loss improved from 0.01421 to 0.01413, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0160 - mean_absolute_error: 0.0958 - mean_squared_error: 0.0160 - val_loss: 0.0141 - val_mean_absolute_error: 0.0905 - val_mean_squared_error: 0.0141\n",
            "Epoch 674/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0161 - mean_absolute_error: 0.0953 - mean_squared_error: 0.0161\n",
            "Epoch 674: val_loss did not improve from 0.01413\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0161 - mean_absolute_error: 0.0954 - mean_squared_error: 0.0161 - val_loss: 0.0159 - val_mean_absolute_error: 0.0958 - val_mean_squared_error: 0.0159\n",
            "Epoch 675/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0160 - mean_absolute_error: 0.0955 - mean_squared_error: 0.0160\n",
            "Epoch 675: val_loss did not improve from 0.01413\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0160 - mean_absolute_error: 0.0955 - mean_squared_error: 0.0160 - val_loss: 0.0178 - val_mean_absolute_error: 0.0996 - val_mean_squared_error: 0.0178\n",
            "Epoch 676/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0156 - mean_absolute_error: 0.0934 - mean_squared_error: 0.0156\n",
            "Epoch 676: val_loss improved from 0.01413 to 0.01406, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0158 - mean_absolute_error: 0.0937 - mean_squared_error: 0.0158 - val_loss: 0.0141 - val_mean_absolute_error: 0.0916 - val_mean_squared_error: 0.0141\n",
            "Epoch 677/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0158 - mean_absolute_error: 0.0950 - mean_squared_error: 0.0158\n",
            "Epoch 677: val_loss did not improve from 0.01406\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0158 - mean_absolute_error: 0.0948 - mean_squared_error: 0.0158 - val_loss: 0.0141 - val_mean_absolute_error: 0.0906 - val_mean_squared_error: 0.0141\n",
            "Epoch 678/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0153 - mean_absolute_error: 0.0935 - mean_squared_error: 0.0153\n",
            "Epoch 678: val_loss did not improve from 0.01406\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0154 - mean_absolute_error: 0.0936 - mean_squared_error: 0.0154 - val_loss: 0.0148 - val_mean_absolute_error: 0.0931 - val_mean_squared_error: 0.0148\n",
            "Epoch 679/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0155 - mean_absolute_error: 0.0934 - mean_squared_error: 0.0155\n",
            "Epoch 679: val_loss improved from 0.01406 to 0.01322, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0156 - mean_absolute_error: 0.0938 - mean_squared_error: 0.0156 - val_loss: 0.0132 - val_mean_absolute_error: 0.0861 - val_mean_squared_error: 0.0132\n",
            "Epoch 680/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0160 - mean_absolute_error: 0.0949 - mean_squared_error: 0.0160\n",
            "Epoch 680: val_loss did not improve from 0.01322\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0160 - mean_absolute_error: 0.0950 - mean_squared_error: 0.0160 - val_loss: 0.0170 - val_mean_absolute_error: 0.0986 - val_mean_squared_error: 0.0170\n",
            "Epoch 681/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.0150 - mean_absolute_error: 0.0921 - mean_squared_error: 0.0150\n",
            "Epoch 681: val_loss did not improve from 0.01322\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0151 - mean_absolute_error: 0.0924 - mean_squared_error: 0.0151 - val_loss: 0.0182 - val_mean_absolute_error: 0.1014 - val_mean_squared_error: 0.0182\n",
            "Epoch 682/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0155 - mean_absolute_error: 0.0948 - mean_squared_error: 0.0155\n",
            "Epoch 682: val_loss did not improve from 0.01322\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0155 - mean_absolute_error: 0.0947 - mean_squared_error: 0.0155 - val_loss: 0.0189 - val_mean_absolute_error: 0.1056 - val_mean_squared_error: 0.0189\n",
            "Epoch 683/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0152 - mean_absolute_error: 0.0920 - mean_squared_error: 0.0152\n",
            "Epoch 683: val_loss did not improve from 0.01322\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0152 - mean_absolute_error: 0.0920 - mean_squared_error: 0.0152 - val_loss: 0.0152 - val_mean_absolute_error: 0.0914 - val_mean_squared_error: 0.0152\n",
            "Epoch 684/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0155 - mean_absolute_error: 0.0936 - mean_squared_error: 0.0155\n",
            "Epoch 684: val_loss did not improve from 0.01322\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0156 - mean_absolute_error: 0.0938 - mean_squared_error: 0.0156 - val_loss: 0.0142 - val_mean_absolute_error: 0.0888 - val_mean_squared_error: 0.0142\n",
            "Epoch 685/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0153 - mean_absolute_error: 0.0931 - mean_squared_error: 0.0153\n",
            "Epoch 685: val_loss did not improve from 0.01322\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0152 - mean_absolute_error: 0.0929 - mean_squared_error: 0.0152 - val_loss: 0.0133 - val_mean_absolute_error: 0.0864 - val_mean_squared_error: 0.0133\n",
            "Epoch 686/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0153 - mean_absolute_error: 0.0931 - mean_squared_error: 0.0153\n",
            "Epoch 686: val_loss did not improve from 0.01322\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0154 - mean_absolute_error: 0.0933 - mean_squared_error: 0.0154 - val_loss: 0.0166 - val_mean_absolute_error: 0.0942 - val_mean_squared_error: 0.0166\n",
            "Epoch 687/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0147 - mean_absolute_error: 0.0920 - mean_squared_error: 0.0147\n",
            "Epoch 687: val_loss did not improve from 0.01322\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0150 - mean_absolute_error: 0.0923 - mean_squared_error: 0.0150 - val_loss: 0.0150 - val_mean_absolute_error: 0.0948 - val_mean_squared_error: 0.0150\n",
            "Epoch 688/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.0154 - mean_absolute_error: 0.0933 - mean_squared_error: 0.0154\n",
            "Epoch 688: val_loss did not improve from 0.01322\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0153 - mean_absolute_error: 0.0931 - mean_squared_error: 0.0153 - val_loss: 0.0140 - val_mean_absolute_error: 0.0892 - val_mean_squared_error: 0.0140\n",
            "Epoch 689/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0163 - mean_absolute_error: 0.0964 - mean_squared_error: 0.0163\n",
            "Epoch 689: val_loss did not improve from 0.01322\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0163 - mean_absolute_error: 0.0965 - mean_squared_error: 0.0163 - val_loss: 0.0133 - val_mean_absolute_error: 0.0873 - val_mean_squared_error: 0.0133\n",
            "Epoch 690/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0148 - mean_absolute_error: 0.0912 - mean_squared_error: 0.0148\n",
            "Epoch 690: val_loss did not improve from 0.01322\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0148 - mean_absolute_error: 0.0913 - mean_squared_error: 0.0148 - val_loss: 0.0138 - val_mean_absolute_error: 0.0882 - val_mean_squared_error: 0.0138\n",
            "Epoch 691/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0148 - mean_absolute_error: 0.0914 - mean_squared_error: 0.0148\n",
            "Epoch 691: val_loss did not improve from 0.01322\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0148 - mean_absolute_error: 0.0915 - mean_squared_error: 0.0148 - val_loss: 0.0151 - val_mean_absolute_error: 0.0944 - val_mean_squared_error: 0.0151\n",
            "Epoch 692/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0149 - mean_absolute_error: 0.0911 - mean_squared_error: 0.0149\n",
            "Epoch 692: val_loss did not improve from 0.01322\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0150 - mean_absolute_error: 0.0916 - mean_squared_error: 0.0150 - val_loss: 0.0150 - val_mean_absolute_error: 0.0932 - val_mean_squared_error: 0.0150\n",
            "Epoch 693/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0152 - mean_absolute_error: 0.0924 - mean_squared_error: 0.0152\n",
            "Epoch 693: val_loss did not improve from 0.01322\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0152 - mean_absolute_error: 0.0923 - mean_squared_error: 0.0152 - val_loss: 0.0151 - val_mean_absolute_error: 0.0923 - val_mean_squared_error: 0.0151\n",
            "Epoch 694/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0150 - mean_absolute_error: 0.0923 - mean_squared_error: 0.0150\n",
            "Epoch 694: val_loss did not improve from 0.01322\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0150 - mean_absolute_error: 0.0923 - mean_squared_error: 0.0150 - val_loss: 0.0163 - val_mean_absolute_error: 0.0982 - val_mean_squared_error: 0.0163\n",
            "Epoch 695/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0154 - mean_absolute_error: 0.0934 - mean_squared_error: 0.0154\n",
            "Epoch 695: val_loss did not improve from 0.01322\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0154 - mean_absolute_error: 0.0934 - mean_squared_error: 0.0154 - val_loss: 0.0148 - val_mean_absolute_error: 0.0922 - val_mean_squared_error: 0.0148\n",
            "Epoch 696/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0149 - mean_absolute_error: 0.0923 - mean_squared_error: 0.0149\n",
            "Epoch 696: val_loss improved from 0.01322 to 0.01274, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0148 - mean_absolute_error: 0.0921 - mean_squared_error: 0.0148 - val_loss: 0.0127 - val_mean_absolute_error: 0.0845 - val_mean_squared_error: 0.0127\n",
            "Epoch 697/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0146 - mean_absolute_error: 0.0904 - mean_squared_error: 0.0146\n",
            "Epoch 697: val_loss did not improve from 0.01274\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0146 - mean_absolute_error: 0.0905 - mean_squared_error: 0.0146 - val_loss: 0.0170 - val_mean_absolute_error: 0.1011 - val_mean_squared_error: 0.0170\n",
            "Epoch 698/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0150 - mean_absolute_error: 0.0922 - mean_squared_error: 0.0150\n",
            "Epoch 698: val_loss did not improve from 0.01274\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0150 - mean_absolute_error: 0.0918 - mean_squared_error: 0.0150 - val_loss: 0.0147 - val_mean_absolute_error: 0.0917 - val_mean_squared_error: 0.0147\n",
            "Epoch 699/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0153 - mean_absolute_error: 0.0927 - mean_squared_error: 0.0153\n",
            "Epoch 699: val_loss did not improve from 0.01274\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0152 - mean_absolute_error: 0.0925 - mean_squared_error: 0.0152 - val_loss: 0.0146 - val_mean_absolute_error: 0.0908 - val_mean_squared_error: 0.0146\n",
            "Epoch 700/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0144 - mean_absolute_error: 0.0897 - mean_squared_error: 0.0144\n",
            "Epoch 700: val_loss did not improve from 0.01274\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0146 - mean_absolute_error: 0.0899 - mean_squared_error: 0.0146 - val_loss: 0.0140 - val_mean_absolute_error: 0.0885 - val_mean_squared_error: 0.0140\n",
            "Epoch 701/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0153 - mean_absolute_error: 0.0923 - mean_squared_error: 0.0153\n",
            "Epoch 701: val_loss did not improve from 0.01274\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0154 - mean_absolute_error: 0.0926 - mean_squared_error: 0.0154 - val_loss: 0.0162 - val_mean_absolute_error: 0.0962 - val_mean_squared_error: 0.0162\n",
            "Epoch 702/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0144 - mean_absolute_error: 0.0897 - mean_squared_error: 0.0144\n",
            "Epoch 702: val_loss did not improve from 0.01274\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0144 - mean_absolute_error: 0.0898 - mean_squared_error: 0.0144 - val_loss: 0.0191 - val_mean_absolute_error: 0.1028 - val_mean_squared_error: 0.0191\n",
            "Epoch 703/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.0149 - mean_absolute_error: 0.0921 - mean_squared_error: 0.0149\n",
            "Epoch 703: val_loss did not improve from 0.01274\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0150 - mean_absolute_error: 0.0923 - mean_squared_error: 0.0150 - val_loss: 0.0154 - val_mean_absolute_error: 0.0945 - val_mean_squared_error: 0.0154\n",
            "Epoch 704/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.0144 - mean_absolute_error: 0.0906 - mean_squared_error: 0.0144\n",
            "Epoch 704: val_loss did not improve from 0.01274\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0144 - mean_absolute_error: 0.0907 - mean_squared_error: 0.0144 - val_loss: 0.0157 - val_mean_absolute_error: 0.0970 - val_mean_squared_error: 0.0157\n",
            "Epoch 705/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0147 - mean_absolute_error: 0.0904 - mean_squared_error: 0.0147\n",
            "Epoch 705: val_loss did not improve from 0.01274\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0145 - mean_absolute_error: 0.0901 - mean_squared_error: 0.0145 - val_loss: 0.0145 - val_mean_absolute_error: 0.0881 - val_mean_squared_error: 0.0145\n",
            "Epoch 706/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.0873 - mean_squared_error: 0.0138\n",
            "Epoch 706: val_loss did not improve from 0.01274\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0139 - mean_absolute_error: 0.0879 - mean_squared_error: 0.0139 - val_loss: 0.0142 - val_mean_absolute_error: 0.0893 - val_mean_squared_error: 0.0142\n",
            "Epoch 707/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0143 - mean_absolute_error: 0.0896 - mean_squared_error: 0.0143\n",
            "Epoch 707: val_loss did not improve from 0.01274\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0143 - mean_absolute_error: 0.0895 - mean_squared_error: 0.0143 - val_loss: 0.0137 - val_mean_absolute_error: 0.0875 - val_mean_squared_error: 0.0137\n",
            "Epoch 708/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0147 - mean_absolute_error: 0.0913 - mean_squared_error: 0.0147\n",
            "Epoch 708: val_loss did not improve from 0.01274\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0147 - mean_absolute_error: 0.0913 - mean_squared_error: 0.0147 - val_loss: 0.0138 - val_mean_absolute_error: 0.0899 - val_mean_squared_error: 0.0138\n",
            "Epoch 709/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0144 - mean_absolute_error: 0.0900 - mean_squared_error: 0.0144\n",
            "Epoch 709: val_loss did not improve from 0.01274\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0144 - mean_absolute_error: 0.0900 - mean_squared_error: 0.0144 - val_loss: 0.0150 - val_mean_absolute_error: 0.0911 - val_mean_squared_error: 0.0150\n",
            "Epoch 710/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0145 - mean_absolute_error: 0.0899 - mean_squared_error: 0.0145\n",
            "Epoch 710: val_loss did not improve from 0.01274\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0145 - mean_absolute_error: 0.0897 - mean_squared_error: 0.0145 - val_loss: 0.0139 - val_mean_absolute_error: 0.0886 - val_mean_squared_error: 0.0139\n",
            "Epoch 711/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.0142 - mean_absolute_error: 0.0891 - mean_squared_error: 0.0142\n",
            "Epoch 711: val_loss did not improve from 0.01274\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0143 - mean_absolute_error: 0.0895 - mean_squared_error: 0.0143 - val_loss: 0.0143 - val_mean_absolute_error: 0.0908 - val_mean_squared_error: 0.0143\n",
            "Epoch 712/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0139 - mean_absolute_error: 0.0880 - mean_squared_error: 0.0139\n",
            "Epoch 712: val_loss did not improve from 0.01274\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0142 - mean_absolute_error: 0.0890 - mean_squared_error: 0.0142 - val_loss: 0.0170 - val_mean_absolute_error: 0.0991 - val_mean_squared_error: 0.0170\n",
            "Epoch 713/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0148 - mean_absolute_error: 0.0911 - mean_squared_error: 0.0148\n",
            "Epoch 713: val_loss did not improve from 0.01274\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0148 - mean_absolute_error: 0.0911 - mean_squared_error: 0.0148 - val_loss: 0.0155 - val_mean_absolute_error: 0.0917 - val_mean_squared_error: 0.0155\n",
            "Epoch 714/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0145 - mean_absolute_error: 0.0898 - mean_squared_error: 0.0145\n",
            "Epoch 714: val_loss did not improve from 0.01274\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0145 - mean_absolute_error: 0.0898 - mean_squared_error: 0.0145 - val_loss: 0.0141 - val_mean_absolute_error: 0.0898 - val_mean_squared_error: 0.0141\n",
            "Epoch 715/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0143 - mean_absolute_error: 0.0895 - mean_squared_error: 0.0143\n",
            "Epoch 715: val_loss did not improve from 0.01274\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0143 - mean_absolute_error: 0.0895 - mean_squared_error: 0.0143 - val_loss: 0.0136 - val_mean_absolute_error: 0.0872 - val_mean_squared_error: 0.0136\n",
            "Epoch 716/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0139 - mean_absolute_error: 0.0881 - mean_squared_error: 0.0139\n",
            "Epoch 716: val_loss did not improve from 0.01274\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0139 - mean_absolute_error: 0.0882 - mean_squared_error: 0.0139 - val_loss: 0.0172 - val_mean_absolute_error: 0.0998 - val_mean_squared_error: 0.0172\n",
            "Epoch 717/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0140 - mean_absolute_error: 0.0885 - mean_squared_error: 0.0140\n",
            "Epoch 717: val_loss did not improve from 0.01274\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0141 - mean_absolute_error: 0.0886 - mean_squared_error: 0.0141 - val_loss: 0.0154 - val_mean_absolute_error: 0.0973 - val_mean_squared_error: 0.0154\n",
            "Epoch 718/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0140 - mean_absolute_error: 0.0886 - mean_squared_error: 0.0140\n",
            "Epoch 718: val_loss improved from 0.01274 to 0.01223, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0140 - mean_absolute_error: 0.0886 - mean_squared_error: 0.0140 - val_loss: 0.0122 - val_mean_absolute_error: 0.0812 - val_mean_squared_error: 0.0122\n",
            "Epoch 719/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0139 - mean_absolute_error: 0.0877 - mean_squared_error: 0.0139\n",
            "Epoch 719: val_loss did not improve from 0.01223\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0139 - mean_absolute_error: 0.0876 - mean_squared_error: 0.0139 - val_loss: 0.0134 - val_mean_absolute_error: 0.0872 - val_mean_squared_error: 0.0134\n",
            "Epoch 720/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0137 - mean_absolute_error: 0.0875 - mean_squared_error: 0.0137\n",
            "Epoch 720: val_loss did not improve from 0.01223\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0137 - mean_absolute_error: 0.0874 - mean_squared_error: 0.0137 - val_loss: 0.0126 - val_mean_absolute_error: 0.0817 - val_mean_squared_error: 0.0126\n",
            "Epoch 721/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0140 - mean_absolute_error: 0.0880 - mean_squared_error: 0.0140\n",
            "Epoch 721: val_loss did not improve from 0.01223\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0140 - mean_absolute_error: 0.0880 - mean_squared_error: 0.0140 - val_loss: 0.0122 - val_mean_absolute_error: 0.0814 - val_mean_squared_error: 0.0122\n",
            "Epoch 722/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0143 - mean_absolute_error: 0.0895 - mean_squared_error: 0.0143\n",
            "Epoch 722: val_loss did not improve from 0.01223\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0143 - mean_absolute_error: 0.0896 - mean_squared_error: 0.0143 - val_loss: 0.0152 - val_mean_absolute_error: 0.0941 - val_mean_squared_error: 0.0152\n",
            "Epoch 723/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0147 - mean_absolute_error: 0.0910 - mean_squared_error: 0.0147\n",
            "Epoch 723: val_loss did not improve from 0.01223\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0147 - mean_absolute_error: 0.0911 - mean_squared_error: 0.0147 - val_loss: 0.0169 - val_mean_absolute_error: 0.0975 - val_mean_squared_error: 0.0169\n",
            "Epoch 724/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0139 - mean_absolute_error: 0.0882 - mean_squared_error: 0.0139\n",
            "Epoch 724: val_loss did not improve from 0.01223\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0139 - mean_absolute_error: 0.0881 - mean_squared_error: 0.0139 - val_loss: 0.0127 - val_mean_absolute_error: 0.0820 - val_mean_squared_error: 0.0127\n",
            "Epoch 725/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0145 - mean_absolute_error: 0.0905 - mean_squared_error: 0.0145\n",
            "Epoch 725: val_loss did not improve from 0.01223\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0144 - mean_absolute_error: 0.0902 - mean_squared_error: 0.0144 - val_loss: 0.0132 - val_mean_absolute_error: 0.0859 - val_mean_squared_error: 0.0132\n",
            "Epoch 726/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.0875 - mean_squared_error: 0.0138\n",
            "Epoch 726: val_loss did not improve from 0.01223\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0139 - mean_absolute_error: 0.0877 - mean_squared_error: 0.0139 - val_loss: 0.0128 - val_mean_absolute_error: 0.0830 - val_mean_squared_error: 0.0128\n",
            "Epoch 727/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.0135 - mean_absolute_error: 0.0866 - mean_squared_error: 0.0135\n",
            "Epoch 727: val_loss improved from 0.01223 to 0.01190, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0136 - mean_absolute_error: 0.0870 - mean_squared_error: 0.0136 - val_loss: 0.0119 - val_mean_absolute_error: 0.0810 - val_mean_squared_error: 0.0119\n",
            "Epoch 728/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0142 - mean_absolute_error: 0.0888 - mean_squared_error: 0.0142\n",
            "Epoch 728: val_loss did not improve from 0.01190\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0143 - mean_absolute_error: 0.0889 - mean_squared_error: 0.0143 - val_loss: 0.0140 - val_mean_absolute_error: 0.0895 - val_mean_squared_error: 0.0140\n",
            "Epoch 729/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0142 - mean_absolute_error: 0.0888 - mean_squared_error: 0.0142\n",
            "Epoch 729: val_loss did not improve from 0.01190\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0141 - mean_absolute_error: 0.0885 - mean_squared_error: 0.0141 - val_loss: 0.0127 - val_mean_absolute_error: 0.0844 - val_mean_squared_error: 0.0127\n",
            "Epoch 730/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.0879 - mean_squared_error: 0.0138\n",
            "Epoch 730: val_loss improved from 0.01190 to 0.01169, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0138 - mean_absolute_error: 0.0881 - mean_squared_error: 0.0138 - val_loss: 0.0117 - val_mean_absolute_error: 0.0810 - val_mean_squared_error: 0.0117\n",
            "Epoch 731/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0139 - mean_absolute_error: 0.0880 - mean_squared_error: 0.0139\n",
            "Epoch 731: val_loss did not improve from 0.01169\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0138 - mean_absolute_error: 0.0879 - mean_squared_error: 0.0138 - val_loss: 0.0132 - val_mean_absolute_error: 0.0876 - val_mean_squared_error: 0.0132\n",
            "Epoch 732/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.0140 - mean_absolute_error: 0.0884 - mean_squared_error: 0.0140\n",
            "Epoch 732: val_loss did not improve from 0.01169\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0141 - mean_absolute_error: 0.0886 - mean_squared_error: 0.0141 - val_loss: 0.0168 - val_mean_absolute_error: 0.0984 - val_mean_squared_error: 0.0168\n",
            "Epoch 733/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0135 - mean_absolute_error: 0.0874 - mean_squared_error: 0.0135\n",
            "Epoch 733: val_loss did not improve from 0.01169\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0135 - mean_absolute_error: 0.0874 - mean_squared_error: 0.0135 - val_loss: 0.0121 - val_mean_absolute_error: 0.0820 - val_mean_squared_error: 0.0121\n",
            "Epoch 734/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0137 - mean_absolute_error: 0.0869 - mean_squared_error: 0.0137\n",
            "Epoch 734: val_loss did not improve from 0.01169\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0137 - mean_absolute_error: 0.0869 - mean_squared_error: 0.0137 - val_loss: 0.0130 - val_mean_absolute_error: 0.0844 - val_mean_squared_error: 0.0130\n",
            "Epoch 735/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0135 - mean_absolute_error: 0.0866 - mean_squared_error: 0.0135\n",
            "Epoch 735: val_loss did not improve from 0.01169\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0135 - mean_absolute_error: 0.0867 - mean_squared_error: 0.0135 - val_loss: 0.0133 - val_mean_absolute_error: 0.0872 - val_mean_squared_error: 0.0133\n",
            "Epoch 736/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0134 - mean_absolute_error: 0.0861 - mean_squared_error: 0.0134\n",
            "Epoch 736: val_loss did not improve from 0.01169\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0132 - mean_absolute_error: 0.0857 - mean_squared_error: 0.0132 - val_loss: 0.0118 - val_mean_absolute_error: 0.0814 - val_mean_squared_error: 0.0118\n",
            "Epoch 737/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.0131 - mean_absolute_error: 0.0849 - mean_squared_error: 0.0131\n",
            "Epoch 737: val_loss did not improve from 0.01169\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0132 - mean_absolute_error: 0.0852 - mean_squared_error: 0.0132 - val_loss: 0.0152 - val_mean_absolute_error: 0.0910 - val_mean_squared_error: 0.0152\n",
            "Epoch 738/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0144 - mean_absolute_error: 0.0888 - mean_squared_error: 0.0144\n",
            "Epoch 738: val_loss did not improve from 0.01169\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0143 - mean_absolute_error: 0.0887 - mean_squared_error: 0.0143 - val_loss: 0.0135 - val_mean_absolute_error: 0.0870 - val_mean_squared_error: 0.0135\n",
            "Epoch 739/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0132 - mean_absolute_error: 0.0855 - mean_squared_error: 0.0132\n",
            "Epoch 739: val_loss did not improve from 0.01169\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0133 - mean_absolute_error: 0.0856 - mean_squared_error: 0.0133 - val_loss: 0.0144 - val_mean_absolute_error: 0.0887 - val_mean_squared_error: 0.0144\n",
            "Epoch 740/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0134 - mean_absolute_error: 0.0862 - mean_squared_error: 0.0134\n",
            "Epoch 740: val_loss did not improve from 0.01169\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0134 - mean_absolute_error: 0.0864 - mean_squared_error: 0.0134 - val_loss: 0.0122 - val_mean_absolute_error: 0.0802 - val_mean_squared_error: 0.0122\n",
            "Epoch 741/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0139 - mean_absolute_error: 0.0883 - mean_squared_error: 0.0139\n",
            "Epoch 741: val_loss did not improve from 0.01169\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0138 - mean_absolute_error: 0.0883 - mean_squared_error: 0.0138 - val_loss: 0.0131 - val_mean_absolute_error: 0.0864 - val_mean_squared_error: 0.0131\n",
            "Epoch 742/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0135 - mean_absolute_error: 0.0869 - mean_squared_error: 0.0135\n",
            "Epoch 742: val_loss did not improve from 0.01169\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0135 - mean_absolute_error: 0.0868 - mean_squared_error: 0.0135 - val_loss: 0.0140 - val_mean_absolute_error: 0.0868 - val_mean_squared_error: 0.0140\n",
            "Epoch 743/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0134 - mean_absolute_error: 0.0864 - mean_squared_error: 0.0134\n",
            "Epoch 743: val_loss did not improve from 0.01169\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0134 - mean_absolute_error: 0.0864 - mean_squared_error: 0.0134 - val_loss: 0.0138 - val_mean_absolute_error: 0.0894 - val_mean_squared_error: 0.0138\n",
            "Epoch 744/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0145 - mean_absolute_error: 0.0894 - mean_squared_error: 0.0145\n",
            "Epoch 744: val_loss did not improve from 0.01169\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0146 - mean_absolute_error: 0.0898 - mean_squared_error: 0.0146 - val_loss: 0.0142 - val_mean_absolute_error: 0.0865 - val_mean_squared_error: 0.0142\n",
            "Epoch 745/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0135 - mean_absolute_error: 0.0872 - mean_squared_error: 0.0135\n",
            "Epoch 745: val_loss did not improve from 0.01169\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0135 - mean_absolute_error: 0.0872 - mean_squared_error: 0.0135 - val_loss: 0.0119 - val_mean_absolute_error: 0.0805 - val_mean_squared_error: 0.0119\n",
            "Epoch 746/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0133 - mean_absolute_error: 0.0858 - mean_squared_error: 0.0133\n",
            "Epoch 746: val_loss did not improve from 0.01169\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0134 - mean_absolute_error: 0.0860 - mean_squared_error: 0.0134 - val_loss: 0.0159 - val_mean_absolute_error: 0.0973 - val_mean_squared_error: 0.0159\n",
            "Epoch 747/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.0873 - mean_squared_error: 0.0138\n",
            "Epoch 747: val_loss improved from 0.01169 to 0.01152, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0137 - mean_absolute_error: 0.0872 - mean_squared_error: 0.0137 - val_loss: 0.0115 - val_mean_absolute_error: 0.0800 - val_mean_squared_error: 0.0115\n",
            "Epoch 748/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0137 - mean_absolute_error: 0.0869 - mean_squared_error: 0.0137\n",
            "Epoch 748: val_loss did not improve from 0.01152\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0136 - mean_absolute_error: 0.0869 - mean_squared_error: 0.0136 - val_loss: 0.0144 - val_mean_absolute_error: 0.0916 - val_mean_squared_error: 0.0144\n",
            "Epoch 749/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0137 - mean_absolute_error: 0.0873 - mean_squared_error: 0.0137\n",
            "Epoch 749: val_loss did not improve from 0.01152\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0137 - mean_absolute_error: 0.0872 - mean_squared_error: 0.0137 - val_loss: 0.0143 - val_mean_absolute_error: 0.0895 - val_mean_squared_error: 0.0143\n",
            "Epoch 750/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0141 - mean_absolute_error: 0.0887 - mean_squared_error: 0.0141\n",
            "Epoch 750: val_loss did not improve from 0.01152\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0141 - mean_absolute_error: 0.0887 - mean_squared_error: 0.0141 - val_loss: 0.0127 - val_mean_absolute_error: 0.0835 - val_mean_squared_error: 0.0127\n",
            "Epoch 751/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0146 - mean_absolute_error: 0.0906 - mean_squared_error: 0.0146\n",
            "Epoch 751: val_loss did not improve from 0.01152\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0144 - mean_absolute_error: 0.0899 - mean_squared_error: 0.0144 - val_loss: 0.0133 - val_mean_absolute_error: 0.0893 - val_mean_squared_error: 0.0133\n",
            "Epoch 752/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0136 - mean_absolute_error: 0.0868 - mean_squared_error: 0.0136\n",
            "Epoch 752: val_loss improved from 0.01152 to 0.01144, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0136 - mean_absolute_error: 0.0868 - mean_squared_error: 0.0136 - val_loss: 0.0114 - val_mean_absolute_error: 0.0802 - val_mean_squared_error: 0.0114\n",
            "Epoch 753/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0131 - mean_absolute_error: 0.0844 - mean_squared_error: 0.0131\n",
            "Epoch 753: val_loss did not improve from 0.01144\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0131 - mean_absolute_error: 0.0844 - mean_squared_error: 0.0131 - val_loss: 0.0115 - val_mean_absolute_error: 0.0787 - val_mean_squared_error: 0.0115\n",
            "Epoch 754/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0133 - mean_absolute_error: 0.0860 - mean_squared_error: 0.0133\n",
            "Epoch 754: val_loss did not improve from 0.01144\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0132 - mean_absolute_error: 0.0859 - mean_squared_error: 0.0132 - val_loss: 0.0141 - val_mean_absolute_error: 0.0885 - val_mean_squared_error: 0.0141\n",
            "Epoch 755/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0134 - mean_absolute_error: 0.0864 - mean_squared_error: 0.0134\n",
            "Epoch 755: val_loss did not improve from 0.01144\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0136 - mean_absolute_error: 0.0868 - mean_squared_error: 0.0136 - val_loss: 0.0137 - val_mean_absolute_error: 0.0879 - val_mean_squared_error: 0.0137\n",
            "Epoch 756/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0136 - mean_absolute_error: 0.0872 - mean_squared_error: 0.0136\n",
            "Epoch 756: val_loss did not improve from 0.01144\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0136 - mean_absolute_error: 0.0871 - mean_squared_error: 0.0136 - val_loss: 0.0125 - val_mean_absolute_error: 0.0842 - val_mean_squared_error: 0.0125\n",
            "Epoch 757/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0133 - mean_absolute_error: 0.0856 - mean_squared_error: 0.0133\n",
            "Epoch 757: val_loss did not improve from 0.01144\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0134 - mean_absolute_error: 0.0857 - mean_squared_error: 0.0134 - val_loss: 0.0133 - val_mean_absolute_error: 0.0857 - val_mean_squared_error: 0.0133\n",
            "Epoch 758/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0134 - mean_absolute_error: 0.0863 - mean_squared_error: 0.0134\n",
            "Epoch 758: val_loss did not improve from 0.01144\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0136 - mean_absolute_error: 0.0869 - mean_squared_error: 0.0136 - val_loss: 0.0183 - val_mean_absolute_error: 0.1037 - val_mean_squared_error: 0.0183\n",
            "Epoch 759/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0131 - mean_absolute_error: 0.0854 - mean_squared_error: 0.0131\n",
            "Epoch 759: val_loss did not improve from 0.01144\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0131 - mean_absolute_error: 0.0854 - mean_squared_error: 0.0131 - val_loss: 0.0124 - val_mean_absolute_error: 0.0805 - val_mean_squared_error: 0.0124\n",
            "Epoch 760/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0132 - mean_absolute_error: 0.0856 - mean_squared_error: 0.0132\n",
            "Epoch 760: val_loss did not improve from 0.01144\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0132 - mean_absolute_error: 0.0855 - mean_squared_error: 0.0132 - val_loss: 0.0125 - val_mean_absolute_error: 0.0834 - val_mean_squared_error: 0.0125\n",
            "Epoch 761/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0129 - mean_absolute_error: 0.0850 - mean_squared_error: 0.0129\n",
            "Epoch 761: val_loss did not improve from 0.01144\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0128 - mean_absolute_error: 0.0849 - mean_squared_error: 0.0128 - val_loss: 0.0128 - val_mean_absolute_error: 0.0850 - val_mean_squared_error: 0.0128\n",
            "Epoch 762/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.0129 - mean_absolute_error: 0.0849 - mean_squared_error: 0.0129\n",
            "Epoch 762: val_loss did not improve from 0.01144\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0129 - mean_absolute_error: 0.0849 - mean_squared_error: 0.0129 - val_loss: 0.0120 - val_mean_absolute_error: 0.0810 - val_mean_squared_error: 0.0120\n",
            "Epoch 763/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.0135 - mean_absolute_error: 0.0864 - mean_squared_error: 0.0135\n",
            "Epoch 763: val_loss did not improve from 0.01144\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0136 - mean_absolute_error: 0.0866 - mean_squared_error: 0.0136 - val_loss: 0.0154 - val_mean_absolute_error: 0.0947 - val_mean_squared_error: 0.0154\n",
            "Epoch 764/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.0874 - mean_squared_error: 0.0138\n",
            "Epoch 764: val_loss did not improve from 0.01144\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0137 - mean_absolute_error: 0.0873 - mean_squared_error: 0.0137 - val_loss: 0.0146 - val_mean_absolute_error: 0.0904 - val_mean_squared_error: 0.0146\n",
            "Epoch 765/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0127 - mean_absolute_error: 0.0839 - mean_squared_error: 0.0127\n",
            "Epoch 765: val_loss did not improve from 0.01144\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0127 - mean_absolute_error: 0.0838 - mean_squared_error: 0.0127 - val_loss: 0.0137 - val_mean_absolute_error: 0.0883 - val_mean_squared_error: 0.0137\n",
            "Epoch 766/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0131 - mean_absolute_error: 0.0849 - mean_squared_error: 0.0131\n",
            "Epoch 766: val_loss did not improve from 0.01144\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0130 - mean_absolute_error: 0.0847 - mean_squared_error: 0.0130 - val_loss: 0.0140 - val_mean_absolute_error: 0.0917 - val_mean_squared_error: 0.0140\n",
            "Epoch 767/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0128 - mean_absolute_error: 0.0842 - mean_squared_error: 0.0128\n",
            "Epoch 767: val_loss did not improve from 0.01144\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0127 - mean_absolute_error: 0.0841 - mean_squared_error: 0.0127 - val_loss: 0.0129 - val_mean_absolute_error: 0.0844 - val_mean_squared_error: 0.0129\n",
            "Epoch 768/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0134 - mean_absolute_error: 0.0864 - mean_squared_error: 0.0134\n",
            "Epoch 768: val_loss did not improve from 0.01144\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0134 - mean_absolute_error: 0.0864 - mean_squared_error: 0.0134 - val_loss: 0.0127 - val_mean_absolute_error: 0.0852 - val_mean_squared_error: 0.0127\n",
            "Epoch 769/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0132 - mean_absolute_error: 0.0857 - mean_squared_error: 0.0132\n",
            "Epoch 769: val_loss did not improve from 0.01144\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0132 - mean_absolute_error: 0.0856 - mean_squared_error: 0.0132 - val_loss: 0.0130 - val_mean_absolute_error: 0.0865 - val_mean_squared_error: 0.0130\n",
            "Epoch 770/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0128 - mean_absolute_error: 0.0846 - mean_squared_error: 0.0128\n",
            "Epoch 770: val_loss did not improve from 0.01144\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0128 - mean_absolute_error: 0.0846 - mean_squared_error: 0.0128 - val_loss: 0.0189 - val_mean_absolute_error: 0.1025 - val_mean_squared_error: 0.0189\n",
            "Epoch 771/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.0131 - mean_absolute_error: 0.0850 - mean_squared_error: 0.0131\n",
            "Epoch 771: val_loss did not improve from 0.01144\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0130 - mean_absolute_error: 0.0849 - mean_squared_error: 0.0130 - val_loss: 0.0129 - val_mean_absolute_error: 0.0860 - val_mean_squared_error: 0.0129\n",
            "Epoch 772/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0130 - mean_absolute_error: 0.0849 - mean_squared_error: 0.0130\n",
            "Epoch 772: val_loss did not improve from 0.01144\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0131 - mean_absolute_error: 0.0855 - mean_squared_error: 0.0131 - val_loss: 0.0185 - val_mean_absolute_error: 0.1024 - val_mean_squared_error: 0.0185\n",
            "Epoch 773/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.0130 - mean_absolute_error: 0.0840 - mean_squared_error: 0.0130\n",
            "Epoch 773: val_loss did not improve from 0.01144\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0130 - mean_absolute_error: 0.0842 - mean_squared_error: 0.0130 - val_loss: 0.0124 - val_mean_absolute_error: 0.0841 - val_mean_squared_error: 0.0124\n",
            "Epoch 774/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.0125 - mean_absolute_error: 0.0829 - mean_squared_error: 0.0125\n",
            "Epoch 774: val_loss improved from 0.01144 to 0.01107, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0124 - mean_absolute_error: 0.0827 - mean_squared_error: 0.0124 - val_loss: 0.0111 - val_mean_absolute_error: 0.0787 - val_mean_squared_error: 0.0111\n",
            "Epoch 775/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0134 - mean_absolute_error: 0.0865 - mean_squared_error: 0.0134\n",
            "Epoch 775: val_loss did not improve from 0.01107\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0135 - mean_absolute_error: 0.0872 - mean_squared_error: 0.0135 - val_loss: 0.0131 - val_mean_absolute_error: 0.0848 - val_mean_squared_error: 0.0131\n",
            "Epoch 776/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0129 - mean_absolute_error: 0.0843 - mean_squared_error: 0.0129\n",
            "Epoch 776: val_loss improved from 0.01107 to 0.01064, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0127 - mean_absolute_error: 0.0837 - mean_squared_error: 0.0127 - val_loss: 0.0106 - val_mean_absolute_error: 0.0758 - val_mean_squared_error: 0.0106\n",
            "Epoch 777/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0131 - mean_absolute_error: 0.0860 - mean_squared_error: 0.0131\n",
            "Epoch 777: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0131 - mean_absolute_error: 0.0856 - mean_squared_error: 0.0131 - val_loss: 0.0124 - val_mean_absolute_error: 0.0827 - val_mean_squared_error: 0.0124\n",
            "Epoch 778/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0124 - mean_absolute_error: 0.0835 - mean_squared_error: 0.0124\n",
            "Epoch 778: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0124 - mean_absolute_error: 0.0834 - mean_squared_error: 0.0124 - val_loss: 0.0110 - val_mean_absolute_error: 0.0771 - val_mean_squared_error: 0.0110\n",
            "Epoch 779/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0131 - mean_absolute_error: 0.0850 - mean_squared_error: 0.0131\n",
            "Epoch 779: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0131 - mean_absolute_error: 0.0850 - mean_squared_error: 0.0131 - val_loss: 0.0127 - val_mean_absolute_error: 0.0849 - val_mean_squared_error: 0.0127\n",
            "Epoch 780/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.0124 - mean_absolute_error: 0.0826 - mean_squared_error: 0.0124\n",
            "Epoch 780: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0125 - mean_absolute_error: 0.0831 - mean_squared_error: 0.0125 - val_loss: 0.0126 - val_mean_absolute_error: 0.0828 - val_mean_squared_error: 0.0126\n",
            "Epoch 781/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0126 - mean_absolute_error: 0.0839 - mean_squared_error: 0.0126\n",
            "Epoch 781: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0125 - mean_absolute_error: 0.0837 - mean_squared_error: 0.0125 - val_loss: 0.0121 - val_mean_absolute_error: 0.0839 - val_mean_squared_error: 0.0121\n",
            "Epoch 782/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0129 - mean_absolute_error: 0.0841 - mean_squared_error: 0.0129\n",
            "Epoch 782: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0129 - mean_absolute_error: 0.0844 - mean_squared_error: 0.0129 - val_loss: 0.0142 - val_mean_absolute_error: 0.0890 - val_mean_squared_error: 0.0142\n",
            "Epoch 783/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0125 - mean_absolute_error: 0.0831 - mean_squared_error: 0.0125\n",
            "Epoch 783: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0125 - mean_absolute_error: 0.0832 - mean_squared_error: 0.0125 - val_loss: 0.0131 - val_mean_absolute_error: 0.0870 - val_mean_squared_error: 0.0131\n",
            "Epoch 784/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.0126 - mean_absolute_error: 0.0833 - mean_squared_error: 0.0126\n",
            "Epoch 784: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0127 - mean_absolute_error: 0.0833 - mean_squared_error: 0.0127 - val_loss: 0.0124 - val_mean_absolute_error: 0.0836 - val_mean_squared_error: 0.0124\n",
            "Epoch 785/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0125 - mean_absolute_error: 0.0832 - mean_squared_error: 0.0125\n",
            "Epoch 785: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0124 - mean_absolute_error: 0.0828 - mean_squared_error: 0.0124 - val_loss: 0.0123 - val_mean_absolute_error: 0.0814 - val_mean_squared_error: 0.0123\n",
            "Epoch 786/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0123 - mean_absolute_error: 0.0822 - mean_squared_error: 0.0123\n",
            "Epoch 786: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0122 - mean_absolute_error: 0.0820 - mean_squared_error: 0.0122 - val_loss: 0.0115 - val_mean_absolute_error: 0.0812 - val_mean_squared_error: 0.0115\n",
            "Epoch 787/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0120 - mean_absolute_error: 0.0816 - mean_squared_error: 0.0120\n",
            "Epoch 787: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0120 - mean_absolute_error: 0.0816 - mean_squared_error: 0.0120 - val_loss: 0.0150 - val_mean_absolute_error: 0.0943 - val_mean_squared_error: 0.0150\n",
            "Epoch 788/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0129 - mean_absolute_error: 0.0844 - mean_squared_error: 0.0129\n",
            "Epoch 788: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0129 - mean_absolute_error: 0.0842 - mean_squared_error: 0.0129 - val_loss: 0.0109 - val_mean_absolute_error: 0.0777 - val_mean_squared_error: 0.0109\n",
            "Epoch 789/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.0127 - mean_absolute_error: 0.0830 - mean_squared_error: 0.0127\n",
            "Epoch 789: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0126 - mean_absolute_error: 0.0827 - mean_squared_error: 0.0126 - val_loss: 0.0127 - val_mean_absolute_error: 0.0809 - val_mean_squared_error: 0.0127\n",
            "Epoch 790/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0123 - mean_absolute_error: 0.0820 - mean_squared_error: 0.0123\n",
            "Epoch 790: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0122 - mean_absolute_error: 0.0815 - mean_squared_error: 0.0122 - val_loss: 0.0111 - val_mean_absolute_error: 0.0779 - val_mean_squared_error: 0.0111\n",
            "Epoch 791/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0123 - mean_absolute_error: 0.0825 - mean_squared_error: 0.0123\n",
            "Epoch 791: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0123 - mean_absolute_error: 0.0825 - mean_squared_error: 0.0123 - val_loss: 0.0159 - val_mean_absolute_error: 0.0916 - val_mean_squared_error: 0.0159\n",
            "Epoch 792/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0127 - mean_absolute_error: 0.0841 - mean_squared_error: 0.0127\n",
            "Epoch 792: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0127 - mean_absolute_error: 0.0843 - mean_squared_error: 0.0127 - val_loss: 0.0124 - val_mean_absolute_error: 0.0832 - val_mean_squared_error: 0.0124\n",
            "Epoch 793/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0119 - mean_absolute_error: 0.0806 - mean_squared_error: 0.0119\n",
            "Epoch 793: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0119 - mean_absolute_error: 0.0807 - mean_squared_error: 0.0119 - val_loss: 0.0133 - val_mean_absolute_error: 0.0846 - val_mean_squared_error: 0.0133\n",
            "Epoch 794/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0123 - mean_absolute_error: 0.0825 - mean_squared_error: 0.0123\n",
            "Epoch 794: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0123 - mean_absolute_error: 0.0824 - mean_squared_error: 0.0123 - val_loss: 0.0123 - val_mean_absolute_error: 0.0822 - val_mean_squared_error: 0.0123\n",
            "Epoch 795/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0127 - mean_absolute_error: 0.0847 - mean_squared_error: 0.0127\n",
            "Epoch 795: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0126 - mean_absolute_error: 0.0843 - mean_squared_error: 0.0126 - val_loss: 0.0112 - val_mean_absolute_error: 0.0796 - val_mean_squared_error: 0.0112\n",
            "Epoch 796/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0124 - mean_absolute_error: 0.0831 - mean_squared_error: 0.0124\n",
            "Epoch 796: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0124 - mean_absolute_error: 0.0831 - mean_squared_error: 0.0124 - val_loss: 0.0121 - val_mean_absolute_error: 0.0818 - val_mean_squared_error: 0.0121\n",
            "Epoch 797/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0118 - mean_absolute_error: 0.0808 - mean_squared_error: 0.0118\n",
            "Epoch 797: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0118 - mean_absolute_error: 0.0807 - mean_squared_error: 0.0118 - val_loss: 0.0127 - val_mean_absolute_error: 0.0851 - val_mean_squared_error: 0.0127\n",
            "Epoch 798/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.0126 - mean_absolute_error: 0.0841 - mean_squared_error: 0.0126\n",
            "Epoch 798: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0127 - mean_absolute_error: 0.0840 - mean_squared_error: 0.0127 - val_loss: 0.0115 - val_mean_absolute_error: 0.0794 - val_mean_squared_error: 0.0115\n",
            "Epoch 799/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.0122 - mean_absolute_error: 0.0822 - mean_squared_error: 0.0122\n",
            "Epoch 799: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0121 - mean_absolute_error: 0.0819 - mean_squared_error: 0.0121 - val_loss: 0.0113 - val_mean_absolute_error: 0.0799 - val_mean_squared_error: 0.0113\n",
            "Epoch 800/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0119 - mean_absolute_error: 0.0804 - mean_squared_error: 0.0119\n",
            "Epoch 800: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0119 - mean_absolute_error: 0.0806 - mean_squared_error: 0.0119 - val_loss: 0.0126 - val_mean_absolute_error: 0.0818 - val_mean_squared_error: 0.0126\n",
            "Epoch 801/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 0.0121 - mean_absolute_error: 0.0818 - mean_squared_error: 0.0121\n",
            "Epoch 801: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0120 - mean_absolute_error: 0.0816 - mean_squared_error: 0.0120 - val_loss: 0.0114 - val_mean_absolute_error: 0.0785 - val_mean_squared_error: 0.0114\n",
            "Epoch 802/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0125 - mean_absolute_error: 0.0826 - mean_squared_error: 0.0125\n",
            "Epoch 802: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0125 - mean_absolute_error: 0.0826 - mean_squared_error: 0.0125 - val_loss: 0.0114 - val_mean_absolute_error: 0.0802 - val_mean_squared_error: 0.0114\n",
            "Epoch 803/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.0126 - mean_absolute_error: 0.0825 - mean_squared_error: 0.0126\n",
            "Epoch 803: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0126 - mean_absolute_error: 0.0827 - mean_squared_error: 0.0126 - val_loss: 0.0125 - val_mean_absolute_error: 0.0859 - val_mean_squared_error: 0.0125\n",
            "Epoch 804/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.0125 - mean_absolute_error: 0.0832 - mean_squared_error: 0.0125\n",
            "Epoch 804: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0124 - mean_absolute_error: 0.0830 - mean_squared_error: 0.0124 - val_loss: 0.0131 - val_mean_absolute_error: 0.0885 - val_mean_squared_error: 0.0131\n",
            "Epoch 805/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0126 - mean_absolute_error: 0.0823 - mean_squared_error: 0.0126\n",
            "Epoch 805: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0126 - mean_absolute_error: 0.0825 - mean_squared_error: 0.0126 - val_loss: 0.0119 - val_mean_absolute_error: 0.0803 - val_mean_squared_error: 0.0119\n",
            "Epoch 806/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0116 - mean_absolute_error: 0.0802 - mean_squared_error: 0.0116\n",
            "Epoch 806: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0116 - mean_absolute_error: 0.0801 - mean_squared_error: 0.0116 - val_loss: 0.0122 - val_mean_absolute_error: 0.0822 - val_mean_squared_error: 0.0122\n",
            "Epoch 807/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0123 - mean_absolute_error: 0.0818 - mean_squared_error: 0.0123\n",
            "Epoch 807: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0123 - mean_absolute_error: 0.0818 - mean_squared_error: 0.0123 - val_loss: 0.0150 - val_mean_absolute_error: 0.0926 - val_mean_squared_error: 0.0150\n",
            "Epoch 808/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0117 - mean_absolute_error: 0.0798 - mean_squared_error: 0.0117\n",
            "Epoch 808: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0117 - mean_absolute_error: 0.0797 - mean_squared_error: 0.0117 - val_loss: 0.0108 - val_mean_absolute_error: 0.0773 - val_mean_squared_error: 0.0108\n",
            "Epoch 809/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0121 - mean_absolute_error: 0.0818 - mean_squared_error: 0.0121\n",
            "Epoch 809: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0119 - mean_absolute_error: 0.0814 - mean_squared_error: 0.0119 - val_loss: 0.0112 - val_mean_absolute_error: 0.0770 - val_mean_squared_error: 0.0112\n",
            "Epoch 810/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.0124 - mean_absolute_error: 0.0833 - mean_squared_error: 0.0124\n",
            "Epoch 810: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0122 - mean_absolute_error: 0.0827 - mean_squared_error: 0.0122 - val_loss: 0.0107 - val_mean_absolute_error: 0.0777 - val_mean_squared_error: 0.0107\n",
            "Epoch 811/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0119 - mean_absolute_error: 0.0809 - mean_squared_error: 0.0119\n",
            "Epoch 811: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0120 - mean_absolute_error: 0.0809 - mean_squared_error: 0.0120 - val_loss: 0.0131 - val_mean_absolute_error: 0.0857 - val_mean_squared_error: 0.0131\n",
            "Epoch 812/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0124 - mean_absolute_error: 0.0830 - mean_squared_error: 0.0124\n",
            "Epoch 812: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0124 - mean_absolute_error: 0.0830 - mean_squared_error: 0.0124 - val_loss: 0.0113 - val_mean_absolute_error: 0.0781 - val_mean_squared_error: 0.0113\n",
            "Epoch 813/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0122 - mean_absolute_error: 0.0824 - mean_squared_error: 0.0122\n",
            "Epoch 813: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0122 - mean_absolute_error: 0.0821 - mean_squared_error: 0.0122 - val_loss: 0.0134 - val_mean_absolute_error: 0.0852 - val_mean_squared_error: 0.0134\n",
            "Epoch 814/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0118 - mean_absolute_error: 0.0807 - mean_squared_error: 0.0118\n",
            "Epoch 814: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0118 - mean_absolute_error: 0.0807 - mean_squared_error: 0.0118 - val_loss: 0.0111 - val_mean_absolute_error: 0.0799 - val_mean_squared_error: 0.0111\n",
            "Epoch 815/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0121 - mean_absolute_error: 0.0818 - mean_squared_error: 0.0121\n",
            "Epoch 815: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0121 - mean_absolute_error: 0.0817 - mean_squared_error: 0.0121 - val_loss: 0.0124 - val_mean_absolute_error: 0.0824 - val_mean_squared_error: 0.0124\n",
            "Epoch 816/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0122 - mean_absolute_error: 0.0825 - mean_squared_error: 0.0122\n",
            "Epoch 816: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0122 - mean_absolute_error: 0.0825 - mean_squared_error: 0.0122 - val_loss: 0.0119 - val_mean_absolute_error: 0.0815 - val_mean_squared_error: 0.0119\n",
            "Epoch 817/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0121 - mean_absolute_error: 0.0818 - mean_squared_error: 0.0121\n",
            "Epoch 817: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0122 - mean_absolute_error: 0.0820 - mean_squared_error: 0.0122 - val_loss: 0.0119 - val_mean_absolute_error: 0.0804 - val_mean_squared_error: 0.0119\n",
            "Epoch 818/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0122 - mean_absolute_error: 0.0817 - mean_squared_error: 0.0122\n",
            "Epoch 818: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0121 - mean_absolute_error: 0.0817 - mean_squared_error: 0.0121 - val_loss: 0.0127 - val_mean_absolute_error: 0.0847 - val_mean_squared_error: 0.0127\n",
            "Epoch 819/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0117 - mean_absolute_error: 0.0803 - mean_squared_error: 0.0117\n",
            "Epoch 819: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0118 - mean_absolute_error: 0.0805 - mean_squared_error: 0.0118 - val_loss: 0.0128 - val_mean_absolute_error: 0.0837 - val_mean_squared_error: 0.0128\n",
            "Epoch 820/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0114 - mean_absolute_error: 0.0792 - mean_squared_error: 0.0114\n",
            "Epoch 820: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0114 - mean_absolute_error: 0.0791 - mean_squared_error: 0.0114 - val_loss: 0.0130 - val_mean_absolute_error: 0.0836 - val_mean_squared_error: 0.0130\n",
            "Epoch 821/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0118 - mean_absolute_error: 0.0809 - mean_squared_error: 0.0118\n",
            "Epoch 821: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0118 - mean_absolute_error: 0.0809 - mean_squared_error: 0.0118 - val_loss: 0.0127 - val_mean_absolute_error: 0.0857 - val_mean_squared_error: 0.0127\n",
            "Epoch 822/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0119 - mean_absolute_error: 0.0811 - mean_squared_error: 0.0119\n",
            "Epoch 822: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0119 - mean_absolute_error: 0.0811 - mean_squared_error: 0.0119 - val_loss: 0.0115 - val_mean_absolute_error: 0.0833 - val_mean_squared_error: 0.0115\n",
            "Epoch 823/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.0119 - mean_absolute_error: 0.0805 - mean_squared_error: 0.0119\n",
            "Epoch 823: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0120 - mean_absolute_error: 0.0809 - mean_squared_error: 0.0120 - val_loss: 0.0127 - val_mean_absolute_error: 0.0850 - val_mean_squared_error: 0.0127\n",
            "Epoch 824/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0117 - mean_absolute_error: 0.0806 - mean_squared_error: 0.0117\n",
            "Epoch 824: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0118 - mean_absolute_error: 0.0809 - mean_squared_error: 0.0118 - val_loss: 0.0136 - val_mean_absolute_error: 0.0820 - val_mean_squared_error: 0.0136\n",
            "Epoch 825/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0118 - mean_absolute_error: 0.0804 - mean_squared_error: 0.0118\n",
            "Epoch 825: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0117 - mean_absolute_error: 0.0802 - mean_squared_error: 0.0117 - val_loss: 0.0114 - val_mean_absolute_error: 0.0782 - val_mean_squared_error: 0.0114\n",
            "Epoch 826/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0121 - mean_absolute_error: 0.0809 - mean_squared_error: 0.0121\n",
            "Epoch 826: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0121 - mean_absolute_error: 0.0809 - mean_squared_error: 0.0121 - val_loss: 0.0113 - val_mean_absolute_error: 0.0800 - val_mean_squared_error: 0.0113\n",
            "Epoch 827/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0117 - mean_absolute_error: 0.0809 - mean_squared_error: 0.0117\n",
            "Epoch 827: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0117 - mean_absolute_error: 0.0808 - mean_squared_error: 0.0117 - val_loss: 0.0127 - val_mean_absolute_error: 0.0862 - val_mean_squared_error: 0.0127\n",
            "Epoch 828/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0114 - mean_absolute_error: 0.0792 - mean_squared_error: 0.0114\n",
            "Epoch 828: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0115 - mean_absolute_error: 0.0792 - mean_squared_error: 0.0115 - val_loss: 0.0123 - val_mean_absolute_error: 0.0827 - val_mean_squared_error: 0.0123\n",
            "Epoch 829/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.0121 - mean_absolute_error: 0.0816 - mean_squared_error: 0.0121\n",
            "Epoch 829: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0121 - mean_absolute_error: 0.0814 - mean_squared_error: 0.0121 - val_loss: 0.0127 - val_mean_absolute_error: 0.0861 - val_mean_squared_error: 0.0127\n",
            "Epoch 830/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0115 - mean_absolute_error: 0.0795 - mean_squared_error: 0.0115\n",
            "Epoch 830: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0115 - mean_absolute_error: 0.0795 - mean_squared_error: 0.0115 - val_loss: 0.0119 - val_mean_absolute_error: 0.0810 - val_mean_squared_error: 0.0119\n",
            "Epoch 831/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0117 - mean_absolute_error: 0.0798 - mean_squared_error: 0.0117\n",
            "Epoch 831: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0118 - mean_absolute_error: 0.0802 - mean_squared_error: 0.0118 - val_loss: 0.0121 - val_mean_absolute_error: 0.0827 - val_mean_squared_error: 0.0121\n",
            "Epoch 832/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0117 - mean_absolute_error: 0.0802 - mean_squared_error: 0.0117\n",
            "Epoch 832: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0118 - mean_absolute_error: 0.0805 - mean_squared_error: 0.0118 - val_loss: 0.0130 - val_mean_absolute_error: 0.0860 - val_mean_squared_error: 0.0130\n",
            "Epoch 833/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0118 - mean_absolute_error: 0.0809 - mean_squared_error: 0.0118\n",
            "Epoch 833: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0118 - mean_absolute_error: 0.0810 - mean_squared_error: 0.0118 - val_loss: 0.0116 - val_mean_absolute_error: 0.0808 - val_mean_squared_error: 0.0116\n",
            "Epoch 834/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0121 - mean_absolute_error: 0.0820 - mean_squared_error: 0.0121\n",
            "Epoch 834: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0120 - mean_absolute_error: 0.0817 - mean_squared_error: 0.0120 - val_loss: 0.0129 - val_mean_absolute_error: 0.0834 - val_mean_squared_error: 0.0129\n",
            "Epoch 835/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0116 - mean_absolute_error: 0.0800 - mean_squared_error: 0.0116\n",
            "Epoch 835: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0116 - mean_absolute_error: 0.0799 - mean_squared_error: 0.0116 - val_loss: 0.0115 - val_mean_absolute_error: 0.0787 - val_mean_squared_error: 0.0115\n",
            "Epoch 836/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0119 - mean_absolute_error: 0.0811 - mean_squared_error: 0.0119\n",
            "Epoch 836: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0119 - mean_absolute_error: 0.0810 - mean_squared_error: 0.0119 - val_loss: 0.0119 - val_mean_absolute_error: 0.0800 - val_mean_squared_error: 0.0119\n",
            "Epoch 837/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0117 - mean_absolute_error: 0.0800 - mean_squared_error: 0.0117\n",
            "Epoch 837: val_loss did not improve from 0.01064\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0116 - mean_absolute_error: 0.0796 - mean_squared_error: 0.0116 - val_loss: 0.0122 - val_mean_absolute_error: 0.0801 - val_mean_squared_error: 0.0122\n",
            "Epoch 838/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0113 - mean_absolute_error: 0.0782 - mean_squared_error: 0.0113\n",
            "Epoch 838: val_loss improved from 0.01064 to 0.01052, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0114 - mean_absolute_error: 0.0784 - mean_squared_error: 0.0114 - val_loss: 0.0105 - val_mean_absolute_error: 0.0743 - val_mean_squared_error: 0.0105\n",
            "Epoch 839/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0117 - mean_absolute_error: 0.0812 - mean_squared_error: 0.0117\n",
            "Epoch 839: val_loss did not improve from 0.01052\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0117 - mean_absolute_error: 0.0812 - mean_squared_error: 0.0117 - val_loss: 0.0115 - val_mean_absolute_error: 0.0815 - val_mean_squared_error: 0.0115\n",
            "Epoch 840/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0116 - mean_absolute_error: 0.0800 - mean_squared_error: 0.0116\n",
            "Epoch 840: val_loss improved from 0.01052 to 0.01046, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0116 - mean_absolute_error: 0.0798 - mean_squared_error: 0.0116 - val_loss: 0.0105 - val_mean_absolute_error: 0.0740 - val_mean_squared_error: 0.0105\n",
            "Epoch 841/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0120 - mean_absolute_error: 0.0816 - mean_squared_error: 0.0120\n",
            "Epoch 841: val_loss did not improve from 0.01046\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0119 - mean_absolute_error: 0.0816 - mean_squared_error: 0.0119 - val_loss: 0.0117 - val_mean_absolute_error: 0.0779 - val_mean_squared_error: 0.0117\n",
            "Epoch 842/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0116 - mean_absolute_error: 0.0798 - mean_squared_error: 0.0116\n",
            "Epoch 842: val_loss did not improve from 0.01046\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0116 - mean_absolute_error: 0.0798 - mean_squared_error: 0.0116 - val_loss: 0.0115 - val_mean_absolute_error: 0.0804 - val_mean_squared_error: 0.0115\n",
            "Epoch 843/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0116 - mean_absolute_error: 0.0803 - mean_squared_error: 0.0116\n",
            "Epoch 843: val_loss did not improve from 0.01046\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0115 - mean_absolute_error: 0.0801 - mean_squared_error: 0.0115 - val_loss: 0.0106 - val_mean_absolute_error: 0.0766 - val_mean_squared_error: 0.0106\n",
            "Epoch 844/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0117 - mean_absolute_error: 0.0813 - mean_squared_error: 0.0117\n",
            "Epoch 844: val_loss did not improve from 0.01046\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0117 - mean_absolute_error: 0.0814 - mean_squared_error: 0.0117 - val_loss: 0.0119 - val_mean_absolute_error: 0.0816 - val_mean_squared_error: 0.0119\n",
            "Epoch 845/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0118 - mean_absolute_error: 0.0805 - mean_squared_error: 0.0118\n",
            "Epoch 845: val_loss did not improve from 0.01046\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0118 - mean_absolute_error: 0.0805 - mean_squared_error: 0.0118 - val_loss: 0.0128 - val_mean_absolute_error: 0.0860 - val_mean_squared_error: 0.0128\n",
            "Epoch 846/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0120 - mean_absolute_error: 0.0811 - mean_squared_error: 0.0120\n",
            "Epoch 846: val_loss did not improve from 0.01046\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0121 - mean_absolute_error: 0.0815 - mean_squared_error: 0.0121 - val_loss: 0.0124 - val_mean_absolute_error: 0.0840 - val_mean_squared_error: 0.0124\n",
            "Epoch 847/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0116 - mean_absolute_error: 0.0802 - mean_squared_error: 0.0116\n",
            "Epoch 847: val_loss did not improve from 0.01046\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0116 - mean_absolute_error: 0.0804 - mean_squared_error: 0.0116 - val_loss: 0.0113 - val_mean_absolute_error: 0.0789 - val_mean_squared_error: 0.0113\n",
            "Epoch 848/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0117 - mean_absolute_error: 0.0801 - mean_squared_error: 0.0117\n",
            "Epoch 848: val_loss did not improve from 0.01046\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0116 - mean_absolute_error: 0.0801 - mean_squared_error: 0.0116 - val_loss: 0.0110 - val_mean_absolute_error: 0.0770 - val_mean_squared_error: 0.0110\n",
            "Epoch 849/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0112 - mean_absolute_error: 0.0781 - mean_squared_error: 0.0112\n",
            "Epoch 849: val_loss did not improve from 0.01046\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0112 - mean_absolute_error: 0.0782 - mean_squared_error: 0.0112 - val_loss: 0.0112 - val_mean_absolute_error: 0.0783 - val_mean_squared_error: 0.0112\n",
            "Epoch 850/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0114 - mean_absolute_error: 0.0784 - mean_squared_error: 0.0114\n",
            "Epoch 850: val_loss did not improve from 0.01046\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0114 - mean_absolute_error: 0.0787 - mean_squared_error: 0.0114 - val_loss: 0.0154 - val_mean_absolute_error: 0.0983 - val_mean_squared_error: 0.0154\n",
            "Epoch 851/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0111 - mean_absolute_error: 0.0780 - mean_squared_error: 0.0111\n",
            "Epoch 851: val_loss did not improve from 0.01046\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0112 - mean_absolute_error: 0.0783 - mean_squared_error: 0.0112 - val_loss: 0.0139 - val_mean_absolute_error: 0.0893 - val_mean_squared_error: 0.0139\n",
            "Epoch 852/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.0118 - mean_absolute_error: 0.0812 - mean_squared_error: 0.0118\n",
            "Epoch 852: val_loss did not improve from 0.01046\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0119 - mean_absolute_error: 0.0818 - mean_squared_error: 0.0119 - val_loss: 0.0123 - val_mean_absolute_error: 0.0829 - val_mean_squared_error: 0.0123\n",
            "Epoch 853/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0113 - mean_absolute_error: 0.0787 - mean_squared_error: 0.0113\n",
            "Epoch 853: val_loss did not improve from 0.01046\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0113 - mean_absolute_error: 0.0784 - mean_squared_error: 0.0113 - val_loss: 0.0110 - val_mean_absolute_error: 0.0790 - val_mean_squared_error: 0.0110\n",
            "Epoch 854/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0115 - mean_absolute_error: 0.0799 - mean_squared_error: 0.0115\n",
            "Epoch 854: val_loss improved from 0.01046 to 0.01035, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0114 - mean_absolute_error: 0.0795 - mean_squared_error: 0.0114 - val_loss: 0.0104 - val_mean_absolute_error: 0.0764 - val_mean_squared_error: 0.0104\n",
            "Epoch 855/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0117 - mean_absolute_error: 0.0801 - mean_squared_error: 0.0117\n",
            "Epoch 855: val_loss did not improve from 0.01035\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0116 - mean_absolute_error: 0.0797 - mean_squared_error: 0.0116 - val_loss: 0.0105 - val_mean_absolute_error: 0.0735 - val_mean_squared_error: 0.0105\n",
            "Epoch 856/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0120 - mean_absolute_error: 0.0812 - mean_squared_error: 0.0120\n",
            "Epoch 856: val_loss did not improve from 0.01035\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0121 - mean_absolute_error: 0.0816 - mean_squared_error: 0.0121 - val_loss: 0.0128 - val_mean_absolute_error: 0.0868 - val_mean_squared_error: 0.0128\n",
            "Epoch 857/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0116 - mean_absolute_error: 0.0799 - mean_squared_error: 0.0116\n",
            "Epoch 857: val_loss improved from 0.01035 to 0.01035, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0116 - mean_absolute_error: 0.0799 - mean_squared_error: 0.0116 - val_loss: 0.0104 - val_mean_absolute_error: 0.0756 - val_mean_squared_error: 0.0104\n",
            "Epoch 858/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0112 - mean_absolute_error: 0.0781 - mean_squared_error: 0.0112\n",
            "Epoch 858: val_loss did not improve from 0.01035\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0111 - mean_absolute_error: 0.0778 - mean_squared_error: 0.0111 - val_loss: 0.0119 - val_mean_absolute_error: 0.0818 - val_mean_squared_error: 0.0119\n",
            "Epoch 859/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0115 - mean_absolute_error: 0.0801 - mean_squared_error: 0.0115\n",
            "Epoch 859: val_loss did not improve from 0.01035\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0115 - mean_absolute_error: 0.0801 - mean_squared_error: 0.0115 - val_loss: 0.0110 - val_mean_absolute_error: 0.0770 - val_mean_squared_error: 0.0110\n",
            "Epoch 860/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0110 - mean_absolute_error: 0.0785 - mean_squared_error: 0.0110\n",
            "Epoch 860: val_loss did not improve from 0.01035\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0112 - mean_absolute_error: 0.0791 - mean_squared_error: 0.0112 - val_loss: 0.0118 - val_mean_absolute_error: 0.0843 - val_mean_squared_error: 0.0118\n",
            "Epoch 861/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0119 - mean_absolute_error: 0.0802 - mean_squared_error: 0.0119\n",
            "Epoch 861: val_loss did not improve from 0.01035\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0120 - mean_absolute_error: 0.0806 - mean_squared_error: 0.0120 - val_loss: 0.0120 - val_mean_absolute_error: 0.0816 - val_mean_squared_error: 0.0120\n",
            "Epoch 862/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0111 - mean_absolute_error: 0.0775 - mean_squared_error: 0.0111\n",
            "Epoch 862: val_loss did not improve from 0.01035\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0111 - mean_absolute_error: 0.0776 - mean_squared_error: 0.0111 - val_loss: 0.0132 - val_mean_absolute_error: 0.0882 - val_mean_squared_error: 0.0132\n",
            "Epoch 863/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0112 - mean_absolute_error: 0.0787 - mean_squared_error: 0.0112\n",
            "Epoch 863: val_loss did not improve from 0.01035\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0114 - mean_absolute_error: 0.0792 - mean_squared_error: 0.0114 - val_loss: 0.0119 - val_mean_absolute_error: 0.0821 - val_mean_squared_error: 0.0119\n",
            "Epoch 864/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0111 - mean_absolute_error: 0.0782 - mean_squared_error: 0.0111\n",
            "Epoch 864: val_loss improved from 0.01035 to 0.00982, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0112 - mean_absolute_error: 0.0783 - mean_squared_error: 0.0112 - val_loss: 0.0098 - val_mean_absolute_error: 0.0739 - val_mean_squared_error: 0.0098\n",
            "Epoch 865/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0109 - mean_absolute_error: 0.0776 - mean_squared_error: 0.0109\n",
            "Epoch 865: val_loss did not improve from 0.00982\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0110 - mean_absolute_error: 0.0778 - mean_squared_error: 0.0110 - val_loss: 0.0103 - val_mean_absolute_error: 0.0752 - val_mean_squared_error: 0.0103\n",
            "Epoch 866/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0115 - mean_absolute_error: 0.0797 - mean_squared_error: 0.0115\n",
            "Epoch 866: val_loss did not improve from 0.00982\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0113 - mean_absolute_error: 0.0791 - mean_squared_error: 0.0113 - val_loss: 0.0115 - val_mean_absolute_error: 0.0763 - val_mean_squared_error: 0.0115\n",
            "Epoch 867/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0111 - mean_absolute_error: 0.0775 - mean_squared_error: 0.0111\n",
            "Epoch 867: val_loss did not improve from 0.00982\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0112 - mean_absolute_error: 0.0782 - mean_squared_error: 0.0112 - val_loss: 0.0120 - val_mean_absolute_error: 0.0801 - val_mean_squared_error: 0.0120\n",
            "Epoch 868/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0109 - mean_absolute_error: 0.0771 - mean_squared_error: 0.0109\n",
            "Epoch 868: val_loss did not improve from 0.00982\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0110 - mean_absolute_error: 0.0774 - mean_squared_error: 0.0110 - val_loss: 0.0127 - val_mean_absolute_error: 0.0857 - val_mean_squared_error: 0.0127\n",
            "Epoch 869/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0113 - mean_absolute_error: 0.0792 - mean_squared_error: 0.0113\n",
            "Epoch 869: val_loss did not improve from 0.00982\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0113 - mean_absolute_error: 0.0792 - mean_squared_error: 0.0113 - val_loss: 0.0129 - val_mean_absolute_error: 0.0831 - val_mean_squared_error: 0.0129\n",
            "Epoch 870/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0113 - mean_absolute_error: 0.0786 - mean_squared_error: 0.0113\n",
            "Epoch 870: val_loss did not improve from 0.00982\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0113 - mean_absolute_error: 0.0786 - mean_squared_error: 0.0113 - val_loss: 0.0105 - val_mean_absolute_error: 0.0754 - val_mean_squared_error: 0.0105\n",
            "Epoch 871/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.0119 - mean_absolute_error: 0.0819 - mean_squared_error: 0.0119\n",
            "Epoch 871: val_loss did not improve from 0.00982\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0119 - mean_absolute_error: 0.0818 - mean_squared_error: 0.0119 - val_loss: 0.0104 - val_mean_absolute_error: 0.0747 - val_mean_squared_error: 0.0104\n",
            "Epoch 872/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0112 - mean_absolute_error: 0.0781 - mean_squared_error: 0.0112\n",
            "Epoch 872: val_loss did not improve from 0.00982\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0112 - mean_absolute_error: 0.0781 - mean_squared_error: 0.0112 - val_loss: 0.0107 - val_mean_absolute_error: 0.0780 - val_mean_squared_error: 0.0107\n",
            "Epoch 873/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0109 - mean_absolute_error: 0.0774 - mean_squared_error: 0.0109\n",
            "Epoch 873: val_loss did not improve from 0.00982\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0109 - mean_absolute_error: 0.0773 - mean_squared_error: 0.0109 - val_loss: 0.0115 - val_mean_absolute_error: 0.0801 - val_mean_squared_error: 0.0115\n",
            "Epoch 874/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.0112 - mean_absolute_error: 0.0788 - mean_squared_error: 0.0112\n",
            "Epoch 874: val_loss improved from 0.00982 to 0.00959, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0112 - mean_absolute_error: 0.0788 - mean_squared_error: 0.0112 - val_loss: 0.0096 - val_mean_absolute_error: 0.0720 - val_mean_squared_error: 0.0096\n",
            "Epoch 875/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0104 - mean_absolute_error: 0.0761 - mean_squared_error: 0.0104\n",
            "Epoch 875: val_loss did not improve from 0.00959\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0106 - mean_absolute_error: 0.0768 - mean_squared_error: 0.0106 - val_loss: 0.0143 - val_mean_absolute_error: 0.0896 - val_mean_squared_error: 0.0143\n",
            "Epoch 876/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.0109 - mean_absolute_error: 0.0775 - mean_squared_error: 0.0109\n",
            "Epoch 876: val_loss did not improve from 0.00959\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0108 - mean_absolute_error: 0.0772 - mean_squared_error: 0.0108 - val_loss: 0.0106 - val_mean_absolute_error: 0.0770 - val_mean_squared_error: 0.0106\n",
            "Epoch 877/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0109 - mean_absolute_error: 0.0773 - mean_squared_error: 0.0109\n",
            "Epoch 877: val_loss did not improve from 0.00959\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0109 - mean_absolute_error: 0.0774 - mean_squared_error: 0.0109 - val_loss: 0.0107 - val_mean_absolute_error: 0.0781 - val_mean_squared_error: 0.0107\n",
            "Epoch 878/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0112 - mean_absolute_error: 0.0786 - mean_squared_error: 0.0112\n",
            "Epoch 878: val_loss did not improve from 0.00959\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0112 - mean_absolute_error: 0.0785 - mean_squared_error: 0.0112 - val_loss: 0.0130 - val_mean_absolute_error: 0.0839 - val_mean_squared_error: 0.0130\n",
            "Epoch 879/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0110 - mean_absolute_error: 0.0773 - mean_squared_error: 0.0110\n",
            "Epoch 879: val_loss did not improve from 0.00959\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0110 - mean_absolute_error: 0.0773 - mean_squared_error: 0.0110 - val_loss: 0.0113 - val_mean_absolute_error: 0.0804 - val_mean_squared_error: 0.0113\n",
            "Epoch 880/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.0115 - mean_absolute_error: 0.0799 - mean_squared_error: 0.0115\n",
            "Epoch 880: val_loss did not improve from 0.00959\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0116 - mean_absolute_error: 0.0801 - mean_squared_error: 0.0116 - val_loss: 0.0169 - val_mean_absolute_error: 0.1046 - val_mean_squared_error: 0.0169\n",
            "Epoch 881/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0108 - mean_absolute_error: 0.0765 - mean_squared_error: 0.0108\n",
            "Epoch 881: val_loss did not improve from 0.00959\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0109 - mean_absolute_error: 0.0770 - mean_squared_error: 0.0109 - val_loss: 0.0154 - val_mean_absolute_error: 0.0959 - val_mean_squared_error: 0.0154\n",
            "Epoch 882/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0115 - mean_absolute_error: 0.0793 - mean_squared_error: 0.0115\n",
            "Epoch 882: val_loss did not improve from 0.00959\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0115 - mean_absolute_error: 0.0795 - mean_squared_error: 0.0115 - val_loss: 0.0115 - val_mean_absolute_error: 0.0788 - val_mean_squared_error: 0.0115\n",
            "Epoch 883/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0117 - mean_absolute_error: 0.0808 - mean_squared_error: 0.0117\n",
            "Epoch 883: val_loss did not improve from 0.00959\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0116 - mean_absolute_error: 0.0805 - mean_squared_error: 0.0116 - val_loss: 0.0106 - val_mean_absolute_error: 0.0750 - val_mean_squared_error: 0.0106\n",
            "Epoch 884/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0114 - mean_absolute_error: 0.0792 - mean_squared_error: 0.0114\n",
            "Epoch 884: val_loss did not improve from 0.00959\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0114 - mean_absolute_error: 0.0794 - mean_squared_error: 0.0114 - val_loss: 0.0164 - val_mean_absolute_error: 0.0971 - val_mean_squared_error: 0.0164\n",
            "Epoch 885/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0118 - mean_absolute_error: 0.0810 - mean_squared_error: 0.0118\n",
            "Epoch 885: val_loss did not improve from 0.00959\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0117 - mean_absolute_error: 0.0808 - mean_squared_error: 0.0117 - val_loss: 0.0102 - val_mean_absolute_error: 0.0751 - val_mean_squared_error: 0.0102\n",
            "Epoch 886/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0109 - mean_absolute_error: 0.0772 - mean_squared_error: 0.0109\n",
            "Epoch 886: val_loss improved from 0.00959 to 0.00928, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0109 - mean_absolute_error: 0.0774 - mean_squared_error: 0.0109 - val_loss: 0.0093 - val_mean_absolute_error: 0.0710 - val_mean_squared_error: 0.0093\n",
            "Epoch 887/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0111 - mean_absolute_error: 0.0780 - mean_squared_error: 0.0111\n",
            "Epoch 887: val_loss did not improve from 0.00928\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0111 - mean_absolute_error: 0.0779 - mean_squared_error: 0.0111 - val_loss: 0.0102 - val_mean_absolute_error: 0.0746 - val_mean_squared_error: 0.0102\n",
            "Epoch 888/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0105 - mean_absolute_error: 0.0756 - mean_squared_error: 0.0105\n",
            "Epoch 888: val_loss did not improve from 0.00928\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0105 - mean_absolute_error: 0.0756 - mean_squared_error: 0.0105 - val_loss: 0.0108 - val_mean_absolute_error: 0.0737 - val_mean_squared_error: 0.0108\n",
            "Epoch 889/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0107 - mean_absolute_error: 0.0765 - mean_squared_error: 0.0107\n",
            "Epoch 889: val_loss did not improve from 0.00928\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0106 - mean_absolute_error: 0.0761 - mean_squared_error: 0.0106 - val_loss: 0.0098 - val_mean_absolute_error: 0.0711 - val_mean_squared_error: 0.0098\n",
            "Epoch 890/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0111 - mean_absolute_error: 0.0784 - mean_squared_error: 0.0111\n",
            "Epoch 890: val_loss did not improve from 0.00928\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0110 - mean_absolute_error: 0.0783 - mean_squared_error: 0.0110 - val_loss: 0.0102 - val_mean_absolute_error: 0.0730 - val_mean_squared_error: 0.0102\n",
            "Epoch 891/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.0106 - mean_absolute_error: 0.0755 - mean_squared_error: 0.0106\n",
            "Epoch 891: val_loss did not improve from 0.00928\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0105 - mean_absolute_error: 0.0756 - mean_squared_error: 0.0105 - val_loss: 0.0104 - val_mean_absolute_error: 0.0754 - val_mean_squared_error: 0.0104\n",
            "Epoch 892/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0105 - mean_absolute_error: 0.0756 - mean_squared_error: 0.0105\n",
            "Epoch 892: val_loss did not improve from 0.00928\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0105 - mean_absolute_error: 0.0757 - mean_squared_error: 0.0105 - val_loss: 0.0110 - val_mean_absolute_error: 0.0770 - val_mean_squared_error: 0.0110\n",
            "Epoch 893/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0109 - mean_absolute_error: 0.0774 - mean_squared_error: 0.0109\n",
            "Epoch 893: val_loss did not improve from 0.00928\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0108 - mean_absolute_error: 0.0775 - mean_squared_error: 0.0108 - val_loss: 0.0103 - val_mean_absolute_error: 0.0760 - val_mean_squared_error: 0.0103\n",
            "Epoch 894/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0111 - mean_absolute_error: 0.0780 - mean_squared_error: 0.0111\n",
            "Epoch 894: val_loss did not improve from 0.00928\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0111 - mean_absolute_error: 0.0780 - mean_squared_error: 0.0111 - val_loss: 0.0116 - val_mean_absolute_error: 0.0808 - val_mean_squared_error: 0.0116\n",
            "Epoch 895/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0112 - mean_absolute_error: 0.0784 - mean_squared_error: 0.0112\n",
            "Epoch 895: val_loss did not improve from 0.00928\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0111 - mean_absolute_error: 0.0780 - mean_squared_error: 0.0111 - val_loss: 0.0103 - val_mean_absolute_error: 0.0736 - val_mean_squared_error: 0.0103\n",
            "Epoch 896/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0105 - mean_absolute_error: 0.0757 - mean_squared_error: 0.0105\n",
            "Epoch 896: val_loss did not improve from 0.00928\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0106 - mean_absolute_error: 0.0759 - mean_squared_error: 0.0106 - val_loss: 0.0105 - val_mean_absolute_error: 0.0756 - val_mean_squared_error: 0.0105\n",
            "Epoch 897/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.0106 - mean_absolute_error: 0.0759 - mean_squared_error: 0.0106\n",
            "Epoch 897: val_loss did not improve from 0.00928\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0107 - mean_absolute_error: 0.0765 - mean_squared_error: 0.0107 - val_loss: 0.0111 - val_mean_absolute_error: 0.0775 - val_mean_squared_error: 0.0111\n",
            "Epoch 898/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0115 - mean_absolute_error: 0.0791 - mean_squared_error: 0.0115\n",
            "Epoch 898: val_loss did not improve from 0.00928\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0115 - mean_absolute_error: 0.0792 - mean_squared_error: 0.0115 - val_loss: 0.0143 - val_mean_absolute_error: 0.0858 - val_mean_squared_error: 0.0143\n",
            "Epoch 899/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0109 - mean_absolute_error: 0.0771 - mean_squared_error: 0.0109\n",
            "Epoch 899: val_loss did not improve from 0.00928\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0109 - mean_absolute_error: 0.0770 - mean_squared_error: 0.0109 - val_loss: 0.0108 - val_mean_absolute_error: 0.0770 - val_mean_squared_error: 0.0108\n",
            "Epoch 900/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0109 - mean_absolute_error: 0.0781 - mean_squared_error: 0.0109\n",
            "Epoch 900: val_loss did not improve from 0.00928\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0109 - mean_absolute_error: 0.0779 - mean_squared_error: 0.0109 - val_loss: 0.0106 - val_mean_absolute_error: 0.0778 - val_mean_squared_error: 0.0106\n",
            "Epoch 901/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0109 - mean_absolute_error: 0.0776 - mean_squared_error: 0.0109\n",
            "Epoch 901: val_loss did not improve from 0.00928\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0108 - mean_absolute_error: 0.0775 - mean_squared_error: 0.0108 - val_loss: 0.0106 - val_mean_absolute_error: 0.0785 - val_mean_squared_error: 0.0106\n",
            "Epoch 902/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0118 - mean_absolute_error: 0.0803 - mean_squared_error: 0.0118\n",
            "Epoch 902: val_loss did not improve from 0.00928\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0119 - mean_absolute_error: 0.0806 - mean_squared_error: 0.0119 - val_loss: 0.0106 - val_mean_absolute_error: 0.0756 - val_mean_squared_error: 0.0106\n",
            "Epoch 903/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0108 - mean_absolute_error: 0.0776 - mean_squared_error: 0.0108\n",
            "Epoch 903: val_loss did not improve from 0.00928\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0108 - mean_absolute_error: 0.0773 - mean_squared_error: 0.0108 - val_loss: 0.0100 - val_mean_absolute_error: 0.0708 - val_mean_squared_error: 0.0100\n",
            "Epoch 904/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0106 - mean_absolute_error: 0.0764 - mean_squared_error: 0.0106\n",
            "Epoch 904: val_loss did not improve from 0.00928\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0106 - mean_absolute_error: 0.0764 - mean_squared_error: 0.0106 - val_loss: 0.0107 - val_mean_absolute_error: 0.0756 - val_mean_squared_error: 0.0107\n",
            "Epoch 905/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.0106 - mean_absolute_error: 0.0756 - mean_squared_error: 0.0106\n",
            "Epoch 905: val_loss did not improve from 0.00928\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0106 - mean_absolute_error: 0.0756 - mean_squared_error: 0.0106 - val_loss: 0.0098 - val_mean_absolute_error: 0.0726 - val_mean_squared_error: 0.0098\n",
            "Epoch 906/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0113 - mean_absolute_error: 0.0794 - mean_squared_error: 0.0113\n",
            "Epoch 906: val_loss did not improve from 0.00928\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0113 - mean_absolute_error: 0.0794 - mean_squared_error: 0.0113 - val_loss: 0.0101 - val_mean_absolute_error: 0.0753 - val_mean_squared_error: 0.0101\n",
            "Epoch 907/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0105 - mean_absolute_error: 0.0761 - mean_squared_error: 0.0105\n",
            "Epoch 907: val_loss did not improve from 0.00928\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0104 - mean_absolute_error: 0.0758 - mean_squared_error: 0.0104 - val_loss: 0.0111 - val_mean_absolute_error: 0.0758 - val_mean_squared_error: 0.0111\n",
            "Epoch 908/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0107 - mean_absolute_error: 0.0761 - mean_squared_error: 0.0107\n",
            "Epoch 908: val_loss did not improve from 0.00928\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0107 - mean_absolute_error: 0.0762 - mean_squared_error: 0.0107 - val_loss: 0.0105 - val_mean_absolute_error: 0.0765 - val_mean_squared_error: 0.0105\n",
            "Epoch 909/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0108 - mean_absolute_error: 0.0772 - mean_squared_error: 0.0108\n",
            "Epoch 909: val_loss did not improve from 0.00928\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0108 - mean_absolute_error: 0.0772 - mean_squared_error: 0.0108 - val_loss: 0.0113 - val_mean_absolute_error: 0.0779 - val_mean_squared_error: 0.0113\n",
            "Epoch 910/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0108 - mean_absolute_error: 0.0777 - mean_squared_error: 0.0108\n",
            "Epoch 910: val_loss did not improve from 0.00928\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0108 - mean_absolute_error: 0.0777 - mean_squared_error: 0.0108 - val_loss: 0.0124 - val_mean_absolute_error: 0.0824 - val_mean_squared_error: 0.0124\n",
            "Epoch 911/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0108 - mean_absolute_error: 0.0772 - mean_squared_error: 0.0108\n",
            "Epoch 911: val_loss did not improve from 0.00928\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0108 - mean_absolute_error: 0.0771 - mean_squared_error: 0.0108 - val_loss: 0.0118 - val_mean_absolute_error: 0.0793 - val_mean_squared_error: 0.0118\n",
            "Epoch 912/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.0106 - mean_absolute_error: 0.0768 - mean_squared_error: 0.0106\n",
            "Epoch 912: val_loss did not improve from 0.00928\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0107 - mean_absolute_error: 0.0772 - mean_squared_error: 0.0107 - val_loss: 0.0104 - val_mean_absolute_error: 0.0773 - val_mean_squared_error: 0.0104\n",
            "Epoch 913/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0111 - mean_absolute_error: 0.0784 - mean_squared_error: 0.0111\n",
            "Epoch 913: val_loss improved from 0.00928 to 0.00926, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0111 - mean_absolute_error: 0.0783 - mean_squared_error: 0.0111 - val_loss: 0.0093 - val_mean_absolute_error: 0.0708 - val_mean_squared_error: 0.0093\n",
            "Epoch 914/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.0112 - mean_absolute_error: 0.0784 - mean_squared_error: 0.0112\n",
            "Epoch 914: val_loss did not improve from 0.00926\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0113 - mean_absolute_error: 0.0786 - mean_squared_error: 0.0113 - val_loss: 0.0107 - val_mean_absolute_error: 0.0759 - val_mean_squared_error: 0.0107\n",
            "Epoch 915/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0104 - mean_absolute_error: 0.0747 - mean_squared_error: 0.0104\n",
            "Epoch 915: val_loss did not improve from 0.00926\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0105 - mean_absolute_error: 0.0749 - mean_squared_error: 0.0105 - val_loss: 0.0114 - val_mean_absolute_error: 0.0802 - val_mean_squared_error: 0.0114\n",
            "Epoch 916/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0104 - mean_absolute_error: 0.0750 - mean_squared_error: 0.0104\n",
            "Epoch 916: val_loss did not improve from 0.00926\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0104 - mean_absolute_error: 0.0750 - mean_squared_error: 0.0104 - val_loss: 0.0117 - val_mean_absolute_error: 0.0808 - val_mean_squared_error: 0.0117\n",
            "Epoch 917/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.0105 - mean_absolute_error: 0.0758 - mean_squared_error: 0.0105\n",
            "Epoch 917: val_loss did not improve from 0.00926\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0105 - mean_absolute_error: 0.0757 - mean_squared_error: 0.0105 - val_loss: 0.0097 - val_mean_absolute_error: 0.0741 - val_mean_squared_error: 0.0097\n",
            "Epoch 918/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0104 - mean_absolute_error: 0.0759 - mean_squared_error: 0.0104\n",
            "Epoch 918: val_loss did not improve from 0.00926\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0104 - mean_absolute_error: 0.0760 - mean_squared_error: 0.0104 - val_loss: 0.0102 - val_mean_absolute_error: 0.0749 - val_mean_squared_error: 0.0102\n",
            "Epoch 919/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0104 - mean_absolute_error: 0.0755 - mean_squared_error: 0.0104\n",
            "Epoch 919: val_loss did not improve from 0.00926\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0103 - mean_absolute_error: 0.0754 - mean_squared_error: 0.0103 - val_loss: 0.0106 - val_mean_absolute_error: 0.0744 - val_mean_squared_error: 0.0106\n",
            "Epoch 920/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0104 - mean_absolute_error: 0.0755 - mean_squared_error: 0.0104\n",
            "Epoch 920: val_loss did not improve from 0.00926\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0104 - mean_absolute_error: 0.0755 - mean_squared_error: 0.0104 - val_loss: 0.0108 - val_mean_absolute_error: 0.0753 - val_mean_squared_error: 0.0108\n",
            "Epoch 921/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.0102 - mean_absolute_error: 0.0744 - mean_squared_error: 0.0102\n",
            "Epoch 921: val_loss did not improve from 0.00926\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0103 - mean_absolute_error: 0.0749 - mean_squared_error: 0.0103 - val_loss: 0.0117 - val_mean_absolute_error: 0.0786 - val_mean_squared_error: 0.0117\n",
            "Epoch 922/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0103 - mean_absolute_error: 0.0755 - mean_squared_error: 0.0103\n",
            "Epoch 922: val_loss did not improve from 0.00926\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0104 - mean_absolute_error: 0.0756 - mean_squared_error: 0.0104 - val_loss: 0.0121 - val_mean_absolute_error: 0.0807 - val_mean_squared_error: 0.0121\n",
            "Epoch 923/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0106 - mean_absolute_error: 0.0767 - mean_squared_error: 0.0106\n",
            "Epoch 923: val_loss did not improve from 0.00926\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0106 - mean_absolute_error: 0.0767 - mean_squared_error: 0.0106 - val_loss: 0.0108 - val_mean_absolute_error: 0.0764 - val_mean_squared_error: 0.0108\n",
            "Epoch 924/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0105 - mean_absolute_error: 0.0759 - mean_squared_error: 0.0105\n",
            "Epoch 924: val_loss did not improve from 0.00926\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0104 - mean_absolute_error: 0.0758 - mean_squared_error: 0.0104 - val_loss: 0.0100 - val_mean_absolute_error: 0.0736 - val_mean_squared_error: 0.0100\n",
            "Epoch 925/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0105 - mean_absolute_error: 0.0752 - mean_squared_error: 0.0105\n",
            "Epoch 925: val_loss improved from 0.00926 to 0.00921, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0105 - mean_absolute_error: 0.0754 - mean_squared_error: 0.0105 - val_loss: 0.0092 - val_mean_absolute_error: 0.0714 - val_mean_squared_error: 0.0092\n",
            "Epoch 926/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0108 - mean_absolute_error: 0.0772 - mean_squared_error: 0.0108\n",
            "Epoch 926: val_loss did not improve from 0.00921\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0108 - mean_absolute_error: 0.0772 - mean_squared_error: 0.0108 - val_loss: 0.0117 - val_mean_absolute_error: 0.0770 - val_mean_squared_error: 0.0117\n",
            "Epoch 927/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0108 - mean_absolute_error: 0.0773 - mean_squared_error: 0.0108\n",
            "Epoch 927: val_loss did not improve from 0.00921\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0108 - mean_absolute_error: 0.0772 - mean_squared_error: 0.0108 - val_loss: 0.0106 - val_mean_absolute_error: 0.0768 - val_mean_squared_error: 0.0106\n",
            "Epoch 928/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0104 - mean_absolute_error: 0.0753 - mean_squared_error: 0.0104\n",
            "Epoch 928: val_loss did not improve from 0.00921\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0104 - mean_absolute_error: 0.0754 - mean_squared_error: 0.0104 - val_loss: 0.0108 - val_mean_absolute_error: 0.0790 - val_mean_squared_error: 0.0108\n",
            "Epoch 929/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.0105 - mean_absolute_error: 0.0760 - mean_squared_error: 0.0105\n",
            "Epoch 929: val_loss did not improve from 0.00921\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0105 - mean_absolute_error: 0.0762 - mean_squared_error: 0.0105 - val_loss: 0.0104 - val_mean_absolute_error: 0.0748 - val_mean_squared_error: 0.0104\n",
            "Epoch 930/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0099 - mean_absolute_error: 0.0740 - mean_squared_error: 0.0099\n",
            "Epoch 930: val_loss did not improve from 0.00921\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0100 - mean_absolute_error: 0.0742 - mean_squared_error: 0.0100 - val_loss: 0.0106 - val_mean_absolute_error: 0.0784 - val_mean_squared_error: 0.0106\n",
            "Epoch 931/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.0110 - mean_absolute_error: 0.0784 - mean_squared_error: 0.0110\n",
            "Epoch 931: val_loss did not improve from 0.00921\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0110 - mean_absolute_error: 0.0779 - mean_squared_error: 0.0110 - val_loss: 0.0106 - val_mean_absolute_error: 0.0786 - val_mean_squared_error: 0.0106\n",
            "Epoch 932/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0100 - mean_absolute_error: 0.0739 - mean_squared_error: 0.0100\n",
            "Epoch 932: val_loss did not improve from 0.00921\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0100 - mean_absolute_error: 0.0740 - mean_squared_error: 0.0100 - val_loss: 0.0102 - val_mean_absolute_error: 0.0758 - val_mean_squared_error: 0.0102\n",
            "Epoch 933/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.0101 - mean_absolute_error: 0.0742 - mean_squared_error: 0.0101\n",
            "Epoch 933: val_loss did not improve from 0.00921\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0101 - mean_absolute_error: 0.0744 - mean_squared_error: 0.0101 - val_loss: 0.0108 - val_mean_absolute_error: 0.0789 - val_mean_squared_error: 0.0108\n",
            "Epoch 934/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0105 - mean_absolute_error: 0.0757 - mean_squared_error: 0.0105\n",
            "Epoch 934: val_loss did not improve from 0.00921\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0104 - mean_absolute_error: 0.0753 - mean_squared_error: 0.0104 - val_loss: 0.0109 - val_mean_absolute_error: 0.0763 - val_mean_squared_error: 0.0109\n",
            "Epoch 935/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0109 - mean_absolute_error: 0.0768 - mean_squared_error: 0.0109\n",
            "Epoch 935: val_loss did not improve from 0.00921\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0109 - mean_absolute_error: 0.0768 - mean_squared_error: 0.0109 - val_loss: 0.0100 - val_mean_absolute_error: 0.0710 - val_mean_squared_error: 0.0100\n",
            "Epoch 936/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0107 - mean_absolute_error: 0.0777 - mean_squared_error: 0.0107\n",
            "Epoch 936: val_loss did not improve from 0.00921\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0107 - mean_absolute_error: 0.0776 - mean_squared_error: 0.0107 - val_loss: 0.0095 - val_mean_absolute_error: 0.0737 - val_mean_squared_error: 0.0095\n",
            "Epoch 937/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0107 - mean_absolute_error: 0.0766 - mean_squared_error: 0.0107\n",
            "Epoch 937: val_loss did not improve from 0.00921\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0107 - mean_absolute_error: 0.0767 - mean_squared_error: 0.0107 - val_loss: 0.0129 - val_mean_absolute_error: 0.0834 - val_mean_squared_error: 0.0129\n",
            "Epoch 938/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0103 - mean_absolute_error: 0.0748 - mean_squared_error: 0.0103\n",
            "Epoch 938: val_loss did not improve from 0.00921\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0102 - mean_absolute_error: 0.0749 - mean_squared_error: 0.0102 - val_loss: 0.0095 - val_mean_absolute_error: 0.0723 - val_mean_squared_error: 0.0095\n",
            "Epoch 939/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0104 - mean_absolute_error: 0.0751 - mean_squared_error: 0.0104\n",
            "Epoch 939: val_loss did not improve from 0.00921\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0103 - mean_absolute_error: 0.0751 - mean_squared_error: 0.0103 - val_loss: 0.0106 - val_mean_absolute_error: 0.0755 - val_mean_squared_error: 0.0106\n",
            "Epoch 940/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0099 - mean_absolute_error: 0.0742 - mean_squared_error: 0.0099\n",
            "Epoch 940: val_loss did not improve from 0.00921\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0099 - mean_absolute_error: 0.0742 - mean_squared_error: 0.0099 - val_loss: 0.0101 - val_mean_absolute_error: 0.0721 - val_mean_squared_error: 0.0101\n",
            "Epoch 941/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0107 - mean_absolute_error: 0.0763 - mean_squared_error: 0.0107\n",
            "Epoch 941: val_loss did not improve from 0.00921\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0106 - mean_absolute_error: 0.0759 - mean_squared_error: 0.0106 - val_loss: 0.0101 - val_mean_absolute_error: 0.0744 - val_mean_squared_error: 0.0101\n",
            "Epoch 942/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0103 - mean_absolute_error: 0.0759 - mean_squared_error: 0.0103\n",
            "Epoch 942: val_loss did not improve from 0.00921\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0103 - mean_absolute_error: 0.0758 - mean_squared_error: 0.0103 - val_loss: 0.0094 - val_mean_absolute_error: 0.0705 - val_mean_squared_error: 0.0094\n",
            "Epoch 943/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0104 - mean_absolute_error: 0.0758 - mean_squared_error: 0.0104\n",
            "Epoch 943: val_loss did not improve from 0.00921\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0104 - mean_absolute_error: 0.0758 - mean_squared_error: 0.0104 - val_loss: 0.0106 - val_mean_absolute_error: 0.0748 - val_mean_squared_error: 0.0106\n",
            "Epoch 944/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0104 - mean_absolute_error: 0.0763 - mean_squared_error: 0.0104\n",
            "Epoch 944: val_loss did not improve from 0.00921\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0105 - mean_absolute_error: 0.0765 - mean_squared_error: 0.0105 - val_loss: 0.0111 - val_mean_absolute_error: 0.0766 - val_mean_squared_error: 0.0111\n",
            "Epoch 945/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0101 - mean_absolute_error: 0.0746 - mean_squared_error: 0.0101\n",
            "Epoch 945: val_loss improved from 0.00921 to 0.00908, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0101 - mean_absolute_error: 0.0746 - mean_squared_error: 0.0101 - val_loss: 0.0091 - val_mean_absolute_error: 0.0698 - val_mean_squared_error: 0.0091\n",
            "Epoch 946/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0106 - mean_absolute_error: 0.0764 - mean_squared_error: 0.0106\n",
            "Epoch 946: val_loss did not improve from 0.00908\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0106 - mean_absolute_error: 0.0764 - mean_squared_error: 0.0106 - val_loss: 0.0104 - val_mean_absolute_error: 0.0782 - val_mean_squared_error: 0.0104\n",
            "Epoch 947/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0108 - mean_absolute_error: 0.0766 - mean_squared_error: 0.0108\n",
            "Epoch 947: val_loss did not improve from 0.00908\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0107 - mean_absolute_error: 0.0761 - mean_squared_error: 0.0107 - val_loss: 0.0099 - val_mean_absolute_error: 0.0746 - val_mean_squared_error: 0.0099\n",
            "Epoch 948/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0103 - mean_absolute_error: 0.0749 - mean_squared_error: 0.0103\n",
            "Epoch 948: val_loss did not improve from 0.00908\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0103 - mean_absolute_error: 0.0750 - mean_squared_error: 0.0103 - val_loss: 0.0124 - val_mean_absolute_error: 0.0824 - val_mean_squared_error: 0.0124\n",
            "Epoch 949/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0102 - mean_absolute_error: 0.0747 - mean_squared_error: 0.0102\n",
            "Epoch 949: val_loss did not improve from 0.00908\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0102 - mean_absolute_error: 0.0747 - mean_squared_error: 0.0102 - val_loss: 0.0101 - val_mean_absolute_error: 0.0759 - val_mean_squared_error: 0.0101\n",
            "Epoch 950/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0102 - mean_absolute_error: 0.0742 - mean_squared_error: 0.0102\n",
            "Epoch 950: val_loss did not improve from 0.00908\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0102 - mean_absolute_error: 0.0744 - mean_squared_error: 0.0102 - val_loss: 0.0113 - val_mean_absolute_error: 0.0822 - val_mean_squared_error: 0.0113\n",
            "Epoch 951/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0104 - mean_absolute_error: 0.0764 - mean_squared_error: 0.0104\n",
            "Epoch 951: val_loss did not improve from 0.00908\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0104 - mean_absolute_error: 0.0764 - mean_squared_error: 0.0104 - val_loss: 0.0098 - val_mean_absolute_error: 0.0733 - val_mean_squared_error: 0.0098\n",
            "Epoch 952/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.0097 - mean_absolute_error: 0.0727 - mean_squared_error: 0.0097\n",
            "Epoch 952: val_loss did not improve from 0.00908\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0097 - mean_absolute_error: 0.0728 - mean_squared_error: 0.0097 - val_loss: 0.0101 - val_mean_absolute_error: 0.0746 - val_mean_squared_error: 0.0101\n",
            "Epoch 953/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0097 - mean_absolute_error: 0.0729 - mean_squared_error: 0.0097\n",
            "Epoch 953: val_loss did not improve from 0.00908\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0097 - mean_absolute_error: 0.0731 - mean_squared_error: 0.0097 - val_loss: 0.0092 - val_mean_absolute_error: 0.0710 - val_mean_squared_error: 0.0092\n",
            "Epoch 954/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0104 - mean_absolute_error: 0.0754 - mean_squared_error: 0.0104\n",
            "Epoch 954: val_loss did not improve from 0.00908\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0103 - mean_absolute_error: 0.0754 - mean_squared_error: 0.0103 - val_loss: 0.0102 - val_mean_absolute_error: 0.0750 - val_mean_squared_error: 0.0102\n",
            "Epoch 955/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0104 - mean_absolute_error: 0.0760 - mean_squared_error: 0.0104\n",
            "Epoch 955: val_loss did not improve from 0.00908\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0104 - mean_absolute_error: 0.0761 - mean_squared_error: 0.0104 - val_loss: 0.0119 - val_mean_absolute_error: 0.0789 - val_mean_squared_error: 0.0119\n",
            "Epoch 956/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0101 - mean_absolute_error: 0.0740 - mean_squared_error: 0.0101\n",
            "Epoch 956: val_loss did not improve from 0.00908\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0100 - mean_absolute_error: 0.0740 - mean_squared_error: 0.0100 - val_loss: 0.0096 - val_mean_absolute_error: 0.0716 - val_mean_squared_error: 0.0096\n",
            "Epoch 957/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0103 - mean_absolute_error: 0.0747 - mean_squared_error: 0.0103\n",
            "Epoch 957: val_loss did not improve from 0.00908\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0103 - mean_absolute_error: 0.0746 - mean_squared_error: 0.0103 - val_loss: 0.0099 - val_mean_absolute_error: 0.0720 - val_mean_squared_error: 0.0099\n",
            "Epoch 958/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0099 - mean_absolute_error: 0.0734 - mean_squared_error: 0.0099\n",
            "Epoch 958: val_loss improved from 0.00908 to 0.00890, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0099 - mean_absolute_error: 0.0735 - mean_squared_error: 0.0099 - val_loss: 0.0089 - val_mean_absolute_error: 0.0697 - val_mean_squared_error: 0.0089\n",
            "Epoch 959/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0103 - mean_absolute_error: 0.0753 - mean_squared_error: 0.0103\n",
            "Epoch 959: val_loss did not improve from 0.00890\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0102 - mean_absolute_error: 0.0752 - mean_squared_error: 0.0102 - val_loss: 0.0096 - val_mean_absolute_error: 0.0732 - val_mean_squared_error: 0.0096\n",
            "Epoch 960/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0101 - mean_absolute_error: 0.0739 - mean_squared_error: 0.0101\n",
            "Epoch 960: val_loss did not improve from 0.00890\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0102 - mean_absolute_error: 0.0743 - mean_squared_error: 0.0102 - val_loss: 0.0095 - val_mean_absolute_error: 0.0723 - val_mean_squared_error: 0.0095\n",
            "Epoch 961/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0098 - mean_absolute_error: 0.0730 - mean_squared_error: 0.0098\n",
            "Epoch 961: val_loss did not improve from 0.00890\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0098 - mean_absolute_error: 0.0731 - mean_squared_error: 0.0098 - val_loss: 0.0089 - val_mean_absolute_error: 0.0700 - val_mean_squared_error: 0.0089\n",
            "Epoch 962/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0100 - mean_absolute_error: 0.0736 - mean_squared_error: 0.0100\n",
            "Epoch 962: val_loss did not improve from 0.00890\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0099 - mean_absolute_error: 0.0736 - mean_squared_error: 0.0099 - val_loss: 0.0098 - val_mean_absolute_error: 0.0754 - val_mean_squared_error: 0.0098\n",
            "Epoch 963/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0097 - mean_absolute_error: 0.0734 - mean_squared_error: 0.0097\n",
            "Epoch 963: val_loss did not improve from 0.00890\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0098 - mean_absolute_error: 0.0736 - mean_squared_error: 0.0098 - val_loss: 0.0093 - val_mean_absolute_error: 0.0709 - val_mean_squared_error: 0.0093\n",
            "Epoch 964/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.0103 - mean_absolute_error: 0.0758 - mean_squared_error: 0.0103\n",
            "Epoch 964: val_loss did not improve from 0.00890\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0102 - mean_absolute_error: 0.0754 - mean_squared_error: 0.0102 - val_loss: 0.0091 - val_mean_absolute_error: 0.0705 - val_mean_squared_error: 0.0091\n",
            "Epoch 965/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0104 - mean_absolute_error: 0.0751 - mean_squared_error: 0.0104\n",
            "Epoch 965: val_loss did not improve from 0.00890\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0104 - mean_absolute_error: 0.0751 - mean_squared_error: 0.0104 - val_loss: 0.0098 - val_mean_absolute_error: 0.0744 - val_mean_squared_error: 0.0098\n",
            "Epoch 966/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0098 - mean_absolute_error: 0.0724 - mean_squared_error: 0.0098\n",
            "Epoch 966: val_loss did not improve from 0.00890\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0098 - mean_absolute_error: 0.0722 - mean_squared_error: 0.0098 - val_loss: 0.0094 - val_mean_absolute_error: 0.0713 - val_mean_squared_error: 0.0094\n",
            "Epoch 967/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.0097 - mean_absolute_error: 0.0733 - mean_squared_error: 0.0097\n",
            "Epoch 967: val_loss did not improve from 0.00890\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0098 - mean_absolute_error: 0.0734 - mean_squared_error: 0.0098 - val_loss: 0.0105 - val_mean_absolute_error: 0.0750 - val_mean_squared_error: 0.0105\n",
            "Epoch 968/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0103 - mean_absolute_error: 0.0752 - mean_squared_error: 0.0103\n",
            "Epoch 968: val_loss did not improve from 0.00890\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0103 - mean_absolute_error: 0.0754 - mean_squared_error: 0.0103 - val_loss: 0.0112 - val_mean_absolute_error: 0.0790 - val_mean_squared_error: 0.0112\n",
            "Epoch 969/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0102 - mean_absolute_error: 0.0751 - mean_squared_error: 0.0102\n",
            "Epoch 969: val_loss did not improve from 0.00890\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0102 - mean_absolute_error: 0.0751 - mean_squared_error: 0.0102 - val_loss: 0.0092 - val_mean_absolute_error: 0.0709 - val_mean_squared_error: 0.0092\n",
            "Epoch 970/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.0097 - mean_absolute_error: 0.0735 - mean_squared_error: 0.0097\n",
            "Epoch 970: val_loss did not improve from 0.00890\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0097 - mean_absolute_error: 0.0732 - mean_squared_error: 0.0097 - val_loss: 0.0104 - val_mean_absolute_error: 0.0744 - val_mean_squared_error: 0.0104\n",
            "Epoch 971/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0099 - mean_absolute_error: 0.0740 - mean_squared_error: 0.0099\n",
            "Epoch 971: val_loss did not improve from 0.00890\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0100 - mean_absolute_error: 0.0743 - mean_squared_error: 0.0100 - val_loss: 0.0104 - val_mean_absolute_error: 0.0757 - val_mean_squared_error: 0.0104\n",
            "Epoch 972/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0100 - mean_absolute_error: 0.0745 - mean_squared_error: 0.0100\n",
            "Epoch 972: val_loss did not improve from 0.00890\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0099 - mean_absolute_error: 0.0742 - mean_squared_error: 0.0099 - val_loss: 0.0092 - val_mean_absolute_error: 0.0709 - val_mean_squared_error: 0.0092\n",
            "Epoch 973/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0099 - mean_absolute_error: 0.0737 - mean_squared_error: 0.0099\n",
            "Epoch 973: val_loss did not improve from 0.00890\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0100 - mean_absolute_error: 0.0740 - mean_squared_error: 0.0100 - val_loss: 0.0102 - val_mean_absolute_error: 0.0760 - val_mean_squared_error: 0.0102\n",
            "Epoch 974/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0099 - mean_absolute_error: 0.0732 - mean_squared_error: 0.0099\n",
            "Epoch 974: val_loss did not improve from 0.00890\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0098 - mean_absolute_error: 0.0729 - mean_squared_error: 0.0098 - val_loss: 0.0094 - val_mean_absolute_error: 0.0715 - val_mean_squared_error: 0.0094\n",
            "Epoch 975/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.0098 - mean_absolute_error: 0.0731 - mean_squared_error: 0.0098\n",
            "Epoch 975: val_loss did not improve from 0.00890\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0098 - mean_absolute_error: 0.0734 - mean_squared_error: 0.0098 - val_loss: 0.0120 - val_mean_absolute_error: 0.0813 - val_mean_squared_error: 0.0120\n",
            "Epoch 976/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0098 - mean_absolute_error: 0.0730 - mean_squared_error: 0.0098\n",
            "Epoch 976: val_loss did not improve from 0.00890\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0097 - mean_absolute_error: 0.0727 - mean_squared_error: 0.0097 - val_loss: 0.0091 - val_mean_absolute_error: 0.0718 - val_mean_squared_error: 0.0091\n",
            "Epoch 977/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0096 - mean_absolute_error: 0.0730 - mean_squared_error: 0.0096\n",
            "Epoch 977: val_loss did not improve from 0.00890\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0096 - mean_absolute_error: 0.0728 - mean_squared_error: 0.0096 - val_loss: 0.0106 - val_mean_absolute_error: 0.0752 - val_mean_squared_error: 0.0106\n",
            "Epoch 978/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0100 - mean_absolute_error: 0.0741 - mean_squared_error: 0.0100\n",
            "Epoch 978: val_loss did not improve from 0.00890\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0100 - mean_absolute_error: 0.0741 - mean_squared_error: 0.0100 - val_loss: 0.0101 - val_mean_absolute_error: 0.0758 - val_mean_squared_error: 0.0101\n",
            "Epoch 979/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0098 - mean_absolute_error: 0.0728 - mean_squared_error: 0.0098\n",
            "Epoch 979: val_loss did not improve from 0.00890\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0098 - mean_absolute_error: 0.0728 - mean_squared_error: 0.0098 - val_loss: 0.0091 - val_mean_absolute_error: 0.0700 - val_mean_squared_error: 0.0091\n",
            "Epoch 980/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0101 - mean_absolute_error: 0.0746 - mean_squared_error: 0.0101\n",
            "Epoch 980: val_loss did not improve from 0.00890\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0101 - mean_absolute_error: 0.0746 - mean_squared_error: 0.0101 - val_loss: 0.0097 - val_mean_absolute_error: 0.0718 - val_mean_squared_error: 0.0097\n",
            "Epoch 981/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.0101 - mean_absolute_error: 0.0747 - mean_squared_error: 0.0101\n",
            "Epoch 981: val_loss did not improve from 0.00890\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0100 - mean_absolute_error: 0.0744 - mean_squared_error: 0.0100 - val_loss: 0.0094 - val_mean_absolute_error: 0.0731 - val_mean_squared_error: 0.0094\n",
            "Epoch 982/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0099 - mean_absolute_error: 0.0738 - mean_squared_error: 0.0099\n",
            "Epoch 982: val_loss did not improve from 0.00890\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0099 - mean_absolute_error: 0.0738 - mean_squared_error: 0.0099 - val_loss: 0.0118 - val_mean_absolute_error: 0.0833 - val_mean_squared_error: 0.0118\n",
            "Epoch 983/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.0098 - mean_absolute_error: 0.0731 - mean_squared_error: 0.0098\n",
            "Epoch 983: val_loss improved from 0.00890 to 0.00836, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0098 - mean_absolute_error: 0.0730 - mean_squared_error: 0.0098 - val_loss: 0.0084 - val_mean_absolute_error: 0.0678 - val_mean_squared_error: 0.0084\n",
            "Epoch 984/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0101 - mean_absolute_error: 0.0758 - mean_squared_error: 0.0101\n",
            "Epoch 984: val_loss did not improve from 0.00836\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0101 - mean_absolute_error: 0.0754 - mean_squared_error: 0.0101 - val_loss: 0.0097 - val_mean_absolute_error: 0.0709 - val_mean_squared_error: 0.0097\n",
            "Epoch 985/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0106 - mean_absolute_error: 0.0761 - mean_squared_error: 0.0106\n",
            "Epoch 985: val_loss improved from 0.00836 to 0.00821, saving model to best_model.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0105 - mean_absolute_error: 0.0761 - mean_squared_error: 0.0105 - val_loss: 0.0082 - val_mean_absolute_error: 0.0679 - val_mean_squared_error: 0.0082\n",
            "Epoch 986/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0091 - mean_absolute_error: 0.0701 - mean_squared_error: 0.0091\n",
            "Epoch 986: val_loss did not improve from 0.00821\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0090 - mean_absolute_error: 0.0700 - mean_squared_error: 0.0090 - val_loss: 0.0100 - val_mean_absolute_error: 0.0734 - val_mean_squared_error: 0.0100\n",
            "Epoch 987/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0100 - mean_absolute_error: 0.0743 - mean_squared_error: 0.0100\n",
            "Epoch 987: val_loss did not improve from 0.00821\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0100 - mean_absolute_error: 0.0743 - mean_squared_error: 0.0100 - val_loss: 0.0094 - val_mean_absolute_error: 0.0698 - val_mean_squared_error: 0.0094\n",
            "Epoch 988/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.0096 - mean_absolute_error: 0.0719 - mean_squared_error: 0.0096\n",
            "Epoch 988: val_loss did not improve from 0.00821\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0096 - mean_absolute_error: 0.0720 - mean_squared_error: 0.0096 - val_loss: 0.0111 - val_mean_absolute_error: 0.0792 - val_mean_squared_error: 0.0111\n",
            "Epoch 989/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0100 - mean_absolute_error: 0.0736 - mean_squared_error: 0.0100\n",
            "Epoch 989: val_loss did not improve from 0.00821\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0100 - mean_absolute_error: 0.0735 - mean_squared_error: 0.0100 - val_loss: 0.0090 - val_mean_absolute_error: 0.0707 - val_mean_squared_error: 0.0090\n",
            "Epoch 990/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.0099 - mean_absolute_error: 0.0739 - mean_squared_error: 0.0099\n",
            "Epoch 990: val_loss did not improve from 0.00821\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0100 - mean_absolute_error: 0.0741 - mean_squared_error: 0.0100 - val_loss: 0.0107 - val_mean_absolute_error: 0.0764 - val_mean_squared_error: 0.0107\n",
            "Epoch 991/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0100 - mean_absolute_error: 0.0746 - mean_squared_error: 0.0100\n",
            "Epoch 991: val_loss did not improve from 0.00821\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0100 - mean_absolute_error: 0.0745 - mean_squared_error: 0.0100 - val_loss: 0.0100 - val_mean_absolute_error: 0.0730 - val_mean_squared_error: 0.0100\n",
            "Epoch 992/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0096 - mean_absolute_error: 0.0726 - mean_squared_error: 0.0096\n",
            "Epoch 992: val_loss did not improve from 0.00821\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0097 - mean_absolute_error: 0.0728 - mean_squared_error: 0.0097 - val_loss: 0.0088 - val_mean_absolute_error: 0.0688 - val_mean_squared_error: 0.0088\n",
            "Epoch 993/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0098 - mean_absolute_error: 0.0732 - mean_squared_error: 0.0098\n",
            "Epoch 993: val_loss did not improve from 0.00821\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0098 - mean_absolute_error: 0.0731 - mean_squared_error: 0.0098 - val_loss: 0.0087 - val_mean_absolute_error: 0.0685 - val_mean_squared_error: 0.0087\n",
            "Epoch 994/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0098 - mean_absolute_error: 0.0733 - mean_squared_error: 0.0098\n",
            "Epoch 994: val_loss did not improve from 0.00821\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0097 - mean_absolute_error: 0.0730 - mean_squared_error: 0.0097 - val_loss: 0.0092 - val_mean_absolute_error: 0.0714 - val_mean_squared_error: 0.0092\n",
            "Epoch 995/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0100 - mean_absolute_error: 0.0739 - mean_squared_error: 0.0100\n",
            "Epoch 995: val_loss did not improve from 0.00821\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0099 - mean_absolute_error: 0.0734 - mean_squared_error: 0.0099 - val_loss: 0.0095 - val_mean_absolute_error: 0.0736 - val_mean_squared_error: 0.0095\n",
            "Epoch 996/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0098 - mean_absolute_error: 0.0731 - mean_squared_error: 0.0098\n",
            "Epoch 996: val_loss did not improve from 0.00821\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0098 - mean_absolute_error: 0.0731 - mean_squared_error: 0.0098 - val_loss: 0.0106 - val_mean_absolute_error: 0.0773 - val_mean_squared_error: 0.0106\n",
            "Epoch 997/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0099 - mean_absolute_error: 0.0734 - mean_squared_error: 0.0099\n",
            "Epoch 997: val_loss did not improve from 0.00821\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0098 - mean_absolute_error: 0.0731 - mean_squared_error: 0.0098 - val_loss: 0.0083 - val_mean_absolute_error: 0.0670 - val_mean_squared_error: 0.0083\n",
            "Epoch 998/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0097 - mean_absolute_error: 0.0729 - mean_squared_error: 0.0097\n",
            "Epoch 998: val_loss did not improve from 0.00821\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0097 - mean_absolute_error: 0.0729 - mean_squared_error: 0.0097 - val_loss: 0.0100 - val_mean_absolute_error: 0.0757 - val_mean_squared_error: 0.0100\n",
            "Epoch 999/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0101 - mean_absolute_error: 0.0747 - mean_squared_error: 0.0101\n",
            "Epoch 999: val_loss did not improve from 0.00821\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0101 - mean_absolute_error: 0.0747 - mean_squared_error: 0.0101 - val_loss: 0.0109 - val_mean_absolute_error: 0.0741 - val_mean_squared_error: 0.0109\n",
            "Epoch 1000/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0094 - mean_absolute_error: 0.0714 - mean_squared_error: 0.0094\n",
            "Epoch 1000: val_loss did not improve from 0.00821\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0094 - mean_absolute_error: 0.0714 - mean_squared_error: 0.0094 - val_loss: 0.0102 - val_mean_absolute_error: 0.0762 - val_mean_squared_error: 0.0102\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f848b380d50>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mejor modelo y diagnóstico:\n",
        "modelo = load_model('best_model.h5')\n",
        "z_predict = model.predict(Z_train)\n",
        "plt.plot(z_predict,z_train,'.')\n",
        "print('MSE:', mean_squared_error(z_train, z_predict))\n",
        "print('MAE:', mean_absolute_error(z_train, z_predict))\n",
        "print('RMSE:', mean_squared_error(z_train, z_predict)**0.5)\n",
        "print('Spearman R:', spearmanr(z_train, z_predict))\n",
        "print('R2:', r2_score(z_train, z_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "hM3_2Z8nnVZd",
        "outputId": "047d361a-d6f9-48d6-d1f2-23970c685b1f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "219/219 [==============================] - 1s 2ms/step\n",
            "MSE: 0.009760300028732872\n",
            "MAE: 0.07484019983218501\n",
            "RMSE: 0.09879423074619728\n",
            "Spearman R: SpearmanrResult(correlation=0.9781837177032671, pvalue=0.0)\n",
            "R2: 0.9973702452698339\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KhgF0rMSCE1"
      },
      "source": [
        "6. Respecto a la pregunta anterior, concluir sobre los resultados obtenidos discutiendo sobre el sobreajuste y la capacidad de aprendizaje."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#086F0C'>Al permitir que el modelo itere por 1000 épocas, sin parada temprana, se alcanzan, sobre el mismo conjunto de datos de entrenamiento, métricas de error cercanas a 0 (en particular, la raíz del error cuadrático medio, $RMSE$, es cercana a 0.099). Con ello, los indicadores de correlación de Spearman y $R^2$, para estudiar la relación entre el valor real de la función ($z$) y la predicción, exhiben valores cercanos a 1. Esto señala que el modelo sin restricciones que apunten a detener su ejecución, puede llegar a sobreaprender el conjunto de datos sobre el cual se está entrenando, poniendo en riesgo su capacidad de predecir sobre un conjunto de datos foráneo, por ejemplo al evaluar sobre un set de datos de prueba.\n",
        "\n",
        "Por último, es importante señalar que en este experimento se utilizó una red con dos capas ocultas, de 100 y 20 neuronas respectivamente, luego de la capa de entrada.</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "kpo4XMayoJxH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fQqSkxNlUbQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z_predict_test = model.predict(Z_test)\n",
        "plt.plot(z_predict_test,z_test,'.')\n",
        "print('MSE:', mean_squared_error(z_test, z_predict_test))\n",
        "print('MAE:', mean_absolute_error(z_test, z_predict_test))\n",
        "print('RMSE:', mean_squared_error(z_test, z_predict_test)**0.5)\n",
        "print('Spearman R:', spearmanr(z_test, z_predict_test))\n",
        "print('R2:', r2_score(z_test, z_predict_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "zcnL2UA9pSE3",
        "outputId": "34c4eb18-ba67-417b-e205-8063ccd58bd2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 0s 2ms/step\n",
            "MSE: 0.009968469942920829\n",
            "MAE: 0.07569904842383189\n",
            "RMSE: 0.09984222525024584\n",
            "Spearman R: SpearmanrResult(correlation=0.9754114149318694, pvalue=0.0)\n",
            "R2: 0.9972044897253107\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#086F0C'>Cuando se realiza el mismo ejercicio sobre el conjunto de datos de prueba, se verifica nuevamente un desempeño similar ($RMSE \\sim 0.099)$, con elevados correlación de Spearman y coeficiente $R^2$. En este sentido, si bien se concluye que la predicción tiene alto nivel de precisión, se ha forzado a que el modelo sobreaprenda el comportamiento de la función a modelar.</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "FOJY7fo6qKnf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Omh_DhG9SCE8"
      },
      "source": [
        "7. Respecto a la pregunta 5, concluir sobre el **teorema de aproximación universal**."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#086F0C'>De acuerdo con Goodfellow et al. (2016), el Teorema de Aproximación Universal establece que una red feedforward con una capa lineal de salida y al menos una capa oculta, como la arquitectura de este ejercicio, puede representar funciones Borel medibles (como la función de este experimento, que es continua y acotada en el conjunto $[-3,3]x[-3,3]$) con cualquier nivel de error dado (con una cantidad de neuronas en las capas ocultas apropiada).\n",
        "\n",
        "En este caso, el alto nivel de ajuste logrado sustenta de manera empírica el Teorema, en particular notando que la función es no lineal. </font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Q_mhkT2lslds"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff57awSCSCFB"
      },
      "source": [
        "7. **Parada Temprana y búsqueda de un modelo adecuado:** Diseñar e Implentar una red neuronal MLP con el fin de que pueda aprender la variable $V$, teniendo como entrada las variables $X$ e $Y$. El modelo deberá tener una arquitectura parsimoniosa.\n",
        "\n",
        "Calcular la raíz del error cuadrático medio del modelo con respecto a $V$, tanto para el conjunto de entrenamiento como el de test. Ajustar el modelo incorporando un conjunto de validación con el fin de hacer una parada temprana en caso que el error empiece a aumentar. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ajuste del modelo con parada temprana (paciencia = 5):\n",
        "es2 = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "mc2 = ModelCheckpoint('best_model2.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)"
      ],
      "metadata": {
        "id": "Xl6FOhvSui_L"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(Z_train, z_train, epochs=1000, batch_size=20, validation_split=0.3, shuffle=True, verbose=True, callbacks=[es2,mc2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWJawFkWuw10",
        "outputId": "e32f437c-8321-4098-c4ec-a30a7f71699a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0093 - mean_absolute_error: 0.0716 - mean_squared_error: 0.0093\n",
            "Epoch 1: val_loss improved from inf to 0.00947, saving model to best_model2.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0094 - mean_absolute_error: 0.0716 - mean_squared_error: 0.0094 - val_loss: 0.0095 - val_mean_absolute_error: 0.0725 - val_mean_squared_error: 0.0095\n",
            "Epoch 2/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0097 - mean_absolute_error: 0.0729 - mean_squared_error: 0.0097\n",
            "Epoch 2: val_loss improved from 0.00947 to 0.00860, saving model to best_model2.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0097 - mean_absolute_error: 0.0729 - mean_squared_error: 0.0097 - val_loss: 0.0086 - val_mean_absolute_error: 0.0675 - val_mean_squared_error: 0.0086\n",
            "Epoch 3/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0095 - mean_absolute_error: 0.0721 - mean_squared_error: 0.0095\n",
            "Epoch 3: val_loss improved from 0.00860 to 0.00827, saving model to best_model2.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0095 - mean_absolute_error: 0.0722 - mean_squared_error: 0.0095 - val_loss: 0.0083 - val_mean_absolute_error: 0.0678 - val_mean_squared_error: 0.0083\n",
            "Epoch 4/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0102 - mean_absolute_error: 0.0750 - mean_squared_error: 0.0102\n",
            "Epoch 4: val_loss did not improve from 0.00827\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0102 - mean_absolute_error: 0.0751 - mean_squared_error: 0.0102 - val_loss: 0.0096 - val_mean_absolute_error: 0.0726 - val_mean_squared_error: 0.0096\n",
            "Epoch 5/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0098 - mean_absolute_error: 0.0734 - mean_squared_error: 0.0098\n",
            "Epoch 5: val_loss did not improve from 0.00827\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0098 - mean_absolute_error: 0.0735 - mean_squared_error: 0.0098 - val_loss: 0.0141 - val_mean_absolute_error: 0.0891 - val_mean_squared_error: 0.0141\n",
            "Epoch 6/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0092 - mean_absolute_error: 0.0708 - mean_squared_error: 0.0092\n",
            "Epoch 6: val_loss did not improve from 0.00827\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0092 - mean_absolute_error: 0.0708 - mean_squared_error: 0.0092 - val_loss: 0.0086 - val_mean_absolute_error: 0.0669 - val_mean_squared_error: 0.0086\n",
            "Epoch 7/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 0.0093 - mean_absolute_error: 0.0713 - mean_squared_error: 0.0093\n",
            "Epoch 7: val_loss did not improve from 0.00827\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0094 - mean_absolute_error: 0.0714 - mean_squared_error: 0.0094 - val_loss: 0.0104 - val_mean_absolute_error: 0.0752 - val_mean_squared_error: 0.0104\n",
            "Epoch 8/1000\n",
            "218/245 [=========================>....] - ETA: 0s - loss: 0.0095 - mean_absolute_error: 0.0716 - mean_squared_error: 0.0095\n",
            "Epoch 8: val_loss did not improve from 0.00827\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 0.0096 - mean_absolute_error: 0.0721 - mean_squared_error: 0.0096 - val_loss: 0.0097 - val_mean_absolute_error: 0.0731 - val_mean_squared_error: 0.0097\n",
            "Epoch 9/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0096 - mean_absolute_error: 0.0727 - mean_squared_error: 0.0096\n",
            "Epoch 9: val_loss did not improve from 0.00827\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0096 - mean_absolute_error: 0.0725 - mean_squared_error: 0.0096 - val_loss: 0.0097 - val_mean_absolute_error: 0.0719 - val_mean_squared_error: 0.0097\n",
            "Epoch 10/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0094 - mean_absolute_error: 0.0715 - mean_squared_error: 0.0094\n",
            "Epoch 10: val_loss did not improve from 0.00827\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0094 - mean_absolute_error: 0.0716 - mean_squared_error: 0.0094 - val_loss: 0.0099 - val_mean_absolute_error: 0.0722 - val_mean_squared_error: 0.0099\n",
            "Epoch 11/1000\n",
            "218/245 [=========================>....] - ETA: 0s - loss: 0.0092 - mean_absolute_error: 0.0708 - mean_squared_error: 0.0092\n",
            "Epoch 11: val_loss did not improve from 0.00827\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 0.0095 - mean_absolute_error: 0.0720 - mean_squared_error: 0.0095 - val_loss: 0.0104 - val_mean_absolute_error: 0.0761 - val_mean_squared_error: 0.0104\n",
            "Epoch 12/1000\n",
            "218/245 [=========================>....] - ETA: 0s - loss: 0.0095 - mean_absolute_error: 0.0726 - mean_squared_error: 0.0095\n",
            "Epoch 12: val_loss did not improve from 0.00827\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0095 - mean_absolute_error: 0.0728 - mean_squared_error: 0.0095 - val_loss: 0.0119 - val_mean_absolute_error: 0.0816 - val_mean_squared_error: 0.0119\n",
            "Epoch 13/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0102 - mean_absolute_error: 0.0748 - mean_squared_error: 0.0102\n",
            "Epoch 13: val_loss did not improve from 0.00827\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.0101 - mean_absolute_error: 0.0745 - mean_squared_error: 0.0101 - val_loss: 0.0103 - val_mean_absolute_error: 0.0738 - val_mean_squared_error: 0.0103\n",
            "Epoch 13: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f848b172650>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mejor modelo y diagnóstico:\n",
        "modelo = load_model('best_model2.h5')\n",
        "z_predict = model.predict(Z_train)\n",
        "plt.plot(z_predict,z_train,'.')\n",
        "print('MSE:', mean_squared_error(z_train, z_predict))\n",
        "print('MAE:', mean_absolute_error(z_train, z_predict))\n",
        "print('RMSE:', mean_squared_error(z_train, z_predict)**0.5)\n",
        "print('Spearman R:', spearmanr(z_train, z_predict))\n",
        "print('R2:', r2_score(z_train, z_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "aT9FMqzMvS0z",
        "outputId": "2d254a30-e619-4480-d47d-eba49318aecf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "219/219 [==============================] - 0s 1ms/step\n",
            "MSE: 0.00951951744129858\n",
            "MAE: 0.07185651815365489\n",
            "RMSE: 0.09756801443761465\n",
            "Spearman R: SpearmanrResult(correlation=0.9790845681298228, pvalue=0.0)\n",
            "R2: 0.9974351202374458\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z_predict_test2 = model.predict(Z_test)\n",
        "plt.plot(z_predict_test2,z_test,'.')\n",
        "print('MSE:', mean_squared_error(z_test, z_predict_test2))\n",
        "print('MAE:', mean_absolute_error(z_test, z_predict_test2))\n",
        "print('RMSE:', mean_squared_error(z_test, z_predict_test2)**0.5)\n",
        "print('Spearman R:', spearmanr(z_test, z_predict_test2))\n",
        "print('R2:', r2_score(z_test, z_predict_test2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "TlOSSA1AvpBt",
        "outputId": "5b93a869-b07c-4604-c7de-ce96249a9901"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 0s 1ms/step\n",
            "MSE: 0.009831995009089295\n",
            "MAE: 0.07244308127947344\n",
            "RMSE: 0.09915641688307063\n",
            "Spearman R: SpearmanrResult(correlation=0.9774682931606401, pvalue=0.0)\n",
            "R2: 0.9972427621063229\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm7jbkdjSCFD"
      },
      "source": [
        "8. Respecto a la pregunta anterior, concluir sobre los resultados obtenidos discutiendo sobre la capacidad de generalización."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#086F0C'>Al implementar un mecanismo de parada temprana (paciencia = 10) sobre la misma arquitectura de red, en este caso, se ha obtenido una solución muy similar a la anterior, en término de sus medidas de error, pero en un tiempo de ejecución considerablemente inferior. En este sentido, la utilización de una restricción para las ejecuciones, en pos de una solución más práctica, muestra que el resultado logrado puede ser igualmente satisfactorio.\n",
        "\n",
        "No obstante, Goodfellow et al. (2016) levanta la alerta de que no existe un procedimiento universal que asegure que los resultados serán generalizables a un conjunto de datos distintos al de entrenamiento. En este experimento, el buen desempeño en general puede deberse a la cantidad de neuronas empleadas en las capas ocultas (2 capas ocultas), lo que repercute en el elevado número de parámetros que considera el modelo implementado (cerca de 2300 parámetros en total). </font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "VJD-binuwx3X"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfuPmD4aSCFF"
      },
      "source": [
        "9 **Deep vs Wide en MLP**\n",
        "\n",
        "- Shallow MLP: Diseñar e implementar un MLP con una única capa escondida, variando el número de neuronas en 5, 10, 50, 100, 1000.\n",
        "\n",
        "- Deep MLP: Diseñar e implementar un MLP con una única capa escondida, variando el número de capas en 2, 3, 5 y 10, cada capa con 5 neuronas escondidas.\n",
        "\n",
        "Evaluar los desempeños con el conjunto de Test y Concluir\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "grJ14y53SCFG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6345bdf1-ac57-4eb9-f376-b40c27c84bd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 5)                 15        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21\n",
            "Trainable params: 21\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#1 capa escondida, 5 neuronas:\n",
        "\n",
        "model2 = Sequential()\n",
        "#model.add(Dense(100, input_dim=2, activation='sigmoid'))\n",
        "model2.add(Dense(5, input_dim=2, activation='sigmoid'))\n",
        "model2.add(Dense(1, activation='linear'))\n",
        "\n",
        "model2.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error', 'mean_squared_error'])\n",
        "model2.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ajuste:\n",
        "es3 = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "mc3 = ModelCheckpoint('best_model3.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n"
      ],
      "metadata": {
        "id": "V3O-fVqJGaT5"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.fit(Z_train, z_train, epochs=1000, batch_size=20, validation_split=0.3, shuffle=True, verbose=True, callbacks=[es3,mc3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dyc4i-20G5a-",
        "outputId": "a4c89a68-dd80-48c9-de1f-1346a886a2f5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "216/245 [=========================>....] - ETA: 0s - loss: 3.5420 - mean_absolute_error: 1.1954 - mean_squared_error: 3.5420\n",
            "Epoch 1: val_loss improved from inf to 3.45674, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.5922 - mean_absolute_error: 1.2047 - mean_squared_error: 3.5922 - val_loss: 3.4567 - val_mean_absolute_error: 1.2139 - val_mean_squared_error: 3.4567\n",
            "Epoch 2/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 3.5685 - mean_absolute_error: 1.2201 - mean_squared_error: 3.5685\n",
            "Epoch 2: val_loss improved from 3.45674 to 3.40192, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.5420 - mean_absolute_error: 1.2155 - mean_squared_error: 3.5420 - val_loss: 3.4019 - val_mean_absolute_error: 1.1849 - val_mean_squared_error: 3.4019\n",
            "Epoch 3/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 3.5185 - mean_absolute_error: 1.1938 - mean_squared_error: 3.5185\n",
            "Epoch 3: val_loss improved from 3.40192 to 3.35983, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.4948 - mean_absolute_error: 1.1955 - mean_squared_error: 3.4948 - val_loss: 3.3598 - val_mean_absolute_error: 1.1850 - val_mean_squared_error: 3.3598\n",
            "Epoch 4/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 3.4409 - mean_absolute_error: 1.1926 - mean_squared_error: 3.4409\n",
            "Epoch 4: val_loss improved from 3.35983 to 3.31042, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.4501 - mean_absolute_error: 1.1919 - mean_squared_error: 3.4501 - val_loss: 3.3104 - val_mean_absolute_error: 1.1588 - val_mean_squared_error: 3.3104\n",
            "Epoch 5/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 3.4243 - mean_absolute_error: 1.1832 - mean_squared_error: 3.4243\n",
            "Epoch 5: val_loss improved from 3.31042 to 3.26985, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.4069 - mean_absolute_error: 1.1803 - mean_squared_error: 3.4069 - val_loss: 3.2699 - val_mean_absolute_error: 1.1592 - val_mean_squared_error: 3.2699\n",
            "Epoch 6/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 3.3359 - mean_absolute_error: 1.1662 - mean_squared_error: 3.3359\n",
            "Epoch 6: val_loss improved from 3.26985 to 3.23025, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.3657 - mean_absolute_error: 1.1767 - mean_squared_error: 3.3657 - val_loss: 3.2303 - val_mean_absolute_error: 1.1547 - val_mean_squared_error: 3.2303\n",
            "Epoch 7/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 3.3335 - mean_absolute_error: 1.1765 - mean_squared_error: 3.3335\n",
            "Epoch 7: val_loss improved from 3.23025 to 3.19018, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.3282 - mean_absolute_error: 1.1764 - mean_squared_error: 3.3282 - val_loss: 3.1902 - val_mean_absolute_error: 1.1492 - val_mean_squared_error: 3.1902\n",
            "Epoch 8/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 3.2791 - mean_absolute_error: 1.1761 - mean_squared_error: 3.2791\n",
            "Epoch 8: val_loss improved from 3.19018 to 3.15978, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.2926 - mean_absolute_error: 1.1761 - mean_squared_error: 3.2926 - val_loss: 3.1598 - val_mean_absolute_error: 1.1579 - val_mean_squared_error: 3.1598\n",
            "Epoch 9/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 3.2572 - mean_absolute_error: 1.1814 - mean_squared_error: 3.2572\n",
            "Epoch 9: val_loss improved from 3.15978 to 3.12653, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.2611 - mean_absolute_error: 1.1836 - mean_squared_error: 3.2611 - val_loss: 3.1265 - val_mean_absolute_error: 1.1560 - val_mean_squared_error: 3.1265\n",
            "Epoch 10/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 3.2260 - mean_absolute_error: 1.1864 - mean_squared_error: 3.2260\n",
            "Epoch 10: val_loss improved from 3.12653 to 3.10207, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.2355 - mean_absolute_error: 1.1879 - mean_squared_error: 3.2355 - val_loss: 3.1021 - val_mean_absolute_error: 1.1648 - val_mean_squared_error: 3.1021\n",
            "Epoch 11/1000\n",
            "216/245 [=========================>....] - ETA: 0s - loss: 3.2258 - mean_absolute_error: 1.1893 - mean_squared_error: 3.2258\n",
            "Epoch 11: val_loss improved from 3.10207 to 3.08366, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.2121 - mean_absolute_error: 1.1926 - mean_squared_error: 3.2121 - val_loss: 3.0837 - val_mean_absolute_error: 1.1741 - val_mean_squared_error: 3.0837\n",
            "Epoch 12/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 3.2200 - mean_absolute_error: 1.2066 - mean_squared_error: 3.2200\n",
            "Epoch 12: val_loss improved from 3.08366 to 3.06702, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1936 - mean_absolute_error: 1.2021 - mean_squared_error: 3.1936 - val_loss: 3.0670 - val_mean_absolute_error: 1.1814 - val_mean_squared_error: 3.0670\n",
            "Epoch 13/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 3.2294 - mean_absolute_error: 1.2190 - mean_squared_error: 3.2294\n",
            "Epoch 13: val_loss improved from 3.06702 to 3.05324, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1781 - mean_absolute_error: 1.2086 - mean_squared_error: 3.1781 - val_loss: 3.0532 - val_mean_absolute_error: 1.1874 - val_mean_squared_error: 3.0532\n",
            "Epoch 14/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 3.1766 - mean_absolute_error: 1.2202 - mean_squared_error: 3.1766\n",
            "Epoch 14: val_loss improved from 3.05324 to 3.03873, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1657 - mean_absolute_error: 1.2157 - mean_squared_error: 3.1657 - val_loss: 3.0387 - val_mean_absolute_error: 1.1911 - val_mean_squared_error: 3.0387\n",
            "Epoch 15/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 3.1982 - mean_absolute_error: 1.2309 - mean_squared_error: 3.1982\n",
            "Epoch 15: val_loss improved from 3.03873 to 3.03628, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1545 - mean_absolute_error: 1.2210 - mean_squared_error: 3.1545 - val_loss: 3.0363 - val_mean_absolute_error: 1.2011 - val_mean_squared_error: 3.0363\n",
            "Epoch 16/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 3.1533 - mean_absolute_error: 1.2299 - mean_squared_error: 3.1533\n",
            "Epoch 16: val_loss improved from 3.03628 to 3.02095, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1468 - mean_absolute_error: 1.2281 - mean_squared_error: 3.1468 - val_loss: 3.0209 - val_mean_absolute_error: 1.2012 - val_mean_squared_error: 3.0209\n",
            "Epoch 17/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 3.1204 - mean_absolute_error: 1.2289 - mean_squared_error: 3.1204\n",
            "Epoch 17: val_loss improved from 3.02095 to 3.01889, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1406 - mean_absolute_error: 1.2320 - mean_squared_error: 3.1406 - val_loss: 3.0189 - val_mean_absolute_error: 1.2084 - val_mean_squared_error: 3.0189\n",
            "Epoch 18/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 3.0996 - mean_absolute_error: 1.2290 - mean_squared_error: 3.0996\n",
            "Epoch 18: val_loss improved from 3.01889 to 3.01285, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1348 - mean_absolute_error: 1.2366 - mean_squared_error: 3.1348 - val_loss: 3.0128 - val_mean_absolute_error: 1.2117 - val_mean_squared_error: 3.0128\n",
            "Epoch 19/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 3.1469 - mean_absolute_error: 1.2441 - mean_squared_error: 3.1469\n",
            "Epoch 19: val_loss improved from 3.01285 to 3.00818, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 3.1301 - mean_absolute_error: 1.2405 - mean_squared_error: 3.1301 - val_loss: 3.0082 - val_mean_absolute_error: 1.2153 - val_mean_squared_error: 3.0082\n",
            "Epoch 20/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 3.1172 - mean_absolute_error: 1.2421 - mean_squared_error: 3.1172\n",
            "Epoch 20: val_loss improved from 3.00818 to 3.00547, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1267 - mean_absolute_error: 1.2432 - mean_squared_error: 3.1267 - val_loss: 3.0055 - val_mean_absolute_error: 1.2186 - val_mean_squared_error: 3.0055\n",
            "Epoch 21/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 3.1566 - mean_absolute_error: 1.2532 - mean_squared_error: 3.1566\n",
            "Epoch 21: val_loss improved from 3.00547 to 3.00441, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 3.1237 - mean_absolute_error: 1.2473 - mean_squared_error: 3.1237 - val_loss: 3.0044 - val_mean_absolute_error: 1.2229 - val_mean_squared_error: 3.0044\n",
            "Epoch 22/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 3.1193 - mean_absolute_error: 1.2497 - mean_squared_error: 3.1193\n",
            "Epoch 22: val_loss improved from 3.00441 to 3.00009, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 3.1209 - mean_absolute_error: 1.2497 - mean_squared_error: 3.1209 - val_loss: 3.0001 - val_mean_absolute_error: 1.2237 - val_mean_squared_error: 3.0001\n",
            "Epoch 23/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 3.1159 - mean_absolute_error: 1.2473 - mean_squared_error: 3.1159\n",
            "Epoch 23: val_loss did not improve from 3.00009\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 3.1185 - mean_absolute_error: 1.2498 - mean_squared_error: 3.1185 - val_loss: 3.0035 - val_mean_absolute_error: 1.2286 - val_mean_squared_error: 3.0035\n",
            "Epoch 24/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 3.1317 - mean_absolute_error: 1.2565 - mean_squared_error: 3.1317\n",
            "Epoch 24: val_loss improved from 3.00009 to 2.99720, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 3.1178 - mean_absolute_error: 1.2543 - mean_squared_error: 3.1178 - val_loss: 2.9972 - val_mean_absolute_error: 1.2281 - val_mean_squared_error: 2.9972\n",
            "Epoch 25/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 3.1114 - mean_absolute_error: 1.2539 - mean_squared_error: 3.1114\n",
            "Epoch 25: val_loss did not improve from 2.99720\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 3.1152 - mean_absolute_error: 1.2548 - mean_squared_error: 3.1152 - val_loss: 3.0033 - val_mean_absolute_error: 1.2330 - val_mean_squared_error: 3.0033\n",
            "Epoch 26/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 3.1334 - mean_absolute_error: 1.2614 - mean_squared_error: 3.1334\n",
            "Epoch 26: val_loss improved from 2.99720 to 2.99625, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 3.1158 - mean_absolute_error: 1.2585 - mean_squared_error: 3.1158 - val_loss: 2.9963 - val_mean_absolute_error: 1.2318 - val_mean_squared_error: 2.9963\n",
            "Epoch 27/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 3.1162 - mean_absolute_error: 1.2576 - mean_squared_error: 3.1162\n",
            "Epoch 27: val_loss improved from 2.99625 to 2.99606, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 3.1138 - mean_absolute_error: 1.2573 - mean_squared_error: 3.1138 - val_loss: 2.9961 - val_mean_absolute_error: 1.2332 - val_mean_squared_error: 2.9961\n",
            "Epoch 28/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 3.0919 - mean_absolute_error: 1.2550 - mean_squared_error: 3.0919\n",
            "Epoch 28: val_loss improved from 2.99606 to 2.99395, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1136 - mean_absolute_error: 1.2601 - mean_squared_error: 3.1136 - val_loss: 2.9939 - val_mean_absolute_error: 1.2334 - val_mean_squared_error: 2.9939\n",
            "Epoch 29/1000\n",
            "217/245 [=========================>....] - ETA: 0s - loss: 3.1457 - mean_absolute_error: 1.2635 - mean_squared_error: 3.1457\n",
            "Epoch 29: val_loss did not improve from 2.99395\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1131 - mean_absolute_error: 1.2598 - mean_squared_error: 3.1131 - val_loss: 2.9978 - val_mean_absolute_error: 1.2367 - val_mean_squared_error: 2.9978\n",
            "Epoch 30/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 3.1168 - mean_absolute_error: 1.2605 - mean_squared_error: 3.1168\n",
            "Epoch 30: val_loss improved from 2.99395 to 2.99224, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1112 - mean_absolute_error: 1.2615 - mean_squared_error: 3.1112 - val_loss: 2.9922 - val_mean_absolute_error: 1.2348 - val_mean_squared_error: 2.9922\n",
            "Epoch 31/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 3.0687 - mean_absolute_error: 1.2548 - mean_squared_error: 3.0687\n",
            "Epoch 31: val_loss improved from 2.99224 to 2.99190, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1107 - mean_absolute_error: 1.2617 - mean_squared_error: 3.1107 - val_loss: 2.9919 - val_mean_absolute_error: 1.2354 - val_mean_squared_error: 2.9919\n",
            "Epoch 32/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 3.1206 - mean_absolute_error: 1.2631 - mean_squared_error: 3.1206\n",
            "Epoch 32: val_loss did not improve from 2.99190\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1093 - mean_absolute_error: 1.2618 - mean_squared_error: 3.1093 - val_loss: 2.9953 - val_mean_absolute_error: 1.2379 - val_mean_squared_error: 2.9953\n",
            "Epoch 33/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 3.0854 - mean_absolute_error: 1.2597 - mean_squared_error: 3.0854\n",
            "Epoch 33: val_loss did not improve from 2.99190\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1096 - mean_absolute_error: 1.2626 - mean_squared_error: 3.1096 - val_loss: 2.9927 - val_mean_absolute_error: 1.2372 - val_mean_squared_error: 2.9927\n",
            "Epoch 34/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 3.1580 - mean_absolute_error: 1.2711 - mean_squared_error: 3.1580\n",
            "Epoch 34: val_loss did not improve from 2.99190\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1091 - mean_absolute_error: 1.2626 - mean_squared_error: 3.1091 - val_loss: 2.9939 - val_mean_absolute_error: 1.2387 - val_mean_squared_error: 2.9939\n",
            "Epoch 35/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 3.1117 - mean_absolute_error: 1.2640 - mean_squared_error: 3.1117\n",
            "Epoch 35: val_loss did not improve from 2.99190\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1077 - mean_absolute_error: 1.2633 - mean_squared_error: 3.1077 - val_loss: 2.9954 - val_mean_absolute_error: 1.2398 - val_mean_squared_error: 2.9954\n",
            "Epoch 36/1000\n",
            "216/245 [=========================>....] - ETA: 0s - loss: 3.1446 - mean_absolute_error: 1.2695 - mean_squared_error: 3.1446\n",
            "Epoch 36: val_loss improved from 2.99190 to 2.98903, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1068 - mean_absolute_error: 1.2636 - mean_squared_error: 3.1068 - val_loss: 2.9890 - val_mean_absolute_error: 1.2366 - val_mean_squared_error: 2.9890\n",
            "Epoch 37/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 3.0655 - mean_absolute_error: 1.2548 - mean_squared_error: 3.0655\n",
            "Epoch 37: val_loss improved from 2.98903 to 2.98893, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1070 - mean_absolute_error: 1.2629 - mean_squared_error: 3.1070 - val_loss: 2.9889 - val_mean_absolute_error: 1.2370 - val_mean_squared_error: 2.9889\n",
            "Epoch 38/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 3.1104 - mean_absolute_error: 1.2641 - mean_squared_error: 3.1104\n",
            "Epoch 38: val_loss improved from 2.98893 to 2.98781, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1061 - mean_absolute_error: 1.2636 - mean_squared_error: 3.1061 - val_loss: 2.9878 - val_mean_absolute_error: 1.2375 - val_mean_squared_error: 2.9878\n",
            "Epoch 39/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 3.1050 - mean_absolute_error: 1.2637 - mean_squared_error: 3.1050\n",
            "Epoch 39: val_loss did not improve from 2.98781\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1053 - mean_absolute_error: 1.2639 - mean_squared_error: 3.1053 - val_loss: 2.9913 - val_mean_absolute_error: 1.2393 - val_mean_squared_error: 2.9913\n",
            "Epoch 40/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 3.1024 - mean_absolute_error: 1.2645 - mean_squared_error: 3.1024\n",
            "Epoch 40: val_loss improved from 2.98781 to 2.98751, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1053 - mean_absolute_error: 1.2639 - mean_squared_error: 3.1053 - val_loss: 2.9875 - val_mean_absolute_error: 1.2378 - val_mean_squared_error: 2.9875\n",
            "Epoch 41/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 3.0841 - mean_absolute_error: 1.2606 - mean_squared_error: 3.0841\n",
            "Epoch 41: val_loss improved from 2.98751 to 2.98716, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1040 - mean_absolute_error: 1.2629 - mean_squared_error: 3.1040 - val_loss: 2.9872 - val_mean_absolute_error: 1.2381 - val_mean_squared_error: 2.9872\n",
            "Epoch 42/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 3.1002 - mean_absolute_error: 1.2635 - mean_squared_error: 3.1002\n",
            "Epoch 42: val_loss did not improve from 2.98716\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1042 - mean_absolute_error: 1.2640 - mean_squared_error: 3.1042 - val_loss: 2.9872 - val_mean_absolute_error: 1.2386 - val_mean_squared_error: 2.9872\n",
            "Epoch 43/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 3.1005 - mean_absolute_error: 1.2632 - mean_squared_error: 3.1005\n",
            "Epoch 43: val_loss did not improve from 2.98716\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1012 - mean_absolute_error: 1.2633 - mean_squared_error: 3.1012 - val_loss: 2.9992 - val_mean_absolute_error: 1.2437 - val_mean_squared_error: 2.9992\n",
            "Epoch 44/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 3.1063 - mean_absolute_error: 1.2667 - mean_squared_error: 3.1063\n",
            "Epoch 44: val_loss did not improve from 2.98716\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1038 - mean_absolute_error: 1.2645 - mean_squared_error: 3.1038 - val_loss: 2.9926 - val_mean_absolute_error: 1.2417 - val_mean_squared_error: 2.9926\n",
            "Epoch 45/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 3.0984 - mean_absolute_error: 1.2670 - mean_squared_error: 3.0984\n",
            "Epoch 45: val_loss did not improve from 2.98716\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1035 - mean_absolute_error: 1.2637 - mean_squared_error: 3.1035 - val_loss: 2.9875 - val_mean_absolute_error: 1.2391 - val_mean_squared_error: 2.9875\n",
            "Epoch 46/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 3.1090 - mean_absolute_error: 1.2648 - mean_squared_error: 3.1090\n",
            "Epoch 46: val_loss improved from 2.98716 to 2.98565, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1007 - mean_absolute_error: 1.2638 - mean_squared_error: 3.1007 - val_loss: 2.9857 - val_mean_absolute_error: 1.2390 - val_mean_squared_error: 2.9857\n",
            "Epoch 47/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 3.1302 - mean_absolute_error: 1.2682 - mean_squared_error: 3.1302\n",
            "Epoch 47: val_loss did not improve from 2.98565\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1002 - mean_absolute_error: 1.2634 - mean_squared_error: 3.1002 - val_loss: 2.9857 - val_mean_absolute_error: 1.2389 - val_mean_squared_error: 2.9857\n",
            "Epoch 48/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 3.1067 - mean_absolute_error: 1.2643 - mean_squared_error: 3.1067\n",
            "Epoch 48: val_loss improved from 2.98565 to 2.98338, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0993 - mean_absolute_error: 1.2641 - mean_squared_error: 3.0993 - val_loss: 2.9834 - val_mean_absolute_error: 1.2381 - val_mean_squared_error: 2.9834\n",
            "Epoch 49/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 3.0991 - mean_absolute_error: 1.2631 - mean_squared_error: 3.0991\n",
            "Epoch 49: val_loss did not improve from 2.98338\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0989 - mean_absolute_error: 1.2623 - mean_squared_error: 3.0989 - val_loss: 2.9850 - val_mean_absolute_error: 1.2390 - val_mean_squared_error: 2.9850\n",
            "Epoch 50/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 3.0505 - mean_absolute_error: 1.2510 - mean_squared_error: 3.0505\n",
            "Epoch 50: val_loss did not improve from 2.98338\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0977 - mean_absolute_error: 1.2622 - mean_squared_error: 3.0977 - val_loss: 2.9841 - val_mean_absolute_error: 1.2391 - val_mean_squared_error: 2.9841\n",
            "Epoch 51/1000\n",
            "217/245 [=========================>....] - ETA: 0s - loss: 3.1252 - mean_absolute_error: 1.2662 - mean_squared_error: 3.1252\n",
            "Epoch 51: val_loss improved from 2.98338 to 2.98019, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0972 - mean_absolute_error: 1.2622 - mean_squared_error: 3.0972 - val_loss: 2.9802 - val_mean_absolute_error: 1.2374 - val_mean_squared_error: 2.9802\n",
            "Epoch 52/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 3.0955 - mean_absolute_error: 1.2624 - mean_squared_error: 3.0955\n",
            "Epoch 52: val_loss did not improve from 2.98019\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0955 - mean_absolute_error: 1.2624 - mean_squared_error: 3.0955 - val_loss: 2.9821 - val_mean_absolute_error: 1.2384 - val_mean_squared_error: 2.9821\n",
            "Epoch 53/1000\n",
            "218/245 [=========================>....] - ETA: 0s - loss: 3.1298 - mean_absolute_error: 1.2681 - mean_squared_error: 3.1298\n",
            "Epoch 53: val_loss did not improve from 2.98019\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0950 - mean_absolute_error: 1.2633 - mean_squared_error: 3.0950 - val_loss: 2.9817 - val_mean_absolute_error: 1.2386 - val_mean_squared_error: 2.9817\n",
            "Epoch 54/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 3.0956 - mean_absolute_error: 1.2623 - mean_squared_error: 3.0956\n",
            "Epoch 54: val_loss improved from 2.98019 to 2.97826, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0948 - mean_absolute_error: 1.2617 - mean_squared_error: 3.0948 - val_loss: 2.9783 - val_mean_absolute_error: 1.2371 - val_mean_squared_error: 2.9783\n",
            "Epoch 55/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 3.1336 - mean_absolute_error: 1.2720 - mean_squared_error: 3.1336\n",
            "Epoch 55: val_loss improved from 2.97826 to 2.97762, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0939 - mean_absolute_error: 1.2633 - mean_squared_error: 3.0939 - val_loss: 2.9776 - val_mean_absolute_error: 1.2377 - val_mean_squared_error: 2.9776\n",
            "Epoch 56/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 3.1182 - mean_absolute_error: 1.2669 - mean_squared_error: 3.1182\n",
            "Epoch 56: val_loss did not improve from 2.97762\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0929 - mean_absolute_error: 1.2612 - mean_squared_error: 3.0929 - val_loss: 2.9776 - val_mean_absolute_error: 1.2377 - val_mean_squared_error: 2.9776\n",
            "Epoch 57/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 3.0929 - mean_absolute_error: 1.2607 - mean_squared_error: 3.0929\n",
            "Epoch 57: val_loss improved from 2.97762 to 2.97556, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0926 - mean_absolute_error: 1.2629 - mean_squared_error: 3.0926 - val_loss: 2.9756 - val_mean_absolute_error: 1.2364 - val_mean_squared_error: 2.9756\n",
            "Epoch 58/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 3.1167 - mean_absolute_error: 1.2673 - mean_squared_error: 3.1167\n",
            "Epoch 58: val_loss did not improve from 2.97556\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0898 - mean_absolute_error: 1.2617 - mean_squared_error: 3.0898 - val_loss: 2.9796 - val_mean_absolute_error: 1.2384 - val_mean_squared_error: 2.9796\n",
            "Epoch 59/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 3.1131 - mean_absolute_error: 1.2667 - mean_squared_error: 3.1131\n",
            "Epoch 59: val_loss did not improve from 2.97556\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0909 - mean_absolute_error: 1.2622 - mean_squared_error: 3.0909 - val_loss: 2.9756 - val_mean_absolute_error: 1.2370 - val_mean_squared_error: 2.9756\n",
            "Epoch 60/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 3.0842 - mean_absolute_error: 1.2577 - mean_squared_error: 3.0842\n",
            "Epoch 60: val_loss improved from 2.97556 to 2.97510, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0893 - mean_absolute_error: 1.2608 - mean_squared_error: 3.0893 - val_loss: 2.9751 - val_mean_absolute_error: 1.2368 - val_mean_squared_error: 2.9751\n",
            "Epoch 61/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 3.1198 - mean_absolute_error: 1.2686 - mean_squared_error: 3.1198\n",
            "Epoch 61: val_loss improved from 2.97510 to 2.97432, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0884 - mean_absolute_error: 1.2622 - mean_squared_error: 3.0884 - val_loss: 2.9743 - val_mean_absolute_error: 1.2366 - val_mean_squared_error: 2.9743\n",
            "Epoch 62/1000\n",
            "217/245 [=========================>....] - ETA: 0s - loss: 3.1006 - mean_absolute_error: 1.2644 - mean_squared_error: 3.1006\n",
            "Epoch 62: val_loss improved from 2.97432 to 2.97074, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0865 - mean_absolute_error: 1.2613 - mean_squared_error: 3.0865 - val_loss: 2.9707 - val_mean_absolute_error: 1.2349 - val_mean_squared_error: 2.9707\n",
            "Epoch 63/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 3.0926 - mean_absolute_error: 1.2605 - mean_squared_error: 3.0926\n",
            "Epoch 63: val_loss did not improve from 2.97074\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0868 - mean_absolute_error: 1.2594 - mean_squared_error: 3.0868 - val_loss: 2.9728 - val_mean_absolute_error: 1.2360 - val_mean_squared_error: 2.9728\n",
            "Epoch 64/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 3.1294 - mean_absolute_error: 1.2687 - mean_squared_error: 3.1294\n",
            "Epoch 64: val_loss improved from 2.97074 to 2.96981, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0849 - mean_absolute_error: 1.2607 - mean_squared_error: 3.0849 - val_loss: 2.9698 - val_mean_absolute_error: 1.2353 - val_mean_squared_error: 2.9698\n",
            "Epoch 65/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 3.1321 - mean_absolute_error: 1.2691 - mean_squared_error: 3.1321\n",
            "Epoch 65: val_loss improved from 2.96981 to 2.96910, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0840 - mean_absolute_error: 1.2596 - mean_squared_error: 3.0840 - val_loss: 2.9691 - val_mean_absolute_error: 1.2351 - val_mean_squared_error: 2.9691\n",
            "Epoch 66/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 3.0829 - mean_absolute_error: 1.2609 - mean_squared_error: 3.0829\n",
            "Epoch 66: val_loss improved from 2.96910 to 2.96717, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0829 - mean_absolute_error: 1.2609 - mean_squared_error: 3.0829 - val_loss: 2.9672 - val_mean_absolute_error: 1.2342 - val_mean_squared_error: 2.9672\n",
            "Epoch 67/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 3.0775 - mean_absolute_error: 1.2585 - mean_squared_error: 3.0775\n",
            "Epoch 67: val_loss did not improve from 2.96717\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 3.0821 - mean_absolute_error: 1.2592 - mean_squared_error: 3.0821 - val_loss: 2.9677 - val_mean_absolute_error: 1.2349 - val_mean_squared_error: 2.9677\n",
            "Epoch 68/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 3.0751 - mean_absolute_error: 1.2572 - mean_squared_error: 3.0751\n",
            "Epoch 68: val_loss did not improve from 2.96717\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 3.0806 - mean_absolute_error: 1.2584 - mean_squared_error: 3.0806 - val_loss: 2.9691 - val_mean_absolute_error: 1.2353 - val_mean_squared_error: 2.9691\n",
            "Epoch 69/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 3.0938 - mean_absolute_error: 1.2600 - mean_squared_error: 3.0938\n",
            "Epoch 69: val_loss improved from 2.96717 to 2.96452, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 3.0792 - mean_absolute_error: 1.2592 - mean_squared_error: 3.0792 - val_loss: 2.9645 - val_mean_absolute_error: 1.2337 - val_mean_squared_error: 2.9645\n",
            "Epoch 70/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 3.0552 - mean_absolute_error: 1.2539 - mean_squared_error: 3.0552\n",
            "Epoch 70: val_loss did not improve from 2.96452\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0770 - mean_absolute_error: 1.2571 - mean_squared_error: 3.0770 - val_loss: 2.9732 - val_mean_absolute_error: 1.2371 - val_mean_squared_error: 2.9732\n",
            "Epoch 71/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 3.0766 - mean_absolute_error: 1.2584 - mean_squared_error: 3.0766\n",
            "Epoch 71: val_loss improved from 2.96452 to 2.96213, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0766 - mean_absolute_error: 1.2584 - mean_squared_error: 3.0766 - val_loss: 2.9621 - val_mean_absolute_error: 1.2337 - val_mean_squared_error: 2.9621\n",
            "Epoch 72/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 3.0707 - mean_absolute_error: 1.2540 - mean_squared_error: 3.0707\n",
            "Epoch 72: val_loss improved from 2.96213 to 2.96052, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0764 - mean_absolute_error: 1.2585 - mean_squared_error: 3.0764 - val_loss: 2.9605 - val_mean_absolute_error: 1.2330 - val_mean_squared_error: 2.9605\n",
            "Epoch 73/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 3.0984 - mean_absolute_error: 1.2624 - mean_squared_error: 3.0984\n",
            "Epoch 73: val_loss did not improve from 2.96052\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0741 - mean_absolute_error: 1.2576 - mean_squared_error: 3.0741 - val_loss: 2.9634 - val_mean_absolute_error: 1.2338 - val_mean_squared_error: 2.9634\n",
            "Epoch 74/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 3.0675 - mean_absolute_error: 1.2558 - mean_squared_error: 3.0675\n",
            "Epoch 74: val_loss improved from 2.96052 to 2.95804, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0726 - mean_absolute_error: 1.2574 - mean_squared_error: 3.0726 - val_loss: 2.9580 - val_mean_absolute_error: 1.2325 - val_mean_squared_error: 2.9580\n",
            "Epoch 75/1000\n",
            "218/245 [=========================>....] - ETA: 0s - loss: 3.0666 - mean_absolute_error: 1.2496 - mean_squared_error: 3.0666\n",
            "Epoch 75: val_loss did not improve from 2.95804\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0722 - mean_absolute_error: 1.2553 - mean_squared_error: 3.0722 - val_loss: 2.9628 - val_mean_absolute_error: 1.2342 - val_mean_squared_error: 2.9628\n",
            "Epoch 76/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 3.0984 - mean_absolute_error: 1.2613 - mean_squared_error: 3.0984\n",
            "Epoch 76: val_loss did not improve from 2.95804\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0707 - mean_absolute_error: 1.2568 - mean_squared_error: 3.0707 - val_loss: 2.9581 - val_mean_absolute_error: 1.2326 - val_mean_squared_error: 2.9581\n",
            "Epoch 77/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 3.0590 - mean_absolute_error: 1.2530 - mean_squared_error: 3.0590\n",
            "Epoch 77: val_loss did not improve from 2.95804\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0690 - mean_absolute_error: 1.2558 - mean_squared_error: 3.0690 - val_loss: 2.9605 - val_mean_absolute_error: 1.2336 - val_mean_squared_error: 2.9605\n",
            "Epoch 78/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 3.0559 - mean_absolute_error: 1.2539 - mean_squared_error: 3.0559\n",
            "Epoch 78: val_loss improved from 2.95804 to 2.95323, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0676 - mean_absolute_error: 1.2562 - mean_squared_error: 3.0676 - val_loss: 2.9532 - val_mean_absolute_error: 1.2312 - val_mean_squared_error: 2.9532\n",
            "Epoch 79/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 3.0806 - mean_absolute_error: 1.2581 - mean_squared_error: 3.0806\n",
            "Epoch 79: val_loss did not improve from 2.95323\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0670 - mean_absolute_error: 1.2562 - mean_squared_error: 3.0670 - val_loss: 2.9571 - val_mean_absolute_error: 1.2324 - val_mean_squared_error: 2.9571\n",
            "Epoch 80/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 3.0640 - mean_absolute_error: 1.2560 - mean_squared_error: 3.0640\n",
            "Epoch 80: val_loss improved from 2.95323 to 2.95220, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0651 - mean_absolute_error: 1.2554 - mean_squared_error: 3.0651 - val_loss: 2.9522 - val_mean_absolute_error: 1.2309 - val_mean_squared_error: 2.9522\n",
            "Epoch 81/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 3.0917 - mean_absolute_error: 1.2598 - mean_squared_error: 3.0917\n",
            "Epoch 81: val_loss improved from 2.95220 to 2.95120, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0633 - mean_absolute_error: 1.2551 - mean_squared_error: 3.0633 - val_loss: 2.9512 - val_mean_absolute_error: 1.2306 - val_mean_squared_error: 2.9512\n",
            "Epoch 82/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 3.0645 - mean_absolute_error: 1.2547 - mean_squared_error: 3.0645\n",
            "Epoch 82: val_loss did not improve from 2.95120\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0618 - mean_absolute_error: 1.2543 - mean_squared_error: 3.0618 - val_loss: 2.9537 - val_mean_absolute_error: 1.2316 - val_mean_squared_error: 2.9537\n",
            "Epoch 83/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 3.0738 - mean_absolute_error: 1.2565 - mean_squared_error: 3.0738\n",
            "Epoch 83: val_loss improved from 2.95120 to 2.95113, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0602 - mean_absolute_error: 1.2541 - mean_squared_error: 3.0602 - val_loss: 2.9511 - val_mean_absolute_error: 1.2306 - val_mean_squared_error: 2.9511\n",
            "Epoch 84/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 3.0630 - mean_absolute_error: 1.2539 - mean_squared_error: 3.0630\n",
            "Epoch 84: val_loss improved from 2.95113 to 2.94776, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0594 - mean_absolute_error: 1.2534 - mean_squared_error: 3.0594 - val_loss: 2.9478 - val_mean_absolute_error: 1.2295 - val_mean_squared_error: 2.9478\n",
            "Epoch 85/1000\n",
            "216/245 [=========================>....] - ETA: 0s - loss: 3.1158 - mean_absolute_error: 1.2622 - mean_squared_error: 3.1158\n",
            "Epoch 85: val_loss improved from 2.94776 to 2.94458, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0578 - mean_absolute_error: 1.2541 - mean_squared_error: 3.0578 - val_loss: 2.9446 - val_mean_absolute_error: 1.2289 - val_mean_squared_error: 2.9446\n",
            "Epoch 86/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 3.0572 - mean_absolute_error: 1.2537 - mean_squared_error: 3.0572\n",
            "Epoch 86: val_loss did not improve from 2.94458\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0554 - mean_absolute_error: 1.2525 - mean_squared_error: 3.0554 - val_loss: 2.9490 - val_mean_absolute_error: 1.2297 - val_mean_squared_error: 2.9490\n",
            "Epoch 87/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 3.0549 - mean_absolute_error: 1.2514 - mean_squared_error: 3.0549\n",
            "Epoch 87: val_loss improved from 2.94458 to 2.94411, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0549 - mean_absolute_error: 1.2514 - mean_squared_error: 3.0549 - val_loss: 2.9441 - val_mean_absolute_error: 1.2283 - val_mean_squared_error: 2.9441\n",
            "Epoch 88/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 3.0436 - mean_absolute_error: 1.2486 - mean_squared_error: 3.0436\n",
            "Epoch 88: val_loss improved from 2.94411 to 2.93879, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0525 - mean_absolute_error: 1.2517 - mean_squared_error: 3.0525 - val_loss: 2.9388 - val_mean_absolute_error: 1.2274 - val_mean_squared_error: 2.9388\n",
            "Epoch 89/1000\n",
            "214/245 [=========================>....] - ETA: 0s - loss: 3.0569 - mean_absolute_error: 1.2524 - mean_squared_error: 3.0569\n",
            "Epoch 89: val_loss did not improve from 2.93879\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0511 - mean_absolute_error: 1.2505 - mean_squared_error: 3.0511 - val_loss: 2.9391 - val_mean_absolute_error: 1.2275 - val_mean_squared_error: 2.9391\n",
            "Epoch 90/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 3.0548 - mean_absolute_error: 1.2520 - mean_squared_error: 3.0548\n",
            "Epoch 90: val_loss improved from 2.93879 to 2.93621, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0486 - mean_absolute_error: 1.2508 - mean_squared_error: 3.0486 - val_loss: 2.9362 - val_mean_absolute_error: 1.2262 - val_mean_squared_error: 2.9362\n",
            "Epoch 91/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 3.0054 - mean_absolute_error: 1.2406 - mean_squared_error: 3.0054\n",
            "Epoch 91: val_loss did not improve from 2.93621\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0474 - mean_absolute_error: 1.2494 - mean_squared_error: 3.0474 - val_loss: 2.9377 - val_mean_absolute_error: 1.2268 - val_mean_squared_error: 2.9377\n",
            "Epoch 92/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 3.0377 - mean_absolute_error: 1.2479 - mean_squared_error: 3.0377\n",
            "Epoch 92: val_loss improved from 2.93621 to 2.93459, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0458 - mean_absolute_error: 1.2491 - mean_squared_error: 3.0458 - val_loss: 2.9346 - val_mean_absolute_error: 1.2264 - val_mean_squared_error: 2.9346\n",
            "Epoch 93/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 3.0698 - mean_absolute_error: 1.2555 - mean_squared_error: 3.0698\n",
            "Epoch 93: val_loss improved from 2.93459 to 2.93207, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0432 - mean_absolute_error: 1.2497 - mean_squared_error: 3.0432 - val_loss: 2.9321 - val_mean_absolute_error: 1.2254 - val_mean_squared_error: 2.9321\n",
            "Epoch 94/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 3.0445 - mean_absolute_error: 1.2503 - mean_squared_error: 3.0445\n",
            "Epoch 94: val_loss improved from 2.93207 to 2.93029, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0417 - mean_absolute_error: 1.2491 - mean_squared_error: 3.0417 - val_loss: 2.9303 - val_mean_absolute_error: 1.2247 - val_mean_squared_error: 2.9303\n",
            "Epoch 95/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 3.0440 - mean_absolute_error: 1.2492 - mean_squared_error: 3.0440\n",
            "Epoch 95: val_loss did not improve from 2.93029\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0396 - mean_absolute_error: 1.2485 - mean_squared_error: 3.0396 - val_loss: 2.9339 - val_mean_absolute_error: 1.2257 - val_mean_squared_error: 2.9339\n",
            "Epoch 96/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 3.0342 - mean_absolute_error: 1.2457 - mean_squared_error: 3.0342\n",
            "Epoch 96: val_loss improved from 2.93029 to 2.92887, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0379 - mean_absolute_error: 1.2471 - mean_squared_error: 3.0379 - val_loss: 2.9289 - val_mean_absolute_error: 1.2242 - val_mean_squared_error: 2.9289\n",
            "Epoch 97/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 3.0474 - mean_absolute_error: 1.2501 - mean_squared_error: 3.0474\n",
            "Epoch 97: val_loss improved from 2.92887 to 2.92581, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0354 - mean_absolute_error: 1.2474 - mean_squared_error: 3.0354 - val_loss: 2.9258 - val_mean_absolute_error: 1.2237 - val_mean_squared_error: 2.9258\n",
            "Epoch 98/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 3.0522 - mean_absolute_error: 1.2502 - mean_squared_error: 3.0522\n",
            "Epoch 98: val_loss improved from 2.92581 to 2.92287, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0339 - mean_absolute_error: 1.2463 - mean_squared_error: 3.0339 - val_loss: 2.9229 - val_mean_absolute_error: 1.2228 - val_mean_squared_error: 2.9229\n",
            "Epoch 99/1000\n",
            "213/245 [=========================>....] - ETA: 0s - loss: 3.0237 - mean_absolute_error: 1.2442 - mean_squared_error: 3.0237\n",
            "Epoch 99: val_loss improved from 2.92287 to 2.91988, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0319 - mean_absolute_error: 1.2454 - mean_squared_error: 3.0319 - val_loss: 2.9199 - val_mean_absolute_error: 1.2218 - val_mean_squared_error: 2.9199\n",
            "Epoch 100/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 3.0185 - mean_absolute_error: 1.2435 - mean_squared_error: 3.0185\n",
            "Epoch 100: val_loss did not improve from 2.91988\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0298 - mean_absolute_error: 1.2447 - mean_squared_error: 3.0298 - val_loss: 2.9212 - val_mean_absolute_error: 1.2218 - val_mean_squared_error: 2.9212\n",
            "Epoch 101/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 3.0326 - mean_absolute_error: 1.2426 - mean_squared_error: 3.0326\n",
            "Epoch 101: val_loss did not improve from 2.91988\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0270 - mean_absolute_error: 1.2438 - mean_squared_error: 3.0270 - val_loss: 2.9209 - val_mean_absolute_error: 1.2214 - val_mean_squared_error: 2.9209\n",
            "Epoch 102/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 3.0064 - mean_absolute_error: 1.2411 - mean_squared_error: 3.0064\n",
            "Epoch 102: val_loss improved from 2.91988 to 2.91910, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 3.0260 - mean_absolute_error: 1.2443 - mean_squared_error: 3.0260 - val_loss: 2.9191 - val_mean_absolute_error: 1.2209 - val_mean_squared_error: 2.9191\n",
            "Epoch 103/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 3.0360 - mean_absolute_error: 1.2473 - mean_squared_error: 3.0360\n",
            "Epoch 103: val_loss improved from 2.91910 to 2.91355, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 3.0231 - mean_absolute_error: 1.2433 - mean_squared_error: 3.0231 - val_loss: 2.9135 - val_mean_absolute_error: 1.2198 - val_mean_squared_error: 2.9135\n",
            "Epoch 104/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 3.0307 - mean_absolute_error: 1.2428 - mean_squared_error: 3.0307\n",
            "Epoch 104: val_loss did not improve from 2.91355\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 3.0195 - mean_absolute_error: 1.2436 - mean_squared_error: 3.0195 - val_loss: 2.9203 - val_mean_absolute_error: 1.2214 - val_mean_squared_error: 2.9203\n",
            "Epoch 105/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 3.0466 - mean_absolute_error: 1.2484 - mean_squared_error: 3.0466\n",
            "Epoch 105: val_loss improved from 2.91355 to 2.90897, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0197 - mean_absolute_error: 1.2432 - mean_squared_error: 3.0197 - val_loss: 2.9090 - val_mean_absolute_error: 1.2181 - val_mean_squared_error: 2.9090\n",
            "Epoch 106/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 3.0166 - mean_absolute_error: 1.2396 - mean_squared_error: 3.0166\n",
            "Epoch 106: val_loss improved from 2.90897 to 2.90796, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0174 - mean_absolute_error: 1.2403 - mean_squared_error: 3.0174 - val_loss: 2.9080 - val_mean_absolute_error: 1.2177 - val_mean_squared_error: 2.9080\n",
            "Epoch 107/1000\n",
            "214/245 [=========================>....] - ETA: 0s - loss: 3.0293 - mean_absolute_error: 1.2398 - mean_squared_error: 3.0293\n",
            "Epoch 107: val_loss improved from 2.90796 to 2.90459, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0139 - mean_absolute_error: 1.2402 - mean_squared_error: 3.0139 - val_loss: 2.9046 - val_mean_absolute_error: 1.2172 - val_mean_squared_error: 2.9046\n",
            "Epoch 108/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 3.0246 - mean_absolute_error: 1.2438 - mean_squared_error: 3.0246\n",
            "Epoch 108: val_loss did not improve from 2.90459\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0120 - mean_absolute_error: 1.2406 - mean_squared_error: 3.0120 - val_loss: 2.9110 - val_mean_absolute_error: 1.2182 - val_mean_squared_error: 2.9110\n",
            "Epoch 109/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 3.0177 - mean_absolute_error: 1.2406 - mean_squared_error: 3.0177\n",
            "Epoch 109: val_loss did not improve from 2.90459\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0097 - mean_absolute_error: 1.2404 - mean_squared_error: 3.0097 - val_loss: 2.9052 - val_mean_absolute_error: 1.2169 - val_mean_squared_error: 2.9052\n",
            "Epoch 110/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 3.0007 - mean_absolute_error: 1.2383 - mean_squared_error: 3.0007\n",
            "Epoch 110: val_loss improved from 2.90459 to 2.89919, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0074 - mean_absolute_error: 1.2388 - mean_squared_error: 3.0074 - val_loss: 2.8992 - val_mean_absolute_error: 1.2146 - val_mean_squared_error: 2.8992\n",
            "Epoch 111/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 3.0040 - mean_absolute_error: 1.2378 - mean_squared_error: 3.0040\n",
            "Epoch 111: val_loss improved from 2.89919 to 2.89913, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0040 - mean_absolute_error: 1.2378 - mean_squared_error: 3.0040 - val_loss: 2.8991 - val_mean_absolute_error: 1.2147 - val_mean_squared_error: 2.8991\n",
            "Epoch 112/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.9876 - mean_absolute_error: 1.2336 - mean_squared_error: 2.9876\n",
            "Epoch 112: val_loss improved from 2.89913 to 2.89241, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0019 - mean_absolute_error: 1.2371 - mean_squared_error: 3.0019 - val_loss: 2.8924 - val_mean_absolute_error: 1.2131 - val_mean_squared_error: 2.8924\n",
            "Epoch 113/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.9972 - mean_absolute_error: 1.2343 - mean_squared_error: 2.9972\n",
            "Epoch 113: val_loss improved from 2.89241 to 2.89042, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9991 - mean_absolute_error: 1.2362 - mean_squared_error: 2.9991 - val_loss: 2.8904 - val_mean_absolute_error: 1.2127 - val_mean_squared_error: 2.8904\n",
            "Epoch 114/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.9892 - mean_absolute_error: 1.2359 - mean_squared_error: 2.9892\n",
            "Epoch 114: val_loss improved from 2.89042 to 2.88758, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9964 - mean_absolute_error: 1.2361 - mean_squared_error: 2.9964 - val_loss: 2.8876 - val_mean_absolute_error: 1.2118 - val_mean_squared_error: 2.8876\n",
            "Epoch 115/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 3.0056 - mean_absolute_error: 1.2348 - mean_squared_error: 3.0056\n",
            "Epoch 115: val_loss improved from 2.88758 to 2.88639, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9940 - mean_absolute_error: 1.2356 - mean_squared_error: 2.9940 - val_loss: 2.8864 - val_mean_absolute_error: 1.2111 - val_mean_squared_error: 2.8864\n",
            "Epoch 116/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.9915 - mean_absolute_error: 1.2341 - mean_squared_error: 2.9915\n",
            "Epoch 116: val_loss improved from 2.88639 to 2.88591, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9915 - mean_absolute_error: 1.2341 - mean_squared_error: 2.9915 - val_loss: 2.8859 - val_mean_absolute_error: 1.2108 - val_mean_squared_error: 2.8859\n",
            "Epoch 117/1000\n",
            "217/245 [=========================>....] - ETA: 0s - loss: 2.9641 - mean_absolute_error: 1.2299 - mean_squared_error: 2.9641\n",
            "Epoch 117: val_loss improved from 2.88591 to 2.87974, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9879 - mean_absolute_error: 1.2322 - mean_squared_error: 2.9879 - val_loss: 2.8797 - val_mean_absolute_error: 1.2095 - val_mean_squared_error: 2.8797\n",
            "Epoch 118/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.9819 - mean_absolute_error: 1.2344 - mean_squared_error: 2.9819\n",
            "Epoch 118: val_loss improved from 2.87974 to 2.87673, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9870 - mean_absolute_error: 1.2339 - mean_squared_error: 2.9870 - val_loss: 2.8767 - val_mean_absolute_error: 1.2086 - val_mean_squared_error: 2.8767\n",
            "Epoch 119/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.9784 - mean_absolute_error: 1.2317 - mean_squared_error: 2.9784\n",
            "Epoch 119: val_loss improved from 2.87673 to 2.87500, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9833 - mean_absolute_error: 1.2313 - mean_squared_error: 2.9833 - val_loss: 2.8750 - val_mean_absolute_error: 1.2079 - val_mean_squared_error: 2.8750\n",
            "Epoch 120/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 2.9784 - mean_absolute_error: 1.2281 - mean_squared_error: 2.9784\n",
            "Epoch 120: val_loss improved from 2.87500 to 2.87089, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9790 - mean_absolute_error: 1.2305 - mean_squared_error: 2.9790 - val_loss: 2.8709 - val_mean_absolute_error: 1.2076 - val_mean_squared_error: 2.8709\n",
            "Epoch 121/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.9838 - mean_absolute_error: 1.2321 - mean_squared_error: 2.9838\n",
            "Epoch 121: val_loss did not improve from 2.87089\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9768 - mean_absolute_error: 1.2299 - mean_squared_error: 2.9768 - val_loss: 2.8727 - val_mean_absolute_error: 1.2065 - val_mean_squared_error: 2.8727\n",
            "Epoch 122/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.9545 - mean_absolute_error: 1.2249 - mean_squared_error: 2.9545\n",
            "Epoch 122: val_loss improved from 2.87089 to 2.86752, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9753 - mean_absolute_error: 1.2297 - mean_squared_error: 2.9753 - val_loss: 2.8675 - val_mean_absolute_error: 1.2051 - val_mean_squared_error: 2.8675\n",
            "Epoch 123/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.9732 - mean_absolute_error: 1.2265 - mean_squared_error: 2.9732\n",
            "Epoch 123: val_loss improved from 2.86752 to 2.86476, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9713 - mean_absolute_error: 1.2282 - mean_squared_error: 2.9713 - val_loss: 2.8648 - val_mean_absolute_error: 1.2050 - val_mean_squared_error: 2.8648\n",
            "Epoch 124/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.9691 - mean_absolute_error: 1.2273 - mean_squared_error: 2.9691\n",
            "Epoch 124: val_loss improved from 2.86476 to 2.86178, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9690 - mean_absolute_error: 1.2269 - mean_squared_error: 2.9690 - val_loss: 2.8618 - val_mean_absolute_error: 1.2038 - val_mean_squared_error: 2.8618\n",
            "Epoch 125/1000\n",
            "218/245 [=========================>....] - ETA: 0s - loss: 2.9453 - mean_absolute_error: 1.2227 - mean_squared_error: 2.9453\n",
            "Epoch 125: val_loss improved from 2.86178 to 2.86135, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9651 - mean_absolute_error: 1.2260 - mean_squared_error: 2.9651 - val_loss: 2.8614 - val_mean_absolute_error: 1.2034 - val_mean_squared_error: 2.8614\n",
            "Epoch 126/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.9598 - mean_absolute_error: 1.2243 - mean_squared_error: 2.9598\n",
            "Epoch 126: val_loss improved from 2.86135 to 2.85464, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9616 - mean_absolute_error: 1.2264 - mean_squared_error: 2.9616 - val_loss: 2.8546 - val_mean_absolute_error: 1.2023 - val_mean_squared_error: 2.8546\n",
            "Epoch 127/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.9573 - mean_absolute_error: 1.2244 - mean_squared_error: 2.9573\n",
            "Epoch 127: val_loss improved from 2.85464 to 2.85237, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9590 - mean_absolute_error: 1.2248 - mean_squared_error: 2.9590 - val_loss: 2.8524 - val_mean_absolute_error: 1.2014 - val_mean_squared_error: 2.8524\n",
            "Epoch 128/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.9297 - mean_absolute_error: 1.2198 - mean_squared_error: 2.9297\n",
            "Epoch 128: val_loss did not improve from 2.85237\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9554 - mean_absolute_error: 1.2244 - mean_squared_error: 2.9554 - val_loss: 2.8538 - val_mean_absolute_error: 1.2007 - val_mean_squared_error: 2.8538\n",
            "Epoch 129/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.9583 - mean_absolute_error: 1.2213 - mean_squared_error: 2.9583\n",
            "Epoch 129: val_loss improved from 2.85237 to 2.84634, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9529 - mean_absolute_error: 1.2230 - mean_squared_error: 2.9529 - val_loss: 2.8463 - val_mean_absolute_error: 1.1998 - val_mean_squared_error: 2.8463\n",
            "Epoch 130/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.9290 - mean_absolute_error: 1.2203 - mean_squared_error: 2.9290\n",
            "Epoch 130: val_loss improved from 2.84634 to 2.84492, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9501 - mean_absolute_error: 1.2224 - mean_squared_error: 2.9501 - val_loss: 2.8449 - val_mean_absolute_error: 1.1986 - val_mean_squared_error: 2.8449\n",
            "Epoch 131/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.9229 - mean_absolute_error: 1.2169 - mean_squared_error: 2.9229\n",
            "Epoch 131: val_loss did not improve from 2.84492\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9469 - mean_absolute_error: 1.2223 - mean_squared_error: 2.9469 - val_loss: 2.8459 - val_mean_absolute_error: 1.1976 - val_mean_squared_error: 2.8459\n",
            "Epoch 132/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.9633 - mean_absolute_error: 1.2245 - mean_squared_error: 2.9633\n",
            "Epoch 132: val_loss improved from 2.84492 to 2.84165, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9446 - mean_absolute_error: 1.2205 - mean_squared_error: 2.9446 - val_loss: 2.8417 - val_mean_absolute_error: 1.1969 - val_mean_squared_error: 2.8417\n",
            "Epoch 133/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.9327 - mean_absolute_error: 1.2179 - mean_squared_error: 2.9327\n",
            "Epoch 133: val_loss improved from 2.84165 to 2.83515, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9406 - mean_absolute_error: 1.2186 - mean_squared_error: 2.9406 - val_loss: 2.8352 - val_mean_absolute_error: 1.1954 - val_mean_squared_error: 2.8352\n",
            "Epoch 134/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.9433 - mean_absolute_error: 1.2181 - mean_squared_error: 2.9433\n",
            "Epoch 134: val_loss improved from 2.83515 to 2.83071, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9372 - mean_absolute_error: 1.2190 - mean_squared_error: 2.9372 - val_loss: 2.8307 - val_mean_absolute_error: 1.1946 - val_mean_squared_error: 2.8307\n",
            "Epoch 135/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.9390 - mean_absolute_error: 1.2176 - mean_squared_error: 2.9390\n",
            "Epoch 135: val_loss improved from 2.83071 to 2.82969, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9334 - mean_absolute_error: 1.2164 - mean_squared_error: 2.9334 - val_loss: 2.8297 - val_mean_absolute_error: 1.1936 - val_mean_squared_error: 2.8297\n",
            "Epoch 136/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.9523 - mean_absolute_error: 1.2216 - mean_squared_error: 2.9523\n",
            "Epoch 136: val_loss improved from 2.82969 to 2.82592, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9308 - mean_absolute_error: 1.2166 - mean_squared_error: 2.9308 - val_loss: 2.8259 - val_mean_absolute_error: 1.1927 - val_mean_squared_error: 2.8259\n",
            "Epoch 137/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.9279 - mean_absolute_error: 1.2143 - mean_squared_error: 2.9279\n",
            "Epoch 137: val_loss improved from 2.82592 to 2.82338, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9279 - mean_absolute_error: 1.2143 - mean_squared_error: 2.9279 - val_loss: 2.8234 - val_mean_absolute_error: 1.1916 - val_mean_squared_error: 2.8234\n",
            "Epoch 138/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.9335 - mean_absolute_error: 1.2166 - mean_squared_error: 2.9335\n",
            "Epoch 138: val_loss improved from 2.82338 to 2.81754, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9223 - mean_absolute_error: 1.2128 - mean_squared_error: 2.9223 - val_loss: 2.8175 - val_mean_absolute_error: 1.1907 - val_mean_squared_error: 2.8175\n",
            "Epoch 139/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 2.9235 - mean_absolute_error: 1.2122 - mean_squared_error: 2.9235\n",
            "Epoch 139: val_loss improved from 2.81754 to 2.81622, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9191 - mean_absolute_error: 1.2131 - mean_squared_error: 2.9191 - val_loss: 2.8162 - val_mean_absolute_error: 1.1895 - val_mean_squared_error: 2.8162\n",
            "Epoch 140/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 2.9181 - mean_absolute_error: 1.2108 - mean_squared_error: 2.9181\n",
            "Epoch 140: val_loss improved from 2.81622 to 2.81454, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9156 - mean_absolute_error: 1.2112 - mean_squared_error: 2.9156 - val_loss: 2.8145 - val_mean_absolute_error: 1.1886 - val_mean_squared_error: 2.8145\n",
            "Epoch 141/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 2.9482 - mean_absolute_error: 1.2155 - mean_squared_error: 2.9482\n",
            "Epoch 141: val_loss improved from 2.81454 to 2.81298, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9129 - mean_absolute_error: 1.2109 - mean_squared_error: 2.9129 - val_loss: 2.8130 - val_mean_absolute_error: 1.1881 - val_mean_squared_error: 2.8130\n",
            "Epoch 142/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.9477 - mean_absolute_error: 1.2177 - mean_squared_error: 2.9477\n",
            "Epoch 142: val_loss improved from 2.81298 to 2.80489, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9081 - mean_absolute_error: 1.2094 - mean_squared_error: 2.9081 - val_loss: 2.8049 - val_mean_absolute_error: 1.1864 - val_mean_squared_error: 2.8049\n",
            "Epoch 143/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.9062 - mean_absolute_error: 1.2062 - mean_squared_error: 2.9062\n",
            "Epoch 143: val_loss improved from 2.80489 to 2.80068, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9049 - mean_absolute_error: 1.2079 - mean_squared_error: 2.9049 - val_loss: 2.8007 - val_mean_absolute_error: 1.1856 - val_mean_squared_error: 2.8007\n",
            "Epoch 144/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.8852 - mean_absolute_error: 1.2040 - mean_squared_error: 2.8852\n",
            "Epoch 144: val_loss improved from 2.80068 to 2.79787, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9012 - mean_absolute_error: 1.2070 - mean_squared_error: 2.9012 - val_loss: 2.7979 - val_mean_absolute_error: 1.1841 - val_mean_squared_error: 2.7979\n",
            "Epoch 145/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.8648 - mean_absolute_error: 1.1964 - mean_squared_error: 2.8648\n",
            "Epoch 145: val_loss improved from 2.79787 to 2.79269, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8978 - mean_absolute_error: 1.2057 - mean_squared_error: 2.8978 - val_loss: 2.7927 - val_mean_absolute_error: 1.1831 - val_mean_squared_error: 2.7927\n",
            "Epoch 146/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.8996 - mean_absolute_error: 1.2062 - mean_squared_error: 2.8996\n",
            "Epoch 146: val_loss improved from 2.79269 to 2.78992, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.8925 - mean_absolute_error: 1.2051 - mean_squared_error: 2.8925 - val_loss: 2.7899 - val_mean_absolute_error: 1.1821 - val_mean_squared_error: 2.7899\n",
            "Epoch 147/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.9032 - mean_absolute_error: 1.2078 - mean_squared_error: 2.9032\n",
            "Epoch 147: val_loss did not improve from 2.78992\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.8889 - mean_absolute_error: 1.2034 - mean_squared_error: 2.8889 - val_loss: 2.7929 - val_mean_absolute_error: 1.1813 - val_mean_squared_error: 2.7929\n",
            "Epoch 148/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.8651 - mean_absolute_error: 1.2002 - mean_squared_error: 2.8651\n",
            "Epoch 148: val_loss improved from 2.78992 to 2.78639, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8853 - mean_absolute_error: 1.2018 - mean_squared_error: 2.8853 - val_loss: 2.7864 - val_mean_absolute_error: 1.1799 - val_mean_squared_error: 2.7864\n",
            "Epoch 149/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.8581 - mean_absolute_error: 1.1983 - mean_squared_error: 2.8581\n",
            "Epoch 149: val_loss improved from 2.78639 to 2.77935, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.8818 - mean_absolute_error: 1.2002 - mean_squared_error: 2.8818 - val_loss: 2.7794 - val_mean_absolute_error: 1.1788 - val_mean_squared_error: 2.7794\n",
            "Epoch 150/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 2.9141 - mean_absolute_error: 1.2042 - mean_squared_error: 2.9141\n",
            "Epoch 150: val_loss improved from 2.77935 to 2.77587, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8779 - mean_absolute_error: 1.2009 - mean_squared_error: 2.8779 - val_loss: 2.7759 - val_mean_absolute_error: 1.1775 - val_mean_squared_error: 2.7759\n",
            "Epoch 151/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.8794 - mean_absolute_error: 1.1956 - mean_squared_error: 2.8794\n",
            "Epoch 151: val_loss improved from 2.77587 to 2.77238, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.8735 - mean_absolute_error: 1.1979 - mean_squared_error: 2.8735 - val_loss: 2.7724 - val_mean_absolute_error: 1.1760 - val_mean_squared_error: 2.7724\n",
            "Epoch 152/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 2.8472 - mean_absolute_error: 1.1914 - mean_squared_error: 2.8472\n",
            "Epoch 152: val_loss improved from 2.77238 to 2.77013, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8697 - mean_absolute_error: 1.1969 - mean_squared_error: 2.8697 - val_loss: 2.7701 - val_mean_absolute_error: 1.1753 - val_mean_squared_error: 2.7701\n",
            "Epoch 153/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.8737 - mean_absolute_error: 1.1979 - mean_squared_error: 2.8737\n",
            "Epoch 153: val_loss improved from 2.77013 to 2.76337, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.8656 - mean_absolute_error: 1.1966 - mean_squared_error: 2.8656 - val_loss: 2.7634 - val_mean_absolute_error: 1.1742 - val_mean_squared_error: 2.7634\n",
            "Epoch 154/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 2.8707 - mean_absolute_error: 1.1950 - mean_squared_error: 2.8707\n",
            "Epoch 154: val_loss improved from 2.76337 to 2.76134, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8621 - mean_absolute_error: 1.1947 - mean_squared_error: 2.8621 - val_loss: 2.7613 - val_mean_absolute_error: 1.1730 - val_mean_squared_error: 2.7613\n",
            "Epoch 155/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.9024 - mean_absolute_error: 1.2024 - mean_squared_error: 2.9024\n",
            "Epoch 155: val_loss improved from 2.76134 to 2.75616, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8575 - mean_absolute_error: 1.1935 - mean_squared_error: 2.8575 - val_loss: 2.7562 - val_mean_absolute_error: 1.1723 - val_mean_squared_error: 2.7562\n",
            "Epoch 156/1000\n",
            "217/245 [=========================>....] - ETA: 0s - loss: 2.8395 - mean_absolute_error: 1.1929 - mean_squared_error: 2.8395\n",
            "Epoch 156: val_loss improved from 2.75616 to 2.75489, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8536 - mean_absolute_error: 1.1933 - mean_squared_error: 2.8536 - val_loss: 2.7549 - val_mean_absolute_error: 1.1706 - val_mean_squared_error: 2.7549\n",
            "Epoch 157/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.8805 - mean_absolute_error: 1.1985 - mean_squared_error: 2.8805\n",
            "Epoch 157: val_loss improved from 2.75489 to 2.74867, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.8494 - mean_absolute_error: 1.1913 - mean_squared_error: 2.8494 - val_loss: 2.7487 - val_mean_absolute_error: 1.1693 - val_mean_squared_error: 2.7487\n",
            "Epoch 158/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.8437 - mean_absolute_error: 1.1867 - mean_squared_error: 2.8437\n",
            "Epoch 158: val_loss improved from 2.74867 to 2.74551, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8449 - mean_absolute_error: 1.1895 - mean_squared_error: 2.8449 - val_loss: 2.7455 - val_mean_absolute_error: 1.1681 - val_mean_squared_error: 2.7455\n",
            "Epoch 159/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 2.8074 - mean_absolute_error: 1.1797 - mean_squared_error: 2.8074\n",
            "Epoch 159: val_loss improved from 2.74551 to 2.73993, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8420 - mean_absolute_error: 1.1882 - mean_squared_error: 2.8420 - val_loss: 2.7399 - val_mean_absolute_error: 1.1669 - val_mean_squared_error: 2.7399\n",
            "Epoch 160/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 2.8488 - mean_absolute_error: 1.1919 - mean_squared_error: 2.8488\n",
            "Epoch 160: val_loss improved from 2.73993 to 2.73693, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.8372 - mean_absolute_error: 1.1883 - mean_squared_error: 2.8372 - val_loss: 2.7369 - val_mean_absolute_error: 1.1655 - val_mean_squared_error: 2.7369\n",
            "Epoch 161/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.8164 - mean_absolute_error: 1.1828 - mean_squared_error: 2.8164\n",
            "Epoch 161: val_loss improved from 2.73693 to 2.73068, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.8311 - mean_absolute_error: 1.1847 - mean_squared_error: 2.8311 - val_loss: 2.7307 - val_mean_absolute_error: 1.1645 - val_mean_squared_error: 2.7307\n",
            "Epoch 162/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.7987 - mean_absolute_error: 1.1783 - mean_squared_error: 2.7987\n",
            "Epoch 162: val_loss improved from 2.73068 to 2.72817, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8282 - mean_absolute_error: 1.1847 - mean_squared_error: 2.8282 - val_loss: 2.7282 - val_mean_absolute_error: 1.1630 - val_mean_squared_error: 2.7282\n",
            "Epoch 163/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.8222 - mean_absolute_error: 1.1834 - mean_squared_error: 2.8222\n",
            "Epoch 163: val_loss did not improve from 2.72817\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.8222 - mean_absolute_error: 1.1834 - mean_squared_error: 2.8222 - val_loss: 2.7293 - val_mean_absolute_error: 1.1620 - val_mean_squared_error: 2.7293\n",
            "Epoch 164/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.8118 - mean_absolute_error: 1.1803 - mean_squared_error: 2.8118\n",
            "Epoch 164: val_loss improved from 2.72817 to 2.71766, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 6ms/step - loss: 2.8184 - mean_absolute_error: 1.1811 - mean_squared_error: 2.8184 - val_loss: 2.7177 - val_mean_absolute_error: 1.1615 - val_mean_squared_error: 2.7177\n",
            "Epoch 165/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.8403 - mean_absolute_error: 1.1885 - mean_squared_error: 2.8403\n",
            "Epoch 165: val_loss improved from 2.71766 to 2.71659, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 6ms/step - loss: 2.8146 - mean_absolute_error: 1.1819 - mean_squared_error: 2.8146 - val_loss: 2.7166 - val_mean_absolute_error: 1.1594 - val_mean_squared_error: 2.7166\n",
            "Epoch 166/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.7919 - mean_absolute_error: 1.1747 - mean_squared_error: 2.7919\n",
            "Epoch 166: val_loss improved from 2.71659 to 2.71169, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8103 - mean_absolute_error: 1.1783 - mean_squared_error: 2.8103 - val_loss: 2.7117 - val_mean_absolute_error: 1.1579 - val_mean_squared_error: 2.7117\n",
            "Epoch 167/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.8046 - mean_absolute_error: 1.1773 - mean_squared_error: 2.8046\n",
            "Epoch 167: val_loss improved from 2.71169 to 2.70497, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 6ms/step - loss: 2.8046 - mean_absolute_error: 1.1773 - mean_squared_error: 2.8046 - val_loss: 2.7050 - val_mean_absolute_error: 1.1576 - val_mean_squared_error: 2.7050\n",
            "Epoch 168/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.8101 - mean_absolute_error: 1.1788 - mean_squared_error: 2.8101\n",
            "Epoch 168: val_loss did not improve from 2.70497\n",
            "245/245 [==============================] - 3s 10ms/step - loss: 2.8012 - mean_absolute_error: 1.1766 - mean_squared_error: 2.8012 - val_loss: 2.7053 - val_mean_absolute_error: 1.1555 - val_mean_squared_error: 2.7053\n",
            "Epoch 169/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.8085 - mean_absolute_error: 1.1788 - mean_squared_error: 2.8085\n",
            "Epoch 169: val_loss improved from 2.70497 to 2.69860, saving model to best_model3.h5\n",
            "245/245 [==============================] - 2s 7ms/step - loss: 2.7962 - mean_absolute_error: 1.1761 - mean_squared_error: 2.7962 - val_loss: 2.6986 - val_mean_absolute_error: 1.1546 - val_mean_squared_error: 2.6986\n",
            "Epoch 170/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.7618 - mean_absolute_error: 1.1666 - mean_squared_error: 2.7618\n",
            "Epoch 170: val_loss improved from 2.69860 to 2.69266, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.7917 - mean_absolute_error: 1.1736 - mean_squared_error: 2.7917 - val_loss: 2.6927 - val_mean_absolute_error: 1.1534 - val_mean_squared_error: 2.6927\n",
            "Epoch 171/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.7991 - mean_absolute_error: 1.1769 - mean_squared_error: 2.7991\n",
            "Epoch 171: val_loss did not improve from 2.69266\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.7880 - mean_absolute_error: 1.1724 - mean_squared_error: 2.7880 - val_loss: 2.6933 - val_mean_absolute_error: 1.1518 - val_mean_squared_error: 2.6933\n",
            "Epoch 172/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.7877 - mean_absolute_error: 1.1731 - mean_squared_error: 2.7877\n",
            "Epoch 172: val_loss improved from 2.69266 to 2.68448, saving model to best_model3.h5\n",
            "245/245 [==============================] - 2s 9ms/step - loss: 2.7835 - mean_absolute_error: 1.1716 - mean_squared_error: 2.7835 - val_loss: 2.6845 - val_mean_absolute_error: 1.1513 - val_mean_squared_error: 2.6845\n",
            "Epoch 173/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.7779 - mean_absolute_error: 1.1704 - mean_squared_error: 2.7779\n",
            "Epoch 173: val_loss improved from 2.68448 to 2.68414, saving model to best_model3.h5\n",
            "245/245 [==============================] - 3s 12ms/step - loss: 2.7779 - mean_absolute_error: 1.1704 - mean_squared_error: 2.7779 - val_loss: 2.6841 - val_mean_absolute_error: 1.1491 - val_mean_squared_error: 2.6841\n",
            "Epoch 174/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.8161 - mean_absolute_error: 1.1788 - mean_squared_error: 2.8161\n",
            "Epoch 174: val_loss did not improve from 2.68414\n",
            "245/245 [==============================] - 2s 6ms/step - loss: 2.7719 - mean_absolute_error: 1.1690 - mean_squared_error: 2.7719 - val_loss: 2.6869 - val_mean_absolute_error: 1.1481 - val_mean_squared_error: 2.6869\n",
            "Epoch 175/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.7638 - mean_absolute_error: 1.1659 - mean_squared_error: 2.7638\n",
            "Epoch 175: val_loss improved from 2.68414 to 2.67076, saving model to best_model3.h5\n",
            "245/245 [==============================] - 2s 6ms/step - loss: 2.7689 - mean_absolute_error: 1.1669 - mean_squared_error: 2.7689 - val_loss: 2.6708 - val_mean_absolute_error: 1.1474 - val_mean_squared_error: 2.6708\n",
            "Epoch 176/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.7721 - mean_absolute_error: 1.1695 - mean_squared_error: 2.7721\n",
            "Epoch 176: val_loss did not improve from 2.67076\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.7628 - mean_absolute_error: 1.1661 - mean_squared_error: 2.7628 - val_loss: 2.6713 - val_mean_absolute_error: 1.1452 - val_mean_squared_error: 2.6713\n",
            "Epoch 177/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.7594 - mean_absolute_error: 1.1633 - mean_squared_error: 2.7594\n",
            "Epoch 177: val_loss improved from 2.67076 to 2.66223, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7594 - mean_absolute_error: 1.1633 - mean_squared_error: 2.7594 - val_loss: 2.6622 - val_mean_absolute_error: 1.1447 - val_mean_squared_error: 2.6622\n",
            "Epoch 178/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 2.7446 - mean_absolute_error: 1.1600 - mean_squared_error: 2.7446\n",
            "Epoch 178: val_loss improved from 2.66223 to 2.65673, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7539 - mean_absolute_error: 1.1644 - mean_squared_error: 2.7539 - val_loss: 2.6567 - val_mean_absolute_error: 1.1439 - val_mean_squared_error: 2.6567\n",
            "Epoch 179/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.7787 - mean_absolute_error: 1.1696 - mean_squared_error: 2.7787\n",
            "Epoch 179: val_loss improved from 2.65673 to 2.65470, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.7493 - mean_absolute_error: 1.1628 - mean_squared_error: 2.7493 - val_loss: 2.6547 - val_mean_absolute_error: 1.1416 - val_mean_squared_error: 2.6547\n",
            "Epoch 180/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 2.7697 - mean_absolute_error: 1.1657 - mean_squared_error: 2.7697\n",
            "Epoch 180: val_loss improved from 2.65470 to 2.64688, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.7449 - mean_absolute_error: 1.1611 - mean_squared_error: 2.7449 - val_loss: 2.6469 - val_mean_absolute_error: 1.1415 - val_mean_squared_error: 2.6469\n",
            "Epoch 181/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.7453 - mean_absolute_error: 1.1627 - mean_squared_error: 2.7453\n",
            "Epoch 181: val_loss improved from 2.64688 to 2.64417, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7399 - mean_absolute_error: 1.1598 - mean_squared_error: 2.7399 - val_loss: 2.6442 - val_mean_absolute_error: 1.1392 - val_mean_squared_error: 2.6442\n",
            "Epoch 182/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 2.7189 - mean_absolute_error: 1.1560 - mean_squared_error: 2.7189\n",
            "Epoch 182: val_loss did not improve from 2.64417\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.7333 - mean_absolute_error: 1.1584 - mean_squared_error: 2.7333 - val_loss: 2.6484 - val_mean_absolute_error: 1.1373 - val_mean_squared_error: 2.6484\n",
            "Epoch 183/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.7288 - mean_absolute_error: 1.1540 - mean_squared_error: 2.7288\n",
            "Epoch 183: val_loss improved from 2.64417 to 2.63717, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7314 - mean_absolute_error: 1.1559 - mean_squared_error: 2.7314 - val_loss: 2.6372 - val_mean_absolute_error: 1.1363 - val_mean_squared_error: 2.6372\n",
            "Epoch 184/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.7297 - mean_absolute_error: 1.1552 - mean_squared_error: 2.7297\n",
            "Epoch 184: val_loss improved from 2.63717 to 2.62749, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7243 - mean_absolute_error: 1.1550 - mean_squared_error: 2.7243 - val_loss: 2.6275 - val_mean_absolute_error: 1.1369 - val_mean_squared_error: 2.6275\n",
            "Epoch 185/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 2.6443 - mean_absolute_error: 1.1463 - mean_squared_error: 2.6443\n",
            "Epoch 185: val_loss improved from 2.62749 to 2.62719, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.7199 - mean_absolute_error: 1.1552 - mean_squared_error: 2.7199 - val_loss: 2.6272 - val_mean_absolute_error: 1.1332 - val_mean_squared_error: 2.6272\n",
            "Epoch 186/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 2.7040 - mean_absolute_error: 1.1508 - mean_squared_error: 2.7040\n",
            "Epoch 186: val_loss improved from 2.62719 to 2.61888, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7151 - mean_absolute_error: 1.1526 - mean_squared_error: 2.7151 - val_loss: 2.6189 - val_mean_absolute_error: 1.1328 - val_mean_squared_error: 2.6189\n",
            "Epoch 187/1000\n",
            "218/245 [=========================>....] - ETA: 0s - loss: 2.7135 - mean_absolute_error: 1.1481 - mean_squared_error: 2.7135\n",
            "Epoch 187: val_loss improved from 2.61888 to 2.61502, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7100 - mean_absolute_error: 1.1510 - mean_squared_error: 2.7100 - val_loss: 2.6150 - val_mean_absolute_error: 1.1312 - val_mean_squared_error: 2.6150\n",
            "Epoch 188/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.7017 - mean_absolute_error: 1.1483 - mean_squared_error: 2.7017\n",
            "Epoch 188: val_loss improved from 2.61502 to 2.60984, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.7049 - mean_absolute_error: 1.1500 - mean_squared_error: 2.7049 - val_loss: 2.6098 - val_mean_absolute_error: 1.1295 - val_mean_squared_error: 2.6098\n",
            "Epoch 189/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.7174 - mean_absolute_error: 1.1525 - mean_squared_error: 2.7174\n",
            "Epoch 189: val_loss improved from 2.60984 to 2.60334, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.6993 - mean_absolute_error: 1.1493 - mean_squared_error: 2.6993 - val_loss: 2.6033 - val_mean_absolute_error: 1.1288 - val_mean_squared_error: 2.6033\n",
            "Epoch 190/1000\n",
            "218/245 [=========================>....] - ETA: 0s - loss: 2.6617 - mean_absolute_error: 1.1427 - mean_squared_error: 2.6617\n",
            "Epoch 190: val_loss improved from 2.60334 to 2.59818, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6945 - mean_absolute_error: 1.1469 - mean_squared_error: 2.6945 - val_loss: 2.5982 - val_mean_absolute_error: 1.1275 - val_mean_squared_error: 2.5982\n",
            "Epoch 191/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.6859 - mean_absolute_error: 1.1439 - mean_squared_error: 2.6859\n",
            "Epoch 191: val_loss improved from 2.59818 to 2.59348, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6891 - mean_absolute_error: 1.1455 - mean_squared_error: 2.6891 - val_loss: 2.5935 - val_mean_absolute_error: 1.1256 - val_mean_squared_error: 2.5935\n",
            "Epoch 192/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.7018 - mean_absolute_error: 1.1478 - mean_squared_error: 2.7018\n",
            "Epoch 192: val_loss improved from 2.59348 to 2.58842, saving model to best_model3.h5\n",
            "245/245 [==============================] - 2s 8ms/step - loss: 2.6831 - mean_absolute_error: 1.1432 - mean_squared_error: 2.6831 - val_loss: 2.5884 - val_mean_absolute_error: 1.1242 - val_mean_squared_error: 2.5884\n",
            "Epoch 193/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 2.6788 - mean_absolute_error: 1.1415 - mean_squared_error: 2.6788\n",
            "Epoch 193: val_loss improved from 2.58842 to 2.58400, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.6784 - mean_absolute_error: 1.1425 - mean_squared_error: 2.6784 - val_loss: 2.5840 - val_mean_absolute_error: 1.1220 - val_mean_squared_error: 2.5840\n",
            "Epoch 194/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.6903 - mean_absolute_error: 1.1440 - mean_squared_error: 2.6903\n",
            "Epoch 194: val_loss improved from 2.58400 to 2.57695, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.6722 - mean_absolute_error: 1.1408 - mean_squared_error: 2.6722 - val_loss: 2.5770 - val_mean_absolute_error: 1.1226 - val_mean_squared_error: 2.5770\n",
            "Epoch 195/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.6645 - mean_absolute_error: 1.1397 - mean_squared_error: 2.6645\n",
            "Epoch 195: val_loss did not improve from 2.57695\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.6645 - mean_absolute_error: 1.1397 - mean_squared_error: 2.6645 - val_loss: 2.5834 - val_mean_absolute_error: 1.1187 - val_mean_squared_error: 2.5834\n",
            "Epoch 196/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.6720 - mean_absolute_error: 1.1397 - mean_squared_error: 2.6720\n",
            "Epoch 196: val_loss improved from 2.57695 to 2.56625, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.6607 - mean_absolute_error: 1.1367 - mean_squared_error: 2.6607 - val_loss: 2.5662 - val_mean_absolute_error: 1.1197 - val_mean_squared_error: 2.5662\n",
            "Epoch 197/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.6408 - mean_absolute_error: 1.1332 - mean_squared_error: 2.6408\n",
            "Epoch 197: val_loss improved from 2.56625 to 2.56507, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.6557 - mean_absolute_error: 1.1376 - mean_squared_error: 2.6557 - val_loss: 2.5651 - val_mean_absolute_error: 1.1166 - val_mean_squared_error: 2.5651\n",
            "Epoch 198/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.6340 - mean_absolute_error: 1.1311 - mean_squared_error: 2.6340\n",
            "Epoch 198: val_loss improved from 2.56507 to 2.55624, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6504 - mean_absolute_error: 1.1354 - mean_squared_error: 2.6504 - val_loss: 2.5562 - val_mean_absolute_error: 1.1162 - val_mean_squared_error: 2.5562\n",
            "Epoch 199/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.6474 - mean_absolute_error: 1.1338 - mean_squared_error: 2.6474\n",
            "Epoch 199: val_loss improved from 2.55624 to 2.55042, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.6445 - mean_absolute_error: 1.1336 - mean_squared_error: 2.6445 - val_loss: 2.5504 - val_mean_absolute_error: 1.1152 - val_mean_squared_error: 2.5504\n",
            "Epoch 200/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.6433 - mean_absolute_error: 1.1335 - mean_squared_error: 2.6433\n",
            "Epoch 200: val_loss improved from 2.55042 to 2.54938, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.6381 - mean_absolute_error: 1.1326 - mean_squared_error: 2.6381 - val_loss: 2.5494 - val_mean_absolute_error: 1.1122 - val_mean_squared_error: 2.5494\n",
            "Epoch 201/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.6337 - mean_absolute_error: 1.1308 - mean_squared_error: 2.6337\n",
            "Epoch 201: val_loss improved from 2.54938 to 2.54045, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.6335 - mean_absolute_error: 1.1300 - mean_squared_error: 2.6335 - val_loss: 2.5405 - val_mean_absolute_error: 1.1120 - val_mean_squared_error: 2.5405\n",
            "Epoch 202/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.6250 - mean_absolute_error: 1.1294 - mean_squared_error: 2.6250\n",
            "Epoch 202: val_loss improved from 2.54045 to 2.53711, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.6279 - mean_absolute_error: 1.1294 - mean_squared_error: 2.6279 - val_loss: 2.5371 - val_mean_absolute_error: 1.1101 - val_mean_squared_error: 2.5371\n",
            "Epoch 203/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.6238 - mean_absolute_error: 1.1296 - mean_squared_error: 2.6238\n",
            "Epoch 203: val_loss improved from 2.53711 to 2.53334, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6211 - mean_absolute_error: 1.1284 - mean_squared_error: 2.6211 - val_loss: 2.5333 - val_mean_absolute_error: 1.1082 - val_mean_squared_error: 2.5333\n",
            "Epoch 204/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 2.6322 - mean_absolute_error: 1.1310 - mean_squared_error: 2.6322\n",
            "Epoch 204: val_loss improved from 2.53334 to 2.52592, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6169 - mean_absolute_error: 1.1264 - mean_squared_error: 2.6169 - val_loss: 2.5259 - val_mean_absolute_error: 1.1073 - val_mean_squared_error: 2.5259\n",
            "Epoch 205/1000\n",
            "216/245 [=========================>....] - ETA: 0s - loss: 2.6520 - mean_absolute_error: 1.1341 - mean_squared_error: 2.6520\n",
            "Epoch 205: val_loss improved from 2.52592 to 2.51992, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.6099 - mean_absolute_error: 1.1250 - mean_squared_error: 2.6099 - val_loss: 2.5199 - val_mean_absolute_error: 1.1064 - val_mean_squared_error: 2.5199\n",
            "Epoch 206/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.6020 - mean_absolute_error: 1.1210 - mean_squared_error: 2.6020\n",
            "Epoch 206: val_loss improved from 2.51992 to 2.51252, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6037 - mean_absolute_error: 1.1238 - mean_squared_error: 2.6037 - val_loss: 2.5125 - val_mean_absolute_error: 1.1064 - val_mean_squared_error: 2.5125\n",
            "Epoch 207/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.6036 - mean_absolute_error: 1.1236 - mean_squared_error: 2.6036\n",
            "Epoch 207: val_loss improved from 2.51252 to 2.50811, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5991 - mean_absolute_error: 1.1232 - mean_squared_error: 2.5991 - val_loss: 2.5081 - val_mean_absolute_error: 1.1041 - val_mean_squared_error: 2.5081\n",
            "Epoch 208/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.5541 - mean_absolute_error: 1.1125 - mean_squared_error: 2.5541\n",
            "Epoch 208: val_loss improved from 2.50811 to 2.50385, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5931 - mean_absolute_error: 1.1215 - mean_squared_error: 2.5931 - val_loss: 2.5038 - val_mean_absolute_error: 1.1019 - val_mean_squared_error: 2.5038\n",
            "Epoch 209/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.6023 - mean_absolute_error: 1.1215 - mean_squared_error: 2.6023\n",
            "Epoch 209: val_loss improved from 2.50385 to 2.49979, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.5880 - mean_absolute_error: 1.1209 - mean_squared_error: 2.5880 - val_loss: 2.4998 - val_mean_absolute_error: 1.1007 - val_mean_squared_error: 2.4998\n",
            "Epoch 210/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.5941 - mean_absolute_error: 1.1226 - mean_squared_error: 2.5941\n",
            "Epoch 210: val_loss did not improve from 2.49979\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5807 - mean_absolute_error: 1.1193 - mean_squared_error: 2.5807 - val_loss: 2.5006 - val_mean_absolute_error: 1.0988 - val_mean_squared_error: 2.5006\n",
            "Epoch 211/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 2.5762 - mean_absolute_error: 1.1163 - mean_squared_error: 2.5762\n",
            "Epoch 211: val_loss improved from 2.49979 to 2.49120, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5772 - mean_absolute_error: 1.1171 - mean_squared_error: 2.5772 - val_loss: 2.4912 - val_mean_absolute_error: 1.0975 - val_mean_squared_error: 2.4912\n",
            "Epoch 212/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.5628 - mean_absolute_error: 1.1114 - mean_squared_error: 2.5628\n",
            "Epoch 212: val_loss improved from 2.49120 to 2.48110, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.5697 - mean_absolute_error: 1.1159 - mean_squared_error: 2.5697 - val_loss: 2.4811 - val_mean_absolute_error: 1.0976 - val_mean_squared_error: 2.4811\n",
            "Epoch 213/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.5942 - mean_absolute_error: 1.1183 - mean_squared_error: 2.5942\n",
            "Epoch 213: val_loss improved from 2.48110 to 2.47368, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5641 - mean_absolute_error: 1.1141 - mean_squared_error: 2.5641 - val_loss: 2.4737 - val_mean_absolute_error: 1.0983 - val_mean_squared_error: 2.4737\n",
            "Epoch 214/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.5210 - mean_absolute_error: 1.1072 - mean_squared_error: 2.5210\n",
            "Epoch 214: val_loss improved from 2.47368 to 2.47152, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5584 - mean_absolute_error: 1.1151 - mean_squared_error: 2.5584 - val_loss: 2.4715 - val_mean_absolute_error: 1.0943 - val_mean_squared_error: 2.4715\n",
            "Epoch 215/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.5514 - mean_absolute_error: 1.1129 - mean_squared_error: 2.5514\n",
            "Epoch 215: val_loss improved from 2.47152 to 2.46852, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5532 - mean_absolute_error: 1.1130 - mean_squared_error: 2.5532 - val_loss: 2.4685 - val_mean_absolute_error: 1.0930 - val_mean_squared_error: 2.4685\n",
            "Epoch 216/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.5576 - mean_absolute_error: 1.1120 - mean_squared_error: 2.5576\n",
            "Epoch 216: val_loss improved from 2.46852 to 2.45986, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.5473 - mean_absolute_error: 1.1104 - mean_squared_error: 2.5473 - val_loss: 2.4599 - val_mean_absolute_error: 1.0924 - val_mean_squared_error: 2.4599\n",
            "Epoch 217/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.5465 - mean_absolute_error: 1.1101 - mean_squared_error: 2.5465\n",
            "Epoch 217: val_loss improved from 2.45986 to 2.45616, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.5417 - mean_absolute_error: 1.1092 - mean_squared_error: 2.5417 - val_loss: 2.4562 - val_mean_absolute_error: 1.0910 - val_mean_squared_error: 2.4562\n",
            "Epoch 218/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.5530 - mean_absolute_error: 1.1112 - mean_squared_error: 2.5530\n",
            "Epoch 218: val_loss improved from 2.45616 to 2.44978, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5352 - mean_absolute_error: 1.1092 - mean_squared_error: 2.5352 - val_loss: 2.4498 - val_mean_absolute_error: 1.0899 - val_mean_squared_error: 2.4498\n",
            "Epoch 219/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.5012 - mean_absolute_error: 1.0975 - mean_squared_error: 2.5012\n",
            "Epoch 219: val_loss improved from 2.44978 to 2.44533, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5297 - mean_absolute_error: 1.1073 - mean_squared_error: 2.5297 - val_loss: 2.4453 - val_mean_absolute_error: 1.0879 - val_mean_squared_error: 2.4453\n",
            "Epoch 220/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.5408 - mean_absolute_error: 1.1074 - mean_squared_error: 2.5408\n",
            "Epoch 220: val_loss improved from 2.44533 to 2.43738, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5239 - mean_absolute_error: 1.1058 - mean_squared_error: 2.5239 - val_loss: 2.4374 - val_mean_absolute_error: 1.0879 - val_mean_squared_error: 2.4374\n",
            "Epoch 221/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.5193 - mean_absolute_error: 1.1061 - mean_squared_error: 2.5193\n",
            "Epoch 221: val_loss did not improve from 2.43738\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.5176 - mean_absolute_error: 1.1049 - mean_squared_error: 2.5176 - val_loss: 2.4387 - val_mean_absolute_error: 1.0855 - val_mean_squared_error: 2.4387\n",
            "Epoch 222/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 2.5370 - mean_absolute_error: 1.1110 - mean_squared_error: 2.5370\n",
            "Epoch 222: val_loss improved from 2.43738 to 2.42942, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 6ms/step - loss: 2.5117 - mean_absolute_error: 1.1031 - mean_squared_error: 2.5117 - val_loss: 2.4294 - val_mean_absolute_error: 1.0845 - val_mean_squared_error: 2.4294\n",
            "Epoch 223/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.4818 - mean_absolute_error: 1.0966 - mean_squared_error: 2.4818\n",
            "Epoch 223: val_loss improved from 2.42942 to 2.42055, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.5062 - mean_absolute_error: 1.1021 - mean_squared_error: 2.5062 - val_loss: 2.4206 - val_mean_absolute_error: 1.0840 - val_mean_squared_error: 2.4206\n",
            "Epoch 224/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 2.4959 - mean_absolute_error: 1.1015 - mean_squared_error: 2.4959\n",
            "Epoch 224: val_loss improved from 2.42055 to 2.41719, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.5000 - mean_absolute_error: 1.1014 - mean_squared_error: 2.5000 - val_loss: 2.4172 - val_mean_absolute_error: 1.0822 - val_mean_squared_error: 2.4172\n",
            "Epoch 225/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.4940 - mean_absolute_error: 1.0989 - mean_squared_error: 2.4940\n",
            "Epoch 225: val_loss improved from 2.41719 to 2.40820, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.4932 - mean_absolute_error: 1.0994 - mean_squared_error: 2.4932 - val_loss: 2.4082 - val_mean_absolute_error: 1.0822 - val_mean_squared_error: 2.4082\n",
            "Epoch 226/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.4931 - mean_absolute_error: 1.0958 - mean_squared_error: 2.4931\n",
            "Epoch 226: val_loss improved from 2.40820 to 2.40295, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 6ms/step - loss: 2.4883 - mean_absolute_error: 1.0971 - mean_squared_error: 2.4883 - val_loss: 2.4030 - val_mean_absolute_error: 1.0807 - val_mean_squared_error: 2.4030\n",
            "Epoch 227/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.4418 - mean_absolute_error: 1.0874 - mean_squared_error: 2.4418\n",
            "Epoch 227: val_loss improved from 2.40295 to 2.39892, saving model to best_model3.h5\n",
            "245/245 [==============================] - 2s 8ms/step - loss: 2.4825 - mean_absolute_error: 1.0968 - mean_squared_error: 2.4825 - val_loss: 2.3989 - val_mean_absolute_error: 1.0789 - val_mean_squared_error: 2.3989\n",
            "Epoch 228/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.5005 - mean_absolute_error: 1.1007 - mean_squared_error: 2.5005\n",
            "Epoch 228: val_loss improved from 2.39892 to 2.39095, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.4766 - mean_absolute_error: 1.0951 - mean_squared_error: 2.4766 - val_loss: 2.3909 - val_mean_absolute_error: 1.0797 - val_mean_squared_error: 2.3909\n",
            "Epoch 229/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.4710 - mean_absolute_error: 1.0950 - mean_squared_error: 2.4710\n",
            "Epoch 229: val_loss improved from 2.39095 to 2.38672, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.4710 - mean_absolute_error: 1.0950 - mean_squared_error: 2.4710 - val_loss: 2.3867 - val_mean_absolute_error: 1.0771 - val_mean_squared_error: 2.3867\n",
            "Epoch 230/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.4393 - mean_absolute_error: 1.0879 - mean_squared_error: 2.4393\n",
            "Epoch 230: val_loss improved from 2.38672 to 2.38186, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.4656 - mean_absolute_error: 1.0937 - mean_squared_error: 2.4656 - val_loss: 2.3819 - val_mean_absolute_error: 1.0763 - val_mean_squared_error: 2.3819\n",
            "Epoch 231/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.4783 - mean_absolute_error: 1.0967 - mean_squared_error: 2.4783\n",
            "Epoch 231: val_loss improved from 2.38186 to 2.37517, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.4585 - mean_absolute_error: 1.0926 - mean_squared_error: 2.4585 - val_loss: 2.3752 - val_mean_absolute_error: 1.0755 - val_mean_squared_error: 2.3752\n",
            "Epoch 232/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.4304 - mean_absolute_error: 1.0862 - mean_squared_error: 2.4304\n",
            "Epoch 232: val_loss improved from 2.37517 to 2.37361, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.4527 - mean_absolute_error: 1.0909 - mean_squared_error: 2.4527 - val_loss: 2.3736 - val_mean_absolute_error: 1.0732 - val_mean_squared_error: 2.3736\n",
            "Epoch 233/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.4463 - mean_absolute_error: 1.0887 - mean_squared_error: 2.4463\n",
            "Epoch 233: val_loss improved from 2.37361 to 2.36428, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.4463 - mean_absolute_error: 1.0887 - mean_squared_error: 2.4463 - val_loss: 2.3643 - val_mean_absolute_error: 1.0732 - val_mean_squared_error: 2.3643\n",
            "Epoch 234/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.4358 - mean_absolute_error: 1.0864 - mean_squared_error: 2.4358\n",
            "Epoch 234: val_loss improved from 2.36428 to 2.35848, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.4417 - mean_absolute_error: 1.0880 - mean_squared_error: 2.4417 - val_loss: 2.3585 - val_mean_absolute_error: 1.0719 - val_mean_squared_error: 2.3585\n",
            "Epoch 235/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.4368 - mean_absolute_error: 1.0863 - mean_squared_error: 2.4368\n",
            "Epoch 235: val_loss improved from 2.35848 to 2.35296, saving model to best_model3.h5\n",
            "245/245 [==============================] - 2s 9ms/step - loss: 2.4352 - mean_absolute_error: 1.0859 - mean_squared_error: 2.4352 - val_loss: 2.3530 - val_mean_absolute_error: 1.0721 - val_mean_squared_error: 2.3530\n",
            "Epoch 236/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.4056 - mean_absolute_error: 1.0784 - mean_squared_error: 2.4056\n",
            "Epoch 236: val_loss improved from 2.35296 to 2.34774, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4311 - mean_absolute_error: 1.0864 - mean_squared_error: 2.4311 - val_loss: 2.3477 - val_mean_absolute_error: 1.0699 - val_mean_squared_error: 2.3477\n",
            "Epoch 237/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.4236 - mean_absolute_error: 1.0852 - mean_squared_error: 2.4236\n",
            "Epoch 237: val_loss improved from 2.34774 to 2.34339, saving model to best_model3.h5\n",
            "245/245 [==============================] - 2s 7ms/step - loss: 2.4256 - mean_absolute_error: 1.0854 - mean_squared_error: 2.4256 - val_loss: 2.3434 - val_mean_absolute_error: 1.0683 - val_mean_squared_error: 2.3434\n",
            "Epoch 238/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.4211 - mean_absolute_error: 1.0840 - mean_squared_error: 2.4211\n",
            "Epoch 238: val_loss improved from 2.34339 to 2.33908, saving model to best_model3.h5\n",
            "245/245 [==============================] - 2s 6ms/step - loss: 2.4184 - mean_absolute_error: 1.0828 - mean_squared_error: 2.4184 - val_loss: 2.3391 - val_mean_absolute_error: 1.0677 - val_mean_squared_error: 2.3391\n",
            "Epoch 239/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.4147 - mean_absolute_error: 1.0818 - mean_squared_error: 2.4146\n",
            "Epoch 239: val_loss did not improve from 2.33908\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.4116 - mean_absolute_error: 1.0822 - mean_squared_error: 2.4116 - val_loss: 2.3436 - val_mean_absolute_error: 1.0669 - val_mean_squared_error: 2.3436\n",
            "Epoch 240/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.3831 - mean_absolute_error: 1.0737 - mean_squared_error: 2.3831\n",
            "Epoch 240: val_loss improved from 2.33908 to 2.33208, saving model to best_model3.h5\n",
            "245/245 [==============================] - 2s 10ms/step - loss: 2.4086 - mean_absolute_error: 1.0807 - mean_squared_error: 2.4086 - val_loss: 2.3321 - val_mean_absolute_error: 1.0651 - val_mean_squared_error: 2.3321\n",
            "Epoch 241/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.4062 - mean_absolute_error: 1.0805 - mean_squared_error: 2.4062\n",
            "Epoch 241: val_loss improved from 2.33208 to 2.32747, saving model to best_model3.h5\n",
            "245/245 [==============================] - 3s 11ms/step - loss: 2.4020 - mean_absolute_error: 1.0807 - mean_squared_error: 2.4020 - val_loss: 2.3275 - val_mean_absolute_error: 1.0648 - val_mean_squared_error: 2.3275\n",
            "Epoch 242/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.3949 - mean_absolute_error: 1.0802 - mean_squared_error: 2.3949\n",
            "Epoch 242: val_loss improved from 2.32747 to 2.32215, saving model to best_model3.h5\n",
            "245/245 [==============================] - 2s 6ms/step - loss: 2.3960 - mean_absolute_error: 1.0790 - mean_squared_error: 2.3960 - val_loss: 2.3221 - val_mean_absolute_error: 1.0632 - val_mean_squared_error: 2.3221\n",
            "Epoch 243/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.4005 - mean_absolute_error: 1.0809 - mean_squared_error: 2.4005\n",
            "Epoch 243: val_loss improved from 2.32215 to 2.31153, saving model to best_model3.h5\n",
            "245/245 [==============================] - 2s 7ms/step - loss: 2.3915 - mean_absolute_error: 1.0782 - mean_squared_error: 2.3915 - val_loss: 2.3115 - val_mean_absolute_error: 1.0627 - val_mean_squared_error: 2.3115\n",
            "Epoch 244/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.3760 - mean_absolute_error: 1.0722 - mean_squared_error: 2.3760\n",
            "Epoch 244: val_loss improved from 2.31153 to 2.30628, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 6ms/step - loss: 2.3848 - mean_absolute_error: 1.0754 - mean_squared_error: 2.3848 - val_loss: 2.3063 - val_mean_absolute_error: 1.0614 - val_mean_squared_error: 2.3063\n",
            "Epoch 245/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.3921 - mean_absolute_error: 1.0787 - mean_squared_error: 2.3921\n",
            "Epoch 245: val_loss improved from 2.30628 to 2.30206, saving model to best_model3.h5\n",
            "245/245 [==============================] - 2s 6ms/step - loss: 2.3799 - mean_absolute_error: 1.0757 - mean_squared_error: 2.3799 - val_loss: 2.3021 - val_mean_absolute_error: 1.0604 - val_mean_squared_error: 2.3021\n",
            "Epoch 246/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.3787 - mean_absolute_error: 1.0760 - mean_squared_error: 2.3787\n",
            "Epoch 246: val_loss improved from 2.30206 to 2.30001, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3745 - mean_absolute_error: 1.0741 - mean_squared_error: 2.3745 - val_loss: 2.3000 - val_mean_absolute_error: 1.0593 - val_mean_squared_error: 2.3000\n",
            "Epoch 247/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.3720 - mean_absolute_error: 1.0745 - mean_squared_error: 2.3720\n",
            "Epoch 247: val_loss improved from 2.30001 to 2.29353, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3687 - mean_absolute_error: 1.0733 - mean_squared_error: 2.3687 - val_loss: 2.2935 - val_mean_absolute_error: 1.0581 - val_mean_squared_error: 2.2935\n",
            "Epoch 248/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.3720 - mean_absolute_error: 1.0739 - mean_squared_error: 2.3720\n",
            "Epoch 248: val_loss improved from 2.29353 to 2.28650, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3634 - mean_absolute_error: 1.0704 - mean_squared_error: 2.3634 - val_loss: 2.2865 - val_mean_absolute_error: 1.0576 - val_mean_squared_error: 2.2865\n",
            "Epoch 249/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 2.3596 - mean_absolute_error: 1.0688 - mean_squared_error: 2.3596\n",
            "Epoch 249: val_loss improved from 2.28650 to 2.28325, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3582 - mean_absolute_error: 1.0700 - mean_squared_error: 2.3582 - val_loss: 2.2833 - val_mean_absolute_error: 1.0567 - val_mean_squared_error: 2.2833\n",
            "Epoch 250/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.3653 - mean_absolute_error: 1.0705 - mean_squared_error: 2.3653\n",
            "Epoch 250: val_loss improved from 2.28325 to 2.27949, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3531 - mean_absolute_error: 1.0692 - mean_squared_error: 2.3531 - val_loss: 2.2795 - val_mean_absolute_error: 1.0560 - val_mean_squared_error: 2.2795\n",
            "Epoch 251/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.3505 - mean_absolute_error: 1.0685 - mean_squared_error: 2.3505\n",
            "Epoch 251: val_loss improved from 2.27949 to 2.27257, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3485 - mean_absolute_error: 1.0680 - mean_squared_error: 2.3485 - val_loss: 2.2726 - val_mean_absolute_error: 1.0548 - val_mean_squared_error: 2.2726\n",
            "Epoch 252/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 2.3326 - mean_absolute_error: 1.0682 - mean_squared_error: 2.3326\n",
            "Epoch 252: val_loss improved from 2.27257 to 2.26710, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.3420 - mean_absolute_error: 1.0664 - mean_squared_error: 2.3420 - val_loss: 2.2671 - val_mean_absolute_error: 1.0538 - val_mean_squared_error: 2.2671\n",
            "Epoch 253/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 2.3409 - mean_absolute_error: 1.0673 - mean_squared_error: 2.3409\n",
            "Epoch 253: val_loss improved from 2.26710 to 2.26231, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3366 - mean_absolute_error: 1.0662 - mean_squared_error: 2.3366 - val_loss: 2.2623 - val_mean_absolute_error: 1.0529 - val_mean_squared_error: 2.2623\n",
            "Epoch 254/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.3378 - mean_absolute_error: 1.0670 - mean_squared_error: 2.3378\n",
            "Epoch 254: val_loss improved from 2.26231 to 2.25778, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3322 - mean_absolute_error: 1.0652 - mean_squared_error: 2.3322 - val_loss: 2.2578 - val_mean_absolute_error: 1.0519 - val_mean_squared_error: 2.2578\n",
            "Epoch 255/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.2889 - mean_absolute_error: 1.0571 - mean_squared_error: 2.2889\n",
            "Epoch 255: val_loss improved from 2.25778 to 2.25311, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3259 - mean_absolute_error: 1.0634 - mean_squared_error: 2.3259 - val_loss: 2.2531 - val_mean_absolute_error: 1.0510 - val_mean_squared_error: 2.2531\n",
            "Epoch 256/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.3131 - mean_absolute_error: 1.0605 - mean_squared_error: 2.3131\n",
            "Epoch 256: val_loss improved from 2.25311 to 2.24811, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3216 - mean_absolute_error: 1.0623 - mean_squared_error: 2.3216 - val_loss: 2.2481 - val_mean_absolute_error: 1.0501 - val_mean_squared_error: 2.2481\n",
            "Epoch 257/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.3156 - mean_absolute_error: 1.0623 - mean_squared_error: 2.3156\n",
            "Epoch 257: val_loss improved from 2.24811 to 2.24591, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3158 - mean_absolute_error: 1.0619 - mean_squared_error: 2.3158 - val_loss: 2.2459 - val_mean_absolute_error: 1.0492 - val_mean_squared_error: 2.2459\n",
            "Epoch 258/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.2943 - mean_absolute_error: 1.0571 - mean_squared_error: 2.2943\n",
            "Epoch 258: val_loss improved from 2.24591 to 2.23920, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3102 - mean_absolute_error: 1.0601 - mean_squared_error: 2.3102 - val_loss: 2.2392 - val_mean_absolute_error: 1.0480 - val_mean_squared_error: 2.2392\n",
            "Epoch 259/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.3058 - mean_absolute_error: 1.0598 - mean_squared_error: 2.3058\n",
            "Epoch 259: val_loss improved from 2.23920 to 2.23412, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3058 - mean_absolute_error: 1.0598 - mean_squared_error: 2.3058 - val_loss: 2.2341 - val_mean_absolute_error: 1.0472 - val_mean_squared_error: 2.2341\n",
            "Epoch 260/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.2940 - mean_absolute_error: 1.0560 - mean_squared_error: 2.2940\n",
            "Epoch 260: val_loss improved from 2.23412 to 2.22875, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2986 - mean_absolute_error: 1.0566 - mean_squared_error: 2.2986 - val_loss: 2.2287 - val_mean_absolute_error: 1.0464 - val_mean_squared_error: 2.2287\n",
            "Epoch 261/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.2789 - mean_absolute_error: 1.0549 - mean_squared_error: 2.2789\n",
            "Epoch 261: val_loss improved from 2.22875 to 2.22361, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2953 - mean_absolute_error: 1.0575 - mean_squared_error: 2.2953 - val_loss: 2.2236 - val_mean_absolute_error: 1.0455 - val_mean_squared_error: 2.2236\n",
            "Epoch 262/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.3046 - mean_absolute_error: 1.0563 - mean_squared_error: 2.3046\n",
            "Epoch 262: val_loss improved from 2.22361 to 2.21974, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2914 - mean_absolute_error: 1.0560 - mean_squared_error: 2.2914 - val_loss: 2.2197 - val_mean_absolute_error: 1.0445 - val_mean_squared_error: 2.2197\n",
            "Epoch 263/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.2895 - mean_absolute_error: 1.0557 - mean_squared_error: 2.2895\n",
            "Epoch 263: val_loss improved from 2.21974 to 2.21660, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2853 - mean_absolute_error: 1.0554 - mean_squared_error: 2.2853 - val_loss: 2.2166 - val_mean_absolute_error: 1.0434 - val_mean_squared_error: 2.2166\n",
            "Epoch 264/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.2908 - mean_absolute_error: 1.0553 - mean_squared_error: 2.2908\n",
            "Epoch 264: val_loss improved from 2.21660 to 2.21301, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2795 - mean_absolute_error: 1.0535 - mean_squared_error: 2.2795 - val_loss: 2.2130 - val_mean_absolute_error: 1.0428 - val_mean_squared_error: 2.2130\n",
            "Epoch 265/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.2752 - mean_absolute_error: 1.0516 - mean_squared_error: 2.2752\n",
            "Epoch 265: val_loss improved from 2.21301 to 2.20638, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2745 - mean_absolute_error: 1.0519 - mean_squared_error: 2.2745 - val_loss: 2.2064 - val_mean_absolute_error: 1.0416 - val_mean_squared_error: 2.2064\n",
            "Epoch 266/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.2656 - mean_absolute_error: 1.0510 - mean_squared_error: 2.2656\n",
            "Epoch 266: val_loss improved from 2.20638 to 2.20047, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2685 - mean_absolute_error: 1.0509 - mean_squared_error: 2.2685 - val_loss: 2.2005 - val_mean_absolute_error: 1.0404 - val_mean_squared_error: 2.2005\n",
            "Epoch 267/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.2747 - mean_absolute_error: 1.0532 - mean_squared_error: 2.2747\n",
            "Epoch 267: val_loss improved from 2.20047 to 2.19835, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2657 - mean_absolute_error: 1.0509 - mean_squared_error: 2.2657 - val_loss: 2.1984 - val_mean_absolute_error: 1.0398 - val_mean_squared_error: 2.1984\n",
            "Epoch 268/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 2.2704 - mean_absolute_error: 1.0499 - mean_squared_error: 2.2704\n",
            "Epoch 268: val_loss improved from 2.19835 to 2.19230, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2597 - mean_absolute_error: 1.0493 - mean_squared_error: 2.2597 - val_loss: 2.1923 - val_mean_absolute_error: 1.0388 - val_mean_squared_error: 2.1923\n",
            "Epoch 269/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.2390 - mean_absolute_error: 1.0451 - mean_squared_error: 2.2390\n",
            "Epoch 269: val_loss improved from 2.19230 to 2.19104, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2547 - mean_absolute_error: 1.0474 - mean_squared_error: 2.2547 - val_loss: 2.1910 - val_mean_absolute_error: 1.0382 - val_mean_squared_error: 2.1910\n",
            "Epoch 270/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.2434 - mean_absolute_error: 1.0457 - mean_squared_error: 2.2434\n",
            "Epoch 270: val_loss improved from 2.19104 to 2.18331, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2506 - mean_absolute_error: 1.0465 - mean_squared_error: 2.2506 - val_loss: 2.1833 - val_mean_absolute_error: 1.0371 - val_mean_squared_error: 2.1833\n",
            "Epoch 271/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.2663 - mean_absolute_error: 1.0511 - mean_squared_error: 2.2663\n",
            "Epoch 271: val_loss improved from 2.18331 to 2.17968, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2451 - mean_absolute_error: 1.0461 - mean_squared_error: 2.2451 - val_loss: 2.1797 - val_mean_absolute_error: 1.0363 - val_mean_squared_error: 2.1797\n",
            "Epoch 272/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.2436 - mean_absolute_error: 1.0461 - mean_squared_error: 2.2436\n",
            "Epoch 272: val_loss improved from 2.17968 to 2.17656, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2400 - mean_absolute_error: 1.0448 - mean_squared_error: 2.2400 - val_loss: 2.1766 - val_mean_absolute_error: 1.0356 - val_mean_squared_error: 2.1766\n",
            "Epoch 273/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.2340 - mean_absolute_error: 1.0426 - mean_squared_error: 2.2340\n",
            "Epoch 273: val_loss improved from 2.17656 to 2.17018, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2359 - mean_absolute_error: 1.0440 - mean_squared_error: 2.2359 - val_loss: 2.1702 - val_mean_absolute_error: 1.0347 - val_mean_squared_error: 2.1702\n",
            "Epoch 274/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.2331 - mean_absolute_error: 1.0432 - mean_squared_error: 2.2331\n",
            "Epoch 274: val_loss improved from 2.17018 to 2.16699, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2314 - mean_absolute_error: 1.0428 - mean_squared_error: 2.2314 - val_loss: 2.1670 - val_mean_absolute_error: 1.0339 - val_mean_squared_error: 2.1670\n",
            "Epoch 275/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.2310 - mean_absolute_error: 1.0428 - mean_squared_error: 2.2310\n",
            "Epoch 275: val_loss improved from 2.16699 to 2.16290, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2265 - mean_absolute_error: 1.0419 - mean_squared_error: 2.2265 - val_loss: 2.1629 - val_mean_absolute_error: 1.0323 - val_mean_squared_error: 2.1629\n",
            "Epoch 276/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.2212 - mean_absolute_error: 1.0410 - mean_squared_error: 2.2212\n",
            "Epoch 276: val_loss improved from 2.16290 to 2.15951, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2215 - mean_absolute_error: 1.0403 - mean_squared_error: 2.2215 - val_loss: 2.1595 - val_mean_absolute_error: 1.0319 - val_mean_squared_error: 2.1595\n",
            "Epoch 277/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.2359 - mean_absolute_error: 1.0447 - mean_squared_error: 2.2359\n",
            "Epoch 277: val_loss improved from 2.15951 to 2.15589, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2164 - mean_absolute_error: 1.0394 - mean_squared_error: 2.2164 - val_loss: 2.1559 - val_mean_absolute_error: 1.0311 - val_mean_squared_error: 2.1559\n",
            "Epoch 278/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.2015 - mean_absolute_error: 1.0367 - mean_squared_error: 2.2015\n",
            "Epoch 278: val_loss improved from 2.15589 to 2.15182, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2118 - mean_absolute_error: 1.0383 - mean_squared_error: 2.2118 - val_loss: 2.1518 - val_mean_absolute_error: 1.0300 - val_mean_squared_error: 2.1518\n",
            "Epoch 279/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.2149 - mean_absolute_error: 1.0403 - mean_squared_error: 2.2149\n",
            "Epoch 279: val_loss improved from 2.15182 to 2.14470, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2074 - mean_absolute_error: 1.0379 - mean_squared_error: 2.2074 - val_loss: 2.1447 - val_mean_absolute_error: 1.0285 - val_mean_squared_error: 2.1447\n",
            "Epoch 280/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.2071 - mean_absolute_error: 1.0378 - mean_squared_error: 2.2071\n",
            "Epoch 280: val_loss improved from 2.14470 to 2.14296, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2026 - mean_absolute_error: 1.0361 - mean_squared_error: 2.2026 - val_loss: 2.1430 - val_mean_absolute_error: 1.0279 - val_mean_squared_error: 2.1430\n",
            "Epoch 281/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.2129 - mean_absolute_error: 1.0379 - mean_squared_error: 2.2129\n",
            "Epoch 281: val_loss improved from 2.14296 to 2.13888, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1986 - mean_absolute_error: 1.0352 - mean_squared_error: 2.1986 - val_loss: 2.1389 - val_mean_absolute_error: 1.0279 - val_mean_squared_error: 2.1389\n",
            "Epoch 282/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.1864 - mean_absolute_error: 1.0298 - mean_squared_error: 2.1864\n",
            "Epoch 282: val_loss improved from 2.13888 to 2.13242, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1948 - mean_absolute_error: 1.0334 - mean_squared_error: 2.1948 - val_loss: 2.1324 - val_mean_absolute_error: 1.0263 - val_mean_squared_error: 2.1324\n",
            "Epoch 283/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 2.2111 - mean_absolute_error: 1.0384 - mean_squared_error: 2.2111\n",
            "Epoch 283: val_loss improved from 2.13242 to 2.12881, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1899 - mean_absolute_error: 1.0337 - mean_squared_error: 2.1899 - val_loss: 2.1288 - val_mean_absolute_error: 1.0252 - val_mean_squared_error: 2.1288\n",
            "Epoch 284/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.2038 - mean_absolute_error: 1.0387 - mean_squared_error: 2.2038\n",
            "Epoch 284: val_loss did not improve from 2.12881\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1851 - mean_absolute_error: 1.0330 - mean_squared_error: 2.1851 - val_loss: 2.1291 - val_mean_absolute_error: 1.0252 - val_mean_squared_error: 2.1291\n",
            "Epoch 285/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.1856 - mean_absolute_error: 1.0317 - mean_squared_error: 2.1856\n",
            "Epoch 285: val_loss improved from 2.12881 to 2.12254, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1807 - mean_absolute_error: 1.0316 - mean_squared_error: 2.1807 - val_loss: 2.1225 - val_mean_absolute_error: 1.0233 - val_mean_squared_error: 2.1225\n",
            "Epoch 286/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.1828 - mean_absolute_error: 1.0303 - mean_squared_error: 2.1828\n",
            "Epoch 286: val_loss improved from 2.12254 to 2.11822, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1767 - mean_absolute_error: 1.0297 - mean_squared_error: 2.1767 - val_loss: 2.1182 - val_mean_absolute_error: 1.0219 - val_mean_squared_error: 2.1182\n",
            "Epoch 287/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 2.1452 - mean_absolute_error: 1.0247 - mean_squared_error: 2.1452\n",
            "Epoch 287: val_loss improved from 2.11822 to 2.11506, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1725 - mean_absolute_error: 1.0288 - mean_squared_error: 2.1725 - val_loss: 2.1151 - val_mean_absolute_error: 1.0223 - val_mean_squared_error: 2.1151\n",
            "Epoch 288/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.1746 - mean_absolute_error: 1.0303 - mean_squared_error: 2.1746\n",
            "Epoch 288: val_loss improved from 2.11506 to 2.10981, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1674 - mean_absolute_error: 1.0282 - mean_squared_error: 2.1674 - val_loss: 2.1098 - val_mean_absolute_error: 1.0201 - val_mean_squared_error: 2.1098\n",
            "Epoch 289/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.1443 - mean_absolute_error: 1.0204 - mean_squared_error: 2.1443\n",
            "Epoch 289: val_loss did not improve from 2.10981\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1622 - mean_absolute_error: 1.0255 - mean_squared_error: 2.1622 - val_loss: 2.1153 - val_mean_absolute_error: 1.0226 - val_mean_squared_error: 2.1153\n",
            "Epoch 290/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.1674 - mean_absolute_error: 1.0279 - mean_squared_error: 2.1674\n",
            "Epoch 290: val_loss improved from 2.10981 to 2.10175, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1591 - mean_absolute_error: 1.0255 - mean_squared_error: 2.1591 - val_loss: 2.1018 - val_mean_absolute_error: 1.0190 - val_mean_squared_error: 2.1018\n",
            "Epoch 291/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.1400 - mean_absolute_error: 1.0203 - mean_squared_error: 2.1400\n",
            "Epoch 291: val_loss improved from 2.10175 to 2.09913, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1547 - mean_absolute_error: 1.0243 - mean_squared_error: 2.1547 - val_loss: 2.0991 - val_mean_absolute_error: 1.0187 - val_mean_squared_error: 2.0991\n",
            "Epoch 292/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.1710 - mean_absolute_error: 1.0279 - mean_squared_error: 2.1710\n",
            "Epoch 292: val_loss improved from 2.09913 to 2.09738, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1509 - mean_absolute_error: 1.0232 - mean_squared_error: 2.1509 - val_loss: 2.0974 - val_mean_absolute_error: 1.0189 - val_mean_squared_error: 2.0974\n",
            "Epoch 293/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.1451 - mean_absolute_error: 1.0240 - mean_squared_error: 2.1451\n",
            "Epoch 293: val_loss improved from 2.09738 to 2.09281, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1464 - mean_absolute_error: 1.0231 - mean_squared_error: 2.1464 - val_loss: 2.0928 - val_mean_absolute_error: 1.0174 - val_mean_squared_error: 2.0928\n",
            "Epoch 294/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.1333 - mean_absolute_error: 1.0196 - mean_squared_error: 2.1333\n",
            "Epoch 294: val_loss improved from 2.09281 to 2.08948, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1436 - mean_absolute_error: 1.0212 - mean_squared_error: 2.1436 - val_loss: 2.0895 - val_mean_absolute_error: 1.0172 - val_mean_squared_error: 2.0895\n",
            "Epoch 295/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.1669 - mean_absolute_error: 1.0261 - mean_squared_error: 2.1669\n",
            "Epoch 295: val_loss improved from 2.08948 to 2.08331, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1377 - mean_absolute_error: 1.0206 - mean_squared_error: 2.1377 - val_loss: 2.0833 - val_mean_absolute_error: 1.0153 - val_mean_squared_error: 2.0833\n",
            "Epoch 296/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.1355 - mean_absolute_error: 1.0203 - mean_squared_error: 2.1355\n",
            "Epoch 296: val_loss improved from 2.08331 to 2.08278, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1342 - mean_absolute_error: 1.0202 - mean_squared_error: 2.1342 - val_loss: 2.0828 - val_mean_absolute_error: 1.0154 - val_mean_squared_error: 2.0828\n",
            "Epoch 297/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.1326 - mean_absolute_error: 1.0190 - mean_squared_error: 2.1326\n",
            "Epoch 297: val_loss improved from 2.08278 to 2.08144, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1298 - mean_absolute_error: 1.0187 - mean_squared_error: 2.1298 - val_loss: 2.0814 - val_mean_absolute_error: 1.0153 - val_mean_squared_error: 2.0814\n",
            "Epoch 298/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.1165 - mean_absolute_error: 1.0152 - mean_squared_error: 2.1165\n",
            "Epoch 298: val_loss improved from 2.08144 to 2.07244, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1241 - mean_absolute_error: 1.0166 - mean_squared_error: 2.1241 - val_loss: 2.0724 - val_mean_absolute_error: 1.0126 - val_mean_squared_error: 2.0724\n",
            "Epoch 299/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.1416 - mean_absolute_error: 1.0237 - mean_squared_error: 2.1416\n",
            "Epoch 299: val_loss improved from 2.07244 to 2.06904, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1218 - mean_absolute_error: 1.0170 - mean_squared_error: 2.1218 - val_loss: 2.0690 - val_mean_absolute_error: 1.0117 - val_mean_squared_error: 2.0690\n",
            "Epoch 300/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.1267 - mean_absolute_error: 1.0175 - mean_squared_error: 2.1267\n",
            "Epoch 300: val_loss did not improve from 2.06904\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1175 - mean_absolute_error: 1.0157 - mean_squared_error: 2.1175 - val_loss: 2.0736 - val_mean_absolute_error: 1.0137 - val_mean_squared_error: 2.0736\n",
            "Epoch 301/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.1146 - mean_absolute_error: 1.0166 - mean_squared_error: 2.1146\n",
            "Epoch 301: val_loss improved from 2.06904 to 2.06398, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1145 - mean_absolute_error: 1.0151 - mean_squared_error: 2.1145 - val_loss: 2.0640 - val_mean_absolute_error: 1.0109 - val_mean_squared_error: 2.0640\n",
            "Epoch 302/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.1010 - mean_absolute_error: 1.0109 - mean_squared_error: 2.1010\n",
            "Epoch 302: val_loss improved from 2.06398 to 2.05877, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1108 - mean_absolute_error: 1.0136 - mean_squared_error: 2.1108 - val_loss: 2.0588 - val_mean_absolute_error: 1.0086 - val_mean_squared_error: 2.0588\n",
            "Epoch 303/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 2.1293 - mean_absolute_error: 1.0170 - mean_squared_error: 2.1293\n",
            "Epoch 303: val_loss improved from 2.05877 to 2.05608, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1070 - mean_absolute_error: 1.0117 - mean_squared_error: 2.1070 - val_loss: 2.0561 - val_mean_absolute_error: 1.0085 - val_mean_squared_error: 2.0561\n",
            "Epoch 304/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.1027 - mean_absolute_error: 1.0125 - mean_squared_error: 2.1027\n",
            "Epoch 304: val_loss improved from 2.05608 to 2.05253, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1027 - mean_absolute_error: 1.0125 - mean_squared_error: 2.1027 - val_loss: 2.0525 - val_mean_absolute_error: 1.0078 - val_mean_squared_error: 2.0525\n",
            "Epoch 305/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.1043 - mean_absolute_error: 1.0132 - mean_squared_error: 2.1043\n",
            "Epoch 305: val_loss improved from 2.05253 to 2.04910, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0989 - mean_absolute_error: 1.0115 - mean_squared_error: 2.0989 - val_loss: 2.0491 - val_mean_absolute_error: 1.0061 - val_mean_squared_error: 2.0491\n",
            "Epoch 306/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.0950 - mean_absolute_error: 1.0105 - mean_squared_error: 2.0950\n",
            "Epoch 306: val_loss improved from 2.04910 to 2.04635, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0950 - mean_absolute_error: 1.0105 - mean_squared_error: 2.0950 - val_loss: 2.0463 - val_mean_absolute_error: 1.0059 - val_mean_squared_error: 2.0463\n",
            "Epoch 307/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.0872 - mean_absolute_error: 1.0121 - mean_squared_error: 2.0872\n",
            "Epoch 307: val_loss improved from 2.04635 to 2.04435, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0914 - mean_absolute_error: 1.0089 - mean_squared_error: 2.0914 - val_loss: 2.0443 - val_mean_absolute_error: 1.0055 - val_mean_squared_error: 2.0443\n",
            "Epoch 308/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.0780 - mean_absolute_error: 1.0064 - mean_squared_error: 2.0780\n",
            "Epoch 308: val_loss improved from 2.04435 to 2.03926, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0879 - mean_absolute_error: 1.0077 - mean_squared_error: 2.0879 - val_loss: 2.0393 - val_mean_absolute_error: 1.0036 - val_mean_squared_error: 2.0393\n",
            "Epoch 309/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.0650 - mean_absolute_error: 1.0030 - mean_squared_error: 2.0650\n",
            "Epoch 309: val_loss improved from 2.03926 to 2.03785, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0834 - mean_absolute_error: 1.0063 - mean_squared_error: 2.0834 - val_loss: 2.0378 - val_mean_absolute_error: 1.0043 - val_mean_squared_error: 2.0378\n",
            "Epoch 310/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.0743 - mean_absolute_error: 1.0062 - mean_squared_error: 2.0743\n",
            "Epoch 310: val_loss improved from 2.03785 to 2.03311, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0799 - mean_absolute_error: 1.0065 - mean_squared_error: 2.0799 - val_loss: 2.0331 - val_mean_absolute_error: 1.0023 - val_mean_squared_error: 2.0331\n",
            "Epoch 311/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.0643 - mean_absolute_error: 1.0010 - mean_squared_error: 2.0643\n",
            "Epoch 311: val_loss improved from 2.03311 to 2.03022, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0763 - mean_absolute_error: 1.0037 - mean_squared_error: 2.0763 - val_loss: 2.0302 - val_mean_absolute_error: 1.0020 - val_mean_squared_error: 2.0302\n",
            "Epoch 312/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.0594 - mean_absolute_error: 1.0011 - mean_squared_error: 2.0594\n",
            "Epoch 312: val_loss improved from 2.03022 to 2.02673, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0728 - mean_absolute_error: 1.0055 - mean_squared_error: 2.0728 - val_loss: 2.0267 - val_mean_absolute_error: 1.0005 - val_mean_squared_error: 2.0267\n",
            "Epoch 313/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.0659 - mean_absolute_error: 1.0018 - mean_squared_error: 2.0659\n",
            "Epoch 313: val_loss did not improve from 2.02673\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.0693 - mean_absolute_error: 1.0024 - mean_squared_error: 2.0693 - val_loss: 2.0273 - val_mean_absolute_error: 1.0024 - val_mean_squared_error: 2.0273\n",
            "Epoch 314/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.0574 - mean_absolute_error: 1.0022 - mean_squared_error: 2.0574\n",
            "Epoch 314: val_loss improved from 2.02673 to 2.02182, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0654 - mean_absolute_error: 1.0034 - mean_squared_error: 2.0654 - val_loss: 2.0218 - val_mean_absolute_error: 1.0000 - val_mean_squared_error: 2.0218\n",
            "Epoch 315/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.0612 - mean_absolute_error: 1.0003 - mean_squared_error: 2.0612\n",
            "Epoch 315: val_loss improved from 2.02182 to 2.01725, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0621 - mean_absolute_error: 1.0008 - mean_squared_error: 2.0621 - val_loss: 2.0172 - val_mean_absolute_error: 0.9981 - val_mean_squared_error: 2.0172\n",
            "Epoch 316/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.0574 - mean_absolute_error: 0.9991 - mean_squared_error: 2.0574\n",
            "Epoch 316: val_loss did not improve from 2.01725\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0580 - mean_absolute_error: 1.0003 - mean_squared_error: 2.0580 - val_loss: 2.0187 - val_mean_absolute_error: 1.0007 - val_mean_squared_error: 2.0187\n",
            "Epoch 317/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.0629 - mean_absolute_error: 1.0001 - mean_squared_error: 2.0629\n",
            "Epoch 317: val_loss improved from 2.01725 to 2.01118, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0552 - mean_absolute_error: 0.9996 - mean_squared_error: 2.0552 - val_loss: 2.0112 - val_mean_absolute_error: 0.9968 - val_mean_squared_error: 2.0112\n",
            "Epoch 318/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.0575 - mean_absolute_error: 1.0003 - mean_squared_error: 2.0575\n",
            "Epoch 318: val_loss improved from 2.01118 to 2.00814, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0514 - mean_absolute_error: 0.9985 - mean_squared_error: 2.0514 - val_loss: 2.0081 - val_mean_absolute_error: 0.9960 - val_mean_squared_error: 2.0081\n",
            "Epoch 319/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 2.0474 - mean_absolute_error: 0.9982 - mean_squared_error: 2.0474\n",
            "Epoch 319: val_loss did not improve from 2.00814\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0496 - mean_absolute_error: 0.9987 - mean_squared_error: 2.0496 - val_loss: 2.0086 - val_mean_absolute_error: 0.9982 - val_mean_squared_error: 2.0086\n",
            "Epoch 320/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.0281 - mean_absolute_error: 0.9936 - mean_squared_error: 2.0281\n",
            "Epoch 320: val_loss improved from 2.00814 to 2.00260, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0445 - mean_absolute_error: 0.9979 - mean_squared_error: 2.0445 - val_loss: 2.0026 - val_mean_absolute_error: 0.9952 - val_mean_squared_error: 2.0026\n",
            "Epoch 321/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.0488 - mean_absolute_error: 0.9978 - mean_squared_error: 2.0488\n",
            "Epoch 321: val_loss improved from 2.00260 to 2.00072, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0424 - mean_absolute_error: 0.9975 - mean_squared_error: 2.0424 - val_loss: 2.0007 - val_mean_absolute_error: 0.9949 - val_mean_squared_error: 2.0007\n",
            "Epoch 322/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 2.0366 - mean_absolute_error: 0.9970 - mean_squared_error: 2.0366\n",
            "Epoch 322: val_loss improved from 2.00072 to 1.99967, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0380 - mean_absolute_error: 0.9952 - mean_squared_error: 2.0380 - val_loss: 1.9997 - val_mean_absolute_error: 0.9959 - val_mean_squared_error: 1.9997\n",
            "Epoch 323/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.0344 - mean_absolute_error: 0.9943 - mean_squared_error: 2.0344\n",
            "Epoch 323: val_loss improved from 1.99967 to 1.99477, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0344 - mean_absolute_error: 0.9943 - mean_squared_error: 2.0344 - val_loss: 1.9948 - val_mean_absolute_error: 0.9946 - val_mean_squared_error: 1.9948\n",
            "Epoch 324/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.0414 - mean_absolute_error: 0.9977 - mean_squared_error: 2.0414\n",
            "Epoch 324: val_loss improved from 1.99477 to 1.99145, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0318 - mean_absolute_error: 0.9954 - mean_squared_error: 2.0318 - val_loss: 1.9914 - val_mean_absolute_error: 0.9929 - val_mean_squared_error: 1.9914\n",
            "Epoch 325/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.0368 - mean_absolute_error: 0.9969 - mean_squared_error: 2.0368\n",
            "Epoch 325: val_loss did not improve from 1.99145\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0263 - mean_absolute_error: 0.9933 - mean_squared_error: 2.0263 - val_loss: 1.9931 - val_mean_absolute_error: 0.9953 - val_mean_squared_error: 1.9931\n",
            "Epoch 326/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.0281 - mean_absolute_error: 0.9946 - mean_squared_error: 2.0281\n",
            "Epoch 326: val_loss improved from 1.99145 to 1.98554, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0250 - mean_absolute_error: 0.9937 - mean_squared_error: 2.0250 - val_loss: 1.9855 - val_mean_absolute_error: 0.9910 - val_mean_squared_error: 1.9855\n",
            "Epoch 327/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.0200 - mean_absolute_error: 0.9913 - mean_squared_error: 2.0200\n",
            "Epoch 327: val_loss improved from 1.98554 to 1.98516, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0225 - mean_absolute_error: 0.9926 - mean_squared_error: 2.0225 - val_loss: 1.9852 - val_mean_absolute_error: 0.9926 - val_mean_squared_error: 1.9852\n",
            "Epoch 328/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.0304 - mean_absolute_error: 0.9954 - mean_squared_error: 2.0304\n",
            "Epoch 328: val_loss improved from 1.98516 to 1.98211, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0193 - mean_absolute_error: 0.9925 - mean_squared_error: 2.0193 - val_loss: 1.9821 - val_mean_absolute_error: 0.9920 - val_mean_squared_error: 1.9821\n",
            "Epoch 329/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.0428 - mean_absolute_error: 0.9970 - mean_squared_error: 2.0428\n",
            "Epoch 329: val_loss improved from 1.98211 to 1.97910, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0153 - mean_absolute_error: 0.9915 - mean_squared_error: 2.0153 - val_loss: 1.9791 - val_mean_absolute_error: 0.9911 - val_mean_squared_error: 1.9791\n",
            "Epoch 330/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.0475 - mean_absolute_error: 0.9996 - mean_squared_error: 2.0475\n",
            "Epoch 330: val_loss improved from 1.97910 to 1.97587, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0118 - mean_absolute_error: 0.9904 - mean_squared_error: 2.0118 - val_loss: 1.9759 - val_mean_absolute_error: 0.9900 - val_mean_squared_error: 1.9759\n",
            "Epoch 331/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.0113 - mean_absolute_error: 0.9939 - mean_squared_error: 2.0113\n",
            "Epoch 331: val_loss improved from 1.97587 to 1.97281, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0087 - mean_absolute_error: 0.9899 - mean_squared_error: 2.0087 - val_loss: 1.9728 - val_mean_absolute_error: 0.9891 - val_mean_squared_error: 1.9728\n",
            "Epoch 332/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.0181 - mean_absolute_error: 0.9921 - mean_squared_error: 2.0181\n",
            "Epoch 332: val_loss improved from 1.97281 to 1.97054, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0059 - mean_absolute_error: 0.9891 - mean_squared_error: 2.0059 - val_loss: 1.9705 - val_mean_absolute_error: 0.9890 - val_mean_squared_error: 1.9705\n",
            "Epoch 333/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.0079 - mean_absolute_error: 0.9910 - mean_squared_error: 2.0079\n",
            "Epoch 333: val_loss improved from 1.97054 to 1.96933, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0021 - mean_absolute_error: 0.9896 - mean_squared_error: 2.0021 - val_loss: 1.9693 - val_mean_absolute_error: 0.9893 - val_mean_squared_error: 1.9693\n",
            "Epoch 334/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.9845 - mean_absolute_error: 0.9844 - mean_squared_error: 1.9845\n",
            "Epoch 334: val_loss improved from 1.96933 to 1.96855, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9997 - mean_absolute_error: 0.9882 - mean_squared_error: 1.9997 - val_loss: 1.9686 - val_mean_absolute_error: 0.9895 - val_mean_squared_error: 1.9686\n",
            "Epoch 335/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.0165 - mean_absolute_error: 0.9942 - mean_squared_error: 2.0165\n",
            "Epoch 335: val_loss improved from 1.96855 to 1.96462, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9975 - mean_absolute_error: 0.9884 - mean_squared_error: 1.9975 - val_loss: 1.9646 - val_mean_absolute_error: 0.9884 - val_mean_squared_error: 1.9646\n",
            "Epoch 336/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.9881 - mean_absolute_error: 0.9850 - mean_squared_error: 1.9881\n",
            "Epoch 336: val_loss did not improve from 1.96462\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9923 - mean_absolute_error: 0.9860 - mean_squared_error: 1.9923 - val_loss: 1.9724 - val_mean_absolute_error: 0.9934 - val_mean_squared_error: 1.9724\n",
            "Epoch 337/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.9817 - mean_absolute_error: 0.9833 - mean_squared_error: 1.9817\n",
            "Epoch 337: val_loss improved from 1.96462 to 1.95694, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9909 - mean_absolute_error: 0.9878 - mean_squared_error: 1.9909 - val_loss: 1.9569 - val_mean_absolute_error: 0.9841 - val_mean_squared_error: 1.9569\n",
            "Epoch 338/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.9815 - mean_absolute_error: 0.9846 - mean_squared_error: 1.9815\n",
            "Epoch 338: val_loss improved from 1.95694 to 1.95439, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9879 - mean_absolute_error: 0.9862 - mean_squared_error: 1.9879 - val_loss: 1.9544 - val_mean_absolute_error: 0.9839 - val_mean_squared_error: 1.9544\n",
            "Epoch 339/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.9889 - mean_absolute_error: 0.9845 - mean_squared_error: 1.9889\n",
            "Epoch 339: val_loss improved from 1.95439 to 1.95199, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9845 - mean_absolute_error: 0.9841 - mean_squared_error: 1.9845 - val_loss: 1.9520 - val_mean_absolute_error: 0.9832 - val_mean_squared_error: 1.9520\n",
            "Epoch 340/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.9712 - mean_absolute_error: 0.9810 - mean_squared_error: 1.9712\n",
            "Epoch 340: val_loss improved from 1.95199 to 1.95186, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9817 - mean_absolute_error: 0.9843 - mean_squared_error: 1.9817 - val_loss: 1.9519 - val_mean_absolute_error: 0.9856 - val_mean_squared_error: 1.9519\n",
            "Epoch 341/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.9788 - mean_absolute_error: 0.9841 - mean_squared_error: 1.9788\n",
            "Epoch 341: val_loss improved from 1.95186 to 1.95108, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.9785 - mean_absolute_error: 0.9836 - mean_squared_error: 1.9785 - val_loss: 1.9511 - val_mean_absolute_error: 0.9865 - val_mean_squared_error: 1.9511\n",
            "Epoch 342/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.9795 - mean_absolute_error: 0.9854 - mean_squared_error: 1.9795\n",
            "Epoch 342: val_loss improved from 1.95108 to 1.94932, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.9775 - mean_absolute_error: 0.9841 - mean_squared_error: 1.9775 - val_loss: 1.9493 - val_mean_absolute_error: 0.9864 - val_mean_squared_error: 1.9493\n",
            "Epoch 343/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.9752 - mean_absolute_error: 0.9843 - mean_squared_error: 1.9752\n",
            "Epoch 343: val_loss improved from 1.94932 to 1.94361, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.9743 - mean_absolute_error: 0.9831 - mean_squared_error: 1.9743 - val_loss: 1.9436 - val_mean_absolute_error: 0.9829 - val_mean_squared_error: 1.9436\n",
            "Epoch 344/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.9709 - mean_absolute_error: 0.9812 - mean_squared_error: 1.9709\n",
            "Epoch 344: val_loss improved from 1.94361 to 1.94330, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.9709 - mean_absolute_error: 0.9812 - mean_squared_error: 1.9709 - val_loss: 1.9433 - val_mean_absolute_error: 0.9843 - val_mean_squared_error: 1.9433\n",
            "Epoch 345/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.9456 - mean_absolute_error: 0.9785 - mean_squared_error: 1.9456\n",
            "Epoch 345: val_loss improved from 1.94330 to 1.93885, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9697 - mean_absolute_error: 0.9833 - mean_squared_error: 1.9697 - val_loss: 1.9388 - val_mean_absolute_error: 0.9819 - val_mean_squared_error: 1.9388\n",
            "Epoch 346/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.9662 - mean_absolute_error: 0.9818 - mean_squared_error: 1.9662\n",
            "Epoch 346: val_loss improved from 1.93885 to 1.93859, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9662 - mean_absolute_error: 0.9818 - mean_squared_error: 1.9662 - val_loss: 1.9386 - val_mean_absolute_error: 0.9835 - val_mean_squared_error: 1.9386\n",
            "Epoch 347/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.9626 - mean_absolute_error: 0.9816 - mean_squared_error: 1.9626\n",
            "Epoch 347: val_loss improved from 1.93859 to 1.93312, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9632 - mean_absolute_error: 0.9813 - mean_squared_error: 1.9632 - val_loss: 1.9331 - val_mean_absolute_error: 0.9795 - val_mean_squared_error: 1.9331\n",
            "Epoch 348/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.9485 - mean_absolute_error: 0.9762 - mean_squared_error: 1.9485\n",
            "Epoch 348: val_loss improved from 1.93312 to 1.93277, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9595 - mean_absolute_error: 0.9802 - mean_squared_error: 1.9595 - val_loss: 1.9328 - val_mean_absolute_error: 0.9810 - val_mean_squared_error: 1.9328\n",
            "Epoch 349/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.9615 - mean_absolute_error: 0.9803 - mean_squared_error: 1.9615\n",
            "Epoch 349: val_loss improved from 1.93277 to 1.93160, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9567 - mean_absolute_error: 0.9797 - mean_squared_error: 1.9567 - val_loss: 1.9316 - val_mean_absolute_error: 0.9818 - val_mean_squared_error: 1.9316\n",
            "Epoch 350/1000\n",
            "218/245 [=========================>....] - ETA: 0s - loss: 1.9656 - mean_absolute_error: 0.9803 - mean_squared_error: 1.9656\n",
            "Epoch 350: val_loss improved from 1.93160 to 1.92844, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9548 - mean_absolute_error: 0.9794 - mean_squared_error: 1.9548 - val_loss: 1.9284 - val_mean_absolute_error: 0.9811 - val_mean_squared_error: 1.9284\n",
            "Epoch 351/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.9550 - mean_absolute_error: 0.9809 - mean_squared_error: 1.9550\n",
            "Epoch 351: val_loss improved from 1.92844 to 1.92454, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9527 - mean_absolute_error: 0.9796 - mean_squared_error: 1.9527 - val_loss: 1.9245 - val_mean_absolute_error: 0.9780 - val_mean_squared_error: 1.9245\n",
            "Epoch 352/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.9334 - mean_absolute_error: 0.9741 - mean_squared_error: 1.9334\n",
            "Epoch 352: val_loss improved from 1.92454 to 1.92262, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9485 - mean_absolute_error: 0.9787 - mean_squared_error: 1.9485 - val_loss: 1.9226 - val_mean_absolute_error: 0.9780 - val_mean_squared_error: 1.9226\n",
            "Epoch 353/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.9503 - mean_absolute_error: 0.9790 - mean_squared_error: 1.9503\n",
            "Epoch 353: val_loss improved from 1.92262 to 1.92221, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9464 - mean_absolute_error: 0.9782 - mean_squared_error: 1.9464 - val_loss: 1.9222 - val_mean_absolute_error: 0.9792 - val_mean_squared_error: 1.9222\n",
            "Epoch 354/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.9541 - mean_absolute_error: 0.9812 - mean_squared_error: 1.9541\n",
            "Epoch 354: val_loss improved from 1.92221 to 1.91797, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9447 - mean_absolute_error: 0.9786 - mean_squared_error: 1.9447 - val_loss: 1.9180 - val_mean_absolute_error: 0.9764 - val_mean_squared_error: 1.9180\n",
            "Epoch 355/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.9562 - mean_absolute_error: 0.9807 - mean_squared_error: 1.9562\n",
            "Epoch 355: val_loss did not improve from 1.91797\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9414 - mean_absolute_error: 0.9769 - mean_squared_error: 1.9414 - val_loss: 1.9184 - val_mean_absolute_error: 0.9786 - val_mean_squared_error: 1.9184\n",
            "Epoch 356/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.9383 - mean_absolute_error: 0.9753 - mean_squared_error: 1.9383\n",
            "Epoch 356: val_loss improved from 1.91797 to 1.91653, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9385 - mean_absolute_error: 0.9763 - mean_squared_error: 1.9385 - val_loss: 1.9165 - val_mean_absolute_error: 0.9783 - val_mean_squared_error: 1.9165\n",
            "Epoch 357/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.9377 - mean_absolute_error: 0.9758 - mean_squared_error: 1.9377\n",
            "Epoch 357: val_loss improved from 1.91653 to 1.91619, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9363 - mean_absolute_error: 0.9756 - mean_squared_error: 1.9363 - val_loss: 1.9162 - val_mean_absolute_error: 0.9796 - val_mean_squared_error: 1.9162\n",
            "Epoch 358/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.9258 - mean_absolute_error: 0.9733 - mean_squared_error: 1.9258\n",
            "Epoch 358: val_loss improved from 1.91619 to 1.91098, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9333 - mean_absolute_error: 0.9762 - mean_squared_error: 1.9333 - val_loss: 1.9110 - val_mean_absolute_error: 0.9764 - val_mean_squared_error: 1.9110\n",
            "Epoch 359/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.9315 - mean_absolute_error: 0.9751 - mean_squared_error: 1.9315\n",
            "Epoch 359: val_loss improved from 1.91098 to 1.90887, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9328 - mean_absolute_error: 0.9758 - mean_squared_error: 1.9328 - val_loss: 1.9089 - val_mean_absolute_error: 0.9762 - val_mean_squared_error: 1.9089\n",
            "Epoch 360/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.9420 - mean_absolute_error: 0.9772 - mean_squared_error: 1.9420\n",
            "Epoch 360: val_loss improved from 1.90887 to 1.90624, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9287 - mean_absolute_error: 0.9753 - mean_squared_error: 1.9287 - val_loss: 1.9062 - val_mean_absolute_error: 0.9753 - val_mean_squared_error: 1.9062\n",
            "Epoch 361/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.9251 - mean_absolute_error: 0.9728 - mean_squared_error: 1.9251\n",
            "Epoch 361: val_loss improved from 1.90624 to 1.90453, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.9267 - mean_absolute_error: 0.9732 - mean_squared_error: 1.9267 - val_loss: 1.9045 - val_mean_absolute_error: 0.9753 - val_mean_squared_error: 1.9045\n",
            "Epoch 362/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.9232 - mean_absolute_error: 0.9728 - mean_squared_error: 1.9232\n",
            "Epoch 362: val_loss did not improve from 1.90453\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9232 - mean_absolute_error: 0.9728 - mean_squared_error: 1.9232 - val_loss: 1.9074 - val_mean_absolute_error: 0.9789 - val_mean_squared_error: 1.9074\n",
            "Epoch 363/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.9225 - mean_absolute_error: 0.9750 - mean_squared_error: 1.9225\n",
            "Epoch 363: val_loss improved from 1.90453 to 1.90040, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9220 - mean_absolute_error: 0.9744 - mean_squared_error: 1.9220 - val_loss: 1.9004 - val_mean_absolute_error: 0.9748 - val_mean_squared_error: 1.9004\n",
            "Epoch 364/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.9369 - mean_absolute_error: 0.9776 - mean_squared_error: 1.9369\n",
            "Epoch 364: val_loss did not improve from 1.90040\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9206 - mean_absolute_error: 0.9738 - mean_squared_error: 1.9206 - val_loss: 1.9048 - val_mean_absolute_error: 0.9790 - val_mean_squared_error: 1.9048\n",
            "Epoch 365/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.9102 - mean_absolute_error: 0.9713 - mean_squared_error: 1.9102\n",
            "Epoch 365: val_loss improved from 1.90040 to 1.89678, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.9166 - mean_absolute_error: 0.9735 - mean_squared_error: 1.9166 - val_loss: 1.8968 - val_mean_absolute_error: 0.9743 - val_mean_squared_error: 1.8968\n",
            "Epoch 366/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.9140 - mean_absolute_error: 0.9726 - mean_squared_error: 1.9140\n",
            "Epoch 366: val_loss did not improve from 1.89678\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9140 - mean_absolute_error: 0.9726 - mean_squared_error: 1.9140 - val_loss: 1.8974 - val_mean_absolute_error: 0.9757 - val_mean_squared_error: 1.8974\n",
            "Epoch 367/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.9092 - mean_absolute_error: 0.9729 - mean_squared_error: 1.9092\n",
            "Epoch 367: val_loss improved from 1.89678 to 1.89560, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.9121 - mean_absolute_error: 0.9720 - mean_squared_error: 1.9121 - val_loss: 1.8956 - val_mean_absolute_error: 0.9756 - val_mean_squared_error: 1.8956\n",
            "Epoch 368/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.9147 - mean_absolute_error: 0.9715 - mean_squared_error: 1.9147\n",
            "Epoch 368: val_loss did not improve from 1.89560\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.9105 - mean_absolute_error: 0.9710 - mean_squared_error: 1.9105 - val_loss: 1.8959 - val_mean_absolute_error: 0.9770 - val_mean_squared_error: 1.8959\n",
            "Epoch 369/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.9059 - mean_absolute_error: 0.9713 - mean_squared_error: 1.9059\n",
            "Epoch 369: val_loss improved from 1.89560 to 1.89029, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9069 - mean_absolute_error: 0.9714 - mean_squared_error: 1.9069 - val_loss: 1.8903 - val_mean_absolute_error: 0.9743 - val_mean_squared_error: 1.8903\n",
            "Epoch 370/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.9093 - mean_absolute_error: 0.9706 - mean_squared_error: 1.9093\n",
            "Epoch 370: val_loss improved from 1.89029 to 1.88744, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9056 - mean_absolute_error: 0.9720 - mean_squared_error: 1.9056 - val_loss: 1.8874 - val_mean_absolute_error: 0.9727 - val_mean_squared_error: 1.8874\n",
            "Epoch 371/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.9157 - mean_absolute_error: 0.9752 - mean_squared_error: 1.9157\n",
            "Epoch 371: val_loss improved from 1.88744 to 1.88593, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9033 - mean_absolute_error: 0.9713 - mean_squared_error: 1.9033 - val_loss: 1.8859 - val_mean_absolute_error: 0.9725 - val_mean_squared_error: 1.8859\n",
            "Epoch 372/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.8912 - mean_absolute_error: 0.9681 - mean_squared_error: 1.8912\n",
            "Epoch 372: val_loss improved from 1.88593 to 1.88474, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9008 - mean_absolute_error: 0.9699 - mean_squared_error: 1.9008 - val_loss: 1.8847 - val_mean_absolute_error: 0.9731 - val_mean_squared_error: 1.8847\n",
            "Epoch 373/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 1.8959 - mean_absolute_error: 0.9708 - mean_squared_error: 1.8959\n",
            "Epoch 373: val_loss improved from 1.88474 to 1.88256, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8978 - mean_absolute_error: 0.9701 - mean_squared_error: 1.8978 - val_loss: 1.8826 - val_mean_absolute_error: 0.9725 - val_mean_squared_error: 1.8826\n",
            "Epoch 374/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.8979 - mean_absolute_error: 0.9695 - mean_squared_error: 1.8979\n",
            "Epoch 374: val_loss did not improve from 1.88256\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.8965 - mean_absolute_error: 0.9692 - mean_squared_error: 1.8965 - val_loss: 1.8833 - val_mean_absolute_error: 0.9742 - val_mean_squared_error: 1.8833\n",
            "Epoch 375/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.9037 - mean_absolute_error: 0.9737 - mean_squared_error: 1.9037\n",
            "Epoch 375: val_loss did not improve from 1.88256\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8947 - mean_absolute_error: 0.9709 - mean_squared_error: 1.8947 - val_loss: 1.8827 - val_mean_absolute_error: 0.9743 - val_mean_squared_error: 1.8827\n",
            "Epoch 376/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.8898 - mean_absolute_error: 0.9686 - mean_squared_error: 1.8898\n",
            "Epoch 376: val_loss improved from 1.88256 to 1.87668, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8924 - mean_absolute_error: 0.9696 - mean_squared_error: 1.8924 - val_loss: 1.8767 - val_mean_absolute_error: 0.9713 - val_mean_squared_error: 1.8767\n",
            "Epoch 377/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.8961 - mean_absolute_error: 0.9701 - mean_squared_error: 1.8961\n",
            "Epoch 377: val_loss improved from 1.87668 to 1.87597, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8904 - mean_absolute_error: 0.9682 - mean_squared_error: 1.8904 - val_loss: 1.8760 - val_mean_absolute_error: 0.9719 - val_mean_squared_error: 1.8760\n",
            "Epoch 378/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.8983 - mean_absolute_error: 0.9717 - mean_squared_error: 1.8983\n",
            "Epoch 378: val_loss improved from 1.87597 to 1.87390, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8887 - mean_absolute_error: 0.9693 - mean_squared_error: 1.8887 - val_loss: 1.8739 - val_mean_absolute_error: 0.9714 - val_mean_squared_error: 1.8739\n",
            "Epoch 379/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.9038 - mean_absolute_error: 0.9744 - mean_squared_error: 1.9038\n",
            "Epoch 379: val_loss improved from 1.87390 to 1.87154, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8851 - mean_absolute_error: 0.9683 - mean_squared_error: 1.8851 - val_loss: 1.8715 - val_mean_absolute_error: 0.9697 - val_mean_squared_error: 1.8715\n",
            "Epoch 380/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.8908 - mean_absolute_error: 0.9708 - mean_squared_error: 1.8908\n",
            "Epoch 380: val_loss improved from 1.87154 to 1.86989, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8836 - mean_absolute_error: 0.9673 - mean_squared_error: 1.8836 - val_loss: 1.8699 - val_mean_absolute_error: 0.9699 - val_mean_squared_error: 1.8699\n",
            "Epoch 381/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.8854 - mean_absolute_error: 0.9687 - mean_squared_error: 1.8854\n",
            "Epoch 381: val_loss did not improve from 1.86989\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8815 - mean_absolute_error: 0.9677 - mean_squared_error: 1.8815 - val_loss: 1.8714 - val_mean_absolute_error: 0.9726 - val_mean_squared_error: 1.8714\n",
            "Epoch 382/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.8855 - mean_absolute_error: 0.9686 - mean_squared_error: 1.8855\n",
            "Epoch 382: val_loss improved from 1.86989 to 1.86786, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8796 - mean_absolute_error: 0.9671 - mean_squared_error: 1.8796 - val_loss: 1.8679 - val_mean_absolute_error: 0.9708 - val_mean_squared_error: 1.8679\n",
            "Epoch 383/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.8599 - mean_absolute_error: 0.9614 - mean_squared_error: 1.8599\n",
            "Epoch 383: val_loss improved from 1.86786 to 1.86595, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.8783 - mean_absolute_error: 0.9678 - mean_squared_error: 1.8783 - val_loss: 1.8659 - val_mean_absolute_error: 0.9701 - val_mean_squared_error: 1.8659\n",
            "Epoch 384/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.8751 - mean_absolute_error: 0.9657 - mean_squared_error: 1.8751\n",
            "Epoch 384: val_loss improved from 1.86595 to 1.86428, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.8755 - mean_absolute_error: 0.9668 - mean_squared_error: 1.8755 - val_loss: 1.8643 - val_mean_absolute_error: 0.9698 - val_mean_squared_error: 1.8643\n",
            "Epoch 385/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.8679 - mean_absolute_error: 0.9624 - mean_squared_error: 1.8679\n",
            "Epoch 385: val_loss did not improve from 1.86428\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.8732 - mean_absolute_error: 0.9660 - mean_squared_error: 1.8732 - val_loss: 1.8677 - val_mean_absolute_error: 0.9734 - val_mean_squared_error: 1.8677\n",
            "Epoch 386/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.8715 - mean_absolute_error: 0.9657 - mean_squared_error: 1.8715\n",
            "Epoch 386: val_loss did not improve from 1.86428\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8720 - mean_absolute_error: 0.9663 - mean_squared_error: 1.8720 - val_loss: 1.8671 - val_mean_absolute_error: 0.9731 - val_mean_squared_error: 1.8671\n",
            "Epoch 387/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.8889 - mean_absolute_error: 0.9720 - mean_squared_error: 1.8889\n",
            "Epoch 387: val_loss improved from 1.86428 to 1.85942, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.8710 - mean_absolute_error: 0.9669 - mean_squared_error: 1.8710 - val_loss: 1.8594 - val_mean_absolute_error: 0.9691 - val_mean_squared_error: 1.8594\n",
            "Epoch 388/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.8609 - mean_absolute_error: 0.9627 - mean_squared_error: 1.8609\n",
            "Epoch 388: val_loss improved from 1.85942 to 1.85843, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.8685 - mean_absolute_error: 0.9656 - mean_squared_error: 1.8685 - val_loss: 1.8584 - val_mean_absolute_error: 0.9694 - val_mean_squared_error: 1.8584\n",
            "Epoch 389/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.8722 - mean_absolute_error: 0.9673 - mean_squared_error: 1.8722\n",
            "Epoch 389: val_loss did not improve from 1.85843\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.8662 - mean_absolute_error: 0.9647 - mean_squared_error: 1.8662 - val_loss: 1.8615 - val_mean_absolute_error: 0.9723 - val_mean_squared_error: 1.8615\n",
            "Epoch 390/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.8659 - mean_absolute_error: 0.9663 - mean_squared_error: 1.8659\n",
            "Epoch 390: val_loss improved from 1.85843 to 1.85572, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.8659 - mean_absolute_error: 0.9663 - mean_squared_error: 1.8659 - val_loss: 1.8557 - val_mean_absolute_error: 0.9696 - val_mean_squared_error: 1.8557\n",
            "Epoch 391/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.8644 - mean_absolute_error: 0.9659 - mean_squared_error: 1.8644\n",
            "Epoch 391: val_loss improved from 1.85572 to 1.85516, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8628 - mean_absolute_error: 0.9655 - mean_squared_error: 1.8628 - val_loss: 1.8552 - val_mean_absolute_error: 0.9699 - val_mean_squared_error: 1.8552\n",
            "Epoch 392/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.8618 - mean_absolute_error: 0.9651 - mean_squared_error: 1.8618\n",
            "Epoch 392: val_loss improved from 1.85516 to 1.85218, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8620 - mean_absolute_error: 0.9648 - mean_squared_error: 1.8620 - val_loss: 1.8522 - val_mean_absolute_error: 0.9682 - val_mean_squared_error: 1.8522\n",
            "Epoch 393/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.8389 - mean_absolute_error: 0.9620 - mean_squared_error: 1.8389\n",
            "Epoch 393: val_loss did not improve from 1.85218\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8588 - mean_absolute_error: 0.9642 - mean_squared_error: 1.8588 - val_loss: 1.8538 - val_mean_absolute_error: 0.9705 - val_mean_squared_error: 1.8538\n",
            "Epoch 394/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.8714 - mean_absolute_error: 0.9687 - mean_squared_error: 1.8714\n",
            "Epoch 394: val_loss improved from 1.85218 to 1.85007, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8583 - mean_absolute_error: 0.9654 - mean_squared_error: 1.8583 - val_loss: 1.8501 - val_mean_absolute_error: 0.9686 - val_mean_squared_error: 1.8501\n",
            "Epoch 395/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.8582 - mean_absolute_error: 0.9640 - mean_squared_error: 1.8582\n",
            "Epoch 395: val_loss did not improve from 1.85007\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8554 - mean_absolute_error: 0.9634 - mean_squared_error: 1.8554 - val_loss: 1.8504 - val_mean_absolute_error: 0.9700 - val_mean_squared_error: 1.8504\n",
            "Epoch 396/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.8369 - mean_absolute_error: 0.9584 - mean_squared_error: 1.8369\n",
            "Epoch 396: val_loss improved from 1.85007 to 1.84674, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8541 - mean_absolute_error: 0.9639 - mean_squared_error: 1.8541 - val_loss: 1.8467 - val_mean_absolute_error: 0.9679 - val_mean_squared_error: 1.8467\n",
            "Epoch 397/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.8889 - mean_absolute_error: 0.9729 - mean_squared_error: 1.8889\n",
            "Epoch 397: val_loss improved from 1.84674 to 1.84485, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8514 - mean_absolute_error: 0.9642 - mean_squared_error: 1.8514 - val_loss: 1.8448 - val_mean_absolute_error: 0.9671 - val_mean_squared_error: 1.8448\n",
            "Epoch 398/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.8592 - mean_absolute_error: 0.9653 - mean_squared_error: 1.8592\n",
            "Epoch 398: val_loss did not improve from 1.84485\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8500 - mean_absolute_error: 0.9632 - mean_squared_error: 1.8500 - val_loss: 1.8472 - val_mean_absolute_error: 0.9700 - val_mean_squared_error: 1.8472\n",
            "Epoch 399/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.8467 - mean_absolute_error: 0.9626 - mean_squared_error: 1.8467\n",
            "Epoch 399: val_loss improved from 1.84485 to 1.84239, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8481 - mean_absolute_error: 0.9642 - mean_squared_error: 1.8481 - val_loss: 1.8424 - val_mean_absolute_error: 0.9667 - val_mean_squared_error: 1.8424\n",
            "Epoch 400/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.8554 - mean_absolute_error: 0.9646 - mean_squared_error: 1.8554\n",
            "Epoch 400: val_loss improved from 1.84239 to 1.84236, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8471 - mean_absolute_error: 0.9623 - mean_squared_error: 1.8471 - val_loss: 1.8424 - val_mean_absolute_error: 0.9678 - val_mean_squared_error: 1.8424\n",
            "Epoch 401/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.8336 - mean_absolute_error: 0.9588 - mean_squared_error: 1.8336\n",
            "Epoch 401: val_loss improved from 1.84236 to 1.84081, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8451 - mean_absolute_error: 0.9629 - mean_squared_error: 1.8451 - val_loss: 1.8408 - val_mean_absolute_error: 0.9677 - val_mean_squared_error: 1.8408\n",
            "Epoch 402/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.8582 - mean_absolute_error: 0.9665 - mean_squared_error: 1.8582\n",
            "Epoch 402: val_loss improved from 1.84081 to 1.84028, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8444 - mean_absolute_error: 0.9627 - mean_squared_error: 1.8444 - val_loss: 1.8403 - val_mean_absolute_error: 0.9679 - val_mean_squared_error: 1.8403\n",
            "Epoch 403/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.8565 - mean_absolute_error: 0.9635 - mean_squared_error: 1.8565\n",
            "Epoch 403: val_loss improved from 1.84028 to 1.83859, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8416 - mean_absolute_error: 0.9617 - mean_squared_error: 1.8416 - val_loss: 1.8386 - val_mean_absolute_error: 0.9679 - val_mean_squared_error: 1.8386\n",
            "Epoch 404/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.8550 - mean_absolute_error: 0.9670 - mean_squared_error: 1.8550\n",
            "Epoch 404: val_loss improved from 1.83859 to 1.83760, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8404 - mean_absolute_error: 0.9635 - mean_squared_error: 1.8404 - val_loss: 1.8376 - val_mean_absolute_error: 0.9679 - val_mean_squared_error: 1.8376\n",
            "Epoch 405/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 1.8314 - mean_absolute_error: 0.9584 - mean_squared_error: 1.8314\n",
            "Epoch 405: val_loss improved from 1.83760 to 1.83726, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8397 - mean_absolute_error: 0.9629 - mean_squared_error: 1.8397 - val_loss: 1.8373 - val_mean_absolute_error: 0.9682 - val_mean_squared_error: 1.8373\n",
            "Epoch 406/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.8340 - mean_absolute_error: 0.9605 - mean_squared_error: 1.8340\n",
            "Epoch 406: val_loss improved from 1.83726 to 1.83363, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8381 - mean_absolute_error: 0.9614 - mean_squared_error: 1.8381 - val_loss: 1.8336 - val_mean_absolute_error: 0.9659 - val_mean_squared_error: 1.8336\n",
            "Epoch 407/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.8339 - mean_absolute_error: 0.9618 - mean_squared_error: 1.8339\n",
            "Epoch 407: val_loss improved from 1.83363 to 1.83304, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8364 - mean_absolute_error: 0.9615 - mean_squared_error: 1.8364 - val_loss: 1.8330 - val_mean_absolute_error: 0.9669 - val_mean_squared_error: 1.8330\n",
            "Epoch 408/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.8195 - mean_absolute_error: 0.9559 - mean_squared_error: 1.8195\n",
            "Epoch 408: val_loss did not improve from 1.83304\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8340 - mean_absolute_error: 0.9614 - mean_squared_error: 1.8340 - val_loss: 1.8332 - val_mean_absolute_error: 0.9679 - val_mean_squared_error: 1.8332\n",
            "Epoch 409/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.8300 - mean_absolute_error: 0.9617 - mean_squared_error: 1.8300\n",
            "Epoch 409: val_loss improved from 1.83304 to 1.83000, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8329 - mean_absolute_error: 0.9620 - mean_squared_error: 1.8329 - val_loss: 1.8300 - val_mean_absolute_error: 0.9657 - val_mean_squared_error: 1.8300\n",
            "Epoch 410/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.8311 - mean_absolute_error: 0.9623 - mean_squared_error: 1.8311\n",
            "Epoch 410: val_loss improved from 1.83000 to 1.82852, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8320 - mean_absolute_error: 0.9620 - mean_squared_error: 1.8320 - val_loss: 1.8285 - val_mean_absolute_error: 0.9651 - val_mean_squared_error: 1.8285\n",
            "Epoch 411/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.8494 - mean_absolute_error: 0.9662 - mean_squared_error: 1.8494\n",
            "Epoch 411: val_loss improved from 1.82852 to 1.82818, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8308 - mean_absolute_error: 0.9614 - mean_squared_error: 1.8308 - val_loss: 1.8282 - val_mean_absolute_error: 0.9660 - val_mean_squared_error: 1.8282\n",
            "Epoch 412/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.8336 - mean_absolute_error: 0.9620 - mean_squared_error: 1.8336\n",
            "Epoch 412: val_loss improved from 1.82818 to 1.82814, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8297 - mean_absolute_error: 0.9601 - mean_squared_error: 1.8297 - val_loss: 1.8281 - val_mean_absolute_error: 0.9669 - val_mean_squared_error: 1.8281\n",
            "Epoch 413/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.8332 - mean_absolute_error: 0.9636 - mean_squared_error: 1.8332\n",
            "Epoch 413: val_loss improved from 1.82814 to 1.82671, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8268 - mean_absolute_error: 0.9608 - mean_squared_error: 1.8268 - val_loss: 1.8267 - val_mean_absolute_error: 0.9665 - val_mean_squared_error: 1.8267\n",
            "Epoch 414/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.8218 - mean_absolute_error: 0.9598 - mean_squared_error: 1.8218\n",
            "Epoch 414: val_loss improved from 1.82671 to 1.82515, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8252 - mean_absolute_error: 0.9603 - mean_squared_error: 1.8252 - val_loss: 1.8252 - val_mean_absolute_error: 0.9659 - val_mean_squared_error: 1.8252\n",
            "Epoch 415/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.8269 - mean_absolute_error: 0.9628 - mean_squared_error: 1.8269\n",
            "Epoch 415: val_loss improved from 1.82515 to 1.82316, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8244 - mean_absolute_error: 0.9614 - mean_squared_error: 1.8244 - val_loss: 1.8232 - val_mean_absolute_error: 0.9649 - val_mean_squared_error: 1.8232\n",
            "Epoch 416/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.8221 - mean_absolute_error: 0.9602 - mean_squared_error: 1.8221\n",
            "Epoch 416: val_loss improved from 1.82316 to 1.82172, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8221 - mean_absolute_error: 0.9602 - mean_squared_error: 1.8221 - val_loss: 1.8217 - val_mean_absolute_error: 0.9645 - val_mean_squared_error: 1.8217\n",
            "Epoch 417/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.8211 - mean_absolute_error: 0.9610 - mean_squared_error: 1.8211\n",
            "Epoch 417: val_loss improved from 1.82172 to 1.82123, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8212 - mean_absolute_error: 0.9594 - mean_squared_error: 1.8212 - val_loss: 1.8212 - val_mean_absolute_error: 0.9650 - val_mean_squared_error: 1.8212\n",
            "Epoch 418/1000\n",
            "217/245 [=========================>....] - ETA: 0s - loss: 1.8362 - mean_absolute_error: 0.9639 - mean_squared_error: 1.8362\n",
            "Epoch 418: val_loss improved from 1.82123 to 1.81974, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8196 - mean_absolute_error: 0.9602 - mean_squared_error: 1.8196 - val_loss: 1.8197 - val_mean_absolute_error: 0.9644 - val_mean_squared_error: 1.8197\n",
            "Epoch 419/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.8088 - mean_absolute_error: 0.9571 - mean_squared_error: 1.8088\n",
            "Epoch 419: val_loss improved from 1.81974 to 1.81973, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8185 - mean_absolute_error: 0.9590 - mean_squared_error: 1.8185 - val_loss: 1.8197 - val_mean_absolute_error: 0.9651 - val_mean_squared_error: 1.8197\n",
            "Epoch 420/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.8091 - mean_absolute_error: 0.9569 - mean_squared_error: 1.8091\n",
            "Epoch 420: val_loss did not improve from 1.81973\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8169 - mean_absolute_error: 0.9592 - mean_squared_error: 1.8169 - val_loss: 1.8246 - val_mean_absolute_error: 0.9691 - val_mean_squared_error: 1.8246\n",
            "Epoch 421/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.8438 - mean_absolute_error: 0.9683 - mean_squared_error: 1.8438\n",
            "Epoch 421: val_loss improved from 1.81973 to 1.81682, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8149 - mean_absolute_error: 0.9605 - mean_squared_error: 1.8149 - val_loss: 1.8168 - val_mean_absolute_error: 0.9636 - val_mean_squared_error: 1.8168\n",
            "Epoch 422/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.8211 - mean_absolute_error: 0.9594 - mean_squared_error: 1.8211\n",
            "Epoch 422: val_loss did not improve from 1.81682\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8143 - mean_absolute_error: 0.9584 - mean_squared_error: 1.8143 - val_loss: 1.8175 - val_mean_absolute_error: 0.9657 - val_mean_squared_error: 1.8175\n",
            "Epoch 423/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.8070 - mean_absolute_error: 0.9562 - mean_squared_error: 1.8070\n",
            "Epoch 423: val_loss did not improve from 1.81682\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8130 - mean_absolute_error: 0.9593 - mean_squared_error: 1.8130 - val_loss: 1.8173 - val_mean_absolute_error: 0.9660 - val_mean_squared_error: 1.8173\n",
            "Epoch 424/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.8133 - mean_absolute_error: 0.9601 - mean_squared_error: 1.8133\n",
            "Epoch 424: val_loss improved from 1.81682 to 1.81621, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8111 - mean_absolute_error: 0.9595 - mean_squared_error: 1.8111 - val_loss: 1.8162 - val_mean_absolute_error: 0.9658 - val_mean_squared_error: 1.8162\n",
            "Epoch 425/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.8111 - mean_absolute_error: 0.9598 - mean_squared_error: 1.8111\n",
            "Epoch 425: val_loss improved from 1.81621 to 1.81199, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8105 - mean_absolute_error: 0.9590 - mean_squared_error: 1.8105 - val_loss: 1.8120 - val_mean_absolute_error: 0.9631 - val_mean_squared_error: 1.8120\n",
            "Epoch 426/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.7972 - mean_absolute_error: 0.9553 - mean_squared_error: 1.7972\n",
            "Epoch 426: val_loss did not improve from 1.81199\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8082 - mean_absolute_error: 0.9582 - mean_squared_error: 1.8082 - val_loss: 1.8154 - val_mean_absolute_error: 0.9667 - val_mean_squared_error: 1.8154\n",
            "Epoch 427/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.8237 - mean_absolute_error: 0.9601 - mean_squared_error: 1.8237\n",
            "Epoch 427: val_loss did not improve from 1.81199\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8074 - mean_absolute_error: 0.9586 - mean_squared_error: 1.8074 - val_loss: 1.8123 - val_mean_absolute_error: 0.9655 - val_mean_squared_error: 1.8123\n",
            "Epoch 428/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.8029 - mean_absolute_error: 0.9575 - mean_squared_error: 1.8029\n",
            "Epoch 428: val_loss improved from 1.81199 to 1.81155, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.8072 - mean_absolute_error: 0.9587 - mean_squared_error: 1.8072 - val_loss: 1.8116 - val_mean_absolute_error: 0.9650 - val_mean_squared_error: 1.8116\n",
            "Epoch 429/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.8013 - mean_absolute_error: 0.9556 - mean_squared_error: 1.8013\n",
            "Epoch 429: val_loss improved from 1.81155 to 1.80955, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8052 - mean_absolute_error: 0.9582 - mean_squared_error: 1.8052 - val_loss: 1.8095 - val_mean_absolute_error: 0.9646 - val_mean_squared_error: 1.8095\n",
            "Epoch 430/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.8052 - mean_absolute_error: 0.9605 - mean_squared_error: 1.8052\n",
            "Epoch 430: val_loss did not improve from 1.80955\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8028 - mean_absolute_error: 0.9581 - mean_squared_error: 1.8028 - val_loss: 1.8097 - val_mean_absolute_error: 0.9651 - val_mean_squared_error: 1.8097\n",
            "Epoch 431/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.8049 - mean_absolute_error: 0.9589 - mean_squared_error: 1.8049\n",
            "Epoch 431: val_loss improved from 1.80955 to 1.80794, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8018 - mean_absolute_error: 0.9578 - mean_squared_error: 1.8018 - val_loss: 1.8079 - val_mean_absolute_error: 0.9644 - val_mean_squared_error: 1.8079\n",
            "Epoch 432/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.8137 - mean_absolute_error: 0.9613 - mean_squared_error: 1.8137\n",
            "Epoch 432: val_loss improved from 1.80794 to 1.80580, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8018 - mean_absolute_error: 0.9577 - mean_squared_error: 1.8018 - val_loss: 1.8058 - val_mean_absolute_error: 0.9634 - val_mean_squared_error: 1.8058\n",
            "Epoch 433/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.7919 - mean_absolute_error: 0.9549 - mean_squared_error: 1.7919\n",
            "Epoch 433: val_loss did not improve from 1.80580\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8001 - mean_absolute_error: 0.9572 - mean_squared_error: 1.8001 - val_loss: 1.8061 - val_mean_absolute_error: 0.9643 - val_mean_squared_error: 1.8061\n",
            "Epoch 434/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.8034 - mean_absolute_error: 0.9588 - mean_squared_error: 1.8034\n",
            "Epoch 434: val_loss improved from 1.80580 to 1.80351, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7984 - mean_absolute_error: 0.9572 - mean_squared_error: 1.7984 - val_loss: 1.8035 - val_mean_absolute_error: 0.9628 - val_mean_squared_error: 1.8035\n",
            "Epoch 435/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.7798 - mean_absolute_error: 0.9529 - mean_squared_error: 1.7798\n",
            "Epoch 435: val_loss improved from 1.80351 to 1.80261, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7962 - mean_absolute_error: 0.9577 - mean_squared_error: 1.7962 - val_loss: 1.8026 - val_mean_absolute_error: 0.9623 - val_mean_squared_error: 1.8026\n",
            "Epoch 436/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.8036 - mean_absolute_error: 0.9596 - mean_squared_error: 1.8036\n",
            "Epoch 436: val_loss improved from 1.80261 to 1.80156, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7960 - mean_absolute_error: 0.9559 - mean_squared_error: 1.7960 - val_loss: 1.8016 - val_mean_absolute_error: 0.9625 - val_mean_squared_error: 1.8016\n",
            "Epoch 437/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.7934 - mean_absolute_error: 0.9568 - mean_squared_error: 1.7934\n",
            "Epoch 437: val_loss did not improve from 1.80156\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7953 - mean_absolute_error: 0.9575 - mean_squared_error: 1.7953 - val_loss: 1.8027 - val_mean_absolute_error: 0.9644 - val_mean_squared_error: 1.8027\n",
            "Epoch 438/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.8154 - mean_absolute_error: 0.9621 - mean_squared_error: 1.8154\n",
            "Epoch 438: val_loss did not improve from 1.80156\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7928 - mean_absolute_error: 0.9571 - mean_squared_error: 1.7928 - val_loss: 1.8016 - val_mean_absolute_error: 0.9641 - val_mean_squared_error: 1.8016\n",
            "Epoch 439/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.7872 - mean_absolute_error: 0.9553 - mean_squared_error: 1.7872\n",
            "Epoch 439: val_loss improved from 1.80156 to 1.79883, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7922 - mean_absolute_error: 0.9570 - mean_squared_error: 1.7922 - val_loss: 1.7988 - val_mean_absolute_error: 0.9619 - val_mean_squared_error: 1.7988\n",
            "Epoch 440/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.7556 - mean_absolute_error: 0.9490 - mean_squared_error: 1.7556\n",
            "Epoch 440: val_loss did not improve from 1.79883\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7915 - mean_absolute_error: 0.9558 - mean_squared_error: 1.7915 - val_loss: 1.8025 - val_mean_absolute_error: 0.9658 - val_mean_squared_error: 1.8025\n",
            "Epoch 441/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.7946 - mean_absolute_error: 0.9588 - mean_squared_error: 1.7946\n",
            "Epoch 441: val_loss improved from 1.79883 to 1.79767, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7914 - mean_absolute_error: 0.9578 - mean_squared_error: 1.7914 - val_loss: 1.7977 - val_mean_absolute_error: 0.9628 - val_mean_squared_error: 1.7977\n",
            "Epoch 442/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.8152 - mean_absolute_error: 0.9649 - mean_squared_error: 1.8152\n",
            "Epoch 442: val_loss improved from 1.79767 to 1.79751, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7887 - mean_absolute_error: 0.9568 - mean_squared_error: 1.7887 - val_loss: 1.7975 - val_mean_absolute_error: 0.9633 - val_mean_squared_error: 1.7975\n",
            "Epoch 443/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.7864 - mean_absolute_error: 0.9584 - mean_squared_error: 1.7864\n",
            "Epoch 443: val_loss improved from 1.79751 to 1.79570, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7879 - mean_absolute_error: 0.9574 - mean_squared_error: 1.7879 - val_loss: 1.7957 - val_mean_absolute_error: 0.9622 - val_mean_squared_error: 1.7957\n",
            "Epoch 444/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.7984 - mean_absolute_error: 0.9584 - mean_squared_error: 1.7984\n",
            "Epoch 444: val_loss did not improve from 1.79570\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7869 - mean_absolute_error: 0.9557 - mean_squared_error: 1.7869 - val_loss: 1.7962 - val_mean_absolute_error: 0.9633 - val_mean_squared_error: 1.7962\n",
            "Epoch 445/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.7808 - mean_absolute_error: 0.9551 - mean_squared_error: 1.7808\n",
            "Epoch 445: val_loss improved from 1.79570 to 1.79407, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7853 - mean_absolute_error: 0.9558 - mean_squared_error: 1.7853 - val_loss: 1.7941 - val_mean_absolute_error: 0.9623 - val_mean_squared_error: 1.7941\n",
            "Epoch 446/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.7832 - mean_absolute_error: 0.9548 - mean_squared_error: 1.7832\n",
            "Epoch 446: val_loss did not improve from 1.79407\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7832 - mean_absolute_error: 0.9548 - mean_squared_error: 1.7832 - val_loss: 1.7998 - val_mean_absolute_error: 0.9666 - val_mean_squared_error: 1.7998\n",
            "Epoch 447/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.7924 - mean_absolute_error: 0.9579 - mean_squared_error: 1.7924\n",
            "Epoch 447: val_loss did not improve from 1.79407\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7832 - mean_absolute_error: 0.9564 - mean_squared_error: 1.7832 - val_loss: 1.7946 - val_mean_absolute_error: 0.9641 - val_mean_squared_error: 1.7946\n",
            "Epoch 448/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.7880 - mean_absolute_error: 0.9581 - mean_squared_error: 1.7880\n",
            "Epoch 448: val_loss did not improve from 1.79407\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7833 - mean_absolute_error: 0.9562 - mean_squared_error: 1.7833 - val_loss: 1.8029 - val_mean_absolute_error: 0.9689 - val_mean_squared_error: 1.8029\n",
            "Epoch 449/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.7606 - mean_absolute_error: 0.9503 - mean_squared_error: 1.7606\n",
            "Epoch 449: val_loss improved from 1.79407 to 1.79136, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7811 - mean_absolute_error: 0.9561 - mean_squared_error: 1.7811 - val_loss: 1.7914 - val_mean_absolute_error: 0.9606 - val_mean_squared_error: 1.7914\n",
            "Epoch 450/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.7828 - mean_absolute_error: 0.9555 - mean_squared_error: 1.7828\n",
            "Epoch 450: val_loss improved from 1.79136 to 1.78891, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7804 - mean_absolute_error: 0.9554 - mean_squared_error: 1.7804 - val_loss: 1.7889 - val_mean_absolute_error: 0.9606 - val_mean_squared_error: 1.7889\n",
            "Epoch 451/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.7359 - mean_absolute_error: 0.9420 - mean_squared_error: 1.7359\n",
            "Epoch 451: val_loss did not improve from 1.78891\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7797 - mean_absolute_error: 0.9556 - mean_squared_error: 1.7797 - val_loss: 1.7892 - val_mean_absolute_error: 0.9620 - val_mean_squared_error: 1.7892\n",
            "Epoch 452/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.7809 - mean_absolute_error: 0.9571 - mean_squared_error: 1.7809\n",
            "Epoch 452: val_loss did not improve from 1.78891\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7776 - mean_absolute_error: 0.9554 - mean_squared_error: 1.7776 - val_loss: 1.7909 - val_mean_absolute_error: 0.9641 - val_mean_squared_error: 1.7909\n",
            "Epoch 453/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.7873 - mean_absolute_error: 0.9575 - mean_squared_error: 1.7873\n",
            "Epoch 453: val_loss improved from 1.78891 to 1.78753, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7766 - mean_absolute_error: 0.9558 - mean_squared_error: 1.7766 - val_loss: 1.7875 - val_mean_absolute_error: 0.9606 - val_mean_squared_error: 1.7875\n",
            "Epoch 454/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.7756 - mean_absolute_error: 0.9562 - mean_squared_error: 1.7756\n",
            "Epoch 454: val_loss did not improve from 1.78753\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7764 - mean_absolute_error: 0.9554 - mean_squared_error: 1.7764 - val_loss: 1.7883 - val_mean_absolute_error: 0.9630 - val_mean_squared_error: 1.7883\n",
            "Epoch 455/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.7750 - mean_absolute_error: 0.9554 - mean_squared_error: 1.7750\n",
            "Epoch 455: val_loss improved from 1.78753 to 1.78510, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7750 - mean_absolute_error: 0.9554 - mean_squared_error: 1.7750 - val_loss: 1.7851 - val_mean_absolute_error: 0.9601 - val_mean_squared_error: 1.7851\n",
            "Epoch 456/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.7783 - mean_absolute_error: 0.9553 - mean_squared_error: 1.7783\n",
            "Epoch 456: val_loss did not improve from 1.78510\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7735 - mean_absolute_error: 0.9542 - mean_squared_error: 1.7735 - val_loss: 1.7860 - val_mean_absolute_error: 0.9623 - val_mean_squared_error: 1.7860\n",
            "Epoch 457/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.7728 - mean_absolute_error: 0.9555 - mean_squared_error: 1.7728\n",
            "Epoch 457: val_loss improved from 1.78510 to 1.78449, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7730 - mean_absolute_error: 0.9555 - mean_squared_error: 1.7730 - val_loss: 1.7845 - val_mean_absolute_error: 0.9615 - val_mean_squared_error: 1.7845\n",
            "Epoch 458/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.7786 - mean_absolute_error: 0.9566 - mean_squared_error: 1.7786\n",
            "Epoch 458: val_loss did not improve from 1.78449\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7718 - mean_absolute_error: 0.9550 - mean_squared_error: 1.7718 - val_loss: 1.7847 - val_mean_absolute_error: 0.9626 - val_mean_squared_error: 1.7847\n",
            "Epoch 459/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.7726 - mean_absolute_error: 0.9548 - mean_squared_error: 1.7726\n",
            "Epoch 459: val_loss improved from 1.78449 to 1.78381, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7712 - mean_absolute_error: 0.9545 - mean_squared_error: 1.7712 - val_loss: 1.7838 - val_mean_absolute_error: 0.9621 - val_mean_squared_error: 1.7838\n",
            "Epoch 460/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.7544 - mean_absolute_error: 0.9513 - mean_squared_error: 1.7544\n",
            "Epoch 460: val_loss did not improve from 1.78381\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7712 - mean_absolute_error: 0.9541 - mean_squared_error: 1.7712 - val_loss: 1.7974 - val_mean_absolute_error: 0.9696 - val_mean_squared_error: 1.7974\n",
            "Epoch 461/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.7621 - mean_absolute_error: 0.9543 - mean_squared_error: 1.7621\n",
            "Epoch 461: val_loss improved from 1.78381 to 1.78091, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7684 - mean_absolute_error: 0.9553 - mean_squared_error: 1.7684 - val_loss: 1.7809 - val_mean_absolute_error: 0.9598 - val_mean_squared_error: 1.7809\n",
            "Epoch 462/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.7416 - mean_absolute_error: 0.9481 - mean_squared_error: 1.7416\n",
            "Epoch 462: val_loss did not improve from 1.78091\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7681 - mean_absolute_error: 0.9549 - mean_squared_error: 1.7681 - val_loss: 1.7825 - val_mean_absolute_error: 0.9628 - val_mean_squared_error: 1.7825\n",
            "Epoch 463/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.7531 - mean_absolute_error: 0.9513 - mean_squared_error: 1.7531\n",
            "Epoch 463: val_loss did not improve from 1.78091\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7676 - mean_absolute_error: 0.9545 - mean_squared_error: 1.7676 - val_loss: 1.7815 - val_mean_absolute_error: 0.9621 - val_mean_squared_error: 1.7815\n",
            "Epoch 464/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.7736 - mean_absolute_error: 0.9548 - mean_squared_error: 1.7736\n",
            "Epoch 464: val_loss improved from 1.78091 to 1.77830, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7654 - mean_absolute_error: 0.9535 - mean_squared_error: 1.7654 - val_loss: 1.7783 - val_mean_absolute_error: 0.9598 - val_mean_squared_error: 1.7783\n",
            "Epoch 465/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.7635 - mean_absolute_error: 0.9529 - mean_squared_error: 1.7635\n",
            "Epoch 465: val_loss did not improve from 1.77830\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7650 - mean_absolute_error: 0.9535 - mean_squared_error: 1.7650 - val_loss: 1.7809 - val_mean_absolute_error: 0.9625 - val_mean_squared_error: 1.7809\n",
            "Epoch 466/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.7762 - mean_absolute_error: 0.9570 - mean_squared_error: 1.7762\n",
            "Epoch 466: val_loss improved from 1.77830 to 1.77646, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7648 - mean_absolute_error: 0.9555 - mean_squared_error: 1.7648 - val_loss: 1.7765 - val_mean_absolute_error: 0.9591 - val_mean_squared_error: 1.7765\n",
            "Epoch 467/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 1.7745 - mean_absolute_error: 0.9543 - mean_squared_error: 1.7745\n",
            "Epoch 467: val_loss did not improve from 1.77646\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7637 - mean_absolute_error: 0.9526 - mean_squared_error: 1.7637 - val_loss: 1.7803 - val_mean_absolute_error: 0.9632 - val_mean_squared_error: 1.7803\n",
            "Epoch 468/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.7606 - mean_absolute_error: 0.9544 - mean_squared_error: 1.7606\n",
            "Epoch 468: val_loss improved from 1.77646 to 1.77543, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7621 - mean_absolute_error: 0.9542 - mean_squared_error: 1.7621 - val_loss: 1.7754 - val_mean_absolute_error: 0.9597 - val_mean_squared_error: 1.7754\n",
            "Epoch 469/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.7504 - mean_absolute_error: 0.9508 - mean_squared_error: 1.7504\n",
            "Epoch 469: val_loss improved from 1.77543 to 1.77462, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7612 - mean_absolute_error: 0.9538 - mean_squared_error: 1.7612 - val_loss: 1.7746 - val_mean_absolute_error: 0.9592 - val_mean_squared_error: 1.7746\n",
            "Epoch 470/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.7446 - mean_absolute_error: 0.9499 - mean_squared_error: 1.7446\n",
            "Epoch 470: val_loss improved from 1.77462 to 1.77432, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7606 - mean_absolute_error: 0.9536 - mean_squared_error: 1.7606 - val_loss: 1.7743 - val_mean_absolute_error: 0.9600 - val_mean_squared_error: 1.7743\n",
            "Epoch 471/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.7514 - mean_absolute_error: 0.9515 - mean_squared_error: 1.7514\n",
            "Epoch 471: val_loss improved from 1.77432 to 1.77334, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7584 - mean_absolute_error: 0.9525 - mean_squared_error: 1.7584 - val_loss: 1.7733 - val_mean_absolute_error: 0.9593 - val_mean_squared_error: 1.7733\n",
            "Epoch 472/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.7762 - mean_absolute_error: 0.9598 - mean_squared_error: 1.7762\n",
            "Epoch 472: val_loss improved from 1.77334 to 1.77309, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7586 - mean_absolute_error: 0.9530 - mean_squared_error: 1.7586 - val_loss: 1.7731 - val_mean_absolute_error: 0.9602 - val_mean_squared_error: 1.7731\n",
            "Epoch 473/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.7567 - mean_absolute_error: 0.9520 - mean_squared_error: 1.7567\n",
            "Epoch 473: val_loss improved from 1.77309 to 1.77242, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7567 - mean_absolute_error: 0.9520 - mean_squared_error: 1.7567 - val_loss: 1.7724 - val_mean_absolute_error: 0.9600 - val_mean_squared_error: 1.7724\n",
            "Epoch 474/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.7605 - mean_absolute_error: 0.9542 - mean_squared_error: 1.7605\n",
            "Epoch 474: val_loss improved from 1.77242 to 1.77209, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7574 - mean_absolute_error: 0.9535 - mean_squared_error: 1.7574 - val_loss: 1.7721 - val_mean_absolute_error: 0.9602 - val_mean_squared_error: 1.7721\n",
            "Epoch 475/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.7637 - mean_absolute_error: 0.9546 - mean_squared_error: 1.7637\n",
            "Epoch 475: val_loss did not improve from 1.77209\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7562 - mean_absolute_error: 0.9526 - mean_squared_error: 1.7562 - val_loss: 1.7726 - val_mean_absolute_error: 0.9611 - val_mean_squared_error: 1.7726\n",
            "Epoch 476/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.7502 - mean_absolute_error: 0.9529 - mean_squared_error: 1.7502\n",
            "Epoch 476: val_loss improved from 1.77209 to 1.76977, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7549 - mean_absolute_error: 0.9532 - mean_squared_error: 1.7549 - val_loss: 1.7698 - val_mean_absolute_error: 0.9588 - val_mean_squared_error: 1.7698\n",
            "Epoch 477/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.7559 - mean_absolute_error: 0.9530 - mean_squared_error: 1.7559\n",
            "Epoch 477: val_loss did not improve from 1.76977\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7549 - mean_absolute_error: 0.9528 - mean_squared_error: 1.7549 - val_loss: 1.7732 - val_mean_absolute_error: 0.9620 - val_mean_squared_error: 1.7732\n",
            "Epoch 478/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.7639 - mean_absolute_error: 0.9546 - mean_squared_error: 1.7639\n",
            "Epoch 478: val_loss did not improve from 1.76977\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7518 - mean_absolute_error: 0.9515 - mean_squared_error: 1.7518 - val_loss: 1.7750 - val_mean_absolute_error: 0.9631 - val_mean_squared_error: 1.7750\n",
            "Epoch 479/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.7444 - mean_absolute_error: 0.9502 - mean_squared_error: 1.7444\n",
            "Epoch 479: val_loss improved from 1.76977 to 1.76949, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7515 - mean_absolute_error: 0.9519 - mean_squared_error: 1.7515 - val_loss: 1.7695 - val_mean_absolute_error: 0.9602 - val_mean_squared_error: 1.7695\n",
            "Epoch 480/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.7764 - mean_absolute_error: 0.9605 - mean_squared_error: 1.7764\n",
            "Epoch 480: val_loss did not improve from 1.76949\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7511 - mean_absolute_error: 0.9523 - mean_squared_error: 1.7511 - val_loss: 1.7697 - val_mean_absolute_error: 0.9608 - val_mean_squared_error: 1.7697\n",
            "Epoch 481/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.7483 - mean_absolute_error: 0.9518 - mean_squared_error: 1.7483\n",
            "Epoch 481: val_loss improved from 1.76949 to 1.76713, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7501 - mean_absolute_error: 0.9521 - mean_squared_error: 1.7501 - val_loss: 1.7671 - val_mean_absolute_error: 0.9583 - val_mean_squared_error: 1.7671\n",
            "Epoch 482/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.7501 - mean_absolute_error: 0.9523 - mean_squared_error: 1.7501\n",
            "Epoch 482: val_loss did not improve from 1.76713\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7501 - mean_absolute_error: 0.9523 - mean_squared_error: 1.7501 - val_loss: 1.7682 - val_mean_absolute_error: 0.9604 - val_mean_squared_error: 1.7682\n",
            "Epoch 483/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.7477 - mean_absolute_error: 0.9520 - mean_squared_error: 1.7477\n",
            "Epoch 483: val_loss improved from 1.76713 to 1.76478, saving model to best_model3.h5\n",
            "245/245 [==============================] - 2s 7ms/step - loss: 1.7487 - mean_absolute_error: 0.9521 - mean_squared_error: 1.7487 - val_loss: 1.7648 - val_mean_absolute_error: 0.9579 - val_mean_squared_error: 1.7648\n",
            "Epoch 484/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.7476 - mean_absolute_error: 0.9517 - mean_squared_error: 1.7476\n",
            "Epoch 484: val_loss did not improve from 1.76478\n",
            "245/245 [==============================] - 2s 7ms/step - loss: 1.7482 - mean_absolute_error: 0.9515 - mean_squared_error: 1.7482 - val_loss: 1.7657 - val_mean_absolute_error: 0.9592 - val_mean_squared_error: 1.7657\n",
            "Epoch 485/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.7580 - mean_absolute_error: 0.9553 - mean_squared_error: 1.7580\n",
            "Epoch 485: val_loss did not improve from 1.76478\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7465 - mean_absolute_error: 0.9510 - mean_squared_error: 1.7465 - val_loss: 1.7648 - val_mean_absolute_error: 0.9595 - val_mean_squared_error: 1.7648\n",
            "Epoch 486/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.7419 - mean_absolute_error: 0.9485 - mean_squared_error: 1.7419\n",
            "Epoch 486: val_loss improved from 1.76478 to 1.76338, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7459 - mean_absolute_error: 0.9512 - mean_squared_error: 1.7459 - val_loss: 1.7634 - val_mean_absolute_error: 0.9585 - val_mean_squared_error: 1.7634\n",
            "Epoch 487/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.7369 - mean_absolute_error: 0.9491 - mean_squared_error: 1.7369\n",
            "Epoch 487: val_loss did not improve from 1.76338\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.7433 - mean_absolute_error: 0.9502 - mean_squared_error: 1.7433 - val_loss: 1.7721 - val_mean_absolute_error: 0.9637 - val_mean_squared_error: 1.7721\n",
            "Epoch 488/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.7473 - mean_absolute_error: 0.9519 - mean_squared_error: 1.7473\n",
            "Epoch 488: val_loss did not improve from 1.76338\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.7462 - mean_absolute_error: 0.9519 - mean_squared_error: 1.7462 - val_loss: 1.7640 - val_mean_absolute_error: 0.9595 - val_mean_squared_error: 1.7640\n",
            "Epoch 489/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.7524 - mean_absolute_error: 0.9546 - mean_squared_error: 1.7524\n",
            "Epoch 489: val_loss improved from 1.76338 to 1.76230, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7437 - mean_absolute_error: 0.9512 - mean_squared_error: 1.7437 - val_loss: 1.7623 - val_mean_absolute_error: 0.9588 - val_mean_squared_error: 1.7623\n",
            "Epoch 490/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 1.7568 - mean_absolute_error: 0.9539 - mean_squared_error: 1.7568\n",
            "Epoch 490: val_loss improved from 1.76230 to 1.76069, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7430 - mean_absolute_error: 0.9512 - mean_squared_error: 1.7430 - val_loss: 1.7607 - val_mean_absolute_error: 0.9579 - val_mean_squared_error: 1.7607\n",
            "Epoch 491/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.7451 - mean_absolute_error: 0.9507 - mean_squared_error: 1.7451\n",
            "Epoch 491: val_loss did not improve from 1.76069\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7419 - mean_absolute_error: 0.9502 - mean_squared_error: 1.7419 - val_loss: 1.7610 - val_mean_absolute_error: 0.9587 - val_mean_squared_error: 1.7610\n",
            "Epoch 492/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.7387 - mean_absolute_error: 0.9492 - mean_squared_error: 1.7387\n",
            "Epoch 492: val_loss did not improve from 1.76069\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7407 - mean_absolute_error: 0.9504 - mean_squared_error: 1.7407 - val_loss: 1.7612 - val_mean_absolute_error: 0.9589 - val_mean_squared_error: 1.7612\n",
            "Epoch 493/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.7381 - mean_absolute_error: 0.9492 - mean_squared_error: 1.7381\n",
            "Epoch 493: val_loss improved from 1.76069 to 1.75913, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7404 - mean_absolute_error: 0.9503 - mean_squared_error: 1.7404 - val_loss: 1.7591 - val_mean_absolute_error: 0.9579 - val_mean_squared_error: 1.7591\n",
            "Epoch 494/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.7389 - mean_absolute_error: 0.9477 - mean_squared_error: 1.7389\n",
            "Epoch 494: val_loss improved from 1.75913 to 1.75911, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7393 - mean_absolute_error: 0.9496 - mean_squared_error: 1.7393 - val_loss: 1.7591 - val_mean_absolute_error: 0.9584 - val_mean_squared_error: 1.7591\n",
            "Epoch 495/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.7380 - mean_absolute_error: 0.9512 - mean_squared_error: 1.7380\n",
            "Epoch 495: val_loss improved from 1.75911 to 1.75811, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7366 - mean_absolute_error: 0.9509 - mean_squared_error: 1.7366 - val_loss: 1.7581 - val_mean_absolute_error: 0.9557 - val_mean_squared_error: 1.7581\n",
            "Epoch 496/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.7458 - mean_absolute_error: 0.9524 - mean_squared_error: 1.7458\n",
            "Epoch 496: val_loss improved from 1.75811 to 1.75793, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7392 - mean_absolute_error: 0.9493 - mean_squared_error: 1.7392 - val_loss: 1.7579 - val_mean_absolute_error: 0.9583 - val_mean_squared_error: 1.7579\n",
            "Epoch 497/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.7306 - mean_absolute_error: 0.9507 - mean_squared_error: 1.7306\n",
            "Epoch 497: val_loss improved from 1.75793 to 1.75615, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7364 - mean_absolute_error: 0.9502 - mean_squared_error: 1.7364 - val_loss: 1.7561 - val_mean_absolute_error: 0.9563 - val_mean_squared_error: 1.7561\n",
            "Epoch 498/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.7446 - mean_absolute_error: 0.9530 - mean_squared_error: 1.7446\n",
            "Epoch 498: val_loss improved from 1.75615 to 1.75601, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7370 - mean_absolute_error: 0.9493 - mean_squared_error: 1.7370 - val_loss: 1.7560 - val_mean_absolute_error: 0.9576 - val_mean_squared_error: 1.7560\n",
            "Epoch 499/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.7398 - mean_absolute_error: 0.9513 - mean_squared_error: 1.7398\n",
            "Epoch 499: val_loss did not improve from 1.75601\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7351 - mean_absolute_error: 0.9487 - mean_squared_error: 1.7351 - val_loss: 1.7583 - val_mean_absolute_error: 0.9593 - val_mean_squared_error: 1.7583\n",
            "Epoch 500/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.7355 - mean_absolute_error: 0.9488 - mean_squared_error: 1.7355\n",
            "Epoch 500: val_loss did not improve from 1.75601\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7346 - mean_absolute_error: 0.9496 - mean_squared_error: 1.7346 - val_loss: 1.7609 - val_mean_absolute_error: 0.9609 - val_mean_squared_error: 1.7609\n",
            "Epoch 501/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.7500 - mean_absolute_error: 0.9546 - mean_squared_error: 1.7500\n",
            "Epoch 501: val_loss improved from 1.75601 to 1.75454, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7337 - mean_absolute_error: 0.9497 - mean_squared_error: 1.7337 - val_loss: 1.7545 - val_mean_absolute_error: 0.9573 - val_mean_squared_error: 1.7545\n",
            "Epoch 502/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.7302 - mean_absolute_error: 0.9493 - mean_squared_error: 1.7302\n",
            "Epoch 502: val_loss improved from 1.75454 to 1.75324, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7329 - mean_absolute_error: 0.9495 - mean_squared_error: 1.7329 - val_loss: 1.7532 - val_mean_absolute_error: 0.9564 - val_mean_squared_error: 1.7532\n",
            "Epoch 503/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.7401 - mean_absolute_error: 0.9510 - mean_squared_error: 1.7401\n",
            "Epoch 503: val_loss did not improve from 1.75324\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7325 - mean_absolute_error: 0.9482 - mean_squared_error: 1.7325 - val_loss: 1.7591 - val_mean_absolute_error: 0.9608 - val_mean_squared_error: 1.7591\n",
            "Epoch 504/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.7367 - mean_absolute_error: 0.9497 - mean_squared_error: 1.7367\n",
            "Epoch 504: val_loss improved from 1.75324 to 1.75270, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7313 - mean_absolute_error: 0.9492 - mean_squared_error: 1.7313 - val_loss: 1.7527 - val_mean_absolute_error: 0.9571 - val_mean_squared_error: 1.7527\n",
            "Epoch 505/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.7423 - mean_absolute_error: 0.9523 - mean_squared_error: 1.7423\n",
            "Epoch 505: val_loss did not improve from 1.75270\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7312 - mean_absolute_error: 0.9492 - mean_squared_error: 1.7312 - val_loss: 1.7543 - val_mean_absolute_error: 0.9580 - val_mean_squared_error: 1.7543\n",
            "Epoch 506/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.7301 - mean_absolute_error: 0.9461 - mean_squared_error: 1.7301\n",
            "Epoch 506: val_loss did not improve from 1.75270\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7301 - mean_absolute_error: 0.9488 - mean_squared_error: 1.7301 - val_loss: 1.7538 - val_mean_absolute_error: 0.9581 - val_mean_squared_error: 1.7538\n",
            "Epoch 507/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.7279 - mean_absolute_error: 0.9455 - mean_squared_error: 1.7279\n",
            "Epoch 507: val_loss did not improve from 1.75270\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7286 - mean_absolute_error: 0.9485 - mean_squared_error: 1.7286 - val_loss: 1.7624 - val_mean_absolute_error: 0.9625 - val_mean_squared_error: 1.7624\n",
            "Epoch 508/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.7430 - mean_absolute_error: 0.9528 - mean_squared_error: 1.7430\n",
            "Epoch 508: val_loss did not improve from 1.75270\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7289 - mean_absolute_error: 0.9486 - mean_squared_error: 1.7289 - val_loss: 1.7557 - val_mean_absolute_error: 0.9597 - val_mean_squared_error: 1.7557\n",
            "Epoch 509/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.7274 - mean_absolute_error: 0.9474 - mean_squared_error: 1.7274\n",
            "Epoch 509: val_loss improved from 1.75270 to 1.75211, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7275 - mean_absolute_error: 0.9490 - mean_squared_error: 1.7275 - val_loss: 1.7521 - val_mean_absolute_error: 0.9579 - val_mean_squared_error: 1.7521\n",
            "Epoch 510/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.7323 - mean_absolute_error: 0.9505 - mean_squared_error: 1.7323\n",
            "Epoch 510: val_loss improved from 1.75211 to 1.75076, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7277 - mean_absolute_error: 0.9485 - mean_squared_error: 1.7277 - val_loss: 1.7508 - val_mean_absolute_error: 0.9573 - val_mean_squared_error: 1.7508\n",
            "Epoch 511/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.7157 - mean_absolute_error: 0.9454 - mean_squared_error: 1.7157\n",
            "Epoch 511: val_loss improved from 1.75076 to 1.74861, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7261 - mean_absolute_error: 0.9475 - mean_squared_error: 1.7261 - val_loss: 1.7486 - val_mean_absolute_error: 0.9562 - val_mean_squared_error: 1.7486\n",
            "Epoch 512/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.7208 - mean_absolute_error: 0.9467 - mean_squared_error: 1.7208\n",
            "Epoch 512: val_loss did not improve from 1.74861\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7256 - mean_absolute_error: 0.9488 - mean_squared_error: 1.7256 - val_loss: 1.7506 - val_mean_absolute_error: 0.9576 - val_mean_squared_error: 1.7506\n",
            "Epoch 513/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.7203 - mean_absolute_error: 0.9456 - mean_squared_error: 1.7203\n",
            "Epoch 513: val_loss did not improve from 1.74861\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7237 - mean_absolute_error: 0.9491 - mean_squared_error: 1.7237 - val_loss: 1.7493 - val_mean_absolute_error: 0.9570 - val_mean_squared_error: 1.7493\n",
            "Epoch 514/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.7077 - mean_absolute_error: 0.9443 - mean_squared_error: 1.7077\n",
            "Epoch 514: val_loss improved from 1.74861 to 1.74591, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7240 - mean_absolute_error: 0.9483 - mean_squared_error: 1.7240 - val_loss: 1.7459 - val_mean_absolute_error: 0.9542 - val_mean_squared_error: 1.7459\n",
            "Epoch 515/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.7226 - mean_absolute_error: 0.9466 - mean_squared_error: 1.7226\n",
            "Epoch 515: val_loss did not improve from 1.74591\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7240 - mean_absolute_error: 0.9466 - mean_squared_error: 1.7240 - val_loss: 1.7508 - val_mean_absolute_error: 0.9583 - val_mean_squared_error: 1.7508\n",
            "Epoch 516/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.7131 - mean_absolute_error: 0.9450 - mean_squared_error: 1.7131\n",
            "Epoch 516: val_loss did not improve from 1.74591\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7231 - mean_absolute_error: 0.9474 - mean_squared_error: 1.7231 - val_loss: 1.7491 - val_mean_absolute_error: 0.9577 - val_mean_squared_error: 1.7491\n",
            "Epoch 517/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.7357 - mean_absolute_error: 0.9530 - mean_squared_error: 1.7357\n",
            "Epoch 517: val_loss improved from 1.74591 to 1.74546, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7227 - mean_absolute_error: 0.9483 - mean_squared_error: 1.7227 - val_loss: 1.7455 - val_mean_absolute_error: 0.9555 - val_mean_squared_error: 1.7455\n",
            "Epoch 518/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.7121 - mean_absolute_error: 0.9451 - mean_squared_error: 1.7121\n",
            "Epoch 518: val_loss improved from 1.74546 to 1.74395, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7201 - mean_absolute_error: 0.9474 - mean_squared_error: 1.7201 - val_loss: 1.7440 - val_mean_absolute_error: 0.9545 - val_mean_squared_error: 1.7440\n",
            "Epoch 519/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.7185 - mean_absolute_error: 0.9438 - mean_squared_error: 1.7185\n",
            "Epoch 519: val_loss did not improve from 1.74395\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7203 - mean_absolute_error: 0.9462 - mean_squared_error: 1.7203 - val_loss: 1.7456 - val_mean_absolute_error: 0.9559 - val_mean_squared_error: 1.7456\n",
            "Epoch 520/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.7178 - mean_absolute_error: 0.9470 - mean_squared_error: 1.7178\n",
            "Epoch 520: val_loss did not improve from 1.74395\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7189 - mean_absolute_error: 0.9475 - mean_squared_error: 1.7189 - val_loss: 1.7442 - val_mean_absolute_error: 0.9543 - val_mean_squared_error: 1.7442\n",
            "Epoch 521/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.7363 - mean_absolute_error: 0.9508 - mean_squared_error: 1.7363\n",
            "Epoch 521: val_loss did not improve from 1.74395\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7193 - mean_absolute_error: 0.9465 - mean_squared_error: 1.7193 - val_loss: 1.7455 - val_mean_absolute_error: 0.9567 - val_mean_squared_error: 1.7455\n",
            "Epoch 522/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.7243 - mean_absolute_error: 0.9510 - mean_squared_error: 1.7243\n",
            "Epoch 522: val_loss did not improve from 1.74395\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7179 - mean_absolute_error: 0.9471 - mean_squared_error: 1.7179 - val_loss: 1.7452 - val_mean_absolute_error: 0.9564 - val_mean_squared_error: 1.7452\n",
            "Epoch 523/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.7186 - mean_absolute_error: 0.9475 - mean_squared_error: 1.7186\n",
            "Epoch 523: val_loss did not improve from 1.74395\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7174 - mean_absolute_error: 0.9473 - mean_squared_error: 1.7174 - val_loss: 1.7441 - val_mean_absolute_error: 0.9555 - val_mean_squared_error: 1.7441\n",
            "Epoch 524/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.7096 - mean_absolute_error: 0.9433 - mean_squared_error: 1.7096\n",
            "Epoch 524: val_loss improved from 1.74395 to 1.74088, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7169 - mean_absolute_error: 0.9465 - mean_squared_error: 1.7169 - val_loss: 1.7409 - val_mean_absolute_error: 0.9539 - val_mean_squared_error: 1.7409\n",
            "Epoch 525/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.7097 - mean_absolute_error: 0.9423 - mean_squared_error: 1.7097\n",
            "Epoch 525: val_loss improved from 1.74088 to 1.74016, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7162 - mean_absolute_error: 0.9460 - mean_squared_error: 1.7162 - val_loss: 1.7402 - val_mean_absolute_error: 0.9538 - val_mean_squared_error: 1.7402\n",
            "Epoch 526/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.7217 - mean_absolute_error: 0.9478 - mean_squared_error: 1.7217\n",
            "Epoch 526: val_loss did not improve from 1.74016\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7151 - mean_absolute_error: 0.9455 - mean_squared_error: 1.7151 - val_loss: 1.7419 - val_mean_absolute_error: 0.9553 - val_mean_squared_error: 1.7419\n",
            "Epoch 527/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.7351 - mean_absolute_error: 0.9535 - mean_squared_error: 1.7351\n",
            "Epoch 527: val_loss did not improve from 1.74016\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7153 - mean_absolute_error: 0.9466 - mean_squared_error: 1.7153 - val_loss: 1.7410 - val_mean_absolute_error: 0.9548 - val_mean_squared_error: 1.7410\n",
            "Epoch 528/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.7095 - mean_absolute_error: 0.9453 - mean_squared_error: 1.7095\n",
            "Epoch 528: val_loss improved from 1.74016 to 1.73935, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7139 - mean_absolute_error: 0.9461 - mean_squared_error: 1.7139 - val_loss: 1.7393 - val_mean_absolute_error: 0.9541 - val_mean_squared_error: 1.7393\n",
            "Epoch 529/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.6956 - mean_absolute_error: 0.9429 - mean_squared_error: 1.6956\n",
            "Epoch 529: val_loss did not improve from 1.73935\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7130 - mean_absolute_error: 0.9455 - mean_squared_error: 1.7130 - val_loss: 1.7399 - val_mean_absolute_error: 0.9545 - val_mean_squared_error: 1.7399\n",
            "Epoch 530/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.7138 - mean_absolute_error: 0.9458 - mean_squared_error: 1.7138\n",
            "Epoch 530: val_loss did not improve from 1.73935\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7118 - mean_absolute_error: 0.9456 - mean_squared_error: 1.7118 - val_loss: 1.7438 - val_mean_absolute_error: 0.9568 - val_mean_squared_error: 1.7438\n",
            "Epoch 531/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.7009 - mean_absolute_error: 0.9448 - mean_squared_error: 1.7009\n",
            "Epoch 531: val_loss improved from 1.73935 to 1.73706, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7116 - mean_absolute_error: 0.9459 - mean_squared_error: 1.7116 - val_loss: 1.7371 - val_mean_absolute_error: 0.9526 - val_mean_squared_error: 1.7371\n",
            "Epoch 532/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.7037 - mean_absolute_error: 0.9424 - mean_squared_error: 1.7037\n",
            "Epoch 532: val_loss improved from 1.73706 to 1.73660, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7124 - mean_absolute_error: 0.9450 - mean_squared_error: 1.7124 - val_loss: 1.7366 - val_mean_absolute_error: 0.9527 - val_mean_squared_error: 1.7366\n",
            "Epoch 533/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.7003 - mean_absolute_error: 0.9414 - mean_squared_error: 1.7003\n",
            "Epoch 533: val_loss improved from 1.73660 to 1.73619, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7112 - mean_absolute_error: 0.9444 - mean_squared_error: 1.7112 - val_loss: 1.7362 - val_mean_absolute_error: 0.9530 - val_mean_squared_error: 1.7362\n",
            "Epoch 534/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.7047 - mean_absolute_error: 0.9414 - mean_squared_error: 1.7047\n",
            "Epoch 534: val_loss did not improve from 1.73619\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7103 - mean_absolute_error: 0.9446 - mean_squared_error: 1.7103 - val_loss: 1.7363 - val_mean_absolute_error: 0.9531 - val_mean_squared_error: 1.7363\n",
            "Epoch 535/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.7248 - mean_absolute_error: 0.9478 - mean_squared_error: 1.7248\n",
            "Epoch 535: val_loss did not improve from 1.73619\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7100 - mean_absolute_error: 0.9453 - mean_squared_error: 1.7100 - val_loss: 1.7366 - val_mean_absolute_error: 0.9536 - val_mean_squared_error: 1.7366\n",
            "Epoch 536/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.7165 - mean_absolute_error: 0.9470 - mean_squared_error: 1.7165\n",
            "Epoch 536: val_loss did not improve from 1.73619\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7091 - mean_absolute_error: 0.9455 - mean_squared_error: 1.7091 - val_loss: 1.7363 - val_mean_absolute_error: 0.9532 - val_mean_squared_error: 1.7363\n",
            "Epoch 537/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.7059 - mean_absolute_error: 0.9460 - mean_squared_error: 1.7059\n",
            "Epoch 537: val_loss improved from 1.73619 to 1.73522, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7083 - mean_absolute_error: 0.9446 - mean_squared_error: 1.7083 - val_loss: 1.7352 - val_mean_absolute_error: 0.9530 - val_mean_squared_error: 1.7352\n",
            "Epoch 538/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.7196 - mean_absolute_error: 0.9461 - mean_squared_error: 1.7196\n",
            "Epoch 538: val_loss did not improve from 1.73522\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7073 - mean_absolute_error: 0.9439 - mean_squared_error: 1.7073 - val_loss: 1.7382 - val_mean_absolute_error: 0.9549 - val_mean_squared_error: 1.7382\n",
            "Epoch 539/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.7144 - mean_absolute_error: 0.9479 - mean_squared_error: 1.7144\n",
            "Epoch 539: val_loss improved from 1.73522 to 1.73504, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7070 - mean_absolute_error: 0.9447 - mean_squared_error: 1.7070 - val_loss: 1.7350 - val_mean_absolute_error: 0.9529 - val_mean_squared_error: 1.7350\n",
            "Epoch 540/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.7119 - mean_absolute_error: 0.9447 - mean_squared_error: 1.7119\n",
            "Epoch 540: val_loss did not improve from 1.73504\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7059 - mean_absolute_error: 0.9437 - mean_squared_error: 1.7059 - val_loss: 1.7396 - val_mean_absolute_error: 0.9557 - val_mean_squared_error: 1.7396\n",
            "Epoch 541/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.7088 - mean_absolute_error: 0.9457 - mean_squared_error: 1.7088\n",
            "Epoch 541: val_loss improved from 1.73504 to 1.73210, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7055 - mean_absolute_error: 0.9443 - mean_squared_error: 1.7055 - val_loss: 1.7321 - val_mean_absolute_error: 0.9518 - val_mean_squared_error: 1.7321\n",
            "Epoch 542/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.7048 - mean_absolute_error: 0.9434 - mean_squared_error: 1.7048\n",
            "Epoch 542: val_loss improved from 1.73210 to 1.73181, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7048 - mean_absolute_error: 0.9434 - mean_squared_error: 1.7048 - val_loss: 1.7318 - val_mean_absolute_error: 0.9515 - val_mean_squared_error: 1.7318\n",
            "Epoch 543/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.7052 - mean_absolute_error: 0.9437 - mean_squared_error: 1.7052\n",
            "Epoch 543: val_loss improved from 1.73181 to 1.73119, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7034 - mean_absolute_error: 0.9431 - mean_squared_error: 1.7034 - val_loss: 1.7312 - val_mean_absolute_error: 0.9514 - val_mean_squared_error: 1.7312\n",
            "Epoch 544/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.7069 - mean_absolute_error: 0.9444 - mean_squared_error: 1.7069\n",
            "Epoch 544: val_loss did not improve from 1.73119\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7025 - mean_absolute_error: 0.9430 - mean_squared_error: 1.7025 - val_loss: 1.7324 - val_mean_absolute_error: 0.9524 - val_mean_squared_error: 1.7324\n",
            "Epoch 545/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.6868 - mean_absolute_error: 0.9417 - mean_squared_error: 1.6868\n",
            "Epoch 545: val_loss did not improve from 1.73119\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7029 - mean_absolute_error: 0.9436 - mean_squared_error: 1.7029 - val_loss: 1.7335 - val_mean_absolute_error: 0.9529 - val_mean_squared_error: 1.7335\n",
            "Epoch 546/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.7112 - mean_absolute_error: 0.9454 - mean_squared_error: 1.7112\n",
            "Epoch 546: val_loss improved from 1.73119 to 1.73028, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7026 - mean_absolute_error: 0.9443 - mean_squared_error: 1.7026 - val_loss: 1.7303 - val_mean_absolute_error: 0.9514 - val_mean_squared_error: 1.7303\n",
            "Epoch 547/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.7002 - mean_absolute_error: 0.9414 - mean_squared_error: 1.7002\n",
            "Epoch 547: val_loss did not improve from 1.73028\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7011 - mean_absolute_error: 0.9425 - mean_squared_error: 1.7011 - val_loss: 1.7334 - val_mean_absolute_error: 0.9529 - val_mean_squared_error: 1.7334\n",
            "Epoch 548/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.6970 - mean_absolute_error: 0.9409 - mean_squared_error: 1.6970\n",
            "Epoch 548: val_loss improved from 1.73028 to 1.72897, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7018 - mean_absolute_error: 0.9430 - mean_squared_error: 1.7018 - val_loss: 1.7290 - val_mean_absolute_error: 0.9508 - val_mean_squared_error: 1.7290\n",
            "Epoch 549/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.6917 - mean_absolute_error: 0.9404 - mean_squared_error: 1.6917\n",
            "Epoch 549: val_loss improved from 1.72897 to 1.72886, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7019 - mean_absolute_error: 0.9433 - mean_squared_error: 1.7019 - val_loss: 1.7289 - val_mean_absolute_error: 0.9508 - val_mean_squared_error: 1.7289\n",
            "Epoch 550/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.6963 - mean_absolute_error: 0.9416 - mean_squared_error: 1.6963\n",
            "Epoch 550: val_loss did not improve from 1.72886\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6992 - mean_absolute_error: 0.9423 - mean_squared_error: 1.6992 - val_loss: 1.7294 - val_mean_absolute_error: 0.9516 - val_mean_squared_error: 1.7294\n",
            "Epoch 551/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.6852 - mean_absolute_error: 0.9399 - mean_squared_error: 1.6852\n",
            "Epoch 551: val_loss did not improve from 1.72886\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6984 - mean_absolute_error: 0.9426 - mean_squared_error: 1.6984 - val_loss: 1.7295 - val_mean_absolute_error: 0.9514 - val_mean_squared_error: 1.7295\n",
            "Epoch 552/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.6868 - mean_absolute_error: 0.9372 - mean_squared_error: 1.6868\n",
            "Epoch 552: val_loss did not improve from 1.72886\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6973 - mean_absolute_error: 0.9412 - mean_squared_error: 1.6973 - val_loss: 1.7324 - val_mean_absolute_error: 0.9535 - val_mean_squared_error: 1.7324\n",
            "Epoch 553/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.7015 - mean_absolute_error: 0.9451 - mean_squared_error: 1.7015\n",
            "Epoch 553: val_loss improved from 1.72886 to 1.72876, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6981 - mean_absolute_error: 0.9438 - mean_squared_error: 1.6981 - val_loss: 1.7288 - val_mean_absolute_error: 0.9513 - val_mean_squared_error: 1.7288\n",
            "Epoch 554/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.7071 - mean_absolute_error: 0.9461 - mean_squared_error: 1.7071\n",
            "Epoch 554: val_loss did not improve from 1.72876\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6975 - mean_absolute_error: 0.9422 - mean_squared_error: 1.6975 - val_loss: 1.7288 - val_mean_absolute_error: 0.9509 - val_mean_squared_error: 1.7288\n",
            "Epoch 555/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.6974 - mean_absolute_error: 0.9424 - mean_squared_error: 1.6974\n",
            "Epoch 555: val_loss improved from 1.72876 to 1.72582, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6970 - mean_absolute_error: 0.9421 - mean_squared_error: 1.6970 - val_loss: 1.7258 - val_mean_absolute_error: 0.9497 - val_mean_squared_error: 1.7258\n",
            "Epoch 556/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.6942 - mean_absolute_error: 0.9409 - mean_squared_error: 1.6942\n",
            "Epoch 556: val_loss improved from 1.72582 to 1.72466, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6950 - mean_absolute_error: 0.9416 - mean_squared_error: 1.6950 - val_loss: 1.7247 - val_mean_absolute_error: 0.9496 - val_mean_squared_error: 1.7247\n",
            "Epoch 557/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.6971 - mean_absolute_error: 0.9430 - mean_squared_error: 1.6971\n",
            "Epoch 557: val_loss improved from 1.72466 to 1.72444, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6948 - mean_absolute_error: 0.9419 - mean_squared_error: 1.6948 - val_loss: 1.7244 - val_mean_absolute_error: 0.9495 - val_mean_squared_error: 1.7244\n",
            "Epoch 558/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.7044 - mean_absolute_error: 0.9440 - mean_squared_error: 1.7044\n",
            "Epoch 558: val_loss did not improve from 1.72444\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6943 - mean_absolute_error: 0.9423 - mean_squared_error: 1.6943 - val_loss: 1.7250 - val_mean_absolute_error: 0.9490 - val_mean_squared_error: 1.7250\n",
            "Epoch 559/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.6888 - mean_absolute_error: 0.9395 - mean_squared_error: 1.6888\n",
            "Epoch 559: val_loss improved from 1.72444 to 1.72310, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6935 - mean_absolute_error: 0.9419 - mean_squared_error: 1.6935 - val_loss: 1.7231 - val_mean_absolute_error: 0.9486 - val_mean_squared_error: 1.7231\n",
            "Epoch 560/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.6849 - mean_absolute_error: 0.9407 - mean_squared_error: 1.6849\n",
            "Epoch 560: val_loss improved from 1.72310 to 1.72292, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6924 - mean_absolute_error: 0.9406 - mean_squared_error: 1.6924 - val_loss: 1.7229 - val_mean_absolute_error: 0.9484 - val_mean_squared_error: 1.7229\n",
            "Epoch 561/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.6766 - mean_absolute_error: 0.9350 - mean_squared_error: 1.6766\n",
            "Epoch 561: val_loss did not improve from 1.72292\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6926 - mean_absolute_error: 0.9407 - mean_squared_error: 1.6926 - val_loss: 1.7239 - val_mean_absolute_error: 0.9495 - val_mean_squared_error: 1.7239\n",
            "Epoch 562/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.7076 - mean_absolute_error: 0.9447 - mean_squared_error: 1.7076\n",
            "Epoch 562: val_loss did not improve from 1.72292\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6913 - mean_absolute_error: 0.9414 - mean_squared_error: 1.6913 - val_loss: 1.7234 - val_mean_absolute_error: 0.9490 - val_mean_squared_error: 1.7234\n",
            "Epoch 563/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.6741 - mean_absolute_error: 0.9351 - mean_squared_error: 1.6741\n",
            "Epoch 563: val_loss improved from 1.72292 to 1.72149, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6905 - mean_absolute_error: 0.9411 - mean_squared_error: 1.6905 - val_loss: 1.7215 - val_mean_absolute_error: 0.9482 - val_mean_squared_error: 1.7215\n",
            "Epoch 564/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.6837 - mean_absolute_error: 0.9379 - mean_squared_error: 1.6837\n",
            "Epoch 564: val_loss did not improve from 1.72149\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6908 - mean_absolute_error: 0.9401 - mean_squared_error: 1.6908 - val_loss: 1.7222 - val_mean_absolute_error: 0.9489 - val_mean_squared_error: 1.7222\n",
            "Epoch 565/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.6946 - mean_absolute_error: 0.9420 - mean_squared_error: 1.6946\n",
            "Epoch 565: val_loss did not improve from 1.72149\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6916 - mean_absolute_error: 0.9411 - mean_squared_error: 1.6916 - val_loss: 1.7221 - val_mean_absolute_error: 0.9488 - val_mean_squared_error: 1.7221\n",
            "Epoch 566/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.6914 - mean_absolute_error: 0.9402 - mean_squared_error: 1.6914\n",
            "Epoch 566: val_loss did not improve from 1.72149\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6887 - mean_absolute_error: 0.9394 - mean_squared_error: 1.6887 - val_loss: 1.7244 - val_mean_absolute_error: 0.9498 - val_mean_squared_error: 1.7244\n",
            "Epoch 567/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.6892 - mean_absolute_error: 0.9405 - mean_squared_error: 1.6892\n",
            "Epoch 567: val_loss did not improve from 1.72149\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6889 - mean_absolute_error: 0.9395 - mean_squared_error: 1.6889 - val_loss: 1.7228 - val_mean_absolute_error: 0.9493 - val_mean_squared_error: 1.7228\n",
            "Epoch 568/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.6856 - mean_absolute_error: 0.9381 - mean_squared_error: 1.6856\n",
            "Epoch 568: val_loss did not improve from 1.72149\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6884 - mean_absolute_error: 0.9405 - mean_squared_error: 1.6884 - val_loss: 1.7241 - val_mean_absolute_error: 0.9500 - val_mean_squared_error: 1.7241\n",
            "Epoch 569/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.6893 - mean_absolute_error: 0.9404 - mean_squared_error: 1.6893\n",
            "Epoch 569: val_loss improved from 1.72149 to 1.71938, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6875 - mean_absolute_error: 0.9405 - mean_squared_error: 1.6875 - val_loss: 1.7194 - val_mean_absolute_error: 0.9481 - val_mean_squared_error: 1.7194\n",
            "Epoch 570/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.6859 - mean_absolute_error: 0.9356 - mean_squared_error: 1.6859\n",
            "Epoch 570: val_loss did not improve from 1.71938\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6860 - mean_absolute_error: 0.9388 - mean_squared_error: 1.6860 - val_loss: 1.7198 - val_mean_absolute_error: 0.9484 - val_mean_squared_error: 1.7198\n",
            "Epoch 571/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.6874 - mean_absolute_error: 0.9422 - mean_squared_error: 1.6874\n",
            "Epoch 571: val_loss improved from 1.71938 to 1.71779, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6860 - mean_absolute_error: 0.9403 - mean_squared_error: 1.6860 - val_loss: 1.7178 - val_mean_absolute_error: 0.9472 - val_mean_squared_error: 1.7178\n",
            "Epoch 572/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.6891 - mean_absolute_error: 0.9409 - mean_squared_error: 1.6891\n",
            "Epoch 572: val_loss improved from 1.71779 to 1.71744, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6864 - mean_absolute_error: 0.9393 - mean_squared_error: 1.6864 - val_loss: 1.7174 - val_mean_absolute_error: 0.9468 - val_mean_squared_error: 1.7174\n",
            "Epoch 573/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.6996 - mean_absolute_error: 0.9437 - mean_squared_error: 1.6996\n",
            "Epoch 573: val_loss improved from 1.71744 to 1.71709, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6842 - mean_absolute_error: 0.9392 - mean_squared_error: 1.6842 - val_loss: 1.7171 - val_mean_absolute_error: 0.9469 - val_mean_squared_error: 1.7171\n",
            "Epoch 574/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.6935 - mean_absolute_error: 0.9409 - mean_squared_error: 1.6935\n",
            "Epoch 574: val_loss did not improve from 1.71709\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6840 - mean_absolute_error: 0.9397 - mean_squared_error: 1.6840 - val_loss: 1.7180 - val_mean_absolute_error: 0.9471 - val_mean_squared_error: 1.7180\n",
            "Epoch 575/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.6808 - mean_absolute_error: 0.9377 - mean_squared_error: 1.6808\n",
            "Epoch 575: val_loss improved from 1.71709 to 1.71587, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6824 - mean_absolute_error: 0.9383 - mean_squared_error: 1.6824 - val_loss: 1.7159 - val_mean_absolute_error: 0.9460 - val_mean_squared_error: 1.7159\n",
            "Epoch 576/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.6681 - mean_absolute_error: 0.9356 - mean_squared_error: 1.6681\n",
            "Epoch 576: val_loss did not improve from 1.71587\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6823 - mean_absolute_error: 0.9375 - mean_squared_error: 1.6823 - val_loss: 1.7160 - val_mean_absolute_error: 0.9464 - val_mean_squared_error: 1.7160\n",
            "Epoch 577/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.6863 - mean_absolute_error: 0.9399 - mean_squared_error: 1.6863\n",
            "Epoch 577: val_loss did not improve from 1.71587\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6827 - mean_absolute_error: 0.9387 - mean_squared_error: 1.6827 - val_loss: 1.7182 - val_mean_absolute_error: 0.9474 - val_mean_squared_error: 1.7182\n",
            "Epoch 578/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.6727 - mean_absolute_error: 0.9347 - mean_squared_error: 1.6727\n",
            "Epoch 578: val_loss did not improve from 1.71587\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6818 - mean_absolute_error: 0.9375 - mean_squared_error: 1.6818 - val_loss: 1.7180 - val_mean_absolute_error: 0.9474 - val_mean_squared_error: 1.7180\n",
            "Epoch 579/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.6814 - mean_absolute_error: 0.9385 - mean_squared_error: 1.6814\n",
            "Epoch 579: val_loss did not improve from 1.71587\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6810 - mean_absolute_error: 0.9379 - mean_squared_error: 1.6810 - val_loss: 1.7165 - val_mean_absolute_error: 0.9468 - val_mean_squared_error: 1.7165\n",
            "Epoch 580/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.6873 - mean_absolute_error: 0.9412 - mean_squared_error: 1.6873\n",
            "Epoch 580: val_loss improved from 1.71587 to 1.71385, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6798 - mean_absolute_error: 0.9388 - mean_squared_error: 1.6798 - val_loss: 1.7138 - val_mean_absolute_error: 0.9459 - val_mean_squared_error: 1.7138\n",
            "Epoch 581/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.6802 - mean_absolute_error: 0.9375 - mean_squared_error: 1.6802\n",
            "Epoch 581: val_loss did not improve from 1.71385\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6802 - mean_absolute_error: 0.9375 - mean_squared_error: 1.6802 - val_loss: 1.7159 - val_mean_absolute_error: 0.9464 - val_mean_squared_error: 1.7159\n",
            "Epoch 582/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.6786 - mean_absolute_error: 0.9373 - mean_squared_error: 1.6786\n",
            "Epoch 582: val_loss did not improve from 1.71385\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6794 - mean_absolute_error: 0.9373 - mean_squared_error: 1.6794 - val_loss: 1.7141 - val_mean_absolute_error: 0.9459 - val_mean_squared_error: 1.7141\n",
            "Epoch 583/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.6770 - mean_absolute_error: 0.9381 - mean_squared_error: 1.6770\n",
            "Epoch 583: val_loss did not improve from 1.71385\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6784 - mean_absolute_error: 0.9373 - mean_squared_error: 1.6784 - val_loss: 1.7191 - val_mean_absolute_error: 0.9480 - val_mean_squared_error: 1.7191\n",
            "Epoch 584/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.6784 - mean_absolute_error: 0.9379 - mean_squared_error: 1.6784\n",
            "Epoch 584: val_loss improved from 1.71385 to 1.71202, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6784 - mean_absolute_error: 0.9379 - mean_squared_error: 1.6784 - val_loss: 1.7120 - val_mean_absolute_error: 0.9449 - val_mean_squared_error: 1.7120\n",
            "Epoch 585/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.6802 - mean_absolute_error: 0.9381 - mean_squared_error: 1.6802\n",
            "Epoch 585: val_loss improved from 1.71202 to 1.71147, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6766 - mean_absolute_error: 0.9370 - mean_squared_error: 1.6766 - val_loss: 1.7115 - val_mean_absolute_error: 0.9450 - val_mean_squared_error: 1.7115\n",
            "Epoch 586/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.6745 - mean_absolute_error: 0.9347 - mean_squared_error: 1.6745\n",
            "Epoch 586: val_loss did not improve from 1.71147\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6763 - mean_absolute_error: 0.9358 - mean_squared_error: 1.6763 - val_loss: 1.7214 - val_mean_absolute_error: 0.9493 - val_mean_squared_error: 1.7214\n",
            "Epoch 587/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.6797 - mean_absolute_error: 0.9389 - mean_squared_error: 1.6797\n",
            "Epoch 587: val_loss did not improve from 1.71147\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6763 - mean_absolute_error: 0.9375 - mean_squared_error: 1.6763 - val_loss: 1.7144 - val_mean_absolute_error: 0.9462 - val_mean_squared_error: 1.7144\n",
            "Epoch 588/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.6775 - mean_absolute_error: 0.9355 - mean_squared_error: 1.6775\n",
            "Epoch 588: val_loss did not improve from 1.71147\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6753 - mean_absolute_error: 0.9362 - mean_squared_error: 1.6753 - val_loss: 1.7127 - val_mean_absolute_error: 0.9452 - val_mean_squared_error: 1.7127\n",
            "Epoch 589/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.6837 - mean_absolute_error: 0.9377 - mean_squared_error: 1.6837\n",
            "Epoch 589: val_loss did not improve from 1.71147\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6755 - mean_absolute_error: 0.9358 - mean_squared_error: 1.6755 - val_loss: 1.7124 - val_mean_absolute_error: 0.9456 - val_mean_squared_error: 1.7124\n",
            "Epoch 590/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.6684 - mean_absolute_error: 0.9344 - mean_squared_error: 1.6684\n",
            "Epoch 590: val_loss did not improve from 1.71147\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6743 - mean_absolute_error: 0.9363 - mean_squared_error: 1.6743 - val_loss: 1.7115 - val_mean_absolute_error: 0.9451 - val_mean_squared_error: 1.7115\n",
            "Epoch 591/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.6787 - mean_absolute_error: 0.9355 - mean_squared_error: 1.6787\n",
            "Epoch 591: val_loss improved from 1.71147 to 1.70897, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6734 - mean_absolute_error: 0.9366 - mean_squared_error: 1.6734 - val_loss: 1.7090 - val_mean_absolute_error: 0.9441 - val_mean_squared_error: 1.7090\n",
            "Epoch 592/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.6794 - mean_absolute_error: 0.9373 - mean_squared_error: 1.6794\n",
            "Epoch 592: val_loss did not improve from 1.70897\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6730 - mean_absolute_error: 0.9357 - mean_squared_error: 1.6730 - val_loss: 1.7091 - val_mean_absolute_error: 0.9443 - val_mean_squared_error: 1.7091\n",
            "Epoch 593/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.6770 - mean_absolute_error: 0.9383 - mean_squared_error: 1.6770\n",
            "Epoch 593: val_loss improved from 1.70897 to 1.70836, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6725 - mean_absolute_error: 0.9357 - mean_squared_error: 1.6725 - val_loss: 1.7084 - val_mean_absolute_error: 0.9440 - val_mean_squared_error: 1.7084\n",
            "Epoch 594/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.6668 - mean_absolute_error: 0.9349 - mean_squared_error: 1.6668\n",
            "Epoch 594: val_loss did not improve from 1.70836\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6708 - mean_absolute_error: 0.9357 - mean_squared_error: 1.6708 - val_loss: 1.7084 - val_mean_absolute_error: 0.9440 - val_mean_squared_error: 1.7084\n",
            "Epoch 595/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.6734 - mean_absolute_error: 0.9357 - mean_squared_error: 1.6734\n",
            "Epoch 595: val_loss improved from 1.70836 to 1.70709, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6708 - mean_absolute_error: 0.9350 - mean_squared_error: 1.6708 - val_loss: 1.7071 - val_mean_absolute_error: 0.9431 - val_mean_squared_error: 1.7071\n",
            "Epoch 596/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.6631 - mean_absolute_error: 0.9311 - mean_squared_error: 1.6631\n",
            "Epoch 596: val_loss did not improve from 1.70709\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6702 - mean_absolute_error: 0.9349 - mean_squared_error: 1.6702 - val_loss: 1.7090 - val_mean_absolute_error: 0.9437 - val_mean_squared_error: 1.7090\n",
            "Epoch 597/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.6719 - mean_absolute_error: 0.9348 - mean_squared_error: 1.6719\n",
            "Epoch 597: val_loss did not improve from 1.70709\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6697 - mean_absolute_error: 0.9342 - mean_squared_error: 1.6697 - val_loss: 1.7142 - val_mean_absolute_error: 0.9457 - val_mean_squared_error: 1.7142\n",
            "Epoch 598/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.6739 - mean_absolute_error: 0.9359 - mean_squared_error: 1.6739\n",
            "Epoch 598: val_loss did not improve from 1.70709\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6689 - mean_absolute_error: 0.9350 - mean_squared_error: 1.6689 - val_loss: 1.7077 - val_mean_absolute_error: 0.9434 - val_mean_squared_error: 1.7077\n",
            "Epoch 599/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.6785 - mean_absolute_error: 0.9361 - mean_squared_error: 1.6785\n",
            "Epoch 599: val_loss improved from 1.70709 to 1.70687, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6682 - mean_absolute_error: 0.9349 - mean_squared_error: 1.6682 - val_loss: 1.7069 - val_mean_absolute_error: 0.9430 - val_mean_squared_error: 1.7069\n",
            "Epoch 600/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.6667 - mean_absolute_error: 0.9336 - mean_squared_error: 1.6667\n",
            "Epoch 600: val_loss improved from 1.70687 to 1.70555, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6678 - mean_absolute_error: 0.9339 - mean_squared_error: 1.6678 - val_loss: 1.7056 - val_mean_absolute_error: 0.9427 - val_mean_squared_error: 1.7056\n",
            "Epoch 601/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.6642 - mean_absolute_error: 0.9332 - mean_squared_error: 1.6642\n",
            "Epoch 601: val_loss did not improve from 1.70555\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6673 - mean_absolute_error: 0.9344 - mean_squared_error: 1.6673 - val_loss: 1.7063 - val_mean_absolute_error: 0.9429 - val_mean_squared_error: 1.7063\n",
            "Epoch 602/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.6726 - mean_absolute_error: 0.9351 - mean_squared_error: 1.6726\n",
            "Epoch 602: val_loss improved from 1.70555 to 1.70554, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6671 - mean_absolute_error: 0.9339 - mean_squared_error: 1.6671 - val_loss: 1.7055 - val_mean_absolute_error: 0.9424 - val_mean_squared_error: 1.7055\n",
            "Epoch 603/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.6585 - mean_absolute_error: 0.9318 - mean_squared_error: 1.6585\n",
            "Epoch 603: val_loss did not improve from 1.70554\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6665 - mean_absolute_error: 0.9338 - mean_squared_error: 1.6665 - val_loss: 1.7056 - val_mean_absolute_error: 0.9424 - val_mean_squared_error: 1.7056\n",
            "Epoch 604/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.6369 - mean_absolute_error: 0.9257 - mean_squared_error: 1.6369\n",
            "Epoch 604: val_loss did not improve from 1.70554\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6660 - mean_absolute_error: 0.9338 - mean_squared_error: 1.6660 - val_loss: 1.7087 - val_mean_absolute_error: 0.9434 - val_mean_squared_error: 1.7087\n",
            "Epoch 605/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.6598 - mean_absolute_error: 0.9324 - mean_squared_error: 1.6598\n",
            "Epoch 605: val_loss improved from 1.70554 to 1.70270, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6650 - mean_absolute_error: 0.9334 - mean_squared_error: 1.6650 - val_loss: 1.7027 - val_mean_absolute_error: 0.9415 - val_mean_squared_error: 1.7027\n",
            "Epoch 606/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.6690 - mean_absolute_error: 0.9377 - mean_squared_error: 1.6690\n",
            "Epoch 606: val_loss did not improve from 1.70270\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6635 - mean_absolute_error: 0.9342 - mean_squared_error: 1.6635 - val_loss: 1.7051 - val_mean_absolute_error: 0.9426 - val_mean_squared_error: 1.7051\n",
            "Epoch 607/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.6680 - mean_absolute_error: 0.9349 - mean_squared_error: 1.6680\n",
            "Epoch 607: val_loss did not improve from 1.70270\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6640 - mean_absolute_error: 0.9334 - mean_squared_error: 1.6640 - val_loss: 1.7033 - val_mean_absolute_error: 0.9419 - val_mean_squared_error: 1.7033\n",
            "Epoch 608/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.6689 - mean_absolute_error: 0.9349 - mean_squared_error: 1.6689\n",
            "Epoch 608: val_loss improved from 1.70270 to 1.70167, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6636 - mean_absolute_error: 0.9331 - mean_squared_error: 1.6636 - val_loss: 1.7017 - val_mean_absolute_error: 0.9413 - val_mean_squared_error: 1.7017\n",
            "Epoch 609/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.6535 - mean_absolute_error: 0.9289 - mean_squared_error: 1.6535\n",
            "Epoch 609: val_loss improved from 1.70167 to 1.70138, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6624 - mean_absolute_error: 0.9329 - mean_squared_error: 1.6624 - val_loss: 1.7014 - val_mean_absolute_error: 0.9412 - val_mean_squared_error: 1.7014\n",
            "Epoch 610/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.6629 - mean_absolute_error: 0.9323 - mean_squared_error: 1.6629\n",
            "Epoch 610: val_loss improved from 1.70138 to 1.69991, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6620 - mean_absolute_error: 0.9337 - mean_squared_error: 1.6620 - val_loss: 1.6999 - val_mean_absolute_error: 0.9399 - val_mean_squared_error: 1.6999\n",
            "Epoch 611/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.6358 - mean_absolute_error: 0.9257 - mean_squared_error: 1.6358\n",
            "Epoch 611: val_loss did not improve from 1.69991\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6626 - mean_absolute_error: 0.9326 - mean_squared_error: 1.6626 - val_loss: 1.7021 - val_mean_absolute_error: 0.9409 - val_mean_squared_error: 1.7021\n",
            "Epoch 612/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.6558 - mean_absolute_error: 0.9310 - mean_squared_error: 1.6558\n",
            "Epoch 612: val_loss did not improve from 1.69991\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6597 - mean_absolute_error: 0.9322 - mean_squared_error: 1.6597 - val_loss: 1.6999 - val_mean_absolute_error: 0.9408 - val_mean_squared_error: 1.6999\n",
            "Epoch 613/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.6740 - mean_absolute_error: 0.9366 - mean_squared_error: 1.6740\n",
            "Epoch 613: val_loss improved from 1.69991 to 1.69945, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6608 - mean_absolute_error: 0.9324 - mean_squared_error: 1.6608 - val_loss: 1.6995 - val_mean_absolute_error: 0.9403 - val_mean_squared_error: 1.6995\n",
            "Epoch 614/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.6659 - mean_absolute_error: 0.9319 - mean_squared_error: 1.6659\n",
            "Epoch 614: val_loss improved from 1.69945 to 1.69895, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6594 - mean_absolute_error: 0.9322 - mean_squared_error: 1.6594 - val_loss: 1.6989 - val_mean_absolute_error: 0.9406 - val_mean_squared_error: 1.6989\n",
            "Epoch 615/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.6417 - mean_absolute_error: 0.9264 - mean_squared_error: 1.6417\n",
            "Epoch 615: val_loss did not improve from 1.69895\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6598 - mean_absolute_error: 0.9314 - mean_squared_error: 1.6598 - val_loss: 1.7016 - val_mean_absolute_error: 0.9409 - val_mean_squared_error: 1.7016\n",
            "Epoch 616/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.6546 - mean_absolute_error: 0.9322 - mean_squared_error: 1.6546\n",
            "Epoch 616: val_loss improved from 1.69895 to 1.69808, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6582 - mean_absolute_error: 0.9311 - mean_squared_error: 1.6582 - val_loss: 1.6981 - val_mean_absolute_error: 0.9400 - val_mean_squared_error: 1.6981\n",
            "Epoch 617/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.6718 - mean_absolute_error: 0.9367 - mean_squared_error: 1.6718\n",
            "Epoch 617: val_loss improved from 1.69808 to 1.69735, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6568 - mean_absolute_error: 0.9315 - mean_squared_error: 1.6568 - val_loss: 1.6974 - val_mean_absolute_error: 0.9397 - val_mean_squared_error: 1.6974\n",
            "Epoch 618/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.6626 - mean_absolute_error: 0.9323 - mean_squared_error: 1.6626\n",
            "Epoch 618: val_loss did not improve from 1.69735\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6571 - mean_absolute_error: 0.9308 - mean_squared_error: 1.6571 - val_loss: 1.6985 - val_mean_absolute_error: 0.9398 - val_mean_squared_error: 1.6985\n",
            "Epoch 619/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.6558 - mean_absolute_error: 0.9304 - mean_squared_error: 1.6558\n",
            "Epoch 619: val_loss improved from 1.69735 to 1.69670, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6562 - mean_absolute_error: 0.9305 - mean_squared_error: 1.6562 - val_loss: 1.6967 - val_mean_absolute_error: 0.9396 - val_mean_squared_error: 1.6967\n",
            "Epoch 620/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.6553 - mean_absolute_error: 0.9322 - mean_squared_error: 1.6553\n",
            "Epoch 620: val_loss improved from 1.69670 to 1.69589, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6553 - mean_absolute_error: 0.9322 - mean_squared_error: 1.6553 - val_loss: 1.6959 - val_mean_absolute_error: 0.9391 - val_mean_squared_error: 1.6959\n",
            "Epoch 621/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.6552 - mean_absolute_error: 0.9311 - mean_squared_error: 1.6552\n",
            "Epoch 621: val_loss did not improve from 1.69589\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6558 - mean_absolute_error: 0.9294 - mean_squared_error: 1.6558 - val_loss: 1.6979 - val_mean_absolute_error: 0.9392 - val_mean_squared_error: 1.6979\n",
            "Epoch 622/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.6574 - mean_absolute_error: 0.9311 - mean_squared_error: 1.6574\n",
            "Epoch 622: val_loss did not improve from 1.69589\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6545 - mean_absolute_error: 0.9301 - mean_squared_error: 1.6545 - val_loss: 1.6965 - val_mean_absolute_error: 0.9387 - val_mean_squared_error: 1.6965\n",
            "Epoch 623/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.6551 - mean_absolute_error: 0.9290 - mean_squared_error: 1.6551\n",
            "Epoch 623: val_loss did not improve from 1.69589\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6505 - mean_absolute_error: 0.9306 - mean_squared_error: 1.6505 - val_loss: 1.6962 - val_mean_absolute_error: 0.9402 - val_mean_squared_error: 1.6962\n",
            "Epoch 624/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.6481 - mean_absolute_error: 0.9271 - mean_squared_error: 1.6481\n",
            "Epoch 624: val_loss improved from 1.69589 to 1.69404, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6532 - mean_absolute_error: 0.9296 - mean_squared_error: 1.6532 - val_loss: 1.6940 - val_mean_absolute_error: 0.9379 - val_mean_squared_error: 1.6940\n",
            "Epoch 625/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.6441 - mean_absolute_error: 0.9261 - mean_squared_error: 1.6441\n",
            "Epoch 625: val_loss improved from 1.69404 to 1.69368, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6526 - mean_absolute_error: 0.9299 - mean_squared_error: 1.6526 - val_loss: 1.6937 - val_mean_absolute_error: 0.9373 - val_mean_squared_error: 1.6937\n",
            "Epoch 626/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.6547 - mean_absolute_error: 0.9300 - mean_squared_error: 1.6547\n",
            "Epoch 626: val_loss improved from 1.69368 to 1.69346, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6514 - mean_absolute_error: 0.9292 - mean_squared_error: 1.6514 - val_loss: 1.6935 - val_mean_absolute_error: 0.9376 - val_mean_squared_error: 1.6935\n",
            "Epoch 627/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.6397 - mean_absolute_error: 0.9253 - mean_squared_error: 1.6397\n",
            "Epoch 627: val_loss improved from 1.69346 to 1.69247, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6504 - mean_absolute_error: 0.9292 - mean_squared_error: 1.6504 - val_loss: 1.6925 - val_mean_absolute_error: 0.9376 - val_mean_squared_error: 1.6925\n",
            "Epoch 628/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.6535 - mean_absolute_error: 0.9293 - mean_squared_error: 1.6535\n",
            "Epoch 628: val_loss improved from 1.69247 to 1.69245, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6503 - mean_absolute_error: 0.9291 - mean_squared_error: 1.6503 - val_loss: 1.6924 - val_mean_absolute_error: 0.9374 - val_mean_squared_error: 1.6924\n",
            "Epoch 629/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.6413 - mean_absolute_error: 0.9266 - mean_squared_error: 1.6413\n",
            "Epoch 629: val_loss did not improve from 1.69245\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6499 - mean_absolute_error: 0.9285 - mean_squared_error: 1.6499 - val_loss: 1.7034 - val_mean_absolute_error: 0.9411 - val_mean_squared_error: 1.7034\n",
            "Epoch 630/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.6566 - mean_absolute_error: 0.9302 - mean_squared_error: 1.6566\n",
            "Epoch 630: val_loss did not improve from 1.69245\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6486 - mean_absolute_error: 0.9291 - mean_squared_error: 1.6486 - val_loss: 1.6966 - val_mean_absolute_error: 0.9382 - val_mean_squared_error: 1.6966\n",
            "Epoch 631/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.6553 - mean_absolute_error: 0.9306 - mean_squared_error: 1.6553\n",
            "Epoch 631: val_loss improved from 1.69245 to 1.69057, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6483 - mean_absolute_error: 0.9291 - mean_squared_error: 1.6483 - val_loss: 1.6906 - val_mean_absolute_error: 0.9370 - val_mean_squared_error: 1.6906\n",
            "Epoch 632/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.6637 - mean_absolute_error: 0.9342 - mean_squared_error: 1.6637\n",
            "Epoch 632: val_loss did not improve from 1.69057\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6484 - mean_absolute_error: 0.9288 - mean_squared_error: 1.6484 - val_loss: 1.6922 - val_mean_absolute_error: 0.9369 - val_mean_squared_error: 1.6922\n",
            "Epoch 633/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.6447 - mean_absolute_error: 0.9275 - mean_squared_error: 1.6447\n",
            "Epoch 633: val_loss improved from 1.69057 to 1.68995, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6486 - mean_absolute_error: 0.9288 - mean_squared_error: 1.6486 - val_loss: 1.6900 - val_mean_absolute_error: 0.9363 - val_mean_squared_error: 1.6900\n",
            "Epoch 634/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.6423 - mean_absolute_error: 0.9263 - mean_squared_error: 1.6423\n",
            "Epoch 634: val_loss improved from 1.68995 to 1.68948, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6462 - mean_absolute_error: 0.9275 - mean_squared_error: 1.6462 - val_loss: 1.6895 - val_mean_absolute_error: 0.9359 - val_mean_squared_error: 1.6895\n",
            "Epoch 635/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.6465 - mean_absolute_error: 0.9276 - mean_squared_error: 1.6465\n",
            "Epoch 635: val_loss improved from 1.68948 to 1.68931, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6464 - mean_absolute_error: 0.9277 - mean_squared_error: 1.6464 - val_loss: 1.6893 - val_mean_absolute_error: 0.9359 - val_mean_squared_error: 1.6893\n",
            "Epoch 636/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.6465 - mean_absolute_error: 0.9278 - mean_squared_error: 1.6465\n",
            "Epoch 636: val_loss did not improve from 1.68931\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6465 - mean_absolute_error: 0.9278 - mean_squared_error: 1.6465 - val_loss: 1.6931 - val_mean_absolute_error: 0.9367 - val_mean_squared_error: 1.6931\n",
            "Epoch 637/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.6288 - mean_absolute_error: 0.9245 - mean_squared_error: 1.6288\n",
            "Epoch 637: val_loss improved from 1.68931 to 1.68769, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6456 - mean_absolute_error: 0.9273 - mean_squared_error: 1.6456 - val_loss: 1.6877 - val_mean_absolute_error: 0.9348 - val_mean_squared_error: 1.6877\n",
            "Epoch 638/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.6562 - mean_absolute_error: 0.9290 - mean_squared_error: 1.6562\n",
            "Epoch 638: val_loss did not improve from 1.68769\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.6441 - mean_absolute_error: 0.9272 - mean_squared_error: 1.6441 - val_loss: 1.6893 - val_mean_absolute_error: 0.9356 - val_mean_squared_error: 1.6893\n",
            "Epoch 639/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.6444 - mean_absolute_error: 0.9271 - mean_squared_error: 1.6444\n",
            "Epoch 639: val_loss did not improve from 1.68769\n",
            "245/245 [==============================] - 2s 8ms/step - loss: 1.6444 - mean_absolute_error: 0.9270 - mean_squared_error: 1.6444 - val_loss: 1.6877 - val_mean_absolute_error: 0.9351 - val_mean_squared_error: 1.6877\n",
            "Epoch 640/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.6429 - mean_absolute_error: 0.9266 - mean_squared_error: 1.6429\n",
            "Epoch 640: val_loss did not improve from 1.68769\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6429 - mean_absolute_error: 0.9266 - mean_squared_error: 1.6429 - val_loss: 1.6902 - val_mean_absolute_error: 0.9356 - val_mean_squared_error: 1.6902\n",
            "Epoch 641/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.6456 - mean_absolute_error: 0.9261 - mean_squared_error: 1.6456\n",
            "Epoch 641: val_loss improved from 1.68769 to 1.68615, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6418 - mean_absolute_error: 0.9262 - mean_squared_error: 1.6418 - val_loss: 1.6861 - val_mean_absolute_error: 0.9347 - val_mean_squared_error: 1.6861\n",
            "Epoch 642/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.6510 - mean_absolute_error: 0.9295 - mean_squared_error: 1.6510\n",
            "Epoch 642: val_loss did not improve from 1.68615\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6413 - mean_absolute_error: 0.9260 - mean_squared_error: 1.6413 - val_loss: 1.6870 - val_mean_absolute_error: 0.9349 - val_mean_squared_error: 1.6870\n",
            "Epoch 643/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.6358 - mean_absolute_error: 0.9236 - mean_squared_error: 1.6358\n",
            "Epoch 643: val_loss improved from 1.68615 to 1.68593, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6403 - mean_absolute_error: 0.9257 - mean_squared_error: 1.6403 - val_loss: 1.6859 - val_mean_absolute_error: 0.9343 - val_mean_squared_error: 1.6859\n",
            "Epoch 644/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.6387 - mean_absolute_error: 0.9261 - mean_squared_error: 1.6387\n",
            "Epoch 644: val_loss improved from 1.68593 to 1.68426, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6387 - mean_absolute_error: 0.9261 - mean_squared_error: 1.6387 - val_loss: 1.6843 - val_mean_absolute_error: 0.9351 - val_mean_squared_error: 1.6843\n",
            "Epoch 645/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.6297 - mean_absolute_error: 0.9219 - mean_squared_error: 1.6297\n",
            "Epoch 645: val_loss did not improve from 1.68426\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6385 - mean_absolute_error: 0.9251 - mean_squared_error: 1.6385 - val_loss: 1.6854 - val_mean_absolute_error: 0.9335 - val_mean_squared_error: 1.6854\n",
            "Epoch 646/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.6398 - mean_absolute_error: 0.9255 - mean_squared_error: 1.6398\n",
            "Epoch 646: val_loss improved from 1.68426 to 1.68318, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6385 - mean_absolute_error: 0.9251 - mean_squared_error: 1.6385 - val_loss: 1.6832 - val_mean_absolute_error: 0.9336 - val_mean_squared_error: 1.6832\n",
            "Epoch 647/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.6373 - mean_absolute_error: 0.9260 - mean_squared_error: 1.6373\n",
            "Epoch 647: val_loss improved from 1.68318 to 1.68310, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6369 - mean_absolute_error: 0.9249 - mean_squared_error: 1.6369 - val_loss: 1.6831 - val_mean_absolute_error: 0.9333 - val_mean_squared_error: 1.6831\n",
            "Epoch 648/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.6414 - mean_absolute_error: 0.9282 - mean_squared_error: 1.6414\n",
            "Epoch 648: val_loss did not improve from 1.68310\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6371 - mean_absolute_error: 0.9254 - mean_squared_error: 1.6371 - val_loss: 1.6831 - val_mean_absolute_error: 0.9329 - val_mean_squared_error: 1.6831\n",
            "Epoch 649/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.6359 - mean_absolute_error: 0.9214 - mean_squared_error: 1.6359\n",
            "Epoch 649: val_loss did not improve from 1.68310\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6375 - mean_absolute_error: 0.9247 - mean_squared_error: 1.6375 - val_loss: 1.6861 - val_mean_absolute_error: 0.9343 - val_mean_squared_error: 1.6861\n",
            "Epoch 650/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.6320 - mean_absolute_error: 0.9233 - mean_squared_error: 1.6320\n",
            "Epoch 650: val_loss improved from 1.68310 to 1.68229, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6345 - mean_absolute_error: 0.9243 - mean_squared_error: 1.6345 - val_loss: 1.6823 - val_mean_absolute_error: 0.9350 - val_mean_squared_error: 1.6823\n",
            "Epoch 651/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.6336 - mean_absolute_error: 0.9236 - mean_squared_error: 1.6336\n",
            "Epoch 651: val_loss did not improve from 1.68229\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6369 - mean_absolute_error: 0.9247 - mean_squared_error: 1.6369 - val_loss: 1.6834 - val_mean_absolute_error: 0.9332 - val_mean_squared_error: 1.6834\n",
            "Epoch 652/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.6407 - mean_absolute_error: 0.9273 - mean_squared_error: 1.6407\n",
            "Epoch 652: val_loss did not improve from 1.68229\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6343 - mean_absolute_error: 0.9242 - mean_squared_error: 1.6343 - val_loss: 1.6856 - val_mean_absolute_error: 0.9344 - val_mean_squared_error: 1.6856\n",
            "Epoch 653/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.6276 - mean_absolute_error: 0.9222 - mean_squared_error: 1.6276\n",
            "Epoch 653: val_loss improved from 1.68229 to 1.67981, saving model to best_model3.h5\n",
            "245/245 [==============================] - 2s 7ms/step - loss: 1.6332 - mean_absolute_error: 0.9236 - mean_squared_error: 1.6332 - val_loss: 1.6798 - val_mean_absolute_error: 0.9330 - val_mean_squared_error: 1.6798\n",
            "Epoch 654/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.6358 - mean_absolute_error: 0.9241 - mean_squared_error: 1.6358\n",
            "Epoch 654: val_loss did not improve from 1.67981\n",
            "245/245 [==============================] - 2s 8ms/step - loss: 1.6341 - mean_absolute_error: 0.9242 - mean_squared_error: 1.6341 - val_loss: 1.6800 - val_mean_absolute_error: 0.9322 - val_mean_squared_error: 1.6800\n",
            "Epoch 655/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.6189 - mean_absolute_error: 0.9202 - mean_squared_error: 1.6189\n",
            "Epoch 655: val_loss improved from 1.67981 to 1.67980, saving model to best_model3.h5\n",
            "245/245 [==============================] - 2s 10ms/step - loss: 1.6320 - mean_absolute_error: 0.9232 - mean_squared_error: 1.6320 - val_loss: 1.6798 - val_mean_absolute_error: 0.9317 - val_mean_squared_error: 1.6798\n",
            "Epoch 656/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.6314 - mean_absolute_error: 0.9229 - mean_squared_error: 1.6314\n",
            "Epoch 656: val_loss did not improve from 1.67980\n",
            "245/245 [==============================] - 4s 16ms/step - loss: 1.6314 - mean_absolute_error: 0.9229 - mean_squared_error: 1.6314 - val_loss: 1.6818 - val_mean_absolute_error: 0.9327 - val_mean_squared_error: 1.6818\n",
            "Epoch 657/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.6337 - mean_absolute_error: 0.9245 - mean_squared_error: 1.6337\n",
            "Epoch 657: val_loss did not improve from 1.67980\n",
            "245/245 [==============================] - 3s 12ms/step - loss: 1.6306 - mean_absolute_error: 0.9229 - mean_squared_error: 1.6306 - val_loss: 1.6803 - val_mean_absolute_error: 0.9320 - val_mean_squared_error: 1.6803\n",
            "Epoch 658/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.6382 - mean_absolute_error: 0.9246 - mean_squared_error: 1.6382\n",
            "Epoch 658: val_loss improved from 1.67980 to 1.67905, saving model to best_model3.h5\n",
            "245/245 [==============================] - 2s 9ms/step - loss: 1.6309 - mean_absolute_error: 0.9233 - mean_squared_error: 1.6309 - val_loss: 1.6790 - val_mean_absolute_error: 0.9312 - val_mean_squared_error: 1.6790\n",
            "Epoch 659/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.6260 - mean_absolute_error: 0.9223 - mean_squared_error: 1.6260\n",
            "Epoch 659: val_loss improved from 1.67905 to 1.67803, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6294 - mean_absolute_error: 0.9221 - mean_squared_error: 1.6294 - val_loss: 1.6780 - val_mean_absolute_error: 0.9308 - val_mean_squared_error: 1.6780\n",
            "Epoch 660/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.6366 - mean_absolute_error: 0.9233 - mean_squared_error: 1.6366\n",
            "Epoch 660: val_loss did not improve from 1.67803\n",
            "245/245 [==============================] - 2s 7ms/step - loss: 1.6283 - mean_absolute_error: 0.9218 - mean_squared_error: 1.6283 - val_loss: 1.6813 - val_mean_absolute_error: 0.9323 - val_mean_squared_error: 1.6813\n",
            "Epoch 661/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.6310 - mean_absolute_error: 0.9224 - mean_squared_error: 1.6310\n",
            "Epoch 661: val_loss improved from 1.67803 to 1.67625, saving model to best_model3.h5\n",
            "245/245 [==============================] - 2s 7ms/step - loss: 1.6289 - mean_absolute_error: 0.9226 - mean_squared_error: 1.6289 - val_loss: 1.6762 - val_mean_absolute_error: 0.9308 - val_mean_squared_error: 1.6762\n",
            "Epoch 662/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.6365 - mean_absolute_error: 0.9255 - mean_squared_error: 1.6365\n",
            "Epoch 662: val_loss improved from 1.67625 to 1.67495, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6283 - mean_absolute_error: 0.9226 - mean_squared_error: 1.6283 - val_loss: 1.6750 - val_mean_absolute_error: 0.9314 - val_mean_squared_error: 1.6750\n",
            "Epoch 663/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.6079 - mean_absolute_error: 0.9160 - mean_squared_error: 1.6079\n",
            "Epoch 663: val_loss did not improve from 1.67495\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6273 - mean_absolute_error: 0.9220 - mean_squared_error: 1.6273 - val_loss: 1.6750 - val_mean_absolute_error: 0.9299 - val_mean_squared_error: 1.6750\n",
            "Epoch 664/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.6378 - mean_absolute_error: 0.9239 - mean_squared_error: 1.6378\n",
            "Epoch 664: val_loss improved from 1.67495 to 1.67409, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6260 - mean_absolute_error: 0.9212 - mean_squared_error: 1.6260 - val_loss: 1.6741 - val_mean_absolute_error: 0.9298 - val_mean_squared_error: 1.6741\n",
            "Epoch 665/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.6287 - mean_absolute_error: 0.9232 - mean_squared_error: 1.6287\n",
            "Epoch 665: val_loss improved from 1.67409 to 1.67355, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6248 - mean_absolute_error: 0.9209 - mean_squared_error: 1.6248 - val_loss: 1.6736 - val_mean_absolute_error: 0.9294 - val_mean_squared_error: 1.6736\n",
            "Epoch 666/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.6210 - mean_absolute_error: 0.9201 - mean_squared_error: 1.6210\n",
            "Epoch 666: val_loss improved from 1.67355 to 1.67281, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6248 - mean_absolute_error: 0.9213 - mean_squared_error: 1.6248 - val_loss: 1.6728 - val_mean_absolute_error: 0.9294 - val_mean_squared_error: 1.6728\n",
            "Epoch 667/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.6232 - mean_absolute_error: 0.9210 - mean_squared_error: 1.6232\n",
            "Epoch 667: val_loss did not improve from 1.67281\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6246 - mean_absolute_error: 0.9201 - mean_squared_error: 1.6246 - val_loss: 1.6771 - val_mean_absolute_error: 0.9306 - val_mean_squared_error: 1.6771\n",
            "Epoch 668/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.6314 - mean_absolute_error: 0.9229 - mean_squared_error: 1.6314\n",
            "Epoch 668: val_loss did not improve from 1.67281\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6239 - mean_absolute_error: 0.9207 - mean_squared_error: 1.6239 - val_loss: 1.6731 - val_mean_absolute_error: 0.9296 - val_mean_squared_error: 1.6731\n",
            "Epoch 669/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.6228 - mean_absolute_error: 0.9203 - mean_squared_error: 1.6228\n",
            "Epoch 669: val_loss improved from 1.67281 to 1.67109, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6228 - mean_absolute_error: 0.9203 - mean_squared_error: 1.6228 - val_loss: 1.6711 - val_mean_absolute_error: 0.9288 - val_mean_squared_error: 1.6711\n",
            "Epoch 670/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.6296 - mean_absolute_error: 0.9240 - mean_squared_error: 1.6296\n",
            "Epoch 670: val_loss did not improve from 1.67109\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6206 - mean_absolute_error: 0.9196 - mean_squared_error: 1.6206 - val_loss: 1.6779 - val_mean_absolute_error: 0.9300 - val_mean_squared_error: 1.6779\n",
            "Epoch 671/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.6052 - mean_absolute_error: 0.9172 - mean_squared_error: 1.6052\n",
            "Epoch 671: val_loss improved from 1.67109 to 1.66963, saving model to best_model3.h5\n",
            "245/245 [==============================] - 2s 8ms/step - loss: 1.6220 - mean_absolute_error: 0.9202 - mean_squared_error: 1.6220 - val_loss: 1.6696 - val_mean_absolute_error: 0.9288 - val_mean_squared_error: 1.6696\n",
            "Epoch 672/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.6355 - mean_absolute_error: 0.9246 - mean_squared_error: 1.6355\n",
            "Epoch 672: val_loss improved from 1.66963 to 1.66926, saving model to best_model3.h5\n",
            "245/245 [==============================] - 2s 6ms/step - loss: 1.6202 - mean_absolute_error: 0.9203 - mean_squared_error: 1.6202 - val_loss: 1.6693 - val_mean_absolute_error: 0.9286 - val_mean_squared_error: 1.6693\n",
            "Epoch 673/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.6120 - mean_absolute_error: 0.9182 - mean_squared_error: 1.6120\n",
            "Epoch 673: val_loss did not improve from 1.66926\n",
            "245/245 [==============================] - 2s 8ms/step - loss: 1.6200 - mean_absolute_error: 0.9198 - mean_squared_error: 1.6200 - val_loss: 1.6716 - val_mean_absolute_error: 0.9282 - val_mean_squared_error: 1.6716\n",
            "Epoch 674/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.6198 - mean_absolute_error: 0.9196 - mean_squared_error: 1.6198\n",
            "Epoch 674: val_loss did not improve from 1.66926\n",
            "245/245 [==============================] - 1s 6ms/step - loss: 1.6191 - mean_absolute_error: 0.9195 - mean_squared_error: 1.6191 - val_loss: 1.6703 - val_mean_absolute_error: 0.9281 - val_mean_squared_error: 1.6703\n",
            "Epoch 675/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.6177 - mean_absolute_error: 0.9190 - mean_squared_error: 1.6177\n",
            "Epoch 675: val_loss did not improve from 1.66926\n",
            "245/245 [==============================] - 4s 16ms/step - loss: 1.6181 - mean_absolute_error: 0.9191 - mean_squared_error: 1.6181 - val_loss: 1.6731 - val_mean_absolute_error: 0.9286 - val_mean_squared_error: 1.6731\n",
            "Epoch 676/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.6244 - mean_absolute_error: 0.9195 - mean_squared_error: 1.6244\n",
            "Epoch 676: val_loss did not improve from 1.66926\n",
            "245/245 [==============================] - 2s 7ms/step - loss: 1.6182 - mean_absolute_error: 0.9188 - mean_squared_error: 1.6182 - val_loss: 1.6720 - val_mean_absolute_error: 0.9287 - val_mean_squared_error: 1.6720\n",
            "Epoch 677/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.6187 - mean_absolute_error: 0.9205 - mean_squared_error: 1.6187\n",
            "Epoch 677: val_loss improved from 1.66926 to 1.66900, saving model to best_model3.h5\n",
            "245/245 [==============================] - 2s 6ms/step - loss: 1.6169 - mean_absolute_error: 0.9193 - mean_squared_error: 1.6169 - val_loss: 1.6690 - val_mean_absolute_error: 0.9274 - val_mean_squared_error: 1.6690\n",
            "Epoch 678/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.6131 - mean_absolute_error: 0.9178 - mean_squared_error: 1.6131\n",
            "Epoch 678: val_loss improved from 1.66900 to 1.66562, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6152 - mean_absolute_error: 0.9185 - mean_squared_error: 1.6152 - val_loss: 1.6656 - val_mean_absolute_error: 0.9280 - val_mean_squared_error: 1.6656\n",
            "Epoch 679/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.6126 - mean_absolute_error: 0.9182 - mean_squared_error: 1.6126\n",
            "Epoch 679: val_loss did not improve from 1.66562\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6157 - mean_absolute_error: 0.9186 - mean_squared_error: 1.6157 - val_loss: 1.6684 - val_mean_absolute_error: 0.9269 - val_mean_squared_error: 1.6684\n",
            "Epoch 680/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.6205 - mean_absolute_error: 0.9200 - mean_squared_error: 1.6205\n",
            "Epoch 680: val_loss did not improve from 1.66562\n",
            "245/245 [==============================] - 2s 7ms/step - loss: 1.6137 - mean_absolute_error: 0.9184 - mean_squared_error: 1.6137 - val_loss: 1.6780 - val_mean_absolute_error: 0.9305 - val_mean_squared_error: 1.6780\n",
            "Epoch 681/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.6098 - mean_absolute_error: 0.9185 - mean_squared_error: 1.6098\n",
            "Epoch 681: val_loss improved from 1.66562 to 1.66536, saving model to best_model3.h5\n",
            "245/245 [==============================] - 2s 8ms/step - loss: 1.6158 - mean_absolute_error: 0.9190 - mean_squared_error: 1.6158 - val_loss: 1.6654 - val_mean_absolute_error: 0.9266 - val_mean_squared_error: 1.6654\n",
            "Epoch 682/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.6250 - mean_absolute_error: 0.9215 - mean_squared_error: 1.6250\n",
            "Epoch 682: val_loss improved from 1.66536 to 1.66380, saving model to best_model3.h5\n",
            "245/245 [==============================] - 3s 10ms/step - loss: 1.6135 - mean_absolute_error: 0.9175 - mean_squared_error: 1.6135 - val_loss: 1.6638 - val_mean_absolute_error: 0.9259 - val_mean_squared_error: 1.6638\n",
            "Epoch 683/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.6168 - mean_absolute_error: 0.9184 - mean_squared_error: 1.6168\n",
            "Epoch 683: val_loss did not improve from 1.66380\n",
            "245/245 [==============================] - 2s 9ms/step - loss: 1.6131 - mean_absolute_error: 0.9175 - mean_squared_error: 1.6131 - val_loss: 1.6640 - val_mean_absolute_error: 0.9261 - val_mean_squared_error: 1.6640\n",
            "Epoch 684/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.6100 - mean_absolute_error: 0.9166 - mean_squared_error: 1.6100\n",
            "Epoch 684: val_loss improved from 1.66380 to 1.66290, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.6117 - mean_absolute_error: 0.9173 - mean_squared_error: 1.6117 - val_loss: 1.6629 - val_mean_absolute_error: 0.9272 - val_mean_squared_error: 1.6629\n",
            "Epoch 685/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.6118 - mean_absolute_error: 0.9173 - mean_squared_error: 1.6118\n",
            "Epoch 685: val_loss improved from 1.66290 to 1.66219, saving model to best_model3.h5\n",
            "245/245 [==============================] - 3s 12ms/step - loss: 1.6118 - mean_absolute_error: 0.9173 - mean_squared_error: 1.6118 - val_loss: 1.6622 - val_mean_absolute_error: 0.9257 - val_mean_squared_error: 1.6622\n",
            "Epoch 686/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.6067 - mean_absolute_error: 0.9152 - mean_squared_error: 1.6067\n",
            "Epoch 686: val_loss did not improve from 1.66219\n",
            "245/245 [==============================] - 2s 8ms/step - loss: 1.6101 - mean_absolute_error: 0.9167 - mean_squared_error: 1.6101 - val_loss: 1.6678 - val_mean_absolute_error: 0.9264 - val_mean_squared_error: 1.6678\n",
            "Epoch 687/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.6097 - mean_absolute_error: 0.9169 - mean_squared_error: 1.6097\n",
            "Epoch 687: val_loss improved from 1.66219 to 1.66183, saving model to best_model3.h5\n",
            "245/245 [==============================] - 2s 9ms/step - loss: 1.6097 - mean_absolute_error: 0.9169 - mean_squared_error: 1.6097 - val_loss: 1.6618 - val_mean_absolute_error: 0.9276 - val_mean_squared_error: 1.6618\n",
            "Epoch 688/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.6092 - mean_absolute_error: 0.9157 - mean_squared_error: 1.6092\n",
            "Epoch 688: val_loss improved from 1.66183 to 1.66006, saving model to best_model3.h5\n",
            "245/245 [==============================] - 2s 9ms/step - loss: 1.6092 - mean_absolute_error: 0.9157 - mean_squared_error: 1.6092 - val_loss: 1.6601 - val_mean_absolute_error: 0.9257 - val_mean_squared_error: 1.6601\n",
            "Epoch 689/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.6103 - mean_absolute_error: 0.9158 - mean_squared_error: 1.6103\n",
            "Epoch 689: val_loss did not improve from 1.66006\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6089 - mean_absolute_error: 0.9160 - mean_squared_error: 1.6089 - val_loss: 1.6619 - val_mean_absolute_error: 0.9253 - val_mean_squared_error: 1.6619\n",
            "Epoch 690/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.6137 - mean_absolute_error: 0.9182 - mean_squared_error: 1.6137\n",
            "Epoch 690: val_loss improved from 1.66006 to 1.65987, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6076 - mean_absolute_error: 0.9164 - mean_squared_error: 1.6076 - val_loss: 1.6599 - val_mean_absolute_error: 0.9244 - val_mean_squared_error: 1.6599\n",
            "Epoch 691/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.5982 - mean_absolute_error: 0.9140 - mean_squared_error: 1.5982\n",
            "Epoch 691: val_loss improved from 1.65987 to 1.65854, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6079 - mean_absolute_error: 0.9165 - mean_squared_error: 1.6079 - val_loss: 1.6585 - val_mean_absolute_error: 0.9243 - val_mean_squared_error: 1.6585\n",
            "Epoch 692/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.6089 - mean_absolute_error: 0.9148 - mean_squared_error: 1.6089\n",
            "Epoch 692: val_loss improved from 1.65854 to 1.65814, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6070 - mean_absolute_error: 0.9152 - mean_squared_error: 1.6070 - val_loss: 1.6581 - val_mean_absolute_error: 0.9253 - val_mean_squared_error: 1.6581\n",
            "Epoch 693/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.6090 - mean_absolute_error: 0.9164 - mean_squared_error: 1.6090\n",
            "Epoch 693: val_loss improved from 1.65814 to 1.65746, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6064 - mean_absolute_error: 0.9157 - mean_squared_error: 1.6064 - val_loss: 1.6575 - val_mean_absolute_error: 0.9246 - val_mean_squared_error: 1.6575\n",
            "Epoch 694/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.6013 - mean_absolute_error: 0.9141 - mean_squared_error: 1.6013\n",
            "Epoch 694: val_loss improved from 1.65746 to 1.65728, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6056 - mean_absolute_error: 0.9149 - mean_squared_error: 1.6056 - val_loss: 1.6573 - val_mean_absolute_error: 0.9250 - val_mean_squared_error: 1.6573\n",
            "Epoch 695/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.6049 - mean_absolute_error: 0.9153 - mean_squared_error: 1.6049\n",
            "Epoch 695: val_loss did not improve from 1.65728\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6049 - mean_absolute_error: 0.9153 - mean_squared_error: 1.6049 - val_loss: 1.6588 - val_mean_absolute_error: 0.9234 - val_mean_squared_error: 1.6588\n",
            "Epoch 696/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.6018 - mean_absolute_error: 0.9143 - mean_squared_error: 1.6018\n",
            "Epoch 696: val_loss did not improve from 1.65728\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6049 - mean_absolute_error: 0.9152 - mean_squared_error: 1.6049 - val_loss: 1.6631 - val_mean_absolute_error: 0.9248 - val_mean_squared_error: 1.6631\n",
            "Epoch 697/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.6010 - mean_absolute_error: 0.9140 - mean_squared_error: 1.6010\n",
            "Epoch 697: val_loss improved from 1.65728 to 1.65525, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6031 - mean_absolute_error: 0.9147 - mean_squared_error: 1.6031 - val_loss: 1.6552 - val_mean_absolute_error: 0.9232 - val_mean_squared_error: 1.6552\n",
            "Epoch 698/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.5962 - mean_absolute_error: 0.9148 - mean_squared_error: 1.5962\n",
            "Epoch 698: val_loss did not improve from 1.65525\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6034 - mean_absolute_error: 0.9147 - mean_squared_error: 1.6034 - val_loss: 1.6597 - val_mean_absolute_error: 0.9239 - val_mean_squared_error: 1.6597\n",
            "Epoch 699/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.6031 - mean_absolute_error: 0.9146 - mean_squared_error: 1.6031\n",
            "Epoch 699: val_loss improved from 1.65525 to 1.65453, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6021 - mean_absolute_error: 0.9142 - mean_squared_error: 1.6021 - val_loss: 1.6545 - val_mean_absolute_error: 0.9241 - val_mean_squared_error: 1.6545\n",
            "Epoch 700/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.6058 - mean_absolute_error: 0.9165 - mean_squared_error: 1.6058\n",
            "Epoch 700: val_loss improved from 1.65453 to 1.65409, saving model to best_model3.h5\n",
            "245/245 [==============================] - 2s 6ms/step - loss: 1.6014 - mean_absolute_error: 0.9144 - mean_squared_error: 1.6014 - val_loss: 1.6541 - val_mean_absolute_error: 0.9230 - val_mean_squared_error: 1.6541\n",
            "Epoch 701/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.5978 - mean_absolute_error: 0.9127 - mean_squared_error: 1.5978\n",
            "Epoch 701: val_loss improved from 1.65409 to 1.65309, saving model to best_model3.h5\n",
            "245/245 [==============================] - 2s 7ms/step - loss: 1.6005 - mean_absolute_error: 0.9142 - mean_squared_error: 1.6005 - val_loss: 1.6531 - val_mean_absolute_error: 0.9230 - val_mean_squared_error: 1.6531\n",
            "Epoch 702/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.5969 - mean_absolute_error: 0.9126 - mean_squared_error: 1.5969\n",
            "Epoch 702: val_loss did not improve from 1.65309\n",
            "245/245 [==============================] - 2s 9ms/step - loss: 1.6008 - mean_absolute_error: 0.9139 - mean_squared_error: 1.6008 - val_loss: 1.6547 - val_mean_absolute_error: 0.9224 - val_mean_squared_error: 1.6547\n",
            "Epoch 703/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.6017 - mean_absolute_error: 0.9143 - mean_squared_error: 1.6017\n",
            "Epoch 703: val_loss improved from 1.65309 to 1.65216, saving model to best_model3.h5\n",
            "245/245 [==============================] - 2s 8ms/step - loss: 1.5998 - mean_absolute_error: 0.9133 - mean_squared_error: 1.5998 - val_loss: 1.6522 - val_mean_absolute_error: 0.9227 - val_mean_squared_error: 1.6522\n",
            "Epoch 704/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.6048 - mean_absolute_error: 0.9137 - mean_squared_error: 1.6048\n",
            "Epoch 704: val_loss did not improve from 1.65216\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.5991 - mean_absolute_error: 0.9129 - mean_squared_error: 1.5991 - val_loss: 1.6522 - val_mean_absolute_error: 0.9221 - val_mean_squared_error: 1.6522\n",
            "Epoch 705/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.6095 - mean_absolute_error: 0.9151 - mean_squared_error: 1.6095\n",
            "Epoch 705: val_loss did not improve from 1.65216\n",
            "245/245 [==============================] - 2s 8ms/step - loss: 1.5987 - mean_absolute_error: 0.9128 - mean_squared_error: 1.5987 - val_loss: 1.6581 - val_mean_absolute_error: 0.9237 - val_mean_squared_error: 1.6581\n",
            "Epoch 706/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.5908 - mean_absolute_error: 0.9112 - mean_squared_error: 1.5908\n",
            "Epoch 706: val_loss did not improve from 1.65216\n",
            "245/245 [==============================] - 2s 7ms/step - loss: 1.5979 - mean_absolute_error: 0.9135 - mean_squared_error: 1.5979 - val_loss: 1.6552 - val_mean_absolute_error: 0.9227 - val_mean_squared_error: 1.6552\n",
            "Epoch 707/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.5947 - mean_absolute_error: 0.9134 - mean_squared_error: 1.5947\n",
            "Epoch 707: val_loss did not improve from 1.65216\n",
            "245/245 [==============================] - 2s 10ms/step - loss: 1.5982 - mean_absolute_error: 0.9134 - mean_squared_error: 1.5982 - val_loss: 1.6537 - val_mean_absolute_error: 0.9220 - val_mean_squared_error: 1.6537\n",
            "Epoch 708/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.5989 - mean_absolute_error: 0.9148 - mean_squared_error: 1.5989\n",
            "Epoch 708: val_loss improved from 1.65216 to 1.65072, saving model to best_model3.h5\n",
            "245/245 [==============================] - 2s 7ms/step - loss: 1.5975 - mean_absolute_error: 0.9135 - mean_squared_error: 1.5975 - val_loss: 1.6507 - val_mean_absolute_error: 0.9216 - val_mean_squared_error: 1.6507\n",
            "Epoch 709/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.6088 - mean_absolute_error: 0.9171 - mean_squared_error: 1.6088\n",
            "Epoch 709: val_loss did not improve from 1.65072\n",
            "245/245 [==============================] - 2s 7ms/step - loss: 1.5955 - mean_absolute_error: 0.9120 - mean_squared_error: 1.5955 - val_loss: 1.6547 - val_mean_absolute_error: 0.9225 - val_mean_squared_error: 1.6547\n",
            "Epoch 710/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.5799 - mean_absolute_error: 0.9076 - mean_squared_error: 1.5799\n",
            "Epoch 710: val_loss did not improve from 1.65072\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5965 - mean_absolute_error: 0.9126 - mean_squared_error: 1.5965 - val_loss: 1.6513 - val_mean_absolute_error: 0.9218 - val_mean_squared_error: 1.6513\n",
            "Epoch 711/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.5972 - mean_absolute_error: 0.9138 - mean_squared_error: 1.5972\n",
            "Epoch 711: val_loss improved from 1.65072 to 1.65058, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5947 - mean_absolute_error: 0.9127 - mean_squared_error: 1.5947 - val_loss: 1.6506 - val_mean_absolute_error: 0.9217 - val_mean_squared_error: 1.6506\n",
            "Epoch 712/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.5939 - mean_absolute_error: 0.9132 - mean_squared_error: 1.5939\n",
            "Epoch 712: val_loss did not improve from 1.65058\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5948 - mean_absolute_error: 0.9127 - mean_squared_error: 1.5948 - val_loss: 1.6549 - val_mean_absolute_error: 0.9225 - val_mean_squared_error: 1.6549\n",
            "Epoch 713/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.5865 - mean_absolute_error: 0.9098 - mean_squared_error: 1.5865\n",
            "Epoch 713: val_loss improved from 1.65058 to 1.64998, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5946 - mean_absolute_error: 0.9126 - mean_squared_error: 1.5946 - val_loss: 1.6500 - val_mean_absolute_error: 0.9215 - val_mean_squared_error: 1.6500\n",
            "Epoch 714/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.5832 - mean_absolute_error: 0.9101 - mean_squared_error: 1.5832\n",
            "Epoch 714: val_loss did not improve from 1.64998\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5926 - mean_absolute_error: 0.9117 - mean_squared_error: 1.5926 - val_loss: 1.6511 - val_mean_absolute_error: 0.9216 - val_mean_squared_error: 1.6511\n",
            "Epoch 715/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.5850 - mean_absolute_error: 0.9082 - mean_squared_error: 1.5850\n",
            "Epoch 715: val_loss improved from 1.64998 to 1.64661, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5921 - mean_absolute_error: 0.9119 - mean_squared_error: 1.5921 - val_loss: 1.6466 - val_mean_absolute_error: 0.9208 - val_mean_squared_error: 1.6466\n",
            "Epoch 716/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.5983 - mean_absolute_error: 0.9120 - mean_squared_error: 1.5983\n",
            "Epoch 716: val_loss did not improve from 1.64661\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5926 - mean_absolute_error: 0.9122 - mean_squared_error: 1.5926 - val_loss: 1.6477 - val_mean_absolute_error: 0.9210 - val_mean_squared_error: 1.6477\n",
            "Epoch 717/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.6008 - mean_absolute_error: 0.9149 - mean_squared_error: 1.6008\n",
            "Epoch 717: val_loss improved from 1.64661 to 1.64602, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5913 - mean_absolute_error: 0.9113 - mean_squared_error: 1.5913 - val_loss: 1.6460 - val_mean_absolute_error: 0.9209 - val_mean_squared_error: 1.6460\n",
            "Epoch 718/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.5873 - mean_absolute_error: 0.9118 - mean_squared_error: 1.5873\n",
            "Epoch 718: val_loss improved from 1.64602 to 1.64584, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5915 - mean_absolute_error: 0.9124 - mean_squared_error: 1.5915 - val_loss: 1.6458 - val_mean_absolute_error: 0.9205 - val_mean_squared_error: 1.6458\n",
            "Epoch 719/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.5851 - mean_absolute_error: 0.9104 - mean_squared_error: 1.5851\n",
            "Epoch 719: val_loss did not improve from 1.64584\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5905 - mean_absolute_error: 0.9110 - mean_squared_error: 1.5905 - val_loss: 1.6463 - val_mean_absolute_error: 0.9209 - val_mean_squared_error: 1.6463\n",
            "Epoch 720/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.6048 - mean_absolute_error: 0.9152 - mean_squared_error: 1.6048\n",
            "Epoch 720: val_loss did not improve from 1.64584\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5882 - mean_absolute_error: 0.9109 - mean_squared_error: 1.5882 - val_loss: 1.6503 - val_mean_absolute_error: 0.9213 - val_mean_squared_error: 1.6503\n",
            "Epoch 721/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.6020 - mean_absolute_error: 0.9149 - mean_squared_error: 1.6020\n",
            "Epoch 721: val_loss did not improve from 1.64584\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5882 - mean_absolute_error: 0.9109 - mean_squared_error: 1.5882 - val_loss: 1.6472 - val_mean_absolute_error: 0.9208 - val_mean_squared_error: 1.6472\n",
            "Epoch 722/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.5804 - mean_absolute_error: 0.9074 - mean_squared_error: 1.5804\n",
            "Epoch 722: val_loss improved from 1.64584 to 1.64384, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5878 - mean_absolute_error: 0.9110 - mean_squared_error: 1.5878 - val_loss: 1.6438 - val_mean_absolute_error: 0.9207 - val_mean_squared_error: 1.6438\n",
            "Epoch 723/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.5909 - mean_absolute_error: 0.9113 - mean_squared_error: 1.5909\n",
            "Epoch 723: val_loss improved from 1.64384 to 1.64297, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5880 - mean_absolute_error: 0.9104 - mean_squared_error: 1.5880 - val_loss: 1.6430 - val_mean_absolute_error: 0.9206 - val_mean_squared_error: 1.6430\n",
            "Epoch 724/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.5871 - mean_absolute_error: 0.9135 - mean_squared_error: 1.5871\n",
            "Epoch 724: val_loss did not improve from 1.64297\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5881 - mean_absolute_error: 0.9108 - mean_squared_error: 1.5881 - val_loss: 1.6445 - val_mean_absolute_error: 0.9199 - val_mean_squared_error: 1.6445\n",
            "Epoch 725/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.5846 - mean_absolute_error: 0.9105 - mean_squared_error: 1.5846\n",
            "Epoch 725: val_loss did not improve from 1.64297\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5876 - mean_absolute_error: 0.9105 - mean_squared_error: 1.5876 - val_loss: 1.6435 - val_mean_absolute_error: 0.9200 - val_mean_squared_error: 1.6435\n",
            "Epoch 726/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.5839 - mean_absolute_error: 0.9108 - mean_squared_error: 1.5839\n",
            "Epoch 726: val_loss did not improve from 1.64297\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5870 - mean_absolute_error: 0.9102 - mean_squared_error: 1.5870 - val_loss: 1.6453 - val_mean_absolute_error: 0.9204 - val_mean_squared_error: 1.6453\n",
            "Epoch 727/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.5994 - mean_absolute_error: 0.9136 - mean_squared_error: 1.5994\n",
            "Epoch 727: val_loss did not improve from 1.64297\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5852 - mean_absolute_error: 0.9102 - mean_squared_error: 1.5852 - val_loss: 1.6468 - val_mean_absolute_error: 0.9207 - val_mean_squared_error: 1.6468\n",
            "Epoch 728/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.5819 - mean_absolute_error: 0.9091 - mean_squared_error: 1.5819\n",
            "Epoch 728: val_loss improved from 1.64297 to 1.64194, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5852 - mean_absolute_error: 0.9099 - mean_squared_error: 1.5852 - val_loss: 1.6419 - val_mean_absolute_error: 0.9195 - val_mean_squared_error: 1.6419\n",
            "Epoch 729/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.5829 - mean_absolute_error: 0.9091 - mean_squared_error: 1.5829\n",
            "Epoch 729: val_loss improved from 1.64194 to 1.64159, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5849 - mean_absolute_error: 0.9103 - mean_squared_error: 1.5849 - val_loss: 1.6416 - val_mean_absolute_error: 0.9194 - val_mean_squared_error: 1.6416\n",
            "Epoch 730/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.5810 - mean_absolute_error: 0.9080 - mean_squared_error: 1.5810\n",
            "Epoch 730: val_loss improved from 1.64159 to 1.64036, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5836 - mean_absolute_error: 0.9091 - mean_squared_error: 1.5836 - val_loss: 1.6404 - val_mean_absolute_error: 0.9201 - val_mean_squared_error: 1.6404\n",
            "Epoch 731/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 1.5845 - mean_absolute_error: 0.9119 - mean_squared_error: 1.5845\n",
            "Epoch 731: val_loss improved from 1.64036 to 1.63974, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5839 - mean_absolute_error: 0.9097 - mean_squared_error: 1.5839 - val_loss: 1.6397 - val_mean_absolute_error: 0.9200 - val_mean_squared_error: 1.6397\n",
            "Epoch 732/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.5869 - mean_absolute_error: 0.9117 - mean_squared_error: 1.5869\n",
            "Epoch 732: val_loss did not improve from 1.63974\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5830 - mean_absolute_error: 0.9095 - mean_squared_error: 1.5830 - val_loss: 1.6402 - val_mean_absolute_error: 0.9198 - val_mean_squared_error: 1.6402\n",
            "Epoch 733/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.5744 - mean_absolute_error: 0.9063 - mean_squared_error: 1.5744\n",
            "Epoch 733: val_loss did not improve from 1.63974\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5819 - mean_absolute_error: 0.9090 - mean_squared_error: 1.5819 - val_loss: 1.6485 - val_mean_absolute_error: 0.9210 - val_mean_squared_error: 1.6485\n",
            "Epoch 734/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.5904 - mean_absolute_error: 0.9101 - mean_squared_error: 1.5904\n",
            "Epoch 734: val_loss did not improve from 1.63974\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5827 - mean_absolute_error: 0.9088 - mean_squared_error: 1.5827 - val_loss: 1.6404 - val_mean_absolute_error: 0.9194 - val_mean_squared_error: 1.6404\n",
            "Epoch 735/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.5874 - mean_absolute_error: 0.9121 - mean_squared_error: 1.5874\n",
            "Epoch 735: val_loss improved from 1.63974 to 1.63872, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5811 - mean_absolute_error: 0.9091 - mean_squared_error: 1.5811 - val_loss: 1.6387 - val_mean_absolute_error: 0.9206 - val_mean_squared_error: 1.6387\n",
            "Epoch 736/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.5617 - mean_absolute_error: 0.9057 - mean_squared_error: 1.5617\n",
            "Epoch 736: val_loss did not improve from 1.63872\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5813 - mean_absolute_error: 0.9088 - mean_squared_error: 1.5813 - val_loss: 1.6400 - val_mean_absolute_error: 0.9196 - val_mean_squared_error: 1.6400\n",
            "Epoch 737/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.5631 - mean_absolute_error: 0.9047 - mean_squared_error: 1.5631\n",
            "Epoch 737: val_loss improved from 1.63872 to 1.63819, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5809 - mean_absolute_error: 0.9089 - mean_squared_error: 1.5809 - val_loss: 1.6382 - val_mean_absolute_error: 0.9194 - val_mean_squared_error: 1.6382\n",
            "Epoch 738/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.5689 - mean_absolute_error: 0.9036 - mean_squared_error: 1.5689\n",
            "Epoch 738: val_loss did not improve from 1.63819\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5800 - mean_absolute_error: 0.9082 - mean_squared_error: 1.5800 - val_loss: 1.6425 - val_mean_absolute_error: 0.9201 - val_mean_squared_error: 1.6425\n",
            "Epoch 739/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.5797 - mean_absolute_error: 0.9093 - mean_squared_error: 1.5797\n",
            "Epoch 739: val_loss did not improve from 1.63819\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5800 - mean_absolute_error: 0.9087 - mean_squared_error: 1.5800 - val_loss: 1.6395 - val_mean_absolute_error: 0.9196 - val_mean_squared_error: 1.6395\n",
            "Epoch 740/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.5832 - mean_absolute_error: 0.9095 - mean_squared_error: 1.5832\n",
            "Epoch 740: val_loss improved from 1.63819 to 1.63786, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5794 - mean_absolute_error: 0.9085 - mean_squared_error: 1.5794 - val_loss: 1.6379 - val_mean_absolute_error: 0.9195 - val_mean_squared_error: 1.6379\n",
            "Epoch 741/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.5856 - mean_absolute_error: 0.9103 - mean_squared_error: 1.5856\n",
            "Epoch 741: val_loss improved from 1.63786 to 1.63667, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5795 - mean_absolute_error: 0.9088 - mean_squared_error: 1.5795 - val_loss: 1.6367 - val_mean_absolute_error: 0.9204 - val_mean_squared_error: 1.6367\n",
            "Epoch 742/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.5805 - mean_absolute_error: 0.9089 - mean_squared_error: 1.5805\n",
            "Epoch 742: val_loss did not improve from 1.63667\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5794 - mean_absolute_error: 0.9087 - mean_squared_error: 1.5794 - val_loss: 1.6379 - val_mean_absolute_error: 0.9193 - val_mean_squared_error: 1.6379\n",
            "Epoch 743/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.5768 - mean_absolute_error: 0.9088 - mean_squared_error: 1.5768\n",
            "Epoch 743: val_loss did not improve from 1.63667\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5780 - mean_absolute_error: 0.9086 - mean_squared_error: 1.5780 - val_loss: 1.6377 - val_mean_absolute_error: 0.9193 - val_mean_squared_error: 1.6377\n",
            "Epoch 744/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.5905 - mean_absolute_error: 0.9126 - mean_squared_error: 1.5905\n",
            "Epoch 744: val_loss improved from 1.63667 to 1.63553, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5765 - mean_absolute_error: 0.9080 - mean_squared_error: 1.5765 - val_loss: 1.6355 - val_mean_absolute_error: 0.9199 - val_mean_squared_error: 1.6355\n",
            "Epoch 745/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.5655 - mean_absolute_error: 0.9054 - mean_squared_error: 1.5655\n",
            "Epoch 745: val_loss improved from 1.63553 to 1.63529, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5779 - mean_absolute_error: 0.9087 - mean_squared_error: 1.5779 - val_loss: 1.6353 - val_mean_absolute_error: 0.9190 - val_mean_squared_error: 1.6353\n",
            "Epoch 746/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.5708 - mean_absolute_error: 0.9047 - mean_squared_error: 1.5708\n",
            "Epoch 746: val_loss improved from 1.63529 to 1.63446, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5766 - mean_absolute_error: 0.9072 - mean_squared_error: 1.5766 - val_loss: 1.6345 - val_mean_absolute_error: 0.9194 - val_mean_squared_error: 1.6345\n",
            "Epoch 747/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.5786 - mean_absolute_error: 0.9087 - mean_squared_error: 1.5786\n",
            "Epoch 747: val_loss did not improve from 1.63446\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5756 - mean_absolute_error: 0.9078 - mean_squared_error: 1.5756 - val_loss: 1.6399 - val_mean_absolute_error: 0.9196 - val_mean_squared_error: 1.6399\n",
            "Epoch 748/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.5561 - mean_absolute_error: 0.9010 - mean_squared_error: 1.5561\n",
            "Epoch 748: val_loss did not improve from 1.63446\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5762 - mean_absolute_error: 0.9077 - mean_squared_error: 1.5762 - val_loss: 1.6360 - val_mean_absolute_error: 0.9190 - val_mean_squared_error: 1.6360\n",
            "Epoch 749/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.5548 - mean_absolute_error: 0.9045 - mean_squared_error: 1.5548\n",
            "Epoch 749: val_loss improved from 1.63446 to 1.63367, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5750 - mean_absolute_error: 0.9078 - mean_squared_error: 1.5750 - val_loss: 1.6337 - val_mean_absolute_error: 0.9195 - val_mean_squared_error: 1.6337\n",
            "Epoch 750/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.5752 - mean_absolute_error: 0.9081 - mean_squared_error: 1.5752\n",
            "Epoch 750: val_loss did not improve from 1.63367\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5752 - mean_absolute_error: 0.9081 - mean_squared_error: 1.5752 - val_loss: 1.6376 - val_mean_absolute_error: 0.9195 - val_mean_squared_error: 1.6376\n",
            "Epoch 751/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.5760 - mean_absolute_error: 0.9080 - mean_squared_error: 1.5760\n",
            "Epoch 751: val_loss improved from 1.63367 to 1.63344, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5734 - mean_absolute_error: 0.9075 - mean_squared_error: 1.5734 - val_loss: 1.6334 - val_mean_absolute_error: 0.9206 - val_mean_squared_error: 1.6334\n",
            "Epoch 752/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.5719 - mean_absolute_error: 0.9091 - mean_squared_error: 1.5719\n",
            "Epoch 752: val_loss did not improve from 1.63344\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5745 - mean_absolute_error: 0.9085 - mean_squared_error: 1.5745 - val_loss: 1.6383 - val_mean_absolute_error: 0.9196 - val_mean_squared_error: 1.6383\n",
            "Epoch 753/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.5732 - mean_absolute_error: 0.9072 - mean_squared_error: 1.5732\n",
            "Epoch 753: val_loss improved from 1.63344 to 1.63291, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5745 - mean_absolute_error: 0.9081 - mean_squared_error: 1.5745 - val_loss: 1.6329 - val_mean_absolute_error: 0.9188 - val_mean_squared_error: 1.6329\n",
            "Epoch 754/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.5455 - mean_absolute_error: 0.8994 - mean_squared_error: 1.5455\n",
            "Epoch 754: val_loss improved from 1.63291 to 1.63227, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5726 - mean_absolute_error: 0.9064 - mean_squared_error: 1.5726 - val_loss: 1.6323 - val_mean_absolute_error: 0.9189 - val_mean_squared_error: 1.6323\n",
            "Epoch 755/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.5765 - mean_absolute_error: 0.9073 - mean_squared_error: 1.5765\n",
            "Epoch 755: val_loss did not improve from 1.63227\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5731 - mean_absolute_error: 0.9074 - mean_squared_error: 1.5731 - val_loss: 1.6358 - val_mean_absolute_error: 0.9197 - val_mean_squared_error: 1.6358\n",
            "Epoch 756/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.5792 - mean_absolute_error: 0.9107 - mean_squared_error: 1.5792\n",
            "Epoch 756: val_loss improved from 1.63227 to 1.63153, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5732 - mean_absolute_error: 0.9083 - mean_squared_error: 1.5732 - val_loss: 1.6315 - val_mean_absolute_error: 0.9195 - val_mean_squared_error: 1.6315\n",
            "Epoch 757/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.5660 - mean_absolute_error: 0.9055 - mean_squared_error: 1.5660\n",
            "Epoch 757: val_loss improved from 1.63153 to 1.63125, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5718 - mean_absolute_error: 0.9072 - mean_squared_error: 1.5718 - val_loss: 1.6312 - val_mean_absolute_error: 0.9189 - val_mean_squared_error: 1.6312\n",
            "Epoch 758/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.5707 - mean_absolute_error: 0.9057 - mean_squared_error: 1.5707\n",
            "Epoch 758: val_loss did not improve from 1.63125\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5711 - mean_absolute_error: 0.9061 - mean_squared_error: 1.5711 - val_loss: 1.6316 - val_mean_absolute_error: 0.9186 - val_mean_squared_error: 1.6316\n",
            "Epoch 759/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.5658 - mean_absolute_error: 0.9060 - mean_squared_error: 1.5658\n",
            "Epoch 759: val_loss did not improve from 1.63125\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5711 - mean_absolute_error: 0.9072 - mean_squared_error: 1.5711 - val_loss: 1.6324 - val_mean_absolute_error: 0.9186 - val_mean_squared_error: 1.6324\n",
            "Epoch 760/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.5713 - mean_absolute_error: 0.9069 - mean_squared_error: 1.5713\n",
            "Epoch 760: val_loss improved from 1.63125 to 1.63117, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5713 - mean_absolute_error: 0.9069 - mean_squared_error: 1.5713 - val_loss: 1.6312 - val_mean_absolute_error: 0.9189 - val_mean_squared_error: 1.6312\n",
            "Epoch 761/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.5803 - mean_absolute_error: 0.9107 - mean_squared_error: 1.5803\n",
            "Epoch 761: val_loss did not improve from 1.63117\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5691 - mean_absolute_error: 0.9065 - mean_squared_error: 1.5691 - val_loss: 1.6386 - val_mean_absolute_error: 0.9198 - val_mean_squared_error: 1.6386\n",
            "Epoch 762/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.5680 - mean_absolute_error: 0.9051 - mean_squared_error: 1.5680\n",
            "Epoch 762: val_loss did not improve from 1.63117\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5704 - mean_absolute_error: 0.9067 - mean_squared_error: 1.5704 - val_loss: 1.6337 - val_mean_absolute_error: 0.9188 - val_mean_squared_error: 1.6337\n",
            "Epoch 763/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.5887 - mean_absolute_error: 0.9092 - mean_squared_error: 1.5887\n",
            "Epoch 763: val_loss improved from 1.63117 to 1.63034, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5703 - mean_absolute_error: 0.9065 - mean_squared_error: 1.5703 - val_loss: 1.6303 - val_mean_absolute_error: 0.9188 - val_mean_squared_error: 1.6303\n",
            "Epoch 764/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.5485 - mean_absolute_error: 0.8972 - mean_squared_error: 1.5485\n",
            "Epoch 764: val_loss improved from 1.63034 to 1.63013, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5697 - mean_absolute_error: 0.9068 - mean_squared_error: 1.5697 - val_loss: 1.6301 - val_mean_absolute_error: 0.9186 - val_mean_squared_error: 1.6301\n",
            "Epoch 765/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.5760 - mean_absolute_error: 0.9087 - mean_squared_error: 1.5760\n",
            "Epoch 765: val_loss improved from 1.63013 to 1.62924, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5697 - mean_absolute_error: 0.9070 - mean_squared_error: 1.5697 - val_loss: 1.6292 - val_mean_absolute_error: 0.9188 - val_mean_squared_error: 1.6292\n",
            "Epoch 766/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.5740 - mean_absolute_error: 0.9084 - mean_squared_error: 1.5740\n",
            "Epoch 766: val_loss improved from 1.62924 to 1.62869, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5677 - mean_absolute_error: 0.9063 - mean_squared_error: 1.5677 - val_loss: 1.6287 - val_mean_absolute_error: 0.9190 - val_mean_squared_error: 1.6287\n",
            "Epoch 767/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.5726 - mean_absolute_error: 0.9069 - mean_squared_error: 1.5726\n",
            "Epoch 767: val_loss did not improve from 1.62869\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5679 - mean_absolute_error: 0.9054 - mean_squared_error: 1.5679 - val_loss: 1.6328 - val_mean_absolute_error: 0.9188 - val_mean_squared_error: 1.6328\n",
            "Epoch 768/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.5691 - mean_absolute_error: 0.9066 - mean_squared_error: 1.5691\n",
            "Epoch 768: val_loss did not improve from 1.62869\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5688 - mean_absolute_error: 0.9071 - mean_squared_error: 1.5688 - val_loss: 1.6328 - val_mean_absolute_error: 0.9189 - val_mean_squared_error: 1.6328\n",
            "Epoch 769/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.5602 - mean_absolute_error: 0.9034 - mean_squared_error: 1.5602\n",
            "Epoch 769: val_loss improved from 1.62869 to 1.62860, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5677 - mean_absolute_error: 0.9063 - mean_squared_error: 1.5677 - val_loss: 1.6286 - val_mean_absolute_error: 0.9189 - val_mean_squared_error: 1.6286\n",
            "Epoch 770/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.5432 - mean_absolute_error: 0.9009 - mean_squared_error: 1.5432\n",
            "Epoch 770: val_loss did not improve from 1.62860\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5674 - mean_absolute_error: 0.9065 - mean_squared_error: 1.5674 - val_loss: 1.6287 - val_mean_absolute_error: 0.9185 - val_mean_squared_error: 1.6287\n",
            "Epoch 771/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.5719 - mean_absolute_error: 0.9068 - mean_squared_error: 1.5719\n",
            "Epoch 771: val_loss improved from 1.62860 to 1.62808, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5671 - mean_absolute_error: 0.9061 - mean_squared_error: 1.5671 - val_loss: 1.6281 - val_mean_absolute_error: 0.9187 - val_mean_squared_error: 1.6281\n",
            "Epoch 772/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.5781 - mean_absolute_error: 0.9092 - mean_squared_error: 1.5781\n",
            "Epoch 772: val_loss did not improve from 1.62808\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5661 - mean_absolute_error: 0.9063 - mean_squared_error: 1.5661 - val_loss: 1.6302 - val_mean_absolute_error: 0.9187 - val_mean_squared_error: 1.6302\n",
            "Epoch 773/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.5652 - mean_absolute_error: 0.9066 - mean_squared_error: 1.5652\n",
            "Epoch 773: val_loss did not improve from 1.62808\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5667 - mean_absolute_error: 0.9064 - mean_squared_error: 1.5667 - val_loss: 1.6292 - val_mean_absolute_error: 0.9184 - val_mean_squared_error: 1.6292\n",
            "Epoch 774/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.5650 - mean_absolute_error: 0.9068 - mean_squared_error: 1.5650\n",
            "Epoch 774: val_loss improved from 1.62808 to 1.62805, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5655 - mean_absolute_error: 0.9066 - mean_squared_error: 1.5655 - val_loss: 1.6280 - val_mean_absolute_error: 0.9180 - val_mean_squared_error: 1.6280\n",
            "Epoch 775/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.5559 - mean_absolute_error: 0.9023 - mean_squared_error: 1.5559\n",
            "Epoch 775: val_loss improved from 1.62805 to 1.62675, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5658 - mean_absolute_error: 0.9055 - mean_squared_error: 1.5658 - val_loss: 1.6268 - val_mean_absolute_error: 0.9185 - val_mean_squared_error: 1.6268\n",
            "Epoch 776/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.5675 - mean_absolute_error: 0.9078 - mean_squared_error: 1.5675\n",
            "Epoch 776: val_loss improved from 1.62675 to 1.62631, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5640 - mean_absolute_error: 0.9058 - mean_squared_error: 1.5640 - val_loss: 1.6263 - val_mean_absolute_error: 0.9191 - val_mean_squared_error: 1.6263\n",
            "Epoch 777/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.5746 - mean_absolute_error: 0.9076 - mean_squared_error: 1.5746\n",
            "Epoch 777: val_loss did not improve from 1.62631\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5656 - mean_absolute_error: 0.9066 - mean_squared_error: 1.5656 - val_loss: 1.6280 - val_mean_absolute_error: 0.9182 - val_mean_squared_error: 1.6280\n",
            "Epoch 778/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.5590 - mean_absolute_error: 0.9036 - mean_squared_error: 1.5590\n",
            "Epoch 778: val_loss improved from 1.62631 to 1.62592, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5643 - mean_absolute_error: 0.9052 - mean_squared_error: 1.5643 - val_loss: 1.6259 - val_mean_absolute_error: 0.9193 - val_mean_squared_error: 1.6259\n",
            "Epoch 779/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.5481 - mean_absolute_error: 0.8999 - mean_squared_error: 1.5481\n",
            "Epoch 779: val_loss did not improve from 1.62592\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5635 - mean_absolute_error: 0.9058 - mean_squared_error: 1.5635 - val_loss: 1.6289 - val_mean_absolute_error: 0.9188 - val_mean_squared_error: 1.6289\n",
            "Epoch 780/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.5640 - mean_absolute_error: 0.9028 - mean_squared_error: 1.5640\n",
            "Epoch 780: val_loss did not improve from 1.62592\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5634 - mean_absolute_error: 0.9050 - mean_squared_error: 1.5634 - val_loss: 1.6263 - val_mean_absolute_error: 0.9196 - val_mean_squared_error: 1.6263\n",
            "Epoch 781/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 1.5706 - mean_absolute_error: 0.9072 - mean_squared_error: 1.5706\n",
            "Epoch 781: val_loss improved from 1.62592 to 1.62548, saving model to best_model3.h5\n",
            "245/245 [==============================] - 2s 8ms/step - loss: 1.5635 - mean_absolute_error: 0.9061 - mean_squared_error: 1.5635 - val_loss: 1.6255 - val_mean_absolute_error: 0.9195 - val_mean_squared_error: 1.6255\n",
            "Epoch 782/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.5679 - mean_absolute_error: 0.9067 - mean_squared_error: 1.5679\n",
            "Epoch 782: val_loss did not improve from 1.62548\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5628 - mean_absolute_error: 0.9058 - mean_squared_error: 1.5628 - val_loss: 1.6262 - val_mean_absolute_error: 0.9188 - val_mean_squared_error: 1.6262\n",
            "Epoch 783/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.5558 - mean_absolute_error: 0.9032 - mean_squared_error: 1.5558\n",
            "Epoch 783: val_loss did not improve from 1.62548\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5632 - mean_absolute_error: 0.9058 - mean_squared_error: 1.5632 - val_loss: 1.6262 - val_mean_absolute_error: 0.9184 - val_mean_squared_error: 1.6262\n",
            "Epoch 784/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.5672 - mean_absolute_error: 0.9080 - mean_squared_error: 1.5672\n",
            "Epoch 784: val_loss did not improve from 1.62548\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5628 - mean_absolute_error: 0.9058 - mean_squared_error: 1.5628 - val_loss: 1.6276 - val_mean_absolute_error: 0.9186 - val_mean_squared_error: 1.6276\n",
            "Epoch 785/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.5481 - mean_absolute_error: 0.9023 - mean_squared_error: 1.5481\n",
            "Epoch 785: val_loss did not improve from 1.62548\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5623 - mean_absolute_error: 0.9058 - mean_squared_error: 1.5623 - val_loss: 1.6257 - val_mean_absolute_error: 0.9184 - val_mean_squared_error: 1.6257\n",
            "Epoch 786/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.5626 - mean_absolute_error: 0.9065 - mean_squared_error: 1.5626\n",
            "Epoch 786: val_loss did not improve from 1.62548\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5626 - mean_absolute_error: 0.9065 - mean_squared_error: 1.5626 - val_loss: 1.6256 - val_mean_absolute_error: 0.9182 - val_mean_squared_error: 1.6256\n",
            "Epoch 787/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.5655 - mean_absolute_error: 0.9067 - mean_squared_error: 1.5655\n",
            "Epoch 787: val_loss did not improve from 1.62548\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5583 - mean_absolute_error: 0.9038 - mean_squared_error: 1.5583 - val_loss: 1.6286 - val_mean_absolute_error: 0.9234 - val_mean_squared_error: 1.6286\n",
            "Epoch 788/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.5562 - mean_absolute_error: 0.9045 - mean_squared_error: 1.5562\n",
            "Epoch 788: val_loss did not improve from 1.62548\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5612 - mean_absolute_error: 0.9059 - mean_squared_error: 1.5612 - val_loss: 1.6284 - val_mean_absolute_error: 0.9187 - val_mean_squared_error: 1.6284\n",
            "Epoch 789/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.5612 - mean_absolute_error: 0.9060 - mean_squared_error: 1.5612\n",
            "Epoch 789: val_loss improved from 1.62548 to 1.62394, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5619 - mean_absolute_error: 0.9056 - mean_squared_error: 1.5619 - val_loss: 1.6239 - val_mean_absolute_error: 0.9198 - val_mean_squared_error: 1.6239\n",
            "Epoch 790/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.5613 - mean_absolute_error: 0.9056 - mean_squared_error: 1.5613\n",
            "Epoch 790: val_loss did not improve from 1.62394\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5613 - mean_absolute_error: 0.9056 - mean_squared_error: 1.5613 - val_loss: 1.6246 - val_mean_absolute_error: 0.9183 - val_mean_squared_error: 1.6246\n",
            "Epoch 791/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.5538 - mean_absolute_error: 0.9031 - mean_squared_error: 1.5538\n",
            "Epoch 791: val_loss did not improve from 1.62394\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5597 - mean_absolute_error: 0.9049 - mean_squared_error: 1.5597 - val_loss: 1.6245 - val_mean_absolute_error: 0.9207 - val_mean_squared_error: 1.6245\n",
            "Epoch 792/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.5578 - mean_absolute_error: 0.9051 - mean_squared_error: 1.5578\n",
            "Epoch 792: val_loss improved from 1.62394 to 1.62368, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5596 - mean_absolute_error: 0.9053 - mean_squared_error: 1.5596 - val_loss: 1.6237 - val_mean_absolute_error: 0.9185 - val_mean_squared_error: 1.6237\n",
            "Epoch 793/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.5743 - mean_absolute_error: 0.9075 - mean_squared_error: 1.5743\n",
            "Epoch 793: val_loss did not improve from 1.62368\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5593 - mean_absolute_error: 0.9054 - mean_squared_error: 1.5593 - val_loss: 1.6273 - val_mean_absolute_error: 0.9187 - val_mean_squared_error: 1.6273\n",
            "Epoch 794/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.5609 - mean_absolute_error: 0.9054 - mean_squared_error: 1.5609\n",
            "Epoch 794: val_loss did not improve from 1.62368\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5605 - mean_absolute_error: 0.9049 - mean_squared_error: 1.5605 - val_loss: 1.6252 - val_mean_absolute_error: 0.9181 - val_mean_squared_error: 1.6252\n",
            "Epoch 795/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.5535 - mean_absolute_error: 0.9016 - mean_squared_error: 1.5535\n",
            "Epoch 795: val_loss did not improve from 1.62368\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5565 - mean_absolute_error: 0.9036 - mean_squared_error: 1.5565 - val_loss: 1.6382 - val_mean_absolute_error: 0.9217 - val_mean_squared_error: 1.6382\n",
            "Epoch 796/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.5585 - mean_absolute_error: 0.9048 - mean_squared_error: 1.5585\n",
            "Epoch 796: val_loss improved from 1.62368 to 1.62239, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5599 - mean_absolute_error: 0.9054 - mean_squared_error: 1.5599 - val_loss: 1.6224 - val_mean_absolute_error: 0.9192 - val_mean_squared_error: 1.6224\n",
            "Epoch 797/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.5651 - mean_absolute_error: 0.9074 - mean_squared_error: 1.5651\n",
            "Epoch 797: val_loss improved from 1.62239 to 1.62204, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5590 - mean_absolute_error: 0.9054 - mean_squared_error: 1.5590 - val_loss: 1.6220 - val_mean_absolute_error: 0.9192 - val_mean_squared_error: 1.6220\n",
            "Epoch 798/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.5688 - mean_absolute_error: 0.9095 - mean_squared_error: 1.5688\n",
            "Epoch 798: val_loss did not improve from 1.62204\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5580 - mean_absolute_error: 0.9055 - mean_squared_error: 1.5580 - val_loss: 1.6222 - val_mean_absolute_error: 0.9189 - val_mean_squared_error: 1.6222\n",
            "Epoch 799/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.5510 - mean_absolute_error: 0.9026 - mean_squared_error: 1.5510\n",
            "Epoch 799: val_loss did not improve from 1.62204\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5588 - mean_absolute_error: 0.9052 - mean_squared_error: 1.5588 - val_loss: 1.6272 - val_mean_absolute_error: 0.9186 - val_mean_squared_error: 1.6272\n",
            "Epoch 800/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.5702 - mean_absolute_error: 0.9077 - mean_squared_error: 1.5702\n",
            "Epoch 800: val_loss did not improve from 1.62204\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5577 - mean_absolute_error: 0.9054 - mean_squared_error: 1.5577 - val_loss: 1.6224 - val_mean_absolute_error: 0.9202 - val_mean_squared_error: 1.6224\n",
            "Epoch 801/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.5675 - mean_absolute_error: 0.9074 - mean_squared_error: 1.5675\n",
            "Epoch 801: val_loss did not improve from 1.62204\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5576 - mean_absolute_error: 0.9047 - mean_squared_error: 1.5576 - val_loss: 1.6230 - val_mean_absolute_error: 0.9179 - val_mean_squared_error: 1.6230\n",
            "Epoch 802/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.5479 - mean_absolute_error: 0.9035 - mean_squared_error: 1.5479\n",
            "Epoch 802: val_loss did not improve from 1.62204\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5584 - mean_absolute_error: 0.9056 - mean_squared_error: 1.5584 - val_loss: 1.6245 - val_mean_absolute_error: 0.9181 - val_mean_squared_error: 1.6245\n",
            "Epoch 803/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.5663 - mean_absolute_error: 0.9071 - mean_squared_error: 1.5663\n",
            "Epoch 803: val_loss did not improve from 1.62204\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5581 - mean_absolute_error: 0.9055 - mean_squared_error: 1.5581 - val_loss: 1.6257 - val_mean_absolute_error: 0.9186 - val_mean_squared_error: 1.6257\n",
            "Epoch 804/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.5600 - mean_absolute_error: 0.9064 - mean_squared_error: 1.5600\n",
            "Epoch 804: val_loss improved from 1.62204 to 1.62182, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5567 - mean_absolute_error: 0.9048 - mean_squared_error: 1.5567 - val_loss: 1.6218 - val_mean_absolute_error: 0.9182 - val_mean_squared_error: 1.6218\n",
            "Epoch 805/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.5650 - mean_absolute_error: 0.9065 - mean_squared_error: 1.5650\n",
            "Epoch 805: val_loss did not improve from 1.62182\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5560 - mean_absolute_error: 0.9052 - mean_squared_error: 1.5560 - val_loss: 1.6220 - val_mean_absolute_error: 0.9179 - val_mean_squared_error: 1.6220\n",
            "Epoch 806/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.5714 - mean_absolute_error: 0.9079 - mean_squared_error: 1.5714\n",
            "Epoch 806: val_loss improved from 1.62182 to 1.62105, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5549 - mean_absolute_error: 0.9045 - mean_squared_error: 1.5549 - val_loss: 1.6211 - val_mean_absolute_error: 0.9185 - val_mean_squared_error: 1.6211\n",
            "Epoch 807/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.5466 - mean_absolute_error: 0.9017 - mean_squared_error: 1.5466\n",
            "Epoch 807: val_loss did not improve from 1.62105\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5556 - mean_absolute_error: 0.9049 - mean_squared_error: 1.5556 - val_loss: 1.6229 - val_mean_absolute_error: 0.9180 - val_mean_squared_error: 1.6229\n",
            "Epoch 808/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.5600 - mean_absolute_error: 0.9051 - mean_squared_error: 1.5600\n",
            "Epoch 808: val_loss improved from 1.62105 to 1.62033, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5547 - mean_absolute_error: 0.9038 - mean_squared_error: 1.5547 - val_loss: 1.6203 - val_mean_absolute_error: 0.9193 - val_mean_squared_error: 1.6203\n",
            "Epoch 809/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.5552 - mean_absolute_error: 0.9047 - mean_squared_error: 1.5552\n",
            "Epoch 809: val_loss did not improve from 1.62033\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5552 - mean_absolute_error: 0.9047 - mean_squared_error: 1.5552 - val_loss: 1.6205 - val_mean_absolute_error: 0.9182 - val_mean_squared_error: 1.6205\n",
            "Epoch 810/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.5854 - mean_absolute_error: 0.9132 - mean_squared_error: 1.5854\n",
            "Epoch 810: val_loss did not improve from 1.62033\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5560 - mean_absolute_error: 0.9051 - mean_squared_error: 1.5560 - val_loss: 1.6225 - val_mean_absolute_error: 0.9182 - val_mean_squared_error: 1.6225\n",
            "Epoch 811/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.5610 - mean_absolute_error: 0.9078 - mean_squared_error: 1.5610\n",
            "Epoch 811: val_loss improved from 1.62033 to 1.62000, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5550 - mean_absolute_error: 0.9053 - mean_squared_error: 1.5550 - val_loss: 1.6200 - val_mean_absolute_error: 0.9185 - val_mean_squared_error: 1.6200\n",
            "Epoch 812/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.5597 - mean_absolute_error: 0.9077 - mean_squared_error: 1.5597\n",
            "Epoch 812: val_loss did not improve from 1.62000\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5547 - mean_absolute_error: 0.9048 - mean_squared_error: 1.5547 - val_loss: 1.6203 - val_mean_absolute_error: 0.9180 - val_mean_squared_error: 1.6203\n",
            "Epoch 813/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.5640 - mean_absolute_error: 0.9061 - mean_squared_error: 1.5640\n",
            "Epoch 813: val_loss improved from 1.62000 to 1.61944, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5555 - mean_absolute_error: 0.9053 - mean_squared_error: 1.5555 - val_loss: 1.6194 - val_mean_absolute_error: 0.9191 - val_mean_squared_error: 1.6194\n",
            "Epoch 814/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.5563 - mean_absolute_error: 0.9047 - mean_squared_error: 1.5563\n",
            "Epoch 814: val_loss did not improve from 1.61944\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5540 - mean_absolute_error: 0.9047 - mean_squared_error: 1.5540 - val_loss: 1.6198 - val_mean_absolute_error: 0.9201 - val_mean_squared_error: 1.6198\n",
            "Epoch 815/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.5673 - mean_absolute_error: 0.9098 - mean_squared_error: 1.5673\n",
            "Epoch 815: val_loss did not improve from 1.61944\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5543 - mean_absolute_error: 0.9055 - mean_squared_error: 1.5543 - val_loss: 1.6199 - val_mean_absolute_error: 0.9200 - val_mean_squared_error: 1.6199\n",
            "Epoch 816/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.5541 - mean_absolute_error: 0.9053 - mean_squared_error: 1.5541\n",
            "Epoch 816: val_loss improved from 1.61944 to 1.61940, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5538 - mean_absolute_error: 0.9048 - mean_squared_error: 1.5538 - val_loss: 1.6194 - val_mean_absolute_error: 0.9203 - val_mean_squared_error: 1.6194\n",
            "Epoch 817/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.5521 - mean_absolute_error: 0.9043 - mean_squared_error: 1.5521\n",
            "Epoch 817: val_loss improved from 1.61940 to 1.61910, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5535 - mean_absolute_error: 0.9050 - mean_squared_error: 1.5535 - val_loss: 1.6191 - val_mean_absolute_error: 0.9184 - val_mean_squared_error: 1.6191\n",
            "Epoch 818/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.5544 - mean_absolute_error: 0.9062 - mean_squared_error: 1.5544\n",
            "Epoch 818: val_loss did not improve from 1.61910\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5538 - mean_absolute_error: 0.9055 - mean_squared_error: 1.5538 - val_loss: 1.6196 - val_mean_absolute_error: 0.9180 - val_mean_squared_error: 1.6196\n",
            "Epoch 819/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.5586 - mean_absolute_error: 0.9065 - mean_squared_error: 1.5586\n",
            "Epoch 819: val_loss improved from 1.61910 to 1.61850, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5534 - mean_absolute_error: 0.9047 - mean_squared_error: 1.5534 - val_loss: 1.6185 - val_mean_absolute_error: 0.9185 - val_mean_squared_error: 1.6185\n",
            "Epoch 820/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.5557 - mean_absolute_error: 0.9046 - mean_squared_error: 1.5557\n",
            "Epoch 820: val_loss did not improve from 1.61850\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5519 - mean_absolute_error: 0.9041 - mean_squared_error: 1.5519 - val_loss: 1.6195 - val_mean_absolute_error: 0.9208 - val_mean_squared_error: 1.6195\n",
            "Epoch 821/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.5442 - mean_absolute_error: 0.9021 - mean_squared_error: 1.5442\n",
            "Epoch 821: val_loss did not improve from 1.61850\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5514 - mean_absolute_error: 0.9044 - mean_squared_error: 1.5514 - val_loss: 1.6187 - val_mean_absolute_error: 0.9202 - val_mean_squared_error: 1.6187\n",
            "Epoch 822/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.5645 - mean_absolute_error: 0.9092 - mean_squared_error: 1.5645\n",
            "Epoch 822: val_loss did not improve from 1.61850\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5523 - mean_absolute_error: 0.9049 - mean_squared_error: 1.5523 - val_loss: 1.6189 - val_mean_absolute_error: 0.9178 - val_mean_squared_error: 1.6189\n",
            "Epoch 823/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.5601 - mean_absolute_error: 0.9071 - mean_squared_error: 1.5601\n",
            "Epoch 823: val_loss did not improve from 1.61850\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5505 - mean_absolute_error: 0.9038 - mean_squared_error: 1.5505 - val_loss: 1.6214 - val_mean_absolute_error: 0.9185 - val_mean_squared_error: 1.6214\n",
            "Epoch 824/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.5668 - mean_absolute_error: 0.9080 - mean_squared_error: 1.5668\n",
            "Epoch 824: val_loss did not improve from 1.61850\n",
            "245/245 [==============================] - 2s 8ms/step - loss: 1.5520 - mean_absolute_error: 0.9051 - mean_squared_error: 1.5520 - val_loss: 1.6207 - val_mean_absolute_error: 0.9183 - val_mean_squared_error: 1.6207\n",
            "Epoch 825/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.5532 - mean_absolute_error: 0.9056 - mean_squared_error: 1.5532\n",
            "Epoch 825: val_loss did not improve from 1.61850\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5509 - mean_absolute_error: 0.9044 - mean_squared_error: 1.5509 - val_loss: 1.6209 - val_mean_absolute_error: 0.9183 - val_mean_squared_error: 1.6209\n",
            "Epoch 826/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.5498 - mean_absolute_error: 0.9041 - mean_squared_error: 1.5498\n",
            "Epoch 826: val_loss improved from 1.61850 to 1.61776, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5511 - mean_absolute_error: 0.9043 - mean_squared_error: 1.5511 - val_loss: 1.6178 - val_mean_absolute_error: 0.9196 - val_mean_squared_error: 1.6178\n",
            "Epoch 827/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.5476 - mean_absolute_error: 0.9040 - mean_squared_error: 1.5476\n",
            "Epoch 827: val_loss did not improve from 1.61776\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5493 - mean_absolute_error: 0.9044 - mean_squared_error: 1.5493 - val_loss: 1.6255 - val_mean_absolute_error: 0.9191 - val_mean_squared_error: 1.6255\n",
            "Epoch 828/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.5482 - mean_absolute_error: 0.9036 - mean_squared_error: 1.5482\n",
            "Epoch 828: val_loss did not improve from 1.61776\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5511 - mean_absolute_error: 0.9040 - mean_squared_error: 1.5511 - val_loss: 1.6186 - val_mean_absolute_error: 0.9180 - val_mean_squared_error: 1.6186\n",
            "Epoch 829/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.5528 - mean_absolute_error: 0.9039 - mean_squared_error: 1.5528\n",
            "Epoch 829: val_loss improved from 1.61776 to 1.61740, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5500 - mean_absolute_error: 0.9040 - mean_squared_error: 1.5500 - val_loss: 1.6174 - val_mean_absolute_error: 0.9189 - val_mean_squared_error: 1.6174\n",
            "Epoch 830/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.5511 - mean_absolute_error: 0.9047 - mean_squared_error: 1.5511\n",
            "Epoch 830: val_loss did not improve from 1.61740\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5505 - mean_absolute_error: 0.9042 - mean_squared_error: 1.5505 - val_loss: 1.6180 - val_mean_absolute_error: 0.9182 - val_mean_squared_error: 1.6180\n",
            "Epoch 831/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.5500 - mean_absolute_error: 0.9047 - mean_squared_error: 1.5500\n",
            "Epoch 831: val_loss did not improve from 1.61740\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5499 - mean_absolute_error: 0.9040 - mean_squared_error: 1.5499 - val_loss: 1.6189 - val_mean_absolute_error: 0.9180 - val_mean_squared_error: 1.6189\n",
            "Epoch 832/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.5548 - mean_absolute_error: 0.9043 - mean_squared_error: 1.5548\n",
            "Epoch 832: val_loss improved from 1.61740 to 1.61693, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5498 - mean_absolute_error: 0.9042 - mean_squared_error: 1.5498 - val_loss: 1.6169 - val_mean_absolute_error: 0.9194 - val_mean_squared_error: 1.6169\n",
            "Epoch 833/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.5530 - mean_absolute_error: 0.9058 - mean_squared_error: 1.5530\n",
            "Epoch 833: val_loss did not improve from 1.61693\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5498 - mean_absolute_error: 0.9048 - mean_squared_error: 1.5498 - val_loss: 1.6192 - val_mean_absolute_error: 0.9183 - val_mean_squared_error: 1.6192\n",
            "Epoch 834/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.5446 - mean_absolute_error: 0.9045 - mean_squared_error: 1.5446\n",
            "Epoch 834: val_loss improved from 1.61693 to 1.61691, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5491 - mean_absolute_error: 0.9042 - mean_squared_error: 1.5491 - val_loss: 1.6169 - val_mean_absolute_error: 0.9200 - val_mean_squared_error: 1.6169\n",
            "Epoch 835/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.5488 - mean_absolute_error: 0.9045 - mean_squared_error: 1.5488\n",
            "Epoch 835: val_loss improved from 1.61691 to 1.61613, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5494 - mean_absolute_error: 0.9053 - mean_squared_error: 1.5494 - val_loss: 1.6161 - val_mean_absolute_error: 0.9188 - val_mean_squared_error: 1.6161\n",
            "Epoch 836/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.5492 - mean_absolute_error: 0.9035 - mean_squared_error: 1.5492\n",
            "Epoch 836: val_loss did not improve from 1.61613\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5483 - mean_absolute_error: 0.9039 - mean_squared_error: 1.5483 - val_loss: 1.6191 - val_mean_absolute_error: 0.9183 - val_mean_squared_error: 1.6191\n",
            "Epoch 837/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.5305 - mean_absolute_error: 0.8988 - mean_squared_error: 1.5305\n",
            "Epoch 837: val_loss did not improve from 1.61613\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5493 - mean_absolute_error: 0.9043 - mean_squared_error: 1.5493 - val_loss: 1.6223 - val_mean_absolute_error: 0.9190 - val_mean_squared_error: 1.6223\n",
            "Epoch 838/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.5426 - mean_absolute_error: 0.9032 - mean_squared_error: 1.5426\n",
            "Epoch 838: val_loss improved from 1.61613 to 1.61581, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5488 - mean_absolute_error: 0.9036 - mean_squared_error: 1.5488 - val_loss: 1.6158 - val_mean_absolute_error: 0.9194 - val_mean_squared_error: 1.6158\n",
            "Epoch 839/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 1.5653 - mean_absolute_error: 0.9088 - mean_squared_error: 1.5653\n",
            "Epoch 839: val_loss did not improve from 1.61581\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5484 - mean_absolute_error: 0.9045 - mean_squared_error: 1.5484 - val_loss: 1.6177 - val_mean_absolute_error: 0.9182 - val_mean_squared_error: 1.6177\n",
            "Epoch 840/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.5398 - mean_absolute_error: 0.9028 - mean_squared_error: 1.5398\n",
            "Epoch 840: val_loss did not improve from 1.61581\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5484 - mean_absolute_error: 0.9038 - mean_squared_error: 1.5484 - val_loss: 1.6164 - val_mean_absolute_error: 0.9183 - val_mean_squared_error: 1.6164\n",
            "Epoch 841/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.5403 - mean_absolute_error: 0.9013 - mean_squared_error: 1.5403\n",
            "Epoch 841: val_loss did not improve from 1.61581\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5476 - mean_absolute_error: 0.9046 - mean_squared_error: 1.5476 - val_loss: 1.6166 - val_mean_absolute_error: 0.9183 - val_mean_squared_error: 1.6166\n",
            "Epoch 842/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.5524 - mean_absolute_error: 0.9055 - mean_squared_error: 1.5524\n",
            "Epoch 842: val_loss did not improve from 1.61581\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5469 - mean_absolute_error: 0.9038 - mean_squared_error: 1.5469 - val_loss: 1.6192 - val_mean_absolute_error: 0.9184 - val_mean_squared_error: 1.6192\n",
            "Epoch 843/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.5506 - mean_absolute_error: 0.9053 - mean_squared_error: 1.5506\n",
            "Epoch 843: val_loss improved from 1.61581 to 1.61525, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5471 - mean_absolute_error: 0.9043 - mean_squared_error: 1.5471 - val_loss: 1.6152 - val_mean_absolute_error: 0.9195 - val_mean_squared_error: 1.6152\n",
            "Epoch 844/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.5423 - mean_absolute_error: 0.9023 - mean_squared_error: 1.5423\n",
            "Epoch 844: val_loss did not improve from 1.61525\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5476 - mean_absolute_error: 0.9045 - mean_squared_error: 1.5476 - val_loss: 1.6168 - val_mean_absolute_error: 0.9181 - val_mean_squared_error: 1.6168\n",
            "Epoch 845/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.5470 - mean_absolute_error: 0.9040 - mean_squared_error: 1.5470\n",
            "Epoch 845: val_loss did not improve from 1.61525\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5470 - mean_absolute_error: 0.9040 - mean_squared_error: 1.5470 - val_loss: 1.6155 - val_mean_absolute_error: 0.9185 - val_mean_squared_error: 1.6155\n",
            "Epoch 846/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.5450 - mean_absolute_error: 0.9038 - mean_squared_error: 1.5450\n",
            "Epoch 846: val_loss did not improve from 1.61525\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5465 - mean_absolute_error: 0.9039 - mean_squared_error: 1.5465 - val_loss: 1.6189 - val_mean_absolute_error: 0.9181 - val_mean_squared_error: 1.6189\n",
            "Epoch 847/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.5447 - mean_absolute_error: 0.9031 - mean_squared_error: 1.5447\n",
            "Epoch 847: val_loss improved from 1.61525 to 1.61512, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5468 - mean_absolute_error: 0.9038 - mean_squared_error: 1.5468 - val_loss: 1.6151 - val_mean_absolute_error: 0.9206 - val_mean_squared_error: 1.6151\n",
            "Epoch 848/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.5327 - mean_absolute_error: 0.8993 - mean_squared_error: 1.5327\n",
            "Epoch 848: val_loss did not improve from 1.61512\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5471 - mean_absolute_error: 0.9041 - mean_squared_error: 1.5471 - val_loss: 1.6160 - val_mean_absolute_error: 0.9180 - val_mean_squared_error: 1.6160\n",
            "Epoch 849/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.5424 - mean_absolute_error: 0.9024 - mean_squared_error: 1.5424\n",
            "Epoch 849: val_loss did not improve from 1.61512\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5459 - mean_absolute_error: 0.9037 - mean_squared_error: 1.5459 - val_loss: 1.6157 - val_mean_absolute_error: 0.9182 - val_mean_squared_error: 1.6157\n",
            "Epoch 850/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.5501 - mean_absolute_error: 0.9033 - mean_squared_error: 1.5501\n",
            "Epoch 850: val_loss improved from 1.61512 to 1.61434, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5458 - mean_absolute_error: 0.9038 - mean_squared_error: 1.5458 - val_loss: 1.6143 - val_mean_absolute_error: 0.9194 - val_mean_squared_error: 1.6143\n",
            "Epoch 851/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.5609 - mean_absolute_error: 0.9073 - mean_squared_error: 1.5609\n",
            "Epoch 851: val_loss did not improve from 1.61434\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5470 - mean_absolute_error: 0.9043 - mean_squared_error: 1.5470 - val_loss: 1.6152 - val_mean_absolute_error: 0.9186 - val_mean_squared_error: 1.6152\n",
            "Epoch 852/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.5451 - mean_absolute_error: 0.9024 - mean_squared_error: 1.5451\n",
            "Epoch 852: val_loss did not improve from 1.61434\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5452 - mean_absolute_error: 0.9032 - mean_squared_error: 1.5452 - val_loss: 1.6144 - val_mean_absolute_error: 0.9205 - val_mean_squared_error: 1.6144\n",
            "Epoch 853/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.5407 - mean_absolute_error: 0.9038 - mean_squared_error: 1.5407\n",
            "Epoch 853: val_loss improved from 1.61434 to 1.61406, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5458 - mean_absolute_error: 0.9042 - mean_squared_error: 1.5458 - val_loss: 1.6141 - val_mean_absolute_error: 0.9196 - val_mean_squared_error: 1.6141\n",
            "Epoch 854/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.5616 - mean_absolute_error: 0.9081 - mean_squared_error: 1.5616\n",
            "Epoch 854: val_loss did not improve from 1.61406\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5448 - mean_absolute_error: 0.9033 - mean_squared_error: 1.5448 - val_loss: 1.6198 - val_mean_absolute_error: 0.9189 - val_mean_squared_error: 1.6198\n",
            "Epoch 855/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.5378 - mean_absolute_error: 0.9037 - mean_squared_error: 1.5378\n",
            "Epoch 855: val_loss improved from 1.61406 to 1.61365, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5461 - mean_absolute_error: 0.9048 - mean_squared_error: 1.5461 - val_loss: 1.6137 - val_mean_absolute_error: 0.9197 - val_mean_squared_error: 1.6137\n",
            "Epoch 856/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.5422 - mean_absolute_error: 0.9028 - mean_squared_error: 1.5422\n",
            "Epoch 856: val_loss did not improve from 1.61365\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5445 - mean_absolute_error: 0.9038 - mean_squared_error: 1.5445 - val_loss: 1.6141 - val_mean_absolute_error: 0.9183 - val_mean_squared_error: 1.6141\n",
            "Epoch 857/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.5685 - mean_absolute_error: 0.9099 - mean_squared_error: 1.5685\n",
            "Epoch 857: val_loss did not improve from 1.61365\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5448 - mean_absolute_error: 0.9040 - mean_squared_error: 1.5448 - val_loss: 1.6138 - val_mean_absolute_error: 0.9192 - val_mean_squared_error: 1.6138\n",
            "Epoch 858/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.5764 - mean_absolute_error: 0.9127 - mean_squared_error: 1.5764\n",
            "Epoch 858: val_loss did not improve from 1.61365\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5430 - mean_absolute_error: 0.9032 - mean_squared_error: 1.5430 - val_loss: 1.6141 - val_mean_absolute_error: 0.9181 - val_mean_squared_error: 1.6141\n",
            "Epoch 859/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.5443 - mean_absolute_error: 0.9032 - mean_squared_error: 1.5443\n",
            "Epoch 859: val_loss did not improve from 1.61365\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5440 - mean_absolute_error: 0.9032 - mean_squared_error: 1.5440 - val_loss: 1.6157 - val_mean_absolute_error: 0.9179 - val_mean_squared_error: 1.6157\n",
            "Epoch 860/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.5522 - mean_absolute_error: 0.9070 - mean_squared_error: 1.5522\n",
            "Epoch 860: val_loss did not improve from 1.61365\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5452 - mean_absolute_error: 0.9040 - mean_squared_error: 1.5452 - val_loss: 1.6172 - val_mean_absolute_error: 0.9182 - val_mean_squared_error: 1.6172\n",
            "Epoch 861/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.5519 - mean_absolute_error: 0.9060 - mean_squared_error: 1.5519\n",
            "Epoch 861: val_loss improved from 1.61365 to 1.61357, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5441 - mean_absolute_error: 0.9037 - mean_squared_error: 1.5441 - val_loss: 1.6136 - val_mean_absolute_error: 0.9184 - val_mean_squared_error: 1.6136\n",
            "Epoch 862/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.5338 - mean_absolute_error: 0.9005 - mean_squared_error: 1.5338\n",
            "Epoch 862: val_loss did not improve from 1.61357\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5417 - mean_absolute_error: 0.9033 - mean_squared_error: 1.5417 - val_loss: 1.6255 - val_mean_absolute_error: 0.9198 - val_mean_squared_error: 1.6255\n",
            "Epoch 863/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.5308 - mean_absolute_error: 0.8994 - mean_squared_error: 1.5308\n",
            "Epoch 863: val_loss improved from 1.61357 to 1.61331, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5448 - mean_absolute_error: 0.9035 - mean_squared_error: 1.5448 - val_loss: 1.6133 - val_mean_absolute_error: 0.9183 - val_mean_squared_error: 1.6133\n",
            "Epoch 864/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.5441 - mean_absolute_error: 0.9033 - mean_squared_error: 1.5441\n",
            "Epoch 864: val_loss improved from 1.61331 to 1.61314, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5425 - mean_absolute_error: 0.9027 - mean_squared_error: 1.5425 - val_loss: 1.6131 - val_mean_absolute_error: 0.9206 - val_mean_squared_error: 1.6131\n",
            "Epoch 865/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.5509 - mean_absolute_error: 0.9046 - mean_squared_error: 1.5509\n",
            "Epoch 865: val_loss did not improve from 1.61314\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5422 - mean_absolute_error: 0.9034 - mean_squared_error: 1.5422 - val_loss: 1.6133 - val_mean_absolute_error: 0.9206 - val_mean_squared_error: 1.6133\n",
            "Epoch 866/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.5559 - mean_absolute_error: 0.9079 - mean_squared_error: 1.5559\n",
            "Epoch 866: val_loss did not improve from 1.61314\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5429 - mean_absolute_error: 0.9033 - mean_squared_error: 1.5429 - val_loss: 1.6168 - val_mean_absolute_error: 0.9183 - val_mean_squared_error: 1.6168\n",
            "Epoch 867/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.5390 - mean_absolute_error: 0.9023 - mean_squared_error: 1.5390\n",
            "Epoch 867: val_loss did not improve from 1.61314\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5434 - mean_absolute_error: 0.9035 - mean_squared_error: 1.5434 - val_loss: 1.6157 - val_mean_absolute_error: 0.9183 - val_mean_squared_error: 1.6157\n",
            "Epoch 868/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.5419 - mean_absolute_error: 0.9037 - mean_squared_error: 1.5419\n",
            "Epoch 868: val_loss improved from 1.61314 to 1.61294, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5422 - mean_absolute_error: 0.9038 - mean_squared_error: 1.5422 - val_loss: 1.6129 - val_mean_absolute_error: 0.9208 - val_mean_squared_error: 1.6129\n",
            "Epoch 869/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.5336 - mean_absolute_error: 0.9014 - mean_squared_error: 1.5336\n",
            "Epoch 869: val_loss improved from 1.61294 to 1.61231, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5421 - mean_absolute_error: 0.9032 - mean_squared_error: 1.5421 - val_loss: 1.6123 - val_mean_absolute_error: 0.9195 - val_mean_squared_error: 1.6123\n",
            "Epoch 870/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.5493 - mean_absolute_error: 0.9054 - mean_squared_error: 1.5493\n",
            "Epoch 870: val_loss did not improve from 1.61231\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5431 - mean_absolute_error: 0.9033 - mean_squared_error: 1.5431 - val_loss: 1.6134 - val_mean_absolute_error: 0.9180 - val_mean_squared_error: 1.6134\n",
            "Epoch 871/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.5506 - mean_absolute_error: 0.9034 - mean_squared_error: 1.5506\n",
            "Epoch 871: val_loss did not improve from 1.61231\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5412 - mean_absolute_error: 0.9030 - mean_squared_error: 1.5412 - val_loss: 1.6190 - val_mean_absolute_error: 0.9187 - val_mean_squared_error: 1.6190\n",
            "Epoch 872/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.5438 - mean_absolute_error: 0.9024 - mean_squared_error: 1.5438\n",
            "Epoch 872: val_loss did not improve from 1.61231\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5420 - mean_absolute_error: 0.9028 - mean_squared_error: 1.5420 - val_loss: 1.6124 - val_mean_absolute_error: 0.9214 - val_mean_squared_error: 1.6124\n",
            "Epoch 873/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.5417 - mean_absolute_error: 0.9039 - mean_squared_error: 1.5417\n",
            "Epoch 873: val_loss did not improve from 1.61231\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5417 - mean_absolute_error: 0.9041 - mean_squared_error: 1.5417 - val_loss: 1.6130 - val_mean_absolute_error: 0.9183 - val_mean_squared_error: 1.6130\n",
            "Epoch 874/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.5451 - mean_absolute_error: 0.9041 - mean_squared_error: 1.5451\n",
            "Epoch 874: val_loss did not improve from 1.61231\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5417 - mean_absolute_error: 0.9028 - mean_squared_error: 1.5417 - val_loss: 1.6131 - val_mean_absolute_error: 0.9184 - val_mean_squared_error: 1.6131\n",
            "Epoch 875/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.5404 - mean_absolute_error: 0.9024 - mean_squared_error: 1.5404\n",
            "Epoch 875: val_loss did not improve from 1.61231\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5409 - mean_absolute_error: 0.9029 - mean_squared_error: 1.5409 - val_loss: 1.6134 - val_mean_absolute_error: 0.9182 - val_mean_squared_error: 1.6134\n",
            "Epoch 876/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.5419 - mean_absolute_error: 0.9015 - mean_squared_error: 1.5419\n",
            "Epoch 876: val_loss improved from 1.61231 to 1.61191, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5404 - mean_absolute_error: 0.9026 - mean_squared_error: 1.5404 - val_loss: 1.6119 - val_mean_absolute_error: 0.9189 - val_mean_squared_error: 1.6119\n",
            "Epoch 877/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.5480 - mean_absolute_error: 0.9048 - mean_squared_error: 1.5480\n",
            "Epoch 877: val_loss did not improve from 1.61191\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5401 - mean_absolute_error: 0.9036 - mean_squared_error: 1.5401 - val_loss: 1.6126 - val_mean_absolute_error: 0.9180 - val_mean_squared_error: 1.6126\n",
            "Epoch 878/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.5364 - mean_absolute_error: 0.9024 - mean_squared_error: 1.5364\n",
            "Epoch 878: val_loss did not improve from 1.61191\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5406 - mean_absolute_error: 0.9029 - mean_squared_error: 1.5406 - val_loss: 1.6129 - val_mean_absolute_error: 0.9176 - val_mean_squared_error: 1.6129\n",
            "Epoch 879/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.5388 - mean_absolute_error: 0.9021 - mean_squared_error: 1.5388\n",
            "Epoch 879: val_loss improved from 1.61191 to 1.61116, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5405 - mean_absolute_error: 0.9025 - mean_squared_error: 1.5405 - val_loss: 1.6112 - val_mean_absolute_error: 0.9189 - val_mean_squared_error: 1.6112\n",
            "Epoch 880/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.5403 - mean_absolute_error: 0.9024 - mean_squared_error: 1.5403\n",
            "Epoch 880: val_loss did not improve from 1.61116\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5400 - mean_absolute_error: 0.9030 - mean_squared_error: 1.5400 - val_loss: 1.6164 - val_mean_absolute_error: 0.9184 - val_mean_squared_error: 1.6164\n",
            "Epoch 881/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 1.5604 - mean_absolute_error: 0.9109 - mean_squared_error: 1.5604\n",
            "Epoch 881: val_loss did not improve from 1.61116\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5406 - mean_absolute_error: 0.9033 - mean_squared_error: 1.5406 - val_loss: 1.6126 - val_mean_absolute_error: 0.9179 - val_mean_squared_error: 1.6126\n",
            "Epoch 882/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.5156 - mean_absolute_error: 0.8990 - mean_squared_error: 1.5156\n",
            "Epoch 882: val_loss improved from 1.61116 to 1.61115, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5398 - mean_absolute_error: 0.9030 - mean_squared_error: 1.5398 - val_loss: 1.6111 - val_mean_absolute_error: 0.9200 - val_mean_squared_error: 1.6111\n",
            "Epoch 883/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.5486 - mean_absolute_error: 0.9055 - mean_squared_error: 1.5486\n",
            "Epoch 883: val_loss improved from 1.61115 to 1.61080, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5396 - mean_absolute_error: 0.9028 - mean_squared_error: 1.5396 - val_loss: 1.6108 - val_mean_absolute_error: 0.9200 - val_mean_squared_error: 1.6108\n",
            "Epoch 884/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.5496 - mean_absolute_error: 0.9038 - mean_squared_error: 1.5496\n",
            "Epoch 884: val_loss did not improve from 1.61080\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5406 - mean_absolute_error: 0.9034 - mean_squared_error: 1.5406 - val_loss: 1.6141 - val_mean_absolute_error: 0.9183 - val_mean_squared_error: 1.6141\n",
            "Epoch 885/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.5426 - mean_absolute_error: 0.9043 - mean_squared_error: 1.5426\n",
            "Epoch 885: val_loss improved from 1.61080 to 1.61079, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5396 - mean_absolute_error: 0.9032 - mean_squared_error: 1.5396 - val_loss: 1.6108 - val_mean_absolute_error: 0.9185 - val_mean_squared_error: 1.6108\n",
            "Epoch 886/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.5459 - mean_absolute_error: 0.9037 - mean_squared_error: 1.5459\n",
            "Epoch 886: val_loss did not improve from 1.61079\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5390 - mean_absolute_error: 0.9024 - mean_squared_error: 1.5390 - val_loss: 1.6138 - val_mean_absolute_error: 0.9178 - val_mean_squared_error: 1.6138\n",
            "Epoch 887/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.5351 - mean_absolute_error: 0.9015 - mean_squared_error: 1.5351\n",
            "Epoch 887: val_loss did not improve from 1.61079\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5392 - mean_absolute_error: 0.9026 - mean_squared_error: 1.5392 - val_loss: 1.6130 - val_mean_absolute_error: 0.9178 - val_mean_squared_error: 1.6130\n",
            "Epoch 888/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.5560 - mean_absolute_error: 0.9069 - mean_squared_error: 1.5560\n",
            "Epoch 888: val_loss did not improve from 1.61079\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5391 - mean_absolute_error: 0.9030 - mean_squared_error: 1.5391 - val_loss: 1.6144 - val_mean_absolute_error: 0.9182 - val_mean_squared_error: 1.6144\n",
            "Epoch 889/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.5376 - mean_absolute_error: 0.9025 - mean_squared_error: 1.5376\n",
            "Epoch 889: val_loss improved from 1.61079 to 1.60999, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5392 - mean_absolute_error: 0.9028 - mean_squared_error: 1.5392 - val_loss: 1.6100 - val_mean_absolute_error: 0.9193 - val_mean_squared_error: 1.6100\n",
            "Epoch 890/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.5386 - mean_absolute_error: 0.9021 - mean_squared_error: 1.5386\n",
            "Epoch 890: val_loss improved from 1.60999 to 1.60995, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5386 - mean_absolute_error: 0.9021 - mean_squared_error: 1.5386 - val_loss: 1.6099 - val_mean_absolute_error: 0.9183 - val_mean_squared_error: 1.6099\n",
            "Epoch 891/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.5242 - mean_absolute_error: 0.8974 - mean_squared_error: 1.5242\n",
            "Epoch 891: val_loss improved from 1.60995 to 1.60973, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5387 - mean_absolute_error: 0.9024 - mean_squared_error: 1.5387 - val_loss: 1.6097 - val_mean_absolute_error: 0.9191 - val_mean_squared_error: 1.6097\n",
            "Epoch 892/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.5408 - mean_absolute_error: 0.9025 - mean_squared_error: 1.5408\n",
            "Epoch 892: val_loss did not improve from 1.60973\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5391 - mean_absolute_error: 0.9023 - mean_squared_error: 1.5391 - val_loss: 1.6108 - val_mean_absolute_error: 0.9183 - val_mean_squared_error: 1.6108\n",
            "Epoch 893/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.5517 - mean_absolute_error: 0.9044 - mean_squared_error: 1.5517\n",
            "Epoch 893: val_loss did not improve from 1.60973\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5375 - mean_absolute_error: 0.9029 - mean_squared_error: 1.5375 - val_loss: 1.6125 - val_mean_absolute_error: 0.9180 - val_mean_squared_error: 1.6125\n",
            "Epoch 894/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.5426 - mean_absolute_error: 0.9056 - mean_squared_error: 1.5426\n",
            "Epoch 894: val_loss improved from 1.60973 to 1.60935, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5382 - mean_absolute_error: 0.9030 - mean_squared_error: 1.5382 - val_loss: 1.6094 - val_mean_absolute_error: 0.9188 - val_mean_squared_error: 1.6094\n",
            "Epoch 895/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.5339 - mean_absolute_error: 0.9021 - mean_squared_error: 1.5339\n",
            "Epoch 895: val_loss improved from 1.60935 to 1.60893, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5382 - mean_absolute_error: 0.9028 - mean_squared_error: 1.5382 - val_loss: 1.6089 - val_mean_absolute_error: 0.9187 - val_mean_squared_error: 1.6089\n",
            "Epoch 896/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.5299 - mean_absolute_error: 0.9004 - mean_squared_error: 1.5299\n",
            "Epoch 896: val_loss improved from 1.60893 to 1.60890, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5371 - mean_absolute_error: 0.9025 - mean_squared_error: 1.5371 - val_loss: 1.6089 - val_mean_absolute_error: 0.9196 - val_mean_squared_error: 1.6089\n",
            "Epoch 897/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.5171 - mean_absolute_error: 0.8983 - mean_squared_error: 1.5171\n",
            "Epoch 897: val_loss did not improve from 1.60890\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5374 - mean_absolute_error: 0.9027 - mean_squared_error: 1.5374 - val_loss: 1.6127 - val_mean_absolute_error: 0.9178 - val_mean_squared_error: 1.6127\n",
            "Epoch 898/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.5276 - mean_absolute_error: 0.8994 - mean_squared_error: 1.5276\n",
            "Epoch 898: val_loss did not improve from 1.60890\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5378 - mean_absolute_error: 0.9023 - mean_squared_error: 1.5378 - val_loss: 1.6107 - val_mean_absolute_error: 0.9180 - val_mean_squared_error: 1.6107\n",
            "Epoch 899/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.5368 - mean_absolute_error: 0.9024 - mean_squared_error: 1.5368\n",
            "Epoch 899: val_loss improved from 1.60890 to 1.60879, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5375 - mean_absolute_error: 0.9024 - mean_squared_error: 1.5375 - val_loss: 1.6088 - val_mean_absolute_error: 0.9187 - val_mean_squared_error: 1.6088\n",
            "Epoch 900/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.5315 - mean_absolute_error: 0.9010 - mean_squared_error: 1.5315\n",
            "Epoch 900: val_loss did not improve from 1.60879\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5360 - mean_absolute_error: 0.9024 - mean_squared_error: 1.5360 - val_loss: 1.6093 - val_mean_absolute_error: 0.9181 - val_mean_squared_error: 1.6093\n",
            "Epoch 901/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.5377 - mean_absolute_error: 0.9020 - mean_squared_error: 1.5377\n",
            "Epoch 901: val_loss did not improve from 1.60879\n",
            "245/245 [==============================] - 2s 9ms/step - loss: 1.5362 - mean_absolute_error: 0.9019 - mean_squared_error: 1.5362 - val_loss: 1.6114 - val_mean_absolute_error: 0.9178 - val_mean_squared_error: 1.6114\n",
            "Epoch 902/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.5331 - mean_absolute_error: 0.9000 - mean_squared_error: 1.5331\n",
            "Epoch 902: val_loss did not improve from 1.60879\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5364 - mean_absolute_error: 0.9025 - mean_squared_error: 1.5364 - val_loss: 1.6091 - val_mean_absolute_error: 0.9187 - val_mean_squared_error: 1.6091\n",
            "Epoch 903/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.5319 - mean_absolute_error: 0.9013 - mean_squared_error: 1.5319\n",
            "Epoch 903: val_loss did not improve from 1.60879\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5361 - mean_absolute_error: 0.9027 - mean_squared_error: 1.5361 - val_loss: 1.6122 - val_mean_absolute_error: 0.9176 - val_mean_squared_error: 1.6122\n",
            "Epoch 904/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.5458 - mean_absolute_error: 0.9041 - mean_squared_error: 1.5458\n",
            "Epoch 904: val_loss did not improve from 1.60879\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5360 - mean_absolute_error: 0.9017 - mean_squared_error: 1.5360 - val_loss: 1.6099 - val_mean_absolute_error: 0.9181 - val_mean_squared_error: 1.6099\n",
            "Epoch 905/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.5201 - mean_absolute_error: 0.8972 - mean_squared_error: 1.5201\n",
            "Epoch 905: val_loss did not improve from 1.60879\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5359 - mean_absolute_error: 0.9022 - mean_squared_error: 1.5359 - val_loss: 1.6116 - val_mean_absolute_error: 0.9177 - val_mean_squared_error: 1.6116\n",
            "Epoch 906/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.5212 - mean_absolute_error: 0.8980 - mean_squared_error: 1.5212\n",
            "Epoch 906: val_loss improved from 1.60879 to 1.60850, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5362 - mean_absolute_error: 0.9022 - mean_squared_error: 1.5362 - val_loss: 1.6085 - val_mean_absolute_error: 0.9184 - val_mean_squared_error: 1.6085\n",
            "Epoch 907/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.5315 - mean_absolute_error: 0.9039 - mean_squared_error: 1.5315\n",
            "Epoch 907: val_loss improved from 1.60850 to 1.60820, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5356 - mean_absolute_error: 0.9026 - mean_squared_error: 1.5356 - val_loss: 1.6082 - val_mean_absolute_error: 0.9199 - val_mean_squared_error: 1.6082\n",
            "Epoch 908/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.5351 - mean_absolute_error: 0.9018 - mean_squared_error: 1.5351\n",
            "Epoch 908: val_loss improved from 1.60820 to 1.60812, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5351 - mean_absolute_error: 0.9018 - mean_squared_error: 1.5351 - val_loss: 1.6081 - val_mean_absolute_error: 0.9187 - val_mean_squared_error: 1.6081\n",
            "Epoch 909/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.5261 - mean_absolute_error: 0.8997 - mean_squared_error: 1.5261\n",
            "Epoch 909: val_loss did not improve from 1.60812\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5355 - mean_absolute_error: 0.9019 - mean_squared_error: 1.5355 - val_loss: 1.6103 - val_mean_absolute_error: 0.9178 - val_mean_squared_error: 1.6103\n",
            "Epoch 910/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.5287 - mean_absolute_error: 0.9020 - mean_squared_error: 1.5287\n",
            "Epoch 910: val_loss did not improve from 1.60812\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5355 - mean_absolute_error: 0.9023 - mean_squared_error: 1.5355 - val_loss: 1.6096 - val_mean_absolute_error: 0.9180 - val_mean_squared_error: 1.6096\n",
            "Epoch 911/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.5453 - mean_absolute_error: 0.9034 - mean_squared_error: 1.5453\n",
            "Epoch 911: val_loss improved from 1.60812 to 1.60740, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5349 - mean_absolute_error: 0.9018 - mean_squared_error: 1.5349 - val_loss: 1.6074 - val_mean_absolute_error: 0.9190 - val_mean_squared_error: 1.6074\n",
            "Epoch 912/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.5381 - mean_absolute_error: 0.9036 - mean_squared_error: 1.5381\n",
            "Epoch 912: val_loss did not improve from 1.60740\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5354 - mean_absolute_error: 0.9021 - mean_squared_error: 1.5354 - val_loss: 1.6076 - val_mean_absolute_error: 0.9184 - val_mean_squared_error: 1.6076\n",
            "Epoch 913/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.5308 - mean_absolute_error: 0.8998 - mean_squared_error: 1.5308\n",
            "Epoch 913: val_loss did not improve from 1.60740\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5341 - mean_absolute_error: 0.9016 - mean_squared_error: 1.5341 - val_loss: 1.6081 - val_mean_absolute_error: 0.9184 - val_mean_squared_error: 1.6081\n",
            "Epoch 914/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.5428 - mean_absolute_error: 0.9040 - mean_squared_error: 1.5428\n",
            "Epoch 914: val_loss improved from 1.60740 to 1.60737, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5345 - mean_absolute_error: 0.9017 - mean_squared_error: 1.5345 - val_loss: 1.6074 - val_mean_absolute_error: 0.9183 - val_mean_squared_error: 1.6074\n",
            "Epoch 915/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.5359 - mean_absolute_error: 0.9031 - mean_squared_error: 1.5359\n",
            "Epoch 915: val_loss did not improve from 1.60737\n",
            "245/245 [==============================] - 2s 7ms/step - loss: 1.5349 - mean_absolute_error: 0.9024 - mean_squared_error: 1.5349 - val_loss: 1.6080 - val_mean_absolute_error: 0.9177 - val_mean_squared_error: 1.6080\n",
            "Epoch 916/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.5275 - mean_absolute_error: 0.8982 - mean_squared_error: 1.5275\n",
            "Epoch 916: val_loss did not improve from 1.60737\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5336 - mean_absolute_error: 0.9010 - mean_squared_error: 1.5336 - val_loss: 1.6089 - val_mean_absolute_error: 0.9173 - val_mean_squared_error: 1.6089\n",
            "Epoch 917/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.5258 - mean_absolute_error: 0.9005 - mean_squared_error: 1.5258\n",
            "Epoch 917: val_loss did not improve from 1.60737\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5336 - mean_absolute_error: 0.9017 - mean_squared_error: 1.5336 - val_loss: 1.6094 - val_mean_absolute_error: 0.9173 - val_mean_squared_error: 1.6094\n",
            "Epoch 918/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.5321 - mean_absolute_error: 0.8983 - mean_squared_error: 1.5321\n",
            "Epoch 918: val_loss improved from 1.60737 to 1.60710, saving model to best_model3.h5\n",
            "245/245 [==============================] - 2s 8ms/step - loss: 1.5342 - mean_absolute_error: 0.9017 - mean_squared_error: 1.5342 - val_loss: 1.6071 - val_mean_absolute_error: 0.9180 - val_mean_squared_error: 1.6071\n",
            "Epoch 919/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.5356 - mean_absolute_error: 0.9023 - mean_squared_error: 1.5356\n",
            "Epoch 919: val_loss did not improve from 1.60710\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5345 - mean_absolute_error: 0.9017 - mean_squared_error: 1.5345 - val_loss: 1.6073 - val_mean_absolute_error: 0.9177 - val_mean_squared_error: 1.6073\n",
            "Epoch 920/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.5291 - mean_absolute_error: 0.9014 - mean_squared_error: 1.5291\n",
            "Epoch 920: val_loss did not improve from 1.60710\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5330 - mean_absolute_error: 0.9017 - mean_squared_error: 1.5330 - val_loss: 1.6074 - val_mean_absolute_error: 0.9178 - val_mean_squared_error: 1.6074\n",
            "Epoch 921/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.5191 - mean_absolute_error: 0.8979 - mean_squared_error: 1.5191\n",
            "Epoch 921: val_loss improved from 1.60710 to 1.60667, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5327 - mean_absolute_error: 0.9014 - mean_squared_error: 1.5327 - val_loss: 1.6067 - val_mean_absolute_error: 0.9178 - val_mean_squared_error: 1.6067\n",
            "Epoch 922/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.5444 - mean_absolute_error: 0.9045 - mean_squared_error: 1.5444\n",
            "Epoch 922: val_loss did not improve from 1.60667\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5330 - mean_absolute_error: 0.9013 - mean_squared_error: 1.5330 - val_loss: 1.6071 - val_mean_absolute_error: 0.9184 - val_mean_squared_error: 1.6071\n",
            "Epoch 923/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.5467 - mean_absolute_error: 0.9067 - mean_squared_error: 1.5467\n",
            "Epoch 923: val_loss did not improve from 1.60667\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5334 - mean_absolute_error: 0.9019 - mean_squared_error: 1.5334 - val_loss: 1.6118 - val_mean_absolute_error: 0.9179 - val_mean_squared_error: 1.6118\n",
            "Epoch 924/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.5220 - mean_absolute_error: 0.8982 - mean_squared_error: 1.5220\n",
            "Epoch 924: val_loss did not improve from 1.60667\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5331 - mean_absolute_error: 0.9019 - mean_squared_error: 1.5331 - val_loss: 1.6076 - val_mean_absolute_error: 0.9180 - val_mean_squared_error: 1.6076\n",
            "Epoch 925/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.5312 - mean_absolute_error: 0.9000 - mean_squared_error: 1.5312\n",
            "Epoch 925: val_loss did not improve from 1.60667\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5317 - mean_absolute_error: 0.9012 - mean_squared_error: 1.5317 - val_loss: 1.6084 - val_mean_absolute_error: 0.9179 - val_mean_squared_error: 1.6084\n",
            "Epoch 926/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.5307 - mean_absolute_error: 0.9011 - mean_squared_error: 1.5307\n",
            "Epoch 926: val_loss improved from 1.60667 to 1.60582, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5327 - mean_absolute_error: 0.9019 - mean_squared_error: 1.5327 - val_loss: 1.6058 - val_mean_absolute_error: 0.9189 - val_mean_squared_error: 1.6058\n",
            "Epoch 927/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.5420 - mean_absolute_error: 0.9069 - mean_squared_error: 1.5420\n",
            "Epoch 927: val_loss did not improve from 1.60582\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5330 - mean_absolute_error: 0.9017 - mean_squared_error: 1.5330 - val_loss: 1.6065 - val_mean_absolute_error: 0.9175 - val_mean_squared_error: 1.6065\n",
            "Epoch 928/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.5278 - mean_absolute_error: 0.9000 - mean_squared_error: 1.5278\n",
            "Epoch 928: val_loss improved from 1.60582 to 1.60577, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5315 - mean_absolute_error: 0.9004 - mean_squared_error: 1.5315 - val_loss: 1.6058 - val_mean_absolute_error: 0.9185 - val_mean_squared_error: 1.6058\n",
            "Epoch 929/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.5344 - mean_absolute_error: 0.9021 - mean_squared_error: 1.5344\n",
            "Epoch 929: val_loss did not improve from 1.60577\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5319 - mean_absolute_error: 0.9017 - mean_squared_error: 1.5319 - val_loss: 1.6078 - val_mean_absolute_error: 0.9213 - val_mean_squared_error: 1.6078\n",
            "Epoch 930/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.5307 - mean_absolute_error: 0.9008 - mean_squared_error: 1.5307\n",
            "Epoch 930: val_loss did not improve from 1.60577\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5307 - mean_absolute_error: 0.9008 - mean_squared_error: 1.5307 - val_loss: 1.6098 - val_mean_absolute_error: 0.9174 - val_mean_squared_error: 1.6098\n",
            "Epoch 931/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.5260 - mean_absolute_error: 0.8996 - mean_squared_error: 1.5260\n",
            "Epoch 931: val_loss did not improve from 1.60577\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5313 - mean_absolute_error: 0.9011 - mean_squared_error: 1.5313 - val_loss: 1.6097 - val_mean_absolute_error: 0.9173 - val_mean_squared_error: 1.6097\n",
            "Epoch 932/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.5242 - mean_absolute_error: 0.8989 - mean_squared_error: 1.5242\n",
            "Epoch 932: val_loss did not improve from 1.60577\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5309 - mean_absolute_error: 0.9012 - mean_squared_error: 1.5309 - val_loss: 1.6065 - val_mean_absolute_error: 0.9172 - val_mean_squared_error: 1.6065\n",
            "Epoch 933/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.5205 - mean_absolute_error: 0.8957 - mean_squared_error: 1.5205\n",
            "Epoch 933: val_loss did not improve from 1.60577\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5315 - mean_absolute_error: 0.9010 - mean_squared_error: 1.5315 - val_loss: 1.6086 - val_mean_absolute_error: 0.9174 - val_mean_squared_error: 1.6086\n",
            "Epoch 934/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.5080 - mean_absolute_error: 0.8935 - mean_squared_error: 1.5080\n",
            "Epoch 934: val_loss did not improve from 1.60577\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5298 - mean_absolute_error: 0.9009 - mean_squared_error: 1.5298 - val_loss: 1.6121 - val_mean_absolute_error: 0.9173 - val_mean_squared_error: 1.6121\n",
            "Epoch 935/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.5282 - mean_absolute_error: 0.8995 - mean_squared_error: 1.5282\n",
            "Epoch 935: val_loss did not improve from 1.60577\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5306 - mean_absolute_error: 0.9011 - mean_squared_error: 1.5306 - val_loss: 1.6094 - val_mean_absolute_error: 0.9175 - val_mean_squared_error: 1.6094\n",
            "Epoch 936/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.5503 - mean_absolute_error: 0.9070 - mean_squared_error: 1.5503\n",
            "Epoch 936: val_loss improved from 1.60577 to 1.60484, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5304 - mean_absolute_error: 0.9007 - mean_squared_error: 1.5304 - val_loss: 1.6048 - val_mean_absolute_error: 0.9185 - val_mean_squared_error: 1.6048\n",
            "Epoch 937/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.5236 - mean_absolute_error: 0.8998 - mean_squared_error: 1.5236\n",
            "Epoch 937: val_loss did not improve from 1.60484\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5317 - mean_absolute_error: 0.9009 - mean_squared_error: 1.5317 - val_loss: 1.6050 - val_mean_absolute_error: 0.9183 - val_mean_squared_error: 1.6050\n",
            "Epoch 938/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.5387 - mean_absolute_error: 0.9036 - mean_squared_error: 1.5387\n",
            "Epoch 938: val_loss did not improve from 1.60484\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5300 - mean_absolute_error: 0.9012 - mean_squared_error: 1.5300 - val_loss: 1.6111 - val_mean_absolute_error: 0.9174 - val_mean_squared_error: 1.6111\n",
            "Epoch 939/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.5239 - mean_absolute_error: 0.8968 - mean_squared_error: 1.5239\n",
            "Epoch 939: val_loss improved from 1.60484 to 1.60454, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5318 - mean_absolute_error: 0.9008 - mean_squared_error: 1.5318 - val_loss: 1.6045 - val_mean_absolute_error: 0.9178 - val_mean_squared_error: 1.6045\n",
            "Epoch 940/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.5306 - mean_absolute_error: 0.9010 - mean_squared_error: 1.5306\n",
            "Epoch 940: val_loss did not improve from 1.60454\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5306 - mean_absolute_error: 0.9010 - mean_squared_error: 1.5306 - val_loss: 1.6057 - val_mean_absolute_error: 0.9178 - val_mean_squared_error: 1.6057\n",
            "Epoch 941/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.5310 - mean_absolute_error: 0.9006 - mean_squared_error: 1.5310\n",
            "Epoch 941: val_loss did not improve from 1.60454\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5301 - mean_absolute_error: 0.9011 - mean_squared_error: 1.5301 - val_loss: 1.6059 - val_mean_absolute_error: 0.9175 - val_mean_squared_error: 1.6059\n",
            "Epoch 942/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.5207 - mean_absolute_error: 0.9009 - mean_squared_error: 1.5207\n",
            "Epoch 942: val_loss did not improve from 1.60454\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5303 - mean_absolute_error: 0.9010 - mean_squared_error: 1.5303 - val_loss: 1.6076 - val_mean_absolute_error: 0.9168 - val_mean_squared_error: 1.6076\n",
            "Epoch 943/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.5387 - mean_absolute_error: 0.9048 - mean_squared_error: 1.5387\n",
            "Epoch 943: val_loss did not improve from 1.60454\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5306 - mean_absolute_error: 0.9007 - mean_squared_error: 1.5306 - val_loss: 1.6058 - val_mean_absolute_error: 0.9171 - val_mean_squared_error: 1.6058\n",
            "Epoch 944/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.5391 - mean_absolute_error: 0.9028 - mean_squared_error: 1.5391\n",
            "Epoch 944: val_loss did not improve from 1.60454\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5295 - mean_absolute_error: 0.9000 - mean_squared_error: 1.5295 - val_loss: 1.6097 - val_mean_absolute_error: 0.9173 - val_mean_squared_error: 1.6097\n",
            "Epoch 945/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.5200 - mean_absolute_error: 0.9005 - mean_squared_error: 1.5200\n",
            "Epoch 945: val_loss did not improve from 1.60454\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5304 - mean_absolute_error: 0.9014 - mean_squared_error: 1.5304 - val_loss: 1.6049 - val_mean_absolute_error: 0.9175 - val_mean_squared_error: 1.6049\n",
            "Epoch 946/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.5259 - mean_absolute_error: 0.8983 - mean_squared_error: 1.5259\n",
            "Epoch 946: val_loss improved from 1.60454 to 1.60377, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5295 - mean_absolute_error: 0.9009 - mean_squared_error: 1.5295 - val_loss: 1.6038 - val_mean_absolute_error: 0.9177 - val_mean_squared_error: 1.6038\n",
            "Epoch 947/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.5376 - mean_absolute_error: 0.9021 - mean_squared_error: 1.5376\n",
            "Epoch 947: val_loss improved from 1.60377 to 1.60357, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5298 - mean_absolute_error: 0.9007 - mean_squared_error: 1.5298 - val_loss: 1.6036 - val_mean_absolute_error: 0.9186 - val_mean_squared_error: 1.6036\n",
            "Epoch 948/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.5302 - mean_absolute_error: 0.9008 - mean_squared_error: 1.5302\n",
            "Epoch 948: val_loss did not improve from 1.60357\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5283 - mean_absolute_error: 0.9004 - mean_squared_error: 1.5283 - val_loss: 1.6042 - val_mean_absolute_error: 0.9174 - val_mean_squared_error: 1.6042\n",
            "Epoch 949/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.5365 - mean_absolute_error: 0.9037 - mean_squared_error: 1.5365\n",
            "Epoch 949: val_loss improved from 1.60357 to 1.60345, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5294 - mean_absolute_error: 0.9003 - mean_squared_error: 1.5294 - val_loss: 1.6035 - val_mean_absolute_error: 0.9180 - val_mean_squared_error: 1.6035\n",
            "Epoch 950/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.5460 - mean_absolute_error: 0.9063 - mean_squared_error: 1.5460\n",
            "Epoch 950: val_loss did not improve from 1.60345\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5283 - mean_absolute_error: 0.9006 - mean_squared_error: 1.5283 - val_loss: 1.6067 - val_mean_absolute_error: 0.9170 - val_mean_squared_error: 1.6067\n",
            "Epoch 951/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.5308 - mean_absolute_error: 0.9004 - mean_squared_error: 1.5308\n",
            "Epoch 951: val_loss did not improve from 1.60345\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5289 - mean_absolute_error: 0.9004 - mean_squared_error: 1.5289 - val_loss: 1.6043 - val_mean_absolute_error: 0.9202 - val_mean_squared_error: 1.6043\n",
            "Epoch 952/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.5225 - mean_absolute_error: 0.8966 - mean_squared_error: 1.5225\n",
            "Epoch 952: val_loss did not improve from 1.60345\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5287 - mean_absolute_error: 0.8997 - mean_squared_error: 1.5287 - val_loss: 1.6041 - val_mean_absolute_error: 0.9172 - val_mean_squared_error: 1.6041\n",
            "Epoch 953/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.5296 - mean_absolute_error: 0.9001 - mean_squared_error: 1.5296\n",
            "Epoch 953: val_loss did not improve from 1.60345\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5278 - mean_absolute_error: 0.8997 - mean_squared_error: 1.5278 - val_loss: 1.6035 - val_mean_absolute_error: 0.9173 - val_mean_squared_error: 1.6035\n",
            "Epoch 954/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.5303 - mean_absolute_error: 0.9002 - mean_squared_error: 1.5303\n",
            "Epoch 954: val_loss improved from 1.60345 to 1.60332, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5282 - mean_absolute_error: 0.8999 - mean_squared_error: 1.5282 - val_loss: 1.6033 - val_mean_absolute_error: 0.9174 - val_mean_squared_error: 1.6033\n",
            "Epoch 955/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.5437 - mean_absolute_error: 0.9082 - mean_squared_error: 1.5437\n",
            "Epoch 955: val_loss did not improve from 1.60332\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5280 - mean_absolute_error: 0.9000 - mean_squared_error: 1.5280 - val_loss: 1.6036 - val_mean_absolute_error: 0.9169 - val_mean_squared_error: 1.6036\n",
            "Epoch 956/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.5283 - mean_absolute_error: 0.9011 - mean_squared_error: 1.5283\n",
            "Epoch 956: val_loss improved from 1.60332 to 1.60270, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5279 - mean_absolute_error: 0.9002 - mean_squared_error: 1.5279 - val_loss: 1.6027 - val_mean_absolute_error: 0.9177 - val_mean_squared_error: 1.6027\n",
            "Epoch 957/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.5180 - mean_absolute_error: 0.8976 - mean_squared_error: 1.5180\n",
            "Epoch 957: val_loss did not improve from 1.60270\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5269 - mean_absolute_error: 0.9002 - mean_squared_error: 1.5269 - val_loss: 1.6042 - val_mean_absolute_error: 0.9163 - val_mean_squared_error: 1.6042\n",
            "Epoch 958/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.5259 - mean_absolute_error: 0.8991 - mean_squared_error: 1.5259\n",
            "Epoch 958: val_loss improved from 1.60270 to 1.60239, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5271 - mean_absolute_error: 0.8990 - mean_squared_error: 1.5271 - val_loss: 1.6024 - val_mean_absolute_error: 0.9178 - val_mean_squared_error: 1.6024\n",
            "Epoch 959/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.5169 - mean_absolute_error: 0.8968 - mean_squared_error: 1.5169\n",
            "Epoch 959: val_loss improved from 1.60239 to 1.60203, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5277 - mean_absolute_error: 0.9003 - mean_squared_error: 1.5277 - val_loss: 1.6020 - val_mean_absolute_error: 0.9183 - val_mean_squared_error: 1.6020\n",
            "Epoch 960/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.5251 - mean_absolute_error: 0.8996 - mean_squared_error: 1.5251\n",
            "Epoch 960: val_loss did not improve from 1.60203\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5254 - mean_absolute_error: 0.8993 - mean_squared_error: 1.5254 - val_loss: 1.6149 - val_mean_absolute_error: 0.9178 - val_mean_squared_error: 1.6149\n",
            "Epoch 961/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.5284 - mean_absolute_error: 0.9001 - mean_squared_error: 1.5284\n",
            "Epoch 961: val_loss did not improve from 1.60203\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5279 - mean_absolute_error: 0.9000 - mean_squared_error: 1.5279 - val_loss: 1.6038 - val_mean_absolute_error: 0.9167 - val_mean_squared_error: 1.6038\n",
            "Epoch 962/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.5154 - mean_absolute_error: 0.8971 - mean_squared_error: 1.5154\n",
            "Epoch 962: val_loss did not improve from 1.60203\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5266 - mean_absolute_error: 0.8997 - mean_squared_error: 1.5266 - val_loss: 1.6022 - val_mean_absolute_error: 0.9172 - val_mean_squared_error: 1.6022\n",
            "Epoch 963/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.5295 - mean_absolute_error: 0.9010 - mean_squared_error: 1.5295\n",
            "Epoch 963: val_loss did not improve from 1.60203\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5269 - mean_absolute_error: 0.8999 - mean_squared_error: 1.5269 - val_loss: 1.6030 - val_mean_absolute_error: 0.9167 - val_mean_squared_error: 1.6030\n",
            "Epoch 964/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.5133 - mean_absolute_error: 0.8964 - mean_squared_error: 1.5133\n",
            "Epoch 964: val_loss did not improve from 1.60203\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5265 - mean_absolute_error: 0.8994 - mean_squared_error: 1.5265 - val_loss: 1.6022 - val_mean_absolute_error: 0.9173 - val_mean_squared_error: 1.6022\n",
            "Epoch 965/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.5338 - mean_absolute_error: 0.9008 - mean_squared_error: 1.5338\n",
            "Epoch 965: val_loss improved from 1.60203 to 1.60146, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5265 - mean_absolute_error: 0.8996 - mean_squared_error: 1.5265 - val_loss: 1.6015 - val_mean_absolute_error: 0.9183 - val_mean_squared_error: 1.6015\n",
            "Epoch 966/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.5266 - mean_absolute_error: 0.8997 - mean_squared_error: 1.5266\n",
            "Epoch 966: val_loss did not improve from 1.60146\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5263 - mean_absolute_error: 0.8993 - mean_squared_error: 1.5263 - val_loss: 1.6019 - val_mean_absolute_error: 0.9174 - val_mean_squared_error: 1.6019\n",
            "Epoch 967/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.5261 - mean_absolute_error: 0.8998 - mean_squared_error: 1.5261\n",
            "Epoch 967: val_loss did not improve from 1.60146\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5261 - mean_absolute_error: 0.8998 - mean_squared_error: 1.5261 - val_loss: 1.6020 - val_mean_absolute_error: 0.9186 - val_mean_squared_error: 1.6020\n",
            "Epoch 968/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.5331 - mean_absolute_error: 0.9015 - mean_squared_error: 1.5331\n",
            "Epoch 968: val_loss did not improve from 1.60146\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5244 - mean_absolute_error: 0.8991 - mean_squared_error: 1.5244 - val_loss: 1.6040 - val_mean_absolute_error: 0.9165 - val_mean_squared_error: 1.6040\n",
            "Epoch 969/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.5317 - mean_absolute_error: 0.8999 - mean_squared_error: 1.5317\n",
            "Epoch 969: val_loss did not improve from 1.60146\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5263 - mean_absolute_error: 0.8995 - mean_squared_error: 1.5263 - val_loss: 1.6019 - val_mean_absolute_error: 0.9169 - val_mean_squared_error: 1.6019\n",
            "Epoch 970/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.5268 - mean_absolute_error: 0.9001 - mean_squared_error: 1.5268\n",
            "Epoch 970: val_loss did not improve from 1.60146\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5256 - mean_absolute_error: 0.8994 - mean_squared_error: 1.5256 - val_loss: 1.6035 - val_mean_absolute_error: 0.9166 - val_mean_squared_error: 1.6035\n",
            "Epoch 971/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.5356 - mean_absolute_error: 0.9023 - mean_squared_error: 1.5356\n",
            "Epoch 971: val_loss did not improve from 1.60146\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5243 - mean_absolute_error: 0.8990 - mean_squared_error: 1.5243 - val_loss: 1.6022 - val_mean_absolute_error: 0.9197 - val_mean_squared_error: 1.6022\n",
            "Epoch 972/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.5315 - mean_absolute_error: 0.9002 - mean_squared_error: 1.5315\n",
            "Epoch 972: val_loss did not improve from 1.60146\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5259 - mean_absolute_error: 0.8993 - mean_squared_error: 1.5259 - val_loss: 1.6035 - val_mean_absolute_error: 0.9165 - val_mean_squared_error: 1.6035\n",
            "Epoch 973/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.5357 - mean_absolute_error: 0.9012 - mean_squared_error: 1.5357\n",
            "Epoch 973: val_loss improved from 1.60146 to 1.60145, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5258 - mean_absolute_error: 0.8996 - mean_squared_error: 1.5258 - val_loss: 1.6015 - val_mean_absolute_error: 0.9165 - val_mean_squared_error: 1.6015\n",
            "Epoch 974/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.5293 - mean_absolute_error: 0.8987 - mean_squared_error: 1.5293\n",
            "Epoch 974: val_loss improved from 1.60145 to 1.60093, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5251 - mean_absolute_error: 0.8992 - mean_squared_error: 1.5251 - val_loss: 1.6009 - val_mean_absolute_error: 0.9168 - val_mean_squared_error: 1.6009\n",
            "Epoch 975/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.5241 - mean_absolute_error: 0.8989 - mean_squared_error: 1.5241\n",
            "Epoch 975: val_loss did not improve from 1.60093\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5242 - mean_absolute_error: 0.8989 - mean_squared_error: 1.5242 - val_loss: 1.6027 - val_mean_absolute_error: 0.9161 - val_mean_squared_error: 1.6027\n",
            "Epoch 976/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.5248 - mean_absolute_error: 0.8991 - mean_squared_error: 1.5248\n",
            "Epoch 976: val_loss did not improve from 1.60093\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5248 - mean_absolute_error: 0.8991 - mean_squared_error: 1.5248 - val_loss: 1.6031 - val_mean_absolute_error: 0.9161 - val_mean_squared_error: 1.6031\n",
            "Epoch 977/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.5272 - mean_absolute_error: 0.8995 - mean_squared_error: 1.5272\n",
            "Epoch 977: val_loss improved from 1.60093 to 1.60044, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5243 - mean_absolute_error: 0.8988 - mean_squared_error: 1.5243 - val_loss: 1.6004 - val_mean_absolute_error: 0.9168 - val_mean_squared_error: 1.6004\n",
            "Epoch 978/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.5191 - mean_absolute_error: 0.8988 - mean_squared_error: 1.5191\n",
            "Epoch 978: val_loss improved from 1.60044 to 1.60026, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5255 - mean_absolute_error: 0.8996 - mean_squared_error: 1.5255 - val_loss: 1.6003 - val_mean_absolute_error: 0.9162 - val_mean_squared_error: 1.6003\n",
            "Epoch 979/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.5249 - mean_absolute_error: 0.8999 - mean_squared_error: 1.5249\n",
            "Epoch 979: val_loss did not improve from 1.60026\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5237 - mean_absolute_error: 0.8989 - mean_squared_error: 1.5237 - val_loss: 1.6007 - val_mean_absolute_error: 0.9165 - val_mean_squared_error: 1.6007\n",
            "Epoch 980/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.5210 - mean_absolute_error: 0.8973 - mean_squared_error: 1.5210\n",
            "Epoch 980: val_loss did not improve from 1.60026\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5228 - mean_absolute_error: 0.8980 - mean_squared_error: 1.5228 - val_loss: 1.6004 - val_mean_absolute_error: 0.9172 - val_mean_squared_error: 1.6004\n",
            "Epoch 981/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.5277 - mean_absolute_error: 0.9011 - mean_squared_error: 1.5277\n",
            "Epoch 981: val_loss improved from 1.60026 to 1.60016, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5247 - mean_absolute_error: 0.8994 - mean_squared_error: 1.5247 - val_loss: 1.6002 - val_mean_absolute_error: 0.9164 - val_mean_squared_error: 1.6002\n",
            "Epoch 982/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.5166 - mean_absolute_error: 0.8964 - mean_squared_error: 1.5166\n",
            "Epoch 982: val_loss improved from 1.60016 to 1.60015, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5237 - mean_absolute_error: 0.8986 - mean_squared_error: 1.5237 - val_loss: 1.6002 - val_mean_absolute_error: 0.9165 - val_mean_squared_error: 1.6002\n",
            "Epoch 983/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.5250 - mean_absolute_error: 0.8990 - mean_squared_error: 1.5250\n",
            "Epoch 983: val_loss did not improve from 1.60015\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5235 - mean_absolute_error: 0.8986 - mean_squared_error: 1.5235 - val_loss: 1.6100 - val_mean_absolute_error: 0.9165 - val_mean_squared_error: 1.6100\n",
            "Epoch 984/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.5164 - mean_absolute_error: 0.8971 - mean_squared_error: 1.5164\n",
            "Epoch 984: val_loss improved from 1.60015 to 1.59999, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5232 - mean_absolute_error: 0.8984 - mean_squared_error: 1.5232 - val_loss: 1.6000 - val_mean_absolute_error: 0.9163 - val_mean_squared_error: 1.6000\n",
            "Epoch 985/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.5203 - mean_absolute_error: 0.8973 - mean_squared_error: 1.5203\n",
            "Epoch 985: val_loss improved from 1.59999 to 1.59971, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5240 - mean_absolute_error: 0.8988 - mean_squared_error: 1.5240 - val_loss: 1.5997 - val_mean_absolute_error: 0.9173 - val_mean_squared_error: 1.5997\n",
            "Epoch 986/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.5253 - mean_absolute_error: 0.8999 - mean_squared_error: 1.5253\n",
            "Epoch 986: val_loss did not improve from 1.59971\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5230 - mean_absolute_error: 0.8990 - mean_squared_error: 1.5230 - val_loss: 1.6002 - val_mean_absolute_error: 0.9158 - val_mean_squared_error: 1.6002\n",
            "Epoch 987/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.5209 - mean_absolute_error: 0.8986 - mean_squared_error: 1.5209\n",
            "Epoch 987: val_loss did not improve from 1.59971\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5224 - mean_absolute_error: 0.8983 - mean_squared_error: 1.5224 - val_loss: 1.6005 - val_mean_absolute_error: 0.9157 - val_mean_squared_error: 1.6005\n",
            "Epoch 988/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.5103 - mean_absolute_error: 0.8931 - mean_squared_error: 1.5103\n",
            "Epoch 988: val_loss did not improve from 1.59971\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5218 - mean_absolute_error: 0.8982 - mean_squared_error: 1.5218 - val_loss: 1.6046 - val_mean_absolute_error: 0.9156 - val_mean_squared_error: 1.6046\n",
            "Epoch 989/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.4978 - mean_absolute_error: 0.8930 - mean_squared_error: 1.4978\n",
            "Epoch 989: val_loss improved from 1.59971 to 1.59888, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5227 - mean_absolute_error: 0.8985 - mean_squared_error: 1.5227 - val_loss: 1.5989 - val_mean_absolute_error: 0.9171 - val_mean_squared_error: 1.5989\n",
            "Epoch 990/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.5193 - mean_absolute_error: 0.8966 - mean_squared_error: 1.5193\n",
            "Epoch 990: val_loss did not improve from 1.59888\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5219 - mean_absolute_error: 0.8982 - mean_squared_error: 1.5219 - val_loss: 1.5989 - val_mean_absolute_error: 0.9169 - val_mean_squared_error: 1.5989\n",
            "Epoch 991/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.5215 - mean_absolute_error: 0.8976 - mean_squared_error: 1.5215\n",
            "Epoch 991: val_loss did not improve from 1.59888\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5217 - mean_absolute_error: 0.8981 - mean_squared_error: 1.5217 - val_loss: 1.6009 - val_mean_absolute_error: 0.9155 - val_mean_squared_error: 1.6009\n",
            "Epoch 992/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.5320 - mean_absolute_error: 0.9011 - mean_squared_error: 1.5320\n",
            "Epoch 992: val_loss did not improve from 1.59888\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5222 - mean_absolute_error: 0.8979 - mean_squared_error: 1.5222 - val_loss: 1.5989 - val_mean_absolute_error: 0.9167 - val_mean_squared_error: 1.5989\n",
            "Epoch 993/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.5075 - mean_absolute_error: 0.8935 - mean_squared_error: 1.5075\n",
            "Epoch 993: val_loss improved from 1.59888 to 1.59851, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5224 - mean_absolute_error: 0.8984 - mean_squared_error: 1.5224 - val_loss: 1.5985 - val_mean_absolute_error: 0.9158 - val_mean_squared_error: 1.5985\n",
            "Epoch 994/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.5165 - mean_absolute_error: 0.8967 - mean_squared_error: 1.5165\n",
            "Epoch 994: val_loss improved from 1.59851 to 1.59825, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5209 - mean_absolute_error: 0.8978 - mean_squared_error: 1.5209 - val_loss: 1.5982 - val_mean_absolute_error: 0.9160 - val_mean_squared_error: 1.5982\n",
            "Epoch 995/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.5234 - mean_absolute_error: 0.8973 - mean_squared_error: 1.5234\n",
            "Epoch 995: val_loss did not improve from 1.59825\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5221 - mean_absolute_error: 0.8978 - mean_squared_error: 1.5221 - val_loss: 1.6019 - val_mean_absolute_error: 0.9155 - val_mean_squared_error: 1.6019\n",
            "Epoch 996/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.5178 - mean_absolute_error: 0.8959 - mean_squared_error: 1.5178\n",
            "Epoch 996: val_loss improved from 1.59825 to 1.59791, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5211 - mean_absolute_error: 0.8975 - mean_squared_error: 1.5211 - val_loss: 1.5979 - val_mean_absolute_error: 0.9163 - val_mean_squared_error: 1.5979\n",
            "Epoch 997/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.5200 - mean_absolute_error: 0.8964 - mean_squared_error: 1.5200\n",
            "Epoch 997: val_loss improved from 1.59791 to 1.59757, saving model to best_model3.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5206 - mean_absolute_error: 0.8975 - mean_squared_error: 1.5206 - val_loss: 1.5976 - val_mean_absolute_error: 0.9167 - val_mean_squared_error: 1.5976\n",
            "Epoch 998/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.5043 - mean_absolute_error: 0.8933 - mean_squared_error: 1.5043\n",
            "Epoch 998: val_loss did not improve from 1.59757\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5211 - mean_absolute_error: 0.8980 - mean_squared_error: 1.5211 - val_loss: 1.5996 - val_mean_absolute_error: 0.9154 - val_mean_squared_error: 1.5996\n",
            "Epoch 999/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.5209 - mean_absolute_error: 0.8965 - mean_squared_error: 1.5209\n",
            "Epoch 999: val_loss did not improve from 1.59757\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5204 - mean_absolute_error: 0.8973 - mean_squared_error: 1.5204 - val_loss: 1.5978 - val_mean_absolute_error: 0.9167 - val_mean_squared_error: 1.5978\n",
            "Epoch 1000/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.5219 - mean_absolute_error: 0.8998 - mean_squared_error: 1.5219\n",
            "Epoch 1000: val_loss did not improve from 1.59757\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5208 - mean_absolute_error: 0.8977 - mean_squared_error: 1.5208 - val_loss: 1.6013 - val_mean_absolute_error: 0.9151 - val_mean_squared_error: 1.6013\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f848b0ac250>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = load_model('best_model3.h5')\n",
        "\n",
        "z_predict_test3 = model2.predict(Z_test)\n",
        "\n",
        "plt.plot(z_predict_test3,z_test,'.')\n",
        "\n",
        "print('MSE:', mean_squared_error(z_test, z_predict_test3))\n",
        "print('MAE:', mean_absolute_error(z_test, z_predict_test3))\n",
        "print('RMSE:', mean_squared_error(z_test, z_predict_test3)**0.5)\n",
        "print('Spearman R:', spearmanr(z_test, z_predict_test3))\n",
        "print('R2:', r2_score(z_test, z_predict_test3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "ZwHa9yA4Gd7s",
        "outputId": "bedf4488-8129-4d4f-fc10-2d61b79647f8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 0s 2ms/step\n",
            "MSE: 1.5485735174071744\n",
            "MAE: 0.9019947805728415\n",
            "RMSE: 1.2444169387336281\n",
            "Spearman R: SpearmanrResult(correlation=0.81259391206599, pvalue=0.0)\n",
            "R2: 0.5657254118423933\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1 capa escondida, 10 neuronas:\n",
        "\n",
        "model4 = Sequential()\n",
        "#model.add(Dense(100, input_dim=2, activation='sigmoid'))\n",
        "model4.add(Dense(10, input_dim=2, activation='sigmoid'))\n",
        "model4.add(Dense(1, activation='linear'))\n",
        "\n",
        "model4.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error', 'mean_squared_error'])\n",
        "model4.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yab-izydlLSi",
        "outputId": "fa8640d5-4a14-4703-b6b9-beb012ac44b1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 10)                30        \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 41\n",
            "Trainable params: 41\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ajuste:\n",
        "es4 = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "mc4 = ModelCheckpoint('best_model4.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)"
      ],
      "metadata": {
        "id": "Y6faC0DzlTru"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model4.fit(Z_train, z_train, epochs=1000, batch_size=20, validation_split=0.3, shuffle=True, verbose=True, callbacks=[es4,mc4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgFD3O6_lZwD",
        "outputId": "09a420b5-a3bf-4ac7-dfba-75773667c4ec"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 3.6486 - mean_absolute_error: 1.2589 - mean_squared_error: 3.6486\n",
            "Epoch 1: val_loss improved from inf to 3.51496, saving model to best_model4.h5\n",
            "245/245 [==============================] - 2s 4ms/step - loss: 3.6627 - mean_absolute_error: 1.2594 - mean_squared_error: 3.6627 - val_loss: 3.5150 - val_mean_absolute_error: 1.2168 - val_mean_squared_error: 3.5150\n",
            "Epoch 2/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 3.6221 - mean_absolute_error: 1.2276 - mean_squared_error: 3.6221\n",
            "Epoch 2: val_loss improved from 3.51496 to 3.46728, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.6066 - mean_absolute_error: 1.2241 - mean_squared_error: 3.6066 - val_loss: 3.4673 - val_mean_absolute_error: 1.2110 - val_mean_squared_error: 3.4673\n",
            "Epoch 3/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 3.5665 - mean_absolute_error: 1.2205 - mean_squared_error: 3.5665\n",
            "Epoch 3: val_loss improved from 3.46728 to 3.41508, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.5557 - mean_absolute_error: 1.2195 - mean_squared_error: 3.5557 - val_loss: 3.4151 - val_mean_absolute_error: 1.1928 - val_mean_squared_error: 3.4151\n",
            "Epoch 4/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 3.5288 - mean_absolute_error: 1.2027 - mean_squared_error: 3.5288\n",
            "Epoch 4: val_loss improved from 3.41508 to 3.36502, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 3.5063 - mean_absolute_error: 1.1975 - mean_squared_error: 3.5063 - val_loss: 3.3650 - val_mean_absolute_error: 1.1824 - val_mean_squared_error: 3.3650\n",
            "Epoch 5/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 3.4662 - mean_absolute_error: 1.1992 - mean_squared_error: 3.4662\n",
            "Epoch 5: val_loss improved from 3.36502 to 3.31040, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 3.4543 - mean_absolute_error: 1.1966 - mean_squared_error: 3.4543 - val_loss: 3.3104 - val_mean_absolute_error: 1.1584 - val_mean_squared_error: 3.3104\n",
            "Epoch 6/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 3.3848 - mean_absolute_error: 1.1737 - mean_squared_error: 3.3848\n",
            "Epoch 6: val_loss improved from 3.31040 to 3.25993, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.4039 - mean_absolute_error: 1.1811 - mean_squared_error: 3.4039 - val_loss: 3.2599 - val_mean_absolute_error: 1.1509 - val_mean_squared_error: 3.2599\n",
            "Epoch 7/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 3.3093 - mean_absolute_error: 1.1662 - mean_squared_error: 3.3093\n",
            "Epoch 7: val_loss improved from 3.25993 to 3.21609, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.3540 - mean_absolute_error: 1.1758 - mean_squared_error: 3.3540 - val_loss: 3.2161 - val_mean_absolute_error: 1.1595 - val_mean_squared_error: 3.2161\n",
            "Epoch 8/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 3.3236 - mean_absolute_error: 1.1782 - mean_squared_error: 3.3236\n",
            "Epoch 8: val_loss improved from 3.21609 to 3.17407, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.3084 - mean_absolute_error: 1.1778 - mean_squared_error: 3.3084 - val_loss: 3.1741 - val_mean_absolute_error: 1.1638 - val_mean_squared_error: 3.1741\n",
            "Epoch 9/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 3.2353 - mean_absolute_error: 1.1776 - mean_squared_error: 3.2353\n",
            "Epoch 9: val_loss improved from 3.17407 to 3.13384, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.2676 - mean_absolute_error: 1.1834 - mean_squared_error: 3.2676 - val_loss: 3.1338 - val_mean_absolute_error: 1.1639 - val_mean_squared_error: 3.1338\n",
            "Epoch 10/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 3.2184 - mean_absolute_error: 1.1848 - mean_squared_error: 3.2184\n",
            "Epoch 10: val_loss improved from 3.13384 to 3.11321, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 3.2317 - mean_absolute_error: 1.1870 - mean_squared_error: 3.2317 - val_loss: 3.1132 - val_mean_absolute_error: 1.1799 - val_mean_squared_error: 3.1132\n",
            "Epoch 11/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 3.1957 - mean_absolute_error: 1.1960 - mean_squared_error: 3.1957\n",
            "Epoch 11: val_loss improved from 3.11321 to 3.07655, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.2080 - mean_absolute_error: 1.2013 - mean_squared_error: 3.2080 - val_loss: 3.0766 - val_mean_absolute_error: 1.1783 - val_mean_squared_error: 3.0766\n",
            "Epoch 12/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 3.1809 - mean_absolute_error: 1.2055 - mean_squared_error: 3.1809\n",
            "Epoch 12: val_loss improved from 3.07655 to 3.05777, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1835 - mean_absolute_error: 1.2067 - mean_squared_error: 3.1835 - val_loss: 3.0578 - val_mean_absolute_error: 1.1863 - val_mean_squared_error: 3.0578\n",
            "Epoch 13/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 3.1688 - mean_absolute_error: 1.2158 - mean_squared_error: 3.1688\n",
            "Epoch 13: val_loss improved from 3.05777 to 3.04156, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1681 - mean_absolute_error: 1.2163 - mean_squared_error: 3.1681 - val_loss: 3.0416 - val_mean_absolute_error: 1.1930 - val_mean_squared_error: 3.0416\n",
            "Epoch 14/1000\n",
            "217/245 [=========================>....] - ETA: 0s - loss: 3.1776 - mean_absolute_error: 1.2278 - mean_squared_error: 3.1776\n",
            "Epoch 14: val_loss improved from 3.04156 to 3.03359, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1567 - mean_absolute_error: 1.2233 - mean_squared_error: 3.1567 - val_loss: 3.0336 - val_mean_absolute_error: 1.2025 - val_mean_squared_error: 3.0336\n",
            "Epoch 15/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 3.1917 - mean_absolute_error: 1.2377 - mean_squared_error: 3.1917\n",
            "Epoch 15: val_loss improved from 3.03359 to 3.02539, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1481 - mean_absolute_error: 1.2315 - mean_squared_error: 3.1481 - val_loss: 3.0254 - val_mean_absolute_error: 1.2086 - val_mean_squared_error: 3.0254\n",
            "Epoch 16/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 3.1391 - mean_absolute_error: 1.2365 - mean_squared_error: 3.1391\n",
            "Epoch 16: val_loss improved from 3.02539 to 3.02484, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1430 - mean_absolute_error: 1.2375 - mean_squared_error: 3.1430 - val_loss: 3.0248 - val_mean_absolute_error: 1.2167 - val_mean_squared_error: 3.0248\n",
            "Epoch 17/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 3.1376 - mean_absolute_error: 1.2428 - mean_squared_error: 3.1376\n",
            "Epoch 17: val_loss improved from 3.02484 to 3.02145, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1376 - mean_absolute_error: 1.2428 - mean_squared_error: 3.1376 - val_loss: 3.0215 - val_mean_absolute_error: 1.2216 - val_mean_squared_error: 3.0215\n",
            "Epoch 18/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 3.1548 - mean_absolute_error: 1.2525 - mean_squared_error: 3.1548\n",
            "Epoch 18: val_loss improved from 3.02145 to 3.01537, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1347 - mean_absolute_error: 1.2484 - mean_squared_error: 3.1347 - val_loss: 3.0154 - val_mean_absolute_error: 1.2228 - val_mean_squared_error: 3.0154\n",
            "Epoch 19/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 3.1181 - mean_absolute_error: 1.2514 - mean_squared_error: 3.1181\n",
            "Epoch 19: val_loss improved from 3.01537 to 3.01227, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1317 - mean_absolute_error: 1.2514 - mean_squared_error: 3.1317 - val_loss: 3.0123 - val_mean_absolute_error: 1.2254 - val_mean_squared_error: 3.0123\n",
            "Epoch 20/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 3.1284 - mean_absolute_error: 1.2529 - mean_squared_error: 3.1284\n",
            "Epoch 20: val_loss improved from 3.01227 to 3.01149, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1309 - mean_absolute_error: 1.2550 - mean_squared_error: 3.1309 - val_loss: 3.0115 - val_mean_absolute_error: 1.2264 - val_mean_squared_error: 3.0115\n",
            "Epoch 21/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 3.1475 - mean_absolute_error: 1.2584 - mean_squared_error: 3.1475\n",
            "Epoch 21: val_loss did not improve from 3.01149\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1304 - mean_absolute_error: 1.2561 - mean_squared_error: 3.1304 - val_loss: 3.0141 - val_mean_absolute_error: 1.2334 - val_mean_squared_error: 3.0141\n",
            "Epoch 22/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 3.1305 - mean_absolute_error: 1.2589 - mean_squared_error: 3.1305\n",
            "Epoch 22: val_loss improved from 3.01149 to 3.00921, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1305 - mean_absolute_error: 1.2597 - mean_squared_error: 3.1305 - val_loss: 3.0092 - val_mean_absolute_error: 1.2312 - val_mean_squared_error: 3.0092\n",
            "Epoch 23/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 3.1172 - mean_absolute_error: 1.2591 - mean_squared_error: 3.1172\n",
            "Epoch 23: val_loss did not improve from 3.00921\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1284 - mean_absolute_error: 1.2595 - mean_squared_error: 3.1284 - val_loss: 3.0096 - val_mean_absolute_error: 1.2345 - val_mean_squared_error: 3.0096\n",
            "Epoch 24/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 3.1238 - mean_absolute_error: 1.2620 - mean_squared_error: 3.1238\n",
            "Epoch 24: val_loss did not improve from 3.00921\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1277 - mean_absolute_error: 1.2619 - mean_squared_error: 3.1277 - val_loss: 3.0105 - val_mean_absolute_error: 1.2367 - val_mean_squared_error: 3.0105\n",
            "Epoch 25/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 3.1236 - mean_absolute_error: 1.2635 - mean_squared_error: 3.1236\n",
            "Epoch 25: val_loss improved from 3.00921 to 3.00804, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1256 - mean_absolute_error: 1.2641 - mean_squared_error: 3.1256 - val_loss: 3.0080 - val_mean_absolute_error: 1.2353 - val_mean_squared_error: 3.0080\n",
            "Epoch 26/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 3.1420 - mean_absolute_error: 1.2660 - mean_squared_error: 3.1420\n",
            "Epoch 26: val_loss did not improve from 3.00804\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1287 - mean_absolute_error: 1.2641 - mean_squared_error: 3.1287 - val_loss: 3.0090 - val_mean_absolute_error: 1.2376 - val_mean_squared_error: 3.0090\n",
            "Epoch 27/1000\n",
            "218/245 [=========================>....] - ETA: 0s - loss: 3.1063 - mean_absolute_error: 1.2563 - mean_squared_error: 3.1063\n",
            "Epoch 27: val_loss did not improve from 3.00804\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1268 - mean_absolute_error: 1.2642 - mean_squared_error: 3.1268 - val_loss: 3.0083 - val_mean_absolute_error: 1.2379 - val_mean_squared_error: 3.0083\n",
            "Epoch 28/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 3.1421 - mean_absolute_error: 1.2684 - mean_squared_error: 3.1421\n",
            "Epoch 28: val_loss did not improve from 3.00804\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1264 - mean_absolute_error: 1.2648 - mean_squared_error: 3.1264 - val_loss: 3.0112 - val_mean_absolute_error: 1.2407 - val_mean_squared_error: 3.0112\n",
            "Epoch 29/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 3.1140 - mean_absolute_error: 1.2682 - mean_squared_error: 3.1140\n",
            "Epoch 29: val_loss improved from 3.00804 to 3.00749, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1269 - mean_absolute_error: 1.2666 - mean_squared_error: 3.1269 - val_loss: 3.0075 - val_mean_absolute_error: 1.2382 - val_mean_squared_error: 3.0075\n",
            "Epoch 30/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 3.1134 - mean_absolute_error: 1.2609 - mean_squared_error: 3.1134\n",
            "Epoch 30: val_loss did not improve from 3.00749\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1254 - mean_absolute_error: 1.2654 - mean_squared_error: 3.1254 - val_loss: 3.0100 - val_mean_absolute_error: 1.2407 - val_mean_squared_error: 3.0100\n",
            "Epoch 31/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 3.1251 - mean_absolute_error: 1.2644 - mean_squared_error: 3.1251\n",
            "Epoch 31: val_loss did not improve from 3.00749\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1251 - mean_absolute_error: 1.2644 - mean_squared_error: 3.1251 - val_loss: 3.0089 - val_mean_absolute_error: 1.2407 - val_mean_squared_error: 3.0089\n",
            "Epoch 32/1000\n",
            "214/245 [=========================>....] - ETA: 0s - loss: 3.0682 - mean_absolute_error: 1.2549 - mean_squared_error: 3.0682\n",
            "Epoch 32: val_loss improved from 3.00749 to 3.00686, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1257 - mean_absolute_error: 1.2663 - mean_squared_error: 3.1257 - val_loss: 3.0069 - val_mean_absolute_error: 1.2388 - val_mean_squared_error: 3.0069\n",
            "Epoch 33/1000\n",
            "214/245 [=========================>....] - ETA: 0s - loss: 3.0799 - mean_absolute_error: 1.2575 - mean_squared_error: 3.0799\n",
            "Epoch 33: val_loss did not improve from 3.00686\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1272 - mean_absolute_error: 1.2670 - mean_squared_error: 3.1272 - val_loss: 3.0079 - val_mean_absolute_error: 1.2401 - val_mean_squared_error: 3.0079\n",
            "Epoch 34/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 3.1170 - mean_absolute_error: 1.2659 - mean_squared_error: 3.1170\n",
            "Epoch 34: val_loss did not improve from 3.00686\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1238 - mean_absolute_error: 1.2655 - mean_squared_error: 3.1238 - val_loss: 3.0108 - val_mean_absolute_error: 1.2428 - val_mean_squared_error: 3.0108\n",
            "Epoch 35/1000\n",
            "217/245 [=========================>....] - ETA: 0s - loss: 3.1137 - mean_absolute_error: 1.2650 - mean_squared_error: 3.1137\n",
            "Epoch 35: val_loss did not improve from 3.00686\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1251 - mean_absolute_error: 1.2681 - mean_squared_error: 3.1251 - val_loss: 3.0117 - val_mean_absolute_error: 1.2435 - val_mean_squared_error: 3.0117\n",
            "Epoch 36/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 3.1066 - mean_absolute_error: 1.2657 - mean_squared_error: 3.1066\n",
            "Epoch 36: val_loss did not improve from 3.00686\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1249 - mean_absolute_error: 1.2671 - mean_squared_error: 3.1249 - val_loss: 3.0076 - val_mean_absolute_error: 1.2408 - val_mean_squared_error: 3.0076\n",
            "Epoch 37/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 3.1243 - mean_absolute_error: 1.2676 - mean_squared_error: 3.1243\n",
            "Epoch 37: val_loss did not improve from 3.00686\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1257 - mean_absolute_error: 1.2665 - mean_squared_error: 3.1257 - val_loss: 3.0077 - val_mean_absolute_error: 1.2413 - val_mean_squared_error: 3.0077\n",
            "Epoch 38/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 3.1270 - mean_absolute_error: 1.2667 - mean_squared_error: 3.1270\n",
            "Epoch 38: val_loss improved from 3.00686 to 3.00532, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1234 - mean_absolute_error: 1.2674 - mean_squared_error: 3.1234 - val_loss: 3.0053 - val_mean_absolute_error: 1.2394 - val_mean_squared_error: 3.0053\n",
            "Epoch 39/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 3.1286 - mean_absolute_error: 1.2674 - mean_squared_error: 3.1286\n",
            "Epoch 39: val_loss did not improve from 3.00532\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1237 - mean_absolute_error: 1.2665 - mean_squared_error: 3.1237 - val_loss: 3.0064 - val_mean_absolute_error: 1.2408 - val_mean_squared_error: 3.0064\n",
            "Epoch 40/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 3.1506 - mean_absolute_error: 1.2733 - mean_squared_error: 3.1506\n",
            "Epoch 40: val_loss did not improve from 3.00532\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1243 - mean_absolute_error: 1.2683 - mean_squared_error: 3.1243 - val_loss: 3.0059 - val_mean_absolute_error: 1.2408 - val_mean_squared_error: 3.0059\n",
            "Epoch 41/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 3.1429 - mean_absolute_error: 1.2707 - mean_squared_error: 3.1429\n",
            "Epoch 41: val_loss did not improve from 3.00532\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1221 - mean_absolute_error: 1.2665 - mean_squared_error: 3.1221 - val_loss: 3.0129 - val_mean_absolute_error: 1.2449 - val_mean_squared_error: 3.0129\n",
            "Epoch 42/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 3.1319 - mean_absolute_error: 1.2685 - mean_squared_error: 3.1319\n",
            "Epoch 42: val_loss improved from 3.00532 to 3.00438, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1204 - mean_absolute_error: 1.2674 - mean_squared_error: 3.1204 - val_loss: 3.0044 - val_mean_absolute_error: 1.2386 - val_mean_squared_error: 3.0044\n",
            "Epoch 43/1000\n",
            "218/245 [=========================>....] - ETA: 0s - loss: 3.1374 - mean_absolute_error: 1.2675 - mean_squared_error: 3.1374\n",
            "Epoch 43: val_loss improved from 3.00438 to 3.00396, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1234 - mean_absolute_error: 1.2668 - mean_squared_error: 3.1234 - val_loss: 3.0040 - val_mean_absolute_error: 1.2392 - val_mean_squared_error: 3.0040\n",
            "Epoch 44/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 3.1294 - mean_absolute_error: 1.2681 - mean_squared_error: 3.1294\n",
            "Epoch 44: val_loss did not improve from 3.00396\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1208 - mean_absolute_error: 1.2664 - mean_squared_error: 3.1208 - val_loss: 3.0135 - val_mean_absolute_error: 1.2455 - val_mean_squared_error: 3.0135\n",
            "Epoch 45/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 3.1229 - mean_absolute_error: 1.2676 - mean_squared_error: 3.1229\n",
            "Epoch 45: val_loss did not improve from 3.00396\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1235 - mean_absolute_error: 1.2673 - mean_squared_error: 3.1235 - val_loss: 3.0055 - val_mean_absolute_error: 1.2407 - val_mean_squared_error: 3.0055\n",
            "Epoch 46/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 3.1199 - mean_absolute_error: 1.2662 - mean_squared_error: 3.1199\n",
            "Epoch 46: val_loss did not improve from 3.00396\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1229 - mean_absolute_error: 1.2662 - mean_squared_error: 3.1229 - val_loss: 3.0063 - val_mean_absolute_error: 1.2412 - val_mean_squared_error: 3.0063\n",
            "Epoch 47/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 3.0982 - mean_absolute_error: 1.2634 - mean_squared_error: 3.0982\n",
            "Epoch 47: val_loss improved from 3.00396 to 3.00332, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1213 - mean_absolute_error: 1.2662 - mean_squared_error: 3.1213 - val_loss: 3.0033 - val_mean_absolute_error: 1.2394 - val_mean_squared_error: 3.0033\n",
            "Epoch 48/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 3.1241 - mean_absolute_error: 1.2669 - mean_squared_error: 3.1241\n",
            "Epoch 48: val_loss improved from 3.00332 to 3.00232, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1206 - mean_absolute_error: 1.2662 - mean_squared_error: 3.1206 - val_loss: 3.0023 - val_mean_absolute_error: 1.2383 - val_mean_squared_error: 3.0023\n",
            "Epoch 49/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 3.0957 - mean_absolute_error: 1.2627 - mean_squared_error: 3.0957\n",
            "Epoch 49: val_loss did not improve from 3.00232\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1188 - mean_absolute_error: 1.2663 - mean_squared_error: 3.1188 - val_loss: 3.0035 - val_mean_absolute_error: 1.2403 - val_mean_squared_error: 3.0035\n",
            "Epoch 50/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 3.1531 - mean_absolute_error: 1.2740 - mean_squared_error: 3.1531\n",
            "Epoch 50: val_loss did not improve from 3.00232\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1200 - mean_absolute_error: 1.2661 - mean_squared_error: 3.1200 - val_loss: 3.0070 - val_mean_absolute_error: 1.2431 - val_mean_squared_error: 3.0070\n",
            "Epoch 51/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 3.1935 - mean_absolute_error: 1.2811 - mean_squared_error: 3.1935\n",
            "Epoch 51: val_loss improved from 3.00232 to 3.00145, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1189 - mean_absolute_error: 1.2683 - mean_squared_error: 3.1189 - val_loss: 3.0015 - val_mean_absolute_error: 1.2387 - val_mean_squared_error: 3.0015\n",
            "Epoch 52/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 3.0825 - mean_absolute_error: 1.2577 - mean_squared_error: 3.0825\n",
            "Epoch 52: val_loss did not improve from 3.00145\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1178 - mean_absolute_error: 1.2653 - mean_squared_error: 3.1178 - val_loss: 3.0041 - val_mean_absolute_error: 1.2412 - val_mean_squared_error: 3.0041\n",
            "Epoch 53/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 3.1266 - mean_absolute_error: 1.2665 - mean_squared_error: 3.1266\n",
            "Epoch 53: val_loss did not improve from 3.00145\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1173 - mean_absolute_error: 1.2658 - mean_squared_error: 3.1173 - val_loss: 3.0133 - val_mean_absolute_error: 1.2466 - val_mean_squared_error: 3.0133\n",
            "Epoch 54/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 3.1287 - mean_absolute_error: 1.2685 - mean_squared_error: 3.1287\n",
            "Epoch 54: val_loss improved from 3.00145 to 3.00048, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1184 - mean_absolute_error: 1.2677 - mean_squared_error: 3.1184 - val_loss: 3.0005 - val_mean_absolute_error: 1.2394 - val_mean_squared_error: 3.0005\n",
            "Epoch 55/1000\n",
            "214/245 [=========================>....] - ETA: 0s - loss: 3.1086 - mean_absolute_error: 1.2620 - mean_squared_error: 3.1086\n",
            "Epoch 55: val_loss did not improve from 3.00048\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1163 - mean_absolute_error: 1.2651 - mean_squared_error: 3.1163 - val_loss: 3.0093 - val_mean_absolute_error: 1.2446 - val_mean_squared_error: 3.0093\n",
            "Epoch 56/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 3.1230 - mean_absolute_error: 1.2663 - mean_squared_error: 3.1230\n",
            "Epoch 56: val_loss did not improve from 3.00048\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1188 - mean_absolute_error: 1.2661 - mean_squared_error: 3.1188 - val_loss: 3.0081 - val_mean_absolute_error: 1.2445 - val_mean_squared_error: 3.0081\n",
            "Epoch 57/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 3.1850 - mean_absolute_error: 1.2820 - mean_squared_error: 3.1850\n",
            "Epoch 57: val_loss improved from 3.00048 to 2.99904, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1161 - mean_absolute_error: 1.2669 - mean_squared_error: 3.1161 - val_loss: 2.9990 - val_mean_absolute_error: 1.2381 - val_mean_squared_error: 2.9990\n",
            "Epoch 58/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 3.1243 - mean_absolute_error: 1.2678 - mean_squared_error: 3.1243\n",
            "Epoch 58: val_loss did not improve from 2.99904\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1172 - mean_absolute_error: 1.2662 - mean_squared_error: 3.1172 - val_loss: 3.0005 - val_mean_absolute_error: 1.2397 - val_mean_squared_error: 3.0005\n",
            "Epoch 59/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 3.1031 - mean_absolute_error: 1.2629 - mean_squared_error: 3.1031\n",
            "Epoch 59: val_loss improved from 2.99904 to 2.99831, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1157 - mean_absolute_error: 1.2656 - mean_squared_error: 3.1157 - val_loss: 2.9983 - val_mean_absolute_error: 1.2377 - val_mean_squared_error: 2.9983\n",
            "Epoch 60/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 3.1080 - mean_absolute_error: 1.2637 - mean_squared_error: 3.1080\n",
            "Epoch 60: val_loss did not improve from 2.99831\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1148 - mean_absolute_error: 1.2657 - mean_squared_error: 3.1148 - val_loss: 2.9985 - val_mean_absolute_error: 1.2373 - val_mean_squared_error: 2.9985\n",
            "Epoch 61/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 3.1196 - mean_absolute_error: 1.2625 - mean_squared_error: 3.1196\n",
            "Epoch 61: val_loss did not improve from 2.99831\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1166 - mean_absolute_error: 1.2641 - mean_squared_error: 3.1166 - val_loss: 2.9993 - val_mean_absolute_error: 1.2404 - val_mean_squared_error: 2.9993\n",
            "Epoch 62/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 3.1343 - mean_absolute_error: 1.2695 - mean_squared_error: 3.1343\n",
            "Epoch 62: val_loss did not improve from 2.99831\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1145 - mean_absolute_error: 1.2662 - mean_squared_error: 3.1145 - val_loss: 2.9985 - val_mean_absolute_error: 1.2401 - val_mean_squared_error: 2.9985\n",
            "Epoch 63/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 3.1089 - mean_absolute_error: 1.2654 - mean_squared_error: 3.1089\n",
            "Epoch 63: val_loss did not improve from 2.99831\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1140 - mean_absolute_error: 1.2648 - mean_squared_error: 3.1140 - val_loss: 3.0047 - val_mean_absolute_error: 1.2438 - val_mean_squared_error: 3.0047\n",
            "Epoch 64/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 3.1179 - mean_absolute_error: 1.2653 - mean_squared_error: 3.1179\n",
            "Epoch 64: val_loss did not improve from 2.99831\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1132 - mean_absolute_error: 1.2656 - mean_squared_error: 3.1132 - val_loss: 3.0001 - val_mean_absolute_error: 1.2416 - val_mean_squared_error: 3.0001\n",
            "Epoch 65/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 3.1140 - mean_absolute_error: 1.2663 - mean_squared_error: 3.1140\n",
            "Epoch 65: val_loss improved from 2.99831 to 2.99659, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1140 - mean_absolute_error: 1.2652 - mean_squared_error: 3.1140 - val_loss: 2.9966 - val_mean_absolute_error: 1.2395 - val_mean_squared_error: 2.9966\n",
            "Epoch 66/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 3.1273 - mean_absolute_error: 1.2700 - mean_squared_error: 3.1273\n",
            "Epoch 66: val_loss improved from 2.99659 to 2.99507, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1127 - mean_absolute_error: 1.2654 - mean_squared_error: 3.1127 - val_loss: 2.9951 - val_mean_absolute_error: 1.2371 - val_mean_squared_error: 2.9951\n",
            "Epoch 67/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 3.0204 - mean_absolute_error: 1.2489 - mean_squared_error: 3.0204\n",
            "Epoch 67: val_loss did not improve from 2.99507\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1122 - mean_absolute_error: 1.2641 - mean_squared_error: 3.1122 - val_loss: 3.0002 - val_mean_absolute_error: 1.2415 - val_mean_squared_error: 3.0002\n",
            "Epoch 68/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 3.1241 - mean_absolute_error: 1.2673 - mean_squared_error: 3.1241\n",
            "Epoch 68: val_loss improved from 2.99507 to 2.99416, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1101 - mean_absolute_error: 1.2654 - mean_squared_error: 3.1101 - val_loss: 2.9942 - val_mean_absolute_error: 1.2386 - val_mean_squared_error: 2.9942\n",
            "Epoch 69/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 3.1391 - mean_absolute_error: 1.2702 - mean_squared_error: 3.1391\n",
            "Epoch 69: val_loss did not improve from 2.99416\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1107 - mean_absolute_error: 1.2645 - mean_squared_error: 3.1107 - val_loss: 2.9988 - val_mean_absolute_error: 1.2416 - val_mean_squared_error: 2.9988\n",
            "Epoch 70/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 3.1212 - mean_absolute_error: 1.2660 - mean_squared_error: 3.1212\n",
            "Epoch 70: val_loss improved from 2.99416 to 2.99398, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1107 - mean_absolute_error: 1.2640 - mean_squared_error: 3.1107 - val_loss: 2.9940 - val_mean_absolute_error: 1.2390 - val_mean_squared_error: 2.9940\n",
            "Epoch 71/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 3.1076 - mean_absolute_error: 1.2629 - mean_squared_error: 3.1076\n",
            "Epoch 71: val_loss did not improve from 2.99398\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1094 - mean_absolute_error: 1.2635 - mean_squared_error: 3.1094 - val_loss: 3.0042 - val_mean_absolute_error: 1.2447 - val_mean_squared_error: 3.0042\n",
            "Epoch 72/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 3.1101 - mean_absolute_error: 1.2662 - mean_squared_error: 3.1101\n",
            "Epoch 72: val_loss improved from 2.99398 to 2.99216, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1101 - mean_absolute_error: 1.2662 - mean_squared_error: 3.1101 - val_loss: 2.9922 - val_mean_absolute_error: 1.2385 - val_mean_squared_error: 2.9922\n",
            "Epoch 73/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 3.1184 - mean_absolute_error: 1.2665 - mean_squared_error: 3.1184\n",
            "Epoch 73: val_loss improved from 2.99216 to 2.99196, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1075 - mean_absolute_error: 1.2641 - mean_squared_error: 3.1075 - val_loss: 2.9920 - val_mean_absolute_error: 1.2385 - val_mean_squared_error: 2.9920\n",
            "Epoch 74/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 3.0821 - mean_absolute_error: 1.2564 - mean_squared_error: 3.0821\n",
            "Epoch 74: val_loss improved from 2.99196 to 2.99033, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1069 - mean_absolute_error: 1.2640 - mean_squared_error: 3.1069 - val_loss: 2.9903 - val_mean_absolute_error: 1.2368 - val_mean_squared_error: 2.9903\n",
            "Epoch 75/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 3.0796 - mean_absolute_error: 1.2581 - mean_squared_error: 3.0796\n",
            "Epoch 75: val_loss did not improve from 2.99033\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1092 - mean_absolute_error: 1.2636 - mean_squared_error: 3.1092 - val_loss: 2.9923 - val_mean_absolute_error: 1.2394 - val_mean_squared_error: 2.9923\n",
            "Epoch 76/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 3.1026 - mean_absolute_error: 1.2634 - mean_squared_error: 3.1026\n",
            "Epoch 76: val_loss did not improve from 2.99033\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1078 - mean_absolute_error: 1.2640 - mean_squared_error: 3.1078 - val_loss: 2.9927 - val_mean_absolute_error: 1.2401 - val_mean_squared_error: 2.9927\n",
            "Epoch 77/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 3.1084 - mean_absolute_error: 1.2638 - mean_squared_error: 3.1084\n",
            "Epoch 77: val_loss improved from 2.99033 to 2.98914, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1047 - mean_absolute_error: 1.2635 - mean_squared_error: 3.1047 - val_loss: 2.9891 - val_mean_absolute_error: 1.2380 - val_mean_squared_error: 2.9891\n",
            "Epoch 78/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 3.1067 - mean_absolute_error: 1.2627 - mean_squared_error: 3.1067\n",
            "Epoch 78: val_loss did not improve from 2.98914\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1047 - mean_absolute_error: 1.2623 - mean_squared_error: 3.1047 - val_loss: 2.9905 - val_mean_absolute_error: 1.2395 - val_mean_squared_error: 2.9905\n",
            "Epoch 79/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 3.0862 - mean_absolute_error: 1.2611 - mean_squared_error: 3.0862\n",
            "Epoch 79: val_loss did not improve from 2.98914\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1048 - mean_absolute_error: 1.2632 - mean_squared_error: 3.1048 - val_loss: 2.9903 - val_mean_absolute_error: 1.2394 - val_mean_squared_error: 2.9903\n",
            "Epoch 80/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 3.1211 - mean_absolute_error: 1.2648 - mean_squared_error: 3.1211\n",
            "Epoch 80: val_loss improved from 2.98914 to 2.98764, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1045 - mean_absolute_error: 1.2634 - mean_squared_error: 3.1045 - val_loss: 2.9876 - val_mean_absolute_error: 1.2384 - val_mean_squared_error: 2.9876\n",
            "Epoch 81/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 3.0774 - mean_absolute_error: 1.2586 - mean_squared_error: 3.0774\n",
            "Epoch 81: val_loss did not improve from 2.98764\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1021 - mean_absolute_error: 1.2634 - mean_squared_error: 3.1021 - val_loss: 2.9910 - val_mean_absolute_error: 1.2405 - val_mean_squared_error: 2.9910\n",
            "Epoch 82/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 3.1300 - mean_absolute_error: 1.2677 - mean_squared_error: 3.1300\n",
            "Epoch 82: val_loss improved from 2.98764 to 2.98724, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1022 - mean_absolute_error: 1.2625 - mean_squared_error: 3.1022 - val_loss: 2.9872 - val_mean_absolute_error: 1.2385 - val_mean_squared_error: 2.9872\n",
            "Epoch 83/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 3.1257 - mean_absolute_error: 1.2680 - mean_squared_error: 3.1257\n",
            "Epoch 83: val_loss improved from 2.98724 to 2.98590, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1020 - mean_absolute_error: 1.2628 - mean_squared_error: 3.1020 - val_loss: 2.9859 - val_mean_absolute_error: 1.2380 - val_mean_squared_error: 2.9859\n",
            "Epoch 84/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 3.0662 - mean_absolute_error: 1.2564 - mean_squared_error: 3.0662\n",
            "Epoch 84: val_loss did not improve from 2.98590\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0997 - mean_absolute_error: 1.2620 - mean_squared_error: 3.0997 - val_loss: 2.9888 - val_mean_absolute_error: 1.2403 - val_mean_squared_error: 2.9888\n",
            "Epoch 85/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 3.1085 - mean_absolute_error: 1.2666 - mean_squared_error: 3.1085\n",
            "Epoch 85: val_loss improved from 2.98590 to 2.98267, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0992 - mean_absolute_error: 1.2648 - mean_squared_error: 3.0992 - val_loss: 2.9827 - val_mean_absolute_error: 1.2363 - val_mean_squared_error: 2.9827\n",
            "Epoch 86/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 3.0954 - mean_absolute_error: 1.2598 - mean_squared_error: 3.0954\n",
            "Epoch 86: val_loss did not improve from 2.98267\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0995 - mean_absolute_error: 1.2618 - mean_squared_error: 3.0995 - val_loss: 2.9877 - val_mean_absolute_error: 1.2401 - val_mean_squared_error: 2.9877\n",
            "Epoch 87/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 3.0782 - mean_absolute_error: 1.2597 - mean_squared_error: 3.0782\n",
            "Epoch 87: val_loss did not improve from 2.98267\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0992 - mean_absolute_error: 1.2625 - mean_squared_error: 3.0992 - val_loss: 2.9835 - val_mean_absolute_error: 1.2376 - val_mean_squared_error: 2.9835\n",
            "Epoch 88/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 3.0979 - mean_absolute_error: 1.2627 - mean_squared_error: 3.0979\n",
            "Epoch 88: val_loss improved from 2.98267 to 2.98032, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0957 - mean_absolute_error: 1.2617 - mean_squared_error: 3.0957 - val_loss: 2.9803 - val_mean_absolute_error: 1.2359 - val_mean_squared_error: 2.9803\n",
            "Epoch 89/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 3.0835 - mean_absolute_error: 1.2576 - mean_squared_error: 3.0835\n",
            "Epoch 89: val_loss did not improve from 2.98032\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0973 - mean_absolute_error: 1.2621 - mean_squared_error: 3.0973 - val_loss: 2.9813 - val_mean_absolute_error: 1.2368 - val_mean_squared_error: 2.9813\n",
            "Epoch 90/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 3.0606 - mean_absolute_error: 1.2575 - mean_squared_error: 3.0606\n",
            "Epoch 90: val_loss improved from 2.98032 to 2.97893, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0961 - mean_absolute_error: 1.2607 - mean_squared_error: 3.0961 - val_loss: 2.9789 - val_mean_absolute_error: 1.2357 - val_mean_squared_error: 2.9789\n",
            "Epoch 91/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 3.0977 - mean_absolute_error: 1.2614 - mean_squared_error: 3.0977\n",
            "Epoch 91: val_loss did not improve from 2.97893\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0939 - mean_absolute_error: 1.2614 - mean_squared_error: 3.0939 - val_loss: 2.9815 - val_mean_absolute_error: 1.2382 - val_mean_squared_error: 2.9815\n",
            "Epoch 92/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 3.1140 - mean_absolute_error: 1.2663 - mean_squared_error: 3.1140\n",
            "Epoch 92: val_loss improved from 2.97893 to 2.97853, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 3.0932 - mean_absolute_error: 1.2631 - mean_squared_error: 3.0932 - val_loss: 2.9785 - val_mean_absolute_error: 1.2364 - val_mean_squared_error: 2.9785\n",
            "Epoch 93/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 3.0780 - mean_absolute_error: 1.2572 - mean_squared_error: 3.0780\n",
            "Epoch 93: val_loss improved from 2.97853 to 2.97663, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 3.0922 - mean_absolute_error: 1.2609 - mean_squared_error: 3.0922 - val_loss: 2.9766 - val_mean_absolute_error: 1.2349 - val_mean_squared_error: 2.9766\n",
            "Epoch 94/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 3.0871 - mean_absolute_error: 1.2606 - mean_squared_error: 3.0871\n",
            "Epoch 94: val_loss improved from 2.97663 to 2.97466, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 3.0902 - mean_absolute_error: 1.2606 - mean_squared_error: 3.0902 - val_loss: 2.9747 - val_mean_absolute_error: 1.2339 - val_mean_squared_error: 2.9747\n",
            "Epoch 95/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 3.1256 - mean_absolute_error: 1.2658 - mean_squared_error: 3.1256\n",
            "Epoch 95: val_loss improved from 2.97466 to 2.97326, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0893 - mean_absolute_error: 1.2602 - mean_squared_error: 3.0893 - val_loss: 2.9733 - val_mean_absolute_error: 1.2336 - val_mean_squared_error: 2.9733\n",
            "Epoch 96/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 3.0878 - mean_absolute_error: 1.2588 - mean_squared_error: 3.0878\n",
            "Epoch 96: val_loss did not improve from 2.97326\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0878 - mean_absolute_error: 1.2588 - mean_squared_error: 3.0878 - val_loss: 2.9779 - val_mean_absolute_error: 1.2371 - val_mean_squared_error: 2.9779\n",
            "Epoch 97/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 3.0727 - mean_absolute_error: 1.2591 - mean_squared_error: 3.0727\n",
            "Epoch 97: val_loss improved from 2.97326 to 2.97291, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0886 - mean_absolute_error: 1.2601 - mean_squared_error: 3.0886 - val_loss: 2.9729 - val_mean_absolute_error: 1.2349 - val_mean_squared_error: 2.9729\n",
            "Epoch 98/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 3.0758 - mean_absolute_error: 1.2579 - mean_squared_error: 3.0758\n",
            "Epoch 98: val_loss did not improve from 2.97291\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0854 - mean_absolute_error: 1.2591 - mean_squared_error: 3.0854 - val_loss: 2.9753 - val_mean_absolute_error: 1.2363 - val_mean_squared_error: 2.9753\n",
            "Epoch 99/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 3.0936 - mean_absolute_error: 1.2601 - mean_squared_error: 3.0936\n",
            "Epoch 99: val_loss did not improve from 2.97291\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0855 - mean_absolute_error: 1.2589 - mean_squared_error: 3.0855 - val_loss: 2.9742 - val_mean_absolute_error: 1.2365 - val_mean_squared_error: 2.9742\n",
            "Epoch 100/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 3.0535 - mean_absolute_error: 1.2559 - mean_squared_error: 3.0535\n",
            "Epoch 100: val_loss did not improve from 2.97291\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0825 - mean_absolute_error: 1.2592 - mean_squared_error: 3.0825 - val_loss: 2.9744 - val_mean_absolute_error: 1.2369 - val_mean_squared_error: 2.9744\n",
            "Epoch 101/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 3.0642 - mean_absolute_error: 1.2553 - mean_squared_error: 3.0642\n",
            "Epoch 101: val_loss improved from 2.97291 to 2.96824, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0833 - mean_absolute_error: 1.2580 - mean_squared_error: 3.0833 - val_loss: 2.9682 - val_mean_absolute_error: 1.2337 - val_mean_squared_error: 2.9682\n",
            "Epoch 102/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 3.0689 - mean_absolute_error: 1.2532 - mean_squared_error: 3.0689\n",
            "Epoch 102: val_loss did not improve from 2.96824\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0797 - mean_absolute_error: 1.2572 - mean_squared_error: 3.0797 - val_loss: 2.9767 - val_mean_absolute_error: 1.2386 - val_mean_squared_error: 2.9767\n",
            "Epoch 103/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 3.1214 - mean_absolute_error: 1.2659 - mean_squared_error: 3.1214\n",
            "Epoch 103: val_loss improved from 2.96824 to 2.96364, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0792 - mean_absolute_error: 1.2598 - mean_squared_error: 3.0792 - val_loss: 2.9636 - val_mean_absolute_error: 1.2316 - val_mean_squared_error: 2.9636\n",
            "Epoch 104/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 3.0792 - mean_absolute_error: 1.2582 - mean_squared_error: 3.0792\n",
            "Epoch 104: val_loss did not improve from 2.96364\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0792 - mean_absolute_error: 1.2582 - mean_squared_error: 3.0792 - val_loss: 2.9663 - val_mean_absolute_error: 1.2340 - val_mean_squared_error: 2.9663\n",
            "Epoch 105/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 3.0827 - mean_absolute_error: 1.2572 - mean_squared_error: 3.0827\n",
            "Epoch 105: val_loss improved from 2.96364 to 2.96110, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 3.0767 - mean_absolute_error: 1.2578 - mean_squared_error: 3.0767 - val_loss: 2.9611 - val_mean_absolute_error: 1.2309 - val_mean_squared_error: 2.9611\n",
            "Epoch 106/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 3.0761 - mean_absolute_error: 1.2570 - mean_squared_error: 3.0761\n",
            "Epoch 106: val_loss improved from 2.96110 to 2.95967, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 3.0729 - mean_absolute_error: 1.2581 - mean_squared_error: 3.0729 - val_loss: 2.9597 - val_mean_absolute_error: 1.2298 - val_mean_squared_error: 2.9597\n",
            "Epoch 107/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 3.0735 - mean_absolute_error: 1.2575 - mean_squared_error: 3.0735\n",
            "Epoch 107: val_loss did not improve from 2.95967\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 3.0735 - mean_absolute_error: 1.2575 - mean_squared_error: 3.0735 - val_loss: 2.9616 - val_mean_absolute_error: 1.2327 - val_mean_squared_error: 2.9616\n",
            "Epoch 108/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 3.0385 - mean_absolute_error: 1.2498 - mean_squared_error: 3.0385\n",
            "Epoch 108: val_loss improved from 2.95967 to 2.95800, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0724 - mean_absolute_error: 1.2570 - mean_squared_error: 3.0724 - val_loss: 2.9580 - val_mean_absolute_error: 1.2306 - val_mean_squared_error: 2.9580\n",
            "Epoch 109/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 3.0860 - mean_absolute_error: 1.2562 - mean_squared_error: 3.0860\n",
            "Epoch 109: val_loss improved from 2.95800 to 2.95571, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0704 - mean_absolute_error: 1.2562 - mean_squared_error: 3.0704 - val_loss: 2.9557 - val_mean_absolute_error: 1.2300 - val_mean_squared_error: 2.9557\n",
            "Epoch 110/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 3.0618 - mean_absolute_error: 1.2557 - mean_squared_error: 3.0618\n",
            "Epoch 110: val_loss improved from 2.95571 to 2.95467, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0693 - mean_absolute_error: 1.2546 - mean_squared_error: 3.0693 - val_loss: 2.9547 - val_mean_absolute_error: 1.2298 - val_mean_squared_error: 2.9547\n",
            "Epoch 111/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 3.0624 - mean_absolute_error: 1.2535 - mean_squared_error: 3.0624\n",
            "Epoch 111: val_loss improved from 2.95467 to 2.95310, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0664 - mean_absolute_error: 1.2549 - mean_squared_error: 3.0664 - val_loss: 2.9531 - val_mean_absolute_error: 1.2293 - val_mean_squared_error: 2.9531\n",
            "Epoch 112/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 3.0513 - mean_absolute_error: 1.2517 - mean_squared_error: 3.0513\n",
            "Epoch 112: val_loss improved from 2.95310 to 2.95113, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0649 - mean_absolute_error: 1.2530 - mean_squared_error: 3.0649 - val_loss: 2.9511 - val_mean_absolute_error: 1.2289 - val_mean_squared_error: 2.9511\n",
            "Epoch 113/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 3.0554 - mean_absolute_error: 1.2537 - mean_squared_error: 3.0554\n",
            "Epoch 113: val_loss improved from 2.95113 to 2.94918, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0633 - mean_absolute_error: 1.2536 - mean_squared_error: 3.0633 - val_loss: 2.9492 - val_mean_absolute_error: 1.2281 - val_mean_squared_error: 2.9492\n",
            "Epoch 114/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 3.0979 - mean_absolute_error: 1.2551 - mean_squared_error: 3.0979\n",
            "Epoch 114: val_loss did not improve from 2.94918\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0610 - mean_absolute_error: 1.2535 - mean_squared_error: 3.0610 - val_loss: 2.9495 - val_mean_absolute_error: 1.2296 - val_mean_squared_error: 2.9495\n",
            "Epoch 115/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 3.0574 - mean_absolute_error: 1.2502 - mean_squared_error: 3.0574\n",
            "Epoch 115: val_loss did not improve from 2.94918\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0579 - mean_absolute_error: 1.2517 - mean_squared_error: 3.0579 - val_loss: 2.9570 - val_mean_absolute_error: 1.2328 - val_mean_squared_error: 2.9570\n",
            "Epoch 116/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 3.0557 - mean_absolute_error: 1.2518 - mean_squared_error: 3.0557\n",
            "Epoch 116: val_loss improved from 2.94918 to 2.94779, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0579 - mean_absolute_error: 1.2531 - mean_squared_error: 3.0579 - val_loss: 2.9478 - val_mean_absolute_error: 1.2293 - val_mean_squared_error: 2.9478\n",
            "Epoch 117/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 3.0273 - mean_absolute_error: 1.2497 - mean_squared_error: 3.0273\n",
            "Epoch 117: val_loss improved from 2.94779 to 2.94325, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0549 - mean_absolute_error: 1.2515 - mean_squared_error: 3.0549 - val_loss: 2.9433 - val_mean_absolute_error: 1.2273 - val_mean_squared_error: 2.9433\n",
            "Epoch 118/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 3.1092 - mean_absolute_error: 1.2636 - mean_squared_error: 3.1092\n",
            "Epoch 118: val_loss improved from 2.94325 to 2.94020, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0532 - mean_absolute_error: 1.2525 - mean_squared_error: 3.0532 - val_loss: 2.9402 - val_mean_absolute_error: 1.2259 - val_mean_squared_error: 2.9402\n",
            "Epoch 119/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 3.0829 - mean_absolute_error: 1.2572 - mean_squared_error: 3.0829\n",
            "Epoch 119: val_loss improved from 2.94020 to 2.93991, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0524 - mean_absolute_error: 1.2507 - mean_squared_error: 3.0524 - val_loss: 2.9399 - val_mean_absolute_error: 1.2268 - val_mean_squared_error: 2.9399\n",
            "Epoch 120/1000\n",
            "218/245 [=========================>....] - ETA: 0s - loss: 3.0435 - mean_absolute_error: 1.2459 - mean_squared_error: 3.0435\n",
            "Epoch 120: val_loss improved from 2.93991 to 2.93749, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0493 - mean_absolute_error: 1.2496 - mean_squared_error: 3.0493 - val_loss: 2.9375 - val_mean_absolute_error: 1.2261 - val_mean_squared_error: 2.9375\n",
            "Epoch 121/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 3.1025 - mean_absolute_error: 1.2615 - mean_squared_error: 3.1025\n",
            "Epoch 121: val_loss improved from 2.93749 to 2.93371, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0488 - mean_absolute_error: 1.2501 - mean_squared_error: 3.0488 - val_loss: 2.9337 - val_mean_absolute_error: 1.2241 - val_mean_squared_error: 2.9337\n",
            "Epoch 122/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 3.0503 - mean_absolute_error: 1.2503 - mean_squared_error: 3.0503\n",
            "Epoch 122: val_loss did not improve from 2.93371\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0437 - mean_absolute_error: 1.2491 - mean_squared_error: 3.0437 - val_loss: 2.9403 - val_mean_absolute_error: 1.2281 - val_mean_squared_error: 2.9403\n",
            "Epoch 123/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 3.0508 - mean_absolute_error: 1.2497 - mean_squared_error: 3.0508\n",
            "Epoch 123: val_loss improved from 2.93371 to 2.93235, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0436 - mean_absolute_error: 1.2484 - mean_squared_error: 3.0436 - val_loss: 2.9324 - val_mean_absolute_error: 1.2248 - val_mean_squared_error: 2.9324\n",
            "Epoch 124/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 3.0607 - mean_absolute_error: 1.2513 - mean_squared_error: 3.0607\n",
            "Epoch 124: val_loss improved from 2.93235 to 2.92775, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0397 - mean_absolute_error: 1.2483 - mean_squared_error: 3.0397 - val_loss: 2.9277 - val_mean_absolute_error: 1.2230 - val_mean_squared_error: 2.9277\n",
            "Epoch 125/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 3.0589 - mean_absolute_error: 1.2509 - mean_squared_error: 3.0589\n",
            "Epoch 125: val_loss improved from 2.92775 to 2.92578, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0387 - mean_absolute_error: 1.2477 - mean_squared_error: 3.0387 - val_loss: 2.9258 - val_mean_absolute_error: 1.2224 - val_mean_squared_error: 2.9258\n",
            "Epoch 126/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 3.0171 - mean_absolute_error: 1.2398 - mean_squared_error: 3.0171\n",
            "Epoch 126: val_loss did not improve from 2.92578\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0354 - mean_absolute_error: 1.2458 - mean_squared_error: 3.0354 - val_loss: 2.9280 - val_mean_absolute_error: 1.2240 - val_mean_squared_error: 2.9280\n",
            "Epoch 127/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 3.0676 - mean_absolute_error: 1.2497 - mean_squared_error: 3.0676\n",
            "Epoch 127: val_loss improved from 2.92578 to 2.92210, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0332 - mean_absolute_error: 1.2456 - mean_squared_error: 3.0332 - val_loss: 2.9221 - val_mean_absolute_error: 1.2217 - val_mean_squared_error: 2.9221\n",
            "Epoch 128/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 3.0606 - mean_absolute_error: 1.2496 - mean_squared_error: 3.0606\n",
            "Epoch 128: val_loss improved from 2.92210 to 2.91885, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0311 - mean_absolute_error: 1.2461 - mean_squared_error: 3.0311 - val_loss: 2.9189 - val_mean_absolute_error: 1.2210 - val_mean_squared_error: 2.9189\n",
            "Epoch 129/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 3.0035 - mean_absolute_error: 1.2384 - mean_squared_error: 3.0035\n",
            "Epoch 129: val_loss improved from 2.91885 to 2.91648, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0280 - mean_absolute_error: 1.2437 - mean_squared_error: 3.0280 - val_loss: 2.9165 - val_mean_absolute_error: 1.2202 - val_mean_squared_error: 2.9165\n",
            "Epoch 130/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 3.0057 - mean_absolute_error: 1.2412 - mean_squared_error: 3.0057\n",
            "Epoch 130: val_loss improved from 2.91648 to 2.91382, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0267 - mean_absolute_error: 1.2434 - mean_squared_error: 3.0267 - val_loss: 2.9138 - val_mean_absolute_error: 1.2196 - val_mean_squared_error: 2.9138\n",
            "Epoch 131/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 3.0675 - mean_absolute_error: 1.2511 - mean_squared_error: 3.0675\n",
            "Epoch 131: val_loss improved from 2.91382 to 2.91148, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0236 - mean_absolute_error: 1.2440 - mean_squared_error: 3.0236 - val_loss: 2.9115 - val_mean_absolute_error: 1.2191 - val_mean_squared_error: 2.9115\n",
            "Epoch 132/1000\n",
            "215/245 [=========================>....] - ETA: 0s - loss: 3.0257 - mean_absolute_error: 1.2469 - mean_squared_error: 3.0257\n",
            "Epoch 132: val_loss improved from 2.91148 to 2.90912, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0199 - mean_absolute_error: 1.2422 - mean_squared_error: 3.0199 - val_loss: 2.9091 - val_mean_absolute_error: 1.2180 - val_mean_squared_error: 2.9091\n",
            "Epoch 133/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 3.0169 - mean_absolute_error: 1.2413 - mean_squared_error: 3.0169\n",
            "Epoch 133: val_loss improved from 2.90912 to 2.90641, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0165 - mean_absolute_error: 1.2419 - mean_squared_error: 3.0165 - val_loss: 2.9064 - val_mean_absolute_error: 1.2159 - val_mean_squared_error: 2.9064\n",
            "Epoch 134/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 3.0322 - mean_absolute_error: 1.2420 - mean_squared_error: 3.0322\n",
            "Epoch 134: val_loss improved from 2.90641 to 2.90328, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0158 - mean_absolute_error: 1.2397 - mean_squared_error: 3.0158 - val_loss: 2.9033 - val_mean_absolute_error: 1.2172 - val_mean_squared_error: 2.9033\n",
            "Epoch 135/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 3.0044 - mean_absolute_error: 1.2392 - mean_squared_error: 3.0044\n",
            "Epoch 135: val_loss did not improve from 2.90328\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0117 - mean_absolute_error: 1.2408 - mean_squared_error: 3.0117 - val_loss: 2.9043 - val_mean_absolute_error: 1.2176 - val_mean_squared_error: 2.9043\n",
            "Epoch 136/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 3.0136 - mean_absolute_error: 1.2411 - mean_squared_error: 3.0136\n",
            "Epoch 136: val_loss improved from 2.90328 to 2.90097, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0082 - mean_absolute_error: 1.2403 - mean_squared_error: 3.0082 - val_loss: 2.9010 - val_mean_absolute_error: 1.2168 - val_mean_squared_error: 2.9010\n",
            "Epoch 137/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 3.0279 - mean_absolute_error: 1.2436 - mean_squared_error: 3.0279\n",
            "Epoch 137: val_loss improved from 2.90097 to 2.90064, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0061 - mean_absolute_error: 1.2394 - mean_squared_error: 3.0061 - val_loss: 2.9006 - val_mean_absolute_error: 1.2169 - val_mean_squared_error: 2.9006\n",
            "Epoch 138/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 3.0276 - mean_absolute_error: 1.2429 - mean_squared_error: 3.0276\n",
            "Epoch 138: val_loss improved from 2.90064 to 2.89125, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0029 - mean_absolute_error: 1.2383 - mean_squared_error: 3.0029 - val_loss: 2.8913 - val_mean_absolute_error: 1.2127 - val_mean_squared_error: 2.8913\n",
            "Epoch 139/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.9993 - mean_absolute_error: 1.2357 - mean_squared_error: 2.9993\n",
            "Epoch 139: val_loss improved from 2.89125 to 2.88967, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9993 - mean_absolute_error: 1.2357 - mean_squared_error: 2.9993 - val_loss: 2.8897 - val_mean_absolute_error: 1.2123 - val_mean_squared_error: 2.8897\n",
            "Epoch 140/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.9955 - mean_absolute_error: 1.2361 - mean_squared_error: 2.9955\n",
            "Epoch 140: val_loss did not improve from 2.88967\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9949 - mean_absolute_error: 1.2356 - mean_squared_error: 2.9949 - val_loss: 2.8946 - val_mean_absolute_error: 1.2153 - val_mean_squared_error: 2.8946\n",
            "Epoch 141/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 2.9984 - mean_absolute_error: 1.2391 - mean_squared_error: 2.9984\n",
            "Epoch 141: val_loss improved from 2.88967 to 2.88196, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9917 - mean_absolute_error: 1.2358 - mean_squared_error: 2.9917 - val_loss: 2.8820 - val_mean_absolute_error: 1.2103 - val_mean_squared_error: 2.8820\n",
            "Epoch 142/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.9971 - mean_absolute_error: 1.2355 - mean_squared_error: 2.9971\n",
            "Epoch 142: val_loss improved from 2.88196 to 2.88119, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9892 - mean_absolute_error: 1.2346 - mean_squared_error: 2.9892 - val_loss: 2.8812 - val_mean_absolute_error: 1.2110 - val_mean_squared_error: 2.8812\n",
            "Epoch 143/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.9660 - mean_absolute_error: 1.2299 - mean_squared_error: 2.9660\n",
            "Epoch 143: val_loss improved from 2.88119 to 2.87545, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9840 - mean_absolute_error: 1.2333 - mean_squared_error: 2.9840 - val_loss: 2.8754 - val_mean_absolute_error: 1.2077 - val_mean_squared_error: 2.8754\n",
            "Epoch 144/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 2.9816 - mean_absolute_error: 1.2293 - mean_squared_error: 2.9816\n",
            "Epoch 144: val_loss improved from 2.87545 to 2.87225, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9806 - mean_absolute_error: 1.2311 - mean_squared_error: 2.9806 - val_loss: 2.8723 - val_mean_absolute_error: 1.2067 - val_mean_squared_error: 2.8723\n",
            "Epoch 145/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.9848 - mean_absolute_error: 1.2317 - mean_squared_error: 2.9848\n",
            "Epoch 145: val_loss did not improve from 2.87225\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9784 - mean_absolute_error: 1.2302 - mean_squared_error: 2.9784 - val_loss: 2.8726 - val_mean_absolute_error: 1.2086 - val_mean_squared_error: 2.8726\n",
            "Epoch 146/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.9895 - mean_absolute_error: 1.2325 - mean_squared_error: 2.9895\n",
            "Epoch 146: val_loss improved from 2.87225 to 2.87031, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9749 - mean_absolute_error: 1.2295 - mean_squared_error: 2.9749 - val_loss: 2.8703 - val_mean_absolute_error: 1.2081 - val_mean_squared_error: 2.8703\n",
            "Epoch 147/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 2.9534 - mean_absolute_error: 1.2266 - mean_squared_error: 2.9534\n",
            "Epoch 147: val_loss improved from 2.87031 to 2.86195, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9711 - mean_absolute_error: 1.2298 - mean_squared_error: 2.9711 - val_loss: 2.8620 - val_mean_absolute_error: 1.2048 - val_mean_squared_error: 2.8620\n",
            "Epoch 148/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.9909 - mean_absolute_error: 1.2332 - mean_squared_error: 2.9909\n",
            "Epoch 148: val_loss improved from 2.86195 to 2.86022, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9675 - mean_absolute_error: 1.2294 - mean_squared_error: 2.9675 - val_loss: 2.8602 - val_mean_absolute_error: 1.2047 - val_mean_squared_error: 2.8602\n",
            "Epoch 149/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.9529 - mean_absolute_error: 1.2239 - mean_squared_error: 2.9529\n",
            "Epoch 149: val_loss did not improve from 2.86022\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9630 - mean_absolute_error: 1.2255 - mean_squared_error: 2.9630 - val_loss: 2.8632 - val_mean_absolute_error: 1.2054 - val_mean_squared_error: 2.8632\n",
            "Epoch 150/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.9595 - mean_absolute_error: 1.2251 - mean_squared_error: 2.9595\n",
            "Epoch 150: val_loss improved from 2.86022 to 2.85851, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9599 - mean_absolute_error: 1.2256 - mean_squared_error: 2.9599 - val_loss: 2.8585 - val_mean_absolute_error: 1.2053 - val_mean_squared_error: 2.8585\n",
            "Epoch 151/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.9462 - mean_absolute_error: 1.2245 - mean_squared_error: 2.9462\n",
            "Epoch 151: val_loss improved from 2.85851 to 2.84973, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9562 - mean_absolute_error: 1.2250 - mean_squared_error: 2.9562 - val_loss: 2.8497 - val_mean_absolute_error: 1.2019 - val_mean_squared_error: 2.8497\n",
            "Epoch 152/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 2.9112 - mean_absolute_error: 1.2137 - mean_squared_error: 2.9112\n",
            "Epoch 152: val_loss improved from 2.84973 to 2.84474, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9524 - mean_absolute_error: 1.2230 - mean_squared_error: 2.9524 - val_loss: 2.8447 - val_mean_absolute_error: 1.2003 - val_mean_squared_error: 2.8447\n",
            "Epoch 153/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 2.9845 - mean_absolute_error: 1.2280 - mean_squared_error: 2.9845\n",
            "Epoch 153: val_loss improved from 2.84474 to 2.84131, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9472 - mean_absolute_error: 1.2225 - mean_squared_error: 2.9472 - val_loss: 2.8413 - val_mean_absolute_error: 1.1998 - val_mean_squared_error: 2.8413\n",
            "Epoch 154/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.9424 - mean_absolute_error: 1.2212 - mean_squared_error: 2.9424\n",
            "Epoch 154: val_loss improved from 2.84131 to 2.83757, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9436 - mean_absolute_error: 1.2215 - mean_squared_error: 2.9436 - val_loss: 2.8376 - val_mean_absolute_error: 1.1979 - val_mean_squared_error: 2.8376\n",
            "Epoch 155/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.9159 - mean_absolute_error: 1.2129 - mean_squared_error: 2.9159\n",
            "Epoch 155: val_loss improved from 2.83757 to 2.83224, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9391 - mean_absolute_error: 1.2192 - mean_squared_error: 2.9391 - val_loss: 2.8322 - val_mean_absolute_error: 1.1960 - val_mean_squared_error: 2.8322\n",
            "Epoch 156/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.9271 - mean_absolute_error: 1.2175 - mean_squared_error: 2.9271\n",
            "Epoch 156: val_loss improved from 2.83224 to 2.83055, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9359 - mean_absolute_error: 1.2194 - mean_squared_error: 2.9359 - val_loss: 2.8306 - val_mean_absolute_error: 1.1963 - val_mean_squared_error: 2.8306\n",
            "Epoch 157/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.9321 - mean_absolute_error: 1.2165 - mean_squared_error: 2.9321\n",
            "Epoch 157: val_loss improved from 2.83055 to 2.82441, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9308 - mean_absolute_error: 1.2171 - mean_squared_error: 2.9308 - val_loss: 2.8244 - val_mean_absolute_error: 1.1942 - val_mean_squared_error: 2.8244\n",
            "Epoch 158/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.9370 - mean_absolute_error: 1.2217 - mean_squared_error: 2.9370\n",
            "Epoch 158: val_loss did not improve from 2.82441\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9273 - mean_absolute_error: 1.2162 - mean_squared_error: 2.9273 - val_loss: 2.8295 - val_mean_absolute_error: 1.1965 - val_mean_squared_error: 2.8295\n",
            "Epoch 159/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.9184 - mean_absolute_error: 1.2137 - mean_squared_error: 2.9184\n",
            "Epoch 159: val_loss improved from 2.82441 to 2.82009, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9233 - mean_absolute_error: 1.2144 - mean_squared_error: 2.9233 - val_loss: 2.8201 - val_mean_absolute_error: 1.1933 - val_mean_squared_error: 2.8201\n",
            "Epoch 160/1000\n",
            "218/245 [=========================>....] - ETA: 0s - loss: 2.9504 - mean_absolute_error: 1.2231 - mean_squared_error: 2.9504\n",
            "Epoch 160: val_loss improved from 2.82009 to 2.81176, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9174 - mean_absolute_error: 1.2141 - mean_squared_error: 2.9174 - val_loss: 2.8118 - val_mean_absolute_error: 1.1910 - val_mean_squared_error: 2.8118\n",
            "Epoch 161/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 2.8865 - mean_absolute_error: 1.2049 - mean_squared_error: 2.8865\n",
            "Epoch 161: val_loss improved from 2.81176 to 2.80731, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9131 - mean_absolute_error: 1.2117 - mean_squared_error: 2.9131 - val_loss: 2.8073 - val_mean_absolute_error: 1.1895 - val_mean_squared_error: 2.8073\n",
            "Epoch 162/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.9059 - mean_absolute_error: 1.2100 - mean_squared_error: 2.9059\n",
            "Epoch 162: val_loss improved from 2.80731 to 2.80301, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9059 - mean_absolute_error: 1.2100 - mean_squared_error: 2.9059 - val_loss: 2.8030 - val_mean_absolute_error: 1.1876 - val_mean_squared_error: 2.8030\n",
            "Epoch 163/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.9149 - mean_absolute_error: 1.2097 - mean_squared_error: 2.9149\n",
            "Epoch 163: val_loss did not improve from 2.80301\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9036 - mean_absolute_error: 1.2085 - mean_squared_error: 2.9036 - val_loss: 2.8061 - val_mean_absolute_error: 1.1901 - val_mean_squared_error: 2.8061\n",
            "Epoch 164/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.9335 - mean_absolute_error: 1.2158 - mean_squared_error: 2.9335\n",
            "Epoch 164: val_loss improved from 2.80301 to 2.79488, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8993 - mean_absolute_error: 1.2095 - mean_squared_error: 2.8993 - val_loss: 2.7949 - val_mean_absolute_error: 1.1860 - val_mean_squared_error: 2.7949\n",
            "Epoch 165/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.8938 - mean_absolute_error: 1.2071 - mean_squared_error: 2.8938\n",
            "Epoch 165: val_loss improved from 2.79488 to 2.79107, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8938 - mean_absolute_error: 1.2071 - mean_squared_error: 2.8938 - val_loss: 2.7911 - val_mean_absolute_error: 1.1845 - val_mean_squared_error: 2.7911\n",
            "Epoch 166/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.9108 - mean_absolute_error: 1.2082 - mean_squared_error: 2.9108\n",
            "Epoch 166: val_loss improved from 2.79107 to 2.78972, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8895 - mean_absolute_error: 1.2052 - mean_squared_error: 2.8895 - val_loss: 2.7897 - val_mean_absolute_error: 1.1844 - val_mean_squared_error: 2.7897\n",
            "Epoch 167/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 2.9037 - mean_absolute_error: 1.2106 - mean_squared_error: 2.9037\n",
            "Epoch 167: val_loss did not improve from 2.78972\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8835 - mean_absolute_error: 1.2035 - mean_squared_error: 2.8835 - val_loss: 2.7939 - val_mean_absolute_error: 1.1857 - val_mean_squared_error: 2.7939\n",
            "Epoch 168/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.8973 - mean_absolute_error: 1.2066 - mean_squared_error: 2.8973\n",
            "Epoch 168: val_loss improved from 2.78972 to 2.77637, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8801 - mean_absolute_error: 1.2027 - mean_squared_error: 2.8801 - val_loss: 2.7764 - val_mean_absolute_error: 1.1797 - val_mean_squared_error: 2.7764\n",
            "Epoch 169/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.8848 - mean_absolute_error: 1.2045 - mean_squared_error: 2.8848\n",
            "Epoch 169: val_loss did not improve from 2.77637\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.8748 - mean_absolute_error: 1.2006 - mean_squared_error: 2.8748 - val_loss: 2.7797 - val_mean_absolute_error: 1.1810 - val_mean_squared_error: 2.7797\n",
            "Epoch 170/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.8919 - mean_absolute_error: 1.2016 - mean_squared_error: 2.8919\n",
            "Epoch 170: val_loss improved from 2.77637 to 2.76905, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.8697 - mean_absolute_error: 1.1985 - mean_squared_error: 2.8697 - val_loss: 2.7690 - val_mean_absolute_error: 1.1785 - val_mean_squared_error: 2.7690\n",
            "Epoch 171/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.8650 - mean_absolute_error: 1.1976 - mean_squared_error: 2.8650\n",
            "Epoch 171: val_loss improved from 2.76905 to 2.76306, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8650 - mean_absolute_error: 1.1976 - mean_squared_error: 2.8650 - val_loss: 2.7631 - val_mean_absolute_error: 1.1767 - val_mean_squared_error: 2.7631\n",
            "Epoch 172/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.8565 - mean_absolute_error: 1.1939 - mean_squared_error: 2.8565\n",
            "Epoch 172: val_loss improved from 2.76306 to 2.76113, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8597 - mean_absolute_error: 1.1951 - mean_squared_error: 2.8597 - val_loss: 2.7611 - val_mean_absolute_error: 1.1757 - val_mean_squared_error: 2.7611\n",
            "Epoch 173/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.9018 - mean_absolute_error: 1.2085 - mean_squared_error: 2.9018\n",
            "Epoch 173: val_loss improved from 2.76113 to 2.75684, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8554 - mean_absolute_error: 1.1953 - mean_squared_error: 2.8554 - val_loss: 2.7568 - val_mean_absolute_error: 1.1748 - val_mean_squared_error: 2.7568\n",
            "Epoch 174/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.8328 - mean_absolute_error: 1.1913 - mean_squared_error: 2.8328\n",
            "Epoch 174: val_loss improved from 2.75684 to 2.74868, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.8495 - mean_absolute_error: 1.1931 - mean_squared_error: 2.8495 - val_loss: 2.7487 - val_mean_absolute_error: 1.1720 - val_mean_squared_error: 2.7487\n",
            "Epoch 175/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.8281 - mean_absolute_error: 1.1876 - mean_squared_error: 2.8281\n",
            "Epoch 175: val_loss improved from 2.74868 to 2.74254, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8443 - mean_absolute_error: 1.1913 - mean_squared_error: 2.8443 - val_loss: 2.7425 - val_mean_absolute_error: 1.1704 - val_mean_squared_error: 2.7425\n",
            "Epoch 176/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.8306 - mean_absolute_error: 1.1865 - mean_squared_error: 2.8306\n",
            "Epoch 176: val_loss improved from 2.74254 to 2.73917, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8391 - mean_absolute_error: 1.1887 - mean_squared_error: 2.8391 - val_loss: 2.7392 - val_mean_absolute_error: 1.1703 - val_mean_squared_error: 2.7392\n",
            "Epoch 177/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.8390 - mean_absolute_error: 1.1903 - mean_squared_error: 2.8390\n",
            "Epoch 177: val_loss improved from 2.73917 to 2.73229, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8332 - mean_absolute_error: 1.1885 - mean_squared_error: 2.8332 - val_loss: 2.7323 - val_mean_absolute_error: 1.1675 - val_mean_squared_error: 2.7323\n",
            "Epoch 178/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 2.8134 - mean_absolute_error: 1.1836 - mean_squared_error: 2.8134\n",
            "Epoch 178: val_loss improved from 2.73229 to 2.72715, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8281 - mean_absolute_error: 1.1864 - mean_squared_error: 2.8281 - val_loss: 2.7271 - val_mean_absolute_error: 1.1669 - val_mean_squared_error: 2.7271\n",
            "Epoch 179/1000\n",
            "217/245 [=========================>....] - ETA: 0s - loss: 2.8410 - mean_absolute_error: 1.1867 - mean_squared_error: 2.8410\n",
            "Epoch 179: val_loss improved from 2.72715 to 2.72309, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8231 - mean_absolute_error: 1.1853 - mean_squared_error: 2.8231 - val_loss: 2.7231 - val_mean_absolute_error: 1.1651 - val_mean_squared_error: 2.7231\n",
            "Epoch 180/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 2.8238 - mean_absolute_error: 1.1827 - mean_squared_error: 2.8238\n",
            "Epoch 180: val_loss improved from 2.72309 to 2.72088, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.8183 - mean_absolute_error: 1.1838 - mean_squared_error: 2.8183 - val_loss: 2.7209 - val_mean_absolute_error: 1.1649 - val_mean_squared_error: 2.7209\n",
            "Epoch 181/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.8228 - mean_absolute_error: 1.1841 - mean_squared_error: 2.8228\n",
            "Epoch 181: val_loss improved from 2.72088 to 2.71180, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8123 - mean_absolute_error: 1.1826 - mean_squared_error: 2.8123 - val_loss: 2.7118 - val_mean_absolute_error: 1.1624 - val_mean_squared_error: 2.7118\n",
            "Epoch 182/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.8045 - mean_absolute_error: 1.1797 - mean_squared_error: 2.8045\n",
            "Epoch 182: val_loss improved from 2.71180 to 2.70717, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8076 - mean_absolute_error: 1.1808 - mean_squared_error: 2.8076 - val_loss: 2.7072 - val_mean_absolute_error: 1.1608 - val_mean_squared_error: 2.7072\n",
            "Epoch 183/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 2.8275 - mean_absolute_error: 1.1845 - mean_squared_error: 2.8275\n",
            "Epoch 183: val_loss did not improve from 2.70717\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8006 - mean_absolute_error: 1.1798 - mean_squared_error: 2.8006 - val_loss: 2.7109 - val_mean_absolute_error: 1.1605 - val_mean_squared_error: 2.7109\n",
            "Epoch 184/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.8362 - mean_absolute_error: 1.1859 - mean_squared_error: 2.8362\n",
            "Epoch 184: val_loss improved from 2.70717 to 2.69798, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7984 - mean_absolute_error: 1.1777 - mean_squared_error: 2.7984 - val_loss: 2.6980 - val_mean_absolute_error: 1.1578 - val_mean_squared_error: 2.6980\n",
            "Epoch 185/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.8211 - mean_absolute_error: 1.1838 - mean_squared_error: 2.8211\n",
            "Epoch 185: val_loss improved from 2.69798 to 2.69185, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7906 - mean_absolute_error: 1.1785 - mean_squared_error: 2.7906 - val_loss: 2.6918 - val_mean_absolute_error: 1.1570 - val_mean_squared_error: 2.6918\n",
            "Epoch 186/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.7342 - mean_absolute_error: 1.1660 - mean_squared_error: 2.7342\n",
            "Epoch 186: val_loss improved from 2.69185 to 2.68812, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7857 - mean_absolute_error: 1.1748 - mean_squared_error: 2.7857 - val_loss: 2.6881 - val_mean_absolute_error: 1.1539 - val_mean_squared_error: 2.6881\n",
            "Epoch 187/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.7847 - mean_absolute_error: 1.1744 - mean_squared_error: 2.7847\n",
            "Epoch 187: val_loss improved from 2.68812 to 2.68379, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7806 - mean_absolute_error: 1.1741 - mean_squared_error: 2.7806 - val_loss: 2.6838 - val_mean_absolute_error: 1.1536 - val_mean_squared_error: 2.6838\n",
            "Epoch 188/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.7469 - mean_absolute_error: 1.1645 - mean_squared_error: 2.7469\n",
            "Epoch 188: val_loss improved from 2.68379 to 2.67828, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.7754 - mean_absolute_error: 1.1715 - mean_squared_error: 2.7754 - val_loss: 2.6783 - val_mean_absolute_error: 1.1515 - val_mean_squared_error: 2.6783\n",
            "Epoch 189/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.7701 - mean_absolute_error: 1.1717 - mean_squared_error: 2.7701\n",
            "Epoch 189: val_loss improved from 2.67828 to 2.67129, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.7701 - mean_absolute_error: 1.1717 - mean_squared_error: 2.7701 - val_loss: 2.6713 - val_mean_absolute_error: 1.1503 - val_mean_squared_error: 2.6713\n",
            "Epoch 190/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.7389 - mean_absolute_error: 1.1654 - mean_squared_error: 2.7389\n",
            "Epoch 190: val_loss improved from 2.67129 to 2.66592, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.7640 - mean_absolute_error: 1.1687 - mean_squared_error: 2.7640 - val_loss: 2.6659 - val_mean_absolute_error: 1.1491 - val_mean_squared_error: 2.6659\n",
            "Epoch 191/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.7552 - mean_absolute_error: 1.1648 - mean_squared_error: 2.7552\n",
            "Epoch 191: val_loss improved from 2.66592 to 2.66099, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.7592 - mean_absolute_error: 1.1665 - mean_squared_error: 2.7592 - val_loss: 2.6610 - val_mean_absolute_error: 1.1494 - val_mean_squared_error: 2.6610\n",
            "Epoch 192/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.7526 - mean_absolute_error: 1.1651 - mean_squared_error: 2.7526\n",
            "Epoch 192: val_loss improved from 2.66099 to 2.65508, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7534 - mean_absolute_error: 1.1650 - mean_squared_error: 2.7534 - val_loss: 2.6551 - val_mean_absolute_error: 1.1471 - val_mean_squared_error: 2.6551\n",
            "Epoch 193/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 2.7884 - mean_absolute_error: 1.1723 - mean_squared_error: 2.7884\n",
            "Epoch 193: val_loss improved from 2.65508 to 2.65104, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7495 - mean_absolute_error: 1.1652 - mean_squared_error: 2.7495 - val_loss: 2.6510 - val_mean_absolute_error: 1.1451 - val_mean_squared_error: 2.6510\n",
            "Epoch 194/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.7385 - mean_absolute_error: 1.1631 - mean_squared_error: 2.7385\n",
            "Epoch 194: val_loss improved from 2.65104 to 2.64495, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7422 - mean_absolute_error: 1.1640 - mean_squared_error: 2.7422 - val_loss: 2.6449 - val_mean_absolute_error: 1.1440 - val_mean_squared_error: 2.6449\n",
            "Epoch 195/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.7011 - mean_absolute_error: 1.1543 - mean_squared_error: 2.7011\n",
            "Epoch 195: val_loss improved from 2.64495 to 2.64166, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7370 - mean_absolute_error: 1.1624 - mean_squared_error: 2.7370 - val_loss: 2.6417 - val_mean_absolute_error: 1.1417 - val_mean_squared_error: 2.6417\n",
            "Epoch 196/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.7300 - mean_absolute_error: 1.1607 - mean_squared_error: 2.7300\n",
            "Epoch 196: val_loss did not improve from 2.64166\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7300 - mean_absolute_error: 1.1607 - mean_squared_error: 2.7300 - val_loss: 2.6438 - val_mean_absolute_error: 1.1408 - val_mean_squared_error: 2.6438\n",
            "Epoch 197/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.7116 - mean_absolute_error: 1.1558 - mean_squared_error: 2.7116\n",
            "Epoch 197: val_loss improved from 2.64166 to 2.62890, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7235 - mean_absolute_error: 1.1579 - mean_squared_error: 2.7235 - val_loss: 2.6289 - val_mean_absolute_error: 1.1406 - val_mean_squared_error: 2.6289\n",
            "Epoch 198/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.6792 - mean_absolute_error: 1.1521 - mean_squared_error: 2.6792\n",
            "Epoch 198: val_loss improved from 2.62890 to 2.62404, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7194 - mean_absolute_error: 1.1578 - mean_squared_error: 2.7194 - val_loss: 2.6240 - val_mean_absolute_error: 1.1384 - val_mean_squared_error: 2.6240\n",
            "Epoch 199/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.7189 - mean_absolute_error: 1.1563 - mean_squared_error: 2.7189\n",
            "Epoch 199: val_loss improved from 2.62404 to 2.61739, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7143 - mean_absolute_error: 1.1569 - mean_squared_error: 2.7143 - val_loss: 2.6174 - val_mean_absolute_error: 1.1387 - val_mean_squared_error: 2.6174\n",
            "Epoch 200/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.6940 - mean_absolute_error: 1.1550 - mean_squared_error: 2.6940\n",
            "Epoch 200: val_loss improved from 2.61739 to 2.61282, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7099 - mean_absolute_error: 1.1564 - mean_squared_error: 2.7099 - val_loss: 2.6128 - val_mean_absolute_error: 1.1359 - val_mean_squared_error: 2.6128\n",
            "Epoch 201/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.7151 - mean_absolute_error: 1.1601 - mean_squared_error: 2.7151\n",
            "Epoch 201: val_loss improved from 2.61282 to 2.61023, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7032 - mean_absolute_error: 1.1556 - mean_squared_error: 2.7032 - val_loss: 2.6102 - val_mean_absolute_error: 1.1330 - val_mean_squared_error: 2.6102\n",
            "Epoch 202/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.7202 - mean_absolute_error: 1.1546 - mean_squared_error: 2.7202\n",
            "Epoch 202: val_loss improved from 2.61023 to 2.60181, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6979 - mean_absolute_error: 1.1517 - mean_squared_error: 2.6979 - val_loss: 2.6018 - val_mean_absolute_error: 1.1337 - val_mean_squared_error: 2.6018\n",
            "Epoch 203/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.6627 - mean_absolute_error: 1.1489 - mean_squared_error: 2.6627\n",
            "Epoch 203: val_loss improved from 2.60181 to 2.59754, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6926 - mean_absolute_error: 1.1526 - mean_squared_error: 2.6926 - val_loss: 2.5975 - val_mean_absolute_error: 1.1316 - val_mean_squared_error: 2.5975\n",
            "Epoch 204/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.6698 - mean_absolute_error: 1.1461 - mean_squared_error: 2.6698\n",
            "Epoch 204: val_loss improved from 2.59754 to 2.59326, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6874 - mean_absolute_error: 1.1496 - mean_squared_error: 2.6874 - val_loss: 2.5933 - val_mean_absolute_error: 1.1295 - val_mean_squared_error: 2.5933\n",
            "Epoch 205/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.7088 - mean_absolute_error: 1.1583 - mean_squared_error: 2.7088\n",
            "Epoch 205: val_loss improved from 2.59326 to 2.58856, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6814 - mean_absolute_error: 1.1506 - mean_squared_error: 2.6814 - val_loss: 2.5886 - val_mean_absolute_error: 1.1287 - val_mean_squared_error: 2.5886\n",
            "Epoch 206/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.6776 - mean_absolute_error: 1.1472 - mean_squared_error: 2.6776\n",
            "Epoch 206: val_loss improved from 2.58856 to 2.58817, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6739 - mean_absolute_error: 1.1468 - mean_squared_error: 2.6739 - val_loss: 2.5882 - val_mean_absolute_error: 1.1268 - val_mean_squared_error: 2.5882\n",
            "Epoch 207/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.6287 - mean_absolute_error: 1.1339 - mean_squared_error: 2.6287\n",
            "Epoch 207: val_loss improved from 2.58817 to 2.57481, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6696 - mean_absolute_error: 1.1458 - mean_squared_error: 2.6696 - val_loss: 2.5748 - val_mean_absolute_error: 1.1282 - val_mean_squared_error: 2.5748\n",
            "Epoch 208/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.7082 - mean_absolute_error: 1.1532 - mean_squared_error: 2.7082\n",
            "Epoch 208: val_loss improved from 2.57481 to 2.56991, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6644 - mean_absolute_error: 1.1462 - mean_squared_error: 2.6644 - val_loss: 2.5699 - val_mean_absolute_error: 1.1264 - val_mean_squared_error: 2.5699\n",
            "Epoch 209/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.6542 - mean_absolute_error: 1.1445 - mean_squared_error: 2.6542\n",
            "Epoch 209: val_loss improved from 2.56991 to 2.56420, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6598 - mean_absolute_error: 1.1439 - mean_squared_error: 2.6598 - val_loss: 2.5642 - val_mean_absolute_error: 1.1256 - val_mean_squared_error: 2.5642\n",
            "Epoch 210/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.6305 - mean_absolute_error: 1.1397 - mean_squared_error: 2.6305\n",
            "Epoch 210: val_loss improved from 2.56420 to 2.56209, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6544 - mean_absolute_error: 1.1436 - mean_squared_error: 2.6544 - val_loss: 2.5621 - val_mean_absolute_error: 1.1218 - val_mean_squared_error: 2.5621\n",
            "Epoch 211/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.6198 - mean_absolute_error: 1.1364 - mean_squared_error: 2.6198\n",
            "Epoch 211: val_loss improved from 2.56209 to 2.55658, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6479 - mean_absolute_error: 1.1421 - mean_squared_error: 2.6479 - val_loss: 2.5566 - val_mean_absolute_error: 1.1211 - val_mean_squared_error: 2.5566\n",
            "Epoch 212/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.6303 - mean_absolute_error: 1.1349 - mean_squared_error: 2.6303\n",
            "Epoch 212: val_loss improved from 2.55658 to 2.55085, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6428 - mean_absolute_error: 1.1399 - mean_squared_error: 2.6428 - val_loss: 2.5509 - val_mean_absolute_error: 1.1205 - val_mean_squared_error: 2.5509\n",
            "Epoch 213/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.6318 - mean_absolute_error: 1.1387 - mean_squared_error: 2.6318\n",
            "Epoch 213: val_loss improved from 2.55085 to 2.54500, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6367 - mean_absolute_error: 1.1390 - mean_squared_error: 2.6367 - val_loss: 2.5450 - val_mean_absolute_error: 1.1194 - val_mean_squared_error: 2.5450\n",
            "Epoch 214/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.6124 - mean_absolute_error: 1.1342 - mean_squared_error: 2.6124\n",
            "Epoch 214: val_loss improved from 2.54500 to 2.53900, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6312 - mean_absolute_error: 1.1383 - mean_squared_error: 2.6312 - val_loss: 2.5390 - val_mean_absolute_error: 1.1184 - val_mean_squared_error: 2.5390\n",
            "Epoch 215/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.6243 - mean_absolute_error: 1.1362 - mean_squared_error: 2.6243\n",
            "Epoch 215: val_loss improved from 2.53900 to 2.53681, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6268 - mean_absolute_error: 1.1372 - mean_squared_error: 2.6268 - val_loss: 2.5368 - val_mean_absolute_error: 1.1168 - val_mean_squared_error: 2.5368\n",
            "Epoch 216/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 2.5896 - mean_absolute_error: 1.1312 - mean_squared_error: 2.5896\n",
            "Epoch 216: val_loss improved from 2.53681 to 2.53562, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6210 - mean_absolute_error: 1.1364 - mean_squared_error: 2.6210 - val_loss: 2.5356 - val_mean_absolute_error: 1.1145 - val_mean_squared_error: 2.5356\n",
            "Epoch 217/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.5886 - mean_absolute_error: 1.1309 - mean_squared_error: 2.5886\n",
            "Epoch 217: val_loss improved from 2.53562 to 2.52824, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6145 - mean_absolute_error: 1.1357 - mean_squared_error: 2.6145 - val_loss: 2.5282 - val_mean_absolute_error: 1.1134 - val_mean_squared_error: 2.5282\n",
            "Epoch 218/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.6140 - mean_absolute_error: 1.1337 - mean_squared_error: 2.6140\n",
            "Epoch 218: val_loss improved from 2.52824 to 2.51667, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6110 - mean_absolute_error: 1.1328 - mean_squared_error: 2.6110 - val_loss: 2.5167 - val_mean_absolute_error: 1.1149 - val_mean_squared_error: 2.5167\n",
            "Epoch 219/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.6120 - mean_absolute_error: 1.1352 - mean_squared_error: 2.6120\n",
            "Epoch 219: val_loss improved from 2.51667 to 2.51194, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6042 - mean_absolute_error: 1.1333 - mean_squared_error: 2.6042 - val_loss: 2.5119 - val_mean_absolute_error: 1.1138 - val_mean_squared_error: 2.5119\n",
            "Epoch 220/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.6020 - mean_absolute_error: 1.1320 - mean_squared_error: 2.6020\n",
            "Epoch 220: val_loss did not improve from 2.51194\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5978 - mean_absolute_error: 1.1319 - mean_squared_error: 2.5978 - val_loss: 2.5142 - val_mean_absolute_error: 1.1101 - val_mean_squared_error: 2.5142\n",
            "Epoch 221/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.6380 - mean_absolute_error: 1.1401 - mean_squared_error: 2.6380\n",
            "Epoch 221: val_loss improved from 2.51194 to 2.50440, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5927 - mean_absolute_error: 1.1300 - mean_squared_error: 2.5927 - val_loss: 2.5044 - val_mean_absolute_error: 1.1099 - val_mean_squared_error: 2.5044\n",
            "Epoch 222/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.5993 - mean_absolute_error: 1.1308 - mean_squared_error: 2.5993\n",
            "Epoch 222: val_loss improved from 2.50440 to 2.49730, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5861 - mean_absolute_error: 1.1294 - mean_squared_error: 2.5861 - val_loss: 2.4973 - val_mean_absolute_error: 1.1145 - val_mean_squared_error: 2.4973\n",
            "Epoch 223/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.6093 - mean_absolute_error: 1.1357 - mean_squared_error: 2.6093\n",
            "Epoch 223: val_loss did not improve from 2.49730\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5799 - mean_absolute_error: 1.1289 - mean_squared_error: 2.5799 - val_loss: 2.5043 - val_mean_absolute_error: 1.1055 - val_mean_squared_error: 2.5043\n",
            "Epoch 224/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 2.5449 - mean_absolute_error: 1.1189 - mean_squared_error: 2.5449\n",
            "Epoch 224: val_loss improved from 2.49730 to 2.48669, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5780 - mean_absolute_error: 1.1254 - mean_squared_error: 2.5780 - val_loss: 2.4867 - val_mean_absolute_error: 1.1063 - val_mean_squared_error: 2.4867\n",
            "Epoch 225/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.5677 - mean_absolute_error: 1.1244 - mean_squared_error: 2.5677\n",
            "Epoch 225: val_loss improved from 2.48669 to 2.48059, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5706 - mean_absolute_error: 1.1247 - mean_squared_error: 2.5706 - val_loss: 2.4806 - val_mean_absolute_error: 1.1050 - val_mean_squared_error: 2.4806\n",
            "Epoch 226/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.5675 - mean_absolute_error: 1.1228 - mean_squared_error: 2.5675\n",
            "Epoch 226: val_loss improved from 2.48059 to 2.47463, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5675 - mean_absolute_error: 1.1228 - mean_squared_error: 2.5675 - val_loss: 2.4746 - val_mean_absolute_error: 1.1052 - val_mean_squared_error: 2.4746\n",
            "Epoch 227/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.5714 - mean_absolute_error: 1.1240 - mean_squared_error: 2.5714\n",
            "Epoch 227: val_loss improved from 2.47463 to 2.47030, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5585 - mean_absolute_error: 1.1216 - mean_squared_error: 2.5585 - val_loss: 2.4703 - val_mean_absolute_error: 1.1084 - val_mean_squared_error: 2.4703\n",
            "Epoch 228/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.5584 - mean_absolute_error: 1.1223 - mean_squared_error: 2.5584\n",
            "Epoch 228: val_loss improved from 2.47030 to 2.46356, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5568 - mean_absolute_error: 1.1219 - mean_squared_error: 2.5568 - val_loss: 2.4636 - val_mean_absolute_error: 1.1038 - val_mean_squared_error: 2.4636\n",
            "Epoch 229/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.5428 - mean_absolute_error: 1.1174 - mean_squared_error: 2.5428\n",
            "Epoch 229: val_loss improved from 2.46356 to 2.46335, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5498 - mean_absolute_error: 1.1207 - mean_squared_error: 2.5498 - val_loss: 2.4633 - val_mean_absolute_error: 1.1000 - val_mean_squared_error: 2.4633\n",
            "Epoch 230/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.5424 - mean_absolute_error: 1.1196 - mean_squared_error: 2.5424\n",
            "Epoch 230: val_loss improved from 2.46335 to 2.45444, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5440 - mean_absolute_error: 1.1190 - mean_squared_error: 2.5440 - val_loss: 2.4544 - val_mean_absolute_error: 1.1004 - val_mean_squared_error: 2.4544\n",
            "Epoch 231/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.5444 - mean_absolute_error: 1.1199 - mean_squared_error: 2.5444\n",
            "Epoch 231: val_loss improved from 2.45444 to 2.45055, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5407 - mean_absolute_error: 1.1188 - mean_squared_error: 2.5407 - val_loss: 2.4506 - val_mean_absolute_error: 1.0983 - val_mean_squared_error: 2.4506\n",
            "Epoch 232/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.5144 - mean_absolute_error: 1.1111 - mean_squared_error: 2.5144\n",
            "Epoch 232: val_loss improved from 2.45055 to 2.44403, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5324 - mean_absolute_error: 1.1162 - mean_squared_error: 2.5324 - val_loss: 2.4440 - val_mean_absolute_error: 1.1000 - val_mean_squared_error: 2.4440\n",
            "Epoch 233/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.5131 - mean_absolute_error: 1.1121 - mean_squared_error: 2.5131\n",
            "Epoch 233: val_loss improved from 2.44403 to 2.44224, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5292 - mean_absolute_error: 1.1155 - mean_squared_error: 2.5292 - val_loss: 2.4422 - val_mean_absolute_error: 1.0949 - val_mean_squared_error: 2.4422\n",
            "Epoch 234/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.5165 - mean_absolute_error: 1.1131 - mean_squared_error: 2.5165\n",
            "Epoch 234: val_loss improved from 2.44224 to 2.43302, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5222 - mean_absolute_error: 1.1130 - mean_squared_error: 2.5222 - val_loss: 2.4330 - val_mean_absolute_error: 1.0978 - val_mean_squared_error: 2.4330\n",
            "Epoch 235/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.5225 - mean_absolute_error: 1.1142 - mean_squared_error: 2.5225\n",
            "Epoch 235: val_loss improved from 2.43302 to 2.42850, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5179 - mean_absolute_error: 1.1132 - mean_squared_error: 2.5179 - val_loss: 2.4285 - val_mean_absolute_error: 1.0954 - val_mean_squared_error: 2.4285\n",
            "Epoch 236/1000\n",
            "217/245 [=========================>....] - ETA: 0s - loss: 2.4575 - mean_absolute_error: 1.1049 - mean_squared_error: 2.4575\n",
            "Epoch 236: val_loss improved from 2.42850 to 2.42386, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5145 - mean_absolute_error: 1.1135 - mean_squared_error: 2.5145 - val_loss: 2.4239 - val_mean_absolute_error: 1.0930 - val_mean_squared_error: 2.4239\n",
            "Epoch 237/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.5064 - mean_absolute_error: 1.1105 - mean_squared_error: 2.5064\n",
            "Epoch 237: val_loss did not improve from 2.42386\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5061 - mean_absolute_error: 1.1117 - mean_squared_error: 2.5061 - val_loss: 2.4243 - val_mean_absolute_error: 1.0907 - val_mean_squared_error: 2.4243\n",
            "Epoch 238/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 2.5327 - mean_absolute_error: 1.1173 - mean_squared_error: 2.5327\n",
            "Epoch 238: val_loss improved from 2.42386 to 2.41373, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5023 - mean_absolute_error: 1.1109 - mean_squared_error: 2.5023 - val_loss: 2.4137 - val_mean_absolute_error: 1.0911 - val_mean_squared_error: 2.4137\n",
            "Epoch 239/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.4987 - mean_absolute_error: 1.1093 - mean_squared_error: 2.4987\n",
            "Epoch 239: val_loss improved from 2.41373 to 2.40844, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4965 - mean_absolute_error: 1.1085 - mean_squared_error: 2.4965 - val_loss: 2.4084 - val_mean_absolute_error: 1.0898 - val_mean_squared_error: 2.4084\n",
            "Epoch 240/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.5150 - mean_absolute_error: 1.1113 - mean_squared_error: 2.5150\n",
            "Epoch 240: val_loss improved from 2.40844 to 2.40412, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4921 - mean_absolute_error: 1.1068 - mean_squared_error: 2.4921 - val_loss: 2.4041 - val_mean_absolute_error: 1.0887 - val_mean_squared_error: 2.4041\n",
            "Epoch 241/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.4847 - mean_absolute_error: 1.1038 - mean_squared_error: 2.4847\n",
            "Epoch 241: val_loss improved from 2.40412 to 2.39929, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4869 - mean_absolute_error: 1.1060 - mean_squared_error: 2.4869 - val_loss: 2.3993 - val_mean_absolute_error: 1.0882 - val_mean_squared_error: 2.3993\n",
            "Epoch 242/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 2.4590 - mean_absolute_error: 1.1013 - mean_squared_error: 2.4590\n",
            "Epoch 242: val_loss improved from 2.39929 to 2.39309, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4804 - mean_absolute_error: 1.1059 - mean_squared_error: 2.4804 - val_loss: 2.3931 - val_mean_absolute_error: 1.0873 - val_mean_squared_error: 2.3931\n",
            "Epoch 243/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.4980 - mean_absolute_error: 1.1095 - mean_squared_error: 2.4980\n",
            "Epoch 243: val_loss improved from 2.39309 to 2.39250, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4750 - mean_absolute_error: 1.1029 - mean_squared_error: 2.4750 - val_loss: 2.3925 - val_mean_absolute_error: 1.0843 - val_mean_squared_error: 2.3925\n",
            "Epoch 244/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.4804 - mean_absolute_error: 1.1039 - mean_squared_error: 2.4804\n",
            "Epoch 244: val_loss improved from 2.39250 to 2.38338, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4707 - mean_absolute_error: 1.1028 - mean_squared_error: 2.4707 - val_loss: 2.3834 - val_mean_absolute_error: 1.0857 - val_mean_squared_error: 2.3834\n",
            "Epoch 245/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 2.4530 - mean_absolute_error: 1.0977 - mean_squared_error: 2.4530\n",
            "Epoch 245: val_loss improved from 2.38338 to 2.37972, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4649 - mean_absolute_error: 1.1016 - mean_squared_error: 2.4649 - val_loss: 2.3797 - val_mean_absolute_error: 1.0830 - val_mean_squared_error: 2.3797\n",
            "Epoch 246/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.4314 - mean_absolute_error: 1.0951 - mean_squared_error: 2.4314\n",
            "Epoch 246: val_loss improved from 2.37972 to 2.37460, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4592 - mean_absolute_error: 1.0999 - mean_squared_error: 2.4592 - val_loss: 2.3746 - val_mean_absolute_error: 1.0817 - val_mean_squared_error: 2.3746\n",
            "Epoch 247/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.4533 - mean_absolute_error: 1.0995 - mean_squared_error: 2.4533\n",
            "Epoch 247: val_loss improved from 2.37460 to 2.37075, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4542 - mean_absolute_error: 1.0976 - mean_squared_error: 2.4542 - val_loss: 2.3708 - val_mean_absolute_error: 1.0806 - val_mean_squared_error: 2.3708\n",
            "Epoch 248/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 2.4144 - mean_absolute_error: 1.0900 - mean_squared_error: 2.4144\n",
            "Epoch 248: val_loss improved from 2.37075 to 2.36342, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4487 - mean_absolute_error: 1.0969 - mean_squared_error: 2.4487 - val_loss: 2.3634 - val_mean_absolute_error: 1.0830 - val_mean_squared_error: 2.3634\n",
            "Epoch 249/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.4447 - mean_absolute_error: 1.0970 - mean_squared_error: 2.4447\n",
            "Epoch 249: val_loss improved from 2.36342 to 2.36092, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4447 - mean_absolute_error: 1.0970 - mean_squared_error: 2.4447 - val_loss: 2.3609 - val_mean_absolute_error: 1.0795 - val_mean_squared_error: 2.3609\n",
            "Epoch 250/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.4425 - mean_absolute_error: 1.0982 - mean_squared_error: 2.4425\n",
            "Epoch 250: val_loss improved from 2.36092 to 2.35518, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4387 - mean_absolute_error: 1.0967 - mean_squared_error: 2.4387 - val_loss: 2.3552 - val_mean_absolute_error: 1.0781 - val_mean_squared_error: 2.3552\n",
            "Epoch 251/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.4024 - mean_absolute_error: 1.0863 - mean_squared_error: 2.4024\n",
            "Epoch 251: val_loss improved from 2.35518 to 2.34883, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4344 - mean_absolute_error: 1.0939 - mean_squared_error: 2.4344 - val_loss: 2.3488 - val_mean_absolute_error: 1.0788 - val_mean_squared_error: 2.3488\n",
            "Epoch 252/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.4588 - mean_absolute_error: 1.0986 - mean_squared_error: 2.4588\n",
            "Epoch 252: val_loss did not improve from 2.34883\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4285 - mean_absolute_error: 1.0942 - mean_squared_error: 2.4285 - val_loss: 2.3502 - val_mean_absolute_error: 1.0760 - val_mean_squared_error: 2.3502\n",
            "Epoch 253/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.4328 - mean_absolute_error: 1.0946 - mean_squared_error: 2.4328\n",
            "Epoch 253: val_loss improved from 2.34883 to 2.33953, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4242 - mean_absolute_error: 1.0935 - mean_squared_error: 2.4242 - val_loss: 2.3395 - val_mean_absolute_error: 1.0777 - val_mean_squared_error: 2.3395\n",
            "Epoch 254/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.4185 - mean_absolute_error: 1.0903 - mean_squared_error: 2.4185\n",
            "Epoch 254: val_loss did not improve from 2.33953\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4190 - mean_absolute_error: 1.0911 - mean_squared_error: 2.4190 - val_loss: 2.3397 - val_mean_absolute_error: 1.0728 - val_mean_squared_error: 2.3397\n",
            "Epoch 255/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.4477 - mean_absolute_error: 1.0994 - mean_squared_error: 2.4477\n",
            "Epoch 255: val_loss improved from 2.33953 to 2.33102, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4136 - mean_absolute_error: 1.0886 - mean_squared_error: 2.4136 - val_loss: 2.3310 - val_mean_absolute_error: 1.0740 - val_mean_squared_error: 2.3310\n",
            "Epoch 256/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.4158 - mean_absolute_error: 1.0915 - mean_squared_error: 2.4158\n",
            "Epoch 256: val_loss improved from 2.33102 to 2.32566, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4087 - mean_absolute_error: 1.0895 - mean_squared_error: 2.4087 - val_loss: 2.3257 - val_mean_absolute_error: 1.0756 - val_mean_squared_error: 2.3257\n",
            "Epoch 257/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.3857 - mean_absolute_error: 1.0842 - mean_squared_error: 2.3857\n",
            "Epoch 257: val_loss did not improve from 2.32566\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4031 - mean_absolute_error: 1.0872 - mean_squared_error: 2.4031 - val_loss: 2.3270 - val_mean_absolute_error: 1.0712 - val_mean_squared_error: 2.3270\n",
            "Epoch 258/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.3925 - mean_absolute_error: 1.0844 - mean_squared_error: 2.3925\n",
            "Epoch 258: val_loss improved from 2.32566 to 2.31634, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4005 - mean_absolute_error: 1.0871 - mean_squared_error: 2.4005 - val_loss: 2.3163 - val_mean_absolute_error: 1.0728 - val_mean_squared_error: 2.3163\n",
            "Epoch 259/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.3913 - mean_absolute_error: 1.0854 - mean_squared_error: 2.3913\n",
            "Epoch 259: val_loss improved from 2.31634 to 2.31222, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3941 - mean_absolute_error: 1.0859 - mean_squared_error: 2.3941 - val_loss: 2.3122 - val_mean_absolute_error: 1.0732 - val_mean_squared_error: 2.3122\n",
            "Epoch 260/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.3984 - mean_absolute_error: 1.0864 - mean_squared_error: 2.3984\n",
            "Epoch 260: val_loss improved from 2.31222 to 2.30713, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3885 - mean_absolute_error: 1.0855 - mean_squared_error: 2.3885 - val_loss: 2.3071 - val_mean_absolute_error: 1.0712 - val_mean_squared_error: 2.3071\n",
            "Epoch 261/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.3716 - mean_absolute_error: 1.0776 - mean_squared_error: 2.3716\n",
            "Epoch 261: val_loss improved from 2.30713 to 2.30559, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3845 - mean_absolute_error: 1.0823 - mean_squared_error: 2.3845 - val_loss: 2.3056 - val_mean_absolute_error: 1.0679 - val_mean_squared_error: 2.3056\n",
            "Epoch 262/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.3804 - mean_absolute_error: 1.0812 - mean_squared_error: 2.3804\n",
            "Epoch 262: val_loss improved from 2.30559 to 2.29882, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3793 - mean_absolute_error: 1.0822 - mean_squared_error: 2.3793 - val_loss: 2.2988 - val_mean_absolute_error: 1.0679 - val_mean_squared_error: 2.2988\n",
            "Epoch 263/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.4041 - mean_absolute_error: 1.0872 - mean_squared_error: 2.4041\n",
            "Epoch 263: val_loss improved from 2.29882 to 2.29676, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3737 - mean_absolute_error: 1.0809 - mean_squared_error: 2.3737 - val_loss: 2.2968 - val_mean_absolute_error: 1.0659 - val_mean_squared_error: 2.2968\n",
            "Epoch 264/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.3715 - mean_absolute_error: 1.0792 - mean_squared_error: 2.3715\n",
            "Epoch 264: val_loss improved from 2.29676 to 2.28920, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3703 - mean_absolute_error: 1.0803 - mean_squared_error: 2.3703 - val_loss: 2.2892 - val_mean_absolute_error: 1.0672 - val_mean_squared_error: 2.2892\n",
            "Epoch 265/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.3669 - mean_absolute_error: 1.0822 - mean_squared_error: 2.3669\n",
            "Epoch 265: val_loss improved from 2.28920 to 2.28746, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3651 - mean_absolute_error: 1.0791 - mean_squared_error: 2.3651 - val_loss: 2.2875 - val_mean_absolute_error: 1.0652 - val_mean_squared_error: 2.2875\n",
            "Epoch 266/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.3696 - mean_absolute_error: 1.0801 - mean_squared_error: 2.3696\n",
            "Epoch 266: val_loss improved from 2.28746 to 2.28111, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3610 - mean_absolute_error: 1.0785 - mean_squared_error: 2.3610 - val_loss: 2.2811 - val_mean_absolute_error: 1.0652 - val_mean_squared_error: 2.2811\n",
            "Epoch 267/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.3635 - mean_absolute_error: 1.0803 - mean_squared_error: 2.3635\n",
            "Epoch 267: val_loss improved from 2.28111 to 2.27605, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.3558 - mean_absolute_error: 1.0780 - mean_squared_error: 2.3558 - val_loss: 2.2760 - val_mean_absolute_error: 1.0633 - val_mean_squared_error: 2.2760\n",
            "Epoch 268/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.3378 - mean_absolute_error: 1.0752 - mean_squared_error: 2.3378\n",
            "Epoch 268: val_loss improved from 2.27605 to 2.27225, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.3503 - mean_absolute_error: 1.0759 - mean_squared_error: 2.3503 - val_loss: 2.2722 - val_mean_absolute_error: 1.0620 - val_mean_squared_error: 2.2722\n",
            "Epoch 269/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.3516 - mean_absolute_error: 1.0761 - mean_squared_error: 2.3516\n",
            "Epoch 269: val_loss improved from 2.27225 to 2.26988, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.3465 - mean_absolute_error: 1.0745 - mean_squared_error: 2.3465 - val_loss: 2.2699 - val_mean_absolute_error: 1.0610 - val_mean_squared_error: 2.2699\n",
            "Epoch 270/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.3156 - mean_absolute_error: 1.0681 - mean_squared_error: 2.3156\n",
            "Epoch 270: val_loss improved from 2.26988 to 2.26287, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.3420 - mean_absolute_error: 1.0737 - mean_squared_error: 2.3420 - val_loss: 2.2629 - val_mean_absolute_error: 1.0623 - val_mean_squared_error: 2.2629\n",
            "Epoch 271/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 2.3501 - mean_absolute_error: 1.0768 - mean_squared_error: 2.3501\n",
            "Epoch 271: val_loss improved from 2.26287 to 2.25895, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3352 - mean_absolute_error: 1.0720 - mean_squared_error: 2.3352 - val_loss: 2.2590 - val_mean_absolute_error: 1.0624 - val_mean_squared_error: 2.2590\n",
            "Epoch 272/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.3312 - mean_absolute_error: 1.0718 - mean_squared_error: 2.3312\n",
            "Epoch 272: val_loss did not improve from 2.25895\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3312 - mean_absolute_error: 1.0718 - mean_squared_error: 2.3312 - val_loss: 2.2652 - val_mean_absolute_error: 1.0574 - val_mean_squared_error: 2.2652\n",
            "Epoch 273/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 2.3547 - mean_absolute_error: 1.0777 - mean_squared_error: 2.3547\n",
            "Epoch 273: val_loss improved from 2.25895 to 2.25170, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3283 - mean_absolute_error: 1.0698 - mean_squared_error: 2.3283 - val_loss: 2.2517 - val_mean_absolute_error: 1.0584 - val_mean_squared_error: 2.2517\n",
            "Epoch 274/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.3492 - mean_absolute_error: 1.0763 - mean_squared_error: 2.3492\n",
            "Epoch 274: val_loss improved from 2.25170 to 2.24861, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3233 - mean_absolute_error: 1.0704 - mean_squared_error: 2.3233 - val_loss: 2.2486 - val_mean_absolute_error: 1.0576 - val_mean_squared_error: 2.2486\n",
            "Epoch 275/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.3293 - mean_absolute_error: 1.0710 - mean_squared_error: 2.3293\n",
            "Epoch 275: val_loss did not improve from 2.24861\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3179 - mean_absolute_error: 1.0674 - mean_squared_error: 2.3179 - val_loss: 2.2538 - val_mean_absolute_error: 1.0554 - val_mean_squared_error: 2.2538\n",
            "Epoch 276/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.2873 - mean_absolute_error: 1.0595 - mean_squared_error: 2.2873\n",
            "Epoch 276: val_loss improved from 2.24861 to 2.24230, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3143 - mean_absolute_error: 1.0653 - mean_squared_error: 2.3143 - val_loss: 2.2423 - val_mean_absolute_error: 1.0550 - val_mean_squared_error: 2.2423\n",
            "Epoch 277/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.3149 - mean_absolute_error: 1.0694 - mean_squared_error: 2.3149\n",
            "Epoch 277: val_loss improved from 2.24230 to 2.23368, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3096 - mean_absolute_error: 1.0680 - mean_squared_error: 2.3096 - val_loss: 2.2337 - val_mean_absolute_error: 1.0560 - val_mean_squared_error: 2.2337\n",
            "Epoch 278/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.3158 - mean_absolute_error: 1.0684 - mean_squared_error: 2.3158\n",
            "Epoch 278: val_loss improved from 2.23368 to 2.22966, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3039 - mean_absolute_error: 1.0654 - mean_squared_error: 2.3039 - val_loss: 2.2297 - val_mean_absolute_error: 1.0565 - val_mean_squared_error: 2.2297\n",
            "Epoch 279/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 2.2951 - mean_absolute_error: 1.0623 - mean_squared_error: 2.2951\n",
            "Epoch 279: val_loss improved from 2.22966 to 2.22630, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3013 - mean_absolute_error: 1.0633 - mean_squared_error: 2.3013 - val_loss: 2.2263 - val_mean_absolute_error: 1.0536 - val_mean_squared_error: 2.2263\n",
            "Epoch 280/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.3054 - mean_absolute_error: 1.0656 - mean_squared_error: 2.3054\n",
            "Epoch 280: val_loss improved from 2.22630 to 2.22141, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2950 - mean_absolute_error: 1.0644 - mean_squared_error: 2.2950 - val_loss: 2.2214 - val_mean_absolute_error: 1.0535 - val_mean_squared_error: 2.2214\n",
            "Epoch 281/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.2924 - mean_absolute_error: 1.0620 - mean_squared_error: 2.2924\n",
            "Epoch 281: val_loss did not improve from 2.22141\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2919 - mean_absolute_error: 1.0626 - mean_squared_error: 2.2919 - val_loss: 2.2224 - val_mean_absolute_error: 1.0499 - val_mean_squared_error: 2.2224\n",
            "Epoch 282/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.2635 - mean_absolute_error: 1.0558 - mean_squared_error: 2.2635\n",
            "Epoch 282: val_loss did not improve from 2.22141\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2892 - mean_absolute_error: 1.0601 - mean_squared_error: 2.2892 - val_loss: 2.2224 - val_mean_absolute_error: 1.0499 - val_mean_squared_error: 2.2224\n",
            "Epoch 283/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.2855 - mean_absolute_error: 1.0590 - mean_squared_error: 2.2855\n",
            "Epoch 283: val_loss improved from 2.22141 to 2.21015, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2839 - mean_absolute_error: 1.0599 - mean_squared_error: 2.2839 - val_loss: 2.2101 - val_mean_absolute_error: 1.0520 - val_mean_squared_error: 2.2101\n",
            "Epoch 284/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.2881 - mean_absolute_error: 1.0606 - mean_squared_error: 2.2881\n",
            "Epoch 284: val_loss improved from 2.21015 to 2.20665, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2773 - mean_absolute_error: 1.0600 - mean_squared_error: 2.2773 - val_loss: 2.2067 - val_mean_absolute_error: 1.0526 - val_mean_squared_error: 2.2067\n",
            "Epoch 285/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.2681 - mean_absolute_error: 1.0562 - mean_squared_error: 2.2681\n",
            "Epoch 285: val_loss improved from 2.20665 to 2.20218, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2741 - mean_absolute_error: 1.0582 - mean_squared_error: 2.2741 - val_loss: 2.2022 - val_mean_absolute_error: 1.0496 - val_mean_squared_error: 2.2022\n",
            "Epoch 286/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.2779 - mean_absolute_error: 1.0582 - mean_squared_error: 2.2779\n",
            "Epoch 286: val_loss improved from 2.20218 to 2.19831, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2707 - mean_absolute_error: 1.0576 - mean_squared_error: 2.2707 - val_loss: 2.1983 - val_mean_absolute_error: 1.0489 - val_mean_squared_error: 2.1983\n",
            "Epoch 287/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.2651 - mean_absolute_error: 1.0574 - mean_squared_error: 2.2651\n",
            "Epoch 287: val_loss improved from 2.19831 to 2.19643, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2651 - mean_absolute_error: 1.0574 - mean_squared_error: 2.2651 - val_loss: 2.1964 - val_mean_absolute_error: 1.0466 - val_mean_squared_error: 2.1964\n",
            "Epoch 288/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.2557 - mean_absolute_error: 1.0520 - mean_squared_error: 2.2557\n",
            "Epoch 288: val_loss improved from 2.19643 to 2.19124, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2617 - mean_absolute_error: 1.0546 - mean_squared_error: 2.2617 - val_loss: 2.1912 - val_mean_absolute_error: 1.0471 - val_mean_squared_error: 2.1912\n",
            "Epoch 289/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.2553 - mean_absolute_error: 1.0538 - mean_squared_error: 2.2553\n",
            "Epoch 289: val_loss improved from 2.19124 to 2.18681, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2576 - mean_absolute_error: 1.0539 - mean_squared_error: 2.2576 - val_loss: 2.1868 - val_mean_absolute_error: 1.0460 - val_mean_squared_error: 2.1868\n",
            "Epoch 290/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.2656 - mean_absolute_error: 1.0579 - mean_squared_error: 2.2656\n",
            "Epoch 290: val_loss did not improve from 2.18681\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2542 - mean_absolute_error: 1.0550 - mean_squared_error: 2.2542 - val_loss: 2.1884 - val_mean_absolute_error: 1.0445 - val_mean_squared_error: 2.1884\n",
            "Epoch 291/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.2498 - mean_absolute_error: 1.0518 - mean_squared_error: 2.2498\n",
            "Epoch 291: val_loss improved from 2.18681 to 2.18112, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2511 - mean_absolute_error: 1.0529 - mean_squared_error: 2.2511 - val_loss: 2.1811 - val_mean_absolute_error: 1.0438 - val_mean_squared_error: 2.1811\n",
            "Epoch 292/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.2325 - mean_absolute_error: 1.0482 - mean_squared_error: 2.2325\n",
            "Epoch 292: val_loss improved from 2.18112 to 2.17646, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2458 - mean_absolute_error: 1.0521 - mean_squared_error: 2.2458 - val_loss: 2.1765 - val_mean_absolute_error: 1.0436 - val_mean_squared_error: 2.1765\n",
            "Epoch 293/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.2521 - mean_absolute_error: 1.0542 - mean_squared_error: 2.2521\n",
            "Epoch 293: val_loss improved from 2.17646 to 2.17338, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2417 - mean_absolute_error: 1.0518 - mean_squared_error: 2.2417 - val_loss: 2.1734 - val_mean_absolute_error: 1.0446 - val_mean_squared_error: 2.1734\n",
            "Epoch 294/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.2302 - mean_absolute_error: 1.0484 - mean_squared_error: 2.2302\n",
            "Epoch 294: val_loss improved from 2.17338 to 2.16969, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2378 - mean_absolute_error: 1.0499 - mean_squared_error: 2.2378 - val_loss: 2.1697 - val_mean_absolute_error: 1.0422 - val_mean_squared_error: 2.1697\n",
            "Epoch 295/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.2380 - mean_absolute_error: 1.0472 - mean_squared_error: 2.2380\n",
            "Epoch 295: val_loss improved from 2.16969 to 2.16700, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.2336 - mean_absolute_error: 1.0486 - mean_squared_error: 2.2336 - val_loss: 2.1670 - val_mean_absolute_error: 1.0438 - val_mean_squared_error: 2.1670\n",
            "Epoch 296/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.2194 - mean_absolute_error: 1.0448 - mean_squared_error: 2.2194\n",
            "Epoch 296: val_loss improved from 2.16700 to 2.16372, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2318 - mean_absolute_error: 1.0487 - mean_squared_error: 2.2318 - val_loss: 2.1637 - val_mean_absolute_error: 1.0416 - val_mean_squared_error: 2.1637\n",
            "Epoch 297/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.2366 - mean_absolute_error: 1.0492 - mean_squared_error: 2.2366\n",
            "Epoch 297: val_loss did not improve from 2.16372\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2271 - mean_absolute_error: 1.0480 - mean_squared_error: 2.2271 - val_loss: 2.1653 - val_mean_absolute_error: 1.0420 - val_mean_squared_error: 2.1653\n",
            "Epoch 298/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 2.2125 - mean_absolute_error: 1.0436 - mean_squared_error: 2.2125\n",
            "Epoch 298: val_loss improved from 2.16372 to 2.15771, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2230 - mean_absolute_error: 1.0468 - mean_squared_error: 2.2230 - val_loss: 2.1577 - val_mean_absolute_error: 1.0408 - val_mean_squared_error: 2.1577\n",
            "Epoch 299/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.1887 - mean_absolute_error: 1.0390 - mean_squared_error: 2.1887\n",
            "Epoch 299: val_loss improved from 2.15771 to 2.15400, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2202 - mean_absolute_error: 1.0482 - mean_squared_error: 2.2202 - val_loss: 2.1540 - val_mean_absolute_error: 1.0411 - val_mean_squared_error: 2.1540\n",
            "Epoch 300/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.2326 - mean_absolute_error: 1.0504 - mean_squared_error: 2.2326\n",
            "Epoch 300: val_loss improved from 2.15400 to 2.15321, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2168 - mean_absolute_error: 1.0466 - mean_squared_error: 2.2168 - val_loss: 2.1532 - val_mean_absolute_error: 1.0392 - val_mean_squared_error: 2.1532\n",
            "Epoch 301/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 2.2071 - mean_absolute_error: 1.0420 - mean_squared_error: 2.2071\n",
            "Epoch 301: val_loss improved from 2.15321 to 2.14778, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2109 - mean_absolute_error: 1.0449 - mean_squared_error: 2.2109 - val_loss: 2.1478 - val_mean_absolute_error: 1.0404 - val_mean_squared_error: 2.1478\n",
            "Epoch 302/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.2087 - mean_absolute_error: 1.0452 - mean_squared_error: 2.2087\n",
            "Epoch 302: val_loss improved from 2.14778 to 2.14677, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2090 - mean_absolute_error: 1.0453 - mean_squared_error: 2.2090 - val_loss: 2.1468 - val_mean_absolute_error: 1.0390 - val_mean_squared_error: 2.1468\n",
            "Epoch 303/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.2368 - mean_absolute_error: 1.0528 - mean_squared_error: 2.2368\n",
            "Epoch 303: val_loss improved from 2.14677 to 2.14216, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2054 - mean_absolute_error: 1.0457 - mean_squared_error: 2.2054 - val_loss: 2.1422 - val_mean_absolute_error: 1.0380 - val_mean_squared_error: 2.1422\n",
            "Epoch 304/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.2034 - mean_absolute_error: 1.0455 - mean_squared_error: 2.2034\n",
            "Epoch 304: val_loss improved from 2.14216 to 2.13767, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2021 - mean_absolute_error: 1.0436 - mean_squared_error: 2.2021 - val_loss: 2.1377 - val_mean_absolute_error: 1.0381 - val_mean_squared_error: 2.1377\n",
            "Epoch 305/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.1995 - mean_absolute_error: 1.0423 - mean_squared_error: 2.1995\n",
            "Epoch 305: val_loss improved from 2.13767 to 2.13456, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1969 - mean_absolute_error: 1.0439 - mean_squared_error: 2.1969 - val_loss: 2.1346 - val_mean_absolute_error: 1.0371 - val_mean_squared_error: 2.1346\n",
            "Epoch 306/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.2429 - mean_absolute_error: 1.0536 - mean_squared_error: 2.2429\n",
            "Epoch 306: val_loss improved from 2.13456 to 2.13171, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1949 - mean_absolute_error: 1.0439 - mean_squared_error: 2.1949 - val_loss: 2.1317 - val_mean_absolute_error: 1.0360 - val_mean_squared_error: 2.1317\n",
            "Epoch 307/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 2.2160 - mean_absolute_error: 1.0507 - mean_squared_error: 2.2160\n",
            "Epoch 307: val_loss improved from 2.13171 to 2.12800, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1919 - mean_absolute_error: 1.0427 - mean_squared_error: 2.1919 - val_loss: 2.1280 - val_mean_absolute_error: 1.0350 - val_mean_squared_error: 2.1280\n",
            "Epoch 308/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.1714 - mean_absolute_error: 1.0357 - mean_squared_error: 2.1714\n",
            "Epoch 308: val_loss improved from 2.12800 to 2.12534, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1882 - mean_absolute_error: 1.0406 - mean_squared_error: 2.1882 - val_loss: 2.1253 - val_mean_absolute_error: 1.0351 - val_mean_squared_error: 2.1253\n",
            "Epoch 309/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.2051 - mean_absolute_error: 1.0440 - mean_squared_error: 2.2051\n",
            "Epoch 309: val_loss did not improve from 2.12534\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1826 - mean_absolute_error: 1.0407 - mean_squared_error: 2.1826 - val_loss: 2.1257 - val_mean_absolute_error: 1.0370 - val_mean_squared_error: 2.1257\n",
            "Epoch 310/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.1830 - mean_absolute_error: 1.0392 - mean_squared_error: 2.1830\n",
            "Epoch 310: val_loss improved from 2.12534 to 2.11910, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1827 - mean_absolute_error: 1.0411 - mean_squared_error: 2.1827 - val_loss: 2.1191 - val_mean_absolute_error: 1.0343 - val_mean_squared_error: 2.1191\n",
            "Epoch 311/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.1716 - mean_absolute_error: 1.0430 - mean_squared_error: 2.1716\n",
            "Epoch 311: val_loss improved from 2.11910 to 2.11746, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1773 - mean_absolute_error: 1.0416 - mean_squared_error: 2.1773 - val_loss: 2.1175 - val_mean_absolute_error: 1.0350 - val_mean_squared_error: 2.1175\n",
            "Epoch 312/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.1899 - mean_absolute_error: 1.0451 - mean_squared_error: 2.1899\n",
            "Epoch 312: val_loss improved from 2.11746 to 2.11601, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1753 - mean_absolute_error: 1.0406 - mean_squared_error: 2.1753 - val_loss: 2.1160 - val_mean_absolute_error: 1.0340 - val_mean_squared_error: 2.1160\n",
            "Epoch 313/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.1820 - mean_absolute_error: 1.0406 - mean_squared_error: 2.1820\n",
            "Epoch 313: val_loss improved from 2.11601 to 2.11556, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1719 - mean_absolute_error: 1.0374 - mean_squared_error: 2.1719 - val_loss: 2.1156 - val_mean_absolute_error: 1.0348 - val_mean_squared_error: 2.1156\n",
            "Epoch 314/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.1687 - mean_absolute_error: 1.0390 - mean_squared_error: 2.1687\n",
            "Epoch 314: val_loss improved from 2.11556 to 2.10909, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1687 - mean_absolute_error: 1.0390 - mean_squared_error: 2.1687 - val_loss: 2.1091 - val_mean_absolute_error: 1.0341 - val_mean_squared_error: 2.1091\n",
            "Epoch 315/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.1384 - mean_absolute_error: 1.0324 - mean_squared_error: 2.1384\n",
            "Epoch 315: val_loss improved from 2.10909 to 2.10713, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1642 - mean_absolute_error: 1.0384 - mean_squared_error: 2.1642 - val_loss: 2.1071 - val_mean_absolute_error: 1.0334 - val_mean_squared_error: 2.1071\n",
            "Epoch 316/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 2.2064 - mean_absolute_error: 1.0474 - mean_squared_error: 2.2064\n",
            "Epoch 316: val_loss improved from 2.10713 to 2.10260, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1624 - mean_absolute_error: 1.0386 - mean_squared_error: 2.1624 - val_loss: 2.1026 - val_mean_absolute_error: 1.0328 - val_mean_squared_error: 2.1026\n",
            "Epoch 317/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.1390 - mean_absolute_error: 1.0344 - mean_squared_error: 2.1390\n",
            "Epoch 317: val_loss improved from 2.10260 to 2.10056, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1583 - mean_absolute_error: 1.0376 - mean_squared_error: 2.1583 - val_loss: 2.1006 - val_mean_absolute_error: 1.0314 - val_mean_squared_error: 2.1006\n",
            "Epoch 318/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.1673 - mean_absolute_error: 1.0401 - mean_squared_error: 2.1673\n",
            "Epoch 318: val_loss improved from 2.10056 to 2.09706, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1547 - mean_absolute_error: 1.0367 - mean_squared_error: 2.1547 - val_loss: 2.0971 - val_mean_absolute_error: 1.0316 - val_mean_squared_error: 2.0971\n",
            "Epoch 319/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 2.1550 - mean_absolute_error: 1.0368 - mean_squared_error: 2.1550\n",
            "Epoch 319: val_loss improved from 2.09706 to 2.09437, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1523 - mean_absolute_error: 1.0360 - mean_squared_error: 2.1523 - val_loss: 2.0944 - val_mean_absolute_error: 1.0305 - val_mean_squared_error: 2.0944\n",
            "Epoch 320/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.1567 - mean_absolute_error: 1.0371 - mean_squared_error: 2.1567\n",
            "Epoch 320: val_loss improved from 2.09437 to 2.09216, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1487 - mean_absolute_error: 1.0354 - mean_squared_error: 2.1487 - val_loss: 2.0922 - val_mean_absolute_error: 1.0313 - val_mean_squared_error: 2.0922\n",
            "Epoch 321/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 2.1766 - mean_absolute_error: 1.0454 - mean_squared_error: 2.1766\n",
            "Epoch 321: val_loss improved from 2.09216 to 2.08975, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1465 - mean_absolute_error: 1.0352 - mean_squared_error: 2.1465 - val_loss: 2.0898 - val_mean_absolute_error: 1.0309 - val_mean_squared_error: 2.0898\n",
            "Epoch 322/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.1431 - mean_absolute_error: 1.0327 - mean_squared_error: 2.1431\n",
            "Epoch 322: val_loss improved from 2.08975 to 2.08641, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1423 - mean_absolute_error: 1.0348 - mean_squared_error: 2.1423 - val_loss: 2.0864 - val_mean_absolute_error: 1.0292 - val_mean_squared_error: 2.0864\n",
            "Epoch 323/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.1428 - mean_absolute_error: 1.0341 - mean_squared_error: 2.1428\n",
            "Epoch 323: val_loss improved from 2.08641 to 2.08432, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1402 - mean_absolute_error: 1.0341 - mean_squared_error: 2.1402 - val_loss: 2.0843 - val_mean_absolute_error: 1.0298 - val_mean_squared_error: 2.0843\n",
            "Epoch 324/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.1379 - mean_absolute_error: 1.0350 - mean_squared_error: 2.1379\n",
            "Epoch 324: val_loss improved from 2.08432 to 2.08140, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1379 - mean_absolute_error: 1.0351 - mean_squared_error: 2.1379 - val_loss: 2.0814 - val_mean_absolute_error: 1.0289 - val_mean_squared_error: 2.0814\n",
            "Epoch 325/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.1334 - mean_absolute_error: 1.0333 - mean_squared_error: 2.1334\n",
            "Epoch 325: val_loss did not improve from 2.08140\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1339 - mean_absolute_error: 1.0330 - mean_squared_error: 2.1339 - val_loss: 2.0815 - val_mean_absolute_error: 1.0307 - val_mean_squared_error: 2.0815\n",
            "Epoch 326/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 2.1197 - mean_absolute_error: 1.0313 - mean_squared_error: 2.1197\n",
            "Epoch 326: val_loss improved from 2.08140 to 2.07745, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1313 - mean_absolute_error: 1.0337 - mean_squared_error: 2.1313 - val_loss: 2.0774 - val_mean_absolute_error: 1.0293 - val_mean_squared_error: 2.0774\n",
            "Epoch 327/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 2.1308 - mean_absolute_error: 1.0393 - mean_squared_error: 2.1308\n",
            "Epoch 327: val_loss improved from 2.07745 to 2.07432, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1307 - mean_absolute_error: 1.0357 - mean_squared_error: 2.1307 - val_loss: 2.0743 - val_mean_absolute_error: 1.0271 - val_mean_squared_error: 2.0743\n",
            "Epoch 328/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.1160 - mean_absolute_error: 1.0310 - mean_squared_error: 2.1160\n",
            "Epoch 328: val_loss improved from 2.07432 to 2.07338, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1257 - mean_absolute_error: 1.0311 - mean_squared_error: 2.1257 - val_loss: 2.0734 - val_mean_absolute_error: 1.0273 - val_mean_squared_error: 2.0734\n",
            "Epoch 329/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.0972 - mean_absolute_error: 1.0295 - mean_squared_error: 2.0972\n",
            "Epoch 329: val_loss improved from 2.07338 to 2.07321, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1225 - mean_absolute_error: 1.0311 - mean_squared_error: 2.1225 - val_loss: 2.0732 - val_mean_absolute_error: 1.0292 - val_mean_squared_error: 2.0732\n",
            "Epoch 330/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.1255 - mean_absolute_error: 1.0314 - mean_squared_error: 2.1255\n",
            "Epoch 330: val_loss did not improve from 2.07321\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1204 - mean_absolute_error: 1.0312 - mean_squared_error: 2.1204 - val_loss: 2.0838 - val_mean_absolute_error: 1.0349 - val_mean_squared_error: 2.0838\n",
            "Epoch 331/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.1332 - mean_absolute_error: 1.0351 - mean_squared_error: 2.1332\n",
            "Epoch 331: val_loss improved from 2.07321 to 2.06532, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1185 - mean_absolute_error: 1.0324 - mean_squared_error: 2.1185 - val_loss: 2.0653 - val_mean_absolute_error: 1.0262 - val_mean_squared_error: 2.0653\n",
            "Epoch 332/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.1205 - mean_absolute_error: 1.0320 - mean_squared_error: 2.1205\n",
            "Epoch 332: val_loss did not improve from 2.06532\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1150 - mean_absolute_error: 1.0307 - mean_squared_error: 2.1150 - val_loss: 2.0680 - val_mean_absolute_error: 1.0292 - val_mean_squared_error: 2.0680\n",
            "Epoch 333/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 2.1222 - mean_absolute_error: 1.0291 - mean_squared_error: 2.1222\n",
            "Epoch 333: val_loss improved from 2.06532 to 2.06171, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1118 - mean_absolute_error: 1.0296 - mean_squared_error: 2.1118 - val_loss: 2.0617 - val_mean_absolute_error: 1.0273 - val_mean_squared_error: 2.0617\n",
            "Epoch 334/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.0833 - mean_absolute_error: 1.0249 - mean_squared_error: 2.0833\n",
            "Epoch 334: val_loss improved from 2.06171 to 2.06033, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1106 - mean_absolute_error: 1.0308 - mean_squared_error: 2.1106 - val_loss: 2.0603 - val_mean_absolute_error: 1.0266 - val_mean_squared_error: 2.0603\n",
            "Epoch 335/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.0998 - mean_absolute_error: 1.0293 - mean_squared_error: 2.0998\n",
            "Epoch 335: val_loss improved from 2.06033 to 2.05618, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1099 - mean_absolute_error: 1.0307 - mean_squared_error: 2.1099 - val_loss: 2.0562 - val_mean_absolute_error: 1.0249 - val_mean_squared_error: 2.0562\n",
            "Epoch 336/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.1057 - mean_absolute_error: 1.0319 - mean_squared_error: 2.1057\n",
            "Epoch 336: val_loss did not improve from 2.05618\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0995 - mean_absolute_error: 1.0287 - mean_squared_error: 2.0995 - val_loss: 2.0655 - val_mean_absolute_error: 1.0306 - val_mean_squared_error: 2.0655\n",
            "Epoch 337/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.1076 - mean_absolute_error: 1.0292 - mean_squared_error: 2.1076\n",
            "Epoch 337: val_loss improved from 2.05618 to 2.05356, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1018 - mean_absolute_error: 1.0287 - mean_squared_error: 2.1018 - val_loss: 2.0536 - val_mean_absolute_error: 1.0241 - val_mean_squared_error: 2.0536\n",
            "Epoch 338/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.0851 - mean_absolute_error: 1.0254 - mean_squared_error: 2.0851\n",
            "Epoch 338: val_loss improved from 2.05356 to 2.05069, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1002 - mean_absolute_error: 1.0286 - mean_squared_error: 2.1002 - val_loss: 2.0507 - val_mean_absolute_error: 1.0252 - val_mean_squared_error: 2.0507\n",
            "Epoch 339/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 2.0820 - mean_absolute_error: 1.0262 - mean_squared_error: 2.0820\n",
            "Epoch 339: val_loss improved from 2.05069 to 2.04977, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0966 - mean_absolute_error: 1.0287 - mean_squared_error: 2.0966 - val_loss: 2.0498 - val_mean_absolute_error: 1.0223 - val_mean_squared_error: 2.0498\n",
            "Epoch 340/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.0974 - mean_absolute_error: 1.0274 - mean_squared_error: 2.0974\n",
            "Epoch 340: val_loss improved from 2.04977 to 2.04603, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0954 - mean_absolute_error: 1.0258 - mean_squared_error: 2.0954 - val_loss: 2.0460 - val_mean_absolute_error: 1.0248 - val_mean_squared_error: 2.0460\n",
            "Epoch 341/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.0932 - mean_absolute_error: 1.0296 - mean_squared_error: 2.0932\n",
            "Epoch 341: val_loss improved from 2.04603 to 2.04448, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0927 - mean_absolute_error: 1.0284 - mean_squared_error: 2.0927 - val_loss: 2.0445 - val_mean_absolute_error: 1.0250 - val_mean_squared_error: 2.0445\n",
            "Epoch 342/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.0952 - mean_absolute_error: 1.0273 - mean_squared_error: 2.0952\n",
            "Epoch 342: val_loss did not improve from 2.04448\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0883 - mean_absolute_error: 1.0260 - mean_squared_error: 2.0883 - val_loss: 2.0497 - val_mean_absolute_error: 1.0284 - val_mean_squared_error: 2.0497\n",
            "Epoch 343/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.1023 - mean_absolute_error: 1.0311 - mean_squared_error: 2.1023\n",
            "Epoch 343: val_loss improved from 2.04448 to 2.03933, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0859 - mean_absolute_error: 1.0274 - mean_squared_error: 2.0859 - val_loss: 2.0393 - val_mean_absolute_error: 1.0222 - val_mean_squared_error: 2.0393\n",
            "Epoch 344/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.0719 - mean_absolute_error: 1.0234 - mean_squared_error: 2.0719\n",
            "Epoch 344: val_loss did not improve from 2.03933\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0855 - mean_absolute_error: 1.0262 - mean_squared_error: 2.0855 - val_loss: 2.0404 - val_mean_absolute_error: 1.0242 - val_mean_squared_error: 2.0404\n",
            "Epoch 345/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.0941 - mean_absolute_error: 1.0281 - mean_squared_error: 2.0941\n",
            "Epoch 345: val_loss improved from 2.03933 to 2.03628, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0839 - mean_absolute_error: 1.0270 - mean_squared_error: 2.0839 - val_loss: 2.0363 - val_mean_absolute_error: 1.0232 - val_mean_squared_error: 2.0363\n",
            "Epoch 346/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.0342 - mean_absolute_error: 1.0148 - mean_squared_error: 2.0342\n",
            "Epoch 346: val_loss did not improve from 2.03628\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0792 - mean_absolute_error: 1.0237 - mean_squared_error: 2.0792 - val_loss: 2.0422 - val_mean_absolute_error: 1.0271 - val_mean_squared_error: 2.0422\n",
            "Epoch 347/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.0806 - mean_absolute_error: 1.0281 - mean_squared_error: 2.0806\n",
            "Epoch 347: val_loss improved from 2.03628 to 2.03138, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0794 - mean_absolute_error: 1.0270 - mean_squared_error: 2.0794 - val_loss: 2.0314 - val_mean_absolute_error: 1.0220 - val_mean_squared_error: 2.0314\n",
            "Epoch 348/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.0855 - mean_absolute_error: 1.0262 - mean_squared_error: 2.0855\n",
            "Epoch 348: val_loss improved from 2.03138 to 2.02952, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0764 - mean_absolute_error: 1.0249 - mean_squared_error: 2.0764 - val_loss: 2.0295 - val_mean_absolute_error: 1.0213 - val_mean_squared_error: 2.0295\n",
            "Epoch 349/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 2.0676 - mean_absolute_error: 1.0219 - mean_squared_error: 2.0676\n",
            "Epoch 349: val_loss improved from 2.02952 to 2.02777, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0712 - mean_absolute_error: 1.0241 - mean_squared_error: 2.0712 - val_loss: 2.0278 - val_mean_absolute_error: 1.0202 - val_mean_squared_error: 2.0278\n",
            "Epoch 350/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.0719 - mean_absolute_error: 1.0243 - mean_squared_error: 2.0719\n",
            "Epoch 350: val_loss improved from 2.02777 to 2.02729, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0702 - mean_absolute_error: 1.0248 - mean_squared_error: 2.0702 - val_loss: 2.0273 - val_mean_absolute_error: 1.0218 - val_mean_squared_error: 2.0273\n",
            "Epoch 351/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.0390 - mean_absolute_error: 1.0198 - mean_squared_error: 2.0390\n",
            "Epoch 351: val_loss improved from 2.02729 to 2.02552, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0686 - mean_absolute_error: 1.0249 - mean_squared_error: 2.0686 - val_loss: 2.0255 - val_mean_absolute_error: 1.0211 - val_mean_squared_error: 2.0255\n",
            "Epoch 352/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 2.0778 - mean_absolute_error: 1.0255 - mean_squared_error: 2.0778\n",
            "Epoch 352: val_loss improved from 2.02552 to 2.02300, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0656 - mean_absolute_error: 1.0234 - mean_squared_error: 2.0656 - val_loss: 2.0230 - val_mean_absolute_error: 1.0208 - val_mean_squared_error: 2.0230\n",
            "Epoch 353/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.0809 - mean_absolute_error: 1.0274 - mean_squared_error: 2.0809\n",
            "Epoch 353: val_loss improved from 2.02300 to 2.02157, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0635 - mean_absolute_error: 1.0231 - mean_squared_error: 2.0635 - val_loss: 2.0216 - val_mean_absolute_error: 1.0184 - val_mean_squared_error: 2.0216\n",
            "Epoch 354/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.0809 - mean_absolute_error: 1.0279 - mean_squared_error: 2.0809\n",
            "Epoch 354: val_loss did not improve from 2.02157\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0615 - mean_absolute_error: 1.0215 - mean_squared_error: 2.0615 - val_loss: 2.0248 - val_mean_absolute_error: 1.0241 - val_mean_squared_error: 2.0248\n",
            "Epoch 355/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.0467 - mean_absolute_error: 1.0222 - mean_squared_error: 2.0467\n",
            "Epoch 355: val_loss improved from 2.02157 to 2.01702, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0588 - mean_absolute_error: 1.0231 - mean_squared_error: 2.0588 - val_loss: 2.0170 - val_mean_absolute_error: 1.0199 - val_mean_squared_error: 2.0170\n",
            "Epoch 356/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.0567 - mean_absolute_error: 1.0242 - mean_squared_error: 2.0567\n",
            "Epoch 356: val_loss improved from 2.01702 to 2.01401, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0587 - mean_absolute_error: 1.0237 - mean_squared_error: 2.0587 - val_loss: 2.0140 - val_mean_absolute_error: 1.0178 - val_mean_squared_error: 2.0140\n",
            "Epoch 357/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.0642 - mean_absolute_error: 1.0236 - mean_squared_error: 2.0642\n",
            "Epoch 357: val_loss improved from 2.01401 to 2.01265, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0550 - mean_absolute_error: 1.0218 - mean_squared_error: 2.0550 - val_loss: 2.0126 - val_mean_absolute_error: 1.0191 - val_mean_squared_error: 2.0126\n",
            "Epoch 358/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.0633 - mean_absolute_error: 1.0244 - mean_squared_error: 2.0633\n",
            "Epoch 358: val_loss improved from 2.01265 to 2.01017, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0535 - mean_absolute_error: 1.0222 - mean_squared_error: 2.0535 - val_loss: 2.0102 - val_mean_absolute_error: 1.0171 - val_mean_squared_error: 2.0102\n",
            "Epoch 359/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.0577 - mean_absolute_error: 1.0213 - mean_squared_error: 2.0577\n",
            "Epoch 359: val_loss did not improve from 2.01017\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0509 - mean_absolute_error: 1.0206 - mean_squared_error: 2.0509 - val_loss: 2.0123 - val_mean_absolute_error: 1.0207 - val_mean_squared_error: 2.0123\n",
            "Epoch 360/1000\n",
            "218/245 [=========================>....] - ETA: 0s - loss: 2.0413 - mean_absolute_error: 1.0219 - mean_squared_error: 2.0413\n",
            "Epoch 360: val_loss improved from 2.01017 to 2.00651, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0489 - mean_absolute_error: 1.0223 - mean_squared_error: 2.0489 - val_loss: 2.0065 - val_mean_absolute_error: 1.0165 - val_mean_squared_error: 2.0065\n",
            "Epoch 361/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.0358 - mean_absolute_error: 1.0135 - mean_squared_error: 2.0358\n",
            "Epoch 361: val_loss did not improve from 2.00651\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0451 - mean_absolute_error: 1.0188 - mean_squared_error: 2.0451 - val_loss: 2.0097 - val_mean_absolute_error: 1.0207 - val_mean_squared_error: 2.0097\n",
            "Epoch 362/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.0362 - mean_absolute_error: 1.0199 - mean_squared_error: 2.0362\n",
            "Epoch 362: val_loss improved from 2.00651 to 2.00345, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0449 - mean_absolute_error: 1.0217 - mean_squared_error: 2.0449 - val_loss: 2.0035 - val_mean_absolute_error: 1.0170 - val_mean_squared_error: 2.0035\n",
            "Epoch 363/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.0609 - mean_absolute_error: 1.0247 - mean_squared_error: 2.0609\n",
            "Epoch 363: val_loss improved from 2.00345 to 2.00155, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0410 - mean_absolute_error: 1.0205 - mean_squared_error: 2.0410 - val_loss: 2.0016 - val_mean_absolute_error: 1.0161 - val_mean_squared_error: 2.0016\n",
            "Epoch 364/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.0282 - mean_absolute_error: 1.0167 - mean_squared_error: 2.0282\n",
            "Epoch 364: val_loss did not improve from 2.00155\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0418 - mean_absolute_error: 1.0209 - mean_squared_error: 2.0418 - val_loss: 2.0044 - val_mean_absolute_error: 1.0194 - val_mean_squared_error: 2.0044\n",
            "Epoch 365/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.0396 - mean_absolute_error: 1.0202 - mean_squared_error: 2.0396\n",
            "Epoch 365: val_loss improved from 2.00155 to 1.99815, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0390 - mean_absolute_error: 1.0185 - mean_squared_error: 2.0390 - val_loss: 1.9982 - val_mean_absolute_error: 1.0162 - val_mean_squared_error: 1.9982\n",
            "Epoch 366/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.0354 - mean_absolute_error: 1.0187 - mean_squared_error: 2.0354\n",
            "Epoch 366: val_loss improved from 1.99815 to 1.99714, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0365 - mean_absolute_error: 1.0190 - mean_squared_error: 2.0365 - val_loss: 1.9971 - val_mean_absolute_error: 1.0168 - val_mean_squared_error: 1.9971\n",
            "Epoch 367/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.0321 - mean_absolute_error: 1.0192 - mean_squared_error: 2.0321\n",
            "Epoch 367: val_loss improved from 1.99714 to 1.99477, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0353 - mean_absolute_error: 1.0201 - mean_squared_error: 2.0353 - val_loss: 1.9948 - val_mean_absolute_error: 1.0155 - val_mean_squared_error: 1.9948\n",
            "Epoch 368/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.0314 - mean_absolute_error: 1.0200 - mean_squared_error: 2.0314\n",
            "Epoch 368: val_loss improved from 1.99477 to 1.99317, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0312 - mean_absolute_error: 1.0192 - mean_squared_error: 2.0312 - val_loss: 1.9932 - val_mean_absolute_error: 1.0140 - val_mean_squared_error: 1.9932\n",
            "Epoch 369/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.0433 - mean_absolute_error: 1.0186 - mean_squared_error: 2.0433\n",
            "Epoch 369: val_loss improved from 1.99317 to 1.99161, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0296 - mean_absolute_error: 1.0176 - mean_squared_error: 2.0296 - val_loss: 1.9916 - val_mean_absolute_error: 1.0149 - val_mean_squared_error: 1.9916\n",
            "Epoch 370/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.0400 - mean_absolute_error: 1.0211 - mean_squared_error: 2.0400\n",
            "Epoch 370: val_loss did not improve from 1.99161\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0281 - mean_absolute_error: 1.0185 - mean_squared_error: 2.0281 - val_loss: 1.9919 - val_mean_absolute_error: 1.0161 - val_mean_squared_error: 1.9919\n",
            "Epoch 371/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.0289 - mean_absolute_error: 1.0186 - mean_squared_error: 2.0289\n",
            "Epoch 371: val_loss improved from 1.99161 to 1.98981, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0267 - mean_absolute_error: 1.0175 - mean_squared_error: 2.0267 - val_loss: 1.9898 - val_mean_absolute_error: 1.0153 - val_mean_squared_error: 1.9898\n",
            "Epoch 372/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.0287 - mean_absolute_error: 1.0182 - mean_squared_error: 2.0287\n",
            "Epoch 372: val_loss improved from 1.98981 to 1.98908, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0245 - mean_absolute_error: 1.0172 - mean_squared_error: 2.0245 - val_loss: 1.9891 - val_mean_absolute_error: 1.0161 - val_mean_squared_error: 1.9891\n",
            "Epoch 373/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.0309 - mean_absolute_error: 1.0202 - mean_squared_error: 2.0309\n",
            "Epoch 373: val_loss improved from 1.98908 to 1.98450, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0236 - mean_absolute_error: 1.0171 - mean_squared_error: 2.0236 - val_loss: 1.9845 - val_mean_absolute_error: 1.0126 - val_mean_squared_error: 1.9845\n",
            "Epoch 374/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.0260 - mean_absolute_error: 1.0170 - mean_squared_error: 2.0260\n",
            "Epoch 374: val_loss improved from 1.98450 to 1.98316, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0210 - mean_absolute_error: 1.0164 - mean_squared_error: 2.0210 - val_loss: 1.9832 - val_mean_absolute_error: 1.0128 - val_mean_squared_error: 1.9832\n",
            "Epoch 375/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.0444 - mean_absolute_error: 1.0221 - mean_squared_error: 2.0444\n",
            "Epoch 375: val_loss did not improve from 1.98316\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0192 - mean_absolute_error: 1.0159 - mean_squared_error: 2.0192 - val_loss: 1.9856 - val_mean_absolute_error: 1.0157 - val_mean_squared_error: 1.9856\n",
            "Epoch 376/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.9892 - mean_absolute_error: 1.0097 - mean_squared_error: 1.9892\n",
            "Epoch 376: val_loss improved from 1.98316 to 1.98169, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0165 - mean_absolute_error: 1.0151 - mean_squared_error: 2.0165 - val_loss: 1.9817 - val_mean_absolute_error: 1.0142 - val_mean_squared_error: 1.9817\n",
            "Epoch 377/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 2.0255 - mean_absolute_error: 1.0185 - mean_squared_error: 2.0255\n",
            "Epoch 377: val_loss improved from 1.98169 to 1.97945, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0138 - mean_absolute_error: 1.0175 - mean_squared_error: 2.0138 - val_loss: 1.9795 - val_mean_absolute_error: 1.0101 - val_mean_squared_error: 1.9795\n",
            "Epoch 378/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.9997 - mean_absolute_error: 1.0118 - mean_squared_error: 1.9997\n",
            "Epoch 378: val_loss improved from 1.97945 to 1.97592, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0145 - mean_absolute_error: 1.0166 - mean_squared_error: 2.0145 - val_loss: 1.9759 - val_mean_absolute_error: 1.0101 - val_mean_squared_error: 1.9759\n",
            "Epoch 379/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.0156 - mean_absolute_error: 1.0134 - mean_squared_error: 2.0156\n",
            "Epoch 379: val_loss did not improve from 1.97592\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0116 - mean_absolute_error: 1.0138 - mean_squared_error: 2.0116 - val_loss: 1.9886 - val_mean_absolute_error: 1.0211 - val_mean_squared_error: 1.9886\n",
            "Epoch 380/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.0110 - mean_absolute_error: 1.0165 - mean_squared_error: 2.0110\n",
            "Epoch 380: val_loss improved from 1.97592 to 1.97320, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0108 - mean_absolute_error: 1.0161 - mean_squared_error: 2.0108 - val_loss: 1.9732 - val_mean_absolute_error: 1.0104 - val_mean_squared_error: 1.9732\n",
            "Epoch 381/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.0123 - mean_absolute_error: 1.0150 - mean_squared_error: 2.0123\n",
            "Epoch 381: val_loss improved from 1.97320 to 1.97188, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0077 - mean_absolute_error: 1.0136 - mean_squared_error: 2.0077 - val_loss: 1.9719 - val_mean_absolute_error: 1.0106 - val_mean_squared_error: 1.9719\n",
            "Epoch 382/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.0033 - mean_absolute_error: 1.0142 - mean_squared_error: 2.0033\n",
            "Epoch 382: val_loss did not improve from 1.97188\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0052 - mean_absolute_error: 1.0145 - mean_squared_error: 2.0052 - val_loss: 1.9720 - val_mean_absolute_error: 1.0119 - val_mean_squared_error: 1.9720\n",
            "Epoch 383/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.0062 - mean_absolute_error: 1.0120 - mean_squared_error: 2.0062\n",
            "Epoch 383: val_loss improved from 1.97188 to 1.96824, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0034 - mean_absolute_error: 1.0131 - mean_squared_error: 2.0034 - val_loss: 1.9682 - val_mean_absolute_error: 1.0086 - val_mean_squared_error: 1.9682\n",
            "Epoch 384/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.0121 - mean_absolute_error: 1.0158 - mean_squared_error: 2.0121\n",
            "Epoch 384: val_loss did not improve from 1.96824\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0021 - mean_absolute_error: 1.0135 - mean_squared_error: 2.0021 - val_loss: 1.9722 - val_mean_absolute_error: 1.0085 - val_mean_squared_error: 1.9722\n",
            "Epoch 385/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.0212 - mean_absolute_error: 1.0166 - mean_squared_error: 2.0212\n",
            "Epoch 385: val_loss did not improve from 1.96824\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0004 - mean_absolute_error: 1.0128 - mean_squared_error: 2.0004 - val_loss: 1.9724 - val_mean_absolute_error: 1.0157 - val_mean_squared_error: 1.9724\n",
            "Epoch 386/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.0141 - mean_absolute_error: 1.0171 - mean_squared_error: 2.0141\n",
            "Epoch 386: val_loss did not improve from 1.96824\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9954 - mean_absolute_error: 1.0127 - mean_squared_error: 1.9954 - val_loss: 1.9778 - val_mean_absolute_error: 1.0189 - val_mean_squared_error: 1.9778\n",
            "Epoch 387/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.9901 - mean_absolute_error: 1.0113 - mean_squared_error: 1.9901\n",
            "Epoch 387: val_loss improved from 1.96824 to 1.96436, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9951 - mean_absolute_error: 1.0119 - mean_squared_error: 1.9951 - val_loss: 1.9644 - val_mean_absolute_error: 1.0071 - val_mean_squared_error: 1.9644\n",
            "Epoch 388/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.0001 - mean_absolute_error: 1.0160 - mean_squared_error: 2.0001\n",
            "Epoch 388: val_loss improved from 1.96436 to 1.96062, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9946 - mean_absolute_error: 1.0118 - mean_squared_error: 1.9946 - val_loss: 1.9606 - val_mean_absolute_error: 1.0070 - val_mean_squared_error: 1.9606\n",
            "Epoch 389/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.0203 - mean_absolute_error: 1.0207 - mean_squared_error: 2.0203\n",
            "Epoch 389: val_loss improved from 1.96062 to 1.96016, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9931 - mean_absolute_error: 1.0119 - mean_squared_error: 1.9931 - val_loss: 1.9602 - val_mean_absolute_error: 1.0095 - val_mean_squared_error: 1.9602\n",
            "Epoch 390/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.9844 - mean_absolute_error: 1.0120 - mean_squared_error: 1.9844\n",
            "Epoch 390: val_loss improved from 1.96016 to 1.95744, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9888 - mean_absolute_error: 1.0115 - mean_squared_error: 1.9888 - val_loss: 1.9574 - val_mean_absolute_error: 1.0062 - val_mean_squared_error: 1.9574\n",
            "Epoch 391/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.9689 - mean_absolute_error: 1.0071 - mean_squared_error: 1.9689\n",
            "Epoch 391: val_loss improved from 1.95744 to 1.95557, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9889 - mean_absolute_error: 1.0118 - mean_squared_error: 1.9889 - val_loss: 1.9556 - val_mean_absolute_error: 1.0055 - val_mean_squared_error: 1.9556\n",
            "Epoch 392/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.9953 - mean_absolute_error: 1.0131 - mean_squared_error: 1.9953\n",
            "Epoch 392: val_loss improved from 1.95557 to 1.95534, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9872 - mean_absolute_error: 1.0114 - mean_squared_error: 1.9872 - val_loss: 1.9553 - val_mean_absolute_error: 1.0054 - val_mean_squared_error: 1.9553\n",
            "Epoch 393/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.9736 - mean_absolute_error: 1.0065 - mean_squared_error: 1.9736\n",
            "Epoch 393: val_loss improved from 1.95534 to 1.95287, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9852 - mean_absolute_error: 1.0095 - mean_squared_error: 1.9852 - val_loss: 1.9529 - val_mean_absolute_error: 1.0054 - val_mean_squared_error: 1.9529\n",
            "Epoch 394/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.9830 - mean_absolute_error: 1.0101 - mean_squared_error: 1.9830\n",
            "Epoch 394: val_loss did not improve from 1.95287\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9828 - mean_absolute_error: 1.0098 - mean_squared_error: 1.9828 - val_loss: 1.9566 - val_mean_absolute_error: 1.0113 - val_mean_squared_error: 1.9566\n",
            "Epoch 395/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.9870 - mean_absolute_error: 1.0116 - mean_squared_error: 1.9870\n",
            "Epoch 395: val_loss improved from 1.95287 to 1.94957, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9794 - mean_absolute_error: 1.0099 - mean_squared_error: 1.9794 - val_loss: 1.9496 - val_mean_absolute_error: 1.0052 - val_mean_squared_error: 1.9496\n",
            "Epoch 396/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.9896 - mean_absolute_error: 1.0165 - mean_squared_error: 1.9896\n",
            "Epoch 396: val_loss did not improve from 1.94957\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9793 - mean_absolute_error: 1.0107 - mean_squared_error: 1.9793 - val_loss: 1.9512 - val_mean_absolute_error: 1.0085 - val_mean_squared_error: 1.9512\n",
            "Epoch 397/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.9637 - mean_absolute_error: 1.0054 - mean_squared_error: 1.9637\n",
            "Epoch 397: val_loss improved from 1.94957 to 1.94667, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9769 - mean_absolute_error: 1.0092 - mean_squared_error: 1.9769 - val_loss: 1.9467 - val_mean_absolute_error: 1.0031 - val_mean_squared_error: 1.9467\n",
            "Epoch 398/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.9850 - mean_absolute_error: 1.0121 - mean_squared_error: 1.9850\n",
            "Epoch 398: val_loss improved from 1.94667 to 1.94450, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9756 - mean_absolute_error: 1.0089 - mean_squared_error: 1.9756 - val_loss: 1.9445 - val_mean_absolute_error: 1.0041 - val_mean_squared_error: 1.9445\n",
            "Epoch 399/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.9753 - mean_absolute_error: 1.0079 - mean_squared_error: 1.9753\n",
            "Epoch 399: val_loss improved from 1.94450 to 1.94340, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9738 - mean_absolute_error: 1.0081 - mean_squared_error: 1.9738 - val_loss: 1.9434 - val_mean_absolute_error: 1.0047 - val_mean_squared_error: 1.9434\n",
            "Epoch 400/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.9815 - mean_absolute_error: 1.0115 - mean_squared_error: 1.9815\n",
            "Epoch 400: val_loss did not improve from 1.94340\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9687 - mean_absolute_error: 1.0070 - mean_squared_error: 1.9687 - val_loss: 1.9565 - val_mean_absolute_error: 1.0144 - val_mean_squared_error: 1.9565\n",
            "Epoch 401/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.9670 - mean_absolute_error: 1.0069 - mean_squared_error: 1.9670\n",
            "Epoch 401: val_loss improved from 1.94340 to 1.94273, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9717 - mean_absolute_error: 1.0082 - mean_squared_error: 1.9717 - val_loss: 1.9427 - val_mean_absolute_error: 1.0068 - val_mean_squared_error: 1.9427\n",
            "Epoch 402/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.9729 - mean_absolute_error: 1.0090 - mean_squared_error: 1.9729\n",
            "Epoch 402: val_loss improved from 1.94273 to 1.93905, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9694 - mean_absolute_error: 1.0086 - mean_squared_error: 1.9694 - val_loss: 1.9391 - val_mean_absolute_error: 1.0044 - val_mean_squared_error: 1.9391\n",
            "Epoch 403/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.9755 - mean_absolute_error: 1.0074 - mean_squared_error: 1.9755\n",
            "Epoch 403: val_loss did not improve from 1.93905\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9675 - mean_absolute_error: 1.0068 - mean_squared_error: 1.9675 - val_loss: 1.9401 - val_mean_absolute_error: 1.0062 - val_mean_squared_error: 1.9401\n",
            "Epoch 404/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.9711 - mean_absolute_error: 1.0124 - mean_squared_error: 1.9711\n",
            "Epoch 404: val_loss did not improve from 1.93905\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9644 - mean_absolute_error: 1.0075 - mean_squared_error: 1.9644 - val_loss: 1.9394 - val_mean_absolute_error: 1.0061 - val_mean_squared_error: 1.9394\n",
            "Epoch 405/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.9712 - mean_absolute_error: 1.0069 - mean_squared_error: 1.9712\n",
            "Epoch 405: val_loss improved from 1.93905 to 1.93648, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9624 - mean_absolute_error: 1.0061 - mean_squared_error: 1.9624 - val_loss: 1.9365 - val_mean_absolute_error: 1.0052 - val_mean_squared_error: 1.9365\n",
            "Epoch 406/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.9617 - mean_absolute_error: 1.0038 - mean_squared_error: 1.9617\n",
            "Epoch 406: val_loss did not improve from 1.93648\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9596 - mean_absolute_error: 1.0053 - mean_squared_error: 1.9596 - val_loss: 1.9483 - val_mean_absolute_error: 1.0137 - val_mean_squared_error: 1.9483\n",
            "Epoch 407/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.9508 - mean_absolute_error: 1.0048 - mean_squared_error: 1.9508\n",
            "Epoch 407: val_loss improved from 1.93648 to 1.93144, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9597 - mean_absolute_error: 1.0064 - mean_squared_error: 1.9597 - val_loss: 1.9314 - val_mean_absolute_error: 1.0017 - val_mean_squared_error: 1.9314\n",
            "Epoch 408/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.9590 - mean_absolute_error: 1.0051 - mean_squared_error: 1.9590\n",
            "Epoch 408: val_loss did not improve from 1.93144\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9576 - mean_absolute_error: 1.0054 - mean_squared_error: 1.9576 - val_loss: 1.9323 - val_mean_absolute_error: 1.0044 - val_mean_squared_error: 1.9323\n",
            "Epoch 409/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.9521 - mean_absolute_error: 1.0059 - mean_squared_error: 1.9521\n",
            "Epoch 409: val_loss improved from 1.93144 to 1.92893, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.9564 - mean_absolute_error: 1.0067 - mean_squared_error: 1.9564 - val_loss: 1.9289 - val_mean_absolute_error: 1.0023 - val_mean_squared_error: 1.9289\n",
            "Epoch 410/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.9608 - mean_absolute_error: 1.0050 - mean_squared_error: 1.9608\n",
            "Epoch 410: val_loss did not improve from 1.92893\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.9530 - mean_absolute_error: 1.0035 - mean_squared_error: 1.9530 - val_loss: 1.9296 - val_mean_absolute_error: 1.0033 - val_mean_squared_error: 1.9296\n",
            "Epoch 411/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.9697 - mean_absolute_error: 1.0068 - mean_squared_error: 1.9697\n",
            "Epoch 411: val_loss improved from 1.92893 to 1.92553, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.9531 - mean_absolute_error: 1.0052 - mean_squared_error: 1.9531 - val_loss: 1.9255 - val_mean_absolute_error: 1.0013 - val_mean_squared_error: 1.9255\n",
            "Epoch 412/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.9659 - mean_absolute_error: 1.0063 - mean_squared_error: 1.9659\n",
            "Epoch 412: val_loss did not improve from 1.92553\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.9530 - mean_absolute_error: 1.0042 - mean_squared_error: 1.9530 - val_loss: 1.9259 - val_mean_absolute_error: 1.0032 - val_mean_squared_error: 1.9259\n",
            "Epoch 413/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.9387 - mean_absolute_error: 1.0006 - mean_squared_error: 1.9387\n",
            "Epoch 413: val_loss improved from 1.92553 to 1.92482, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.9495 - mean_absolute_error: 1.0022 - mean_squared_error: 1.9495 - val_loss: 1.9248 - val_mean_absolute_error: 1.0036 - val_mean_squared_error: 1.9248\n",
            "Epoch 414/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.9424 - mean_absolute_error: 1.0028 - mean_squared_error: 1.9424\n",
            "Epoch 414: val_loss improved from 1.92482 to 1.92169, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9465 - mean_absolute_error: 1.0037 - mean_squared_error: 1.9465 - val_loss: 1.9217 - val_mean_absolute_error: 1.0012 - val_mean_squared_error: 1.9217\n",
            "Epoch 415/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.9477 - mean_absolute_error: 1.0056 - mean_squared_error: 1.9477\n",
            "Epoch 415: val_loss improved from 1.92169 to 1.91935, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9453 - mean_absolute_error: 1.0045 - mean_squared_error: 1.9453 - val_loss: 1.9193 - val_mean_absolute_error: 0.9988 - val_mean_squared_error: 1.9193\n",
            "Epoch 416/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.9629 - mean_absolute_error: 1.0096 - mean_squared_error: 1.9629\n",
            "Epoch 416: val_loss did not improve from 1.91935\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9441 - mean_absolute_error: 1.0026 - mean_squared_error: 1.9441 - val_loss: 1.9216 - val_mean_absolute_error: 1.0029 - val_mean_squared_error: 1.9216\n",
            "Epoch 417/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.9415 - mean_absolute_error: 1.0034 - mean_squared_error: 1.9415\n",
            "Epoch 417: val_loss improved from 1.91935 to 1.91933, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9425 - mean_absolute_error: 1.0029 - mean_squared_error: 1.9425 - val_loss: 1.9193 - val_mean_absolute_error: 1.0015 - val_mean_squared_error: 1.9193\n",
            "Epoch 418/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.9582 - mean_absolute_error: 1.0074 - mean_squared_error: 1.9582\n",
            "Epoch 418: val_loss improved from 1.91933 to 1.91572, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9389 - mean_absolute_error: 1.0023 - mean_squared_error: 1.9389 - val_loss: 1.9157 - val_mean_absolute_error: 0.9973 - val_mean_squared_error: 1.9157\n",
            "Epoch 419/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.9514 - mean_absolute_error: 1.0052 - mean_squared_error: 1.9514\n",
            "Epoch 419: val_loss improved from 1.91572 to 1.91331, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.9378 - mean_absolute_error: 1.0020 - mean_squared_error: 1.9378 - val_loss: 1.9133 - val_mean_absolute_error: 0.9978 - val_mean_squared_error: 1.9133\n",
            "Epoch 420/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.9216 - mean_absolute_error: 0.9968 - mean_squared_error: 1.9216\n",
            "Epoch 420: val_loss did not improve from 1.91331\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.9367 - mean_absolute_error: 0.9997 - mean_squared_error: 1.9367 - val_loss: 1.9322 - val_mean_absolute_error: 1.0110 - val_mean_squared_error: 1.9322\n",
            "Epoch 421/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.9477 - mean_absolute_error: 1.0051 - mean_squared_error: 1.9477\n",
            "Epoch 421: val_loss did not improve from 1.91331\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.9358 - mean_absolute_error: 1.0018 - mean_squared_error: 1.9358 - val_loss: 1.9179 - val_mean_absolute_error: 1.0034 - val_mean_squared_error: 1.9179\n",
            "Epoch 422/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.9234 - mean_absolute_error: 0.9980 - mean_squared_error: 1.9234\n",
            "Epoch 422: val_loss improved from 1.91331 to 1.90904, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.9348 - mean_absolute_error: 1.0010 - mean_squared_error: 1.9348 - val_loss: 1.9090 - val_mean_absolute_error: 0.9967 - val_mean_squared_error: 1.9090\n",
            "Epoch 423/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.9104 - mean_absolute_error: 0.9926 - mean_squared_error: 1.9104\n",
            "Epoch 423: val_loss improved from 1.90904 to 1.90775, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.9317 - mean_absolute_error: 0.9999 - mean_squared_error: 1.9317 - val_loss: 1.9078 - val_mean_absolute_error: 0.9970 - val_mean_squared_error: 1.9078\n",
            "Epoch 424/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.9288 - mean_absolute_error: 1.0002 - mean_squared_error: 1.9288\n",
            "Epoch 424: val_loss improved from 1.90775 to 1.90755, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9312 - mean_absolute_error: 1.0012 - mean_squared_error: 1.9312 - val_loss: 1.9075 - val_mean_absolute_error: 0.9956 - val_mean_squared_error: 1.9075\n",
            "Epoch 425/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.9380 - mean_absolute_error: 1.0035 - mean_squared_error: 1.9380\n",
            "Epoch 425: val_loss improved from 1.90755 to 1.90657, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9298 - mean_absolute_error: 1.0001 - mean_squared_error: 1.9298 - val_loss: 1.9066 - val_mean_absolute_error: 0.9983 - val_mean_squared_error: 1.9066\n",
            "Epoch 426/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.9436 - mean_absolute_error: 1.0038 - mean_squared_error: 1.9436\n",
            "Epoch 426: val_loss did not improve from 1.90657\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9253 - mean_absolute_error: 0.9991 - mean_squared_error: 1.9253 - val_loss: 1.9092 - val_mean_absolute_error: 0.9952 - val_mean_squared_error: 1.9092\n",
            "Epoch 427/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.9269 - mean_absolute_error: 0.9988 - mean_squared_error: 1.9269\n",
            "Epoch 427: val_loss did not improve from 1.90657\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9251 - mean_absolute_error: 0.9986 - mean_squared_error: 1.9251 - val_loss: 1.9072 - val_mean_absolute_error: 0.9953 - val_mean_squared_error: 1.9072\n",
            "Epoch 428/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.9264 - mean_absolute_error: 0.9976 - mean_squared_error: 1.9264\n",
            "Epoch 428: val_loss improved from 1.90657 to 1.90176, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9239 - mean_absolute_error: 0.9991 - mean_squared_error: 1.9239 - val_loss: 1.9018 - val_mean_absolute_error: 0.9941 - val_mean_squared_error: 1.9018\n",
            "Epoch 429/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 1.9256 - mean_absolute_error: 1.0001 - mean_squared_error: 1.9256\n",
            "Epoch 429: val_loss improved from 1.90176 to 1.89945, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9221 - mean_absolute_error: 0.9991 - mean_squared_error: 1.9221 - val_loss: 1.8994 - val_mean_absolute_error: 0.9957 - val_mean_squared_error: 1.8994\n",
            "Epoch 430/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.9096 - mean_absolute_error: 0.9944 - mean_squared_error: 1.9096\n",
            "Epoch 430: val_loss improved from 1.89945 to 1.89738, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9191 - mean_absolute_error: 0.9975 - mean_squared_error: 1.9191 - val_loss: 1.8974 - val_mean_absolute_error: 0.9935 - val_mean_squared_error: 1.8974\n",
            "Epoch 431/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.9239 - mean_absolute_error: 0.9998 - mean_squared_error: 1.9239\n",
            "Epoch 431: val_loss did not improve from 1.89738\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9185 - mean_absolute_error: 0.9973 - mean_squared_error: 1.9185 - val_loss: 1.8979 - val_mean_absolute_error: 0.9961 - val_mean_squared_error: 1.8979\n",
            "Epoch 432/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.9157 - mean_absolute_error: 0.9963 - mean_squared_error: 1.9157\n",
            "Epoch 432: val_loss improved from 1.89738 to 1.89575, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9157 - mean_absolute_error: 0.9963 - mean_squared_error: 1.9157 - val_loss: 1.8958 - val_mean_absolute_error: 0.9952 - val_mean_squared_error: 1.8958\n",
            "Epoch 433/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.9135 - mean_absolute_error: 0.9974 - mean_squared_error: 1.9135\n",
            "Epoch 433: val_loss did not improve from 1.89575\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9135 - mean_absolute_error: 0.9974 - mean_squared_error: 1.9135 - val_loss: 1.8976 - val_mean_absolute_error: 0.9974 - val_mean_squared_error: 1.8976\n",
            "Epoch 434/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.9028 - mean_absolute_error: 0.9957 - mean_squared_error: 1.9028\n",
            "Epoch 434: val_loss improved from 1.89575 to 1.89437, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9134 - mean_absolute_error: 0.9970 - mean_squared_error: 1.9134 - val_loss: 1.8944 - val_mean_absolute_error: 0.9954 - val_mean_squared_error: 1.8944\n",
            "Epoch 435/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.9094 - mean_absolute_error: 0.9951 - mean_squared_error: 1.9094\n",
            "Epoch 435: val_loss improved from 1.89437 to 1.89221, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9112 - mean_absolute_error: 0.9966 - mean_squared_error: 1.9112 - val_loss: 1.8922 - val_mean_absolute_error: 0.9922 - val_mean_squared_error: 1.8922\n",
            "Epoch 436/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.8925 - mean_absolute_error: 0.9905 - mean_squared_error: 1.8925\n",
            "Epoch 436: val_loss improved from 1.89221 to 1.88919, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9099 - mean_absolute_error: 0.9952 - mean_squared_error: 1.9099 - val_loss: 1.8892 - val_mean_absolute_error: 0.9931 - val_mean_squared_error: 1.8892\n",
            "Epoch 437/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.9229 - mean_absolute_error: 0.9992 - mean_squared_error: 1.9229\n",
            "Epoch 437: val_loss improved from 1.88919 to 1.88751, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9073 - mean_absolute_error: 0.9958 - mean_squared_error: 1.9073 - val_loss: 1.8875 - val_mean_absolute_error: 0.9918 - val_mean_squared_error: 1.8875\n",
            "Epoch 438/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.9271 - mean_absolute_error: 1.0006 - mean_squared_error: 1.9271\n",
            "Epoch 438: val_loss improved from 1.88751 to 1.88610, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9071 - mean_absolute_error: 0.9953 - mean_squared_error: 1.9071 - val_loss: 1.8861 - val_mean_absolute_error: 0.9920 - val_mean_squared_error: 1.8861\n",
            "Epoch 439/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.9069 - mean_absolute_error: 0.9932 - mean_squared_error: 1.9069\n",
            "Epoch 439: val_loss improved from 1.88610 to 1.88552, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9051 - mean_absolute_error: 0.9947 - mean_squared_error: 1.9051 - val_loss: 1.8855 - val_mean_absolute_error: 0.9927 - val_mean_squared_error: 1.8855\n",
            "Epoch 440/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.8939 - mean_absolute_error: 0.9908 - mean_squared_error: 1.8939\n",
            "Epoch 440: val_loss did not improve from 1.88552\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9032 - mean_absolute_error: 0.9931 - mean_squared_error: 1.9032 - val_loss: 1.8859 - val_mean_absolute_error: 0.9943 - val_mean_squared_error: 1.8859\n",
            "Epoch 441/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.9001 - mean_absolute_error: 0.9952 - mean_squared_error: 1.9001\n",
            "Epoch 441: val_loss improved from 1.88552 to 1.88144, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9020 - mean_absolute_error: 0.9942 - mean_squared_error: 1.9020 - val_loss: 1.8814 - val_mean_absolute_error: 0.9905 - val_mean_squared_error: 1.8814\n",
            "Epoch 442/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.8828 - mean_absolute_error: 0.9893 - mean_squared_error: 1.8828\n",
            "Epoch 442: val_loss improved from 1.88144 to 1.88026, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8995 - mean_absolute_error: 0.9931 - mean_squared_error: 1.8995 - val_loss: 1.8803 - val_mean_absolute_error: 0.9905 - val_mean_squared_error: 1.8803\n",
            "Epoch 443/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.8856 - mean_absolute_error: 0.9922 - mean_squared_error: 1.8856\n",
            "Epoch 443: val_loss did not improve from 1.88026\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8969 - mean_absolute_error: 0.9930 - mean_squared_error: 1.8969 - val_loss: 1.8809 - val_mean_absolute_error: 0.9899 - val_mean_squared_error: 1.8809\n",
            "Epoch 444/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.8892 - mean_absolute_error: 0.9918 - mean_squared_error: 1.8892\n",
            "Epoch 444: val_loss improved from 1.88026 to 1.87860, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8963 - mean_absolute_error: 0.9916 - mean_squared_error: 1.8963 - val_loss: 1.8786 - val_mean_absolute_error: 0.9913 - val_mean_squared_error: 1.8786\n",
            "Epoch 445/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.9024 - mean_absolute_error: 0.9937 - mean_squared_error: 1.9024\n",
            "Epoch 445: val_loss improved from 1.87860 to 1.87616, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8942 - mean_absolute_error: 0.9928 - mean_squared_error: 1.8942 - val_loss: 1.8762 - val_mean_absolute_error: 0.9902 - val_mean_squared_error: 1.8762\n",
            "Epoch 446/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.8905 - mean_absolute_error: 0.9907 - mean_squared_error: 1.8905\n",
            "Epoch 446: val_loss improved from 1.87616 to 1.87391, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8919 - mean_absolute_error: 0.9914 - mean_squared_error: 1.8919 - val_loss: 1.8739 - val_mean_absolute_error: 0.9887 - val_mean_squared_error: 1.8739\n",
            "Epoch 447/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.8907 - mean_absolute_error: 0.9919 - mean_squared_error: 1.8907\n",
            "Epoch 447: val_loss improved from 1.87391 to 1.87279, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8899 - mean_absolute_error: 0.9914 - mean_squared_error: 1.8899 - val_loss: 1.8728 - val_mean_absolute_error: 0.9888 - val_mean_squared_error: 1.8728\n",
            "Epoch 448/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.9151 - mean_absolute_error: 0.9991 - mean_squared_error: 1.9151\n",
            "Epoch 448: val_loss improved from 1.87279 to 1.87126, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8878 - mean_absolute_error: 0.9911 - mean_squared_error: 1.8878 - val_loss: 1.8713 - val_mean_absolute_error: 0.9883 - val_mean_squared_error: 1.8713\n",
            "Epoch 449/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.8864 - mean_absolute_error: 0.9899 - mean_squared_error: 1.8864\n",
            "Epoch 449: val_loss did not improve from 1.87126\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8864 - mean_absolute_error: 0.9899 - mean_squared_error: 1.8864 - val_loss: 1.8738 - val_mean_absolute_error: 0.9913 - val_mean_squared_error: 1.8738\n",
            "Epoch 450/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.8788 - mean_absolute_error: 0.9890 - mean_squared_error: 1.8788\n",
            "Epoch 450: val_loss improved from 1.87126 to 1.86935, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8850 - mean_absolute_error: 0.9898 - mean_squared_error: 1.8850 - val_loss: 1.8694 - val_mean_absolute_error: 0.9885 - val_mean_squared_error: 1.8694\n",
            "Epoch 451/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.8810 - mean_absolute_error: 0.9874 - mean_squared_error: 1.8810\n",
            "Epoch 451: val_loss improved from 1.86935 to 1.86701, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8843 - mean_absolute_error: 0.9892 - mean_squared_error: 1.8843 - val_loss: 1.8670 - val_mean_absolute_error: 0.9875 - val_mean_squared_error: 1.8670\n",
            "Epoch 452/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.8835 - mean_absolute_error: 0.9904 - mean_squared_error: 1.8835\n",
            "Epoch 452: val_loss improved from 1.86701 to 1.86548, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8825 - mean_absolute_error: 0.9899 - mean_squared_error: 1.8825 - val_loss: 1.8655 - val_mean_absolute_error: 0.9874 - val_mean_squared_error: 1.8655\n",
            "Epoch 453/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.8792 - mean_absolute_error: 0.9891 - mean_squared_error: 1.8792\n",
            "Epoch 453: val_loss improved from 1.86548 to 1.86451, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8814 - mean_absolute_error: 0.9890 - mean_squared_error: 1.8814 - val_loss: 1.8645 - val_mean_absolute_error: 0.9852 - val_mean_squared_error: 1.8645\n",
            "Epoch 454/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.8837 - mean_absolute_error: 0.9877 - mean_squared_error: 1.8837\n",
            "Epoch 454: val_loss improved from 1.86451 to 1.86418, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8796 - mean_absolute_error: 0.9871 - mean_squared_error: 1.8796 - val_loss: 1.8642 - val_mean_absolute_error: 0.9883 - val_mean_squared_error: 1.8642\n",
            "Epoch 455/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.8778 - mean_absolute_error: 0.9899 - mean_squared_error: 1.8778\n",
            "Epoch 455: val_loss did not improve from 1.86418\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8757 - mean_absolute_error: 0.9889 - mean_squared_error: 1.8757 - val_loss: 1.8653 - val_mean_absolute_error: 0.9848 - val_mean_squared_error: 1.8653\n",
            "Epoch 456/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.8764 - mean_absolute_error: 0.9868 - mean_squared_error: 1.8764\n",
            "Epoch 456: val_loss improved from 1.86418 to 1.86053, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8764 - mean_absolute_error: 0.9868 - mean_squared_error: 1.8764 - val_loss: 1.8605 - val_mean_absolute_error: 0.9869 - val_mean_squared_error: 1.8605\n",
            "Epoch 457/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.8638 - mean_absolute_error: 0.9854 - mean_squared_error: 1.8638\n",
            "Epoch 457: val_loss improved from 1.86053 to 1.85741, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8735 - mean_absolute_error: 0.9869 - mean_squared_error: 1.8735 - val_loss: 1.8574 - val_mean_absolute_error: 0.9848 - val_mean_squared_error: 1.8574\n",
            "Epoch 458/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.8712 - mean_absolute_error: 0.9878 - mean_squared_error: 1.8712\n",
            "Epoch 458: val_loss improved from 1.85741 to 1.85586, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8722 - mean_absolute_error: 0.9866 - mean_squared_error: 1.8722 - val_loss: 1.8559 - val_mean_absolute_error: 0.9845 - val_mean_squared_error: 1.8559\n",
            "Epoch 459/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.8671 - mean_absolute_error: 0.9847 - mean_squared_error: 1.8671\n",
            "Epoch 459: val_loss did not improve from 1.85586\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8699 - mean_absolute_error: 0.9847 - mean_squared_error: 1.8699 - val_loss: 1.8560 - val_mean_absolute_error: 0.9856 - val_mean_squared_error: 1.8560\n",
            "Epoch 460/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.8480 - mean_absolute_error: 0.9829 - mean_squared_error: 1.8480\n",
            "Epoch 460: val_loss improved from 1.85586 to 1.85231, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8673 - mean_absolute_error: 0.9858 - mean_squared_error: 1.8673 - val_loss: 1.8523 - val_mean_absolute_error: 0.9831 - val_mean_squared_error: 1.8523\n",
            "Epoch 461/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.8680 - mean_absolute_error: 0.9845 - mean_squared_error: 1.8680\n",
            "Epoch 461: val_loss improved from 1.85231 to 1.85140, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8639 - mean_absolute_error: 0.9836 - mean_squared_error: 1.8639 - val_loss: 1.8514 - val_mean_absolute_error: 0.9818 - val_mean_squared_error: 1.8514\n",
            "Epoch 462/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.8714 - mean_absolute_error: 0.9850 - mean_squared_error: 1.8714\n",
            "Epoch 462: val_loss improved from 1.85140 to 1.84997, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8677 - mean_absolute_error: 0.9835 - mean_squared_error: 1.8677 - val_loss: 1.8500 - val_mean_absolute_error: 0.9834 - val_mean_squared_error: 1.8500\n",
            "Epoch 463/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.8647 - mean_absolute_error: 0.9838 - mean_squared_error: 1.8647\n",
            "Epoch 463: val_loss improved from 1.84997 to 1.84965, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8621 - mean_absolute_error: 0.9839 - mean_squared_error: 1.8621 - val_loss: 1.8496 - val_mean_absolute_error: 0.9811 - val_mean_squared_error: 1.8496\n",
            "Epoch 464/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.8583 - mean_absolute_error: 0.9841 - mean_squared_error: 1.8583\n",
            "Epoch 464: val_loss did not improve from 1.84965\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8602 - mean_absolute_error: 0.9829 - mean_squared_error: 1.8602 - val_loss: 1.8518 - val_mean_absolute_error: 0.9813 - val_mean_squared_error: 1.8518\n",
            "Epoch 465/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.8887 - mean_absolute_error: 0.9888 - mean_squared_error: 1.8887\n",
            "Epoch 465: val_loss improved from 1.84965 to 1.84760, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8597 - mean_absolute_error: 0.9828 - mean_squared_error: 1.8597 - val_loss: 1.8476 - val_mean_absolute_error: 0.9841 - val_mean_squared_error: 1.8476\n",
            "Epoch 466/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.8504 - mean_absolute_error: 0.9810 - mean_squared_error: 1.8504\n",
            "Epoch 466: val_loss improved from 1.84760 to 1.84384, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8574 - mean_absolute_error: 0.9816 - mean_squared_error: 1.8574 - val_loss: 1.8438 - val_mean_absolute_error: 0.9820 - val_mean_squared_error: 1.8438\n",
            "Epoch 467/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.8720 - mean_absolute_error: 0.9875 - mean_squared_error: 1.8720\n",
            "Epoch 467: val_loss improved from 1.84384 to 1.84315, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8563 - mean_absolute_error: 0.9828 - mean_squared_error: 1.8563 - val_loss: 1.8431 - val_mean_absolute_error: 0.9826 - val_mean_squared_error: 1.8431\n",
            "Epoch 468/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.8547 - mean_absolute_error: 0.9848 - mean_squared_error: 1.8547\n",
            "Epoch 468: val_loss did not improve from 1.84315\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8524 - mean_absolute_error: 0.9811 - mean_squared_error: 1.8524 - val_loss: 1.8456 - val_mean_absolute_error: 0.9842 - val_mean_squared_error: 1.8456\n",
            "Epoch 469/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.8444 - mean_absolute_error: 0.9803 - mean_squared_error: 1.8444\n",
            "Epoch 469: val_loss improved from 1.84315 to 1.83913, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8514 - mean_absolute_error: 0.9821 - mean_squared_error: 1.8514 - val_loss: 1.8391 - val_mean_absolute_error: 0.9806 - val_mean_squared_error: 1.8391\n",
            "Epoch 470/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.8546 - mean_absolute_error: 0.9808 - mean_squared_error: 1.8546\n",
            "Epoch 470: val_loss improved from 1.83913 to 1.83833, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8473 - mean_absolute_error: 0.9796 - mean_squared_error: 1.8473 - val_loss: 1.8383 - val_mean_absolute_error: 0.9778 - val_mean_squared_error: 1.8383\n",
            "Epoch 471/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.8511 - mean_absolute_error: 0.9784 - mean_squared_error: 1.8511\n",
            "Epoch 471: val_loss improved from 1.83833 to 1.83424, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8463 - mean_absolute_error: 0.9784 - mean_squared_error: 1.8463 - val_loss: 1.8342 - val_mean_absolute_error: 0.9771 - val_mean_squared_error: 1.8342\n",
            "Epoch 472/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.8479 - mean_absolute_error: 0.9790 - mean_squared_error: 1.8479\n",
            "Epoch 472: val_loss improved from 1.83424 to 1.83375, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8479 - mean_absolute_error: 0.9790 - mean_squared_error: 1.8479 - val_loss: 1.8337 - val_mean_absolute_error: 0.9789 - val_mean_squared_error: 1.8337\n",
            "Epoch 473/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.8312 - mean_absolute_error: 0.9755 - mean_squared_error: 1.8312\n",
            "Epoch 473: val_loss improved from 1.83375 to 1.83103, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8449 - mean_absolute_error: 0.9789 - mean_squared_error: 1.8449 - val_loss: 1.8310 - val_mean_absolute_error: 0.9761 - val_mean_squared_error: 1.8310\n",
            "Epoch 474/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.8293 - mean_absolute_error: 0.9741 - mean_squared_error: 1.8293\n",
            "Epoch 474: val_loss did not improve from 1.83103\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8405 - mean_absolute_error: 0.9768 - mean_squared_error: 1.8405 - val_loss: 1.8430 - val_mean_absolute_error: 0.9855 - val_mean_squared_error: 1.8430\n",
            "Epoch 475/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.8380 - mean_absolute_error: 0.9792 - mean_squared_error: 1.8380\n",
            "Epoch 475: val_loss improved from 1.83103 to 1.82655, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8398 - mean_absolute_error: 0.9795 - mean_squared_error: 1.8398 - val_loss: 1.8266 - val_mean_absolute_error: 0.9751 - val_mean_squared_error: 1.8266\n",
            "Epoch 476/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.8372 - mean_absolute_error: 0.9759 - mean_squared_error: 1.8372\n",
            "Epoch 476: val_loss improved from 1.82655 to 1.82629, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8372 - mean_absolute_error: 0.9759 - mean_squared_error: 1.8372 - val_loss: 1.8263 - val_mean_absolute_error: 0.9763 - val_mean_squared_error: 1.8263\n",
            "Epoch 477/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.8361 - mean_absolute_error: 0.9767 - mean_squared_error: 1.8361\n",
            "Epoch 477: val_loss did not improve from 1.82629\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8360 - mean_absolute_error: 0.9755 - mean_squared_error: 1.8360 - val_loss: 1.8267 - val_mean_absolute_error: 0.9776 - val_mean_squared_error: 1.8267\n",
            "Epoch 478/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.8288 - mean_absolute_error: 0.9731 - mean_squared_error: 1.8288\n",
            "Epoch 478: val_loss did not improve from 1.82629\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8333 - mean_absolute_error: 0.9742 - mean_squared_error: 1.8333 - val_loss: 1.8307 - val_mean_absolute_error: 0.9802 - val_mean_squared_error: 1.8307\n",
            "Epoch 479/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.8374 - mean_absolute_error: 0.9750 - mean_squared_error: 1.8374\n",
            "Epoch 479: val_loss improved from 1.82629 to 1.82042, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8319 - mean_absolute_error: 0.9756 - mean_squared_error: 1.8319 - val_loss: 1.8204 - val_mean_absolute_error: 0.9747 - val_mean_squared_error: 1.8204\n",
            "Epoch 480/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.8136 - mean_absolute_error: 0.9734 - mean_squared_error: 1.8136\n",
            "Epoch 480: val_loss improved from 1.82042 to 1.81876, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8279 - mean_absolute_error: 0.9743 - mean_squared_error: 1.8279 - val_loss: 1.8188 - val_mean_absolute_error: 0.9710 - val_mean_squared_error: 1.8188\n",
            "Epoch 481/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.8245 - mean_absolute_error: 0.9727 - mean_squared_error: 1.8245\n",
            "Epoch 481: val_loss improved from 1.81876 to 1.81702, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8271 - mean_absolute_error: 0.9730 - mean_squared_error: 1.8271 - val_loss: 1.8170 - val_mean_absolute_error: 0.9708 - val_mean_squared_error: 1.8170\n",
            "Epoch 482/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.8473 - mean_absolute_error: 0.9771 - mean_squared_error: 1.8473\n",
            "Epoch 482: val_loss improved from 1.81702 to 1.81621, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8255 - mean_absolute_error: 0.9719 - mean_squared_error: 1.8255 - val_loss: 1.8162 - val_mean_absolute_error: 0.9739 - val_mean_squared_error: 1.8162\n",
            "Epoch 483/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.8303 - mean_absolute_error: 0.9733 - mean_squared_error: 1.8303\n",
            "Epoch 483: val_loss improved from 1.81621 to 1.81508, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8240 - mean_absolute_error: 0.9721 - mean_squared_error: 1.8240 - val_loss: 1.8151 - val_mean_absolute_error: 0.9737 - val_mean_squared_error: 1.8151\n",
            "Epoch 484/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.8394 - mean_absolute_error: 0.9759 - mean_squared_error: 1.8394\n",
            "Epoch 484: val_loss improved from 1.81508 to 1.80897, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8211 - mean_absolute_error: 0.9715 - mean_squared_error: 1.8211 - val_loss: 1.8090 - val_mean_absolute_error: 0.9692 - val_mean_squared_error: 1.8090\n",
            "Epoch 485/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.8026 - mean_absolute_error: 0.9691 - mean_squared_error: 1.8026\n",
            "Epoch 485: val_loss improved from 1.80897 to 1.80796, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8179 - mean_absolute_error: 0.9719 - mean_squared_error: 1.8179 - val_loss: 1.8080 - val_mean_absolute_error: 0.9674 - val_mean_squared_error: 1.8080\n",
            "Epoch 486/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.8268 - mean_absolute_error: 0.9728 - mean_squared_error: 1.8268\n",
            "Epoch 486: val_loss improved from 1.80796 to 1.80473, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8159 - mean_absolute_error: 0.9700 - mean_squared_error: 1.8159 - val_loss: 1.8047 - val_mean_absolute_error: 0.9678 - val_mean_squared_error: 1.8047\n",
            "Epoch 487/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.8107 - mean_absolute_error: 0.9686 - mean_squared_error: 1.8107\n",
            "Epoch 487: val_loss did not improve from 1.80473\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8133 - mean_absolute_error: 0.9669 - mean_squared_error: 1.8133 - val_loss: 1.8049 - val_mean_absolute_error: 0.9691 - val_mean_squared_error: 1.8049\n",
            "Epoch 488/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.8151 - mean_absolute_error: 0.9688 - mean_squared_error: 1.8151\n",
            "Epoch 488: val_loss improved from 1.80473 to 1.80463, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8097 - mean_absolute_error: 0.9672 - mean_squared_error: 1.8097 - val_loss: 1.8046 - val_mean_absolute_error: 0.9658 - val_mean_squared_error: 1.8046\n",
            "Epoch 489/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.7969 - mean_absolute_error: 0.9618 - mean_squared_error: 1.7969\n",
            "Epoch 489: val_loss did not improve from 1.80463\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8079 - mean_absolute_error: 0.9658 - mean_squared_error: 1.8079 - val_loss: 1.8049 - val_mean_absolute_error: 0.9715 - val_mean_squared_error: 1.8049\n",
            "Epoch 490/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.8060 - mean_absolute_error: 0.9646 - mean_squared_error: 1.8060\n",
            "Epoch 490: val_loss improved from 1.80463 to 1.79858, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8058 - mean_absolute_error: 0.9659 - mean_squared_error: 1.8058 - val_loss: 1.7986 - val_mean_absolute_error: 0.9680 - val_mean_squared_error: 1.7986\n",
            "Epoch 491/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.8127 - mean_absolute_error: 0.9683 - mean_squared_error: 1.8127\n",
            "Epoch 491: val_loss improved from 1.79858 to 1.79541, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8027 - mean_absolute_error: 0.9648 - mean_squared_error: 1.8027 - val_loss: 1.7954 - val_mean_absolute_error: 0.9662 - val_mean_squared_error: 1.7954\n",
            "Epoch 492/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.7883 - mean_absolute_error: 0.9616 - mean_squared_error: 1.7883\n",
            "Epoch 492: val_loss improved from 1.79541 to 1.79423, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8014 - mean_absolute_error: 0.9643 - mean_squared_error: 1.8014 - val_loss: 1.7942 - val_mean_absolute_error: 0.9659 - val_mean_squared_error: 1.7942\n",
            "Epoch 493/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.8070 - mean_absolute_error: 0.9650 - mean_squared_error: 1.8070\n",
            "Epoch 493: val_loss improved from 1.79423 to 1.79209, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7987 - mean_absolute_error: 0.9632 - mean_squared_error: 1.7987 - val_loss: 1.7921 - val_mean_absolute_error: 0.9656 - val_mean_squared_error: 1.7921\n",
            "Epoch 494/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.7939 - mean_absolute_error: 0.9625 - mean_squared_error: 1.7939\n",
            "Epoch 494: val_loss improved from 1.79209 to 1.78694, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7948 - mean_absolute_error: 0.9623 - mean_squared_error: 1.7948 - val_loss: 1.7869 - val_mean_absolute_error: 0.9619 - val_mean_squared_error: 1.7869\n",
            "Epoch 495/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.8043 - mean_absolute_error: 0.9633 - mean_squared_error: 1.8043\n",
            "Epoch 495: val_loss improved from 1.78694 to 1.78522, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7942 - mean_absolute_error: 0.9616 - mean_squared_error: 1.7942 - val_loss: 1.7852 - val_mean_absolute_error: 0.9625 - val_mean_squared_error: 1.7852\n",
            "Epoch 496/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.7966 - mean_absolute_error: 0.9617 - mean_squared_error: 1.7966\n",
            "Epoch 496: val_loss improved from 1.78522 to 1.78280, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7899 - mean_absolute_error: 0.9597 - mean_squared_error: 1.7899 - val_loss: 1.7828 - val_mean_absolute_error: 0.9604 - val_mean_squared_error: 1.7828\n",
            "Epoch 497/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.7937 - mean_absolute_error: 0.9648 - mean_squared_error: 1.7937\n",
            "Epoch 497: val_loss improved from 1.78280 to 1.77935, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7866 - mean_absolute_error: 0.9600 - mean_squared_error: 1.7866 - val_loss: 1.7793 - val_mean_absolute_error: 0.9592 - val_mean_squared_error: 1.7793\n",
            "Epoch 498/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.7860 - mean_absolute_error: 0.9588 - mean_squared_error: 1.7860\n",
            "Epoch 498: val_loss improved from 1.77935 to 1.77686, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7841 - mean_absolute_error: 0.9586 - mean_squared_error: 1.7841 - val_loss: 1.7769 - val_mean_absolute_error: 0.9574 - val_mean_squared_error: 1.7769\n",
            "Epoch 499/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.7686 - mean_absolute_error: 0.9553 - mean_squared_error: 1.7686\n",
            "Epoch 499: val_loss improved from 1.77686 to 1.77495, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7829 - mean_absolute_error: 0.9573 - mean_squared_error: 1.7829 - val_loss: 1.7749 - val_mean_absolute_error: 0.9564 - val_mean_squared_error: 1.7749\n",
            "Epoch 500/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.7880 - mean_absolute_error: 0.9594 - mean_squared_error: 1.7880\n",
            "Epoch 500: val_loss improved from 1.77495 to 1.77374, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7787 - mean_absolute_error: 0.9564 - mean_squared_error: 1.7787 - val_loss: 1.7737 - val_mean_absolute_error: 0.9557 - val_mean_squared_error: 1.7737\n",
            "Epoch 501/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.7938 - mean_absolute_error: 0.9585 - mean_squared_error: 1.7938\n",
            "Epoch 501: val_loss improved from 1.77374 to 1.76930, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7763 - mean_absolute_error: 0.9547 - mean_squared_error: 1.7763 - val_loss: 1.7693 - val_mean_absolute_error: 0.9558 - val_mean_squared_error: 1.7693\n",
            "Epoch 502/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.7886 - mean_absolute_error: 0.9579 - mean_squared_error: 1.7886\n",
            "Epoch 502: val_loss did not improve from 1.76930\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7721 - mean_absolute_error: 0.9540 - mean_squared_error: 1.7721 - val_loss: 1.7702 - val_mean_absolute_error: 0.9580 - val_mean_squared_error: 1.7702\n",
            "Epoch 503/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.7615 - mean_absolute_error: 0.9504 - mean_squared_error: 1.7615\n",
            "Epoch 503: val_loss improved from 1.76930 to 1.76406, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7719 - mean_absolute_error: 0.9540 - mean_squared_error: 1.7719 - val_loss: 1.7641 - val_mean_absolute_error: 0.9542 - val_mean_squared_error: 1.7641\n",
            "Epoch 504/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.7406 - mean_absolute_error: 0.9435 - mean_squared_error: 1.7406\n",
            "Epoch 504: val_loss improved from 1.76406 to 1.76174, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7676 - mean_absolute_error: 0.9510 - mean_squared_error: 1.7676 - val_loss: 1.7617 - val_mean_absolute_error: 0.9534 - val_mean_squared_error: 1.7617\n",
            "Epoch 505/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.7672 - mean_absolute_error: 0.9509 - mean_squared_error: 1.7672\n",
            "Epoch 505: val_loss improved from 1.76174 to 1.75915, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7647 - mean_absolute_error: 0.9511 - mean_squared_error: 1.7647 - val_loss: 1.7592 - val_mean_absolute_error: 0.9529 - val_mean_squared_error: 1.7592\n",
            "Epoch 506/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.7812 - mean_absolute_error: 0.9563 - mean_squared_error: 1.7812\n",
            "Epoch 506: val_loss improved from 1.75915 to 1.75551, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7648 - mean_absolute_error: 0.9514 - mean_squared_error: 1.7648 - val_loss: 1.7555 - val_mean_absolute_error: 0.9504 - val_mean_squared_error: 1.7555\n",
            "Epoch 507/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.7710 - mean_absolute_error: 0.9541 - mean_squared_error: 1.7710\n",
            "Epoch 507: val_loss improved from 1.75551 to 1.75458, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7611 - mean_absolute_error: 0.9491 - mean_squared_error: 1.7611 - val_loss: 1.7546 - val_mean_absolute_error: 0.9516 - val_mean_squared_error: 1.7546\n",
            "Epoch 508/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.7509 - mean_absolute_error: 0.9480 - mean_squared_error: 1.7509\n",
            "Epoch 508: val_loss improved from 1.75458 to 1.75432, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7562 - mean_absolute_error: 0.9483 - mean_squared_error: 1.7562 - val_loss: 1.7543 - val_mean_absolute_error: 0.9525 - val_mean_squared_error: 1.7543\n",
            "Epoch 509/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.7522 - mean_absolute_error: 0.9448 - mean_squared_error: 1.7522\n",
            "Epoch 509: val_loss improved from 1.75432 to 1.75216, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7525 - mean_absolute_error: 0.9465 - mean_squared_error: 1.7525 - val_loss: 1.7522 - val_mean_absolute_error: 0.9522 - val_mean_squared_error: 1.7522\n",
            "Epoch 510/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.7573 - mean_absolute_error: 0.9483 - mean_squared_error: 1.7573\n",
            "Epoch 510: val_loss improved from 1.75216 to 1.74469, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7470 - mean_absolute_error: 0.9467 - mean_squared_error: 1.7470 - val_loss: 1.7447 - val_mean_absolute_error: 0.9465 - val_mean_squared_error: 1.7447\n",
            "Epoch 511/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.7442 - mean_absolute_error: 0.9452 - mean_squared_error: 1.7442\n",
            "Epoch 511: val_loss improved from 1.74469 to 1.74333, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7466 - mean_absolute_error: 0.9452 - mean_squared_error: 1.7466 - val_loss: 1.7433 - val_mean_absolute_error: 0.9470 - val_mean_squared_error: 1.7433\n",
            "Epoch 512/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.7517 - mean_absolute_error: 0.9455 - mean_squared_error: 1.7517\n",
            "Epoch 512: val_loss improved from 1.74333 to 1.74093, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7443 - mean_absolute_error: 0.9436 - mean_squared_error: 1.7443 - val_loss: 1.7409 - val_mean_absolute_error: 0.9464 - val_mean_squared_error: 1.7409\n",
            "Epoch 513/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.7476 - mean_absolute_error: 0.9438 - mean_squared_error: 1.7476\n",
            "Epoch 513: val_loss improved from 1.74093 to 1.73820, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7420 - mean_absolute_error: 0.9417 - mean_squared_error: 1.7420 - val_loss: 1.7382 - val_mean_absolute_error: 0.9458 - val_mean_squared_error: 1.7382\n",
            "Epoch 514/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.7445 - mean_absolute_error: 0.9434 - mean_squared_error: 1.7445\n",
            "Epoch 514: val_loss improved from 1.73820 to 1.73458, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7385 - mean_absolute_error: 0.9418 - mean_squared_error: 1.7385 - val_loss: 1.7346 - val_mean_absolute_error: 0.9438 - val_mean_squared_error: 1.7346\n",
            "Epoch 515/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.7132 - mean_absolute_error: 0.9352 - mean_squared_error: 1.7132\n",
            "Epoch 515: val_loss did not improve from 1.73458\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7359 - mean_absolute_error: 0.9392 - mean_squared_error: 1.7359 - val_loss: 1.7352 - val_mean_absolute_error: 0.9454 - val_mean_squared_error: 1.7352\n",
            "Epoch 516/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.7384 - mean_absolute_error: 0.9399 - mean_squared_error: 1.7384\n",
            "Epoch 516: val_loss improved from 1.73458 to 1.72771, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7320 - mean_absolute_error: 0.9393 - mean_squared_error: 1.7320 - val_loss: 1.7277 - val_mean_absolute_error: 0.9392 - val_mean_squared_error: 1.7277\n",
            "Epoch 517/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.7407 - mean_absolute_error: 0.9399 - mean_squared_error: 1.7407\n",
            "Epoch 517: val_loss did not improve from 1.72771\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7313 - mean_absolute_error: 0.9370 - mean_squared_error: 1.7313 - val_loss: 1.7300 - val_mean_absolute_error: 0.9439 - val_mean_squared_error: 1.7300\n",
            "Epoch 518/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.6900 - mean_absolute_error: 0.9230 - mean_squared_error: 1.6900\n",
            "Epoch 518: val_loss improved from 1.72771 to 1.72229, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7280 - mean_absolute_error: 0.9366 - mean_squared_error: 1.7280 - val_loss: 1.7223 - val_mean_absolute_error: 0.9383 - val_mean_squared_error: 1.7223\n",
            "Epoch 519/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.7213 - mean_absolute_error: 0.9347 - mean_squared_error: 1.7213\n",
            "Epoch 519: val_loss improved from 1.72229 to 1.72089, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7216 - mean_absolute_error: 0.9340 - mean_squared_error: 1.7216 - val_loss: 1.7209 - val_mean_absolute_error: 0.9391 - val_mean_squared_error: 1.7209\n",
            "Epoch 520/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.7374 - mean_absolute_error: 0.9404 - mean_squared_error: 1.7374\n",
            "Epoch 520: val_loss improved from 1.72089 to 1.71685, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7207 - mean_absolute_error: 0.9357 - mean_squared_error: 1.7207 - val_loss: 1.7168 - val_mean_absolute_error: 0.9362 - val_mean_squared_error: 1.7168\n",
            "Epoch 521/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.7177 - mean_absolute_error: 0.9323 - mean_squared_error: 1.7177\n",
            "Epoch 521: val_loss improved from 1.71685 to 1.71564, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7177 - mean_absolute_error: 0.9323 - mean_squared_error: 1.7177 - val_loss: 1.7156 - val_mean_absolute_error: 0.9372 - val_mean_squared_error: 1.7156\n",
            "Epoch 522/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 1.7123 - mean_absolute_error: 0.9303 - mean_squared_error: 1.7123\n",
            "Epoch 522: val_loss improved from 1.71564 to 1.71181, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7141 - mean_absolute_error: 0.9315 - mean_squared_error: 1.7141 - val_loss: 1.7118 - val_mean_absolute_error: 0.9346 - val_mean_squared_error: 1.7118\n",
            "Epoch 523/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.7227 - mean_absolute_error: 0.9342 - mean_squared_error: 1.7227\n",
            "Epoch 523: val_loss improved from 1.71181 to 1.70874, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7117 - mean_absolute_error: 0.9312 - mean_squared_error: 1.7117 - val_loss: 1.7087 - val_mean_absolute_error: 0.9334 - val_mean_squared_error: 1.7087\n",
            "Epoch 524/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.6996 - mean_absolute_error: 0.9269 - mean_squared_error: 1.6996\n",
            "Epoch 524: val_loss did not improve from 1.70874\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7092 - mean_absolute_error: 0.9304 - mean_squared_error: 1.7092 - val_loss: 1.7223 - val_mean_absolute_error: 0.9434 - val_mean_squared_error: 1.7223\n",
            "Epoch 525/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.6985 - mean_absolute_error: 0.9259 - mean_squared_error: 1.6985\n",
            "Epoch 525: val_loss improved from 1.70874 to 1.70537, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7042 - mean_absolute_error: 0.9277 - mean_squared_error: 1.7042 - val_loss: 1.7054 - val_mean_absolute_error: 0.9294 - val_mean_squared_error: 1.7054\n",
            "Epoch 526/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.6992 - mean_absolute_error: 0.9253 - mean_squared_error: 1.6992\n",
            "Epoch 526: val_loss improved from 1.70537 to 1.70133, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7017 - mean_absolute_error: 0.9267 - mean_squared_error: 1.7017 - val_loss: 1.7013 - val_mean_absolute_error: 0.9313 - val_mean_squared_error: 1.7013\n",
            "Epoch 527/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.7049 - mean_absolute_error: 0.9279 - mean_squared_error: 1.7049\n",
            "Epoch 527: val_loss did not improve from 1.70133\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6991 - mean_absolute_error: 0.9264 - mean_squared_error: 1.6991 - val_loss: 1.7045 - val_mean_absolute_error: 0.9349 - val_mean_squared_error: 1.7045\n",
            "Epoch 528/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.6818 - mean_absolute_error: 0.9227 - mean_squared_error: 1.6818\n",
            "Epoch 528: val_loss improved from 1.70133 to 1.69606, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6972 - mean_absolute_error: 0.9258 - mean_squared_error: 1.6972 - val_loss: 1.6961 - val_mean_absolute_error: 0.9290 - val_mean_squared_error: 1.6961\n",
            "Epoch 529/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.6958 - mean_absolute_error: 0.9233 - mean_squared_error: 1.6958\n",
            "Epoch 529: val_loss did not improve from 1.69606\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6934 - mean_absolute_error: 0.9232 - mean_squared_error: 1.6934 - val_loss: 1.7009 - val_mean_absolute_error: 0.9337 - val_mean_squared_error: 1.7009\n",
            "Epoch 530/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.6875 - mean_absolute_error: 0.9203 - mean_squared_error: 1.6875\n",
            "Epoch 530: val_loss improved from 1.69606 to 1.69450, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6908 - mean_absolute_error: 0.9222 - mean_squared_error: 1.6908 - val_loss: 1.6945 - val_mean_absolute_error: 0.9302 - val_mean_squared_error: 1.6945\n",
            "Epoch 531/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.6917 - mean_absolute_error: 0.9241 - mean_squared_error: 1.6917\n",
            "Epoch 531: val_loss improved from 1.69450 to 1.68670, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6891 - mean_absolute_error: 0.9216 - mean_squared_error: 1.6891 - val_loss: 1.6867 - val_mean_absolute_error: 0.9251 - val_mean_squared_error: 1.6867\n",
            "Epoch 532/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.6647 - mean_absolute_error: 0.9120 - mean_squared_error: 1.6647\n",
            "Epoch 532: val_loss did not improve from 1.68670\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6861 - mean_absolute_error: 0.9195 - mean_squared_error: 1.6861 - val_loss: 1.6879 - val_mean_absolute_error: 0.9281 - val_mean_squared_error: 1.6879\n",
            "Epoch 533/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.6879 - mean_absolute_error: 0.9212 - mean_squared_error: 1.6879\n",
            "Epoch 533: val_loss improved from 1.68670 to 1.68508, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6823 - mean_absolute_error: 0.9196 - mean_squared_error: 1.6823 - val_loss: 1.6851 - val_mean_absolute_error: 0.9269 - val_mean_squared_error: 1.6851\n",
            "Epoch 534/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.6827 - mean_absolute_error: 0.9198 - mean_squared_error: 1.6827\n",
            "Epoch 534: val_loss improved from 1.68508 to 1.68362, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6800 - mean_absolute_error: 0.9185 - mean_squared_error: 1.6800 - val_loss: 1.6836 - val_mean_absolute_error: 0.9266 - val_mean_squared_error: 1.6836\n",
            "Epoch 535/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.6615 - mean_absolute_error: 0.9129 - mean_squared_error: 1.6615\n",
            "Epoch 535: val_loss improved from 1.68362 to 1.67637, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6768 - mean_absolute_error: 0.9167 - mean_squared_error: 1.6768 - val_loss: 1.6764 - val_mean_absolute_error: 0.9214 - val_mean_squared_error: 1.6764\n",
            "Epoch 536/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.6675 - mean_absolute_error: 0.9148 - mean_squared_error: 1.6675\n",
            "Epoch 536: val_loss improved from 1.67637 to 1.67534, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6717 - mean_absolute_error: 0.9158 - mean_squared_error: 1.6717 - val_loss: 1.6753 - val_mean_absolute_error: 0.9182 - val_mean_squared_error: 1.6753\n",
            "Epoch 537/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.6666 - mean_absolute_error: 0.9135 - mean_squared_error: 1.6666\n",
            "Epoch 537: val_loss did not improve from 1.67534\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6701 - mean_absolute_error: 0.9143 - mean_squared_error: 1.6701 - val_loss: 1.6764 - val_mean_absolute_error: 0.9239 - val_mean_squared_error: 1.6764\n",
            "Epoch 538/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.6866 - mean_absolute_error: 0.9182 - mean_squared_error: 1.6866\n",
            "Epoch 538: val_loss improved from 1.67534 to 1.67467, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6681 - mean_absolute_error: 0.9141 - mean_squared_error: 1.6681 - val_loss: 1.6747 - val_mean_absolute_error: 0.9237 - val_mean_squared_error: 1.6747\n",
            "Epoch 539/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.6686 - mean_absolute_error: 0.9123 - mean_squared_error: 1.6686\n",
            "Epoch 539: val_loss improved from 1.67467 to 1.67310, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6648 - mean_absolute_error: 0.9116 - mean_squared_error: 1.6648 - val_loss: 1.6731 - val_mean_absolute_error: 0.9236 - val_mean_squared_error: 1.6731\n",
            "Epoch 540/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.6551 - mean_absolute_error: 0.9087 - mean_squared_error: 1.6551\n",
            "Epoch 540: val_loss improved from 1.67310 to 1.66272, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6634 - mean_absolute_error: 0.9125 - mean_squared_error: 1.6634 - val_loss: 1.6627 - val_mean_absolute_error: 0.9156 - val_mean_squared_error: 1.6627\n",
            "Epoch 541/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.6629 - mean_absolute_error: 0.9114 - mean_squared_error: 1.6629\n",
            "Epoch 541: val_loss improved from 1.66272 to 1.66231, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6596 - mean_absolute_error: 0.9111 - mean_squared_error: 1.6596 - val_loss: 1.6623 - val_mean_absolute_error: 0.9166 - val_mean_squared_error: 1.6623\n",
            "Epoch 542/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.6450 - mean_absolute_error: 0.9059 - mean_squared_error: 1.6450\n",
            "Epoch 542: val_loss did not improve from 1.66231\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6554 - mean_absolute_error: 0.9079 - mean_squared_error: 1.6554 - val_loss: 1.6653 - val_mean_absolute_error: 0.9200 - val_mean_squared_error: 1.6653\n",
            "Epoch 543/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.6487 - mean_absolute_error: 0.9077 - mean_squared_error: 1.6487\n",
            "Epoch 543: val_loss improved from 1.66231 to 1.65436, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6541 - mean_absolute_error: 0.9086 - mean_squared_error: 1.6541 - val_loss: 1.6544 - val_mean_absolute_error: 0.9114 - val_mean_squared_error: 1.6544\n",
            "Epoch 544/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.6581 - mean_absolute_error: 0.9082 - mean_squared_error: 1.6581\n",
            "Epoch 544: val_loss did not improve from 1.65436\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6504 - mean_absolute_error: 0.9061 - mean_squared_error: 1.6504 - val_loss: 1.6571 - val_mean_absolute_error: 0.9160 - val_mean_squared_error: 1.6571\n",
            "Epoch 545/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.6633 - mean_absolute_error: 0.9131 - mean_squared_error: 1.6633\n",
            "Epoch 545: val_loss improved from 1.65436 to 1.64883, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6476 - mean_absolute_error: 0.9069 - mean_squared_error: 1.6476 - val_loss: 1.6488 - val_mean_absolute_error: 0.9094 - val_mean_squared_error: 1.6488\n",
            "Epoch 546/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.6442 - mean_absolute_error: 0.9056 - mean_squared_error: 1.6442\n",
            "Epoch 546: val_loss improved from 1.64883 to 1.64651, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6442 - mean_absolute_error: 0.9056 - mean_squared_error: 1.6442 - val_loss: 1.6465 - val_mean_absolute_error: 0.9091 - val_mean_squared_error: 1.6465\n",
            "Epoch 547/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.6404 - mean_absolute_error: 0.9035 - mean_squared_error: 1.6404\n",
            "Epoch 547: val_loss improved from 1.64651 to 1.64375, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6426 - mean_absolute_error: 0.9038 - mean_squared_error: 1.6426 - val_loss: 1.6438 - val_mean_absolute_error: 0.9062 - val_mean_squared_error: 1.6438\n",
            "Epoch 548/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.6249 - mean_absolute_error: 0.8996 - mean_squared_error: 1.6249\n",
            "Epoch 548: val_loss improved from 1.64375 to 1.64143, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6400 - mean_absolute_error: 0.9024 - mean_squared_error: 1.6400 - val_loss: 1.6414 - val_mean_absolute_error: 0.9060 - val_mean_squared_error: 1.6414\n",
            "Epoch 549/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.6521 - mean_absolute_error: 0.9079 - mean_squared_error: 1.6521\n",
            "Epoch 549: val_loss did not improve from 1.64143\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6367 - mean_absolute_error: 0.9011 - mean_squared_error: 1.6367 - val_loss: 1.6424 - val_mean_absolute_error: 0.9097 - val_mean_squared_error: 1.6424\n",
            "Epoch 550/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.6345 - mean_absolute_error: 0.9002 - mean_squared_error: 1.6345\n",
            "Epoch 550: val_loss improved from 1.64143 to 1.63657, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6349 - mean_absolute_error: 0.9011 - mean_squared_error: 1.6349 - val_loss: 1.6366 - val_mean_absolute_error: 0.9041 - val_mean_squared_error: 1.6366\n",
            "Epoch 551/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.6518 - mean_absolute_error: 0.9049 - mean_squared_error: 1.6518\n",
            "Epoch 551: val_loss improved from 1.63657 to 1.63497, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6320 - mean_absolute_error: 0.9006 - mean_squared_error: 1.6320 - val_loss: 1.6350 - val_mean_absolute_error: 0.9061 - val_mean_squared_error: 1.6350\n",
            "Epoch 552/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.6300 - mean_absolute_error: 0.9000 - mean_squared_error: 1.6300\n",
            "Epoch 552: val_loss improved from 1.63497 to 1.63074, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6287 - mean_absolute_error: 0.8991 - mean_squared_error: 1.6287 - val_loss: 1.6307 - val_mean_absolute_error: 0.9014 - val_mean_squared_error: 1.6307\n",
            "Epoch 553/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.6289 - mean_absolute_error: 0.8981 - mean_squared_error: 1.6289\n",
            "Epoch 553: val_loss did not improve from 1.63074\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6240 - mean_absolute_error: 0.8964 - mean_squared_error: 1.6240 - val_loss: 1.6318 - val_mean_absolute_error: 0.9055 - val_mean_squared_error: 1.6318\n",
            "Epoch 554/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.6394 - mean_absolute_error: 0.8998 - mean_squared_error: 1.6394\n",
            "Epoch 554: val_loss improved from 1.63074 to 1.62759, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6245 - mean_absolute_error: 0.8971 - mean_squared_error: 1.6245 - val_loss: 1.6276 - val_mean_absolute_error: 0.9006 - val_mean_squared_error: 1.6276\n",
            "Epoch 555/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.6259 - mean_absolute_error: 0.8967 - mean_squared_error: 1.6259\n",
            "Epoch 555: val_loss improved from 1.62759 to 1.62407, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6193 - mean_absolute_error: 0.8947 - mean_squared_error: 1.6193 - val_loss: 1.6241 - val_mean_absolute_error: 0.8996 - val_mean_squared_error: 1.6241\n",
            "Epoch 556/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.6030 - mean_absolute_error: 0.8927 - mean_squared_error: 1.6030\n",
            "Epoch 556: val_loss improved from 1.62407 to 1.62131, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6170 - mean_absolute_error: 0.8948 - mean_squared_error: 1.6170 - val_loss: 1.6213 - val_mean_absolute_error: 0.8978 - val_mean_squared_error: 1.6213\n",
            "Epoch 557/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.6232 - mean_absolute_error: 0.8978 - mean_squared_error: 1.6232\n",
            "Epoch 557: val_loss improved from 1.62131 to 1.62003, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6126 - mean_absolute_error: 0.8944 - mean_squared_error: 1.6126 - val_loss: 1.6200 - val_mean_absolute_error: 0.8963 - val_mean_squared_error: 1.6200\n",
            "Epoch 558/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.6026 - mean_absolute_error: 0.8908 - mean_squared_error: 1.6026\n",
            "Epoch 558: val_loss improved from 1.62003 to 1.61562, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6110 - mean_absolute_error: 0.8922 - mean_squared_error: 1.6110 - val_loss: 1.6156 - val_mean_absolute_error: 0.8950 - val_mean_squared_error: 1.6156\n",
            "Epoch 559/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.6089 - mean_absolute_error: 0.8907 - mean_squared_error: 1.6089\n",
            "Epoch 559: val_loss improved from 1.61562 to 1.61293, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6089 - mean_absolute_error: 0.8907 - mean_squared_error: 1.6089 - val_loss: 1.6129 - val_mean_absolute_error: 0.8951 - val_mean_squared_error: 1.6129\n",
            "Epoch 560/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.5981 - mean_absolute_error: 0.8874 - mean_squared_error: 1.5981\n",
            "Epoch 560: val_loss improved from 1.61293 to 1.61220, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6054 - mean_absolute_error: 0.8890 - mean_squared_error: 1.6054 - val_loss: 1.6122 - val_mean_absolute_error: 0.8970 - val_mean_squared_error: 1.6122\n",
            "Epoch 561/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.6078 - mean_absolute_error: 0.8900 - mean_squared_error: 1.6078\n",
            "Epoch 561: val_loss did not improve from 1.61220\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6015 - mean_absolute_error: 0.8889 - mean_squared_error: 1.6015 - val_loss: 1.6166 - val_mean_absolute_error: 0.8932 - val_mean_squared_error: 1.6166\n",
            "Epoch 562/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.6052 - mean_absolute_error: 0.8894 - mean_squared_error: 1.6052\n",
            "Epoch 562: val_loss improved from 1.61220 to 1.60599, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6003 - mean_absolute_error: 0.8881 - mean_squared_error: 1.6003 - val_loss: 1.6060 - val_mean_absolute_error: 0.8939 - val_mean_squared_error: 1.6060\n",
            "Epoch 563/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.5992 - mean_absolute_error: 0.8859 - mean_squared_error: 1.5992\n",
            "Epoch 563: val_loss improved from 1.60599 to 1.60362, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5965 - mean_absolute_error: 0.8865 - mean_squared_error: 1.5965 - val_loss: 1.6036 - val_mean_absolute_error: 0.8931 - val_mean_squared_error: 1.6036\n",
            "Epoch 564/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.5844 - mean_absolute_error: 0.8822 - mean_squared_error: 1.5844\n",
            "Epoch 564: val_loss improved from 1.60362 to 1.60304, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5946 - mean_absolute_error: 0.8856 - mean_squared_error: 1.5946 - val_loss: 1.6030 - val_mean_absolute_error: 0.8945 - val_mean_squared_error: 1.6030\n",
            "Epoch 565/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.5962 - mean_absolute_error: 0.8877 - mean_squared_error: 1.5962\n",
            "Epoch 565: val_loss improved from 1.60304 to 1.59807, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5903 - mean_absolute_error: 0.8838 - mean_squared_error: 1.5903 - val_loss: 1.5981 - val_mean_absolute_error: 0.8895 - val_mean_squared_error: 1.5981\n",
            "Epoch 566/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.5734 - mean_absolute_error: 0.8798 - mean_squared_error: 1.5734\n",
            "Epoch 566: val_loss improved from 1.59807 to 1.59717, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5856 - mean_absolute_error: 0.8833 - mean_squared_error: 1.5856 - val_loss: 1.5972 - val_mean_absolute_error: 0.8911 - val_mean_squared_error: 1.5972\n",
            "Epoch 567/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.5789 - mean_absolute_error: 0.8813 - mean_squared_error: 1.5789\n",
            "Epoch 567: val_loss improved from 1.59717 to 1.59676, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5846 - mean_absolute_error: 0.8816 - mean_squared_error: 1.5846 - val_loss: 1.5968 - val_mean_absolute_error: 0.8925 - val_mean_squared_error: 1.5968\n",
            "Epoch 568/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.5872 - mean_absolute_error: 0.8831 - mean_squared_error: 1.5872\n",
            "Epoch 568: val_loss improved from 1.59676 to 1.59108, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5827 - mean_absolute_error: 0.8817 - mean_squared_error: 1.5827 - val_loss: 1.5911 - val_mean_absolute_error: 0.8857 - val_mean_squared_error: 1.5911\n",
            "Epoch 569/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.5789 - mean_absolute_error: 0.8805 - mean_squared_error: 1.5789\n",
            "Epoch 569: val_loss improved from 1.59108 to 1.58822, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5801 - mean_absolute_error: 0.8806 - mean_squared_error: 1.5801 - val_loss: 1.5882 - val_mean_absolute_error: 0.8839 - val_mean_squared_error: 1.5882\n",
            "Epoch 570/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.5932 - mean_absolute_error: 0.8793 - mean_squared_error: 1.5932\n",
            "Epoch 570: val_loss did not improve from 1.58822\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5747 - mean_absolute_error: 0.8774 - mean_squared_error: 1.5747 - val_loss: 1.5910 - val_mean_absolute_error: 0.8850 - val_mean_squared_error: 1.5910\n",
            "Epoch 571/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.5752 - mean_absolute_error: 0.8788 - mean_squared_error: 1.5752\n",
            "Epoch 571: val_loss improved from 1.58822 to 1.58391, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5732 - mean_absolute_error: 0.8784 - mean_squared_error: 1.5732 - val_loss: 1.5839 - val_mean_absolute_error: 0.8858 - val_mean_squared_error: 1.5839\n",
            "Epoch 572/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.5484 - mean_absolute_error: 0.8712 - mean_squared_error: 1.5484\n",
            "Epoch 572: val_loss did not improve from 1.58391\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5697 - mean_absolute_error: 0.8757 - mean_squared_error: 1.5697 - val_loss: 1.5842 - val_mean_absolute_error: 0.8872 - val_mean_squared_error: 1.5842\n",
            "Epoch 573/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.5527 - mean_absolute_error: 0.8736 - mean_squared_error: 1.5527\n",
            "Epoch 573: val_loss improved from 1.58391 to 1.57774, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5673 - mean_absolute_error: 0.8767 - mean_squared_error: 1.5673 - val_loss: 1.5777 - val_mean_absolute_error: 0.8801 - val_mean_squared_error: 1.5777\n",
            "Epoch 574/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.5463 - mean_absolute_error: 0.8720 - mean_squared_error: 1.5463\n",
            "Epoch 574: val_loss improved from 1.57774 to 1.57416, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5668 - mean_absolute_error: 0.8758 - mean_squared_error: 1.5668 - val_loss: 1.5742 - val_mean_absolute_error: 0.8796 - val_mean_squared_error: 1.5742\n",
            "Epoch 575/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.5849 - mean_absolute_error: 0.8790 - mean_squared_error: 1.5849\n",
            "Epoch 575: val_loss did not improve from 1.57416\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5620 - mean_absolute_error: 0.8727 - mean_squared_error: 1.5620 - val_loss: 1.5758 - val_mean_absolute_error: 0.8830 - val_mean_squared_error: 1.5758\n",
            "Epoch 576/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.5573 - mean_absolute_error: 0.8731 - mean_squared_error: 1.5573\n",
            "Epoch 576: val_loss improved from 1.57416 to 1.56981, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5599 - mean_absolute_error: 0.8730 - mean_squared_error: 1.5599 - val_loss: 1.5698 - val_mean_absolute_error: 0.8785 - val_mean_squared_error: 1.5698\n",
            "Epoch 577/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.5404 - mean_absolute_error: 0.8652 - mean_squared_error: 1.5404\n",
            "Epoch 577: val_loss improved from 1.56981 to 1.56728, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5567 - mean_absolute_error: 0.8713 - mean_squared_error: 1.5567 - val_loss: 1.5673 - val_mean_absolute_error: 0.8766 - val_mean_squared_error: 1.5673\n",
            "Epoch 578/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.5396 - mean_absolute_error: 0.8662 - mean_squared_error: 1.5396\n",
            "Epoch 578: val_loss did not improve from 1.56728\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5526 - mean_absolute_error: 0.8698 - mean_squared_error: 1.5526 - val_loss: 1.5681 - val_mean_absolute_error: 0.8803 - val_mean_squared_error: 1.5681\n",
            "Epoch 579/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.5547 - mean_absolute_error: 0.8698 - mean_squared_error: 1.5547\n",
            "Epoch 579: val_loss improved from 1.56728 to 1.56366, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5509 - mean_absolute_error: 0.8693 - mean_squared_error: 1.5509 - val_loss: 1.5637 - val_mean_absolute_error: 0.8778 - val_mean_squared_error: 1.5637\n",
            "Epoch 580/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.5538 - mean_absolute_error: 0.8693 - mean_squared_error: 1.5538\n",
            "Epoch 580: val_loss improved from 1.56366 to 1.55999, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5470 - mean_absolute_error: 0.8680 - mean_squared_error: 1.5470 - val_loss: 1.5600 - val_mean_absolute_error: 0.8752 - val_mean_squared_error: 1.5600\n",
            "Epoch 581/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.5594 - mean_absolute_error: 0.8735 - mean_squared_error: 1.5594\n",
            "Epoch 581: val_loss improved from 1.55999 to 1.55694, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5442 - mean_absolute_error: 0.8685 - mean_squared_error: 1.5442 - val_loss: 1.5569 - val_mean_absolute_error: 0.8736 - val_mean_squared_error: 1.5569\n",
            "Epoch 582/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.5361 - mean_absolute_error: 0.8630 - mean_squared_error: 1.5361\n",
            "Epoch 582: val_loss improved from 1.55694 to 1.55478, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5403 - mean_absolute_error: 0.8649 - mean_squared_error: 1.5403 - val_loss: 1.5548 - val_mean_absolute_error: 0.8734 - val_mean_squared_error: 1.5548\n",
            "Epoch 583/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.5411 - mean_absolute_error: 0.8647 - mean_squared_error: 1.5411\n",
            "Epoch 583: val_loss improved from 1.55478 to 1.55456, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5400 - mean_absolute_error: 0.8651 - mean_squared_error: 1.5400 - val_loss: 1.5546 - val_mean_absolute_error: 0.8707 - val_mean_squared_error: 1.5546\n",
            "Epoch 584/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.5431 - mean_absolute_error: 0.8667 - mean_squared_error: 1.5431\n",
            "Epoch 584: val_loss improved from 1.55456 to 1.55008, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5359 - mean_absolute_error: 0.8645 - mean_squared_error: 1.5359 - val_loss: 1.5501 - val_mean_absolute_error: 0.8713 - val_mean_squared_error: 1.5501\n",
            "Epoch 585/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.5347 - mean_absolute_error: 0.8617 - mean_squared_error: 1.5347\n",
            "Epoch 585: val_loss improved from 1.55008 to 1.54750, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5320 - mean_absolute_error: 0.8617 - mean_squared_error: 1.5320 - val_loss: 1.5475 - val_mean_absolute_error: 0.8700 - val_mean_squared_error: 1.5475\n",
            "Epoch 586/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.5349 - mean_absolute_error: 0.8633 - mean_squared_error: 1.5349\n",
            "Epoch 586: val_loss improved from 1.54750 to 1.54466, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5292 - mean_absolute_error: 0.8626 - mean_squared_error: 1.5292 - val_loss: 1.5447 - val_mean_absolute_error: 0.8685 - val_mean_squared_error: 1.5447\n",
            "Epoch 587/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.5316 - mean_absolute_error: 0.8616 - mean_squared_error: 1.5316\n",
            "Epoch 587: val_loss did not improve from 1.54466\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5272 - mean_absolute_error: 0.8597 - mean_squared_error: 1.5272 - val_loss: 1.5484 - val_mean_absolute_error: 0.8733 - val_mean_squared_error: 1.5484\n",
            "Epoch 588/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.5297 - mean_absolute_error: 0.8610 - mean_squared_error: 1.5297\n",
            "Epoch 588: val_loss improved from 1.54466 to 1.54021, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5231 - mean_absolute_error: 0.8598 - mean_squared_error: 1.5231 - val_loss: 1.5402 - val_mean_absolute_error: 0.8663 - val_mean_squared_error: 1.5402\n",
            "Epoch 589/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.5139 - mean_absolute_error: 0.8561 - mean_squared_error: 1.5139\n",
            "Epoch 589: val_loss did not improve from 1.54021\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5201 - mean_absolute_error: 0.8583 - mean_squared_error: 1.5201 - val_loss: 1.5421 - val_mean_absolute_error: 0.8704 - val_mean_squared_error: 1.5421\n",
            "Epoch 590/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.5285 - mean_absolute_error: 0.8605 - mean_squared_error: 1.5285\n",
            "Epoch 590: val_loss improved from 1.54021 to 1.53701, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5192 - mean_absolute_error: 0.8575 - mean_squared_error: 1.5192 - val_loss: 1.5370 - val_mean_absolute_error: 0.8672 - val_mean_squared_error: 1.5370\n",
            "Epoch 591/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.5180 - mean_absolute_error: 0.8575 - mean_squared_error: 1.5180\n",
            "Epoch 591: val_loss improved from 1.53701 to 1.53357, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5158 - mean_absolute_error: 0.8570 - mean_squared_error: 1.5158 - val_loss: 1.5336 - val_mean_absolute_error: 0.8630 - val_mean_squared_error: 1.5336\n",
            "Epoch 592/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.5254 - mean_absolute_error: 0.8596 - mean_squared_error: 1.5254\n",
            "Epoch 592: val_loss did not improve from 1.53357\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5108 - mean_absolute_error: 0.8555 - mean_squared_error: 1.5108 - val_loss: 1.5384 - val_mean_absolute_error: 0.8636 - val_mean_squared_error: 1.5384\n",
            "Epoch 593/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.5243 - mean_absolute_error: 0.8599 - mean_squared_error: 1.5243\n",
            "Epoch 593: val_loss improved from 1.53357 to 1.53131, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5088 - mean_absolute_error: 0.8545 - mean_squared_error: 1.5088 - val_loss: 1.5313 - val_mean_absolute_error: 0.8620 - val_mean_squared_error: 1.5313\n",
            "Epoch 594/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.5024 - mean_absolute_error: 0.8526 - mean_squared_error: 1.5024\n",
            "Epoch 594: val_loss improved from 1.53131 to 1.52926, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5077 - mean_absolute_error: 0.8539 - mean_squared_error: 1.5077 - val_loss: 1.5293 - val_mean_absolute_error: 0.8594 - val_mean_squared_error: 1.5293\n",
            "Epoch 595/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.4962 - mean_absolute_error: 0.8500 - mean_squared_error: 1.4962\n",
            "Epoch 595: val_loss improved from 1.52926 to 1.52430, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5062 - mean_absolute_error: 0.8523 - mean_squared_error: 1.5062 - val_loss: 1.5243 - val_mean_absolute_error: 0.8605 - val_mean_squared_error: 1.5243\n",
            "Epoch 596/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.5110 - mean_absolute_error: 0.8538 - mean_squared_error: 1.5110\n",
            "Epoch 596: val_loss did not improve from 1.52430\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5035 - mean_absolute_error: 0.8518 - mean_squared_error: 1.5035 - val_loss: 1.5270 - val_mean_absolute_error: 0.8641 - val_mean_squared_error: 1.5270\n",
            "Epoch 597/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.4930 - mean_absolute_error: 0.8473 - mean_squared_error: 1.4930\n",
            "Epoch 597: val_loss did not improve from 1.52430\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5000 - mean_absolute_error: 0.8497 - mean_squared_error: 1.5000 - val_loss: 1.5248 - val_mean_absolute_error: 0.8632 - val_mean_squared_error: 1.5248\n",
            "Epoch 598/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.4875 - mean_absolute_error: 0.8473 - mean_squared_error: 1.4875\n",
            "Epoch 598: val_loss improved from 1.52430 to 1.52001, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4997 - mean_absolute_error: 0.8508 - mean_squared_error: 1.4997 - val_loss: 1.5200 - val_mean_absolute_error: 0.8600 - val_mean_squared_error: 1.5200\n",
            "Epoch 599/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.5008 - mean_absolute_error: 0.8466 - mean_squared_error: 1.5008\n",
            "Epoch 599: val_loss improved from 1.52001 to 1.51769, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4971 - mean_absolute_error: 0.8497 - mean_squared_error: 1.4971 - val_loss: 1.5177 - val_mean_absolute_error: 0.8586 - val_mean_squared_error: 1.5177\n",
            "Epoch 600/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.5107 - mean_absolute_error: 0.8528 - mean_squared_error: 1.5107\n",
            "Epoch 600: val_loss improved from 1.51769 to 1.51409, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4932 - mean_absolute_error: 0.8477 - mean_squared_error: 1.4932 - val_loss: 1.5141 - val_mean_absolute_error: 0.8570 - val_mean_squared_error: 1.5141\n",
            "Epoch 601/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.4810 - mean_absolute_error: 0.8462 - mean_squared_error: 1.4810\n",
            "Epoch 601: val_loss did not improve from 1.51409\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4902 - mean_absolute_error: 0.8482 - mean_squared_error: 1.4902 - val_loss: 1.5189 - val_mean_absolute_error: 0.8544 - val_mean_squared_error: 1.5189\n",
            "Epoch 602/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.4851 - mean_absolute_error: 0.8476 - mean_squared_error: 1.4851\n",
            "Epoch 602: val_loss improved from 1.51409 to 1.51052, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4862 - mean_absolute_error: 0.8461 - mean_squared_error: 1.4862 - val_loss: 1.5105 - val_mean_absolute_error: 0.8519 - val_mean_squared_error: 1.5105\n",
            "Epoch 603/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.4930 - mean_absolute_error: 0.8461 - mean_squared_error: 1.4930\n",
            "Epoch 603: val_loss improved from 1.51052 to 1.50741, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4868 - mean_absolute_error: 0.8450 - mean_squared_error: 1.4868 - val_loss: 1.5074 - val_mean_absolute_error: 0.8538 - val_mean_squared_error: 1.5074\n",
            "Epoch 604/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.4908 - mean_absolute_error: 0.8456 - mean_squared_error: 1.4908\n",
            "Epoch 604: val_loss did not improve from 1.50741\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4816 - mean_absolute_error: 0.8434 - mean_squared_error: 1.4816 - val_loss: 1.5099 - val_mean_absolute_error: 0.8577 - val_mean_squared_error: 1.5099\n",
            "Epoch 605/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.4778 - mean_absolute_error: 0.8451 - mean_squared_error: 1.4778\n",
            "Epoch 605: val_loss improved from 1.50741 to 1.50295, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4802 - mean_absolute_error: 0.8443 - mean_squared_error: 1.4802 - val_loss: 1.5030 - val_mean_absolute_error: 0.8512 - val_mean_squared_error: 1.5030\n",
            "Epoch 606/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.4628 - mean_absolute_error: 0.8361 - mean_squared_error: 1.4628\n",
            "Epoch 606: val_loss improved from 1.50295 to 1.50293, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4774 - mean_absolute_error: 0.8413 - mean_squared_error: 1.4774 - val_loss: 1.5029 - val_mean_absolute_error: 0.8503 - val_mean_squared_error: 1.5029\n",
            "Epoch 607/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.4781 - mean_absolute_error: 0.8437 - mean_squared_error: 1.4781\n",
            "Epoch 607: val_loss improved from 1.50293 to 1.50139, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4725 - mean_absolute_error: 0.8412 - mean_squared_error: 1.4725 - val_loss: 1.5014 - val_mean_absolute_error: 0.8498 - val_mean_squared_error: 1.5014\n",
            "Epoch 608/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.4692 - mean_absolute_error: 0.8397 - mean_squared_error: 1.4692\n",
            "Epoch 608: val_loss improved from 1.50139 to 1.49904, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4732 - mean_absolute_error: 0.8397 - mean_squared_error: 1.4732 - val_loss: 1.4990 - val_mean_absolute_error: 0.8525 - val_mean_squared_error: 1.4990\n",
            "Epoch 609/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.4768 - mean_absolute_error: 0.8416 - mean_squared_error: 1.4768\n",
            "Epoch 609: val_loss improved from 1.49904 to 1.49593, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4702 - mean_absolute_error: 0.8406 - mean_squared_error: 1.4702 - val_loss: 1.4959 - val_mean_absolute_error: 0.8496 - val_mean_squared_error: 1.4959\n",
            "Epoch 610/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.4718 - mean_absolute_error: 0.8390 - mean_squared_error: 1.4718\n",
            "Epoch 610: val_loss improved from 1.49593 to 1.49575, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4691 - mean_absolute_error: 0.8382 - mean_squared_error: 1.4691 - val_loss: 1.4958 - val_mean_absolute_error: 0.8510 - val_mean_squared_error: 1.4958\n",
            "Epoch 611/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.4882 - mean_absolute_error: 0.8455 - mean_squared_error: 1.4882\n",
            "Epoch 611: val_loss improved from 1.49575 to 1.49486, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4664 - mean_absolute_error: 0.8382 - mean_squared_error: 1.4664 - val_loss: 1.4949 - val_mean_absolute_error: 0.8513 - val_mean_squared_error: 1.4949\n",
            "Epoch 612/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.4736 - mean_absolute_error: 0.8422 - mean_squared_error: 1.4736\n",
            "Epoch 612: val_loss improved from 1.49486 to 1.49088, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4641 - mean_absolute_error: 0.8381 - mean_squared_error: 1.4641 - val_loss: 1.4909 - val_mean_absolute_error: 0.8460 - val_mean_squared_error: 1.4909\n",
            "Epoch 613/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.4638 - mean_absolute_error: 0.8382 - mean_squared_error: 1.4638\n",
            "Epoch 613: val_loss improved from 1.49088 to 1.48901, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4612 - mean_absolute_error: 0.8363 - mean_squared_error: 1.4612 - val_loss: 1.4890 - val_mean_absolute_error: 0.8482 - val_mean_squared_error: 1.4890\n",
            "Epoch 614/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.4564 - mean_absolute_error: 0.8359 - mean_squared_error: 1.4564\n",
            "Epoch 614: val_loss did not improve from 1.48901\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4588 - mean_absolute_error: 0.8346 - mean_squared_error: 1.4588 - val_loss: 1.4955 - val_mean_absolute_error: 0.8529 - val_mean_squared_error: 1.4955\n",
            "Epoch 615/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.4450 - mean_absolute_error: 0.8346 - mean_squared_error: 1.4450\n",
            "Epoch 615: val_loss improved from 1.48901 to 1.48357, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4577 - mean_absolute_error: 0.8365 - mean_squared_error: 1.4577 - val_loss: 1.4836 - val_mean_absolute_error: 0.8439 - val_mean_squared_error: 1.4836\n",
            "Epoch 616/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.4228 - mean_absolute_error: 0.8254 - mean_squared_error: 1.4228\n",
            "Epoch 616: val_loss did not improve from 1.48357\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4532 - mean_absolute_error: 0.8328 - mean_squared_error: 1.4532 - val_loss: 1.4946 - val_mean_absolute_error: 0.8528 - val_mean_squared_error: 1.4946\n",
            "Epoch 617/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.4604 - mean_absolute_error: 0.8374 - mean_squared_error: 1.4604\n",
            "Epoch 617: val_loss improved from 1.48357 to 1.47990, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4529 - mean_absolute_error: 0.8350 - mean_squared_error: 1.4529 - val_loss: 1.4799 - val_mean_absolute_error: 0.8427 - val_mean_squared_error: 1.4799\n",
            "Epoch 618/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.4567 - mean_absolute_error: 0.8341 - mean_squared_error: 1.4567\n",
            "Epoch 618: val_loss improved from 1.47990 to 1.47806, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4496 - mean_absolute_error: 0.8323 - mean_squared_error: 1.4496 - val_loss: 1.4781 - val_mean_absolute_error: 0.8415 - val_mean_squared_error: 1.4781\n",
            "Epoch 619/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.4588 - mean_absolute_error: 0.8354 - mean_squared_error: 1.4588\n",
            "Epoch 619: val_loss improved from 1.47806 to 1.47620, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4478 - mean_absolute_error: 0.8307 - mean_squared_error: 1.4478 - val_loss: 1.4762 - val_mean_absolute_error: 0.8411 - val_mean_squared_error: 1.4762\n",
            "Epoch 620/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.4505 - mean_absolute_error: 0.8336 - mean_squared_error: 1.4505\n",
            "Epoch 620: val_loss improved from 1.47620 to 1.47576, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4437 - mean_absolute_error: 0.8298 - mean_squared_error: 1.4437 - val_loss: 1.4758 - val_mean_absolute_error: 0.8425 - val_mean_squared_error: 1.4758\n",
            "Epoch 621/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.4350 - mean_absolute_error: 0.8289 - mean_squared_error: 1.4350\n",
            "Epoch 621: val_loss improved from 1.47576 to 1.47531, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4438 - mean_absolute_error: 0.8299 - mean_squared_error: 1.4438 - val_loss: 1.4753 - val_mean_absolute_error: 0.8382 - val_mean_squared_error: 1.4753\n",
            "Epoch 622/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.4397 - mean_absolute_error: 0.8284 - mean_squared_error: 1.4397\n",
            "Epoch 622: val_loss did not improve from 1.47531\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4431 - mean_absolute_error: 0.8291 - mean_squared_error: 1.4431 - val_loss: 1.4874 - val_mean_absolute_error: 0.8535 - val_mean_squared_error: 1.4874\n",
            "Epoch 623/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.4329 - mean_absolute_error: 0.8275 - mean_squared_error: 1.4329\n",
            "Epoch 623: val_loss did not improve from 1.47531\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4386 - mean_absolute_error: 0.8287 - mean_squared_error: 1.4386 - val_loss: 1.4754 - val_mean_absolute_error: 0.8452 - val_mean_squared_error: 1.4754\n",
            "Epoch 624/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.4460 - mean_absolute_error: 0.8319 - mean_squared_error: 1.4460\n",
            "Epoch 624: val_loss improved from 1.47531 to 1.46681, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4356 - mean_absolute_error: 0.8280 - mean_squared_error: 1.4356 - val_loss: 1.4668 - val_mean_absolute_error: 0.8374 - val_mean_squared_error: 1.4668\n",
            "Epoch 625/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.4402 - mean_absolute_error: 0.8288 - mean_squared_error: 1.4402\n",
            "Epoch 625: val_loss improved from 1.46681 to 1.46557, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4345 - mean_absolute_error: 0.8268 - mean_squared_error: 1.4345 - val_loss: 1.4656 - val_mean_absolute_error: 0.8383 - val_mean_squared_error: 1.4656\n",
            "Epoch 626/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.4456 - mean_absolute_error: 0.8313 - mean_squared_error: 1.4456\n",
            "Epoch 626: val_loss improved from 1.46557 to 1.46338, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4307 - mean_absolute_error: 0.8258 - mean_squared_error: 1.4307 - val_loss: 1.4634 - val_mean_absolute_error: 0.8366 - val_mean_squared_error: 1.4634\n",
            "Epoch 627/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.4441 - mean_absolute_error: 0.8273 - mean_squared_error: 1.4441\n",
            "Epoch 627: val_loss improved from 1.46338 to 1.46239, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4308 - mean_absolute_error: 0.8260 - mean_squared_error: 1.4308 - val_loss: 1.4624 - val_mean_absolute_error: 0.8373 - val_mean_squared_error: 1.4624\n",
            "Epoch 628/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.4223 - mean_absolute_error: 0.8221 - mean_squared_error: 1.4223\n",
            "Epoch 628: val_loss did not improve from 1.46239\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4269 - mean_absolute_error: 0.8234 - mean_squared_error: 1.4269 - val_loss: 1.4666 - val_mean_absolute_error: 0.8437 - val_mean_squared_error: 1.4666\n",
            "Epoch 629/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.4297 - mean_absolute_error: 0.8262 - mean_squared_error: 1.4297\n",
            "Epoch 629: val_loss improved from 1.46239 to 1.45819, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4275 - mean_absolute_error: 0.8252 - mean_squared_error: 1.4275 - val_loss: 1.4582 - val_mean_absolute_error: 0.8344 - val_mean_squared_error: 1.4582\n",
            "Epoch 630/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.4041 - mean_absolute_error: 0.8198 - mean_squared_error: 1.4041\n",
            "Epoch 630: val_loss did not improve from 1.45819\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4262 - mean_absolute_error: 0.8262 - mean_squared_error: 1.4262 - val_loss: 1.4591 - val_mean_absolute_error: 0.8382 - val_mean_squared_error: 1.4591\n",
            "Epoch 631/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.4223 - mean_absolute_error: 0.8230 - mean_squared_error: 1.4223\n",
            "Epoch 631: val_loss did not improve from 1.45819\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4200 - mean_absolute_error: 0.8226 - mean_squared_error: 1.4200 - val_loss: 1.4618 - val_mean_absolute_error: 0.8428 - val_mean_squared_error: 1.4618\n",
            "Epoch 632/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.4216 - mean_absolute_error: 0.8265 - mean_squared_error: 1.4216\n",
            "Epoch 632: val_loss improved from 1.45819 to 1.45382, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4184 - mean_absolute_error: 0.8237 - mean_squared_error: 1.4184 - val_loss: 1.4538 - val_mean_absolute_error: 0.8344 - val_mean_squared_error: 1.4538\n",
            "Epoch 633/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.4102 - mean_absolute_error: 0.8207 - mean_squared_error: 1.4102\n",
            "Epoch 633: val_loss improved from 1.45382 to 1.45253, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4188 - mean_absolute_error: 0.8234 - mean_squared_error: 1.4188 - val_loss: 1.4525 - val_mean_absolute_error: 0.8349 - val_mean_squared_error: 1.4525\n",
            "Epoch 634/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.4176 - mean_absolute_error: 0.8226 - mean_squared_error: 1.4176\n",
            "Epoch 634: val_loss did not improve from 1.45253\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4159 - mean_absolute_error: 0.8223 - mean_squared_error: 1.4159 - val_loss: 1.4559 - val_mean_absolute_error: 0.8403 - val_mean_squared_error: 1.4559\n",
            "Epoch 635/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.4114 - mean_absolute_error: 0.8203 - mean_squared_error: 1.4114\n",
            "Epoch 635: val_loss improved from 1.45253 to 1.45140, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4131 - mean_absolute_error: 0.8206 - mean_squared_error: 1.4131 - val_loss: 1.4514 - val_mean_absolute_error: 0.8368 - val_mean_squared_error: 1.4514\n",
            "Epoch 636/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.4148 - mean_absolute_error: 0.8222 - mean_squared_error: 1.4148\n",
            "Epoch 636: val_loss improved from 1.45140 to 1.44748, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.4127 - mean_absolute_error: 0.8225 - mean_squared_error: 1.4127 - val_loss: 1.4475 - val_mean_absolute_error: 0.8331 - val_mean_squared_error: 1.4475\n",
            "Epoch 637/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.4260 - mean_absolute_error: 0.8248 - mean_squared_error: 1.4260\n",
            "Epoch 637: val_loss improved from 1.44748 to 1.44653, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4094 - mean_absolute_error: 0.8210 - mean_squared_error: 1.4094 - val_loss: 1.4465 - val_mean_absolute_error: 0.8345 - val_mean_squared_error: 1.4465\n",
            "Epoch 638/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.4046 - mean_absolute_error: 0.8193 - mean_squared_error: 1.4046\n",
            "Epoch 638: val_loss improved from 1.44653 to 1.44424, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4074 - mean_absolute_error: 0.8202 - mean_squared_error: 1.4074 - val_loss: 1.4442 - val_mean_absolute_error: 0.8330 - val_mean_squared_error: 1.4442\n",
            "Epoch 639/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.4087 - mean_absolute_error: 0.8194 - mean_squared_error: 1.4087\n",
            "Epoch 639: val_loss did not improve from 1.44424\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4045 - mean_absolute_error: 0.8191 - mean_squared_error: 1.4045 - val_loss: 1.4607 - val_mean_absolute_error: 0.8482 - val_mean_squared_error: 1.4607\n",
            "Epoch 640/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.4049 - mean_absolute_error: 0.8180 - mean_squared_error: 1.4049\n",
            "Epoch 640: val_loss improved from 1.44424 to 1.44404, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4076 - mean_absolute_error: 0.8200 - mean_squared_error: 1.4076 - val_loss: 1.4440 - val_mean_absolute_error: 0.8356 - val_mean_squared_error: 1.4440\n",
            "Epoch 641/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.4005 - mean_absolute_error: 0.8192 - mean_squared_error: 1.4005\n",
            "Epoch 641: val_loss improved from 1.44404 to 1.44113, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4005 - mean_absolute_error: 0.8192 - mean_squared_error: 1.4005 - val_loss: 1.4411 - val_mean_absolute_error: 0.8318 - val_mean_squared_error: 1.4411\n",
            "Epoch 642/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.3996 - mean_absolute_error: 0.8191 - mean_squared_error: 1.3996\n",
            "Epoch 642: val_loss did not improve from 1.44113\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3996 - mean_absolute_error: 0.8191 - mean_squared_error: 1.3996 - val_loss: 1.4435 - val_mean_absolute_error: 0.8315 - val_mean_squared_error: 1.4435\n",
            "Epoch 643/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.3770 - mean_absolute_error: 0.8097 - mean_squared_error: 1.3770\n",
            "Epoch 643: val_loss did not improve from 1.44113\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3979 - mean_absolute_error: 0.8178 - mean_squared_error: 1.3979 - val_loss: 1.4537 - val_mean_absolute_error: 0.8472 - val_mean_squared_error: 1.4537\n",
            "Epoch 644/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.4077 - mean_absolute_error: 0.8240 - mean_squared_error: 1.4077\n",
            "Epoch 644: val_loss improved from 1.44113 to 1.43899, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3948 - mean_absolute_error: 0.8205 - mean_squared_error: 1.3948 - val_loss: 1.4390 - val_mean_absolute_error: 0.8287 - val_mean_squared_error: 1.4390\n",
            "Epoch 645/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.3959 - mean_absolute_error: 0.8168 - mean_squared_error: 1.3959\n",
            "Epoch 645: val_loss improved from 1.43899 to 1.43839, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3948 - mean_absolute_error: 0.8164 - mean_squared_error: 1.3948 - val_loss: 1.4384 - val_mean_absolute_error: 0.8360 - val_mean_squared_error: 1.4384\n",
            "Epoch 646/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.4051 - mean_absolute_error: 0.8222 - mean_squared_error: 1.4051\n",
            "Epoch 646: val_loss did not improve from 1.43839\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3940 - mean_absolute_error: 0.8179 - mean_squared_error: 1.3940 - val_loss: 1.4386 - val_mean_absolute_error: 0.8374 - val_mean_squared_error: 1.4386\n",
            "Epoch 647/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.3915 - mean_absolute_error: 0.8185 - mean_squared_error: 1.3915\n",
            "Epoch 647: val_loss improved from 1.43839 to 1.43167, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3913 - mean_absolute_error: 0.8181 - mean_squared_error: 1.3913 - val_loss: 1.4317 - val_mean_absolute_error: 0.8306 - val_mean_squared_error: 1.4317\n",
            "Epoch 648/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.3785 - mean_absolute_error: 0.8112 - mean_squared_error: 1.3785\n",
            "Epoch 648: val_loss improved from 1.43167 to 1.42994, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3916 - mean_absolute_error: 0.8170 - mean_squared_error: 1.3916 - val_loss: 1.4299 - val_mean_absolute_error: 0.8277 - val_mean_squared_error: 1.4299\n",
            "Epoch 649/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.3838 - mean_absolute_error: 0.8142 - mean_squared_error: 1.3838\n",
            "Epoch 649: val_loss did not improve from 1.42994\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3902 - mean_absolute_error: 0.8165 - mean_squared_error: 1.3902 - val_loss: 1.4306 - val_mean_absolute_error: 0.8323 - val_mean_squared_error: 1.4306\n",
            "Epoch 650/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.3879 - mean_absolute_error: 0.8174 - mean_squared_error: 1.3879\n",
            "Epoch 650: val_loss improved from 1.42994 to 1.42741, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3881 - mean_absolute_error: 0.8166 - mean_squared_error: 1.3881 - val_loss: 1.4274 - val_mean_absolute_error: 0.8296 - val_mean_squared_error: 1.4274\n",
            "Epoch 651/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.3447 - mean_absolute_error: 0.8028 - mean_squared_error: 1.3447\n",
            "Epoch 651: val_loss did not improve from 1.42741\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3857 - mean_absolute_error: 0.8158 - mean_squared_error: 1.3857 - val_loss: 1.4275 - val_mean_absolute_error: 0.8314 - val_mean_squared_error: 1.4275\n",
            "Epoch 652/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.3877 - mean_absolute_error: 0.8153 - mean_squared_error: 1.3877\n",
            "Epoch 652: val_loss improved from 1.42741 to 1.42653, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3839 - mean_absolute_error: 0.8162 - mean_squared_error: 1.3839 - val_loss: 1.4265 - val_mean_absolute_error: 0.8286 - val_mean_squared_error: 1.4265\n",
            "Epoch 653/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.3990 - mean_absolute_error: 0.8194 - mean_squared_error: 1.3990\n",
            "Epoch 653: val_loss improved from 1.42653 to 1.42359, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3832 - mean_absolute_error: 0.8154 - mean_squared_error: 1.3832 - val_loss: 1.4236 - val_mean_absolute_error: 0.8279 - val_mean_squared_error: 1.4236\n",
            "Epoch 654/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.3798 - mean_absolute_error: 0.8142 - mean_squared_error: 1.3798\n",
            "Epoch 654: val_loss improved from 1.42359 to 1.42264, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3803 - mean_absolute_error: 0.8138 - mean_squared_error: 1.3803 - val_loss: 1.4226 - val_mean_absolute_error: 0.8294 - val_mean_squared_error: 1.4226\n",
            "Epoch 655/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.3789 - mean_absolute_error: 0.8149 - mean_squared_error: 1.3789\n",
            "Epoch 655: val_loss improved from 1.42264 to 1.42113, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3789 - mean_absolute_error: 0.8149 - mean_squared_error: 1.3789 - val_loss: 1.4211 - val_mean_absolute_error: 0.8280 - val_mean_squared_error: 1.4211\n",
            "Epoch 656/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.3687 - mean_absolute_error: 0.8117 - mean_squared_error: 1.3687\n",
            "Epoch 656: val_loss improved from 1.42113 to 1.41996, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3766 - mean_absolute_error: 0.8143 - mean_squared_error: 1.3766 - val_loss: 1.4200 - val_mean_absolute_error: 0.8275 - val_mean_squared_error: 1.4200\n",
            "Epoch 657/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.3729 - mean_absolute_error: 0.8135 - mean_squared_error: 1.3729\n",
            "Epoch 657: val_loss improved from 1.41996 to 1.41837, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3767 - mean_absolute_error: 0.8139 - mean_squared_error: 1.3767 - val_loss: 1.4184 - val_mean_absolute_error: 0.8273 - val_mean_squared_error: 1.4184\n",
            "Epoch 658/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.3634 - mean_absolute_error: 0.8109 - mean_squared_error: 1.3634\n",
            "Epoch 658: val_loss did not improve from 1.41837\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3743 - mean_absolute_error: 0.8139 - mean_squared_error: 1.3743 - val_loss: 1.4207 - val_mean_absolute_error: 0.8322 - val_mean_squared_error: 1.4207\n",
            "Epoch 659/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.3818 - mean_absolute_error: 0.8178 - mean_squared_error: 1.3818\n",
            "Epoch 659: val_loss did not improve from 1.41837\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3735 - mean_absolute_error: 0.8140 - mean_squared_error: 1.3735 - val_loss: 1.4189 - val_mean_absolute_error: 0.8308 - val_mean_squared_error: 1.4189\n",
            "Epoch 660/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.3795 - mean_absolute_error: 0.8146 - mean_squared_error: 1.3795\n",
            "Epoch 660: val_loss improved from 1.41837 to 1.41449, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3712 - mean_absolute_error: 0.8136 - mean_squared_error: 1.3712 - val_loss: 1.4145 - val_mean_absolute_error: 0.8239 - val_mean_squared_error: 1.4145\n",
            "Epoch 661/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.3682 - mean_absolute_error: 0.8125 - mean_squared_error: 1.3682\n",
            "Epoch 661: val_loss improved from 1.41449 to 1.41251, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3703 - mean_absolute_error: 0.8126 - mean_squared_error: 1.3703 - val_loss: 1.4125 - val_mean_absolute_error: 0.8248 - val_mean_squared_error: 1.4125\n",
            "Epoch 662/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.3636 - mean_absolute_error: 0.8125 - mean_squared_error: 1.3636\n",
            "Epoch 662: val_loss did not improve from 1.41251\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3687 - mean_absolute_error: 0.8133 - mean_squared_error: 1.3687 - val_loss: 1.4143 - val_mean_absolute_error: 0.8243 - val_mean_squared_error: 1.4143\n",
            "Epoch 663/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.3615 - mean_absolute_error: 0.8105 - mean_squared_error: 1.3615\n",
            "Epoch 663: val_loss did not improve from 1.41251\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3688 - mean_absolute_error: 0.8126 - mean_squared_error: 1.3688 - val_loss: 1.4134 - val_mean_absolute_error: 0.8294 - val_mean_squared_error: 1.4134\n",
            "Epoch 664/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.3552 - mean_absolute_error: 0.8096 - mean_squared_error: 1.3552\n",
            "Epoch 664: val_loss improved from 1.41251 to 1.41235, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3652 - mean_absolute_error: 0.8114 - mean_squared_error: 1.3652 - val_loss: 1.4123 - val_mean_absolute_error: 0.8291 - val_mean_squared_error: 1.4123\n",
            "Epoch 665/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.3695 - mean_absolute_error: 0.8144 - mean_squared_error: 1.3695\n",
            "Epoch 665: val_loss improved from 1.41235 to 1.41092, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3659 - mean_absolute_error: 0.8127 - mean_squared_error: 1.3659 - val_loss: 1.4109 - val_mean_absolute_error: 0.8287 - val_mean_squared_error: 1.4109\n",
            "Epoch 666/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.3853 - mean_absolute_error: 0.8194 - mean_squared_error: 1.3853\n",
            "Epoch 666: val_loss improved from 1.41092 to 1.40988, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3616 - mean_absolute_error: 0.8120 - mean_squared_error: 1.3616 - val_loss: 1.4099 - val_mean_absolute_error: 0.8240 - val_mean_squared_error: 1.4099\n",
            "Epoch 667/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.3717 - mean_absolute_error: 0.8132 - mean_squared_error: 1.3717\n",
            "Epoch 667: val_loss improved from 1.40988 to 1.40840, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3629 - mean_absolute_error: 0.8107 - mean_squared_error: 1.3629 - val_loss: 1.4084 - val_mean_absolute_error: 0.8248 - val_mean_squared_error: 1.4084\n",
            "Epoch 668/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.3282 - mean_absolute_error: 0.8034 - mean_squared_error: 1.3282\n",
            "Epoch 668: val_loss improved from 1.40840 to 1.40776, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3606 - mean_absolute_error: 0.8111 - mean_squared_error: 1.3606 - val_loss: 1.4078 - val_mean_absolute_error: 0.8286 - val_mean_squared_error: 1.4078\n",
            "Epoch 669/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.3629 - mean_absolute_error: 0.8128 - mean_squared_error: 1.3629\n",
            "Epoch 669: val_loss did not improve from 1.40776\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3610 - mean_absolute_error: 0.8115 - mean_squared_error: 1.3610 - val_loss: 1.4082 - val_mean_absolute_error: 0.8296 - val_mean_squared_error: 1.4082\n",
            "Epoch 670/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.3606 - mean_absolute_error: 0.8138 - mean_squared_error: 1.3606\n",
            "Epoch 670: val_loss improved from 1.40776 to 1.40468, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3581 - mean_absolute_error: 0.8108 - mean_squared_error: 1.3581 - val_loss: 1.4047 - val_mean_absolute_error: 0.8243 - val_mean_squared_error: 1.4047\n",
            "Epoch 671/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.3508 - mean_absolute_error: 0.8086 - mean_squared_error: 1.3508\n",
            "Epoch 671: val_loss improved from 1.40468 to 1.40363, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3555 - mean_absolute_error: 0.8100 - mean_squared_error: 1.3555 - val_loss: 1.4036 - val_mean_absolute_error: 0.8265 - val_mean_squared_error: 1.4036\n",
            "Epoch 672/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.3554 - mean_absolute_error: 0.8104 - mean_squared_error: 1.3554\n",
            "Epoch 672: val_loss improved from 1.40363 to 1.40225, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3557 - mean_absolute_error: 0.8102 - mean_squared_error: 1.3557 - val_loss: 1.4023 - val_mean_absolute_error: 0.8259 - val_mean_squared_error: 1.4023\n",
            "Epoch 673/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.3587 - mean_absolute_error: 0.8118 - mean_squared_error: 1.3587\n",
            "Epoch 673: val_loss improved from 1.40225 to 1.39988, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3544 - mean_absolute_error: 0.8101 - mean_squared_error: 1.3544 - val_loss: 1.3999 - val_mean_absolute_error: 0.8241 - val_mean_squared_error: 1.3999\n",
            "Epoch 674/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.3597 - mean_absolute_error: 0.8114 - mean_squared_error: 1.3597\n",
            "Epoch 674: val_loss did not improve from 1.39988\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3537 - mean_absolute_error: 0.8100 - mean_squared_error: 1.3537 - val_loss: 1.4027 - val_mean_absolute_error: 0.8286 - val_mean_squared_error: 1.4027\n",
            "Epoch 675/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.3599 - mean_absolute_error: 0.8118 - mean_squared_error: 1.3599\n",
            "Epoch 675: val_loss improved from 1.39988 to 1.39839, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3513 - mean_absolute_error: 0.8100 - mean_squared_error: 1.3513 - val_loss: 1.3984 - val_mean_absolute_error: 0.8245 - val_mean_squared_error: 1.3984\n",
            "Epoch 676/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.3489 - mean_absolute_error: 0.8076 - mean_squared_error: 1.3489\n",
            "Epoch 676: val_loss improved from 1.39839 to 1.39633, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3499 - mean_absolute_error: 0.8084 - mean_squared_error: 1.3499 - val_loss: 1.3963 - val_mean_absolute_error: 0.8230 - val_mean_squared_error: 1.3963\n",
            "Epoch 677/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.3601 - mean_absolute_error: 0.8110 - mean_squared_error: 1.3601\n",
            "Epoch 677: val_loss did not improve from 1.39633\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3488 - mean_absolute_error: 0.8077 - mean_squared_error: 1.3488 - val_loss: 1.4039 - val_mean_absolute_error: 0.8313 - val_mean_squared_error: 1.4039\n",
            "Epoch 678/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.3549 - mean_absolute_error: 0.8129 - mean_squared_error: 1.3549\n",
            "Epoch 678: val_loss improved from 1.39633 to 1.39486, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3501 - mean_absolute_error: 0.8093 - mean_squared_error: 1.3501 - val_loss: 1.3949 - val_mean_absolute_error: 0.8235 - val_mean_squared_error: 1.3949\n",
            "Epoch 679/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.3466 - mean_absolute_error: 0.8085 - mean_squared_error: 1.3466\n",
            "Epoch 679: val_loss improved from 1.39486 to 1.39337, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3457 - mean_absolute_error: 0.8078 - mean_squared_error: 1.3457 - val_loss: 1.3934 - val_mean_absolute_error: 0.8225 - val_mean_squared_error: 1.3934\n",
            "Epoch 680/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.3629 - mean_absolute_error: 0.8155 - mean_squared_error: 1.3629\n",
            "Epoch 680: val_loss did not improve from 1.39337\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3465 - mean_absolute_error: 0.8089 - mean_squared_error: 1.3465 - val_loss: 1.3936 - val_mean_absolute_error: 0.8245 - val_mean_squared_error: 1.3936\n",
            "Epoch 681/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.3382 - mean_absolute_error: 0.8057 - mean_squared_error: 1.3382\n",
            "Epoch 681: val_loss did not improve from 1.39337\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3434 - mean_absolute_error: 0.8066 - mean_squared_error: 1.3434 - val_loss: 1.3943 - val_mean_absolute_error: 0.8260 - val_mean_squared_error: 1.3943\n",
            "Epoch 682/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.3421 - mean_absolute_error: 0.8095 - mean_squared_error: 1.3421\n",
            "Epoch 682: val_loss did not improve from 1.39337\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3429 - mean_absolute_error: 0.8081 - mean_squared_error: 1.3429 - val_loss: 1.3950 - val_mean_absolute_error: 0.8275 - val_mean_squared_error: 1.3950\n",
            "Epoch 683/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.3366 - mean_absolute_error: 0.8053 - mean_squared_error: 1.3366\n",
            "Epoch 683: val_loss did not improve from 1.39337\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3412 - mean_absolute_error: 0.8069 - mean_squared_error: 1.3412 - val_loss: 1.4078 - val_mean_absolute_error: 0.8378 - val_mean_squared_error: 1.4078\n",
            "Epoch 684/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.3422 - mean_absolute_error: 0.8099 - mean_squared_error: 1.3422\n",
            "Epoch 684: val_loss improved from 1.39337 to 1.38997, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3409 - mean_absolute_error: 0.8087 - mean_squared_error: 1.3409 - val_loss: 1.3900 - val_mean_absolute_error: 0.8237 - val_mean_squared_error: 1.3900\n",
            "Epoch 685/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.3430 - mean_absolute_error: 0.8084 - mean_squared_error: 1.3430\n",
            "Epoch 685: val_loss improved from 1.38997 to 1.38768, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3390 - mean_absolute_error: 0.8072 - mean_squared_error: 1.3390 - val_loss: 1.3877 - val_mean_absolute_error: 0.8223 - val_mean_squared_error: 1.3877\n",
            "Epoch 686/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.3320 - mean_absolute_error: 0.8042 - mean_squared_error: 1.3320\n",
            "Epoch 686: val_loss improved from 1.38768 to 1.38726, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3374 - mean_absolute_error: 0.8054 - mean_squared_error: 1.3374 - val_loss: 1.3873 - val_mean_absolute_error: 0.8226 - val_mean_squared_error: 1.3873\n",
            "Epoch 687/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.3410 - mean_absolute_error: 0.8087 - mean_squared_error: 1.3410\n",
            "Epoch 687: val_loss improved from 1.38726 to 1.38615, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3366 - mean_absolute_error: 0.8074 - mean_squared_error: 1.3366 - val_loss: 1.3862 - val_mean_absolute_error: 0.8228 - val_mean_squared_error: 1.3862\n",
            "Epoch 688/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.3302 - mean_absolute_error: 0.8044 - mean_squared_error: 1.3302\n",
            "Epoch 688: val_loss improved from 1.38615 to 1.38466, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3358 - mean_absolute_error: 0.8062 - mean_squared_error: 1.3358 - val_loss: 1.3847 - val_mean_absolute_error: 0.8218 - val_mean_squared_error: 1.3847\n",
            "Epoch 689/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.3312 - mean_absolute_error: 0.8073 - mean_squared_error: 1.3312\n",
            "Epoch 689: val_loss improved from 1.38466 to 1.38335, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3335 - mean_absolute_error: 0.8068 - mean_squared_error: 1.3335 - val_loss: 1.3833 - val_mean_absolute_error: 0.8213 - val_mean_squared_error: 1.3833\n",
            "Epoch 690/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.3340 - mean_absolute_error: 0.8056 - mean_squared_error: 1.3340\n",
            "Epoch 690: val_loss did not improve from 1.38335\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3323 - mean_absolute_error: 0.8050 - mean_squared_error: 1.3323 - val_loss: 1.3842 - val_mean_absolute_error: 0.8230 - val_mean_squared_error: 1.3842\n",
            "Epoch 691/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.3378 - mean_absolute_error: 0.8086 - mean_squared_error: 1.3378\n",
            "Epoch 691: val_loss improved from 1.38335 to 1.38248, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3317 - mean_absolute_error: 0.8067 - mean_squared_error: 1.3317 - val_loss: 1.3825 - val_mean_absolute_error: 0.8187 - val_mean_squared_error: 1.3825\n",
            "Epoch 692/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.3488 - mean_absolute_error: 0.8101 - mean_squared_error: 1.3488\n",
            "Epoch 692: val_loss improved from 1.38248 to 1.38016, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3311 - mean_absolute_error: 0.8049 - mean_squared_error: 1.3311 - val_loss: 1.3802 - val_mean_absolute_error: 0.8203 - val_mean_squared_error: 1.3802\n",
            "Epoch 693/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.3286 - mean_absolute_error: 0.8043 - mean_squared_error: 1.3286\n",
            "Epoch 693: val_loss did not improve from 1.38016\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3308 - mean_absolute_error: 0.8051 - mean_squared_error: 1.3308 - val_loss: 1.3806 - val_mean_absolute_error: 0.8215 - val_mean_squared_error: 1.3806\n",
            "Epoch 694/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.3285 - mean_absolute_error: 0.8047 - mean_squared_error: 1.3285\n",
            "Epoch 694: val_loss did not improve from 1.38016\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3285 - mean_absolute_error: 0.8047 - mean_squared_error: 1.3285 - val_loss: 1.3828 - val_mean_absolute_error: 0.8198 - val_mean_squared_error: 1.3828\n",
            "Epoch 695/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.3128 - mean_absolute_error: 0.8000 - mean_squared_error: 1.3128\n",
            "Epoch 695: val_loss improved from 1.38016 to 1.37884, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3297 - mean_absolute_error: 0.8056 - mean_squared_error: 1.3297 - val_loss: 1.3788 - val_mean_absolute_error: 0.8210 - val_mean_squared_error: 1.3788\n",
            "Epoch 696/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.3266 - mean_absolute_error: 0.8051 - mean_squared_error: 1.3266\n",
            "Epoch 696: val_loss improved from 1.37884 to 1.37702, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3262 - mean_absolute_error: 0.8048 - mean_squared_error: 1.3262 - val_loss: 1.3770 - val_mean_absolute_error: 0.8195 - val_mean_squared_error: 1.3770\n",
            "Epoch 697/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.3300 - mean_absolute_error: 0.8053 - mean_squared_error: 1.3300\n",
            "Epoch 697: val_loss did not improve from 1.37702\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3264 - mean_absolute_error: 0.8045 - mean_squared_error: 1.3264 - val_loss: 1.3786 - val_mean_absolute_error: 0.8197 - val_mean_squared_error: 1.3786\n",
            "Epoch 698/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.3221 - mean_absolute_error: 0.8023 - mean_squared_error: 1.3221\n",
            "Epoch 698: val_loss improved from 1.37702 to 1.37643, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3248 - mean_absolute_error: 0.8025 - mean_squared_error: 1.3248 - val_loss: 1.3764 - val_mean_absolute_error: 0.8214 - val_mean_squared_error: 1.3764\n",
            "Epoch 699/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.3093 - mean_absolute_error: 0.7983 - mean_squared_error: 1.3093\n",
            "Epoch 699: val_loss did not improve from 1.37643\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3256 - mean_absolute_error: 0.8041 - mean_squared_error: 1.3256 - val_loss: 1.3778 - val_mean_absolute_error: 0.8233 - val_mean_squared_error: 1.3778\n",
            "Epoch 700/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.3198 - mean_absolute_error: 0.8035 - mean_squared_error: 1.3198\n",
            "Epoch 700: val_loss did not improve from 1.37643\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3225 - mean_absolute_error: 0.8040 - mean_squared_error: 1.3225 - val_loss: 1.3776 - val_mean_absolute_error: 0.8237 - val_mean_squared_error: 1.3776\n",
            "Epoch 701/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.3194 - mean_absolute_error: 0.8035 - mean_squared_error: 1.3194\n",
            "Epoch 701: val_loss improved from 1.37643 to 1.37234, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3212 - mean_absolute_error: 0.8032 - mean_squared_error: 1.3212 - val_loss: 1.3723 - val_mean_absolute_error: 0.8186 - val_mean_squared_error: 1.3723\n",
            "Epoch 702/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.3250 - mean_absolute_error: 0.8045 - mean_squared_error: 1.3250\n",
            "Epoch 702: val_loss did not improve from 1.37234\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3195 - mean_absolute_error: 0.8026 - mean_squared_error: 1.3195 - val_loss: 1.3746 - val_mean_absolute_error: 0.8223 - val_mean_squared_error: 1.3746\n",
            "Epoch 703/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.3198 - mean_absolute_error: 0.8029 - mean_squared_error: 1.3198\n",
            "Epoch 703: val_loss did not improve from 1.37234\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3196 - mean_absolute_error: 0.8028 - mean_squared_error: 1.3196 - val_loss: 1.3805 - val_mean_absolute_error: 0.8272 - val_mean_squared_error: 1.3805\n",
            "Epoch 704/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.3183 - mean_absolute_error: 0.8039 - mean_squared_error: 1.3183\n",
            "Epoch 704: val_loss improved from 1.37234 to 1.37020, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3182 - mean_absolute_error: 0.8037 - mean_squared_error: 1.3182 - val_loss: 1.3702 - val_mean_absolute_error: 0.8179 - val_mean_squared_error: 1.3702\n",
            "Epoch 705/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.3221 - mean_absolute_error: 0.8052 - mean_squared_error: 1.3221\n",
            "Epoch 705: val_loss improved from 1.37020 to 1.36950, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3179 - mean_absolute_error: 0.8022 - mean_squared_error: 1.3179 - val_loss: 1.3695 - val_mean_absolute_error: 0.8192 - val_mean_squared_error: 1.3695\n",
            "Epoch 706/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.3140 - mean_absolute_error: 0.8004 - mean_squared_error: 1.3140\n",
            "Epoch 706: val_loss improved from 1.36950 to 1.36911, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3158 - mean_absolute_error: 0.8024 - mean_squared_error: 1.3158 - val_loss: 1.3691 - val_mean_absolute_error: 0.8192 - val_mean_squared_error: 1.3691\n",
            "Epoch 707/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.3013 - mean_absolute_error: 0.7972 - mean_squared_error: 1.3013\n",
            "Epoch 707: val_loss did not improve from 1.36911\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3148 - mean_absolute_error: 0.8008 - mean_squared_error: 1.3148 - val_loss: 1.3696 - val_mean_absolute_error: 0.8200 - val_mean_squared_error: 1.3696\n",
            "Epoch 708/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.3166 - mean_absolute_error: 0.8026 - mean_squared_error: 1.3166\n",
            "Epoch 708: val_loss did not improve from 1.36911\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3143 - mean_absolute_error: 0.8022 - mean_squared_error: 1.3143 - val_loss: 1.3697 - val_mean_absolute_error: 0.8209 - val_mean_squared_error: 1.3697\n",
            "Epoch 709/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.3112 - mean_absolute_error: 0.8012 - mean_squared_error: 1.3112\n",
            "Epoch 709: val_loss did not improve from 1.36911\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3117 - mean_absolute_error: 0.8014 - mean_squared_error: 1.3117 - val_loss: 1.3741 - val_mean_absolute_error: 0.8249 - val_mean_squared_error: 1.3741\n",
            "Epoch 710/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.2949 - mean_absolute_error: 0.7975 - mean_squared_error: 1.2949\n",
            "Epoch 710: val_loss improved from 1.36911 to 1.36494, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3129 - mean_absolute_error: 0.8024 - mean_squared_error: 1.3129 - val_loss: 1.3649 - val_mean_absolute_error: 0.8166 - val_mean_squared_error: 1.3649\n",
            "Epoch 711/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.3033 - mean_absolute_error: 0.7967 - mean_squared_error: 1.3033\n",
            "Epoch 711: val_loss did not improve from 1.36494\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3102 - mean_absolute_error: 0.8008 - mean_squared_error: 1.3102 - val_loss: 1.3651 - val_mean_absolute_error: 0.8169 - val_mean_squared_error: 1.3651\n",
            "Epoch 712/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.3197 - mean_absolute_error: 0.8037 - mean_squared_error: 1.3197\n",
            "Epoch 712: val_loss did not improve from 1.36494\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3110 - mean_absolute_error: 0.8014 - mean_squared_error: 1.3110 - val_loss: 1.3670 - val_mean_absolute_error: 0.8221 - val_mean_squared_error: 1.3670\n",
            "Epoch 713/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.3053 - mean_absolute_error: 0.7994 - mean_squared_error: 1.3053\n",
            "Epoch 713: val_loss did not improve from 1.36494\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3093 - mean_absolute_error: 0.8007 - mean_squared_error: 1.3093 - val_loss: 1.3672 - val_mean_absolute_error: 0.8218 - val_mean_squared_error: 1.3672\n",
            "Epoch 714/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.3119 - mean_absolute_error: 0.8023 - mean_squared_error: 1.3119\n",
            "Epoch 714: val_loss did not improve from 1.36494\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3069 - mean_absolute_error: 0.8003 - mean_squared_error: 1.3069 - val_loss: 1.3652 - val_mean_absolute_error: 0.8209 - val_mean_squared_error: 1.3652\n",
            "Epoch 715/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.3035 - mean_absolute_error: 0.8006 - mean_squared_error: 1.3035\n",
            "Epoch 715: val_loss improved from 1.36494 to 1.36229, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3070 - mean_absolute_error: 0.8016 - mean_squared_error: 1.3070 - val_loss: 1.3623 - val_mean_absolute_error: 0.8168 - val_mean_squared_error: 1.3623\n",
            "Epoch 716/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.2887 - mean_absolute_error: 0.7932 - mean_squared_error: 1.2887\n",
            "Epoch 716: val_loss improved from 1.36229 to 1.35924, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3059 - mean_absolute_error: 0.7993 - mean_squared_error: 1.3059 - val_loss: 1.3592 - val_mean_absolute_error: 0.8167 - val_mean_squared_error: 1.3592\n",
            "Epoch 717/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.2808 - mean_absolute_error: 0.7939 - mean_squared_error: 1.2808\n",
            "Epoch 717: val_loss improved from 1.35924 to 1.35839, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3043 - mean_absolute_error: 0.8001 - mean_squared_error: 1.3043 - val_loss: 1.3584 - val_mean_absolute_error: 0.8153 - val_mean_squared_error: 1.3584\n",
            "Epoch 718/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.3101 - mean_absolute_error: 0.8022 - mean_squared_error: 1.3101\n",
            "Epoch 718: val_loss improved from 1.35839 to 1.35832, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3052 - mean_absolute_error: 0.8009 - mean_squared_error: 1.3052 - val_loss: 1.3583 - val_mean_absolute_error: 0.8165 - val_mean_squared_error: 1.3583\n",
            "Epoch 719/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.3028 - mean_absolute_error: 0.7989 - mean_squared_error: 1.3028\n",
            "Epoch 719: val_loss did not improve from 1.35832\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3028 - mean_absolute_error: 0.7989 - mean_squared_error: 1.3028 - val_loss: 1.3605 - val_mean_absolute_error: 0.8198 - val_mean_squared_error: 1.3605\n",
            "Epoch 720/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.3072 - mean_absolute_error: 0.8016 - mean_squared_error: 1.3072\n",
            "Epoch 720: val_loss did not improve from 1.35832\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3034 - mean_absolute_error: 0.8010 - mean_squared_error: 1.3034 - val_loss: 1.3621 - val_mean_absolute_error: 0.8213 - val_mean_squared_error: 1.3621\n",
            "Epoch 721/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.3046 - mean_absolute_error: 0.7998 - mean_squared_error: 1.3046\n",
            "Epoch 721: val_loss improved from 1.35832 to 1.35776, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3016 - mean_absolute_error: 0.7988 - mean_squared_error: 1.3016 - val_loss: 1.3578 - val_mean_absolute_error: 0.8165 - val_mean_squared_error: 1.3578\n",
            "Epoch 722/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.2969 - mean_absolute_error: 0.7972 - mean_squared_error: 1.2969\n",
            "Epoch 722: val_loss improved from 1.35776 to 1.35535, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3006 - mean_absolute_error: 0.7991 - mean_squared_error: 1.3006 - val_loss: 1.3554 - val_mean_absolute_error: 0.8168 - val_mean_squared_error: 1.3554\n",
            "Epoch 723/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.2993 - mean_absolute_error: 0.8001 - mean_squared_error: 1.2993\n",
            "Epoch 723: val_loss improved from 1.35535 to 1.35409, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2993 - mean_absolute_error: 0.8001 - mean_squared_error: 1.2993 - val_loss: 1.3541 - val_mean_absolute_error: 0.8155 - val_mean_squared_error: 1.3541\n",
            "Epoch 724/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.2969 - mean_absolute_error: 0.7983 - mean_squared_error: 1.2969\n",
            "Epoch 724: val_loss improved from 1.35409 to 1.35398, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2994 - mean_absolute_error: 0.7990 - mean_squared_error: 1.2994 - val_loss: 1.3540 - val_mean_absolute_error: 0.8163 - val_mean_squared_error: 1.3540\n",
            "Epoch 725/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.2947 - mean_absolute_error: 0.7963 - mean_squared_error: 1.2947\n",
            "Epoch 725: val_loss improved from 1.35398 to 1.35282, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2979 - mean_absolute_error: 0.7974 - mean_squared_error: 1.2979 - val_loss: 1.3528 - val_mean_absolute_error: 0.8164 - val_mean_squared_error: 1.3528\n",
            "Epoch 726/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.3109 - mean_absolute_error: 0.8037 - mean_squared_error: 1.3109\n",
            "Epoch 726: val_loss improved from 1.35282 to 1.35224, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2977 - mean_absolute_error: 0.8001 - mean_squared_error: 1.2977 - val_loss: 1.3522 - val_mean_absolute_error: 0.8151 - val_mean_squared_error: 1.3522\n",
            "Epoch 727/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.2946 - mean_absolute_error: 0.7967 - mean_squared_error: 1.2946\n",
            "Epoch 727: val_loss improved from 1.35224 to 1.35159, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2954 - mean_absolute_error: 0.7976 - mean_squared_error: 1.2954 - val_loss: 1.3516 - val_mean_absolute_error: 0.8166 - val_mean_squared_error: 1.3516\n",
            "Epoch 728/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.2950 - mean_absolute_error: 0.7984 - mean_squared_error: 1.2950\n",
            "Epoch 728: val_loss improved from 1.35159 to 1.35088, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2942 - mean_absolute_error: 0.7983 - mean_squared_error: 1.2942 - val_loss: 1.3509 - val_mean_absolute_error: 0.8159 - val_mean_squared_error: 1.3509\n",
            "Epoch 729/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.2918 - mean_absolute_error: 0.7993 - mean_squared_error: 1.2918\n",
            "Epoch 729: val_loss improved from 1.35088 to 1.34980, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2936 - mean_absolute_error: 0.7996 - mean_squared_error: 1.2936 - val_loss: 1.3498 - val_mean_absolute_error: 0.8145 - val_mean_squared_error: 1.3498\n",
            "Epoch 730/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.2851 - mean_absolute_error: 0.7949 - mean_squared_error: 1.2851\n",
            "Epoch 730: val_loss did not improve from 1.34980\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2954 - mean_absolute_error: 0.7984 - mean_squared_error: 1.2954 - val_loss: 1.3528 - val_mean_absolute_error: 0.8190 - val_mean_squared_error: 1.3528\n",
            "Epoch 731/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.2928 - mean_absolute_error: 0.7985 - mean_squared_error: 1.2928\n",
            "Epoch 731: val_loss improved from 1.34980 to 1.34915, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2918 - mean_absolute_error: 0.7971 - mean_squared_error: 1.2918 - val_loss: 1.3492 - val_mean_absolute_error: 0.8165 - val_mean_squared_error: 1.3492\n",
            "Epoch 732/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.3018 - mean_absolute_error: 0.8014 - mean_squared_error: 1.3018\n",
            "Epoch 732: val_loss improved from 1.34915 to 1.34841, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2918 - mean_absolute_error: 0.7983 - mean_squared_error: 1.2918 - val_loss: 1.3484 - val_mean_absolute_error: 0.8165 - val_mean_squared_error: 1.3484\n",
            "Epoch 733/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.2900 - mean_absolute_error: 0.7974 - mean_squared_error: 1.2900\n",
            "Epoch 733: val_loss improved from 1.34841 to 1.34694, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2898 - mean_absolute_error: 0.7971 - mean_squared_error: 1.2898 - val_loss: 1.3469 - val_mean_absolute_error: 0.8146 - val_mean_squared_error: 1.3469\n",
            "Epoch 734/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.2876 - mean_absolute_error: 0.7961 - mean_squared_error: 1.2876\n",
            "Epoch 734: val_loss did not improve from 1.34694\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2888 - mean_absolute_error: 0.7967 - mean_squared_error: 1.2888 - val_loss: 1.3550 - val_mean_absolute_error: 0.8212 - val_mean_squared_error: 1.3550\n",
            "Epoch 735/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.2924 - mean_absolute_error: 0.7980 - mean_squared_error: 1.2924\n",
            "Epoch 735: val_loss improved from 1.34694 to 1.34595, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2884 - mean_absolute_error: 0.7968 - mean_squared_error: 1.2884 - val_loss: 1.3459 - val_mean_absolute_error: 0.8156 - val_mean_squared_error: 1.3459\n",
            "Epoch 736/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.2812 - mean_absolute_error: 0.7958 - mean_squared_error: 1.2812\n",
            "Epoch 736: val_loss improved from 1.34595 to 1.34548, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2874 - mean_absolute_error: 0.7981 - mean_squared_error: 1.2874 - val_loss: 1.3455 - val_mean_absolute_error: 0.8162 - val_mean_squared_error: 1.3455\n",
            "Epoch 737/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.2750 - mean_absolute_error: 0.7938 - mean_squared_error: 1.2750\n",
            "Epoch 737: val_loss improved from 1.34548 to 1.34502, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2865 - mean_absolute_error: 0.7959 - mean_squared_error: 1.2865 - val_loss: 1.3450 - val_mean_absolute_error: 0.8147 - val_mean_squared_error: 1.3450\n",
            "Epoch 738/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.2846 - mean_absolute_error: 0.7962 - mean_squared_error: 1.2846\n",
            "Epoch 738: val_loss improved from 1.34502 to 1.34363, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2859 - mean_absolute_error: 0.7969 - mean_squared_error: 1.2859 - val_loss: 1.3436 - val_mean_absolute_error: 0.8153 - val_mean_squared_error: 1.3436\n",
            "Epoch 739/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.2779 - mean_absolute_error: 0.7955 - mean_squared_error: 1.2779\n",
            "Epoch 739: val_loss did not improve from 1.34363\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2843 - mean_absolute_error: 0.7964 - mean_squared_error: 1.2843 - val_loss: 1.3487 - val_mean_absolute_error: 0.8199 - val_mean_squared_error: 1.3487\n",
            "Epoch 740/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.2635 - mean_absolute_error: 0.7902 - mean_squared_error: 1.2635\n",
            "Epoch 740: val_loss did not improve from 1.34363\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2854 - mean_absolute_error: 0.7965 - mean_squared_error: 1.2854 - val_loss: 1.3443 - val_mean_absolute_error: 0.8174 - val_mean_squared_error: 1.3443\n",
            "Epoch 741/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.2868 - mean_absolute_error: 0.7981 - mean_squared_error: 1.2868\n",
            "Epoch 741: val_loss improved from 1.34363 to 1.34025, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2844 - mean_absolute_error: 0.7972 - mean_squared_error: 1.2844 - val_loss: 1.3402 - val_mean_absolute_error: 0.8138 - val_mean_squared_error: 1.3402\n",
            "Epoch 742/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.2845 - mean_absolute_error: 0.7967 - mean_squared_error: 1.2845\n",
            "Epoch 742: val_loss did not improve from 1.34025\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2855 - mean_absolute_error: 0.7967 - mean_squared_error: 1.2855 - val_loss: 1.3403 - val_mean_absolute_error: 0.8149 - val_mean_squared_error: 1.3403\n",
            "Epoch 743/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.2773 - mean_absolute_error: 0.7934 - mean_squared_error: 1.2773\n",
            "Epoch 743: val_loss did not improve from 1.34025\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2819 - mean_absolute_error: 0.7946 - mean_squared_error: 1.2819 - val_loss: 1.3437 - val_mean_absolute_error: 0.8181 - val_mean_squared_error: 1.3437\n",
            "Epoch 744/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.2630 - mean_absolute_error: 0.7901 - mean_squared_error: 1.2630\n",
            "Epoch 744: val_loss improved from 1.34025 to 1.33889, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2814 - mean_absolute_error: 0.7955 - mean_squared_error: 1.2814 - val_loss: 1.3389 - val_mean_absolute_error: 0.8147 - val_mean_squared_error: 1.3389\n",
            "Epoch 745/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.2887 - mean_absolute_error: 0.7978 - mean_squared_error: 1.2887\n",
            "Epoch 745: val_loss improved from 1.33889 to 1.33850, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2819 - mean_absolute_error: 0.7960 - mean_squared_error: 1.2819 - val_loss: 1.3385 - val_mean_absolute_error: 0.8157 - val_mean_squared_error: 1.3385\n",
            "Epoch 746/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.2826 - mean_absolute_error: 0.7970 - mean_squared_error: 1.2826\n",
            "Epoch 746: val_loss improved from 1.33850 to 1.33744, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2792 - mean_absolute_error: 0.7960 - mean_squared_error: 1.2792 - val_loss: 1.3374 - val_mean_absolute_error: 0.8147 - val_mean_squared_error: 1.3374\n",
            "Epoch 747/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.2840 - mean_absolute_error: 0.7989 - mean_squared_error: 1.2840\n",
            "Epoch 747: val_loss did not improve from 1.33744\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2783 - mean_absolute_error: 0.7955 - mean_squared_error: 1.2783 - val_loss: 1.3411 - val_mean_absolute_error: 0.8183 - val_mean_squared_error: 1.3411\n",
            "Epoch 748/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.2682 - mean_absolute_error: 0.7935 - mean_squared_error: 1.2682\n",
            "Epoch 748: val_loss improved from 1.33744 to 1.33719, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2774 - mean_absolute_error: 0.7955 - mean_squared_error: 1.2774 - val_loss: 1.3372 - val_mean_absolute_error: 0.8161 - val_mean_squared_error: 1.3372\n",
            "Epoch 749/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.2639 - mean_absolute_error: 0.7920 - mean_squared_error: 1.2639\n",
            "Epoch 749: val_loss improved from 1.33719 to 1.33511, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2775 - mean_absolute_error: 0.7954 - mean_squared_error: 1.2775 - val_loss: 1.3351 - val_mean_absolute_error: 0.8143 - val_mean_squared_error: 1.3351\n",
            "Epoch 750/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.2749 - mean_absolute_error: 0.7946 - mean_squared_error: 1.2749\n",
            "Epoch 750: val_loss did not improve from 1.33511\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2763 - mean_absolute_error: 0.7950 - mean_squared_error: 1.2763 - val_loss: 1.3420 - val_mean_absolute_error: 0.8194 - val_mean_squared_error: 1.3420\n",
            "Epoch 751/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.2842 - mean_absolute_error: 0.7965 - mean_squared_error: 1.2842\n",
            "Epoch 751: val_loss did not improve from 1.33511\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2745 - mean_absolute_error: 0.7938 - mean_squared_error: 1.2745 - val_loss: 1.3370 - val_mean_absolute_error: 0.8154 - val_mean_squared_error: 1.3370\n",
            "Epoch 752/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.2836 - mean_absolute_error: 0.7960 - mean_squared_error: 1.2836\n",
            "Epoch 752: val_loss did not improve from 1.33511\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2736 - mean_absolute_error: 0.7949 - mean_squared_error: 1.2736 - val_loss: 1.3359 - val_mean_absolute_error: 0.8160 - val_mean_squared_error: 1.3359\n",
            "Epoch 753/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.2757 - mean_absolute_error: 0.7960 - mean_squared_error: 1.2757\n",
            "Epoch 753: val_loss improved from 1.33511 to 1.33292, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2757 - mean_absolute_error: 0.7960 - mean_squared_error: 1.2757 - val_loss: 1.3329 - val_mean_absolute_error: 0.8140 - val_mean_squared_error: 1.3329\n",
            "Epoch 754/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.2728 - mean_absolute_error: 0.7954 - mean_squared_error: 1.2728\n",
            "Epoch 754: val_loss did not improve from 1.33292\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2728 - mean_absolute_error: 0.7954 - mean_squared_error: 1.2728 - val_loss: 1.3332 - val_mean_absolute_error: 0.8137 - val_mean_squared_error: 1.3332\n",
            "Epoch 755/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.2814 - mean_absolute_error: 0.7966 - mean_squared_error: 1.2814\n",
            "Epoch 755: val_loss did not improve from 1.33292\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2722 - mean_absolute_error: 0.7931 - mean_squared_error: 1.2722 - val_loss: 1.3346 - val_mean_absolute_error: 0.8162 - val_mean_squared_error: 1.3346\n",
            "Epoch 756/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.2760 - mean_absolute_error: 0.7967 - mean_squared_error: 1.2760\n",
            "Epoch 756: val_loss did not improve from 1.33292\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2697 - mean_absolute_error: 0.7943 - mean_squared_error: 1.2697 - val_loss: 1.3335 - val_mean_absolute_error: 0.8160 - val_mean_squared_error: 1.3335\n",
            "Epoch 757/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.2685 - mean_absolute_error: 0.7935 - mean_squared_error: 1.2685\n",
            "Epoch 757: val_loss improved from 1.33292 to 1.33144, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2703 - mean_absolute_error: 0.7937 - mean_squared_error: 1.2703 - val_loss: 1.3314 - val_mean_absolute_error: 0.8150 - val_mean_squared_error: 1.3314\n",
            "Epoch 758/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.2777 - mean_absolute_error: 0.7958 - mean_squared_error: 1.2777\n",
            "Epoch 758: val_loss did not improve from 1.33144\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2688 - mean_absolute_error: 0.7937 - mean_squared_error: 1.2688 - val_loss: 1.3322 - val_mean_absolute_error: 0.8162 - val_mean_squared_error: 1.3322\n",
            "Epoch 759/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.2600 - mean_absolute_error: 0.7916 - mean_squared_error: 1.2600\n",
            "Epoch 759: val_loss improved from 1.33144 to 1.32915, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2693 - mean_absolute_error: 0.7947 - mean_squared_error: 1.2693 - val_loss: 1.3291 - val_mean_absolute_error: 0.8136 - val_mean_squared_error: 1.3291\n",
            "Epoch 760/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.2575 - mean_absolute_error: 0.7915 - mean_squared_error: 1.2575\n",
            "Epoch 760: val_loss improved from 1.32915 to 1.32799, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2690 - mean_absolute_error: 0.7941 - mean_squared_error: 1.2690 - val_loss: 1.3280 - val_mean_absolute_error: 0.8137 - val_mean_squared_error: 1.3280\n",
            "Epoch 761/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.2510 - mean_absolute_error: 0.7884 - mean_squared_error: 1.2510\n",
            "Epoch 761: val_loss did not improve from 1.32799\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2663 - mean_absolute_error: 0.7937 - mean_squared_error: 1.2663 - val_loss: 1.3298 - val_mean_absolute_error: 0.8157 - val_mean_squared_error: 1.3298\n",
            "Epoch 762/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.2556 - mean_absolute_error: 0.7908 - mean_squared_error: 1.2556\n",
            "Epoch 762: val_loss did not improve from 1.32799\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2673 - mean_absolute_error: 0.7932 - mean_squared_error: 1.2673 - val_loss: 1.3289 - val_mean_absolute_error: 0.8144 - val_mean_squared_error: 1.3289\n",
            "Epoch 763/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.2603 - mean_absolute_error: 0.7938 - mean_squared_error: 1.2603\n",
            "Epoch 763: val_loss improved from 1.32799 to 1.32665, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2663 - mean_absolute_error: 0.7939 - mean_squared_error: 1.2663 - val_loss: 1.3266 - val_mean_absolute_error: 0.8149 - val_mean_squared_error: 1.3266\n",
            "Epoch 764/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.2449 - mean_absolute_error: 0.7874 - mean_squared_error: 1.2449\n",
            "Epoch 764: val_loss did not improve from 1.32665\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2649 - mean_absolute_error: 0.7932 - mean_squared_error: 1.2649 - val_loss: 1.3273 - val_mean_absolute_error: 0.8159 - val_mean_squared_error: 1.3273\n",
            "Epoch 765/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.2661 - mean_absolute_error: 0.7942 - mean_squared_error: 1.2661\n",
            "Epoch 765: val_loss improved from 1.32665 to 1.32625, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2639 - mean_absolute_error: 0.7933 - mean_squared_error: 1.2639 - val_loss: 1.3262 - val_mean_absolute_error: 0.8153 - val_mean_squared_error: 1.3262\n",
            "Epoch 766/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.2807 - mean_absolute_error: 0.7975 - mean_squared_error: 1.2807\n",
            "Epoch 766: val_loss did not improve from 1.32625\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2656 - mean_absolute_error: 0.7935 - mean_squared_error: 1.2656 - val_loss: 1.3274 - val_mean_absolute_error: 0.8171 - val_mean_squared_error: 1.3274\n",
            "Epoch 767/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.2691 - mean_absolute_error: 0.7962 - mean_squared_error: 1.2691\n",
            "Epoch 767: val_loss improved from 1.32625 to 1.32378, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2616 - mean_absolute_error: 0.7941 - mean_squared_error: 1.2616 - val_loss: 1.3238 - val_mean_absolute_error: 0.8139 - val_mean_squared_error: 1.3238\n",
            "Epoch 768/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.2539 - mean_absolute_error: 0.7894 - mean_squared_error: 1.2539\n",
            "Epoch 768: val_loss did not improve from 1.32378\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2618 - mean_absolute_error: 0.7934 - mean_squared_error: 1.2618 - val_loss: 1.3460 - val_mean_absolute_error: 0.8273 - val_mean_squared_error: 1.3460\n",
            "Epoch 769/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.2562 - mean_absolute_error: 0.7933 - mean_squared_error: 1.2562\n",
            "Epoch 769: val_loss did not improve from 1.32378\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2612 - mean_absolute_error: 0.7936 - mean_squared_error: 1.2612 - val_loss: 1.3369 - val_mean_absolute_error: 0.8226 - val_mean_squared_error: 1.3369\n",
            "Epoch 770/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.2539 - mean_absolute_error: 0.7924 - mean_squared_error: 1.2539\n",
            "Epoch 770: val_loss improved from 1.32378 to 1.32261, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2600 - mean_absolute_error: 0.7949 - mean_squared_error: 1.2600 - val_loss: 1.3226 - val_mean_absolute_error: 0.8142 - val_mean_squared_error: 1.3226\n",
            "Epoch 771/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.2601 - mean_absolute_error: 0.7929 - mean_squared_error: 1.2601\n",
            "Epoch 771: val_loss improved from 1.32261 to 1.32124, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2616 - mean_absolute_error: 0.7934 - mean_squared_error: 1.2616 - val_loss: 1.3212 - val_mean_absolute_error: 0.8145 - val_mean_squared_error: 1.3212\n",
            "Epoch 772/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.2608 - mean_absolute_error: 0.7946 - mean_squared_error: 1.2608\n",
            "Epoch 772: val_loss did not improve from 1.32124\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2571 - mean_absolute_error: 0.7932 - mean_squared_error: 1.2571 - val_loss: 1.3219 - val_mean_absolute_error: 0.8148 - val_mean_squared_error: 1.3219\n",
            "Epoch 773/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.2609 - mean_absolute_error: 0.7938 - mean_squared_error: 1.2609\n",
            "Epoch 773: val_loss did not improve from 1.32124\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2591 - mean_absolute_error: 0.7933 - mean_squared_error: 1.2591 - val_loss: 1.3229 - val_mean_absolute_error: 0.8160 - val_mean_squared_error: 1.3229\n",
            "Epoch 774/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.2561 - mean_absolute_error: 0.7922 - mean_squared_error: 1.2561\n",
            "Epoch 774: val_loss improved from 1.32124 to 1.32092, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2572 - mean_absolute_error: 0.7930 - mean_squared_error: 1.2572 - val_loss: 1.3209 - val_mean_absolute_error: 0.8160 - val_mean_squared_error: 1.3209\n",
            "Epoch 775/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.2578 - mean_absolute_error: 0.7933 - mean_squared_error: 1.2578\n",
            "Epoch 775: val_loss improved from 1.32092 to 1.31978, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2573 - mean_absolute_error: 0.7933 - mean_squared_error: 1.2573 - val_loss: 1.3198 - val_mean_absolute_error: 0.8154 - val_mean_squared_error: 1.3198\n",
            "Epoch 776/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.2660 - mean_absolute_error: 0.7936 - mean_squared_error: 1.2660\n",
            "Epoch 776: val_loss did not improve from 1.31978\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2546 - mean_absolute_error: 0.7926 - mean_squared_error: 1.2546 - val_loss: 1.3216 - val_mean_absolute_error: 0.8158 - val_mean_squared_error: 1.3216\n",
            "Epoch 777/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.2467 - mean_absolute_error: 0.7902 - mean_squared_error: 1.2467\n",
            "Epoch 777: val_loss did not improve from 1.31978\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2569 - mean_absolute_error: 0.7928 - mean_squared_error: 1.2569 - val_loss: 1.3202 - val_mean_absolute_error: 0.8159 - val_mean_squared_error: 1.3202\n",
            "Epoch 778/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.2590 - mean_absolute_error: 0.7918 - mean_squared_error: 1.2590\n",
            "Epoch 778: val_loss did not improve from 1.31978\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2558 - mean_absolute_error: 0.7916 - mean_squared_error: 1.2558 - val_loss: 1.3211 - val_mean_absolute_error: 0.8173 - val_mean_squared_error: 1.3211\n",
            "Epoch 779/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.2494 - mean_absolute_error: 0.7932 - mean_squared_error: 1.2494\n",
            "Epoch 779: val_loss improved from 1.31978 to 1.31670, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2537 - mean_absolute_error: 0.7946 - mean_squared_error: 1.2537 - val_loss: 1.3167 - val_mean_absolute_error: 0.8142 - val_mean_squared_error: 1.3167\n",
            "Epoch 780/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.2443 - mean_absolute_error: 0.7893 - mean_squared_error: 1.2443\n",
            "Epoch 780: val_loss improved from 1.31670 to 1.31556, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2523 - mean_absolute_error: 0.7920 - mean_squared_error: 1.2523 - val_loss: 1.3156 - val_mean_absolute_error: 0.8144 - val_mean_squared_error: 1.3156\n",
            "Epoch 781/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.2549 - mean_absolute_error: 0.7947 - mean_squared_error: 1.2549\n",
            "Epoch 781: val_loss did not improve from 1.31556\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2530 - mean_absolute_error: 0.7937 - mean_squared_error: 1.2530 - val_loss: 1.3168 - val_mean_absolute_error: 0.8157 - val_mean_squared_error: 1.3168\n",
            "Epoch 782/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.2540 - mean_absolute_error: 0.7923 - mean_squared_error: 1.2540\n",
            "Epoch 782: val_loss did not improve from 1.31556\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2517 - mean_absolute_error: 0.7917 - mean_squared_error: 1.2517 - val_loss: 1.3206 - val_mean_absolute_error: 0.8180 - val_mean_squared_error: 1.3206\n",
            "Epoch 783/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.2552 - mean_absolute_error: 0.7945 - mean_squared_error: 1.2552\n",
            "Epoch 783: val_loss improved from 1.31556 to 1.31402, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2513 - mean_absolute_error: 0.7940 - mean_squared_error: 1.2513 - val_loss: 1.3140 - val_mean_absolute_error: 0.8129 - val_mean_squared_error: 1.3140\n",
            "Epoch 784/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.2482 - mean_absolute_error: 0.7922 - mean_squared_error: 1.2482\n",
            "Epoch 784: val_loss improved from 1.31402 to 1.31309, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2498 - mean_absolute_error: 0.7920 - mean_squared_error: 1.2498 - val_loss: 1.3131 - val_mean_absolute_error: 0.8132 - val_mean_squared_error: 1.3131\n",
            "Epoch 785/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.2478 - mean_absolute_error: 0.7915 - mean_squared_error: 1.2478\n",
            "Epoch 785: val_loss did not improve from 1.31309\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2493 - mean_absolute_error: 0.7915 - mean_squared_error: 1.2493 - val_loss: 1.3200 - val_mean_absolute_error: 0.8178 - val_mean_squared_error: 1.3200\n",
            "Epoch 786/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.2504 - mean_absolute_error: 0.7932 - mean_squared_error: 1.2504\n",
            "Epoch 786: val_loss improved from 1.31309 to 1.31225, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2489 - mean_absolute_error: 0.7930 - mean_squared_error: 1.2489 - val_loss: 1.3123 - val_mean_absolute_error: 0.8141 - val_mean_squared_error: 1.3123\n",
            "Epoch 787/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.2535 - mean_absolute_error: 0.7937 - mean_squared_error: 1.2535\n",
            "Epoch 787: val_loss did not improve from 1.31225\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2481 - mean_absolute_error: 0.7919 - mean_squared_error: 1.2481 - val_loss: 1.3268 - val_mean_absolute_error: 0.8240 - val_mean_squared_error: 1.3268\n",
            "Epoch 788/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.2464 - mean_absolute_error: 0.7948 - mean_squared_error: 1.2464\n",
            "Epoch 788: val_loss improved from 1.31225 to 1.31051, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2468 - mean_absolute_error: 0.7937 - mean_squared_error: 1.2468 - val_loss: 1.3105 - val_mean_absolute_error: 0.8136 - val_mean_squared_error: 1.3105\n",
            "Epoch 789/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.2448 - mean_absolute_error: 0.7905 - mean_squared_error: 1.2448\n",
            "Epoch 789: val_loss did not improve from 1.31051\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2464 - mean_absolute_error: 0.7913 - mean_squared_error: 1.2464 - val_loss: 1.3112 - val_mean_absolute_error: 0.8142 - val_mean_squared_error: 1.3112\n",
            "Epoch 790/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.2363 - mean_absolute_error: 0.7891 - mean_squared_error: 1.2363\n",
            "Epoch 790: val_loss did not improve from 1.31051\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2466 - mean_absolute_error: 0.7928 - mean_squared_error: 1.2466 - val_loss: 1.3108 - val_mean_absolute_error: 0.8145 - val_mean_squared_error: 1.3108\n",
            "Epoch 791/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.2265 - mean_absolute_error: 0.7868 - mean_squared_error: 1.2265\n",
            "Epoch 791: val_loss did not improve from 1.31051\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2435 - mean_absolute_error: 0.7920 - mean_squared_error: 1.2435 - val_loss: 1.3129 - val_mean_absolute_error: 0.8146 - val_mean_squared_error: 1.3129\n",
            "Epoch 792/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.2435 - mean_absolute_error: 0.7920 - mean_squared_error: 1.2435\n",
            "Epoch 792: val_loss did not improve from 1.31051\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2435 - mean_absolute_error: 0.7918 - mean_squared_error: 1.2435 - val_loss: 1.3147 - val_mean_absolute_error: 0.8157 - val_mean_squared_error: 1.3147\n",
            "Epoch 793/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.2442 - mean_absolute_error: 0.7916 - mean_squared_error: 1.2442\n",
            "Epoch 793: val_loss improved from 1.31051 to 1.30786, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2456 - mean_absolute_error: 0.7919 - mean_squared_error: 1.2456 - val_loss: 1.3079 - val_mean_absolute_error: 0.8143 - val_mean_squared_error: 1.3079\n",
            "Epoch 794/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.2529 - mean_absolute_error: 0.7963 - mean_squared_error: 1.2529\n",
            "Epoch 794: val_loss improved from 1.30786 to 1.30646, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2422 - mean_absolute_error: 0.7920 - mean_squared_error: 1.2422 - val_loss: 1.3065 - val_mean_absolute_error: 0.8135 - val_mean_squared_error: 1.3065\n",
            "Epoch 795/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.2382 - mean_absolute_error: 0.7906 - mean_squared_error: 1.2382\n",
            "Epoch 795: val_loss improved from 1.30646 to 1.30618, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2411 - mean_absolute_error: 0.7916 - mean_squared_error: 1.2411 - val_loss: 1.3062 - val_mean_absolute_error: 0.8129 - val_mean_squared_error: 1.3062\n",
            "Epoch 796/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.2477 - mean_absolute_error: 0.7926 - mean_squared_error: 1.2477\n",
            "Epoch 796: val_loss did not improve from 1.30618\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2411 - mean_absolute_error: 0.7914 - mean_squared_error: 1.2411 - val_loss: 1.3106 - val_mean_absolute_error: 0.8161 - val_mean_squared_error: 1.3106\n",
            "Epoch 797/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.2542 - mean_absolute_error: 0.7952 - mean_squared_error: 1.2542\n",
            "Epoch 797: val_loss did not improve from 1.30618\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2411 - mean_absolute_error: 0.7910 - mean_squared_error: 1.2411 - val_loss: 1.3065 - val_mean_absolute_error: 0.8145 - val_mean_squared_error: 1.3065\n",
            "Epoch 798/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.2411 - mean_absolute_error: 0.7923 - mean_squared_error: 1.2411\n",
            "Epoch 798: val_loss improved from 1.30618 to 1.30440, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2409 - mean_absolute_error: 0.7907 - mean_squared_error: 1.2409 - val_loss: 1.3044 - val_mean_absolute_error: 0.8142 - val_mean_squared_error: 1.3044\n",
            "Epoch 799/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.2489 - mean_absolute_error: 0.7941 - mean_squared_error: 1.2489\n",
            "Epoch 799: val_loss did not improve from 1.30440\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2402 - mean_absolute_error: 0.7925 - mean_squared_error: 1.2402 - val_loss: 1.3061 - val_mean_absolute_error: 0.8161 - val_mean_squared_error: 1.3061\n",
            "Epoch 800/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.2317 - mean_absolute_error: 0.7862 - mean_squared_error: 1.2317\n",
            "Epoch 800: val_loss did not improve from 1.30440\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2386 - mean_absolute_error: 0.7902 - mean_squared_error: 1.2386 - val_loss: 1.3141 - val_mean_absolute_error: 0.8204 - val_mean_squared_error: 1.3141\n",
            "Epoch 801/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.2318 - mean_absolute_error: 0.7883 - mean_squared_error: 1.2318\n",
            "Epoch 801: val_loss did not improve from 1.30440\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2379 - mean_absolute_error: 0.7912 - mean_squared_error: 1.2379 - val_loss: 1.3051 - val_mean_absolute_error: 0.8155 - val_mean_squared_error: 1.3051\n",
            "Epoch 802/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.2410 - mean_absolute_error: 0.7925 - mean_squared_error: 1.2410\n",
            "Epoch 802: val_loss did not improve from 1.30440\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2364 - mean_absolute_error: 0.7928 - mean_squared_error: 1.2364 - val_loss: 1.3097 - val_mean_absolute_error: 0.8190 - val_mean_squared_error: 1.3097\n",
            "Epoch 803/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.2474 - mean_absolute_error: 0.7949 - mean_squared_error: 1.2474\n",
            "Epoch 803: val_loss improved from 1.30440 to 1.30330, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2357 - mean_absolute_error: 0.7920 - mean_squared_error: 1.2357 - val_loss: 1.3033 - val_mean_absolute_error: 0.8149 - val_mean_squared_error: 1.3033\n",
            "Epoch 804/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.2317 - mean_absolute_error: 0.7902 - mean_squared_error: 1.2317\n",
            "Epoch 804: val_loss improved from 1.30330 to 1.30071, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2344 - mean_absolute_error: 0.7911 - mean_squared_error: 1.2344 - val_loss: 1.3007 - val_mean_absolute_error: 0.8132 - val_mean_squared_error: 1.3007\n",
            "Epoch 805/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.2236 - mean_absolute_error: 0.7861 - mean_squared_error: 1.2236\n",
            "Epoch 805: val_loss did not improve from 1.30071\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2334 - mean_absolute_error: 0.7894 - mean_squared_error: 1.2334 - val_loss: 1.3078 - val_mean_absolute_error: 0.8186 - val_mean_squared_error: 1.3078\n",
            "Epoch 806/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.2289 - mean_absolute_error: 0.7894 - mean_squared_error: 1.2289\n",
            "Epoch 806: val_loss improved from 1.30071 to 1.29883, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2343 - mean_absolute_error: 0.7913 - mean_squared_error: 1.2343 - val_loss: 1.2988 - val_mean_absolute_error: 0.8137 - val_mean_squared_error: 1.2988\n",
            "Epoch 807/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.2332 - mean_absolute_error: 0.7911 - mean_squared_error: 1.2332\n",
            "Epoch 807: val_loss improved from 1.29883 to 1.29781, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2332 - mean_absolute_error: 0.7911 - mean_squared_error: 1.2332 - val_loss: 1.2978 - val_mean_absolute_error: 0.8125 - val_mean_squared_error: 1.2978\n",
            "Epoch 808/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.2263 - mean_absolute_error: 0.7884 - mean_squared_error: 1.2263\n",
            "Epoch 808: val_loss did not improve from 1.29781\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2328 - mean_absolute_error: 0.7900 - mean_squared_error: 1.2328 - val_loss: 1.2991 - val_mean_absolute_error: 0.8140 - val_mean_squared_error: 1.2991\n",
            "Epoch 809/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.2382 - mean_absolute_error: 0.7942 - mean_squared_error: 1.2382\n",
            "Epoch 809: val_loss did not improve from 1.29781\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2322 - mean_absolute_error: 0.7906 - mean_squared_error: 1.2322 - val_loss: 1.3036 - val_mean_absolute_error: 0.8169 - val_mean_squared_error: 1.3036\n",
            "Epoch 810/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.2357 - mean_absolute_error: 0.7911 - mean_squared_error: 1.2357\n",
            "Epoch 810: val_loss did not improve from 1.29781\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2308 - mean_absolute_error: 0.7898 - mean_squared_error: 1.2308 - val_loss: 1.2979 - val_mean_absolute_error: 0.8145 - val_mean_squared_error: 1.2979\n",
            "Epoch 811/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.2345 - mean_absolute_error: 0.7943 - mean_squared_error: 1.2345\n",
            "Epoch 811: val_loss improved from 1.29781 to 1.29776, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2297 - mean_absolute_error: 0.7916 - mean_squared_error: 1.2297 - val_loss: 1.2978 - val_mean_absolute_error: 0.8136 - val_mean_squared_error: 1.2978\n",
            "Epoch 812/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.2191 - mean_absolute_error: 0.7880 - mean_squared_error: 1.2191\n",
            "Epoch 812: val_loss improved from 1.29776 to 1.29622, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2304 - mean_absolute_error: 0.7914 - mean_squared_error: 1.2304 - val_loss: 1.2962 - val_mean_absolute_error: 0.8122 - val_mean_squared_error: 1.2962\n",
            "Epoch 813/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.2368 - mean_absolute_error: 0.7943 - mean_squared_error: 1.2368\n",
            "Epoch 813: val_loss did not improve from 1.29622\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2292 - mean_absolute_error: 0.7907 - mean_squared_error: 1.2292 - val_loss: 1.2965 - val_mean_absolute_error: 0.8142 - val_mean_squared_error: 1.2965\n",
            "Epoch 814/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.2263 - mean_absolute_error: 0.7894 - mean_squared_error: 1.2263\n",
            "Epoch 814: val_loss did not improve from 1.29622\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2259 - mean_absolute_error: 0.7900 - mean_squared_error: 1.2259 - val_loss: 1.2966 - val_mean_absolute_error: 0.8146 - val_mean_squared_error: 1.2966\n",
            "Epoch 815/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.2299 - mean_absolute_error: 0.7902 - mean_squared_error: 1.2299\n",
            "Epoch 815: val_loss did not improve from 1.29622\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2263 - mean_absolute_error: 0.7900 - mean_squared_error: 1.2263 - val_loss: 1.2972 - val_mean_absolute_error: 0.8154 - val_mean_squared_error: 1.2972\n",
            "Epoch 816/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.2174 - mean_absolute_error: 0.7870 - mean_squared_error: 1.2174\n",
            "Epoch 816: val_loss did not improve from 1.29622\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2267 - mean_absolute_error: 0.7899 - mean_squared_error: 1.2267 - val_loss: 1.3020 - val_mean_absolute_error: 0.8191 - val_mean_squared_error: 1.3020\n",
            "Epoch 817/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.2342 - mean_absolute_error: 0.7965 - mean_squared_error: 1.2342\n",
            "Epoch 817: val_loss improved from 1.29622 to 1.29251, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2247 - mean_absolute_error: 0.7909 - mean_squared_error: 1.2247 - val_loss: 1.2925 - val_mean_absolute_error: 0.8121 - val_mean_squared_error: 1.2925\n",
            "Epoch 818/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.2296 - mean_absolute_error: 0.7906 - mean_squared_error: 1.2296\n",
            "Epoch 818: val_loss did not improve from 1.29251\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2243 - mean_absolute_error: 0.7895 - mean_squared_error: 1.2243 - val_loss: 1.2952 - val_mean_absolute_error: 0.8147 - val_mean_squared_error: 1.2952\n",
            "Epoch 819/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.2288 - mean_absolute_error: 0.7910 - mean_squared_error: 1.2288\n",
            "Epoch 819: val_loss did not improve from 1.29251\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2225 - mean_absolute_error: 0.7891 - mean_squared_error: 1.2225 - val_loss: 1.2972 - val_mean_absolute_error: 0.8164 - val_mean_squared_error: 1.2972\n",
            "Epoch 820/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.2156 - mean_absolute_error: 0.7878 - mean_squared_error: 1.2156\n",
            "Epoch 820: val_loss improved from 1.29251 to 1.28918, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2219 - mean_absolute_error: 0.7894 - mean_squared_error: 1.2219 - val_loss: 1.2892 - val_mean_absolute_error: 0.8121 - val_mean_squared_error: 1.2892\n",
            "Epoch 821/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.2156 - mean_absolute_error: 0.7861 - mean_squared_error: 1.2156\n",
            "Epoch 821: val_loss did not improve from 1.28918\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2217 - mean_absolute_error: 0.7879 - mean_squared_error: 1.2217 - val_loss: 1.2953 - val_mean_absolute_error: 0.8156 - val_mean_squared_error: 1.2953\n",
            "Epoch 822/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.2284 - mean_absolute_error: 0.7916 - mean_squared_error: 1.2284\n",
            "Epoch 822: val_loss did not improve from 1.28918\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2201 - mean_absolute_error: 0.7885 - mean_squared_error: 1.2201 - val_loss: 1.2923 - val_mean_absolute_error: 0.8151 - val_mean_squared_error: 1.2923\n",
            "Epoch 823/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.2210 - mean_absolute_error: 0.7890 - mean_squared_error: 1.2210\n",
            "Epoch 823: val_loss did not improve from 1.28918\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2199 - mean_absolute_error: 0.7894 - mean_squared_error: 1.2199 - val_loss: 1.2926 - val_mean_absolute_error: 0.8157 - val_mean_squared_error: 1.2926\n",
            "Epoch 824/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.2283 - mean_absolute_error: 0.7908 - mean_squared_error: 1.2283\n",
            "Epoch 824: val_loss improved from 1.28918 to 1.28629, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2185 - mean_absolute_error: 0.7885 - mean_squared_error: 1.2185 - val_loss: 1.2863 - val_mean_absolute_error: 0.8119 - val_mean_squared_error: 1.2863\n",
            "Epoch 825/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.2218 - mean_absolute_error: 0.7895 - mean_squared_error: 1.2218\n",
            "Epoch 825: val_loss did not improve from 1.28629\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2184 - mean_absolute_error: 0.7881 - mean_squared_error: 1.2184 - val_loss: 1.2865 - val_mean_absolute_error: 0.8127 - val_mean_squared_error: 1.2865\n",
            "Epoch 826/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.2132 - mean_absolute_error: 0.7874 - mean_squared_error: 1.2132\n",
            "Epoch 826: val_loss improved from 1.28629 to 1.28603, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2164 - mean_absolute_error: 0.7887 - mean_squared_error: 1.2164 - val_loss: 1.2860 - val_mean_absolute_error: 0.8122 - val_mean_squared_error: 1.2860\n",
            "Epoch 827/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.2231 - mean_absolute_error: 0.7918 - mean_squared_error: 1.2231\n",
            "Epoch 827: val_loss improved from 1.28603 to 1.28510, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2155 - mean_absolute_error: 0.7892 - mean_squared_error: 1.2155 - val_loss: 1.2851 - val_mean_absolute_error: 0.8126 - val_mean_squared_error: 1.2851\n",
            "Epoch 828/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.2158 - mean_absolute_error: 0.7879 - mean_squared_error: 1.2158\n",
            "Epoch 828: val_loss improved from 1.28510 to 1.28291, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2155 - mean_absolute_error: 0.7889 - mean_squared_error: 1.2155 - val_loss: 1.2829 - val_mean_absolute_error: 0.8110 - val_mean_squared_error: 1.2829\n",
            "Epoch 829/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.2174 - mean_absolute_error: 0.7886 - mean_squared_error: 1.2174\n",
            "Epoch 829: val_loss did not improve from 1.28291\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2149 - mean_absolute_error: 0.7882 - mean_squared_error: 1.2149 - val_loss: 1.2830 - val_mean_absolute_error: 0.8117 - val_mean_squared_error: 1.2830\n",
            "Epoch 830/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.2177 - mean_absolute_error: 0.7909 - mean_squared_error: 1.2177\n",
            "Epoch 830: val_loss improved from 1.28291 to 1.28164, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2132 - mean_absolute_error: 0.7892 - mean_squared_error: 1.2132 - val_loss: 1.2816 - val_mean_absolute_error: 0.8110 - val_mean_squared_error: 1.2816\n",
            "Epoch 831/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.2006 - mean_absolute_error: 0.7847 - mean_squared_error: 1.2006\n",
            "Epoch 831: val_loss improved from 1.28164 to 1.28034, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2124 - mean_absolute_error: 0.7880 - mean_squared_error: 1.2124 - val_loss: 1.2803 - val_mean_absolute_error: 0.8110 - val_mean_squared_error: 1.2803\n",
            "Epoch 832/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.2065 - mean_absolute_error: 0.7885 - mean_squared_error: 1.2065\n",
            "Epoch 832: val_loss improved from 1.28034 to 1.28001, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2106 - mean_absolute_error: 0.7880 - mean_squared_error: 1.2106 - val_loss: 1.2800 - val_mean_absolute_error: 0.8105 - val_mean_squared_error: 1.2800\n",
            "Epoch 833/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.2144 - mean_absolute_error: 0.7879 - mean_squared_error: 1.2144\n",
            "Epoch 833: val_loss improved from 1.28001 to 1.27928, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2092 - mean_absolute_error: 0.7866 - mean_squared_error: 1.2092 - val_loss: 1.2793 - val_mean_absolute_error: 0.8108 - val_mean_squared_error: 1.2793\n",
            "Epoch 834/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.2086 - mean_absolute_error: 0.7877 - mean_squared_error: 1.2086\n",
            "Epoch 834: val_loss did not improve from 1.27928\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2102 - mean_absolute_error: 0.7889 - mean_squared_error: 1.2102 - val_loss: 1.2794 - val_mean_absolute_error: 0.8105 - val_mean_squared_error: 1.2794\n",
            "Epoch 835/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.2069 - mean_absolute_error: 0.7862 - mean_squared_error: 1.2069\n",
            "Epoch 835: val_loss improved from 1.27928 to 1.27746, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2082 - mean_absolute_error: 0.7862 - mean_squared_error: 1.2082 - val_loss: 1.2775 - val_mean_absolute_error: 0.8096 - val_mean_squared_error: 1.2775\n",
            "Epoch 836/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.2023 - mean_absolute_error: 0.7827 - mean_squared_error: 1.2023\n",
            "Epoch 836: val_loss did not improve from 1.27746\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2077 - mean_absolute_error: 0.7853 - mean_squared_error: 1.2077 - val_loss: 1.2858 - val_mean_absolute_error: 0.8155 - val_mean_squared_error: 1.2858\n",
            "Epoch 837/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.2109 - mean_absolute_error: 0.7903 - mean_squared_error: 1.2109\n",
            "Epoch 837: val_loss improved from 1.27746 to 1.27497, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2048 - mean_absolute_error: 0.7881 - mean_squared_error: 1.2048 - val_loss: 1.2750 - val_mean_absolute_error: 0.8082 - val_mean_squared_error: 1.2750\n",
            "Epoch 838/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.2175 - mean_absolute_error: 0.7872 - mean_squared_error: 1.2175\n",
            "Epoch 838: val_loss did not improve from 1.27497\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2074 - mean_absolute_error: 0.7854 - mean_squared_error: 1.2074 - val_loss: 1.2751 - val_mean_absolute_error: 0.8097 - val_mean_squared_error: 1.2751\n",
            "Epoch 839/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.2011 - mean_absolute_error: 0.7842 - mean_squared_error: 1.2011\n",
            "Epoch 839: val_loss improved from 1.27497 to 1.27446, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2052 - mean_absolute_error: 0.7856 - mean_squared_error: 1.2052 - val_loss: 1.2745 - val_mean_absolute_error: 0.8101 - val_mean_squared_error: 1.2745\n",
            "Epoch 840/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.2016 - mean_absolute_error: 0.7844 - mean_squared_error: 1.2016\n",
            "Epoch 840: val_loss did not improve from 1.27446\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2031 - mean_absolute_error: 0.7851 - mean_squared_error: 1.2031 - val_loss: 1.2749 - val_mean_absolute_error: 0.8109 - val_mean_squared_error: 1.2749\n",
            "Epoch 841/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.2020 - mean_absolute_error: 0.7850 - mean_squared_error: 1.2020\n",
            "Epoch 841: val_loss improved from 1.27446 to 1.27420, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2036 - mean_absolute_error: 0.7857 - mean_squared_error: 1.2036 - val_loss: 1.2742 - val_mean_absolute_error: 0.8109 - val_mean_squared_error: 1.2742\n",
            "Epoch 842/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.2014 - mean_absolute_error: 0.7843 - mean_squared_error: 1.2014\n",
            "Epoch 842: val_loss did not improve from 1.27420\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2006 - mean_absolute_error: 0.7841 - mean_squared_error: 1.2006 - val_loss: 1.2779 - val_mean_absolute_error: 0.8128 - val_mean_squared_error: 1.2779\n",
            "Epoch 843/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.1933 - mean_absolute_error: 0.7832 - mean_squared_error: 1.1933\n",
            "Epoch 843: val_loss improved from 1.27420 to 1.27185, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1998 - mean_absolute_error: 0.7850 - mean_squared_error: 1.1998 - val_loss: 1.2718 - val_mean_absolute_error: 0.8095 - val_mean_squared_error: 1.2718\n",
            "Epoch 844/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.1976 - mean_absolute_error: 0.7836 - mean_squared_error: 1.1976\n",
            "Epoch 844: val_loss did not improve from 1.27185\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1993 - mean_absolute_error: 0.7844 - mean_squared_error: 1.1993 - val_loss: 1.2836 - val_mean_absolute_error: 0.8171 - val_mean_squared_error: 1.2836\n",
            "Epoch 845/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.1939 - mean_absolute_error: 0.7843 - mean_squared_error: 1.1939\n",
            "Epoch 845: val_loss did not improve from 1.27185\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1989 - mean_absolute_error: 0.7862 - mean_squared_error: 1.1989 - val_loss: 1.2857 - val_mean_absolute_error: 0.8190 - val_mean_squared_error: 1.2857\n",
            "Epoch 846/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.1957 - mean_absolute_error: 0.7842 - mean_squared_error: 1.1957\n",
            "Epoch 846: val_loss improved from 1.27185 to 1.27060, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1957 - mean_absolute_error: 0.7842 - mean_squared_error: 1.1957 - val_loss: 1.2706 - val_mean_absolute_error: 0.8100 - val_mean_squared_error: 1.2706\n",
            "Epoch 847/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.2041 - mean_absolute_error: 0.7850 - mean_squared_error: 1.2041\n",
            "Epoch 847: val_loss improved from 1.27060 to 1.26770, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1974 - mean_absolute_error: 0.7833 - mean_squared_error: 1.1974 - val_loss: 1.2677 - val_mean_absolute_error: 0.8088 - val_mean_squared_error: 1.2677\n",
            "Epoch 848/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.1932 - mean_absolute_error: 0.7844 - mean_squared_error: 1.1932\n",
            "Epoch 848: val_loss improved from 1.26770 to 1.26424, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1936 - mean_absolute_error: 0.7842 - mean_squared_error: 1.1936 - val_loss: 1.2642 - val_mean_absolute_error: 0.8056 - val_mean_squared_error: 1.2642\n",
            "Epoch 849/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.1814 - mean_absolute_error: 0.7770 - mean_squared_error: 1.1814\n",
            "Epoch 849: val_loss did not improve from 1.26424\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1946 - mean_absolute_error: 0.7821 - mean_squared_error: 1.1946 - val_loss: 1.2722 - val_mean_absolute_error: 0.8120 - val_mean_squared_error: 1.2722\n",
            "Epoch 850/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.1887 - mean_absolute_error: 0.7831 - mean_squared_error: 1.1887\n",
            "Epoch 850: val_loss improved from 1.26424 to 1.26221, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1946 - mean_absolute_error: 0.7836 - mean_squared_error: 1.1946 - val_loss: 1.2622 - val_mean_absolute_error: 0.8057 - val_mean_squared_error: 1.2622\n",
            "Epoch 851/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.1659 - mean_absolute_error: 0.7722 - mean_squared_error: 1.1659\n",
            "Epoch 851: val_loss did not improve from 1.26221\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1925 - mean_absolute_error: 0.7826 - mean_squared_error: 1.1925 - val_loss: 1.2623 - val_mean_absolute_error: 0.8063 - val_mean_squared_error: 1.2623\n",
            "Epoch 852/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.1935 - mean_absolute_error: 0.7819 - mean_squared_error: 1.1935\n",
            "Epoch 852: val_loss did not improve from 1.26221\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1912 - mean_absolute_error: 0.7819 - mean_squared_error: 1.1912 - val_loss: 1.2627 - val_mean_absolute_error: 0.8069 - val_mean_squared_error: 1.2627\n",
            "Epoch 853/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.1900 - mean_absolute_error: 0.7803 - mean_squared_error: 1.1900\n",
            "Epoch 853: val_loss improved from 1.26221 to 1.26069, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1888 - mean_absolute_error: 0.7823 - mean_squared_error: 1.1888 - val_loss: 1.2607 - val_mean_absolute_error: 0.8061 - val_mean_squared_error: 1.2607\n",
            "Epoch 854/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.1896 - mean_absolute_error: 0.7823 - mean_squared_error: 1.1896\n",
            "Epoch 854: val_loss improved from 1.26069 to 1.25832, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1883 - mean_absolute_error: 0.7820 - mean_squared_error: 1.1883 - val_loss: 1.2583 - val_mean_absolute_error: 0.8038 - val_mean_squared_error: 1.2583\n",
            "Epoch 855/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.1916 - mean_absolute_error: 0.7820 - mean_squared_error: 1.1916\n",
            "Epoch 855: val_loss did not improve from 1.25832\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1862 - mean_absolute_error: 0.7802 - mean_squared_error: 1.1862 - val_loss: 1.2652 - val_mean_absolute_error: 0.8092 - val_mean_squared_error: 1.2652\n",
            "Epoch 856/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.1842 - mean_absolute_error: 0.7803 - mean_squared_error: 1.1842\n",
            "Epoch 856: val_loss did not improve from 1.25832\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1842 - mean_absolute_error: 0.7803 - mean_squared_error: 1.1842 - val_loss: 1.2781 - val_mean_absolute_error: 0.8164 - val_mean_squared_error: 1.2781\n",
            "Epoch 857/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.1846 - mean_absolute_error: 0.7805 - mean_squared_error: 1.1846\n",
            "Epoch 857: val_loss improved from 1.25832 to 1.25550, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1842 - mean_absolute_error: 0.7803 - mean_squared_error: 1.1842 - val_loss: 1.2555 - val_mean_absolute_error: 0.8043 - val_mean_squared_error: 1.2555\n",
            "Epoch 858/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.1931 - mean_absolute_error: 0.7818 - mean_squared_error: 1.1931\n",
            "Epoch 858: val_loss did not improve from 1.25550\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1833 - mean_absolute_error: 0.7790 - mean_squared_error: 1.1833 - val_loss: 1.2608 - val_mean_absolute_error: 0.8080 - val_mean_squared_error: 1.2608\n",
            "Epoch 859/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.1880 - mean_absolute_error: 0.7829 - mean_squared_error: 1.1880\n",
            "Epoch 859: val_loss improved from 1.25550 to 1.25184, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1816 - mean_absolute_error: 0.7808 - mean_squared_error: 1.1816 - val_loss: 1.2518 - val_mean_absolute_error: 0.8020 - val_mean_squared_error: 1.2518\n",
            "Epoch 860/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.1698 - mean_absolute_error: 0.7762 - mean_squared_error: 1.1698\n",
            "Epoch 860: val_loss improved from 1.25184 to 1.25163, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1816 - mean_absolute_error: 0.7791 - mean_squared_error: 1.1816 - val_loss: 1.2516 - val_mean_absolute_error: 0.8021 - val_mean_squared_error: 1.2516\n",
            "Epoch 861/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.1821 - mean_absolute_error: 0.7800 - mean_squared_error: 1.1821\n",
            "Epoch 861: val_loss did not improve from 1.25163\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1801 - mean_absolute_error: 0.7795 - mean_squared_error: 1.1801 - val_loss: 1.2524 - val_mean_absolute_error: 0.8034 - val_mean_squared_error: 1.2524\n",
            "Epoch 862/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.1789 - mean_absolute_error: 0.7786 - mean_squared_error: 1.1789\n",
            "Epoch 862: val_loss did not improve from 1.25163\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1789 - mean_absolute_error: 0.7786 - mean_squared_error: 1.1789 - val_loss: 1.2525 - val_mean_absolute_error: 0.8035 - val_mean_squared_error: 1.2525\n",
            "Epoch 863/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.1839 - mean_absolute_error: 0.7799 - mean_squared_error: 1.1839\n",
            "Epoch 863: val_loss improved from 1.25163 to 1.24675, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1766 - mean_absolute_error: 0.7782 - mean_squared_error: 1.1766 - val_loss: 1.2467 - val_mean_absolute_error: 0.7993 - val_mean_squared_error: 1.2467\n",
            "Epoch 864/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.1824 - mean_absolute_error: 0.7789 - mean_squared_error: 1.1824\n",
            "Epoch 864: val_loss improved from 1.24675 to 1.24638, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1769 - mean_absolute_error: 0.7773 - mean_squared_error: 1.1769 - val_loss: 1.2464 - val_mean_absolute_error: 0.8006 - val_mean_squared_error: 1.2464\n",
            "Epoch 865/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.1606 - mean_absolute_error: 0.7722 - mean_squared_error: 1.1606\n",
            "Epoch 865: val_loss did not improve from 1.24638\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1750 - mean_absolute_error: 0.7762 - mean_squared_error: 1.1750 - val_loss: 1.2468 - val_mean_absolute_error: 0.8014 - val_mean_squared_error: 1.2468\n",
            "Epoch 866/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.1642 - mean_absolute_error: 0.7753 - mean_squared_error: 1.1642\n",
            "Epoch 866: val_loss improved from 1.24638 to 1.24343, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1726 - mean_absolute_error: 0.7767 - mean_squared_error: 1.1726 - val_loss: 1.2434 - val_mean_absolute_error: 0.7994 - val_mean_squared_error: 1.2434\n",
            "Epoch 867/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.1689 - mean_absolute_error: 0.7760 - mean_squared_error: 1.1689\n",
            "Epoch 867: val_loss did not improve from 1.24343\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1713 - mean_absolute_error: 0.7766 - mean_squared_error: 1.1713 - val_loss: 1.2477 - val_mean_absolute_error: 0.8022 - val_mean_squared_error: 1.2477\n",
            "Epoch 868/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.1768 - mean_absolute_error: 0.7769 - mean_squared_error: 1.1768\n",
            "Epoch 868: val_loss improved from 1.24343 to 1.24099, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1692 - mean_absolute_error: 0.7753 - mean_squared_error: 1.1692 - val_loss: 1.2410 - val_mean_absolute_error: 0.7982 - val_mean_squared_error: 1.2410\n",
            "Epoch 869/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.1691 - mean_absolute_error: 0.7751 - mean_squared_error: 1.1691\n",
            "Epoch 869: val_loss improved from 1.24099 to 1.23906, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1677 - mean_absolute_error: 0.7744 - mean_squared_error: 1.1677 - val_loss: 1.2391 - val_mean_absolute_error: 0.7965 - val_mean_squared_error: 1.2391\n",
            "Epoch 870/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.1577 - mean_absolute_error: 0.7719 - mean_squared_error: 1.1577\n",
            "Epoch 870: val_loss did not improve from 1.23906\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1662 - mean_absolute_error: 0.7734 - mean_squared_error: 1.1662 - val_loss: 1.2433 - val_mean_absolute_error: 0.8003 - val_mean_squared_error: 1.2433\n",
            "Epoch 871/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.1611 - mean_absolute_error: 0.7726 - mean_squared_error: 1.1611\n",
            "Epoch 871: val_loss improved from 1.23906 to 1.23844, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1650 - mean_absolute_error: 0.7737 - mean_squared_error: 1.1650 - val_loss: 1.2384 - val_mean_absolute_error: 0.7980 - val_mean_squared_error: 1.2384\n",
            "Epoch 872/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.1616 - mean_absolute_error: 0.7733 - mean_squared_error: 1.1616\n",
            "Epoch 872: val_loss improved from 1.23844 to 1.23785, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1633 - mean_absolute_error: 0.7738 - mean_squared_error: 1.1633 - val_loss: 1.2378 - val_mean_absolute_error: 0.7978 - val_mean_squared_error: 1.2378\n",
            "Epoch 873/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 1.1627 - mean_absolute_error: 0.7738 - mean_squared_error: 1.1627\n",
            "Epoch 873: val_loss improved from 1.23785 to 1.23452, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1649 - mean_absolute_error: 0.7738 - mean_squared_error: 1.1649 - val_loss: 1.2345 - val_mean_absolute_error: 0.7959 - val_mean_squared_error: 1.2345\n",
            "Epoch 874/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.1577 - mean_absolute_error: 0.7714 - mean_squared_error: 1.1577\n",
            "Epoch 874: val_loss improved from 1.23452 to 1.23439, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1614 - mean_absolute_error: 0.7722 - mean_squared_error: 1.1614 - val_loss: 1.2344 - val_mean_absolute_error: 0.7963 - val_mean_squared_error: 1.2344\n",
            "Epoch 875/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.1647 - mean_absolute_error: 0.7716 - mean_squared_error: 1.1647\n",
            "Epoch 875: val_loss did not improve from 1.23439\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1606 - mean_absolute_error: 0.7707 - mean_squared_error: 1.1606 - val_loss: 1.2361 - val_mean_absolute_error: 0.7988 - val_mean_squared_error: 1.2361\n",
            "Epoch 876/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.1571 - mean_absolute_error: 0.7713 - mean_squared_error: 1.1571\n",
            "Epoch 876: val_loss improved from 1.23439 to 1.23182, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1595 - mean_absolute_error: 0.7721 - mean_squared_error: 1.1595 - val_loss: 1.2318 - val_mean_absolute_error: 0.7953 - val_mean_squared_error: 1.2318\n",
            "Epoch 877/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.1544 - mean_absolute_error: 0.7719 - mean_squared_error: 1.1544\n",
            "Epoch 877: val_loss improved from 1.23182 to 1.23002, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1566 - mean_absolute_error: 0.7722 - mean_squared_error: 1.1566 - val_loss: 1.2300 - val_mean_absolute_error: 0.7933 - val_mean_squared_error: 1.2300\n",
            "Epoch 878/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.1666 - mean_absolute_error: 0.7732 - mean_squared_error: 1.1666\n",
            "Epoch 878: val_loss did not improve from 1.23002\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1552 - mean_absolute_error: 0.7694 - mean_squared_error: 1.1552 - val_loss: 1.2301 - val_mean_absolute_error: 0.7941 - val_mean_squared_error: 1.2301\n",
            "Epoch 879/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.1434 - mean_absolute_error: 0.7648 - mean_squared_error: 1.1434\n",
            "Epoch 879: val_loss improved from 1.23002 to 1.22550, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1549 - mean_absolute_error: 0.7697 - mean_squared_error: 1.1549 - val_loss: 1.2255 - val_mean_absolute_error: 0.7911 - val_mean_squared_error: 1.2255\n",
            "Epoch 880/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.1577 - mean_absolute_error: 0.7704 - mean_squared_error: 1.1577\n",
            "Epoch 880: val_loss improved from 1.22550 to 1.22290, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1530 - mean_absolute_error: 0.7677 - mean_squared_error: 1.1530 - val_loss: 1.2229 - val_mean_absolute_error: 0.7905 - val_mean_squared_error: 1.2229\n",
            "Epoch 881/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.1485 - mean_absolute_error: 0.7676 - mean_squared_error: 1.1485\n",
            "Epoch 881: val_loss did not improve from 1.22290\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1500 - mean_absolute_error: 0.7677 - mean_squared_error: 1.1500 - val_loss: 1.2244 - val_mean_absolute_error: 0.7920 - val_mean_squared_error: 1.2244\n",
            "Epoch 882/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.1499 - mean_absolute_error: 0.7678 - mean_squared_error: 1.1499\n",
            "Epoch 882: val_loss improved from 1.22290 to 1.22069, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1488 - mean_absolute_error: 0.7674 - mean_squared_error: 1.1488 - val_loss: 1.2207 - val_mean_absolute_error: 0.7899 - val_mean_squared_error: 1.2207\n",
            "Epoch 883/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.1521 - mean_absolute_error: 0.7665 - mean_squared_error: 1.1521\n",
            "Epoch 883: val_loss did not improve from 1.22069\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1465 - mean_absolute_error: 0.7657 - mean_squared_error: 1.1465 - val_loss: 1.2263 - val_mean_absolute_error: 0.7946 - val_mean_squared_error: 1.2263\n",
            "Epoch 884/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.1532 - mean_absolute_error: 0.7691 - mean_squared_error: 1.1532\n",
            "Epoch 884: val_loss improved from 1.22069 to 1.21816, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1452 - mean_absolute_error: 0.7665 - mean_squared_error: 1.1452 - val_loss: 1.2182 - val_mean_absolute_error: 0.7889 - val_mean_squared_error: 1.2182\n",
            "Epoch 885/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.1431 - mean_absolute_error: 0.7655 - mean_squared_error: 1.1431\n",
            "Epoch 885: val_loss improved from 1.21816 to 1.21668, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1450 - mean_absolute_error: 0.7656 - mean_squared_error: 1.1450 - val_loss: 1.2167 - val_mean_absolute_error: 0.7885 - val_mean_squared_error: 1.2167\n",
            "Epoch 886/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.1443 - mean_absolute_error: 0.7653 - mean_squared_error: 1.1443\n",
            "Epoch 886: val_loss did not improve from 1.21668\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1429 - mean_absolute_error: 0.7652 - mean_squared_error: 1.1429 - val_loss: 1.2170 - val_mean_absolute_error: 0.7898 - val_mean_squared_error: 1.2170\n",
            "Epoch 887/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.1362 - mean_absolute_error: 0.7631 - mean_squared_error: 1.1362\n",
            "Epoch 887: val_loss improved from 1.21668 to 1.21514, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1413 - mean_absolute_error: 0.7644 - mean_squared_error: 1.1413 - val_loss: 1.2151 - val_mean_absolute_error: 0.7887 - val_mean_squared_error: 1.2151\n",
            "Epoch 888/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.1439 - mean_absolute_error: 0.7644 - mean_squared_error: 1.1439\n",
            "Epoch 888: val_loss improved from 1.21514 to 1.21456, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1398 - mean_absolute_error: 0.7623 - mean_squared_error: 1.1398 - val_loss: 1.2146 - val_mean_absolute_error: 0.7898 - val_mean_squared_error: 1.2146\n",
            "Epoch 889/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.1326 - mean_absolute_error: 0.7608 - mean_squared_error: 1.1326\n",
            "Epoch 889: val_loss improved from 1.21456 to 1.21030, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1378 - mean_absolute_error: 0.7630 - mean_squared_error: 1.1378 - val_loss: 1.2103 - val_mean_absolute_error: 0.7869 - val_mean_squared_error: 1.2103\n",
            "Epoch 890/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.1545 - mean_absolute_error: 0.7705 - mean_squared_error: 1.1545\n",
            "Epoch 890: val_loss did not improve from 1.21030\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1366 - mean_absolute_error: 0.7639 - mean_squared_error: 1.1366 - val_loss: 1.2104 - val_mean_absolute_error: 0.7873 - val_mean_squared_error: 1.2104\n",
            "Epoch 891/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.1321 - mean_absolute_error: 0.7614 - mean_squared_error: 1.1321\n",
            "Epoch 891: val_loss improved from 1.21030 to 1.20746, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1358 - mean_absolute_error: 0.7618 - mean_squared_error: 1.1358 - val_loss: 1.2075 - val_mean_absolute_error: 0.7848 - val_mean_squared_error: 1.2075\n",
            "Epoch 892/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.1364 - mean_absolute_error: 0.7614 - mean_squared_error: 1.1364\n",
            "Epoch 892: val_loss improved from 1.20746 to 1.20539, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1326 - mean_absolute_error: 0.7611 - mean_squared_error: 1.1326 - val_loss: 1.2054 - val_mean_absolute_error: 0.7842 - val_mean_squared_error: 1.2054\n",
            "Epoch 893/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.1261 - mean_absolute_error: 0.7598 - mean_squared_error: 1.1261\n",
            "Epoch 893: val_loss improved from 1.20539 to 1.20333, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1318 - mean_absolute_error: 0.7615 - mean_squared_error: 1.1318 - val_loss: 1.2033 - val_mean_absolute_error: 0.7831 - val_mean_squared_error: 1.2033\n",
            "Epoch 894/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.1311 - mean_absolute_error: 0.7593 - mean_squared_error: 1.1311\n",
            "Epoch 894: val_loss improved from 1.20333 to 1.20254, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1287 - mean_absolute_error: 0.7590 - mean_squared_error: 1.1287 - val_loss: 1.2025 - val_mean_absolute_error: 0.7830 - val_mean_squared_error: 1.2025\n",
            "Epoch 895/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.1403 - mean_absolute_error: 0.7650 - mean_squared_error: 1.1403\n",
            "Epoch 895: val_loss improved from 1.20254 to 1.19890, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1292 - mean_absolute_error: 0.7602 - mean_squared_error: 1.1292 - val_loss: 1.1989 - val_mean_absolute_error: 0.7801 - val_mean_squared_error: 1.1989\n",
            "Epoch 896/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.1354 - mean_absolute_error: 0.7606 - mean_squared_error: 1.1354\n",
            "Epoch 896: val_loss improved from 1.19890 to 1.19888, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1269 - mean_absolute_error: 0.7573 - mean_squared_error: 1.1269 - val_loss: 1.1989 - val_mean_absolute_error: 0.7812 - val_mean_squared_error: 1.1989\n",
            "Epoch 897/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.1182 - mean_absolute_error: 0.7556 - mean_squared_error: 1.1182\n",
            "Epoch 897: val_loss improved from 1.19888 to 1.19664, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1239 - mean_absolute_error: 0.7569 - mean_squared_error: 1.1239 - val_loss: 1.1966 - val_mean_absolute_error: 0.7799 - val_mean_squared_error: 1.1966\n",
            "Epoch 898/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.1162 - mean_absolute_error: 0.7539 - mean_squared_error: 1.1162\n",
            "Epoch 898: val_loss did not improve from 1.19664\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1222 - mean_absolute_error: 0.7566 - mean_squared_error: 1.1222 - val_loss: 1.2098 - val_mean_absolute_error: 0.7905 - val_mean_squared_error: 1.2098\n",
            "Epoch 899/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.1210 - mean_absolute_error: 0.7592 - mean_squared_error: 1.1210\n",
            "Epoch 899: val_loss improved from 1.19664 to 1.19588, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1174 - mean_absolute_error: 0.7584 - mean_squared_error: 1.1174 - val_loss: 1.1959 - val_mean_absolute_error: 0.7795 - val_mean_squared_error: 1.1959\n",
            "Epoch 900/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.1124 - mean_absolute_error: 0.7520 - mean_squared_error: 1.1124\n",
            "Epoch 900: val_loss improved from 1.19588 to 1.19252, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1192 - mean_absolute_error: 0.7547 - mean_squared_error: 1.1192 - val_loss: 1.1925 - val_mean_absolute_error: 0.7790 - val_mean_squared_error: 1.1925\n",
            "Epoch 901/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.1132 - mean_absolute_error: 0.7538 - mean_squared_error: 1.1132\n",
            "Epoch 901: val_loss improved from 1.19252 to 1.19190, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1163 - mean_absolute_error: 0.7554 - mean_squared_error: 1.1163 - val_loss: 1.1919 - val_mean_absolute_error: 0.7785 - val_mean_squared_error: 1.1919\n",
            "Epoch 902/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.1065 - mean_absolute_error: 0.7500 - mean_squared_error: 1.1065\n",
            "Epoch 902: val_loss improved from 1.19190 to 1.18949, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1155 - mean_absolute_error: 0.7526 - mean_squared_error: 1.1155 - val_loss: 1.1895 - val_mean_absolute_error: 0.7776 - val_mean_squared_error: 1.1895\n",
            "Epoch 903/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.1178 - mean_absolute_error: 0.7557 - mean_squared_error: 1.1178\n",
            "Epoch 903: val_loss improved from 1.18949 to 1.18683, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1141 - mean_absolute_error: 0.7541 - mean_squared_error: 1.1141 - val_loss: 1.1868 - val_mean_absolute_error: 0.7760 - val_mean_squared_error: 1.1868\n",
            "Epoch 904/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.1132 - mean_absolute_error: 0.7532 - mean_squared_error: 1.1132\n",
            "Epoch 904: val_loss improved from 1.18683 to 1.18415, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1136 - mean_absolute_error: 0.7533 - mean_squared_error: 1.1136 - val_loss: 1.1842 - val_mean_absolute_error: 0.7738 - val_mean_squared_error: 1.1842\n",
            "Epoch 905/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.1097 - mean_absolute_error: 0.7500 - mean_squared_error: 1.1097\n",
            "Epoch 905: val_loss did not improve from 1.18415\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1097 - mean_absolute_error: 0.7500 - mean_squared_error: 1.1097 - val_loss: 1.1863 - val_mean_absolute_error: 0.7777 - val_mean_squared_error: 1.1863\n",
            "Epoch 906/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.1193 - mean_absolute_error: 0.7548 - mean_squared_error: 1.1193\n",
            "Epoch 906: val_loss improved from 1.18415 to 1.18112, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1092 - mean_absolute_error: 0.7521 - mean_squared_error: 1.1092 - val_loss: 1.1811 - val_mean_absolute_error: 0.7733 - val_mean_squared_error: 1.1811\n",
            "Epoch 907/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.1017 - mean_absolute_error: 0.7479 - mean_squared_error: 1.1017\n",
            "Epoch 907: val_loss did not improve from 1.18112\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1075 - mean_absolute_error: 0.7499 - mean_squared_error: 1.1075 - val_loss: 1.1823 - val_mean_absolute_error: 0.7753 - val_mean_squared_error: 1.1823\n",
            "Epoch 908/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.1073 - mean_absolute_error: 0.7509 - mean_squared_error: 1.1073\n",
            "Epoch 908: val_loss improved from 1.18112 to 1.17839, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1055 - mean_absolute_error: 0.7498 - mean_squared_error: 1.1055 - val_loss: 1.1784 - val_mean_absolute_error: 0.7731 - val_mean_squared_error: 1.1784\n",
            "Epoch 909/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 1.0933 - mean_absolute_error: 0.7449 - mean_squared_error: 1.0933\n",
            "Epoch 909: val_loss improved from 1.17839 to 1.17756, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1036 - mean_absolute_error: 0.7488 - mean_squared_error: 1.1036 - val_loss: 1.1776 - val_mean_absolute_error: 0.7721 - val_mean_squared_error: 1.1776\n",
            "Epoch 910/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.1030 - mean_absolute_error: 0.7477 - mean_squared_error: 1.1030\n",
            "Epoch 910: val_loss improved from 1.17756 to 1.17441, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1030 - mean_absolute_error: 0.7478 - mean_squared_error: 1.1030 - val_loss: 1.1744 - val_mean_absolute_error: 0.7711 - val_mean_squared_error: 1.1744\n",
            "Epoch 911/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.0987 - mean_absolute_error: 0.7466 - mean_squared_error: 1.0987\n",
            "Epoch 911: val_loss improved from 1.17441 to 1.17341, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1002 - mean_absolute_error: 0.7469 - mean_squared_error: 1.1002 - val_loss: 1.1734 - val_mean_absolute_error: 0.7713 - val_mean_squared_error: 1.1734\n",
            "Epoch 912/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.0963 - mean_absolute_error: 0.7462 - mean_squared_error: 1.0963\n",
            "Epoch 912: val_loss did not improve from 1.17341\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0972 - mean_absolute_error: 0.7465 - mean_squared_error: 1.0972 - val_loss: 1.1791 - val_mean_absolute_error: 0.7735 - val_mean_squared_error: 1.1791\n",
            "Epoch 913/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.0960 - mean_absolute_error: 0.7455 - mean_squared_error: 1.0960\n",
            "Epoch 913: val_loss improved from 1.17341 to 1.17210, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0979 - mean_absolute_error: 0.7458 - mean_squared_error: 1.0979 - val_loss: 1.1721 - val_mean_absolute_error: 0.7711 - val_mean_squared_error: 1.1721\n",
            "Epoch 914/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.0899 - mean_absolute_error: 0.7432 - mean_squared_error: 1.0899\n",
            "Epoch 914: val_loss improved from 1.17210 to 1.16707, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0936 - mean_absolute_error: 0.7445 - mean_squared_error: 1.0936 - val_loss: 1.1671 - val_mean_absolute_error: 0.7675 - val_mean_squared_error: 1.1671\n",
            "Epoch 915/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.0935 - mean_absolute_error: 0.7452 - mean_squared_error: 1.0935\n",
            "Epoch 915: val_loss did not improve from 1.16707\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0930 - mean_absolute_error: 0.7445 - mean_squared_error: 1.0930 - val_loss: 1.1672 - val_mean_absolute_error: 0.7686 - val_mean_squared_error: 1.1672\n",
            "Epoch 916/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.0929 - mean_absolute_error: 0.7452 - mean_squared_error: 1.0929\n",
            "Epoch 916: val_loss improved from 1.16707 to 1.16340, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0927 - mean_absolute_error: 0.7448 - mean_squared_error: 1.0927 - val_loss: 1.1634 - val_mean_absolute_error: 0.7665 - val_mean_squared_error: 1.1634\n",
            "Epoch 917/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.0899 - mean_absolute_error: 0.7421 - mean_squared_error: 1.0899\n",
            "Epoch 917: val_loss improved from 1.16340 to 1.16113, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0892 - mean_absolute_error: 0.7421 - mean_squared_error: 1.0892 - val_loss: 1.1611 - val_mean_absolute_error: 0.7640 - val_mean_squared_error: 1.1611\n",
            "Epoch 918/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.1002 - mean_absolute_error: 0.7447 - mean_squared_error: 1.1002\n",
            "Epoch 918: val_loss did not improve from 1.16113\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0890 - mean_absolute_error: 0.7422 - mean_squared_error: 1.0890 - val_loss: 1.1627 - val_mean_absolute_error: 0.7671 - val_mean_squared_error: 1.1627\n",
            "Epoch 919/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.0881 - mean_absolute_error: 0.7421 - mean_squared_error: 1.0881\n",
            "Epoch 919: val_loss improved from 1.16113 to 1.15793, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0856 - mean_absolute_error: 0.7417 - mean_squared_error: 1.0856 - val_loss: 1.1579 - val_mean_absolute_error: 0.7637 - val_mean_squared_error: 1.1579\n",
            "Epoch 920/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.0810 - mean_absolute_error: 0.7398 - mean_squared_error: 1.0810\n",
            "Epoch 920: val_loss improved from 1.15793 to 1.15702, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0842 - mean_absolute_error: 0.7400 - mean_squared_error: 1.0842 - val_loss: 1.1570 - val_mean_absolute_error: 0.7648 - val_mean_squared_error: 1.1570\n",
            "Epoch 921/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.0870 - mean_absolute_error: 0.7412 - mean_squared_error: 1.0870\n",
            "Epoch 921: val_loss did not improve from 1.15702\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0842 - mean_absolute_error: 0.7419 - mean_squared_error: 1.0842 - val_loss: 1.1589 - val_mean_absolute_error: 0.7670 - val_mean_squared_error: 1.1589\n",
            "Epoch 922/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.0807 - mean_absolute_error: 0.7391 - mean_squared_error: 1.0807\n",
            "Epoch 922: val_loss improved from 1.15702 to 1.15445, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0807 - mean_absolute_error: 0.7391 - mean_squared_error: 1.0807 - val_loss: 1.1544 - val_mean_absolute_error: 0.7635 - val_mean_squared_error: 1.1544\n",
            "Epoch 923/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.0834 - mean_absolute_error: 0.7409 - mean_squared_error: 1.0834\n",
            "Epoch 923: val_loss did not improve from 1.15445\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0804 - mean_absolute_error: 0.7388 - mean_squared_error: 1.0804 - val_loss: 1.1620 - val_mean_absolute_error: 0.7707 - val_mean_squared_error: 1.1620\n",
            "Epoch 924/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.0747 - mean_absolute_error: 0.7365 - mean_squared_error: 1.0747\n",
            "Epoch 924: val_loss did not improve from 1.15445\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0779 - mean_absolute_error: 0.7373 - mean_squared_error: 1.0779 - val_loss: 1.1557 - val_mean_absolute_error: 0.7659 - val_mean_squared_error: 1.1557\n",
            "Epoch 925/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.0592 - mean_absolute_error: 0.7307 - mean_squared_error: 1.0592\n",
            "Epoch 925: val_loss improved from 1.15445 to 1.14877, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0745 - mean_absolute_error: 0.7360 - mean_squared_error: 1.0745 - val_loss: 1.1488 - val_mean_absolute_error: 0.7624 - val_mean_squared_error: 1.1488\n",
            "Epoch 926/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.0693 - mean_absolute_error: 0.7350 - mean_squared_error: 1.0693\n",
            "Epoch 926: val_loss improved from 1.14877 to 1.14767, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0734 - mean_absolute_error: 0.7371 - mean_squared_error: 1.0734 - val_loss: 1.1477 - val_mean_absolute_error: 0.7614 - val_mean_squared_error: 1.1477\n",
            "Epoch 927/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.0765 - mean_absolute_error: 0.7388 - mean_squared_error: 1.0765\n",
            "Epoch 927: val_loss improved from 1.14767 to 1.14522, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0720 - mean_absolute_error: 0.7372 - mean_squared_error: 1.0720 - val_loss: 1.1452 - val_mean_absolute_error: 0.7591 - val_mean_squared_error: 1.1452\n",
            "Epoch 928/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.0723 - mean_absolute_error: 0.7341 - mean_squared_error: 1.0723\n",
            "Epoch 928: val_loss improved from 1.14522 to 1.14360, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0703 - mean_absolute_error: 0.7331 - mean_squared_error: 1.0703 - val_loss: 1.1436 - val_mean_absolute_error: 0.7595 - val_mean_squared_error: 1.1436\n",
            "Epoch 929/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.0720 - mean_absolute_error: 0.7352 - mean_squared_error: 1.0720\n",
            "Epoch 929: val_loss improved from 1.14360 to 1.14088, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0673 - mean_absolute_error: 0.7344 - mean_squared_error: 1.0673 - val_loss: 1.1409 - val_mean_absolute_error: 0.7574 - val_mean_squared_error: 1.1409\n",
            "Epoch 930/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.0641 - mean_absolute_error: 0.7345 - mean_squared_error: 1.0641\n",
            "Epoch 930: val_loss did not improve from 1.14088\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0666 - mean_absolute_error: 0.7337 - mean_squared_error: 1.0666 - val_loss: 1.1417 - val_mean_absolute_error: 0.7596 - val_mean_squared_error: 1.1417\n",
            "Epoch 931/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 1.0947 - mean_absolute_error: 0.7447 - mean_squared_error: 1.0947\n",
            "Epoch 931: val_loss improved from 1.14088 to 1.13786, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0636 - mean_absolute_error: 0.7338 - mean_squared_error: 1.0636 - val_loss: 1.1379 - val_mean_absolute_error: 0.7568 - val_mean_squared_error: 1.1379\n",
            "Epoch 932/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.0694 - mean_absolute_error: 0.7337 - mean_squared_error: 1.0694\n",
            "Epoch 932: val_loss did not improve from 1.13786\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0614 - mean_absolute_error: 0.7311 - mean_squared_error: 1.0614 - val_loss: 1.1569 - val_mean_absolute_error: 0.7712 - val_mean_squared_error: 1.1569\n",
            "Epoch 933/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.0734 - mean_absolute_error: 0.7350 - mean_squared_error: 1.0734\n",
            "Epoch 933: val_loss improved from 1.13786 to 1.13582, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0631 - mean_absolute_error: 0.7316 - mean_squared_error: 1.0631 - val_loss: 1.1358 - val_mean_absolute_error: 0.7570 - val_mean_squared_error: 1.1358\n",
            "Epoch 934/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.0609 - mean_absolute_error: 0.7322 - mean_squared_error: 1.0609\n",
            "Epoch 934: val_loss improved from 1.13582 to 1.13230, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0609 - mean_absolute_error: 0.7322 - mean_squared_error: 1.0609 - val_loss: 1.1323 - val_mean_absolute_error: 0.7546 - val_mean_squared_error: 1.1323\n",
            "Epoch 935/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.0642 - mean_absolute_error: 0.7330 - mean_squared_error: 1.0642\n",
            "Epoch 935: val_loss improved from 1.13230 to 1.13049, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0589 - mean_absolute_error: 0.7315 - mean_squared_error: 1.0589 - val_loss: 1.1305 - val_mean_absolute_error: 0.7535 - val_mean_squared_error: 1.1305\n",
            "Epoch 936/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.0528 - mean_absolute_error: 0.7287 - mean_squared_error: 1.0528\n",
            "Epoch 936: val_loss did not improve from 1.13049\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0559 - mean_absolute_error: 0.7287 - mean_squared_error: 1.0559 - val_loss: 1.1375 - val_mean_absolute_error: 0.7602 - val_mean_squared_error: 1.1375\n",
            "Epoch 937/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.0558 - mean_absolute_error: 0.7300 - mean_squared_error: 1.0558\n",
            "Epoch 937: val_loss improved from 1.13049 to 1.12824, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0556 - mean_absolute_error: 0.7297 - mean_squared_error: 1.0556 - val_loss: 1.1282 - val_mean_absolute_error: 0.7539 - val_mean_squared_error: 1.1282\n",
            "Epoch 938/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.0568 - mean_absolute_error: 0.7301 - mean_squared_error: 1.0568\n",
            "Epoch 938: val_loss improved from 1.12824 to 1.12670, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0535 - mean_absolute_error: 0.7285 - mean_squared_error: 1.0535 - val_loss: 1.1267 - val_mean_absolute_error: 0.7532 - val_mean_squared_error: 1.1267\n",
            "Epoch 939/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.0509 - mean_absolute_error: 0.7270 - mean_squared_error: 1.0509\n",
            "Epoch 939: val_loss improved from 1.12670 to 1.12511, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0516 - mean_absolute_error: 0.7280 - mean_squared_error: 1.0516 - val_loss: 1.1251 - val_mean_absolute_error: 0.7526 - val_mean_squared_error: 1.1251\n",
            "Epoch 940/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.0577 - mean_absolute_error: 0.7275 - mean_squared_error: 1.0577\n",
            "Epoch 940: val_loss improved from 1.12511 to 1.12270, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0500 - mean_absolute_error: 0.7260 - mean_squared_error: 1.0500 - val_loss: 1.1227 - val_mean_absolute_error: 0.7521 - val_mean_squared_error: 1.1227\n",
            "Epoch 941/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.0464 - mean_absolute_error: 0.7275 - mean_squared_error: 1.0464\n",
            "Epoch 941: val_loss improved from 1.12270 to 1.12174, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0470 - mean_absolute_error: 0.7268 - mean_squared_error: 1.0470 - val_loss: 1.1217 - val_mean_absolute_error: 0.7506 - val_mean_squared_error: 1.1217\n",
            "Epoch 942/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.0571 - mean_absolute_error: 0.7292 - mean_squared_error: 1.0571\n",
            "Epoch 942: val_loss improved from 1.12174 to 1.11942, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0473 - mean_absolute_error: 0.7254 - mean_squared_error: 1.0473 - val_loss: 1.1194 - val_mean_absolute_error: 0.7500 - val_mean_squared_error: 1.1194\n",
            "Epoch 943/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.0319 - mean_absolute_error: 0.7203 - mean_squared_error: 1.0319\n",
            "Epoch 943: val_loss improved from 1.11942 to 1.11869, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0436 - mean_absolute_error: 0.7241 - mean_squared_error: 1.0436 - val_loss: 1.1187 - val_mean_absolute_error: 0.7514 - val_mean_squared_error: 1.1187\n",
            "Epoch 944/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.0484 - mean_absolute_error: 0.7269 - mean_squared_error: 1.0484\n",
            "Epoch 944: val_loss did not improve from 1.11869\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0429 - mean_absolute_error: 0.7248 - mean_squared_error: 1.0429 - val_loss: 1.1218 - val_mean_absolute_error: 0.7545 - val_mean_squared_error: 1.1218\n",
            "Epoch 945/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.0470 - mean_absolute_error: 0.7276 - mean_squared_error: 1.0470\n",
            "Epoch 945: val_loss improved from 1.11869 to 1.11855, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.0423 - mean_absolute_error: 0.7268 - mean_squared_error: 1.0423 - val_loss: 1.1186 - val_mean_absolute_error: 0.7517 - val_mean_squared_error: 1.1186\n",
            "Epoch 946/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.0448 - mean_absolute_error: 0.7241 - mean_squared_error: 1.0448\n",
            "Epoch 946: val_loss improved from 1.11855 to 1.11523, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0383 - mean_absolute_error: 0.7220 - mean_squared_error: 1.0383 - val_loss: 1.1152 - val_mean_absolute_error: 0.7510 - val_mean_squared_error: 1.1152\n",
            "Epoch 947/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.0463 - mean_absolute_error: 0.7265 - mean_squared_error: 1.0463\n",
            "Epoch 947: val_loss improved from 1.11523 to 1.11186, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0368 - mean_absolute_error: 0.7224 - mean_squared_error: 1.0368 - val_loss: 1.1119 - val_mean_absolute_error: 0.7491 - val_mean_squared_error: 1.1119\n",
            "Epoch 948/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.0407 - mean_absolute_error: 0.7257 - mean_squared_error: 1.0407\n",
            "Epoch 948: val_loss improved from 1.11186 to 1.10985, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0367 - mean_absolute_error: 0.7234 - mean_squared_error: 1.0367 - val_loss: 1.1099 - val_mean_absolute_error: 0.7472 - val_mean_squared_error: 1.1099\n",
            "Epoch 949/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.0422 - mean_absolute_error: 0.7251 - mean_squared_error: 1.0422\n",
            "Epoch 949: val_loss improved from 1.10985 to 1.10785, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0359 - mean_absolute_error: 0.7226 - mean_squared_error: 1.0359 - val_loss: 1.1078 - val_mean_absolute_error: 0.7467 - val_mean_squared_error: 1.1078\n",
            "Epoch 950/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.0250 - mean_absolute_error: 0.7195 - mean_squared_error: 1.0250\n",
            "Epoch 950: val_loss did not improve from 1.10785\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.0332 - mean_absolute_error: 0.7213 - mean_squared_error: 1.0332 - val_loss: 1.1172 - val_mean_absolute_error: 0.7548 - val_mean_squared_error: 1.1172\n",
            "Epoch 951/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.0341 - mean_absolute_error: 0.7227 - mean_squared_error: 1.0341\n",
            "Epoch 951: val_loss did not improve from 1.10785\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0319 - mean_absolute_error: 0.7217 - mean_squared_error: 1.0319 - val_loss: 1.1083 - val_mean_absolute_error: 0.7491 - val_mean_squared_error: 1.1083\n",
            "Epoch 952/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.0311 - mean_absolute_error: 0.7204 - mean_squared_error: 1.0311\n",
            "Epoch 952: val_loss improved from 1.10785 to 1.10784, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.0287 - mean_absolute_error: 0.7195 - mean_squared_error: 1.0287 - val_loss: 1.1078 - val_mean_absolute_error: 0.7496 - val_mean_squared_error: 1.1078\n",
            "Epoch 953/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.0358 - mean_absolute_error: 0.7221 - mean_squared_error: 1.0358\n",
            "Epoch 953: val_loss improved from 1.10784 to 1.10716, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0297 - mean_absolute_error: 0.7205 - mean_squared_error: 1.0297 - val_loss: 1.1072 - val_mean_absolute_error: 0.7496 - val_mean_squared_error: 1.1072\n",
            "Epoch 954/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.0260 - mean_absolute_error: 0.7201 - mean_squared_error: 1.0260\n",
            "Epoch 954: val_loss improved from 1.10716 to 1.09993, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0264 - mean_absolute_error: 0.7194 - mean_squared_error: 1.0264 - val_loss: 1.0999 - val_mean_absolute_error: 0.7449 - val_mean_squared_error: 1.0999\n",
            "Epoch 955/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.0081 - mean_absolute_error: 0.7134 - mean_squared_error: 1.0081\n",
            "Epoch 955: val_loss did not improve from 1.09993\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0237 - mean_absolute_error: 0.7178 - mean_squared_error: 1.0237 - val_loss: 1.1055 - val_mean_absolute_error: 0.7509 - val_mean_squared_error: 1.1055\n",
            "Epoch 956/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.0104 - mean_absolute_error: 0.7140 - mean_squared_error: 1.0104\n",
            "Epoch 956: val_loss improved from 1.09993 to 1.09651, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0237 - mean_absolute_error: 0.7193 - mean_squared_error: 1.0237 - val_loss: 1.0965 - val_mean_absolute_error: 0.7439 - val_mean_squared_error: 1.0965\n",
            "Epoch 957/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.0276 - mean_absolute_error: 0.7231 - mean_squared_error: 1.0276\n",
            "Epoch 957: val_loss improved from 1.09651 to 1.09500, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0221 - mean_absolute_error: 0.7187 - mean_squared_error: 1.0221 - val_loss: 1.0950 - val_mean_absolute_error: 0.7423 - val_mean_squared_error: 1.0950\n",
            "Epoch 958/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.0173 - mean_absolute_error: 0.7168 - mean_squared_error: 1.0173\n",
            "Epoch 958: val_loss did not improve from 1.09500\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0198 - mean_absolute_error: 0.7172 - mean_squared_error: 1.0198 - val_loss: 1.1048 - val_mean_absolute_error: 0.7503 - val_mean_squared_error: 1.1048\n",
            "Epoch 959/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.0158 - mean_absolute_error: 0.7152 - mean_squared_error: 1.0158\n",
            "Epoch 959: val_loss did not improve from 1.09500\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0167 - mean_absolute_error: 0.7152 - mean_squared_error: 1.0167 - val_loss: 1.0971 - val_mean_absolute_error: 0.7462 - val_mean_squared_error: 1.0971\n",
            "Epoch 960/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.0201 - mean_absolute_error: 0.7180 - mean_squared_error: 1.0201\n",
            "Epoch 960: val_loss did not improve from 1.09500\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0173 - mean_absolute_error: 0.7165 - mean_squared_error: 1.0173 - val_loss: 1.1006 - val_mean_absolute_error: 0.7499 - val_mean_squared_error: 1.1006\n",
            "Epoch 961/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.0179 - mean_absolute_error: 0.7164 - mean_squared_error: 1.0179\n",
            "Epoch 961: val_loss improved from 1.09500 to 1.09045, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0165 - mean_absolute_error: 0.7162 - mean_squared_error: 1.0165 - val_loss: 1.0904 - val_mean_absolute_error: 0.7427 - val_mean_squared_error: 1.0904\n",
            "Epoch 962/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.0343 - mean_absolute_error: 0.7238 - mean_squared_error: 1.0343\n",
            "Epoch 962: val_loss improved from 1.09045 to 1.08930, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0147 - mean_absolute_error: 0.7160 - mean_squared_error: 1.0147 - val_loss: 1.0893 - val_mean_absolute_error: 0.7427 - val_mean_squared_error: 1.0893\n",
            "Epoch 963/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.0224 - mean_absolute_error: 0.7180 - mean_squared_error: 1.0224\n",
            "Epoch 963: val_loss improved from 1.08930 to 1.08569, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0131 - mean_absolute_error: 0.7140 - mean_squared_error: 1.0131 - val_loss: 1.0857 - val_mean_absolute_error: 0.7411 - val_mean_squared_error: 1.0857\n",
            "Epoch 964/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.0089 - mean_absolute_error: 0.7136 - mean_squared_error: 1.0089\n",
            "Epoch 964: val_loss improved from 1.08569 to 1.08370, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0126 - mean_absolute_error: 0.7140 - mean_squared_error: 1.0126 - val_loss: 1.0837 - val_mean_absolute_error: 0.7399 - val_mean_squared_error: 1.0837\n",
            "Epoch 965/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.9979 - mean_absolute_error: 0.7113 - mean_squared_error: 0.9979\n",
            "Epoch 965: val_loss did not improve from 1.08370\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0091 - mean_absolute_error: 0.7140 - mean_squared_error: 1.0091 - val_loss: 1.0886 - val_mean_absolute_error: 0.7451 - val_mean_squared_error: 1.0886\n",
            "Epoch 966/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.0105 - mean_absolute_error: 0.7151 - mean_squared_error: 1.0105\n",
            "Epoch 966: val_loss improved from 1.08370 to 1.08161, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0082 - mean_absolute_error: 0.7140 - mean_squared_error: 1.0082 - val_loss: 1.0816 - val_mean_absolute_error: 0.7399 - val_mean_squared_error: 1.0816\n",
            "Epoch 967/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.9816 - mean_absolute_error: 0.7058 - mean_squared_error: 0.9816\n",
            "Epoch 967: val_loss improved from 1.08161 to 1.08114, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0065 - mean_absolute_error: 0.7123 - mean_squared_error: 1.0065 - val_loss: 1.0811 - val_mean_absolute_error: 0.7403 - val_mean_squared_error: 1.0811\n",
            "Epoch 968/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.9958 - mean_absolute_error: 0.7091 - mean_squared_error: 0.9958\n",
            "Epoch 968: val_loss improved from 1.08114 to 1.07943, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0045 - mean_absolute_error: 0.7119 - mean_squared_error: 1.0045 - val_loss: 1.0794 - val_mean_absolute_error: 0.7406 - val_mean_squared_error: 1.0794\n",
            "Epoch 969/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.0105 - mean_absolute_error: 0.7147 - mean_squared_error: 1.0105\n",
            "Epoch 969: val_loss improved from 1.07943 to 1.07580, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0040 - mean_absolute_error: 0.7135 - mean_squared_error: 1.0040 - val_loss: 1.0758 - val_mean_absolute_error: 0.7378 - val_mean_squared_error: 1.0758\n",
            "Epoch 970/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.9976 - mean_absolute_error: 0.7106 - mean_squared_error: 0.9976\n",
            "Epoch 970: val_loss improved from 1.07580 to 1.07518, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0027 - mean_absolute_error: 0.7106 - mean_squared_error: 1.0027 - val_loss: 1.0752 - val_mean_absolute_error: 0.7384 - val_mean_squared_error: 1.0752\n",
            "Epoch 971/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.9988 - mean_absolute_error: 0.7108 - mean_squared_error: 0.9988\n",
            "Epoch 971: val_loss improved from 1.07518 to 1.07511, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0012 - mean_absolute_error: 0.7125 - mean_squared_error: 1.0012 - val_loss: 1.0751 - val_mean_absolute_error: 0.7389 - val_mean_squared_error: 1.0751\n",
            "Epoch 972/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.0075 - mean_absolute_error: 0.7145 - mean_squared_error: 1.0075\n",
            "Epoch 972: val_loss did not improve from 1.07511\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0005 - mean_absolute_error: 0.7117 - mean_squared_error: 1.0005 - val_loss: 1.0904 - val_mean_absolute_error: 0.7508 - val_mean_squared_error: 1.0904\n",
            "Epoch 973/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 0.9954 - mean_absolute_error: 0.7103 - mean_squared_error: 0.9954\n",
            "Epoch 973: val_loss did not improve from 1.07511\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9992 - mean_absolute_error: 0.7111 - mean_squared_error: 0.9992 - val_loss: 1.0754 - val_mean_absolute_error: 0.7408 - val_mean_squared_error: 1.0754\n",
            "Epoch 974/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.9956 - mean_absolute_error: 0.7098 - mean_squared_error: 0.9956\n",
            "Epoch 974: val_loss improved from 1.07511 to 1.07295, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9973 - mean_absolute_error: 0.7107 - mean_squared_error: 0.9973 - val_loss: 1.0729 - val_mean_absolute_error: 0.7400 - val_mean_squared_error: 1.0729\n",
            "Epoch 975/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.9923 - mean_absolute_error: 0.7082 - mean_squared_error: 0.9923\n",
            "Epoch 975: val_loss did not improve from 1.07295\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9946 - mean_absolute_error: 0.7102 - mean_squared_error: 0.9946 - val_loss: 1.0777 - val_mean_absolute_error: 0.7434 - val_mean_squared_error: 1.0777\n",
            "Epoch 976/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.9983 - mean_absolute_error: 0.7116 - mean_squared_error: 0.9983\n",
            "Epoch 976: val_loss did not improve from 1.07295\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9924 - mean_absolute_error: 0.7093 - mean_squared_error: 0.9924 - val_loss: 1.0742 - val_mean_absolute_error: 0.7416 - val_mean_squared_error: 1.0742\n",
            "Epoch 977/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.9896 - mean_absolute_error: 0.7101 - mean_squared_error: 0.9896\n",
            "Epoch 977: val_loss improved from 1.07295 to 1.06490, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9912 - mean_absolute_error: 0.7099 - mean_squared_error: 0.9912 - val_loss: 1.0649 - val_mean_absolute_error: 0.7345 - val_mean_squared_error: 1.0649\n",
            "Epoch 978/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.9896 - mean_absolute_error: 0.7076 - mean_squared_error: 0.9896\n",
            "Epoch 978: val_loss did not improve from 1.06490\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9899 - mean_absolute_error: 0.7084 - mean_squared_error: 0.9899 - val_loss: 1.0755 - val_mean_absolute_error: 0.7443 - val_mean_squared_error: 1.0755\n",
            "Epoch 979/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.9914 - mean_absolute_error: 0.7089 - mean_squared_error: 0.9914\n",
            "Epoch 979: val_loss improved from 1.06490 to 1.06384, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9870 - mean_absolute_error: 0.7077 - mean_squared_error: 0.9870 - val_loss: 1.0638 - val_mean_absolute_error: 0.7356 - val_mean_squared_error: 1.0638\n",
            "Epoch 980/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.9793 - mean_absolute_error: 0.7029 - mean_squared_error: 0.9793\n",
            "Epoch 980: val_loss did not improve from 1.06384\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9876 - mean_absolute_error: 0.7076 - mean_squared_error: 0.9876 - val_loss: 1.0709 - val_mean_absolute_error: 0.7419 - val_mean_squared_error: 1.0709\n",
            "Epoch 981/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.9908 - mean_absolute_error: 0.7101 - mean_squared_error: 0.9908\n",
            "Epoch 981: val_loss improved from 1.06384 to 1.05865, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9859 - mean_absolute_error: 0.7081 - mean_squared_error: 0.9859 - val_loss: 1.0587 - val_mean_absolute_error: 0.7325 - val_mean_squared_error: 1.0587\n",
            "Epoch 982/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.9854 - mean_absolute_error: 0.7067 - mean_squared_error: 0.9854\n",
            "Epoch 982: val_loss did not improve from 1.05865\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9859 - mean_absolute_error: 0.7072 - mean_squared_error: 0.9859 - val_loss: 1.0603 - val_mean_absolute_error: 0.7338 - val_mean_squared_error: 1.0603\n",
            "Epoch 983/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.9801 - mean_absolute_error: 0.7042 - mean_squared_error: 0.9801\n",
            "Epoch 983: val_loss did not improve from 1.05865\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9823 - mean_absolute_error: 0.7050 - mean_squared_error: 0.9823 - val_loss: 1.0728 - val_mean_absolute_error: 0.7454 - val_mean_squared_error: 1.0728\n",
            "Epoch 984/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.9860 - mean_absolute_error: 0.7080 - mean_squared_error: 0.9860\n",
            "Epoch 984: val_loss improved from 1.05865 to 1.05385, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9839 - mean_absolute_error: 0.7070 - mean_squared_error: 0.9839 - val_loss: 1.0538 - val_mean_absolute_error: 0.7329 - val_mean_squared_error: 1.0538\n",
            "Epoch 985/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.9760 - mean_absolute_error: 0.7049 - mean_squared_error: 0.9760\n",
            "Epoch 985: val_loss did not improve from 1.05385\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9803 - mean_absolute_error: 0.7060 - mean_squared_error: 0.9803 - val_loss: 1.0557 - val_mean_absolute_error: 0.7346 - val_mean_squared_error: 1.0557\n",
            "Epoch 986/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.9811 - mean_absolute_error: 0.7064 - mean_squared_error: 0.9811\n",
            "Epoch 986: val_loss improved from 1.05385 to 1.05180, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9814 - mean_absolute_error: 0.7077 - mean_squared_error: 0.9814 - val_loss: 1.0518 - val_mean_absolute_error: 0.7328 - val_mean_squared_error: 1.0518\n",
            "Epoch 987/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.9796 - mean_absolute_error: 0.7049 - mean_squared_error: 0.9796\n",
            "Epoch 987: val_loss improved from 1.05180 to 1.05107, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9782 - mean_absolute_error: 0.7047 - mean_squared_error: 0.9782 - val_loss: 1.0511 - val_mean_absolute_error: 0.7328 - val_mean_squared_error: 1.0511\n",
            "Epoch 988/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.9781 - mean_absolute_error: 0.7059 - mean_squared_error: 0.9781\n",
            "Epoch 988: val_loss improved from 1.05107 to 1.05068, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9765 - mean_absolute_error: 0.7051 - mean_squared_error: 0.9765 - val_loss: 1.0507 - val_mean_absolute_error: 0.7328 - val_mean_squared_error: 1.0507\n",
            "Epoch 989/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.9726 - mean_absolute_error: 0.7034 - mean_squared_error: 0.9726\n",
            "Epoch 989: val_loss improved from 1.05068 to 1.04771, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9741 - mean_absolute_error: 0.7042 - mean_squared_error: 0.9741 - val_loss: 1.0477 - val_mean_absolute_error: 0.7302 - val_mean_squared_error: 1.0477\n",
            "Epoch 990/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.9849 - mean_absolute_error: 0.7088 - mean_squared_error: 0.9849\n",
            "Epoch 990: val_loss did not improve from 1.04771\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9742 - mean_absolute_error: 0.7047 - mean_squared_error: 0.9742 - val_loss: 1.0502 - val_mean_absolute_error: 0.7339 - val_mean_squared_error: 1.0502\n",
            "Epoch 991/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.9723 - mean_absolute_error: 0.7032 - mean_squared_error: 0.9723\n",
            "Epoch 991: val_loss improved from 1.04771 to 1.04440, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9715 - mean_absolute_error: 0.7032 - mean_squared_error: 0.9715 - val_loss: 1.0444 - val_mean_absolute_error: 0.7306 - val_mean_squared_error: 1.0444\n",
            "Epoch 992/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.9770 - mean_absolute_error: 0.7070 - mean_squared_error: 0.9770\n",
            "Epoch 992: val_loss improved from 1.04440 to 1.04434, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9720 - mean_absolute_error: 0.7036 - mean_squared_error: 0.9720 - val_loss: 1.0443 - val_mean_absolute_error: 0.7313 - val_mean_squared_error: 1.0443\n",
            "Epoch 993/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.9749 - mean_absolute_error: 0.7064 - mean_squared_error: 0.9749\n",
            "Epoch 993: val_loss did not improve from 1.04434\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9691 - mean_absolute_error: 0.7039 - mean_squared_error: 0.9691 - val_loss: 1.0453 - val_mean_absolute_error: 0.7333 - val_mean_squared_error: 1.0453\n",
            "Epoch 994/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.9677 - mean_absolute_error: 0.7038 - mean_squared_error: 0.9677\n",
            "Epoch 994: val_loss improved from 1.04434 to 1.04118, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9676 - mean_absolute_error: 0.7036 - mean_squared_error: 0.9676 - val_loss: 1.0412 - val_mean_absolute_error: 0.7296 - val_mean_squared_error: 1.0412\n",
            "Epoch 995/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 0.9712 - mean_absolute_error: 0.7033 - mean_squared_error: 0.9712\n",
            "Epoch 995: val_loss did not improve from 1.04118\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9664 - mean_absolute_error: 0.7019 - mean_squared_error: 0.9664 - val_loss: 1.0628 - val_mean_absolute_error: 0.7466 - val_mean_squared_error: 1.0628\n",
            "Epoch 996/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.9651 - mean_absolute_error: 0.7038 - mean_squared_error: 0.9651\n",
            "Epoch 996: val_loss improved from 1.04118 to 1.04043, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9679 - mean_absolute_error: 0.7040 - mean_squared_error: 0.9679 - val_loss: 1.0404 - val_mean_absolute_error: 0.7310 - val_mean_squared_error: 1.0404\n",
            "Epoch 997/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.9601 - mean_absolute_error: 0.7011 - mean_squared_error: 0.9601\n",
            "Epoch 997: val_loss did not improve from 1.04043\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9639 - mean_absolute_error: 0.7030 - mean_squared_error: 0.9639 - val_loss: 1.0434 - val_mean_absolute_error: 0.7336 - val_mean_squared_error: 1.0434\n",
            "Epoch 998/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.9734 - mean_absolute_error: 0.7065 - mean_squared_error: 0.9734\n",
            "Epoch 998: val_loss improved from 1.04043 to 1.03751, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9626 - mean_absolute_error: 0.7021 - mean_squared_error: 0.9626 - val_loss: 1.0375 - val_mean_absolute_error: 0.7293 - val_mean_squared_error: 1.0375\n",
            "Epoch 999/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 0.9708 - mean_absolute_error: 0.7035 - mean_squared_error: 0.9708\n",
            "Epoch 999: val_loss improved from 1.03751 to 1.03399, saving model to best_model4.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9594 - mean_absolute_error: 0.6991 - mean_squared_error: 0.9594 - val_loss: 1.0340 - val_mean_absolute_error: 0.7294 - val_mean_squared_error: 1.0340\n",
            "Epoch 1000/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.9609 - mean_absolute_error: 0.7007 - mean_squared_error: 0.9609\n",
            "Epoch 1000: val_loss did not improve from 1.03399\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9594 - mean_absolute_error: 0.7006 - mean_squared_error: 0.9594 - val_loss: 1.0364 - val_mean_absolute_error: 0.7322 - val_mean_squared_error: 1.0364\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f848adc3dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = load_model('best_model4.h5')\n",
        "\n",
        "z_predict_test4 = model4.predict(Z_test)\n",
        "\n",
        "plt.plot(z_predict_test4,z_test,'.')\n",
        "\n",
        "print('MSE:', mean_squared_error(z_test, z_predict_test4))\n",
        "print('MAE:', mean_absolute_error(z_test, z_predict_test4))\n",
        "print('RMSE:', mean_squared_error(z_test, z_predict_test4)**0.5)\n",
        "print('Spearman R:', spearmanr(z_test, z_predict_test4))\n",
        "print('R2:', r2_score(z_test, z_predict_test4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "8nWIOv_xlhLn",
        "outputId": "4310f601-844d-4ce0-fb86-151da844dbaa"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 0s 1ms/step\n",
            "MSE: 0.9939577929832596\n",
            "MAE: 0.7181265381211597\n",
            "RMSE: 0.9969743191192337\n",
            "Spearman R: SpearmanrResult(correlation=0.8647837049759671, pvalue=0.0)\n",
            "R2: 0.7212592063975272\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1 capa escondida, 50 neuronas:\n",
        "\n",
        "model5 = Sequential()\n",
        "#model.add(Dense(100, input_dim=2, activation='sigmoid'))\n",
        "model5.add(Dense(50, input_dim=2, activation='sigmoid'))\n",
        "model5.add(Dense(1, activation='linear'))\n",
        "\n",
        "model5.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error', 'mean_squared_error'])\n",
        "model5.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7WCics8QTkH",
        "outputId": "b61b5f75-4726-4491-e5a5-42a9ff03403d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_7 (Dense)             (None, 50)                150       \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 201\n",
            "Trainable params: 201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ajuste:\n",
        "es5 = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "mc5 = ModelCheckpoint('best_model5.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)"
      ],
      "metadata": {
        "id": "R-L-AwzqQcSx"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model5.fit(Z_train, z_train, epochs=1000, batch_size=20, validation_split=0.3, shuffle=True, verbose=True, callbacks=[es5,mc5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af4YxTnHQirp",
        "outputId": "8ac8ca2f-d87b-4de5-b064-5e4dc0875cc6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 3.6878 - mean_absolute_error: 1.2568 - mean_squared_error: 3.6878\n",
            "Epoch 1: val_loss improved from inf to 3.49359, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.6983 - mean_absolute_error: 1.2564 - mean_squared_error: 3.6983 - val_loss: 3.4936 - val_mean_absolute_error: 1.1771 - val_mean_squared_error: 3.4936\n",
            "Epoch 2/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 3.5521 - mean_absolute_error: 1.2088 - mean_squared_error: 3.5521\n",
            "Epoch 2: val_loss improved from 3.49359 to 3.38333, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.5521 - mean_absolute_error: 1.2088 - mean_squared_error: 3.5521 - val_loss: 3.3833 - val_mean_absolute_error: 1.2011 - val_mean_squared_error: 3.3833\n",
            "Epoch 3/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 3.4718 - mean_absolute_error: 1.1960 - mean_squared_error: 3.4718\n",
            "Epoch 3: val_loss improved from 3.38333 to 3.26382, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.4424 - mean_absolute_error: 1.1923 - mean_squared_error: 3.4424 - val_loss: 3.2638 - val_mean_absolute_error: 1.1401 - val_mean_squared_error: 3.2638\n",
            "Epoch 4/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 3.3728 - mean_absolute_error: 1.1830 - mean_squared_error: 3.3728\n",
            "Epoch 4: val_loss improved from 3.26382 to 3.17847, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.3460 - mean_absolute_error: 1.1781 - mean_squared_error: 3.3460 - val_loss: 3.1785 - val_mean_absolute_error: 1.1443 - val_mean_squared_error: 3.1785\n",
            "Epoch 5/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 3.3089 - mean_absolute_error: 1.1943 - mean_squared_error: 3.3089\n",
            "Epoch 5: val_loss improved from 3.17847 to 3.11705, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.2620 - mean_absolute_error: 1.1837 - mean_squared_error: 3.2620 - val_loss: 3.1171 - val_mean_absolute_error: 1.1693 - val_mean_squared_error: 3.1171\n",
            "Epoch 6/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 3.2094 - mean_absolute_error: 1.2024 - mean_squared_error: 3.2094\n",
            "Epoch 6: val_loss improved from 3.11705 to 3.07406, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.2209 - mean_absolute_error: 1.2034 - mean_squared_error: 3.2209 - val_loss: 3.0741 - val_mean_absolute_error: 1.1791 - val_mean_squared_error: 3.0741\n",
            "Epoch 7/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 3.1798 - mean_absolute_error: 1.2185 - mean_squared_error: 3.1798\n",
            "Epoch 7: val_loss improved from 3.07406 to 3.06083, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1850 - mean_absolute_error: 1.2181 - mean_squared_error: 3.1850 - val_loss: 3.0608 - val_mean_absolute_error: 1.1924 - val_mean_squared_error: 3.0608\n",
            "Epoch 8/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 3.1900 - mean_absolute_error: 1.2404 - mean_squared_error: 3.1900\n",
            "Epoch 8: val_loss improved from 3.06083 to 3.04015, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1676 - mean_absolute_error: 1.2318 - mean_squared_error: 3.1676 - val_loss: 3.0402 - val_mean_absolute_error: 1.2092 - val_mean_squared_error: 3.0402\n",
            "Epoch 9/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 3.1419 - mean_absolute_error: 1.2393 - mean_squared_error: 3.1419\n",
            "Epoch 9: val_loss improved from 3.04015 to 3.03379, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1580 - mean_absolute_error: 1.2409 - mean_squared_error: 3.1580 - val_loss: 3.0338 - val_mean_absolute_error: 1.2170 - val_mean_squared_error: 3.0338\n",
            "Epoch 10/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 3.1430 - mean_absolute_error: 1.2503 - mean_squared_error: 3.1430\n",
            "Epoch 10: val_loss improved from 3.03379 to 3.03153, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1523 - mean_absolute_error: 1.2480 - mean_squared_error: 3.1523 - val_loss: 3.0315 - val_mean_absolute_error: 1.2245 - val_mean_squared_error: 3.0315\n",
            "Epoch 11/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 3.1541 - mean_absolute_error: 1.2546 - mean_squared_error: 3.1541\n",
            "Epoch 11: val_loss improved from 3.03153 to 3.02931, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1508 - mean_absolute_error: 1.2547 - mean_squared_error: 3.1508 - val_loss: 3.0293 - val_mean_absolute_error: 1.2297 - val_mean_squared_error: 3.0293\n",
            "Epoch 12/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 3.1769 - mean_absolute_error: 1.2652 - mean_squared_error: 3.1769\n",
            "Epoch 12: val_loss improved from 3.02931 to 3.02868, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1527 - mean_absolute_error: 1.2607 - mean_squared_error: 3.1527 - val_loss: 3.0287 - val_mean_absolute_error: 1.2311 - val_mean_squared_error: 3.0287\n",
            "Epoch 13/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 3.1593 - mean_absolute_error: 1.2602 - mean_squared_error: 3.1593\n",
            "Epoch 13: val_loss did not improve from 3.02868\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1504 - mean_absolute_error: 1.2607 - mean_squared_error: 3.1504 - val_loss: 3.0301 - val_mean_absolute_error: 1.2352 - val_mean_squared_error: 3.0301\n",
            "Epoch 14/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 3.0953 - mean_absolute_error: 1.2513 - mean_squared_error: 3.0953\n",
            "Epoch 14: val_loss did not improve from 3.02868\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1499 - mean_absolute_error: 1.2624 - mean_squared_error: 3.1499 - val_loss: 3.0308 - val_mean_absolute_error: 1.2365 - val_mean_squared_error: 3.0308\n",
            "Epoch 15/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 3.1247 - mean_absolute_error: 1.2569 - mean_squared_error: 3.1247\n",
            "Epoch 15: val_loss did not improve from 3.02868\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1516 - mean_absolute_error: 1.2637 - mean_squared_error: 3.1516 - val_loss: 3.0311 - val_mean_absolute_error: 1.2381 - val_mean_squared_error: 3.0311\n",
            "Epoch 16/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 3.1371 - mean_absolute_error: 1.2634 - mean_squared_error: 3.1371\n",
            "Epoch 16: val_loss did not improve from 3.02868\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1516 - mean_absolute_error: 1.2656 - mean_squared_error: 3.1516 - val_loss: 3.0376 - val_mean_absolute_error: 1.2419 - val_mean_squared_error: 3.0376\n",
            "Epoch 17/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 3.1171 - mean_absolute_error: 1.2601 - mean_squared_error: 3.1171\n",
            "Epoch 17: val_loss did not improve from 3.02868\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1476 - mean_absolute_error: 1.2651 - mean_squared_error: 3.1476 - val_loss: 3.0337 - val_mean_absolute_error: 1.2408 - val_mean_squared_error: 3.0337\n",
            "Epoch 18/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 3.1093 - mean_absolute_error: 1.2569 - mean_squared_error: 3.1093\n",
            "Epoch 18: val_loss improved from 3.02868 to 3.02783, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1502 - mean_absolute_error: 1.2668 - mean_squared_error: 3.1502 - val_loss: 3.0278 - val_mean_absolute_error: 1.2368 - val_mean_squared_error: 3.0278\n",
            "Epoch 19/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 3.1508 - mean_absolute_error: 1.2679 - mean_squared_error: 3.1508\n",
            "Epoch 19: val_loss did not improve from 3.02783\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1508 - mean_absolute_error: 1.2679 - mean_squared_error: 3.1508 - val_loss: 3.0357 - val_mean_absolute_error: 1.2415 - val_mean_squared_error: 3.0357\n",
            "Epoch 20/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 3.1587 - mean_absolute_error: 1.2678 - mean_squared_error: 3.1587\n",
            "Epoch 20: val_loss did not improve from 3.02783\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1491 - mean_absolute_error: 1.2649 - mean_squared_error: 3.1491 - val_loss: 3.0368 - val_mean_absolute_error: 1.2417 - val_mean_squared_error: 3.0368\n",
            "Epoch 21/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 3.1350 - mean_absolute_error: 1.2632 - mean_squared_error: 3.1350\n",
            "Epoch 21: val_loss did not improve from 3.02783\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1484 - mean_absolute_error: 1.2659 - mean_squared_error: 3.1484 - val_loss: 3.0284 - val_mean_absolute_error: 1.2384 - val_mean_squared_error: 3.0284\n",
            "Epoch 22/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 3.0931 - mean_absolute_error: 1.2575 - mean_squared_error: 3.0931\n",
            "Epoch 22: val_loss did not improve from 3.02783\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1487 - mean_absolute_error: 1.2653 - mean_squared_error: 3.1487 - val_loss: 3.0402 - val_mean_absolute_error: 1.2441 - val_mean_squared_error: 3.0402\n",
            "Epoch 23/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 3.1274 - mean_absolute_error: 1.2641 - mean_squared_error: 3.1274\n",
            "Epoch 23: val_loss did not improve from 3.02783\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1542 - mean_absolute_error: 1.2673 - mean_squared_error: 3.1542 - val_loss: 3.0287 - val_mean_absolute_error: 1.2379 - val_mean_squared_error: 3.0287\n",
            "Epoch 24/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 3.1531 - mean_absolute_error: 1.2676 - mean_squared_error: 3.1531\n",
            "Epoch 24: val_loss improved from 3.02783 to 3.02733, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1531 - mean_absolute_error: 1.2676 - mean_squared_error: 3.1531 - val_loss: 3.0273 - val_mean_absolute_error: 1.2376 - val_mean_squared_error: 3.0273\n",
            "Epoch 25/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 3.1189 - mean_absolute_error: 1.2610 - mean_squared_error: 3.1189\n",
            "Epoch 25: val_loss did not improve from 3.02733\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1478 - mean_absolute_error: 1.2648 - mean_squared_error: 3.1478 - val_loss: 3.0283 - val_mean_absolute_error: 1.2372 - val_mean_squared_error: 3.0283\n",
            "Epoch 26/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 3.1397 - mean_absolute_error: 1.2649 - mean_squared_error: 3.1397\n",
            "Epoch 26: val_loss improved from 3.02733 to 3.02708, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1467 - mean_absolute_error: 1.2661 - mean_squared_error: 3.1467 - val_loss: 3.0271 - val_mean_absolute_error: 1.2381 - val_mean_squared_error: 3.0271\n",
            "Epoch 27/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 3.1521 - mean_absolute_error: 1.2638 - mean_squared_error: 3.1521\n",
            "Epoch 27: val_loss did not improve from 3.02708\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1426 - mean_absolute_error: 1.2619 - mean_squared_error: 3.1426 - val_loss: 3.1124 - val_mean_absolute_error: 1.2714 - val_mean_squared_error: 3.1124\n",
            "Epoch 28/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 3.1779 - mean_absolute_error: 1.2691 - mean_squared_error: 3.1779\n",
            "Epoch 28: val_loss did not improve from 3.02708\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1515 - mean_absolute_error: 1.2681 - mean_squared_error: 3.1515 - val_loss: 3.0682 - val_mean_absolute_error: 1.2569 - val_mean_squared_error: 3.0682\n",
            "Epoch 29/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 3.1342 - mean_absolute_error: 1.2658 - mean_squared_error: 3.1342\n",
            "Epoch 29: val_loss did not improve from 3.02708\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1532 - mean_absolute_error: 1.2690 - mean_squared_error: 3.1532 - val_loss: 3.0385 - val_mean_absolute_error: 1.2443 - val_mean_squared_error: 3.0385\n",
            "Epoch 30/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 3.1595 - mean_absolute_error: 1.2720 - mean_squared_error: 3.1595\n",
            "Epoch 30: val_loss did not improve from 3.02708\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1472 - mean_absolute_error: 1.2676 - mean_squared_error: 3.1472 - val_loss: 3.0401 - val_mean_absolute_error: 1.2450 - val_mean_squared_error: 3.0401\n",
            "Epoch 31/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 3.1757 - mean_absolute_error: 1.2740 - mean_squared_error: 3.1757\n",
            "Epoch 31: val_loss did not improve from 3.02708\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1464 - mean_absolute_error: 1.2673 - mean_squared_error: 3.1464 - val_loss: 3.0353 - val_mean_absolute_error: 1.2431 - val_mean_squared_error: 3.0353\n",
            "Epoch 32/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 3.1585 - mean_absolute_error: 1.2667 - mean_squared_error: 3.1585\n",
            "Epoch 32: val_loss improved from 3.02708 to 3.02651, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1525 - mean_absolute_error: 1.2668 - mean_squared_error: 3.1525 - val_loss: 3.0265 - val_mean_absolute_error: 1.2386 - val_mean_squared_error: 3.0265\n",
            "Epoch 33/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 3.1761 - mean_absolute_error: 1.2700 - mean_squared_error: 3.1761\n",
            "Epoch 33: val_loss did not improve from 3.02651\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1517 - mean_absolute_error: 1.2666 - mean_squared_error: 3.1517 - val_loss: 3.0268 - val_mean_absolute_error: 1.2374 - val_mean_squared_error: 3.0268\n",
            "Epoch 34/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 3.1570 - mean_absolute_error: 1.2660 - mean_squared_error: 3.1570\n",
            "Epoch 34: val_loss did not improve from 3.02651\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1475 - mean_absolute_error: 1.2650 - mean_squared_error: 3.1475 - val_loss: 3.0529 - val_mean_absolute_error: 1.2507 - val_mean_squared_error: 3.0529\n",
            "Epoch 35/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 3.1266 - mean_absolute_error: 1.2635 - mean_squared_error: 3.1266\n",
            "Epoch 35: val_loss did not improve from 3.02651\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1468 - mean_absolute_error: 1.2663 - mean_squared_error: 3.1468 - val_loss: 3.0323 - val_mean_absolute_error: 1.2381 - val_mean_squared_error: 3.0323\n",
            "Epoch 36/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 3.1142 - mean_absolute_error: 1.2586 - mean_squared_error: 3.1142\n",
            "Epoch 36: val_loss improved from 3.02651 to 3.02629, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1452 - mean_absolute_error: 1.2673 - mean_squared_error: 3.1452 - val_loss: 3.0263 - val_mean_absolute_error: 1.2382 - val_mean_squared_error: 3.0263\n",
            "Epoch 37/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 3.1498 - mean_absolute_error: 1.2707 - mean_squared_error: 3.1498\n",
            "Epoch 37: val_loss did not improve from 3.02629\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1495 - mean_absolute_error: 1.2669 - mean_squared_error: 3.1495 - val_loss: 3.0267 - val_mean_absolute_error: 1.2373 - val_mean_squared_error: 3.0267\n",
            "Epoch 38/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 3.1537 - mean_absolute_error: 1.2682 - mean_squared_error: 3.1537\n",
            "Epoch 38: val_loss improved from 3.02629 to 3.02590, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1482 - mean_absolute_error: 1.2668 - mean_squared_error: 3.1482 - val_loss: 3.0259 - val_mean_absolute_error: 1.2386 - val_mean_squared_error: 3.0259\n",
            "Epoch 39/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 3.1465 - mean_absolute_error: 1.2691 - mean_squared_error: 3.1465\n",
            "Epoch 39: val_loss did not improve from 3.02590\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1490 - mean_absolute_error: 1.2681 - mean_squared_error: 3.1490 - val_loss: 3.0275 - val_mean_absolute_error: 1.2385 - val_mean_squared_error: 3.0275\n",
            "Epoch 40/1000\n",
            "218/245 [=========================>....] - ETA: 0s - loss: 3.1447 - mean_absolute_error: 1.2659 - mean_squared_error: 3.1447\n",
            "Epoch 40: val_loss improved from 3.02590 to 3.02547, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1527 - mean_absolute_error: 1.2694 - mean_squared_error: 3.1527 - val_loss: 3.0255 - val_mean_absolute_error: 1.2377 - val_mean_squared_error: 3.0255\n",
            "Epoch 41/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 3.1459 - mean_absolute_error: 1.2641 - mean_squared_error: 3.1459\n",
            "Epoch 41: val_loss did not improve from 3.02547\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1442 - mean_absolute_error: 1.2651 - mean_squared_error: 3.1442 - val_loss: 3.0264 - val_mean_absolute_error: 1.2384 - val_mean_squared_error: 3.0264\n",
            "Epoch 42/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 3.1777 - mean_absolute_error: 1.2743 - mean_squared_error: 3.1777\n",
            "Epoch 42: val_loss did not improve from 3.02547\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1479 - mean_absolute_error: 1.2673 - mean_squared_error: 3.1479 - val_loss: 3.0262 - val_mean_absolute_error: 1.2367 - val_mean_squared_error: 3.0262\n",
            "Epoch 43/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 3.1258 - mean_absolute_error: 1.2651 - mean_squared_error: 3.1258\n",
            "Epoch 43: val_loss did not improve from 3.02547\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1481 - mean_absolute_error: 1.2669 - mean_squared_error: 3.1481 - val_loss: 3.0488 - val_mean_absolute_error: 1.2480 - val_mean_squared_error: 3.0488\n",
            "Epoch 44/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 3.1759 - mean_absolute_error: 1.2706 - mean_squared_error: 3.1759\n",
            "Epoch 44: val_loss did not improve from 3.02547\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1464 - mean_absolute_error: 1.2657 - mean_squared_error: 3.1464 - val_loss: 3.0298 - val_mean_absolute_error: 1.2376 - val_mean_squared_error: 3.0298\n",
            "Epoch 45/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 3.1660 - mean_absolute_error: 1.2685 - mean_squared_error: 3.1660\n",
            "Epoch 45: val_loss did not improve from 3.02547\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1455 - mean_absolute_error: 1.2650 - mean_squared_error: 3.1455 - val_loss: 3.0348 - val_mean_absolute_error: 1.2423 - val_mean_squared_error: 3.0348\n",
            "Epoch 46/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 3.1573 - mean_absolute_error: 1.2670 - mean_squared_error: 3.1573\n",
            "Epoch 46: val_loss did not improve from 3.02547\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1480 - mean_absolute_error: 1.2660 - mean_squared_error: 3.1480 - val_loss: 3.0268 - val_mean_absolute_error: 1.2395 - val_mean_squared_error: 3.0268\n",
            "Epoch 47/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 3.1432 - mean_absolute_error: 1.2656 - mean_squared_error: 3.1432\n",
            "Epoch 47: val_loss improved from 3.02547 to 3.02469, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1473 - mean_absolute_error: 1.2664 - mean_squared_error: 3.1473 - val_loss: 3.0247 - val_mean_absolute_error: 1.2372 - val_mean_squared_error: 3.0247\n",
            "Epoch 48/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 3.1779 - mean_absolute_error: 1.2750 - mean_squared_error: 3.1779\n",
            "Epoch 48: val_loss improved from 3.02469 to 3.02449, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1456 - mean_absolute_error: 1.2676 - mean_squared_error: 3.1456 - val_loss: 3.0245 - val_mean_absolute_error: 1.2376 - val_mean_squared_error: 3.0245\n",
            "Epoch 49/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 3.1375 - mean_absolute_error: 1.2632 - mean_squared_error: 3.1375\n",
            "Epoch 49: val_loss did not improve from 3.02449\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1506 - mean_absolute_error: 1.2648 - mean_squared_error: 3.1506 - val_loss: 3.0342 - val_mean_absolute_error: 1.2431 - val_mean_squared_error: 3.0342\n",
            "Epoch 50/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 3.1121 - mean_absolute_error: 1.2585 - mean_squared_error: 3.1121\n",
            "Epoch 50: val_loss improved from 3.02449 to 3.02426, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1448 - mean_absolute_error: 1.2665 - mean_squared_error: 3.1448 - val_loss: 3.0243 - val_mean_absolute_error: 1.2379 - val_mean_squared_error: 3.0243\n",
            "Epoch 51/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 3.1522 - mean_absolute_error: 1.2684 - mean_squared_error: 3.1522\n",
            "Epoch 51: val_loss did not improve from 3.02426\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1486 - mean_absolute_error: 1.2683 - mean_squared_error: 3.1486 - val_loss: 3.0290 - val_mean_absolute_error: 1.2405 - val_mean_squared_error: 3.0290\n",
            "Epoch 52/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 3.1309 - mean_absolute_error: 1.2619 - mean_squared_error: 3.1309\n",
            "Epoch 52: val_loss did not improve from 3.02426\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1453 - mean_absolute_error: 1.2638 - mean_squared_error: 3.1453 - val_loss: 3.0271 - val_mean_absolute_error: 1.2386 - val_mean_squared_error: 3.0271\n",
            "Epoch 53/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 3.1025 - mean_absolute_error: 1.2631 - mean_squared_error: 3.1025\n",
            "Epoch 53: val_loss did not improve from 3.02426\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1502 - mean_absolute_error: 1.2680 - mean_squared_error: 3.1502 - val_loss: 3.0488 - val_mean_absolute_error: 1.2489 - val_mean_squared_error: 3.0488\n",
            "Epoch 54/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 3.1678 - mean_absolute_error: 1.2707 - mean_squared_error: 3.1678\n",
            "Epoch 54: val_loss improved from 3.02426 to 3.02402, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1482 - mean_absolute_error: 1.2685 - mean_squared_error: 3.1482 - val_loss: 3.0240 - val_mean_absolute_error: 1.2374 - val_mean_squared_error: 3.0240\n",
            "Epoch 55/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 3.1526 - mean_absolute_error: 1.2653 - mean_squared_error: 3.1526\n",
            "Epoch 55: val_loss did not improve from 3.02402\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1465 - mean_absolute_error: 1.2660 - mean_squared_error: 3.1465 - val_loss: 3.0242 - val_mean_absolute_error: 1.2363 - val_mean_squared_error: 3.0242\n",
            "Epoch 56/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 3.1430 - mean_absolute_error: 1.2649 - mean_squared_error: 3.1430\n",
            "Epoch 56: val_loss did not improve from 3.02402\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1464 - mean_absolute_error: 1.2663 - mean_squared_error: 3.1464 - val_loss: 3.0245 - val_mean_absolute_error: 1.2369 - val_mean_squared_error: 3.0245\n",
            "Epoch 57/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 3.1370 - mean_absolute_error: 1.2625 - mean_squared_error: 3.1370\n",
            "Epoch 57: val_loss did not improve from 3.02402\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1486 - mean_absolute_error: 1.2653 - mean_squared_error: 3.1486 - val_loss: 3.0448 - val_mean_absolute_error: 1.2473 - val_mean_squared_error: 3.0448\n",
            "Epoch 58/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 3.1600 - mean_absolute_error: 1.2649 - mean_squared_error: 3.1600\n",
            "Epoch 58: val_loss did not improve from 3.02402\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1469 - mean_absolute_error: 1.2651 - mean_squared_error: 3.1469 - val_loss: 3.0336 - val_mean_absolute_error: 1.2427 - val_mean_squared_error: 3.0336\n",
            "Epoch 59/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 3.0980 - mean_absolute_error: 1.2559 - mean_squared_error: 3.0980\n",
            "Epoch 59: val_loss did not improve from 3.02402\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1397 - mean_absolute_error: 1.2637 - mean_squared_error: 3.1397 - val_loss: 3.0647 - val_mean_absolute_error: 1.2560 - val_mean_squared_error: 3.0647\n",
            "Epoch 60/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 3.0982 - mean_absolute_error: 1.2632 - mean_squared_error: 3.0982\n",
            "Epoch 60: val_loss did not improve from 3.02402\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1455 - mean_absolute_error: 1.2688 - mean_squared_error: 3.1455 - val_loss: 3.0275 - val_mean_absolute_error: 1.2406 - val_mean_squared_error: 3.0275\n",
            "Epoch 61/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 3.1450 - mean_absolute_error: 1.2663 - mean_squared_error: 3.1450\n",
            "Epoch 61: val_loss did not improve from 3.02402\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1450 - mean_absolute_error: 1.2663 - mean_squared_error: 3.1450 - val_loss: 3.0254 - val_mean_absolute_error: 1.2403 - val_mean_squared_error: 3.0254\n",
            "Epoch 62/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 3.1529 - mean_absolute_error: 1.2693 - mean_squared_error: 3.1529\n",
            "Epoch 62: val_loss improved from 3.02402 to 3.02262, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1433 - mean_absolute_error: 1.2679 - mean_squared_error: 3.1433 - val_loss: 3.0226 - val_mean_absolute_error: 1.2378 - val_mean_squared_error: 3.0226\n",
            "Epoch 63/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 3.0990 - mean_absolute_error: 1.2568 - mean_squared_error: 3.0990\n",
            "Epoch 63: val_loss did not improve from 3.02262\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1442 - mean_absolute_error: 1.2650 - mean_squared_error: 3.1442 - val_loss: 3.0316 - val_mean_absolute_error: 1.2424 - val_mean_squared_error: 3.0316\n",
            "Epoch 64/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 3.1463 - mean_absolute_error: 1.2670 - mean_squared_error: 3.1463\n",
            "Epoch 64: val_loss did not improve from 3.02262\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1463 - mean_absolute_error: 1.2668 - mean_squared_error: 3.1463 - val_loss: 3.0343 - val_mean_absolute_error: 1.2440 - val_mean_squared_error: 3.0343\n",
            "Epoch 65/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 3.1432 - mean_absolute_error: 1.2670 - mean_squared_error: 3.1432\n",
            "Epoch 65: val_loss did not improve from 3.02262\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1469 - mean_absolute_error: 1.2670 - mean_squared_error: 3.1469 - val_loss: 3.0243 - val_mean_absolute_error: 1.2396 - val_mean_squared_error: 3.0243\n",
            "Epoch 66/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 3.1425 - mean_absolute_error: 1.2671 - mean_squared_error: 3.1425\n",
            "Epoch 66: val_loss improved from 3.02262 to 3.02196, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1467 - mean_absolute_error: 1.2667 - mean_squared_error: 3.1467 - val_loss: 3.0220 - val_mean_absolute_error: 1.2384 - val_mean_squared_error: 3.0220\n",
            "Epoch 67/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 3.1656 - mean_absolute_error: 1.2715 - mean_squared_error: 3.1656\n",
            "Epoch 67: val_loss did not improve from 3.02196\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1429 - mean_absolute_error: 1.2670 - mean_squared_error: 3.1429 - val_loss: 3.0238 - val_mean_absolute_error: 1.2378 - val_mean_squared_error: 3.0238\n",
            "Epoch 68/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 3.1357 - mean_absolute_error: 1.2637 - mean_squared_error: 3.1357\n",
            "Epoch 68: val_loss did not improve from 3.02196\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1446 - mean_absolute_error: 1.2660 - mean_squared_error: 3.1446 - val_loss: 3.0376 - val_mean_absolute_error: 1.2459 - val_mean_squared_error: 3.0376\n",
            "Epoch 69/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 3.1390 - mean_absolute_error: 1.2637 - mean_squared_error: 3.1390\n",
            "Epoch 69: val_loss did not improve from 3.02196\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1416 - mean_absolute_error: 1.2643 - mean_squared_error: 3.1416 - val_loss: 3.0277 - val_mean_absolute_error: 1.2418 - val_mean_squared_error: 3.0277\n",
            "Epoch 70/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 3.1325 - mean_absolute_error: 1.2650 - mean_squared_error: 3.1325\n",
            "Epoch 70: val_loss did not improve from 3.02196\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1425 - mean_absolute_error: 1.2671 - mean_squared_error: 3.1425 - val_loss: 3.0272 - val_mean_absolute_error: 1.2409 - val_mean_squared_error: 3.0272\n",
            "Epoch 71/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 3.1638 - mean_absolute_error: 1.2737 - mean_squared_error: 3.1638\n",
            "Epoch 71: val_loss improved from 3.02196 to 3.02104, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1463 - mean_absolute_error: 1.2687 - mean_squared_error: 3.1463 - val_loss: 3.0210 - val_mean_absolute_error: 1.2376 - val_mean_squared_error: 3.0210\n",
            "Epoch 72/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 3.1417 - mean_absolute_error: 1.2658 - mean_squared_error: 3.1417\n",
            "Epoch 72: val_loss did not improve from 3.02104\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 3.1417 - mean_absolute_error: 1.2658 - mean_squared_error: 3.1417 - val_loss: 3.0367 - val_mean_absolute_error: 1.2444 - val_mean_squared_error: 3.0367\n",
            "Epoch 73/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 3.1333 - mean_absolute_error: 1.2608 - mean_squared_error: 3.1333\n",
            "Epoch 73: val_loss did not improve from 3.02104\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 3.1421 - mean_absolute_error: 1.2628 - mean_squared_error: 3.1421 - val_loss: 3.0517 - val_mean_absolute_error: 1.2517 - val_mean_squared_error: 3.0517\n",
            "Epoch 74/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 3.1573 - mean_absolute_error: 1.2671 - mean_squared_error: 3.1573\n",
            "Epoch 74: val_loss did not improve from 3.02104\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1452 - mean_absolute_error: 1.2659 - mean_squared_error: 3.1452 - val_loss: 3.0233 - val_mean_absolute_error: 1.2388 - val_mean_squared_error: 3.0233\n",
            "Epoch 75/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 3.1887 - mean_absolute_error: 1.2732 - mean_squared_error: 3.1887\n",
            "Epoch 75: val_loss improved from 3.02104 to 3.02021, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1422 - mean_absolute_error: 1.2665 - mean_squared_error: 3.1422 - val_loss: 3.0202 - val_mean_absolute_error: 1.2389 - val_mean_squared_error: 3.0202\n",
            "Epoch 76/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 3.1469 - mean_absolute_error: 1.2675 - mean_squared_error: 3.1469\n",
            "Epoch 76: val_loss did not improve from 3.02021\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1381 - mean_absolute_error: 1.2661 - mean_squared_error: 3.1381 - val_loss: 3.0385 - val_mean_absolute_error: 1.2415 - val_mean_squared_error: 3.0385\n",
            "Epoch 77/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 3.2093 - mean_absolute_error: 1.2717 - mean_squared_error: 3.2093\n",
            "Epoch 77: val_loss improved from 3.02021 to 3.01983, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1499 - mean_absolute_error: 1.2671 - mean_squared_error: 3.1499 - val_loss: 3.0198 - val_mean_absolute_error: 1.2390 - val_mean_squared_error: 3.0198\n",
            "Epoch 78/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 3.1509 - mean_absolute_error: 1.2679 - mean_squared_error: 3.1509\n",
            "Epoch 78: val_loss did not improve from 3.01983\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1468 - mean_absolute_error: 1.2680 - mean_squared_error: 3.1468 - val_loss: 3.0199 - val_mean_absolute_error: 1.2379 - val_mean_squared_error: 3.0199\n",
            "Epoch 79/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 3.1616 - mean_absolute_error: 1.2685 - mean_squared_error: 3.1616\n",
            "Epoch 79: val_loss did not improve from 3.01983\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1433 - mean_absolute_error: 1.2675 - mean_squared_error: 3.1433 - val_loss: 3.0213 - val_mean_absolute_error: 1.2370 - val_mean_squared_error: 3.0213\n",
            "Epoch 80/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 3.1318 - mean_absolute_error: 1.2634 - mean_squared_error: 3.1318\n",
            "Epoch 80: val_loss improved from 3.01983 to 3.01911, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1428 - mean_absolute_error: 1.2661 - mean_squared_error: 3.1428 - val_loss: 3.0191 - val_mean_absolute_error: 1.2365 - val_mean_squared_error: 3.0191\n",
            "Epoch 81/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 3.1696 - mean_absolute_error: 1.2716 - mean_squared_error: 3.1696\n",
            "Epoch 81: val_loss did not improve from 3.01911\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1425 - mean_absolute_error: 1.2657 - mean_squared_error: 3.1425 - val_loss: 3.0212 - val_mean_absolute_error: 1.2373 - val_mean_squared_error: 3.0212\n",
            "Epoch 82/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 3.1365 - mean_absolute_error: 1.2656 - mean_squared_error: 3.1365\n",
            "Epoch 82: val_loss did not improve from 3.01911\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1407 - mean_absolute_error: 1.2665 - mean_squared_error: 3.1407 - val_loss: 3.0302 - val_mean_absolute_error: 1.2427 - val_mean_squared_error: 3.0302\n",
            "Epoch 83/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 3.1383 - mean_absolute_error: 1.2651 - mean_squared_error: 3.1383\n",
            "Epoch 83: val_loss did not improve from 3.01911\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1404 - mean_absolute_error: 1.2656 - mean_squared_error: 3.1404 - val_loss: 3.0205 - val_mean_absolute_error: 1.2384 - val_mean_squared_error: 3.0205\n",
            "Epoch 84/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 3.1125 - mean_absolute_error: 1.2610 - mean_squared_error: 3.1125\n",
            "Epoch 84: val_loss improved from 3.01911 to 3.01862, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1396 - mean_absolute_error: 1.2648 - mean_squared_error: 3.1396 - val_loss: 3.0186 - val_mean_absolute_error: 1.2364 - val_mean_squared_error: 3.0186\n",
            "Epoch 85/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 3.1550 - mean_absolute_error: 1.2704 - mean_squared_error: 3.1550\n",
            "Epoch 85: val_loss did not improve from 3.01862\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1378 - mean_absolute_error: 1.2678 - mean_squared_error: 3.1378 - val_loss: 3.0573 - val_mean_absolute_error: 1.2545 - val_mean_squared_error: 3.0573\n",
            "Epoch 86/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 3.1263 - mean_absolute_error: 1.2611 - mean_squared_error: 3.1263\n",
            "Epoch 86: val_loss did not improve from 3.01862\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1413 - mean_absolute_error: 1.2644 - mean_squared_error: 3.1413 - val_loss: 3.0188 - val_mean_absolute_error: 1.2388 - val_mean_squared_error: 3.0188\n",
            "Epoch 87/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 3.1397 - mean_absolute_error: 1.2669 - mean_squared_error: 3.1397\n",
            "Epoch 87: val_loss did not improve from 3.01862\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1399 - mean_absolute_error: 1.2667 - mean_squared_error: 3.1399 - val_loss: 3.0186 - val_mean_absolute_error: 1.2364 - val_mean_squared_error: 3.0186\n",
            "Epoch 88/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 3.1284 - mean_absolute_error: 1.2641 - mean_squared_error: 3.1284\n",
            "Epoch 88: val_loss improved from 3.01862 to 3.01743, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1393 - mean_absolute_error: 1.2672 - mean_squared_error: 3.1393 - val_loss: 3.0174 - val_mean_absolute_error: 1.2376 - val_mean_squared_error: 3.0174\n",
            "Epoch 89/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 3.1847 - mean_absolute_error: 1.2736 - mean_squared_error: 3.1847\n",
            "Epoch 89: val_loss did not improve from 3.01743\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1396 - mean_absolute_error: 1.2665 - mean_squared_error: 3.1396 - val_loss: 3.0182 - val_mean_absolute_error: 1.2379 - val_mean_squared_error: 3.0182\n",
            "Epoch 90/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 3.1400 - mean_absolute_error: 1.2641 - mean_squared_error: 3.1400\n",
            "Epoch 90: val_loss did not improve from 3.01743\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1428 - mean_absolute_error: 1.2657 - mean_squared_error: 3.1428 - val_loss: 3.0188 - val_mean_absolute_error: 1.2384 - val_mean_squared_error: 3.0188\n",
            "Epoch 91/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 3.1008 - mean_absolute_error: 1.2551 - mean_squared_error: 3.1008\n",
            "Epoch 91: val_loss did not improve from 3.01743\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1350 - mean_absolute_error: 1.2642 - mean_squared_error: 3.1350 - val_loss: 3.0189 - val_mean_absolute_error: 1.2380 - val_mean_squared_error: 3.0189\n",
            "Epoch 92/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 3.1480 - mean_absolute_error: 1.2692 - mean_squared_error: 3.1480\n",
            "Epoch 92: val_loss did not improve from 3.01743\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1403 - mean_absolute_error: 1.2663 - mean_squared_error: 3.1403 - val_loss: 3.0179 - val_mean_absolute_error: 1.2385 - val_mean_squared_error: 3.0179\n",
            "Epoch 93/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 3.0933 - mean_absolute_error: 1.2662 - mean_squared_error: 3.0933\n",
            "Epoch 93: val_loss did not improve from 3.01743\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1379 - mean_absolute_error: 1.2647 - mean_squared_error: 3.1379 - val_loss: 3.0252 - val_mean_absolute_error: 1.2420 - val_mean_squared_error: 3.0252\n",
            "Epoch 94/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 3.1548 - mean_absolute_error: 1.2684 - mean_squared_error: 3.1548\n",
            "Epoch 94: val_loss did not improve from 3.01743\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1384 - mean_absolute_error: 1.2650 - mean_squared_error: 3.1384 - val_loss: 3.0212 - val_mean_absolute_error: 1.2409 - val_mean_squared_error: 3.0212\n",
            "Epoch 95/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 3.1410 - mean_absolute_error: 1.2668 - mean_squared_error: 3.1410\n",
            "Epoch 95: val_loss did not improve from 3.01743\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1353 - mean_absolute_error: 1.2663 - mean_squared_error: 3.1353 - val_loss: 3.0227 - val_mean_absolute_error: 1.2409 - val_mean_squared_error: 3.0227\n",
            "Epoch 96/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 3.1434 - mean_absolute_error: 1.2665 - mean_squared_error: 3.1434\n",
            "Epoch 96: val_loss improved from 3.01743 to 3.01427, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1349 - mean_absolute_error: 1.2645 - mean_squared_error: 3.1349 - val_loss: 3.0143 - val_mean_absolute_error: 1.2366 - val_mean_squared_error: 3.0143\n",
            "Epoch 97/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 3.0876 - mean_absolute_error: 1.2584 - mean_squared_error: 3.0876\n",
            "Epoch 97: val_loss did not improve from 3.01427\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1399 - mean_absolute_error: 1.2662 - mean_squared_error: 3.1399 - val_loss: 3.0251 - val_mean_absolute_error: 1.2418 - val_mean_squared_error: 3.0251\n",
            "Epoch 98/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 3.1500 - mean_absolute_error: 1.2665 - mean_squared_error: 3.1500\n",
            "Epoch 98: val_loss improved from 3.01427 to 3.01285, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1371 - mean_absolute_error: 1.2643 - mean_squared_error: 3.1371 - val_loss: 3.0128 - val_mean_absolute_error: 1.2362 - val_mean_squared_error: 3.0128\n",
            "Epoch 99/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 3.1294 - mean_absolute_error: 1.2650 - mean_squared_error: 3.1294\n",
            "Epoch 99: val_loss did not improve from 3.01285\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1326 - mean_absolute_error: 1.2658 - mean_squared_error: 3.1326 - val_loss: 3.0167 - val_mean_absolute_error: 1.2375 - val_mean_squared_error: 3.0167\n",
            "Epoch 100/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 3.1167 - mean_absolute_error: 1.2602 - mean_squared_error: 3.1167\n",
            "Epoch 100: val_loss did not improve from 3.01285\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1334 - mean_absolute_error: 1.2639 - mean_squared_error: 3.1334 - val_loss: 3.0130 - val_mean_absolute_error: 1.2351 - val_mean_squared_error: 3.0130\n",
            "Epoch 101/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 3.0956 - mean_absolute_error: 1.2594 - mean_squared_error: 3.0956\n",
            "Epoch 101: val_loss did not improve from 3.01285\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1332 - mean_absolute_error: 1.2634 - mean_squared_error: 3.1332 - val_loss: 3.0152 - val_mean_absolute_error: 1.2349 - val_mean_squared_error: 3.0152\n",
            "Epoch 102/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 3.1333 - mean_absolute_error: 1.2633 - mean_squared_error: 3.1333\n",
            "Epoch 102: val_loss did not improve from 3.01285\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1320 - mean_absolute_error: 1.2637 - mean_squared_error: 3.1320 - val_loss: 3.0139 - val_mean_absolute_error: 1.2380 - val_mean_squared_error: 3.0139\n",
            "Epoch 103/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 3.1414 - mean_absolute_error: 1.2644 - mean_squared_error: 3.1414\n",
            "Epoch 103: val_loss improved from 3.01285 to 3.01042, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1362 - mean_absolute_error: 1.2631 - mean_squared_error: 3.1362 - val_loss: 3.0104 - val_mean_absolute_error: 1.2354 - val_mean_squared_error: 3.0104\n",
            "Epoch 104/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 3.1484 - mean_absolute_error: 1.2667 - mean_squared_error: 3.1484\n",
            "Epoch 104: val_loss improved from 3.01042 to 3.00874, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1307 - mean_absolute_error: 1.2641 - mean_squared_error: 3.1307 - val_loss: 3.0087 - val_mean_absolute_error: 1.2361 - val_mean_squared_error: 3.0087\n",
            "Epoch 105/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 3.1399 - mean_absolute_error: 1.2643 - mean_squared_error: 3.1399\n",
            "Epoch 105: val_loss did not improve from 3.00874\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1289 - mean_absolute_error: 1.2633 - mean_squared_error: 3.1289 - val_loss: 3.0113 - val_mean_absolute_error: 1.2366 - val_mean_squared_error: 3.0113\n",
            "Epoch 106/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 3.1394 - mean_absolute_error: 1.2653 - mean_squared_error: 3.1394\n",
            "Epoch 106: val_loss did not improve from 3.00874\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1333 - mean_absolute_error: 1.2640 - mean_squared_error: 3.1333 - val_loss: 3.0188 - val_mean_absolute_error: 1.2399 - val_mean_squared_error: 3.0188\n",
            "Epoch 107/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 3.1360 - mean_absolute_error: 1.2682 - mean_squared_error: 3.1360\n",
            "Epoch 107: val_loss improved from 3.00874 to 3.00623, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1272 - mean_absolute_error: 1.2661 - mean_squared_error: 3.1272 - val_loss: 3.0062 - val_mean_absolute_error: 1.2333 - val_mean_squared_error: 3.0062\n",
            "Epoch 108/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 3.1768 - mean_absolute_error: 1.2735 - mean_squared_error: 3.1768\n",
            "Epoch 108: val_loss improved from 3.00623 to 3.00561, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1299 - mean_absolute_error: 1.2631 - mean_squared_error: 3.1299 - val_loss: 3.0056 - val_mean_absolute_error: 1.2336 - val_mean_squared_error: 3.0056\n",
            "Epoch 109/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 3.1140 - mean_absolute_error: 1.2636 - mean_squared_error: 3.1140\n",
            "Epoch 109: val_loss did not improve from 3.00561\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1267 - mean_absolute_error: 1.2618 - mean_squared_error: 3.1267 - val_loss: 3.0142 - val_mean_absolute_error: 1.2372 - val_mean_squared_error: 3.0142\n",
            "Epoch 110/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 3.1346 - mean_absolute_error: 1.2629 - mean_squared_error: 3.1346\n",
            "Epoch 110: val_loss improved from 3.00561 to 3.00304, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1241 - mean_absolute_error: 1.2613 - mean_squared_error: 3.1241 - val_loss: 3.0030 - val_mean_absolute_error: 1.2323 - val_mean_squared_error: 3.0030\n",
            "Epoch 111/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 3.1286 - mean_absolute_error: 1.2614 - mean_squared_error: 3.1286\n",
            "Epoch 111: val_loss did not improve from 3.00304\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1187 - mean_absolute_error: 1.2597 - mean_squared_error: 3.1187 - val_loss: 3.0046 - val_mean_absolute_error: 1.2325 - val_mean_squared_error: 3.0046\n",
            "Epoch 112/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 3.1079 - mean_absolute_error: 1.2545 - mean_squared_error: 3.1079\n",
            "Epoch 112: val_loss did not improve from 3.00304\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1220 - mean_absolute_error: 1.2587 - mean_squared_error: 3.1220 - val_loss: 3.0083 - val_mean_absolute_error: 1.2361 - val_mean_squared_error: 3.0083\n",
            "Epoch 113/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 3.1310 - mean_absolute_error: 1.2621 - mean_squared_error: 3.1310\n",
            "Epoch 113: val_loss did not improve from 3.00304\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1180 - mean_absolute_error: 1.2588 - mean_squared_error: 3.1180 - val_loss: 3.0032 - val_mean_absolute_error: 1.2353 - val_mean_squared_error: 3.0032\n",
            "Epoch 114/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 3.1415 - mean_absolute_error: 1.2623 - mean_squared_error: 3.1415\n",
            "Epoch 114: val_loss improved from 3.00304 to 2.99749, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1172 - mean_absolute_error: 1.2616 - mean_squared_error: 3.1172 - val_loss: 2.9975 - val_mean_absolute_error: 1.2329 - val_mean_squared_error: 2.9975\n",
            "Epoch 115/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 3.1305 - mean_absolute_error: 1.2618 - mean_squared_error: 3.1305\n",
            "Epoch 115: val_loss improved from 2.99749 to 2.99646, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1172 - mean_absolute_error: 1.2594 - mean_squared_error: 3.1172 - val_loss: 2.9965 - val_mean_absolute_error: 1.2304 - val_mean_squared_error: 2.9965\n",
            "Epoch 116/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 3.1571 - mean_absolute_error: 1.2652 - mean_squared_error: 3.1571\n",
            "Epoch 116: val_loss improved from 2.99646 to 2.99562, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1155 - mean_absolute_error: 1.2584 - mean_squared_error: 3.1155 - val_loss: 2.9956 - val_mean_absolute_error: 1.2290 - val_mean_squared_error: 2.9956\n",
            "Epoch 117/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 3.1404 - mean_absolute_error: 1.2647 - mean_squared_error: 3.1404\n",
            "Epoch 117: val_loss improved from 2.99562 to 2.99241, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1170 - mean_absolute_error: 1.2584 - mean_squared_error: 3.1170 - val_loss: 2.9924 - val_mean_absolute_error: 1.2291 - val_mean_squared_error: 2.9924\n",
            "Epoch 118/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 3.0983 - mean_absolute_error: 1.2534 - mean_squared_error: 3.0983\n",
            "Epoch 118: val_loss did not improve from 2.99241\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1118 - mean_absolute_error: 1.2566 - mean_squared_error: 3.1118 - val_loss: 2.9942 - val_mean_absolute_error: 1.2298 - val_mean_squared_error: 2.9942\n",
            "Epoch 119/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 3.1096 - mean_absolute_error: 1.2537 - mean_squared_error: 3.1096\n",
            "Epoch 119: val_loss did not improve from 2.99241\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1066 - mean_absolute_error: 1.2539 - mean_squared_error: 3.1066 - val_loss: 2.9969 - val_mean_absolute_error: 1.2321 - val_mean_squared_error: 2.9969\n",
            "Epoch 120/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 3.1125 - mean_absolute_error: 1.2573 - mean_squared_error: 3.1125\n",
            "Epoch 120: val_loss improved from 2.99241 to 2.99199, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1052 - mean_absolute_error: 1.2537 - mean_squared_error: 3.1052 - val_loss: 2.9920 - val_mean_absolute_error: 1.2312 - val_mean_squared_error: 2.9920\n",
            "Epoch 121/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 3.0915 - mean_absolute_error: 1.2505 - mean_squared_error: 3.0915\n",
            "Epoch 121: val_loss improved from 2.99199 to 2.98424, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1027 - mean_absolute_error: 1.2529 - mean_squared_error: 3.1027 - val_loss: 2.9842 - val_mean_absolute_error: 1.2281 - val_mean_squared_error: 2.9842\n",
            "Epoch 122/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 3.0973 - mean_absolute_error: 1.2539 - mean_squared_error: 3.0973\n",
            "Epoch 122: val_loss improved from 2.98424 to 2.98113, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1021 - mean_absolute_error: 1.2542 - mean_squared_error: 3.1021 - val_loss: 2.9811 - val_mean_absolute_error: 1.2265 - val_mean_squared_error: 2.9811\n",
            "Epoch 123/1000\n",
            "218/245 [=========================>....] - ETA: 0s - loss: 3.0642 - mean_absolute_error: 1.2423 - mean_squared_error: 3.0642\n",
            "Epoch 123: val_loss did not improve from 2.98113\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0976 - mean_absolute_error: 1.2531 - mean_squared_error: 3.0976 - val_loss: 3.0006 - val_mean_absolute_error: 1.2327 - val_mean_squared_error: 3.0006\n",
            "Epoch 124/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 3.0895 - mean_absolute_error: 1.2491 - mean_squared_error: 3.0895\n",
            "Epoch 124: val_loss did not improve from 2.98113\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0952 - mean_absolute_error: 1.2512 - mean_squared_error: 3.0952 - val_loss: 2.9816 - val_mean_absolute_error: 1.2265 - val_mean_squared_error: 2.9816\n",
            "Epoch 125/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 3.0515 - mean_absolute_error: 1.2391 - mean_squared_error: 3.0515\n",
            "Epoch 125: val_loss improved from 2.98113 to 2.97447, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0886 - mean_absolute_error: 1.2476 - mean_squared_error: 3.0886 - val_loss: 2.9745 - val_mean_absolute_error: 1.2240 - val_mean_squared_error: 2.9745\n",
            "Epoch 126/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 3.1268 - mean_absolute_error: 1.2559 - mean_squared_error: 3.1268\n",
            "Epoch 126: val_loss improved from 2.97447 to 2.96925, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0830 - mean_absolute_error: 1.2488 - mean_squared_error: 3.0830 - val_loss: 2.9693 - val_mean_absolute_error: 1.2232 - val_mean_squared_error: 2.9693\n",
            "Epoch 127/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 3.1144 - mean_absolute_error: 1.2546 - mean_squared_error: 3.1144\n",
            "Epoch 127: val_loss improved from 2.96925 to 2.96638, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0823 - mean_absolute_error: 1.2494 - mean_squared_error: 3.0823 - val_loss: 2.9664 - val_mean_absolute_error: 1.2216 - val_mean_squared_error: 2.9664\n",
            "Epoch 128/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 3.0652 - mean_absolute_error: 1.2418 - mean_squared_error: 3.0652\n",
            "Epoch 128: val_loss did not improve from 2.96638\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0763 - mean_absolute_error: 1.2453 - mean_squared_error: 3.0763 - val_loss: 2.9726 - val_mean_absolute_error: 1.2217 - val_mean_squared_error: 2.9726\n",
            "Epoch 129/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 3.0856 - mean_absolute_error: 1.2450 - mean_squared_error: 3.0856\n",
            "Epoch 129: val_loss improved from 2.96638 to 2.96023, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0751 - mean_absolute_error: 1.2437 - mean_squared_error: 3.0751 - val_loss: 2.9602 - val_mean_absolute_error: 1.2198 - val_mean_squared_error: 2.9602\n",
            "Epoch 130/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 3.1078 - mean_absolute_error: 1.2472 - mean_squared_error: 3.1078\n",
            "Epoch 130: val_loss did not improve from 2.96023\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0719 - mean_absolute_error: 1.2431 - mean_squared_error: 3.0719 - val_loss: 2.9630 - val_mean_absolute_error: 1.2209 - val_mean_squared_error: 2.9630\n",
            "Epoch 131/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 3.0509 - mean_absolute_error: 1.2412 - mean_squared_error: 3.0509\n",
            "Epoch 131: val_loss improved from 2.96023 to 2.95444, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0645 - mean_absolute_error: 1.2424 - mean_squared_error: 3.0645 - val_loss: 2.9544 - val_mean_absolute_error: 1.2166 - val_mean_squared_error: 2.9544\n",
            "Epoch 132/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 3.0798 - mean_absolute_error: 1.2415 - mean_squared_error: 3.0798\n",
            "Epoch 132: val_loss improved from 2.95444 to 2.95037, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0599 - mean_absolute_error: 1.2400 - mean_squared_error: 3.0599 - val_loss: 2.9504 - val_mean_absolute_error: 1.2156 - val_mean_squared_error: 2.9504\n",
            "Epoch 133/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 3.0569 - mean_absolute_error: 1.2383 - mean_squared_error: 3.0569\n",
            "Epoch 133: val_loss improved from 2.95037 to 2.94364, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0569 - mean_absolute_error: 1.2372 - mean_squared_error: 3.0569 - val_loss: 2.9436 - val_mean_absolute_error: 1.2141 - val_mean_squared_error: 2.9436\n",
            "Epoch 134/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 3.0131 - mean_absolute_error: 1.2299 - mean_squared_error: 3.0131\n",
            "Epoch 134: val_loss did not improve from 2.94364\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0535 - mean_absolute_error: 1.2349 - mean_squared_error: 3.0535 - val_loss: 2.9474 - val_mean_absolute_error: 1.2136 - val_mean_squared_error: 2.9474\n",
            "Epoch 135/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 3.0504 - mean_absolute_error: 1.2368 - mean_squared_error: 3.0504\n",
            "Epoch 135: val_loss improved from 2.94364 to 2.94328, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0501 - mean_absolute_error: 1.2363 - mean_squared_error: 3.0501 - val_loss: 2.9433 - val_mean_absolute_error: 1.2127 - val_mean_squared_error: 2.9433\n",
            "Epoch 136/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 3.0382 - mean_absolute_error: 1.2307 - mean_squared_error: 3.0382\n",
            "Epoch 136: val_loss improved from 2.94328 to 2.93094, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0437 - mean_absolute_error: 1.2326 - mean_squared_error: 3.0437 - val_loss: 2.9309 - val_mean_absolute_error: 1.2095 - val_mean_squared_error: 2.9309\n",
            "Epoch 137/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 3.0260 - mean_absolute_error: 1.2273 - mean_squared_error: 3.0260\n",
            "Epoch 137: val_loss did not improve from 2.93094\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0353 - mean_absolute_error: 1.2316 - mean_squared_error: 3.0353 - val_loss: 2.9441 - val_mean_absolute_error: 1.2127 - val_mean_squared_error: 2.9441\n",
            "Epoch 138/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 3.0442 - mean_absolute_error: 1.2341 - mean_squared_error: 3.0442\n",
            "Epoch 138: val_loss improved from 2.93094 to 2.91992, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0311 - mean_absolute_error: 1.2316 - mean_squared_error: 3.0311 - val_loss: 2.9199 - val_mean_absolute_error: 1.2065 - val_mean_squared_error: 2.9199\n",
            "Epoch 139/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 3.0322 - mean_absolute_error: 1.2293 - mean_squared_error: 3.0322\n",
            "Epoch 139: val_loss improved from 2.91992 to 2.91800, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0247 - mean_absolute_error: 1.2269 - mean_squared_error: 3.0247 - val_loss: 2.9180 - val_mean_absolute_error: 1.2060 - val_mean_squared_error: 2.9180\n",
            "Epoch 140/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 3.0336 - mean_absolute_error: 1.2276 - mean_squared_error: 3.0336\n",
            "Epoch 140: val_loss improved from 2.91800 to 2.91087, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0200 - mean_absolute_error: 1.2261 - mean_squared_error: 3.0200 - val_loss: 2.9109 - val_mean_absolute_error: 1.2052 - val_mean_squared_error: 2.9109\n",
            "Epoch 141/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 3.0427 - mean_absolute_error: 1.2317 - mean_squared_error: 3.0427\n",
            "Epoch 141: val_loss improved from 2.91087 to 2.90947, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0178 - mean_absolute_error: 1.2273 - mean_squared_error: 3.0178 - val_loss: 2.9095 - val_mean_absolute_error: 1.2008 - val_mean_squared_error: 2.9095\n",
            "Epoch 142/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 3.0485 - mean_absolute_error: 1.2268 - mean_squared_error: 3.0485\n",
            "Epoch 142: val_loss improved from 2.90947 to 2.90287, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0093 - mean_absolute_error: 1.2221 - mean_squared_error: 3.0093 - val_loss: 2.9029 - val_mean_absolute_error: 1.1983 - val_mean_squared_error: 2.9029\n",
            "Epoch 143/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 3.0029 - mean_absolute_error: 1.2176 - mean_squared_error: 3.0029\n",
            "Epoch 143: val_loss improved from 2.90287 to 2.89954, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0049 - mean_absolute_error: 1.2190 - mean_squared_error: 3.0049 - val_loss: 2.8995 - val_mean_absolute_error: 1.1968 - val_mean_squared_error: 2.8995\n",
            "Epoch 144/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 3.0010 - mean_absolute_error: 1.2207 - mean_squared_error: 3.0010\n",
            "Epoch 144: val_loss improved from 2.89954 to 2.89203, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9987 - mean_absolute_error: 1.2171 - mean_squared_error: 2.9987 - val_loss: 2.8920 - val_mean_absolute_error: 1.1963 - val_mean_squared_error: 2.8920\n",
            "Epoch 145/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.9940 - mean_absolute_error: 1.2165 - mean_squared_error: 2.9940\n",
            "Epoch 145: val_loss did not improve from 2.89203\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9905 - mean_absolute_error: 1.2171 - mean_squared_error: 2.9905 - val_loss: 2.9148 - val_mean_absolute_error: 1.1985 - val_mean_squared_error: 2.9148\n",
            "Epoch 146/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 3.0284 - mean_absolute_error: 1.2201 - mean_squared_error: 3.0284\n",
            "Epoch 146: val_loss improved from 2.89203 to 2.88499, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9918 - mean_absolute_error: 1.2136 - mean_squared_error: 2.9918 - val_loss: 2.8850 - val_mean_absolute_error: 1.1943 - val_mean_squared_error: 2.8850\n",
            "Epoch 147/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.9747 - mean_absolute_error: 1.2095 - mean_squared_error: 2.9747\n",
            "Epoch 147: val_loss improved from 2.88499 to 2.87921, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9841 - mean_absolute_error: 1.2113 - mean_squared_error: 2.9841 - val_loss: 2.8792 - val_mean_absolute_error: 1.1924 - val_mean_squared_error: 2.8792\n",
            "Epoch 148/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.9581 - mean_absolute_error: 1.2047 - mean_squared_error: 2.9581\n",
            "Epoch 148: val_loss improved from 2.87921 to 2.87695, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9781 - mean_absolute_error: 1.2100 - mean_squared_error: 2.9781 - val_loss: 2.8769 - val_mean_absolute_error: 1.1918 - val_mean_squared_error: 2.8769\n",
            "Epoch 149/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 2.9788 - mean_absolute_error: 1.2056 - mean_squared_error: 2.9788\n",
            "Epoch 149: val_loss improved from 2.87695 to 2.87021, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9756 - mean_absolute_error: 1.2086 - mean_squared_error: 2.9756 - val_loss: 2.8702 - val_mean_absolute_error: 1.1905 - val_mean_squared_error: 2.8702\n",
            "Epoch 150/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.9819 - mean_absolute_error: 1.2093 - mean_squared_error: 2.9819\n",
            "Epoch 150: val_loss improved from 2.87021 to 2.86448, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9652 - mean_absolute_error: 1.2073 - mean_squared_error: 2.9652 - val_loss: 2.8645 - val_mean_absolute_error: 1.1911 - val_mean_squared_error: 2.8645\n",
            "Epoch 151/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.9831 - mean_absolute_error: 1.2093 - mean_squared_error: 2.9831\n",
            "Epoch 151: val_loss improved from 2.86448 to 2.86097, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9634 - mean_absolute_error: 1.2037 - mean_squared_error: 2.9634 - val_loss: 2.8610 - val_mean_absolute_error: 1.1916 - val_mean_squared_error: 2.8610\n",
            "Epoch 152/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.9839 - mean_absolute_error: 1.2143 - mean_squared_error: 2.9839\n",
            "Epoch 152: val_loss did not improve from 2.86097\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.9611 - mean_absolute_error: 1.2096 - mean_squared_error: 2.9611 - val_loss: 2.8627 - val_mean_absolute_error: 1.1840 - val_mean_squared_error: 2.8627\n",
            "Epoch 153/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.9420 - mean_absolute_error: 1.1987 - mean_squared_error: 2.9420\n",
            "Epoch 153: val_loss improved from 2.86097 to 2.85905, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.9550 - mean_absolute_error: 1.2016 - mean_squared_error: 2.9550 - val_loss: 2.8590 - val_mean_absolute_error: 1.1831 - val_mean_squared_error: 2.8590\n",
            "Epoch 154/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.9363 - mean_absolute_error: 1.1943 - mean_squared_error: 2.9363\n",
            "Epoch 154: val_loss improved from 2.85905 to 2.84782, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.9461 - mean_absolute_error: 1.1964 - mean_squared_error: 2.9461 - val_loss: 2.8478 - val_mean_absolute_error: 1.1832 - val_mean_squared_error: 2.8478\n",
            "Epoch 155/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.9220 - mean_absolute_error: 1.1948 - mean_squared_error: 2.9220\n",
            "Epoch 155: val_loss did not improve from 2.84782\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.9360 - mean_absolute_error: 1.1991 - mean_squared_error: 2.9360 - val_loss: 2.8546 - val_mean_absolute_error: 1.1916 - val_mean_squared_error: 2.8546\n",
            "Epoch 156/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.9483 - mean_absolute_error: 1.2005 - mean_squared_error: 2.9483\n",
            "Epoch 156: val_loss improved from 2.84782 to 2.83754, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9367 - mean_absolute_error: 1.1983 - mean_squared_error: 2.9367 - val_loss: 2.8375 - val_mean_absolute_error: 1.1827 - val_mean_squared_error: 2.8375\n",
            "Epoch 157/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.9269 - mean_absolute_error: 1.1943 - mean_squared_error: 2.9269\n",
            "Epoch 157: val_loss improved from 2.83754 to 2.83435, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9338 - mean_absolute_error: 1.1958 - mean_squared_error: 2.9338 - val_loss: 2.8343 - val_mean_absolute_error: 1.1784 - val_mean_squared_error: 2.8343\n",
            "Epoch 158/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.9278 - mean_absolute_error: 1.1936 - mean_squared_error: 2.9278\n",
            "Epoch 158: val_loss did not improve from 2.83435\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9265 - mean_absolute_error: 1.1944 - mean_squared_error: 2.9265 - val_loss: 2.8454 - val_mean_absolute_error: 1.1774 - val_mean_squared_error: 2.8454\n",
            "Epoch 159/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.9603 - mean_absolute_error: 1.2024 - mean_squared_error: 2.9603\n",
            "Epoch 159: val_loss did not improve from 2.83435\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9265 - mean_absolute_error: 1.1944 - mean_squared_error: 2.9265 - val_loss: 2.8353 - val_mean_absolute_error: 1.1773 - val_mean_squared_error: 2.8353\n",
            "Epoch 160/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.9116 - mean_absolute_error: 1.1897 - mean_squared_error: 2.9116\n",
            "Epoch 160: val_loss improved from 2.83435 to 2.82155, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9194 - mean_absolute_error: 1.1906 - mean_squared_error: 2.9194 - val_loss: 2.8215 - val_mean_absolute_error: 1.1797 - val_mean_squared_error: 2.8215\n",
            "Epoch 161/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 2.9179 - mean_absolute_error: 1.1964 - mean_squared_error: 2.9179\n",
            "Epoch 161: val_loss improved from 2.82155 to 2.81895, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9153 - mean_absolute_error: 1.1921 - mean_squared_error: 2.9153 - val_loss: 2.8189 - val_mean_absolute_error: 1.1770 - val_mean_squared_error: 2.8189\n",
            "Epoch 162/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.8944 - mean_absolute_error: 1.1826 - mean_squared_error: 2.8944\n",
            "Epoch 162: val_loss did not improve from 2.81895\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9084 - mean_absolute_error: 1.1861 - mean_squared_error: 2.9084 - val_loss: 2.8305 - val_mean_absolute_error: 1.1785 - val_mean_squared_error: 2.8305\n",
            "Epoch 163/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.8985 - mean_absolute_error: 1.1883 - mean_squared_error: 2.8985\n",
            "Epoch 163: val_loss did not improve from 2.81895\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9045 - mean_absolute_error: 1.1905 - mean_squared_error: 2.9045 - val_loss: 2.8332 - val_mean_absolute_error: 1.1764 - val_mean_squared_error: 2.8332\n",
            "Epoch 164/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 2.9305 - mean_absolute_error: 1.1951 - mean_squared_error: 2.9305\n",
            "Epoch 164: val_loss improved from 2.81895 to 2.81593, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9039 - mean_absolute_error: 1.1906 - mean_squared_error: 2.9039 - val_loss: 2.8159 - val_mean_absolute_error: 1.1737 - val_mean_squared_error: 2.8159\n",
            "Epoch 165/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.8679 - mean_absolute_error: 1.1826 - mean_squared_error: 2.8679\n",
            "Epoch 165: val_loss improved from 2.81593 to 2.80028, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8975 - mean_absolute_error: 1.1865 - mean_squared_error: 2.8975 - val_loss: 2.8003 - val_mean_absolute_error: 1.1731 - val_mean_squared_error: 2.8003\n",
            "Epoch 166/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.8951 - mean_absolute_error: 1.1878 - mean_squared_error: 2.8951\n",
            "Epoch 166: val_loss did not improve from 2.80028\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8916 - mean_absolute_error: 1.1876 - mean_squared_error: 2.8916 - val_loss: 2.8034 - val_mean_absolute_error: 1.1734 - val_mean_squared_error: 2.8034\n",
            "Epoch 167/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.9109 - mean_absolute_error: 1.1898 - mean_squared_error: 2.9109\n",
            "Epoch 167: val_loss improved from 2.80028 to 2.79461, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8859 - mean_absolute_error: 1.1863 - mean_squared_error: 2.8859 - val_loss: 2.7946 - val_mean_absolute_error: 1.1736 - val_mean_squared_error: 2.7946\n",
            "Epoch 168/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 2.8532 - mean_absolute_error: 1.1780 - mean_squared_error: 2.8532\n",
            "Epoch 168: val_loss improved from 2.79461 to 2.79332, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8824 - mean_absolute_error: 1.1850 - mean_squared_error: 2.8824 - val_loss: 2.7933 - val_mean_absolute_error: 1.1685 - val_mean_squared_error: 2.7933\n",
            "Epoch 169/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.8739 - mean_absolute_error: 1.1805 - mean_squared_error: 2.8739\n",
            "Epoch 169: val_loss improved from 2.79332 to 2.78336, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8758 - mean_absolute_error: 1.1811 - mean_squared_error: 2.8758 - val_loss: 2.7834 - val_mean_absolute_error: 1.1692 - val_mean_squared_error: 2.7834\n",
            "Epoch 170/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.8726 - mean_absolute_error: 1.1863 - mean_squared_error: 2.8726\n",
            "Epoch 170: val_loss improved from 2.78336 to 2.77989, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8690 - mean_absolute_error: 1.1856 - mean_squared_error: 2.8690 - val_loss: 2.7799 - val_mean_absolute_error: 1.1680 - val_mean_squared_error: 2.7799\n",
            "Epoch 171/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.8504 - mean_absolute_error: 1.1793 - mean_squared_error: 2.8504\n",
            "Epoch 171: val_loss did not improve from 2.77989\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8689 - mean_absolute_error: 1.1824 - mean_squared_error: 2.8689 - val_loss: 2.7968 - val_mean_absolute_error: 1.1675 - val_mean_squared_error: 2.7968\n",
            "Epoch 172/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.8881 - mean_absolute_error: 1.1841 - mean_squared_error: 2.8881\n",
            "Epoch 172: val_loss improved from 2.77989 to 2.77038, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8618 - mean_absolute_error: 1.1824 - mean_squared_error: 2.8618 - val_loss: 2.7704 - val_mean_absolute_error: 1.1659 - val_mean_squared_error: 2.7704\n",
            "Epoch 173/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.8977 - mean_absolute_error: 1.1859 - mean_squared_error: 2.8977\n",
            "Epoch 173: val_loss improved from 2.77038 to 2.76788, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8592 - mean_absolute_error: 1.1783 - mean_squared_error: 2.8592 - val_loss: 2.7679 - val_mean_absolute_error: 1.1664 - val_mean_squared_error: 2.7679\n",
            "Epoch 174/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.8546 - mean_absolute_error: 1.1777 - mean_squared_error: 2.8546\n",
            "Epoch 174: val_loss did not improve from 2.76788\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8546 - mean_absolute_error: 1.1777 - mean_squared_error: 2.8546 - val_loss: 2.7729 - val_mean_absolute_error: 1.1647 - val_mean_squared_error: 2.7729\n",
            "Epoch 175/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 2.8365 - mean_absolute_error: 1.1721 - mean_squared_error: 2.8365\n",
            "Epoch 175: val_loss improved from 2.76788 to 2.76034, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8488 - mean_absolute_error: 1.1776 - mean_squared_error: 2.8488 - val_loss: 2.7603 - val_mean_absolute_error: 1.1652 - val_mean_squared_error: 2.7603\n",
            "Epoch 176/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.8557 - mean_absolute_error: 1.1756 - mean_squared_error: 2.8557\n",
            "Epoch 176: val_loss improved from 2.76034 to 2.75526, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8431 - mean_absolute_error: 1.1780 - mean_squared_error: 2.8431 - val_loss: 2.7553 - val_mean_absolute_error: 1.1697 - val_mean_squared_error: 2.7553\n",
            "Epoch 177/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.8574 - mean_absolute_error: 1.1767 - mean_squared_error: 2.8574\n",
            "Epoch 177: val_loss improved from 2.75526 to 2.75026, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8419 - mean_absolute_error: 1.1756 - mean_squared_error: 2.8419 - val_loss: 2.7503 - val_mean_absolute_error: 1.1646 - val_mean_squared_error: 2.7503\n",
            "Epoch 178/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.8210 - mean_absolute_error: 1.1712 - mean_squared_error: 2.8210\n",
            "Epoch 178: val_loss did not improve from 2.75026\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8367 - mean_absolute_error: 1.1753 - mean_squared_error: 2.8367 - val_loss: 2.7598 - val_mean_absolute_error: 1.1614 - val_mean_squared_error: 2.7598\n",
            "Epoch 179/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.8538 - mean_absolute_error: 1.1807 - mean_squared_error: 2.8538\n",
            "Epoch 179: val_loss improved from 2.75026 to 2.74332, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8297 - mean_absolute_error: 1.1749 - mean_squared_error: 2.8297 - val_loss: 2.7433 - val_mean_absolute_error: 1.1689 - val_mean_squared_error: 2.7433\n",
            "Epoch 180/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.8045 - mean_absolute_error: 1.1725 - mean_squared_error: 2.8045\n",
            "Epoch 180: val_loss improved from 2.74332 to 2.73490, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8327 - mean_absolute_error: 1.1777 - mean_squared_error: 2.8327 - val_loss: 2.7349 - val_mean_absolute_error: 1.1614 - val_mean_squared_error: 2.7349\n",
            "Epoch 181/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.7845 - mean_absolute_error: 1.1675 - mean_squared_error: 2.7845\n",
            "Epoch 181: val_loss did not improve from 2.73490\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8235 - mean_absolute_error: 1.1746 - mean_squared_error: 2.8235 - val_loss: 2.7388 - val_mean_absolute_error: 1.1542 - val_mean_squared_error: 2.7388\n",
            "Epoch 182/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.8154 - mean_absolute_error: 1.1717 - mean_squared_error: 2.8154\n",
            "Epoch 182: val_loss improved from 2.73490 to 2.73246, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8154 - mean_absolute_error: 1.1717 - mean_squared_error: 2.8154 - val_loss: 2.7325 - val_mean_absolute_error: 1.1563 - val_mean_squared_error: 2.7325\n",
            "Epoch 183/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.8309 - mean_absolute_error: 1.1707 - mean_squared_error: 2.8309\n",
            "Epoch 183: val_loss improved from 2.73246 to 2.72134, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8102 - mean_absolute_error: 1.1672 - mean_squared_error: 2.8102 - val_loss: 2.7213 - val_mean_absolute_error: 1.1605 - val_mean_squared_error: 2.7213\n",
            "Epoch 184/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.8272 - mean_absolute_error: 1.1763 - mean_squared_error: 2.8272\n",
            "Epoch 184: val_loss improved from 2.72134 to 2.71659, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8092 - mean_absolute_error: 1.1734 - mean_squared_error: 2.8092 - val_loss: 2.7166 - val_mean_absolute_error: 1.1583 - val_mean_squared_error: 2.7166\n",
            "Epoch 185/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.7806 - mean_absolute_error: 1.1647 - mean_squared_error: 2.7806\n",
            "Epoch 185: val_loss did not improve from 2.71659\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8029 - mean_absolute_error: 1.1673 - mean_squared_error: 2.8029 - val_loss: 2.7196 - val_mean_absolute_error: 1.1645 - val_mean_squared_error: 2.7196\n",
            "Epoch 186/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.7738 - mean_absolute_error: 1.1649 - mean_squared_error: 2.7738\n",
            "Epoch 186: val_loss improved from 2.71659 to 2.71098, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8008 - mean_absolute_error: 1.1674 - mean_squared_error: 2.8008 - val_loss: 2.7110 - val_mean_absolute_error: 1.1522 - val_mean_squared_error: 2.7110\n",
            "Epoch 187/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 2.7763 - mean_absolute_error: 1.1580 - mean_squared_error: 2.7763\n",
            "Epoch 187: val_loss improved from 2.71098 to 2.70546, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7890 - mean_absolute_error: 1.1649 - mean_squared_error: 2.7890 - val_loss: 2.7055 - val_mean_absolute_error: 1.1550 - val_mean_squared_error: 2.7055\n",
            "Epoch 188/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.8072 - mean_absolute_error: 1.1733 - mean_squared_error: 2.8072\n",
            "Epoch 188: val_loss improved from 2.70546 to 2.70114, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7875 - mean_absolute_error: 1.1668 - mean_squared_error: 2.7875 - val_loss: 2.7011 - val_mean_absolute_error: 1.1510 - val_mean_squared_error: 2.7011\n",
            "Epoch 189/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.7821 - mean_absolute_error: 1.1654 - mean_squared_error: 2.7821\n",
            "Epoch 189: val_loss improved from 2.70114 to 2.69351, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7844 - mean_absolute_error: 1.1654 - mean_squared_error: 2.7844 - val_loss: 2.6935 - val_mean_absolute_error: 1.1501 - val_mean_squared_error: 2.6935\n",
            "Epoch 190/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.7679 - mean_absolute_error: 1.1594 - mean_squared_error: 2.7679\n",
            "Epoch 190: val_loss improved from 2.69351 to 2.68927, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7766 - mean_absolute_error: 1.1618 - mean_squared_error: 2.7766 - val_loss: 2.6893 - val_mean_absolute_error: 1.1511 - val_mean_squared_error: 2.6893\n",
            "Epoch 191/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.7730 - mean_absolute_error: 1.1604 - mean_squared_error: 2.7730\n",
            "Epoch 191: val_loss improved from 2.68927 to 2.68693, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7730 - mean_absolute_error: 1.1604 - mean_squared_error: 2.7730 - val_loss: 2.6869 - val_mean_absolute_error: 1.1564 - val_mean_squared_error: 2.6869\n",
            "Epoch 192/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.7532 - mean_absolute_error: 1.1601 - mean_squared_error: 2.7532\n",
            "Epoch 192: val_loss improved from 2.68693 to 2.67935, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7686 - mean_absolute_error: 1.1627 - mean_squared_error: 2.7686 - val_loss: 2.6793 - val_mean_absolute_error: 1.1485 - val_mean_squared_error: 2.6793\n",
            "Epoch 193/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.7624 - mean_absolute_error: 1.1592 - mean_squared_error: 2.7624\n",
            "Epoch 193: val_loss improved from 2.67935 to 2.67806, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.7631 - mean_absolute_error: 1.1568 - mean_squared_error: 2.7631 - val_loss: 2.6781 - val_mean_absolute_error: 1.1455 - val_mean_squared_error: 2.6781\n",
            "Epoch 194/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.7542 - mean_absolute_error: 1.1584 - mean_squared_error: 2.7542\n",
            "Epoch 194: val_loss improved from 2.67806 to 2.67090, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7600 - mean_absolute_error: 1.1597 - mean_squared_error: 2.7600 - val_loss: 2.6709 - val_mean_absolute_error: 1.1441 - val_mean_squared_error: 2.6709\n",
            "Epoch 195/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.7517 - mean_absolute_error: 1.1576 - mean_squared_error: 2.7517\n",
            "Epoch 195: val_loss improved from 2.67090 to 2.66559, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7610 - mean_absolute_error: 1.1595 - mean_squared_error: 2.7610 - val_loss: 2.6656 - val_mean_absolute_error: 1.1430 - val_mean_squared_error: 2.6656\n",
            "Epoch 196/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 2.8111 - mean_absolute_error: 1.1708 - mean_squared_error: 2.8111\n",
            "Epoch 196: val_loss improved from 2.66559 to 2.66221, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7411 - mean_absolute_error: 1.1577 - mean_squared_error: 2.7411 - val_loss: 2.6622 - val_mean_absolute_error: 1.1444 - val_mean_squared_error: 2.6622\n",
            "Epoch 197/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.7398 - mean_absolute_error: 1.1502 - mean_squared_error: 2.7398\n",
            "Epoch 197: val_loss improved from 2.66221 to 2.65971, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7438 - mean_absolute_error: 1.1534 - mean_squared_error: 2.7438 - val_loss: 2.6597 - val_mean_absolute_error: 1.1479 - val_mean_squared_error: 2.6597\n",
            "Epoch 198/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.7173 - mean_absolute_error: 1.1510 - mean_squared_error: 2.7173\n",
            "Epoch 198: val_loss did not improve from 2.65971\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7369 - mean_absolute_error: 1.1528 - mean_squared_error: 2.7369 - val_loss: 2.6659 - val_mean_absolute_error: 1.1373 - val_mean_squared_error: 2.6659\n",
            "Epoch 199/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.7249 - mean_absolute_error: 1.1510 - mean_squared_error: 2.7249\n",
            "Epoch 199: val_loss improved from 2.65971 to 2.64994, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.7323 - mean_absolute_error: 1.1540 - mean_squared_error: 2.7323 - val_loss: 2.6499 - val_mean_absolute_error: 1.1367 - val_mean_squared_error: 2.6499\n",
            "Epoch 200/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 2.7708 - mean_absolute_error: 1.1618 - mean_squared_error: 2.7708\n",
            "Epoch 200: val_loss did not improve from 2.64994\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7288 - mean_absolute_error: 1.1516 - mean_squared_error: 2.7288 - val_loss: 2.6578 - val_mean_absolute_error: 1.1356 - val_mean_squared_error: 2.6578\n",
            "Epoch 201/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.7165 - mean_absolute_error: 1.1513 - mean_squared_error: 2.7165\n",
            "Epoch 201: val_loss improved from 2.64994 to 2.63921, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7257 - mean_absolute_error: 1.1510 - mean_squared_error: 2.7257 - val_loss: 2.6392 - val_mean_absolute_error: 1.1330 - val_mean_squared_error: 2.6392\n",
            "Epoch 202/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.6945 - mean_absolute_error: 1.1425 - mean_squared_error: 2.6945\n",
            "Epoch 202: val_loss did not improve from 2.63921\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7191 - mean_absolute_error: 1.1484 - mean_squared_error: 2.7191 - val_loss: 2.6393 - val_mean_absolute_error: 1.1439 - val_mean_squared_error: 2.6393\n",
            "Epoch 203/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.7173 - mean_absolute_error: 1.1513 - mean_squared_error: 2.7173\n",
            "Epoch 203: val_loss improved from 2.63921 to 2.62638, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7141 - mean_absolute_error: 1.1490 - mean_squared_error: 2.7141 - val_loss: 2.6264 - val_mean_absolute_error: 1.1330 - val_mean_squared_error: 2.6264\n",
            "Epoch 204/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.7085 - mean_absolute_error: 1.1496 - mean_squared_error: 2.7085\n",
            "Epoch 204: val_loss did not improve from 2.62638\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7112 - mean_absolute_error: 1.1459 - mean_squared_error: 2.7112 - val_loss: 2.6339 - val_mean_absolute_error: 1.1303 - val_mean_squared_error: 2.6339\n",
            "Epoch 205/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.7051 - mean_absolute_error: 1.1470 - mean_squared_error: 2.7051\n",
            "Epoch 205: val_loss improved from 2.62638 to 2.61843, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7051 - mean_absolute_error: 1.1470 - mean_squared_error: 2.7051 - val_loss: 2.6184 - val_mean_absolute_error: 1.1347 - val_mean_squared_error: 2.6184\n",
            "Epoch 206/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.6795 - mean_absolute_error: 1.1409 - mean_squared_error: 2.6795\n",
            "Epoch 206: val_loss did not improve from 2.61843\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6988 - mean_absolute_error: 1.1441 - mean_squared_error: 2.6988 - val_loss: 2.6210 - val_mean_absolute_error: 1.1254 - val_mean_squared_error: 2.6210\n",
            "Epoch 207/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.6988 - mean_absolute_error: 1.1407 - mean_squared_error: 2.6988\n",
            "Epoch 207: val_loss improved from 2.61843 to 2.61593, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6931 - mean_absolute_error: 1.1415 - mean_squared_error: 2.6931 - val_loss: 2.6159 - val_mean_absolute_error: 1.1262 - val_mean_squared_error: 2.6159\n",
            "Epoch 208/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.7208 - mean_absolute_error: 1.1489 - mean_squared_error: 2.7208\n",
            "Epoch 208: val_loss improved from 2.61593 to 2.60465, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6891 - mean_absolute_error: 1.1430 - mean_squared_error: 2.6891 - val_loss: 2.6047 - val_mean_absolute_error: 1.1310 - val_mean_squared_error: 2.6047\n",
            "Epoch 209/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.7069 - mean_absolute_error: 1.1440 - mean_squared_error: 2.7069\n",
            "Epoch 209: val_loss did not improve from 2.60465\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6840 - mean_absolute_error: 1.1399 - mean_squared_error: 2.6840 - val_loss: 2.6078 - val_mean_absolute_error: 1.1243 - val_mean_squared_error: 2.6078\n",
            "Epoch 210/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.7255 - mean_absolute_error: 1.1490 - mean_squared_error: 2.7255\n",
            "Epoch 210: val_loss improved from 2.60465 to 2.60345, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6786 - mean_absolute_error: 1.1401 - mean_squared_error: 2.6786 - val_loss: 2.6034 - val_mean_absolute_error: 1.1363 - val_mean_squared_error: 2.6034\n",
            "Epoch 211/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.6740 - mean_absolute_error: 1.1375 - mean_squared_error: 2.6740\n",
            "Epoch 211: val_loss did not improve from 2.60345\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6736 - mean_absolute_error: 1.1366 - mean_squared_error: 2.6736 - val_loss: 2.6052 - val_mean_absolute_error: 1.1217 - val_mean_squared_error: 2.6052\n",
            "Epoch 212/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.6955 - mean_absolute_error: 1.1413 - mean_squared_error: 2.6955\n",
            "Epoch 212: val_loss improved from 2.60345 to 2.58405, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6691 - mean_absolute_error: 1.1361 - mean_squared_error: 2.6691 - val_loss: 2.5841 - val_mean_absolute_error: 1.1282 - val_mean_squared_error: 2.5841\n",
            "Epoch 213/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.6711 - mean_absolute_error: 1.1400 - mean_squared_error: 2.6711\n",
            "Epoch 213: val_loss improved from 2.58405 to 2.57847, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.6627 - mean_absolute_error: 1.1382 - mean_squared_error: 2.6627 - val_loss: 2.5785 - val_mean_absolute_error: 1.1148 - val_mean_squared_error: 2.5785\n",
            "Epoch 214/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.6731 - mean_absolute_error: 1.1359 - mean_squared_error: 2.6731\n",
            "Epoch 214: val_loss improved from 2.57847 to 2.57253, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6592 - mean_absolute_error: 1.1324 - mean_squared_error: 2.6592 - val_loss: 2.5725 - val_mean_absolute_error: 1.1185 - val_mean_squared_error: 2.5725\n",
            "Epoch 215/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.6531 - mean_absolute_error: 1.1320 - mean_squared_error: 2.6531\n",
            "Epoch 215: val_loss improved from 2.57253 to 2.56836, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6531 - mean_absolute_error: 1.1320 - mean_squared_error: 2.6531 - val_loss: 2.5684 - val_mean_absolute_error: 1.1165 - val_mean_squared_error: 2.5684\n",
            "Epoch 216/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.6103 - mean_absolute_error: 1.1250 - mean_squared_error: 2.6103\n",
            "Epoch 216: val_loss did not improve from 2.56836\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6487 - mean_absolute_error: 1.1316 - mean_squared_error: 2.6487 - val_loss: 2.5720 - val_mean_absolute_error: 1.1137 - val_mean_squared_error: 2.5720\n",
            "Epoch 217/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.6422 - mean_absolute_error: 1.1323 - mean_squared_error: 2.6422\n",
            "Epoch 217: val_loss did not improve from 2.56836\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6433 - mean_absolute_error: 1.1332 - mean_squared_error: 2.6433 - val_loss: 2.5738 - val_mean_absolute_error: 1.1120 - val_mean_squared_error: 2.5738\n",
            "Epoch 218/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.6344 - mean_absolute_error: 1.1266 - mean_squared_error: 2.6344\n",
            "Epoch 218: val_loss improved from 2.56836 to 2.55397, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6396 - mean_absolute_error: 1.1275 - mean_squared_error: 2.6396 - val_loss: 2.5540 - val_mean_absolute_error: 1.1135 - val_mean_squared_error: 2.5540\n",
            "Epoch 219/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.6304 - mean_absolute_error: 1.1297 - mean_squared_error: 2.6304\n",
            "Epoch 219: val_loss did not improve from 2.55397\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6350 - mean_absolute_error: 1.1297 - mean_squared_error: 2.6350 - val_loss: 2.5671 - val_mean_absolute_error: 1.1131 - val_mean_squared_error: 2.5671\n",
            "Epoch 220/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.6452 - mean_absolute_error: 1.1330 - mean_squared_error: 2.6452\n",
            "Epoch 220: val_loss improved from 2.55397 to 2.54772, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.6307 - mean_absolute_error: 1.1287 - mean_squared_error: 2.6307 - val_loss: 2.5477 - val_mean_absolute_error: 1.1111 - val_mean_squared_error: 2.5477\n",
            "Epoch 221/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.6370 - mean_absolute_error: 1.1310 - mean_squared_error: 2.6370\n",
            "Epoch 221: val_loss improved from 2.54772 to 2.54730, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.6256 - mean_absolute_error: 1.1295 - mean_squared_error: 2.6256 - val_loss: 2.5473 - val_mean_absolute_error: 1.1095 - val_mean_squared_error: 2.5473\n",
            "Epoch 222/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.6347 - mean_absolute_error: 1.1339 - mean_squared_error: 2.6347\n",
            "Epoch 222: val_loss improved from 2.54730 to 2.53857, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.6171 - mean_absolute_error: 1.1297 - mean_squared_error: 2.6171 - val_loss: 2.5386 - val_mean_absolute_error: 1.1056 - val_mean_squared_error: 2.5386\n",
            "Epoch 223/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.6116 - mean_absolute_error: 1.1229 - mean_squared_error: 2.6116\n",
            "Epoch 223: val_loss improved from 2.53857 to 2.53207, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.6161 - mean_absolute_error: 1.1243 - mean_squared_error: 2.6161 - val_loss: 2.5321 - val_mean_absolute_error: 1.1092 - val_mean_squared_error: 2.5321\n",
            "Epoch 224/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.6104 - mean_absolute_error: 1.1229 - mean_squared_error: 2.6104\n",
            "Epoch 224: val_loss did not improve from 2.53207\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6071 - mean_absolute_error: 1.1219 - mean_squared_error: 2.6071 - val_loss: 2.5692 - val_mean_absolute_error: 1.1151 - val_mean_squared_error: 2.5692\n",
            "Epoch 225/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.6170 - mean_absolute_error: 1.1288 - mean_squared_error: 2.6170\n",
            "Epoch 225: val_loss improved from 2.53207 to 2.52784, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.6105 - mean_absolute_error: 1.1268 - mean_squared_error: 2.6105 - val_loss: 2.5278 - val_mean_absolute_error: 1.1044 - val_mean_squared_error: 2.5278\n",
            "Epoch 226/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.5974 - mean_absolute_error: 1.1209 - mean_squared_error: 2.5974\n",
            "Epoch 226: val_loss improved from 2.52784 to 2.51764, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.6018 - mean_absolute_error: 1.1218 - mean_squared_error: 2.6018 - val_loss: 2.5176 - val_mean_absolute_error: 1.1078 - val_mean_squared_error: 2.5176\n",
            "Epoch 227/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.5740 - mean_absolute_error: 1.1166 - mean_squared_error: 2.5740\n",
            "Epoch 227: val_loss improved from 2.51764 to 2.51372, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5962 - mean_absolute_error: 1.1207 - mean_squared_error: 2.5962 - val_loss: 2.5137 - val_mean_absolute_error: 1.1095 - val_mean_squared_error: 2.5137\n",
            "Epoch 228/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.5926 - mean_absolute_error: 1.1183 - mean_squared_error: 2.5926\n",
            "Epoch 228: val_loss did not improve from 2.51372\n",
            "245/245 [==============================] - 1s 6ms/step - loss: 2.5903 - mean_absolute_error: 1.1180 - mean_squared_error: 2.5903 - val_loss: 2.5195 - val_mean_absolute_error: 1.1057 - val_mean_squared_error: 2.5195\n",
            "Epoch 229/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.5450 - mean_absolute_error: 1.1081 - mean_squared_error: 2.5450\n",
            "Epoch 229: val_loss improved from 2.51372 to 2.50960, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5880 - mean_absolute_error: 1.1182 - mean_squared_error: 2.5880 - val_loss: 2.5096 - val_mean_absolute_error: 1.1039 - val_mean_squared_error: 2.5096\n",
            "Epoch 230/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.5786 - mean_absolute_error: 1.1179 - mean_squared_error: 2.5786\n",
            "Epoch 230: val_loss improved from 2.50960 to 2.50110, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5832 - mean_absolute_error: 1.1210 - mean_squared_error: 2.5832 - val_loss: 2.5011 - val_mean_absolute_error: 1.1063 - val_mean_squared_error: 2.5011\n",
            "Epoch 231/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.5815 - mean_absolute_error: 1.1196 - mean_squared_error: 2.5815\n",
            "Epoch 231: val_loss improved from 2.50110 to 2.49500, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5794 - mean_absolute_error: 1.1182 - mean_squared_error: 2.5794 - val_loss: 2.4950 - val_mean_absolute_error: 1.1020 - val_mean_squared_error: 2.4950\n",
            "Epoch 232/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.5652 - mean_absolute_error: 1.1150 - mean_squared_error: 2.5652\n",
            "Epoch 232: val_loss did not improve from 2.49500\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5746 - mean_absolute_error: 1.1169 - mean_squared_error: 2.5746 - val_loss: 2.5109 - val_mean_absolute_error: 1.1026 - val_mean_squared_error: 2.5109\n",
            "Epoch 233/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.5926 - mean_absolute_error: 1.1206 - mean_squared_error: 2.5926\n",
            "Epoch 233: val_loss did not improve from 2.49500\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5720 - mean_absolute_error: 1.1163 - mean_squared_error: 2.5720 - val_loss: 2.5048 - val_mean_absolute_error: 1.1013 - val_mean_squared_error: 2.5048\n",
            "Epoch 234/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.5557 - mean_absolute_error: 1.1133 - mean_squared_error: 2.5557\n",
            "Epoch 234: val_loss improved from 2.49500 to 2.48766, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5670 - mean_absolute_error: 1.1166 - mean_squared_error: 2.5670 - val_loss: 2.4877 - val_mean_absolute_error: 1.1014 - val_mean_squared_error: 2.4877\n",
            "Epoch 235/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.5408 - mean_absolute_error: 1.1097 - mean_squared_error: 2.5408\n",
            "Epoch 235: val_loss did not improve from 2.48766\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5620 - mean_absolute_error: 1.1148 - mean_squared_error: 2.5620 - val_loss: 2.5077 - val_mean_absolute_error: 1.1030 - val_mean_squared_error: 2.5077\n",
            "Epoch 236/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.5151 - mean_absolute_error: 1.1061 - mean_squared_error: 2.5151\n",
            "Epoch 236: val_loss improved from 2.48766 to 2.47518, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5585 - mean_absolute_error: 1.1129 - mean_squared_error: 2.5585 - val_loss: 2.4752 - val_mean_absolute_error: 1.1016 - val_mean_squared_error: 2.4752\n",
            "Epoch 237/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.6011 - mean_absolute_error: 1.1252 - mean_squared_error: 2.6011\n",
            "Epoch 237: val_loss did not improve from 2.47518\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5541 - mean_absolute_error: 1.1148 - mean_squared_error: 2.5541 - val_loss: 2.4761 - val_mean_absolute_error: 1.1051 - val_mean_squared_error: 2.4761\n",
            "Epoch 238/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.5514 - mean_absolute_error: 1.1133 - mean_squared_error: 2.5514\n",
            "Epoch 238: val_loss improved from 2.47518 to 2.46552, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5473 - mean_absolute_error: 1.1114 - mean_squared_error: 2.5473 - val_loss: 2.4655 - val_mean_absolute_error: 1.0958 - val_mean_squared_error: 2.4655\n",
            "Epoch 239/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.5418 - mean_absolute_error: 1.1069 - mean_squared_error: 2.5418\n",
            "Epoch 239: val_loss did not improve from 2.46552\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5453 - mean_absolute_error: 1.1088 - mean_squared_error: 2.5453 - val_loss: 2.4672 - val_mean_absolute_error: 1.1050 - val_mean_squared_error: 2.4672\n",
            "Epoch 240/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.5480 - mean_absolute_error: 1.1139 - mean_squared_error: 2.5480\n",
            "Epoch 240: val_loss did not improve from 2.46552\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5403 - mean_absolute_error: 1.1126 - mean_squared_error: 2.5403 - val_loss: 2.4656 - val_mean_absolute_error: 1.0949 - val_mean_squared_error: 2.4656\n",
            "Epoch 241/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.5297 - mean_absolute_error: 1.1050 - mean_squared_error: 2.5297\n",
            "Epoch 241: val_loss improved from 2.46552 to 2.45635, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5392 - mean_absolute_error: 1.1091 - mean_squared_error: 2.5392 - val_loss: 2.4564 - val_mean_absolute_error: 1.1027 - val_mean_squared_error: 2.4564\n",
            "Epoch 242/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.5458 - mean_absolute_error: 1.1130 - mean_squared_error: 2.5458\n",
            "Epoch 242: val_loss improved from 2.45635 to 2.45407, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5305 - mean_absolute_error: 1.1089 - mean_squared_error: 2.5305 - val_loss: 2.4541 - val_mean_absolute_error: 1.1032 - val_mean_squared_error: 2.4541\n",
            "Epoch 243/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.4843 - mean_absolute_error: 1.0974 - mean_squared_error: 2.4843\n",
            "Epoch 243: val_loss improved from 2.45407 to 2.44640, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5277 - mean_absolute_error: 1.1061 - mean_squared_error: 2.5277 - val_loss: 2.4464 - val_mean_absolute_error: 1.0960 - val_mean_squared_error: 2.4464\n",
            "Epoch 244/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.5208 - mean_absolute_error: 1.1105 - mean_squared_error: 2.5208\n",
            "Epoch 244: val_loss improved from 2.44640 to 2.44283, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5237 - mean_absolute_error: 1.1100 - mean_squared_error: 2.5237 - val_loss: 2.4428 - val_mean_absolute_error: 1.0917 - val_mean_squared_error: 2.4428\n",
            "Epoch 245/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.5154 - mean_absolute_error: 1.1079 - mean_squared_error: 2.5154\n",
            "Epoch 245: val_loss improved from 2.44283 to 2.44230, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5171 - mean_absolute_error: 1.1054 - mean_squared_error: 2.5171 - val_loss: 2.4423 - val_mean_absolute_error: 1.0902 - val_mean_squared_error: 2.4423\n",
            "Epoch 246/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.5125 - mean_absolute_error: 1.1077 - mean_squared_error: 2.5125\n",
            "Epoch 246: val_loss improved from 2.44230 to 2.43945, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5136 - mean_absolute_error: 1.1074 - mean_squared_error: 2.5136 - val_loss: 2.4395 - val_mean_absolute_error: 1.0901 - val_mean_squared_error: 2.4395\n",
            "Epoch 247/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.4724 - mean_absolute_error: 1.0962 - mean_squared_error: 2.4724\n",
            "Epoch 247: val_loss improved from 2.43945 to 2.42786, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5097 - mean_absolute_error: 1.1028 - mean_squared_error: 2.5097 - val_loss: 2.4279 - val_mean_absolute_error: 1.0909 - val_mean_squared_error: 2.4279\n",
            "Epoch 248/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.4986 - mean_absolute_error: 1.1020 - mean_squared_error: 2.4986\n",
            "Epoch 248: val_loss improved from 2.42786 to 2.42513, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5059 - mean_absolute_error: 1.1034 - mean_squared_error: 2.5059 - val_loss: 2.4251 - val_mean_absolute_error: 1.0887 - val_mean_squared_error: 2.4251\n",
            "Epoch 249/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.4970 - mean_absolute_error: 1.1020 - mean_squared_error: 2.4970\n",
            "Epoch 249: val_loss did not improve from 2.42513\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.4998 - mean_absolute_error: 1.1027 - mean_squared_error: 2.4998 - val_loss: 2.4267 - val_mean_absolute_error: 1.0904 - val_mean_squared_error: 2.4267\n",
            "Epoch 250/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.5251 - mean_absolute_error: 1.1077 - mean_squared_error: 2.5251\n",
            "Epoch 250: val_loss improved from 2.42513 to 2.41552, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4945 - mean_absolute_error: 1.1016 - mean_squared_error: 2.4945 - val_loss: 2.4155 - val_mean_absolute_error: 1.0900 - val_mean_squared_error: 2.4155\n",
            "Epoch 251/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.4856 - mean_absolute_error: 1.1012 - mean_squared_error: 2.4856\n",
            "Epoch 251: val_loss improved from 2.41552 to 2.41233, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4910 - mean_absolute_error: 1.1037 - mean_squared_error: 2.4910 - val_loss: 2.4123 - val_mean_absolute_error: 1.0863 - val_mean_squared_error: 2.4123\n",
            "Epoch 252/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.4644 - mean_absolute_error: 1.0969 - mean_squared_error: 2.4644\n",
            "Epoch 252: val_loss improved from 2.41233 to 2.40732, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4893 - mean_absolute_error: 1.1011 - mean_squared_error: 2.4893 - val_loss: 2.4073 - val_mean_absolute_error: 1.0842 - val_mean_squared_error: 2.4073\n",
            "Epoch 253/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.4786 - mean_absolute_error: 1.1007 - mean_squared_error: 2.4786\n",
            "Epoch 253: val_loss did not improve from 2.40732\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4786 - mean_absolute_error: 1.1007 - mean_squared_error: 2.4786 - val_loss: 2.4135 - val_mean_absolute_error: 1.0859 - val_mean_squared_error: 2.4135\n",
            "Epoch 254/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.4656 - mean_absolute_error: 1.0943 - mean_squared_error: 2.4656\n",
            "Epoch 254: val_loss did not improve from 2.40732\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4788 - mean_absolute_error: 1.0991 - mean_squared_error: 2.4788 - val_loss: 2.4118 - val_mean_absolute_error: 1.0954 - val_mean_squared_error: 2.4118\n",
            "Epoch 255/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.4795 - mean_absolute_error: 1.0991 - mean_squared_error: 2.4795\n",
            "Epoch 255: val_loss improved from 2.40732 to 2.39973, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4761 - mean_absolute_error: 1.0987 - mean_squared_error: 2.4761 - val_loss: 2.3997 - val_mean_absolute_error: 1.0815 - val_mean_squared_error: 2.3997\n",
            "Epoch 256/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.4978 - mean_absolute_error: 1.1029 - mean_squared_error: 2.4978\n",
            "Epoch 256: val_loss did not improve from 2.39973\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4711 - mean_absolute_error: 1.0952 - mean_squared_error: 2.4711 - val_loss: 2.4056 - val_mean_absolute_error: 1.0853 - val_mean_squared_error: 2.4056\n",
            "Epoch 257/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.4567 - mean_absolute_error: 1.0924 - mean_squared_error: 2.4567\n",
            "Epoch 257: val_loss improved from 2.39973 to 2.39402, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4675 - mean_absolute_error: 1.0971 - mean_squared_error: 2.4675 - val_loss: 2.3940 - val_mean_absolute_error: 1.0870 - val_mean_squared_error: 2.3940\n",
            "Epoch 258/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.4419 - mean_absolute_error: 1.0882 - mean_squared_error: 2.4419\n",
            "Epoch 258: val_loss improved from 2.39402 to 2.38161, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4604 - mean_absolute_error: 1.0926 - mean_squared_error: 2.4604 - val_loss: 2.3816 - val_mean_absolute_error: 1.0829 - val_mean_squared_error: 2.3816\n",
            "Epoch 259/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.4682 - mean_absolute_error: 1.0969 - mean_squared_error: 2.4682\n",
            "Epoch 259: val_loss improved from 2.38161 to 2.37692, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4594 - mean_absolute_error: 1.0944 - mean_squared_error: 2.4594 - val_loss: 2.3769 - val_mean_absolute_error: 1.0802 - val_mean_squared_error: 2.3769\n",
            "Epoch 260/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.4466 - mean_absolute_error: 1.0921 - mean_squared_error: 2.4466\n",
            "Epoch 260: val_loss did not improve from 2.37692\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4535 - mean_absolute_error: 1.0933 - mean_squared_error: 2.4535 - val_loss: 2.3807 - val_mean_absolute_error: 1.0834 - val_mean_squared_error: 2.3807\n",
            "Epoch 261/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.4520 - mean_absolute_error: 1.0942 - mean_squared_error: 2.4520\n",
            "Epoch 261: val_loss did not improve from 2.37692\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4431 - mean_absolute_error: 1.0921 - mean_squared_error: 2.4431 - val_loss: 2.4005 - val_mean_absolute_error: 1.0986 - val_mean_squared_error: 2.4005\n",
            "Epoch 262/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.4469 - mean_absolute_error: 1.0925 - mean_squared_error: 2.4469\n",
            "Epoch 262: val_loss did not improve from 2.37692\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4470 - mean_absolute_error: 1.0920 - mean_squared_error: 2.4470 - val_loss: 2.3875 - val_mean_absolute_error: 1.0832 - val_mean_squared_error: 2.3875\n",
            "Epoch 263/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.4524 - mean_absolute_error: 1.0930 - mean_squared_error: 2.4524\n",
            "Epoch 263: val_loss improved from 2.37692 to 2.36226, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4423 - mean_absolute_error: 1.0920 - mean_squared_error: 2.4423 - val_loss: 2.3623 - val_mean_absolute_error: 1.0801 - val_mean_squared_error: 2.3623\n",
            "Epoch 264/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.4309 - mean_absolute_error: 1.0882 - mean_squared_error: 2.4309\n",
            "Epoch 264: val_loss improved from 2.36226 to 2.35693, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4362 - mean_absolute_error: 1.0893 - mean_squared_error: 2.4362 - val_loss: 2.3569 - val_mean_absolute_error: 1.0740 - val_mean_squared_error: 2.3569\n",
            "Epoch 265/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.4387 - mean_absolute_error: 1.0893 - mean_squared_error: 2.4387\n",
            "Epoch 265: val_loss improved from 2.35693 to 2.35384, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4330 - mean_absolute_error: 1.0890 - mean_squared_error: 2.4330 - val_loss: 2.3538 - val_mean_absolute_error: 1.0750 - val_mean_squared_error: 2.3538\n",
            "Epoch 266/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 2.4579 - mean_absolute_error: 1.0951 - mean_squared_error: 2.4579\n",
            "Epoch 266: val_loss improved from 2.35384 to 2.34987, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4301 - mean_absolute_error: 1.0882 - mean_squared_error: 2.4301 - val_loss: 2.3499 - val_mean_absolute_error: 1.0738 - val_mean_squared_error: 2.3499\n",
            "Epoch 267/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.4183 - mean_absolute_error: 1.0802 - mean_squared_error: 2.4183\n",
            "Epoch 267: val_loss improved from 2.34987 to 2.34566, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4229 - mean_absolute_error: 1.0851 - mean_squared_error: 2.4229 - val_loss: 2.3457 - val_mean_absolute_error: 1.0757 - val_mean_squared_error: 2.3457\n",
            "Epoch 268/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.4109 - mean_absolute_error: 1.0814 - mean_squared_error: 2.4109\n",
            "Epoch 268: val_loss improved from 2.34566 to 2.34042, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4174 - mean_absolute_error: 1.0845 - mean_squared_error: 2.4174 - val_loss: 2.3404 - val_mean_absolute_error: 1.0727 - val_mean_squared_error: 2.3404\n",
            "Epoch 269/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.4162 - mean_absolute_error: 1.0845 - mean_squared_error: 2.4162\n",
            "Epoch 269: val_loss did not improve from 2.34042\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4148 - mean_absolute_error: 1.0835 - mean_squared_error: 2.4148 - val_loss: 2.3434 - val_mean_absolute_error: 1.0721 - val_mean_squared_error: 2.3434\n",
            "Epoch 270/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.4020 - mean_absolute_error: 1.0878 - mean_squared_error: 2.4020\n",
            "Epoch 270: val_loss improved from 2.34042 to 2.33717, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4050 - mean_absolute_error: 1.0877 - mean_squared_error: 2.4050 - val_loss: 2.3372 - val_mean_absolute_error: 1.0683 - val_mean_squared_error: 2.3372\n",
            "Epoch 271/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.4065 - mean_absolute_error: 1.0844 - mean_squared_error: 2.4065\n",
            "Epoch 271: val_loss did not improve from 2.33717\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4065 - mean_absolute_error: 1.0844 - mean_squared_error: 2.4065 - val_loss: 2.3378 - val_mean_absolute_error: 1.0724 - val_mean_squared_error: 2.3378\n",
            "Epoch 272/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.4278 - mean_absolute_error: 1.0891 - mean_squared_error: 2.4278\n",
            "Epoch 272: val_loss did not improve from 2.33717\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3959 - mean_absolute_error: 1.0815 - mean_squared_error: 2.3959 - val_loss: 2.3373 - val_mean_absolute_error: 1.0722 - val_mean_squared_error: 2.3373\n",
            "Epoch 273/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.3722 - mean_absolute_error: 1.0743 - mean_squared_error: 2.3722\n",
            "Epoch 273: val_loss improved from 2.33717 to 2.32120, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3962 - mean_absolute_error: 1.0807 - mean_squared_error: 2.3962 - val_loss: 2.3212 - val_mean_absolute_error: 1.0670 - val_mean_squared_error: 2.3212\n",
            "Epoch 274/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.4040 - mean_absolute_error: 1.0827 - mean_squared_error: 2.4040\n",
            "Epoch 274: val_loss improved from 2.32120 to 2.31912, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3959 - mean_absolute_error: 1.0818 - mean_squared_error: 2.3959 - val_loss: 2.3191 - val_mean_absolute_error: 1.0660 - val_mean_squared_error: 2.3191\n",
            "Epoch 275/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.3879 - mean_absolute_error: 1.0768 - mean_squared_error: 2.3879\n",
            "Epoch 275: val_loss improved from 2.31912 to 2.31583, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3889 - mean_absolute_error: 1.0779 - mean_squared_error: 2.3889 - val_loss: 2.3158 - val_mean_absolute_error: 1.0708 - val_mean_squared_error: 2.3158\n",
            "Epoch 276/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.3733 - mean_absolute_error: 1.0762 - mean_squared_error: 2.3733\n",
            "Epoch 276: val_loss improved from 2.31583 to 2.31022, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3845 - mean_absolute_error: 1.0789 - mean_squared_error: 2.3845 - val_loss: 2.3102 - val_mean_absolute_error: 1.0641 - val_mean_squared_error: 2.3102\n",
            "Epoch 277/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.3820 - mean_absolute_error: 1.0800 - mean_squared_error: 2.3820\n",
            "Epoch 277: val_loss improved from 2.31022 to 2.30572, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3820 - mean_absolute_error: 1.0800 - mean_squared_error: 2.3820 - val_loss: 2.3057 - val_mean_absolute_error: 1.0613 - val_mean_squared_error: 2.3057\n",
            "Epoch 278/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.3868 - mean_absolute_error: 1.0770 - mean_squared_error: 2.3868\n",
            "Epoch 278: val_loss improved from 2.30572 to 2.30148, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3736 - mean_absolute_error: 1.0763 - mean_squared_error: 2.3736 - val_loss: 2.3015 - val_mean_absolute_error: 1.0598 - val_mean_squared_error: 2.3015\n",
            "Epoch 279/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.3838 - mean_absolute_error: 1.0783 - mean_squared_error: 2.3838\n",
            "Epoch 279: val_loss improved from 2.30148 to 2.29633, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3724 - mean_absolute_error: 1.0738 - mean_squared_error: 2.3724 - val_loss: 2.2963 - val_mean_absolute_error: 1.0621 - val_mean_squared_error: 2.2963\n",
            "Epoch 280/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.3681 - mean_absolute_error: 1.0768 - mean_squared_error: 2.3681\n",
            "Epoch 280: val_loss did not improve from 2.29633\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3705 - mean_absolute_error: 1.0756 - mean_squared_error: 2.3705 - val_loss: 2.2975 - val_mean_absolute_error: 1.0619 - val_mean_squared_error: 2.2975\n",
            "Epoch 281/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.3652 - mean_absolute_error: 1.0749 - mean_squared_error: 2.3652\n",
            "Epoch 281: val_loss improved from 2.29633 to 2.28872, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3628 - mean_absolute_error: 1.0740 - mean_squared_error: 2.3628 - val_loss: 2.2887 - val_mean_absolute_error: 1.0581 - val_mean_squared_error: 2.2887\n",
            "Epoch 282/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 2.3887 - mean_absolute_error: 1.0826 - mean_squared_error: 2.3887\n",
            "Epoch 282: val_loss improved from 2.28872 to 2.28570, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3553 - mean_absolute_error: 1.0725 - mean_squared_error: 2.3553 - val_loss: 2.2857 - val_mean_absolute_error: 1.0576 - val_mean_squared_error: 2.2857\n",
            "Epoch 283/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.3204 - mean_absolute_error: 1.0646 - mean_squared_error: 2.3204\n",
            "Epoch 283: val_loss improved from 2.28570 to 2.28288, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3540 - mean_absolute_error: 1.0711 - mean_squared_error: 2.3540 - val_loss: 2.2829 - val_mean_absolute_error: 1.0594 - val_mean_squared_error: 2.2829\n",
            "Epoch 284/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.3407 - mean_absolute_error: 1.0692 - mean_squared_error: 2.3407\n",
            "Epoch 284: val_loss improved from 2.28288 to 2.27593, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3495 - mean_absolute_error: 1.0709 - mean_squared_error: 2.3495 - val_loss: 2.2759 - val_mean_absolute_error: 1.0561 - val_mean_squared_error: 2.2759\n",
            "Epoch 285/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.3428 - mean_absolute_error: 1.0692 - mean_squared_error: 2.3428\n",
            "Epoch 285: val_loss improved from 2.27593 to 2.27177, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3438 - mean_absolute_error: 1.0695 - mean_squared_error: 2.3438 - val_loss: 2.2718 - val_mean_absolute_error: 1.0557 - val_mean_squared_error: 2.2718\n",
            "Epoch 286/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.3387 - mean_absolute_error: 1.0686 - mean_squared_error: 2.3387\n",
            "Epoch 286: val_loss did not improve from 2.27177\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3471 - mean_absolute_error: 1.0698 - mean_squared_error: 2.3471 - val_loss: 2.2732 - val_mean_absolute_error: 1.0572 - val_mean_squared_error: 2.2732\n",
            "Epoch 287/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.3411 - mean_absolute_error: 1.0658 - mean_squared_error: 2.3411\n",
            "Epoch 287: val_loss did not improve from 2.27177\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3374 - mean_absolute_error: 1.0649 - mean_squared_error: 2.3374 - val_loss: 2.2988 - val_mean_absolute_error: 1.0704 - val_mean_squared_error: 2.2988\n",
            "Epoch 288/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.3420 - mean_absolute_error: 1.0696 - mean_squared_error: 2.3420\n",
            "Epoch 288: val_loss improved from 2.27177 to 2.26145, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3372 - mean_absolute_error: 1.0693 - mean_squared_error: 2.3372 - val_loss: 2.2614 - val_mean_absolute_error: 1.0539 - val_mean_squared_error: 2.2614\n",
            "Epoch 289/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.3361 - mean_absolute_error: 1.0652 - mean_squared_error: 2.3361\n",
            "Epoch 289: val_loss improved from 2.26145 to 2.25575, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3291 - mean_absolute_error: 1.0646 - mean_squared_error: 2.3291 - val_loss: 2.2558 - val_mean_absolute_error: 1.0536 - val_mean_squared_error: 2.2558\n",
            "Epoch 290/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.3284 - mean_absolute_error: 1.0671 - mean_squared_error: 2.3284\n",
            "Epoch 290: val_loss improved from 2.25575 to 2.25129, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3217 - mean_absolute_error: 1.0641 - mean_squared_error: 2.3217 - val_loss: 2.2513 - val_mean_absolute_error: 1.0485 - val_mean_squared_error: 2.2513\n",
            "Epoch 291/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.3080 - mean_absolute_error: 1.0606 - mean_squared_error: 2.3080\n",
            "Epoch 291: val_loss did not improve from 2.25129\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3254 - mean_absolute_error: 1.0641 - mean_squared_error: 2.3254 - val_loss: 2.2768 - val_mean_absolute_error: 1.0642 - val_mean_squared_error: 2.2768\n",
            "Epoch 292/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.3109 - mean_absolute_error: 1.0634 - mean_squared_error: 2.3109\n",
            "Epoch 292: val_loss improved from 2.25129 to 2.24430, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3119 - mean_absolute_error: 1.0633 - mean_squared_error: 2.3119 - val_loss: 2.2443 - val_mean_absolute_error: 1.0519 - val_mean_squared_error: 2.2443\n",
            "Epoch 293/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.2905 - mean_absolute_error: 1.0554 - mean_squared_error: 2.2905\n",
            "Epoch 293: val_loss did not improve from 2.24430\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3085 - mean_absolute_error: 1.0593 - mean_squared_error: 2.3085 - val_loss: 2.2807 - val_mean_absolute_error: 1.0676 - val_mean_squared_error: 2.2807\n",
            "Epoch 294/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.3184 - mean_absolute_error: 1.0649 - mean_squared_error: 2.3184\n",
            "Epoch 294: val_loss improved from 2.24430 to 2.23922, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3031 - mean_absolute_error: 1.0626 - mean_squared_error: 2.3031 - val_loss: 2.2392 - val_mean_absolute_error: 1.0492 - val_mean_squared_error: 2.2392\n",
            "Epoch 295/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.2883 - mean_absolute_error: 1.0604 - mean_squared_error: 2.2883\n",
            "Epoch 295: val_loss improved from 2.23922 to 2.23191, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2987 - mean_absolute_error: 1.0599 - mean_squared_error: 2.2987 - val_loss: 2.2319 - val_mean_absolute_error: 1.0443 - val_mean_squared_error: 2.2319\n",
            "Epoch 296/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.2641 - mean_absolute_error: 1.0511 - mean_squared_error: 2.2641\n",
            "Epoch 296: val_loss did not improve from 2.23191\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.2957 - mean_absolute_error: 1.0555 - mean_squared_error: 2.2957 - val_loss: 2.2357 - val_mean_absolute_error: 1.0497 - val_mean_squared_error: 2.2357\n",
            "Epoch 297/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.3196 - mean_absolute_error: 1.0644 - mean_squared_error: 2.3196\n",
            "Epoch 297: val_loss improved from 2.23191 to 2.22292, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.2934 - mean_absolute_error: 1.0579 - mean_squared_error: 2.2934 - val_loss: 2.2229 - val_mean_absolute_error: 1.0461 - val_mean_squared_error: 2.2229\n",
            "Epoch 298/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.3012 - mean_absolute_error: 1.0595 - mean_squared_error: 2.3012\n",
            "Epoch 298: val_loss improved from 2.22292 to 2.21893, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.2952 - mean_absolute_error: 1.0585 - mean_squared_error: 2.2952 - val_loss: 2.2189 - val_mean_absolute_error: 1.0439 - val_mean_squared_error: 2.2189\n",
            "Epoch 299/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.2673 - mean_absolute_error: 1.0522 - mean_squared_error: 2.2673\n",
            "Epoch 299: val_loss did not improve from 2.21893\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2809 - mean_absolute_error: 1.0553 - mean_squared_error: 2.2809 - val_loss: 2.2513 - val_mean_absolute_error: 1.0578 - val_mean_squared_error: 2.2513\n",
            "Epoch 300/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.2874 - mean_absolute_error: 1.0560 - mean_squared_error: 2.2874\n",
            "Epoch 300: val_loss improved from 2.21893 to 2.21441, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2858 - mean_absolute_error: 1.0548 - mean_squared_error: 2.2858 - val_loss: 2.2144 - val_mean_absolute_error: 1.0428 - val_mean_squared_error: 2.2144\n",
            "Epoch 301/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.2933 - mean_absolute_error: 1.0577 - mean_squared_error: 2.2933\n",
            "Epoch 301: val_loss improved from 2.21441 to 2.20624, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2774 - mean_absolute_error: 1.0536 - mean_squared_error: 2.2774 - val_loss: 2.2062 - val_mean_absolute_error: 1.0384 - val_mean_squared_error: 2.2062\n",
            "Epoch 302/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.2823 - mean_absolute_error: 1.0572 - mean_squared_error: 2.2823\n",
            "Epoch 302: val_loss improved from 2.20624 to 2.20459, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2727 - mean_absolute_error: 1.0549 - mean_squared_error: 2.2727 - val_loss: 2.2046 - val_mean_absolute_error: 1.0395 - val_mean_squared_error: 2.2046\n",
            "Epoch 303/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.2684 - mean_absolute_error: 1.0492 - mean_squared_error: 2.2684\n",
            "Epoch 303: val_loss improved from 2.20459 to 2.19796, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2715 - mean_absolute_error: 1.0511 - mean_squared_error: 2.2715 - val_loss: 2.1980 - val_mean_absolute_error: 1.0350 - val_mean_squared_error: 2.1980\n",
            "Epoch 304/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.2616 - mean_absolute_error: 1.0500 - mean_squared_error: 2.2616\n",
            "Epoch 304: val_loss improved from 2.19796 to 2.19416, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2610 - mean_absolute_error: 1.0494 - mean_squared_error: 2.2610 - val_loss: 2.1942 - val_mean_absolute_error: 1.0349 - val_mean_squared_error: 2.1942\n",
            "Epoch 305/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.2658 - mean_absolute_error: 1.0479 - mean_squared_error: 2.2658\n",
            "Epoch 305: val_loss improved from 2.19416 to 2.19148, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2562 - mean_absolute_error: 1.0449 - mean_squared_error: 2.2562 - val_loss: 2.1915 - val_mean_absolute_error: 1.0377 - val_mean_squared_error: 2.1915\n",
            "Epoch 306/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.2607 - mean_absolute_error: 1.0475 - mean_squared_error: 2.2607\n",
            "Epoch 306: val_loss improved from 2.19148 to 2.19139, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2517 - mean_absolute_error: 1.0464 - mean_squared_error: 2.2517 - val_loss: 2.1914 - val_mean_absolute_error: 1.0384 - val_mean_squared_error: 2.1914\n",
            "Epoch 307/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.2451 - mean_absolute_error: 1.0447 - mean_squared_error: 2.2451\n",
            "Epoch 307: val_loss improved from 2.19139 to 2.18466, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2492 - mean_absolute_error: 1.0470 - mean_squared_error: 2.2492 - val_loss: 2.1847 - val_mean_absolute_error: 1.0359 - val_mean_squared_error: 2.1847\n",
            "Epoch 308/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.2448 - mean_absolute_error: 1.0452 - mean_squared_error: 2.2448\n",
            "Epoch 308: val_loss improved from 2.18466 to 2.18157, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2483 - mean_absolute_error: 1.0453 - mean_squared_error: 2.2483 - val_loss: 2.1816 - val_mean_absolute_error: 1.0335 - val_mean_squared_error: 2.1816\n",
            "Epoch 309/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 2.2373 - mean_absolute_error: 1.0434 - mean_squared_error: 2.2373\n",
            "Epoch 309: val_loss improved from 2.18157 to 2.17810, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2407 - mean_absolute_error: 1.0448 - mean_squared_error: 2.2407 - val_loss: 2.1781 - val_mean_absolute_error: 1.0310 - val_mean_squared_error: 2.1781\n",
            "Epoch 310/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.2141 - mean_absolute_error: 1.0392 - mean_squared_error: 2.2141\n",
            "Epoch 310: val_loss did not improve from 2.17810\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2324 - mean_absolute_error: 1.0418 - mean_squared_error: 2.2324 - val_loss: 2.1863 - val_mean_absolute_error: 1.0408 - val_mean_squared_error: 2.1863\n",
            "Epoch 311/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.2478 - mean_absolute_error: 1.0477 - mean_squared_error: 2.2478\n",
            "Epoch 311: val_loss did not improve from 2.17810\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2351 - mean_absolute_error: 1.0451 - mean_squared_error: 2.2351 - val_loss: 2.1860 - val_mean_absolute_error: 1.0385 - val_mean_squared_error: 2.1860\n",
            "Epoch 312/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.2338 - mean_absolute_error: 1.0406 - mean_squared_error: 2.2338\n",
            "Epoch 312: val_loss improved from 2.17810 to 2.17563, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2310 - mean_absolute_error: 1.0410 - mean_squared_error: 2.2310 - val_loss: 2.1756 - val_mean_absolute_error: 1.0380 - val_mean_squared_error: 2.1756\n",
            "Epoch 313/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.2408 - mean_absolute_error: 1.0408 - mean_squared_error: 2.2408\n",
            "Epoch 313: val_loss improved from 2.17563 to 2.16214, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2265 - mean_absolute_error: 1.0391 - mean_squared_error: 2.2265 - val_loss: 2.1621 - val_mean_absolute_error: 1.0314 - val_mean_squared_error: 2.1621\n",
            "Epoch 314/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.2026 - mean_absolute_error: 1.0356 - mean_squared_error: 2.2026\n",
            "Epoch 314: val_loss did not improve from 2.16214\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2163 - mean_absolute_error: 1.0394 - mean_squared_error: 2.2163 - val_loss: 2.1692 - val_mean_absolute_error: 1.0320 - val_mean_squared_error: 2.1692\n",
            "Epoch 315/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.2022 - mean_absolute_error: 1.0338 - mean_squared_error: 2.2022\n",
            "Epoch 315: val_loss improved from 2.16214 to 2.15896, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2182 - mean_absolute_error: 1.0379 - mean_squared_error: 2.2182 - val_loss: 2.1590 - val_mean_absolute_error: 1.0316 - val_mean_squared_error: 2.1590\n",
            "Epoch 316/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.2138 - mean_absolute_error: 1.0380 - mean_squared_error: 2.2138\n",
            "Epoch 316: val_loss improved from 2.15896 to 2.14871, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2127 - mean_absolute_error: 1.0389 - mean_squared_error: 2.2127 - val_loss: 2.1487 - val_mean_absolute_error: 1.0240 - val_mean_squared_error: 2.1487\n",
            "Epoch 317/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.1922 - mean_absolute_error: 1.0357 - mean_squared_error: 2.1922\n",
            "Epoch 317: val_loss did not improve from 2.14871\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2103 - mean_absolute_error: 1.0379 - mean_squared_error: 2.2103 - val_loss: 2.1601 - val_mean_absolute_error: 1.0235 - val_mean_squared_error: 2.1601\n",
            "Epoch 318/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.2240 - mean_absolute_error: 1.0394 - mean_squared_error: 2.2240\n",
            "Epoch 318: val_loss improved from 2.14871 to 2.14784, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2054 - mean_absolute_error: 1.0351 - mean_squared_error: 2.2054 - val_loss: 2.1478 - val_mean_absolute_error: 1.0234 - val_mean_squared_error: 2.1478\n",
            "Epoch 319/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.1996 - mean_absolute_error: 1.0318 - mean_squared_error: 2.1996\n",
            "Epoch 319: val_loss improved from 2.14784 to 2.14015, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2018 - mean_absolute_error: 1.0341 - mean_squared_error: 2.2018 - val_loss: 2.1402 - val_mean_absolute_error: 1.0205 - val_mean_squared_error: 2.1402\n",
            "Epoch 320/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.1954 - mean_absolute_error: 1.0336 - mean_squared_error: 2.1954\n",
            "Epoch 320: val_loss improved from 2.14015 to 2.13510, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1943 - mean_absolute_error: 1.0328 - mean_squared_error: 2.1943 - val_loss: 2.1351 - val_mean_absolute_error: 1.0157 - val_mean_squared_error: 2.1351\n",
            "Epoch 321/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.1855 - mean_absolute_error: 1.0266 - mean_squared_error: 2.1855\n",
            "Epoch 321: val_loss improved from 2.13510 to 2.13125, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1953 - mean_absolute_error: 1.0300 - mean_squared_error: 2.1953 - val_loss: 2.1312 - val_mean_absolute_error: 1.0196 - val_mean_squared_error: 2.1312\n",
            "Epoch 322/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.1882 - mean_absolute_error: 1.0310 - mean_squared_error: 2.1882\n",
            "Epoch 322: val_loss improved from 2.13125 to 2.12786, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1872 - mean_absolute_error: 1.0310 - mean_squared_error: 2.1872 - val_loss: 2.1279 - val_mean_absolute_error: 1.0173 - val_mean_squared_error: 2.1279\n",
            "Epoch 323/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.1430 - mean_absolute_error: 1.0200 - mean_squared_error: 2.1430\n",
            "Epoch 323: val_loss improved from 2.12786 to 2.12469, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1854 - mean_absolute_error: 1.0262 - mean_squared_error: 2.1854 - val_loss: 2.1247 - val_mean_absolute_error: 1.0208 - val_mean_squared_error: 2.1247\n",
            "Epoch 324/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.1948 - mean_absolute_error: 1.0339 - mean_squared_error: 2.1948\n",
            "Epoch 324: val_loss did not improve from 2.12469\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1816 - mean_absolute_error: 1.0304 - mean_squared_error: 2.1816 - val_loss: 2.1348 - val_mean_absolute_error: 1.0208 - val_mean_squared_error: 2.1348\n",
            "Epoch 325/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 2.1433 - mean_absolute_error: 1.0205 - mean_squared_error: 2.1433\n",
            "Epoch 325: val_loss improved from 2.12469 to 2.11603, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1787 - mean_absolute_error: 1.0298 - mean_squared_error: 2.1787 - val_loss: 2.1160 - val_mean_absolute_error: 1.0156 - val_mean_squared_error: 2.1160\n",
            "Epoch 326/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.1649 - mean_absolute_error: 1.0218 - mean_squared_error: 2.1649\n",
            "Epoch 326: val_loss improved from 2.11603 to 2.11307, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1760 - mean_absolute_error: 1.0248 - mean_squared_error: 2.1760 - val_loss: 2.1131 - val_mean_absolute_error: 1.0165 - val_mean_squared_error: 2.1131\n",
            "Epoch 327/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.1742 - mean_absolute_error: 1.0295 - mean_squared_error: 2.1742\n",
            "Epoch 327: val_loss improved from 2.11307 to 2.11163, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1701 - mean_absolute_error: 1.0284 - mean_squared_error: 2.1701 - val_loss: 2.1116 - val_mean_absolute_error: 1.0154 - val_mean_squared_error: 2.1116\n",
            "Epoch 328/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.1758 - mean_absolute_error: 1.0255 - mean_squared_error: 2.1758\n",
            "Epoch 328: val_loss improved from 2.11163 to 2.11123, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1706 - mean_absolute_error: 1.0239 - mean_squared_error: 2.1706 - val_loss: 2.1112 - val_mean_absolute_error: 1.0136 - val_mean_squared_error: 2.1112\n",
            "Epoch 329/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.1387 - mean_absolute_error: 1.0171 - mean_squared_error: 2.1387\n",
            "Epoch 329: val_loss improved from 2.11123 to 2.10416, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1619 - mean_absolute_error: 1.0236 - mean_squared_error: 2.1619 - val_loss: 2.1042 - val_mean_absolute_error: 1.0168 - val_mean_squared_error: 2.1042\n",
            "Epoch 330/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.1613 - mean_absolute_error: 1.0233 - mean_squared_error: 2.1613\n",
            "Epoch 330: val_loss improved from 2.10416 to 2.10257, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1577 - mean_absolute_error: 1.0226 - mean_squared_error: 2.1577 - val_loss: 2.1026 - val_mean_absolute_error: 1.0177 - val_mean_squared_error: 2.1026\n",
            "Epoch 331/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.1326 - mean_absolute_error: 1.0214 - mean_squared_error: 2.1326\n",
            "Epoch 331: val_loss improved from 2.10257 to 2.09757, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1503 - mean_absolute_error: 1.0250 - mean_squared_error: 2.1503 - val_loss: 2.0976 - val_mean_absolute_error: 1.0045 - val_mean_squared_error: 2.0976\n",
            "Epoch 332/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.1511 - mean_absolute_error: 1.0213 - mean_squared_error: 2.1511\n",
            "Epoch 332: val_loss improved from 2.09757 to 2.09185, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1513 - mean_absolute_error: 1.0189 - mean_squared_error: 2.1513 - val_loss: 2.0918 - val_mean_absolute_error: 1.0098 - val_mean_squared_error: 2.0918\n",
            "Epoch 333/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.1743 - mean_absolute_error: 1.0244 - mean_squared_error: 2.1743\n",
            "Epoch 333: val_loss did not improve from 2.09185\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1483 - mean_absolute_error: 1.0204 - mean_squared_error: 2.1483 - val_loss: 2.1049 - val_mean_absolute_error: 1.0210 - val_mean_squared_error: 2.1049\n",
            "Epoch 334/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.1308 - mean_absolute_error: 1.0144 - mean_squared_error: 2.1308\n",
            "Epoch 334: val_loss did not improve from 2.09185\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1437 - mean_absolute_error: 1.0187 - mean_squared_error: 2.1437 - val_loss: 2.0965 - val_mean_absolute_error: 1.0168 - val_mean_squared_error: 2.0965\n",
            "Epoch 335/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.1442 - mean_absolute_error: 1.0180 - mean_squared_error: 2.1442\n",
            "Epoch 335: val_loss did not improve from 2.09185\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1358 - mean_absolute_error: 1.0156 - mean_squared_error: 2.1358 - val_loss: 2.1203 - val_mean_absolute_error: 1.0332 - val_mean_squared_error: 2.1203\n",
            "Epoch 336/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.1497 - mean_absolute_error: 1.0157 - mean_squared_error: 2.1497\n",
            "Epoch 336: val_loss improved from 2.09185 to 2.08497, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1365 - mean_absolute_error: 1.0151 - mean_squared_error: 2.1365 - val_loss: 2.0850 - val_mean_absolute_error: 1.0148 - val_mean_squared_error: 2.0850\n",
            "Epoch 337/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.1343 - mean_absolute_error: 1.0164 - mean_squared_error: 2.1343\n",
            "Epoch 337: val_loss did not improve from 2.08497\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1303 - mean_absolute_error: 1.0158 - mean_squared_error: 2.1303 - val_loss: 2.0868 - val_mean_absolute_error: 1.0152 - val_mean_squared_error: 2.0868\n",
            "Epoch 338/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.1249 - mean_absolute_error: 1.0156 - mean_squared_error: 2.1249\n",
            "Epoch 338: val_loss improved from 2.08497 to 2.08027, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1287 - mean_absolute_error: 1.0165 - mean_squared_error: 2.1287 - val_loss: 2.0803 - val_mean_absolute_error: 1.0104 - val_mean_squared_error: 2.0803\n",
            "Epoch 339/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.1163 - mean_absolute_error: 1.0084 - mean_squared_error: 2.1163\n",
            "Epoch 339: val_loss did not improve from 2.08027\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1219 - mean_absolute_error: 1.0106 - mean_squared_error: 2.1219 - val_loss: 2.1002 - val_mean_absolute_error: 1.0271 - val_mean_squared_error: 2.1002\n",
            "Epoch 340/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.1168 - mean_absolute_error: 1.0116 - mean_squared_error: 2.1168\n",
            "Epoch 340: val_loss did not improve from 2.08027\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1124 - mean_absolute_error: 1.0141 - mean_squared_error: 2.1124 - val_loss: 2.0978 - val_mean_absolute_error: 1.0266 - val_mean_squared_error: 2.0978\n",
            "Epoch 341/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.1201 - mean_absolute_error: 1.0134 - mean_squared_error: 2.1201\n",
            "Epoch 341: val_loss did not improve from 2.08027\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1167 - mean_absolute_error: 1.0125 - mean_squared_error: 2.1167 - val_loss: 2.1029 - val_mean_absolute_error: 1.0306 - val_mean_squared_error: 2.1029\n",
            "Epoch 342/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.0890 - mean_absolute_error: 1.0070 - mean_squared_error: 2.0890\n",
            "Epoch 342: val_loss improved from 2.08027 to 2.05904, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1181 - mean_absolute_error: 1.0129 - mean_squared_error: 2.1181 - val_loss: 2.0590 - val_mean_absolute_error: 1.0003 - val_mean_squared_error: 2.0590\n",
            "Epoch 343/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.0963 - mean_absolute_error: 1.0073 - mean_squared_error: 2.0963\n",
            "Epoch 343: val_loss improved from 2.05904 to 2.05744, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1076 - mean_absolute_error: 1.0116 - mean_squared_error: 2.1076 - val_loss: 2.0574 - val_mean_absolute_error: 1.0017 - val_mean_squared_error: 2.0574\n",
            "Epoch 344/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.1051 - mean_absolute_error: 1.0091 - mean_squared_error: 2.1051\n",
            "Epoch 344: val_loss improved from 2.05744 to 2.05296, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1048 - mean_absolute_error: 1.0088 - mean_squared_error: 2.1048 - val_loss: 2.0530 - val_mean_absolute_error: 0.9998 - val_mean_squared_error: 2.0530\n",
            "Epoch 345/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.1011 - mean_absolute_error: 1.0104 - mean_squared_error: 2.1011\n",
            "Epoch 345: val_loss improved from 2.05296 to 2.05151, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0992 - mean_absolute_error: 1.0089 - mean_squared_error: 2.0992 - val_loss: 2.0515 - val_mean_absolute_error: 0.9994 - val_mean_squared_error: 2.0515\n",
            "Epoch 346/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.1102 - mean_absolute_error: 1.0112 - mean_squared_error: 2.1102\n",
            "Epoch 346: val_loss improved from 2.05151 to 2.04779, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0989 - mean_absolute_error: 1.0075 - mean_squared_error: 2.0989 - val_loss: 2.0478 - val_mean_absolute_error: 1.0018 - val_mean_squared_error: 2.0478\n",
            "Epoch 347/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.1048 - mean_absolute_error: 1.0110 - mean_squared_error: 2.1048\n",
            "Epoch 347: val_loss improved from 2.04779 to 2.04646, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0977 - mean_absolute_error: 1.0099 - mean_squared_error: 2.0977 - val_loss: 2.0465 - val_mean_absolute_error: 1.0020 - val_mean_squared_error: 2.0465\n",
            "Epoch 348/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.0674 - mean_absolute_error: 1.0004 - mean_squared_error: 2.0674\n",
            "Epoch 348: val_loss improved from 2.04646 to 2.04121, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0919 - mean_absolute_error: 1.0048 - mean_squared_error: 2.0919 - val_loss: 2.0412 - val_mean_absolute_error: 0.9989 - val_mean_squared_error: 2.0412\n",
            "Epoch 349/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.0855 - mean_absolute_error: 1.0038 - mean_squared_error: 2.0855\n",
            "Epoch 349: val_loss did not improve from 2.04121\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0893 - mean_absolute_error: 1.0045 - mean_squared_error: 2.0893 - val_loss: 2.0430 - val_mean_absolute_error: 1.0045 - val_mean_squared_error: 2.0430\n",
            "Epoch 350/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.0810 - mean_absolute_error: 1.0048 - mean_squared_error: 2.0810\n",
            "Epoch 350: val_loss improved from 2.04121 to 2.03792, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0870 - mean_absolute_error: 1.0050 - mean_squared_error: 2.0870 - val_loss: 2.0379 - val_mean_absolute_error: 0.9989 - val_mean_squared_error: 2.0379\n",
            "Epoch 351/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.0808 - mean_absolute_error: 1.0029 - mean_squared_error: 2.0808\n",
            "Epoch 351: val_loss did not improve from 2.03792\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0810 - mean_absolute_error: 1.0021 - mean_squared_error: 2.0810 - val_loss: 2.0414 - val_mean_absolute_error: 1.0046 - val_mean_squared_error: 2.0414\n",
            "Epoch 352/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.0721 - mean_absolute_error: 1.0032 - mean_squared_error: 2.0721\n",
            "Epoch 352: val_loss improved from 2.03792 to 2.02892, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0762 - mean_absolute_error: 1.0043 - mean_squared_error: 2.0762 - val_loss: 2.0289 - val_mean_absolute_error: 0.9896 - val_mean_squared_error: 2.0289\n",
            "Epoch 353/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.0705 - mean_absolute_error: 1.0002 - mean_squared_error: 2.0705\n",
            "Epoch 353: val_loss improved from 2.02892 to 2.02587, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0737 - mean_absolute_error: 1.0015 - mean_squared_error: 2.0737 - val_loss: 2.0259 - val_mean_absolute_error: 0.9896 - val_mean_squared_error: 2.0259\n",
            "Epoch 354/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.0756 - mean_absolute_error: 1.0017 - mean_squared_error: 2.0756\n",
            "Epoch 354: val_loss did not improve from 2.02587\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0726 - mean_absolute_error: 1.0015 - mean_squared_error: 2.0726 - val_loss: 2.0377 - val_mean_absolute_error: 1.0057 - val_mean_squared_error: 2.0377\n",
            "Epoch 355/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.0490 - mean_absolute_error: 0.9975 - mean_squared_error: 2.0490\n",
            "Epoch 355: val_loss improved from 2.02587 to 2.02141, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0691 - mean_absolute_error: 0.9993 - mean_squared_error: 2.0691 - val_loss: 2.0214 - val_mean_absolute_error: 0.9923 - val_mean_squared_error: 2.0214\n",
            "Epoch 356/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.0588 - mean_absolute_error: 0.9986 - mean_squared_error: 2.0588\n",
            "Epoch 356: val_loss improved from 2.02141 to 2.02017, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0672 - mean_absolute_error: 1.0013 - mean_squared_error: 2.0672 - val_loss: 2.0202 - val_mean_absolute_error: 0.9880 - val_mean_squared_error: 2.0202\n",
            "Epoch 357/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.0512 - mean_absolute_error: 0.9983 - mean_squared_error: 2.0512\n",
            "Epoch 357: val_loss improved from 2.02017 to 2.01576, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0627 - mean_absolute_error: 1.0000 - mean_squared_error: 2.0627 - val_loss: 2.0158 - val_mean_absolute_error: 0.9927 - val_mean_squared_error: 2.0158\n",
            "Epoch 358/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.0337 - mean_absolute_error: 0.9893 - mean_squared_error: 2.0337\n",
            "Epoch 358: val_loss did not improve from 2.01576\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0577 - mean_absolute_error: 0.9971 - mean_squared_error: 2.0577 - val_loss: 2.0206 - val_mean_absolute_error: 0.9979 - val_mean_squared_error: 2.0206\n",
            "Epoch 359/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.0480 - mean_absolute_error: 0.9973 - mean_squared_error: 2.0480\n",
            "Epoch 359: val_loss improved from 2.01576 to 2.00839, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0550 - mean_absolute_error: 0.9971 - mean_squared_error: 2.0550 - val_loss: 2.0084 - val_mean_absolute_error: 0.9876 - val_mean_squared_error: 2.0084\n",
            "Epoch 360/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.0536 - mean_absolute_error: 0.9994 - mean_squared_error: 2.0536\n",
            "Epoch 360: val_loss did not improve from 2.00839\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0559 - mean_absolute_error: 0.9998 - mean_squared_error: 2.0559 - val_loss: 2.0120 - val_mean_absolute_error: 0.9861 - val_mean_squared_error: 2.0120\n",
            "Epoch 361/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.0698 - mean_absolute_error: 1.0018 - mean_squared_error: 2.0698\n",
            "Epoch 361: val_loss improved from 2.00839 to 2.00343, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0514 - mean_absolute_error: 0.9967 - mean_squared_error: 2.0514 - val_loss: 2.0034 - val_mean_absolute_error: 0.9897 - val_mean_squared_error: 2.0034\n",
            "Epoch 362/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.0629 - mean_absolute_error: 0.9975 - mean_squared_error: 2.0629\n",
            "Epoch 362: val_loss improved from 2.00343 to 2.00208, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0459 - mean_absolute_error: 0.9945 - mean_squared_error: 2.0459 - val_loss: 2.0021 - val_mean_absolute_error: 0.9916 - val_mean_squared_error: 2.0021\n",
            "Epoch 363/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.0578 - mean_absolute_error: 1.0012 - mean_squared_error: 2.0578\n",
            "Epoch 363: val_loss did not improve from 2.00208\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0483 - mean_absolute_error: 0.9967 - mean_squared_error: 2.0483 - val_loss: 2.0134 - val_mean_absolute_error: 0.9993 - val_mean_squared_error: 2.0134\n",
            "Epoch 364/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.0275 - mean_absolute_error: 0.9913 - mean_squared_error: 2.0275\n",
            "Epoch 364: val_loss improved from 2.00208 to 1.99642, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0399 - mean_absolute_error: 0.9942 - mean_squared_error: 2.0399 - val_loss: 1.9964 - val_mean_absolute_error: 0.9885 - val_mean_squared_error: 1.9964\n",
            "Epoch 365/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.0406 - mean_absolute_error: 0.9938 - mean_squared_error: 2.0406\n",
            "Epoch 365: val_loss improved from 1.99642 to 1.99253, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0347 - mean_absolute_error: 0.9924 - mean_squared_error: 2.0347 - val_loss: 1.9925 - val_mean_absolute_error: 0.9858 - val_mean_squared_error: 1.9925\n",
            "Epoch 366/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.0364 - mean_absolute_error: 0.9937 - mean_squared_error: 2.0364\n",
            "Epoch 366: val_loss did not improve from 1.99253\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0343 - mean_absolute_error: 0.9924 - mean_squared_error: 2.0343 - val_loss: 2.0041 - val_mean_absolute_error: 0.9970 - val_mean_squared_error: 2.0041\n",
            "Epoch 367/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.0247 - mean_absolute_error: 0.9919 - mean_squared_error: 2.0247\n",
            "Epoch 367: val_loss improved from 1.99253 to 1.98627, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.0289 - mean_absolute_error: 0.9927 - mean_squared_error: 2.0289 - val_loss: 1.9863 - val_mean_absolute_error: 0.9813 - val_mean_squared_error: 1.9863\n",
            "Epoch 368/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.0179 - mean_absolute_error: 0.9901 - mean_squared_error: 2.0179\n",
            "Epoch 368: val_loss improved from 1.98627 to 1.98570, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.0287 - mean_absolute_error: 0.9916 - mean_squared_error: 2.0287 - val_loss: 1.9857 - val_mean_absolute_error: 0.9849 - val_mean_squared_error: 1.9857\n",
            "Epoch 369/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.0125 - mean_absolute_error: 0.9878 - mean_squared_error: 2.0125\n",
            "Epoch 369: val_loss did not improve from 1.98570\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0245 - mean_absolute_error: 0.9916 - mean_squared_error: 2.0245 - val_loss: 2.0031 - val_mean_absolute_error: 1.0014 - val_mean_squared_error: 2.0031\n",
            "Epoch 370/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.0335 - mean_absolute_error: 0.9929 - mean_squared_error: 2.0335\n",
            "Epoch 370: val_loss improved from 1.98570 to 1.97868, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0241 - mean_absolute_error: 0.9894 - mean_squared_error: 2.0241 - val_loss: 1.9787 - val_mean_absolute_error: 0.9798 - val_mean_squared_error: 1.9787\n",
            "Epoch 371/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.0051 - mean_absolute_error: 0.9895 - mean_squared_error: 2.0051\n",
            "Epoch 371: val_loss did not improve from 1.97868\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0163 - mean_absolute_error: 0.9909 - mean_squared_error: 2.0163 - val_loss: 1.9876 - val_mean_absolute_error: 0.9757 - val_mean_squared_error: 1.9876\n",
            "Epoch 372/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.0377 - mean_absolute_error: 0.9939 - mean_squared_error: 2.0377\n",
            "Epoch 372: val_loss improved from 1.97868 to 1.97539, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0167 - mean_absolute_error: 0.9891 - mean_squared_error: 2.0167 - val_loss: 1.9754 - val_mean_absolute_error: 0.9832 - val_mean_squared_error: 1.9754\n",
            "Epoch 373/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.0126 - mean_absolute_error: 0.9896 - mean_squared_error: 2.0126\n",
            "Epoch 373: val_loss improved from 1.97539 to 1.97229, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0151 - mean_absolute_error: 0.9900 - mean_squared_error: 2.0151 - val_loss: 1.9723 - val_mean_absolute_error: 0.9794 - val_mean_squared_error: 1.9723\n",
            "Epoch 374/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.0174 - mean_absolute_error: 0.9920 - mean_squared_error: 2.0174\n",
            "Epoch 374: val_loss did not improve from 1.97229\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0129 - mean_absolute_error: 0.9895 - mean_squared_error: 2.0129 - val_loss: 1.9727 - val_mean_absolute_error: 0.9838 - val_mean_squared_error: 1.9727\n",
            "Epoch 375/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.0152 - mean_absolute_error: 0.9914 - mean_squared_error: 2.0152\n",
            "Epoch 375: val_loss improved from 1.97229 to 1.96840, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0099 - mean_absolute_error: 0.9901 - mean_squared_error: 2.0099 - val_loss: 1.9684 - val_mean_absolute_error: 0.9818 - val_mean_squared_error: 1.9684\n",
            "Epoch 376/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.0276 - mean_absolute_error: 0.9926 - mean_squared_error: 2.0276\n",
            "Epoch 376: val_loss improved from 1.96840 to 1.96373, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0039 - mean_absolute_error: 0.9880 - mean_squared_error: 2.0039 - val_loss: 1.9637 - val_mean_absolute_error: 0.9755 - val_mean_squared_error: 1.9637\n",
            "Epoch 377/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.9841 - mean_absolute_error: 0.9822 - mean_squared_error: 1.9841\n",
            "Epoch 377: val_loss improved from 1.96373 to 1.96272, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0052 - mean_absolute_error: 0.9849 - mean_squared_error: 2.0052 - val_loss: 1.9627 - val_mean_absolute_error: 0.9797 - val_mean_squared_error: 1.9627\n",
            "Epoch 378/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.9952 - mean_absolute_error: 0.9856 - mean_squared_error: 1.9952\n",
            "Epoch 378: val_loss improved from 1.96272 to 1.96040, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9984 - mean_absolute_error: 0.9864 - mean_squared_error: 1.9984 - val_loss: 1.9604 - val_mean_absolute_error: 0.9781 - val_mean_squared_error: 1.9604\n",
            "Epoch 379/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.9781 - mean_absolute_error: 0.9809 - mean_squared_error: 1.9781\n",
            "Epoch 379: val_loss did not improve from 1.96040\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9945 - mean_absolute_error: 0.9849 - mean_squared_error: 1.9945 - val_loss: 1.9633 - val_mean_absolute_error: 0.9851 - val_mean_squared_error: 1.9633\n",
            "Epoch 380/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.9920 - mean_absolute_error: 0.9867 - mean_squared_error: 1.9920\n",
            "Epoch 380: val_loss improved from 1.96040 to 1.95488, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.9920 - mean_absolute_error: 0.9867 - mean_squared_error: 1.9920 - val_loss: 1.9549 - val_mean_absolute_error: 0.9764 - val_mean_squared_error: 1.9549\n",
            "Epoch 381/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.0104 - mean_absolute_error: 0.9866 - mean_squared_error: 2.0104\n",
            "Epoch 381: val_loss did not improve from 1.95488\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9881 - mean_absolute_error: 0.9817 - mean_squared_error: 1.9881 - val_loss: 2.0211 - val_mean_absolute_error: 1.0238 - val_mean_squared_error: 2.0211\n",
            "Epoch 382/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.9889 - mean_absolute_error: 0.9872 - mean_squared_error: 1.9889\n",
            "Epoch 382: val_loss improved from 1.95488 to 1.95139, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9921 - mean_absolute_error: 0.9859 - mean_squared_error: 1.9921 - val_loss: 1.9514 - val_mean_absolute_error: 0.9754 - val_mean_squared_error: 1.9514\n",
            "Epoch 383/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.9886 - mean_absolute_error: 0.9826 - mean_squared_error: 1.9886\n",
            "Epoch 383: val_loss did not improve from 1.95139\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9876 - mean_absolute_error: 0.9831 - mean_squared_error: 1.9876 - val_loss: 1.9520 - val_mean_absolute_error: 0.9747 - val_mean_squared_error: 1.9520\n",
            "Epoch 384/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.9945 - mean_absolute_error: 0.9817 - mean_squared_error: 1.9945\n",
            "Epoch 384: val_loss improved from 1.95139 to 1.94741, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9839 - mean_absolute_error: 0.9811 - mean_squared_error: 1.9839 - val_loss: 1.9474 - val_mean_absolute_error: 0.9777 - val_mean_squared_error: 1.9474\n",
            "Epoch 385/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.9836 - mean_absolute_error: 0.9841 - mean_squared_error: 1.9836\n",
            "Epoch 385: val_loss did not improve from 1.94741\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9796 - mean_absolute_error: 0.9839 - mean_squared_error: 1.9796 - val_loss: 1.9724 - val_mean_absolute_error: 0.9778 - val_mean_squared_error: 1.9724\n",
            "Epoch 386/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.9791 - mean_absolute_error: 0.9835 - mean_squared_error: 1.9791\n",
            "Epoch 386: val_loss improved from 1.94741 to 1.94064, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9785 - mean_absolute_error: 0.9818 - mean_squared_error: 1.9785 - val_loss: 1.9406 - val_mean_absolute_error: 0.9717 - val_mean_squared_error: 1.9406\n",
            "Epoch 387/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.9822 - mean_absolute_error: 0.9815 - mean_squared_error: 1.9822\n",
            "Epoch 387: val_loss did not improve from 1.94064\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9768 - mean_absolute_error: 0.9801 - mean_squared_error: 1.9768 - val_loss: 1.9518 - val_mean_absolute_error: 0.9863 - val_mean_squared_error: 1.9518\n",
            "Epoch 388/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.9609 - mean_absolute_error: 0.9793 - mean_squared_error: 1.9609\n",
            "Epoch 388: val_loss did not improve from 1.94064\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9695 - mean_absolute_error: 0.9810 - mean_squared_error: 1.9695 - val_loss: 1.9429 - val_mean_absolute_error: 0.9659 - val_mean_squared_error: 1.9429\n",
            "Epoch 389/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.9642 - mean_absolute_error: 0.9776 - mean_squared_error: 1.9642\n",
            "Epoch 389: val_loss improved from 1.94064 to 1.93592, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9721 - mean_absolute_error: 0.9789 - mean_squared_error: 1.9721 - val_loss: 1.9359 - val_mean_absolute_error: 0.9749 - val_mean_squared_error: 1.9359\n",
            "Epoch 390/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.9681 - mean_absolute_error: 0.9810 - mean_squared_error: 1.9681\n",
            "Epoch 390: val_loss did not improve from 1.93592\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9661 - mean_absolute_error: 0.9803 - mean_squared_error: 1.9661 - val_loss: 1.9540 - val_mean_absolute_error: 0.9693 - val_mean_squared_error: 1.9540\n",
            "Epoch 391/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.9553 - mean_absolute_error: 0.9778 - mean_squared_error: 1.9553\n",
            "Epoch 391: val_loss did not improve from 1.93592\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.9612 - mean_absolute_error: 0.9797 - mean_squared_error: 1.9612 - val_loss: 1.9424 - val_mean_absolute_error: 0.9829 - val_mean_squared_error: 1.9424\n",
            "Epoch 392/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.9753 - mean_absolute_error: 0.9813 - mean_squared_error: 1.9753\n",
            "Epoch 392: val_loss improved from 1.93592 to 1.93214, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9611 - mean_absolute_error: 0.9775 - mean_squared_error: 1.9611 - val_loss: 1.9321 - val_mean_absolute_error: 0.9643 - val_mean_squared_error: 1.9321\n",
            "Epoch 393/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.9473 - mean_absolute_error: 0.9756 - mean_squared_error: 1.9473\n",
            "Epoch 393: val_loss did not improve from 1.93214\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9609 - mean_absolute_error: 0.9784 - mean_squared_error: 1.9609 - val_loss: 1.9592 - val_mean_absolute_error: 0.9728 - val_mean_squared_error: 1.9592\n",
            "Epoch 394/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.9800 - mean_absolute_error: 0.9805 - mean_squared_error: 1.9800\n",
            "Epoch 394: val_loss improved from 1.93214 to 1.92268, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9580 - mean_absolute_error: 0.9780 - mean_squared_error: 1.9580 - val_loss: 1.9227 - val_mean_absolute_error: 0.9671 - val_mean_squared_error: 1.9227\n",
            "Epoch 395/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.9612 - mean_absolute_error: 0.9774 - mean_squared_error: 1.9612\n",
            "Epoch 395: val_loss did not improve from 1.92268\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9514 - mean_absolute_error: 0.9753 - mean_squared_error: 1.9514 - val_loss: 1.9313 - val_mean_absolute_error: 0.9801 - val_mean_squared_error: 1.9313\n",
            "Epoch 396/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.9369 - mean_absolute_error: 0.9717 - mean_squared_error: 1.9369\n",
            "Epoch 396: val_loss did not improve from 1.92268\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9512 - mean_absolute_error: 0.9757 - mean_squared_error: 1.9512 - val_loss: 1.9269 - val_mean_absolute_error: 0.9771 - val_mean_squared_error: 1.9269\n",
            "Epoch 397/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.9677 - mean_absolute_error: 0.9794 - mean_squared_error: 1.9677\n",
            "Epoch 397: val_loss did not improve from 1.92268\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9572 - mean_absolute_error: 0.9767 - mean_squared_error: 1.9572 - val_loss: 1.9228 - val_mean_absolute_error: 0.9742 - val_mean_squared_error: 1.9228\n",
            "Epoch 398/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.9391 - mean_absolute_error: 0.9708 - mean_squared_error: 1.9391\n",
            "Epoch 398: val_loss did not improve from 1.92268\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9490 - mean_absolute_error: 0.9735 - mean_squared_error: 1.9490 - val_loss: 1.9245 - val_mean_absolute_error: 0.9785 - val_mean_squared_error: 1.9245\n",
            "Epoch 399/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.9485 - mean_absolute_error: 0.9775 - mean_squared_error: 1.9485\n",
            "Epoch 399: val_loss improved from 1.92268 to 1.91331, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9500 - mean_absolute_error: 0.9773 - mean_squared_error: 1.9500 - val_loss: 1.9133 - val_mean_absolute_error: 0.9624 - val_mean_squared_error: 1.9133\n",
            "Epoch 400/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.9401 - mean_absolute_error: 0.9713 - mean_squared_error: 1.9401\n",
            "Epoch 400: val_loss did not improve from 1.91331\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9399 - mean_absolute_error: 0.9730 - mean_squared_error: 1.9399 - val_loss: 1.9146 - val_mean_absolute_error: 0.9717 - val_mean_squared_error: 1.9146\n",
            "Epoch 401/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.9369 - mean_absolute_error: 0.9720 - mean_squared_error: 1.9369\n",
            "Epoch 401: val_loss did not improve from 1.91331\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9383 - mean_absolute_error: 0.9719 - mean_squared_error: 1.9383 - val_loss: 1.9267 - val_mean_absolute_error: 0.9835 - val_mean_squared_error: 1.9267\n",
            "Epoch 402/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.9414 - mean_absolute_error: 0.9753 - mean_squared_error: 1.9414\n",
            "Epoch 402: val_loss improved from 1.91331 to 1.91174, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9392 - mean_absolute_error: 0.9744 - mean_squared_error: 1.9392 - val_loss: 1.9117 - val_mean_absolute_error: 0.9631 - val_mean_squared_error: 1.9117\n",
            "Epoch 403/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.9305 - mean_absolute_error: 0.9703 - mean_squared_error: 1.9305\n",
            "Epoch 403: val_loss improved from 1.91174 to 1.90477, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.9371 - mean_absolute_error: 0.9729 - mean_squared_error: 1.9371 - val_loss: 1.9048 - val_mean_absolute_error: 0.9646 - val_mean_squared_error: 1.9048\n",
            "Epoch 404/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.9363 - mean_absolute_error: 0.9741 - mean_squared_error: 1.9363\n",
            "Epoch 404: val_loss did not improve from 1.90477\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9417 - mean_absolute_error: 0.9747 - mean_squared_error: 1.9417 - val_loss: 1.9156 - val_mean_absolute_error: 0.9788 - val_mean_squared_error: 1.9156\n",
            "Epoch 405/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.9329 - mean_absolute_error: 0.9719 - mean_squared_error: 1.9329\n",
            "Epoch 405: val_loss did not improve from 1.90477\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9329 - mean_absolute_error: 0.9719 - mean_squared_error: 1.9329 - val_loss: 1.9048 - val_mean_absolute_error: 0.9701 - val_mean_squared_error: 1.9048\n",
            "Epoch 406/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.9353 - mean_absolute_error: 0.9784 - mean_squared_error: 1.9353\n",
            "Epoch 406: val_loss improved from 1.90477 to 1.90000, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9304 - mean_absolute_error: 0.9734 - mean_squared_error: 1.9304 - val_loss: 1.9000 - val_mean_absolute_error: 0.9637 - val_mean_squared_error: 1.9000\n",
            "Epoch 407/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.9291 - mean_absolute_error: 0.9699 - mean_squared_error: 1.9291\n",
            "Epoch 407: val_loss did not improve from 1.90000\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9285 - mean_absolute_error: 0.9700 - mean_squared_error: 1.9285 - val_loss: 1.9005 - val_mean_absolute_error: 0.9690 - val_mean_squared_error: 1.9005\n",
            "Epoch 408/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.9004 - mean_absolute_error: 0.9647 - mean_squared_error: 1.9004\n",
            "Epoch 408: val_loss did not improve from 1.90000\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9270 - mean_absolute_error: 0.9705 - mean_squared_error: 1.9270 - val_loss: 1.9006 - val_mean_absolute_error: 0.9657 - val_mean_squared_error: 1.9006\n",
            "Epoch 409/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.9339 - mean_absolute_error: 0.9761 - mean_squared_error: 1.9339\n",
            "Epoch 409: val_loss improved from 1.90000 to 1.89524, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9266 - mean_absolute_error: 0.9740 - mean_squared_error: 1.9266 - val_loss: 1.8952 - val_mean_absolute_error: 0.9599 - val_mean_squared_error: 1.8952\n",
            "Epoch 410/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.9124 - mean_absolute_error: 0.9663 - mean_squared_error: 1.9124\n",
            "Epoch 410: val_loss did not improve from 1.89524\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9163 - mean_absolute_error: 0.9672 - mean_squared_error: 1.9163 - val_loss: 1.9190 - val_mean_absolute_error: 0.9875 - val_mean_squared_error: 1.9190\n",
            "Epoch 411/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.9204 - mean_absolute_error: 0.9686 - mean_squared_error: 1.9204\n",
            "Epoch 411: val_loss did not improve from 1.89524\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9172 - mean_absolute_error: 0.9689 - mean_squared_error: 1.9172 - val_loss: 1.9241 - val_mean_absolute_error: 0.9913 - val_mean_squared_error: 1.9241\n",
            "Epoch 412/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.9175 - mean_absolute_error: 0.9676 - mean_squared_error: 1.9175\n",
            "Epoch 412: val_loss did not improve from 1.89524\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9175 - mean_absolute_error: 0.9676 - mean_squared_error: 1.9175 - val_loss: 1.8973 - val_mean_absolute_error: 0.9733 - val_mean_squared_error: 1.8973\n",
            "Epoch 413/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.9127 - mean_absolute_error: 0.9709 - mean_squared_error: 1.9127\n",
            "Epoch 413: val_loss improved from 1.89524 to 1.89416, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9151 - mean_absolute_error: 0.9704 - mean_squared_error: 1.9151 - val_loss: 1.8942 - val_mean_absolute_error: 0.9704 - val_mean_squared_error: 1.8942\n",
            "Epoch 414/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.9066 - mean_absolute_error: 0.9665 - mean_squared_error: 1.9066\n",
            "Epoch 414: val_loss improved from 1.89416 to 1.88452, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9148 - mean_absolute_error: 0.9688 - mean_squared_error: 1.9148 - val_loss: 1.8845 - val_mean_absolute_error: 0.9625 - val_mean_squared_error: 1.8845\n",
            "Epoch 415/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.9038 - mean_absolute_error: 0.9651 - mean_squared_error: 1.9038\n",
            "Epoch 415: val_loss did not improve from 1.88452\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9071 - mean_absolute_error: 0.9659 - mean_squared_error: 1.9071 - val_loss: 1.8936 - val_mean_absolute_error: 0.9606 - val_mean_squared_error: 1.8936\n",
            "Epoch 416/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.9086 - mean_absolute_error: 0.9676 - mean_squared_error: 1.9086\n",
            "Epoch 416: val_loss did not improve from 1.88452\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9085 - mean_absolute_error: 0.9673 - mean_squared_error: 1.9085 - val_loss: 1.8989 - val_mean_absolute_error: 0.9626 - val_mean_squared_error: 1.8989\n",
            "Epoch 417/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.9003 - mean_absolute_error: 0.9665 - mean_squared_error: 1.9003\n",
            "Epoch 417: val_loss improved from 1.88452 to 1.88345, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9049 - mean_absolute_error: 0.9668 - mean_squared_error: 1.9049 - val_loss: 1.8835 - val_mean_absolute_error: 0.9669 - val_mean_squared_error: 1.8835\n",
            "Epoch 418/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.9283 - mean_absolute_error: 0.9703 - mean_squared_error: 1.9283\n",
            "Epoch 418: val_loss improved from 1.88345 to 1.87597, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9040 - mean_absolute_error: 0.9653 - mean_squared_error: 1.9040 - val_loss: 1.8760 - val_mean_absolute_error: 0.9584 - val_mean_squared_error: 1.8760\n",
            "Epoch 419/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.9067 - mean_absolute_error: 0.9718 - mean_squared_error: 1.9067\n",
            "Epoch 419: val_loss did not improve from 1.87597\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9014 - mean_absolute_error: 0.9670 - mean_squared_error: 1.9014 - val_loss: 1.8830 - val_mean_absolute_error: 0.9682 - val_mean_squared_error: 1.8830\n",
            "Epoch 420/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.9196 - mean_absolute_error: 0.9719 - mean_squared_error: 1.9196\n",
            "Epoch 420: val_loss improved from 1.87597 to 1.87432, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.8985 - mean_absolute_error: 0.9654 - mean_squared_error: 1.8985 - val_loss: 1.8743 - val_mean_absolute_error: 0.9603 - val_mean_squared_error: 1.8743\n",
            "Epoch 421/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.9055 - mean_absolute_error: 0.9672 - mean_squared_error: 1.9055\n",
            "Epoch 421: val_loss improved from 1.87432 to 1.87225, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8945 - mean_absolute_error: 0.9655 - mean_squared_error: 1.8945 - val_loss: 1.8723 - val_mean_absolute_error: 0.9596 - val_mean_squared_error: 1.8723\n",
            "Epoch 422/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.9055 - mean_absolute_error: 0.9691 - mean_squared_error: 1.9055\n",
            "Epoch 422: val_loss improved from 1.87225 to 1.87159, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8945 - mean_absolute_error: 0.9644 - mean_squared_error: 1.8945 - val_loss: 1.8716 - val_mean_absolute_error: 0.9612 - val_mean_squared_error: 1.8716\n",
            "Epoch 423/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.8784 - mean_absolute_error: 0.9592 - mean_squared_error: 1.8784\n",
            "Epoch 423: val_loss did not improve from 1.87159\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8890 - mean_absolute_error: 0.9627 - mean_squared_error: 1.8890 - val_loss: 1.9135 - val_mean_absolute_error: 0.9927 - val_mean_squared_error: 1.9135\n",
            "Epoch 424/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.8924 - mean_absolute_error: 0.9662 - mean_squared_error: 1.8924\n",
            "Epoch 424: val_loss did not improve from 1.87159\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8934 - mean_absolute_error: 0.9654 - mean_squared_error: 1.8934 - val_loss: 1.9061 - val_mean_absolute_error: 0.9619 - val_mean_squared_error: 1.9061\n",
            "Epoch 425/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.8906 - mean_absolute_error: 0.9621 - mean_squared_error: 1.8906\n",
            "Epoch 425: val_loss improved from 1.87159 to 1.86683, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8908 - mean_absolute_error: 0.9620 - mean_squared_error: 1.8908 - val_loss: 1.8668 - val_mean_absolute_error: 0.9560 - val_mean_squared_error: 1.8668\n",
            "Epoch 426/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.8774 - mean_absolute_error: 0.9633 - mean_squared_error: 1.8774\n",
            "Epoch 426: val_loss did not improve from 1.86683\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8836 - mean_absolute_error: 0.9618 - mean_squared_error: 1.8836 - val_loss: 1.8677 - val_mean_absolute_error: 0.9634 - val_mean_squared_error: 1.8677\n",
            "Epoch 427/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.8867 - mean_absolute_error: 0.9621 - mean_squared_error: 1.8867\n",
            "Epoch 427: val_loss did not improve from 1.86683\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8817 - mean_absolute_error: 0.9606 - mean_squared_error: 1.8817 - val_loss: 1.8722 - val_mean_absolute_error: 0.9687 - val_mean_squared_error: 1.8722\n",
            "Epoch 428/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.8910 - mean_absolute_error: 0.9635 - mean_squared_error: 1.8910\n",
            "Epoch 428: val_loss improved from 1.86683 to 1.86180, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8821 - mean_absolute_error: 0.9622 - mean_squared_error: 1.8821 - val_loss: 1.8618 - val_mean_absolute_error: 0.9552 - val_mean_squared_error: 1.8618\n",
            "Epoch 429/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.8748 - mean_absolute_error: 0.9604 - mean_squared_error: 1.8748\n",
            "Epoch 429: val_loss improved from 1.86180 to 1.85803, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8877 - mean_absolute_error: 0.9617 - mean_squared_error: 1.8877 - val_loss: 1.8580 - val_mean_absolute_error: 0.9553 - val_mean_squared_error: 1.8580\n",
            "Epoch 430/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.8718 - mean_absolute_error: 0.9597 - mean_squared_error: 1.8718\n",
            "Epoch 430: val_loss did not improve from 1.85803\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8769 - mean_absolute_error: 0.9599 - mean_squared_error: 1.8769 - val_loss: 1.8621 - val_mean_absolute_error: 0.9637 - val_mean_squared_error: 1.8621\n",
            "Epoch 431/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.8731 - mean_absolute_error: 0.9622 - mean_squared_error: 1.8731\n",
            "Epoch 431: val_loss did not improve from 1.85803\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8794 - mean_absolute_error: 0.9641 - mean_squared_error: 1.8794 - val_loss: 1.8604 - val_mean_absolute_error: 0.9484 - val_mean_squared_error: 1.8604\n",
            "Epoch 432/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.8747 - mean_absolute_error: 0.9605 - mean_squared_error: 1.8747\n",
            "Epoch 432: val_loss did not improve from 1.85803\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8753 - mean_absolute_error: 0.9604 - mean_squared_error: 1.8753 - val_loss: 1.8587 - val_mean_absolute_error: 0.9620 - val_mean_squared_error: 1.8587\n",
            "Epoch 433/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.8854 - mean_absolute_error: 0.9618 - mean_squared_error: 1.8854\n",
            "Epoch 433: val_loss improved from 1.85803 to 1.85086, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8721 - mean_absolute_error: 0.9589 - mean_squared_error: 1.8721 - val_loss: 1.8509 - val_mean_absolute_error: 0.9523 - val_mean_squared_error: 1.8509\n",
            "Epoch 434/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.8649 - mean_absolute_error: 0.9554 - mean_squared_error: 1.8649\n",
            "Epoch 434: val_loss improved from 1.85086 to 1.85028, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8687 - mean_absolute_error: 0.9570 - mean_squared_error: 1.8687 - val_loss: 1.8503 - val_mean_absolute_error: 0.9519 - val_mean_squared_error: 1.8503\n",
            "Epoch 435/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.8750 - mean_absolute_error: 0.9619 - mean_squared_error: 1.8750\n",
            "Epoch 435: val_loss improved from 1.85028 to 1.84605, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.8656 - mean_absolute_error: 0.9578 - mean_squared_error: 1.8656 - val_loss: 1.8461 - val_mean_absolute_error: 0.9519 - val_mean_squared_error: 1.8461\n",
            "Epoch 436/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.8708 - mean_absolute_error: 0.9588 - mean_squared_error: 1.8708\n",
            "Epoch 436: val_loss did not improve from 1.84605\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.8701 - mean_absolute_error: 0.9588 - mean_squared_error: 1.8701 - val_loss: 1.8468 - val_mean_absolute_error: 0.9558 - val_mean_squared_error: 1.8468\n",
            "Epoch 437/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.8569 - mean_absolute_error: 0.9551 - mean_squared_error: 1.8569\n",
            "Epoch 437: val_loss did not improve from 1.84605\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.8667 - mean_absolute_error: 0.9560 - mean_squared_error: 1.8667 - val_loss: 1.8558 - val_mean_absolute_error: 0.9653 - val_mean_squared_error: 1.8558\n",
            "Epoch 438/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.8483 - mean_absolute_error: 0.9513 - mean_squared_error: 1.8483\n",
            "Epoch 438: val_loss improved from 1.84605 to 1.84033, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.8617 - mean_absolute_error: 0.9579 - mean_squared_error: 1.8617 - val_loss: 1.8403 - val_mean_absolute_error: 0.9502 - val_mean_squared_error: 1.8403\n",
            "Epoch 439/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.8573 - mean_absolute_error: 0.9526 - mean_squared_error: 1.8573\n",
            "Epoch 439: val_loss did not improve from 1.84033\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.8633 - mean_absolute_error: 0.9541 - mean_squared_error: 1.8633 - val_loss: 1.8408 - val_mean_absolute_error: 0.9507 - val_mean_squared_error: 1.8408\n",
            "Epoch 440/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.8712 - mean_absolute_error: 0.9627 - mean_squared_error: 1.8712\n",
            "Epoch 440: val_loss improved from 1.84033 to 1.83662, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8586 - mean_absolute_error: 0.9567 - mean_squared_error: 1.8586 - val_loss: 1.8366 - val_mean_absolute_error: 0.9479 - val_mean_squared_error: 1.8366\n",
            "Epoch 441/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.8715 - mean_absolute_error: 0.9574 - mean_squared_error: 1.8715\n",
            "Epoch 441: val_loss did not improve from 1.83662\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8528 - mean_absolute_error: 0.9554 - mean_squared_error: 1.8528 - val_loss: 1.8647 - val_mean_absolute_error: 0.9751 - val_mean_squared_error: 1.8647\n",
            "Epoch 442/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.8602 - mean_absolute_error: 0.9573 - mean_squared_error: 1.8602\n",
            "Epoch 442: val_loss did not improve from 1.83662\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.8547 - mean_absolute_error: 0.9540 - mean_squared_error: 1.8547 - val_loss: 1.8437 - val_mean_absolute_error: 0.9607 - val_mean_squared_error: 1.8437\n",
            "Epoch 443/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.8505 - mean_absolute_error: 0.9535 - mean_squared_error: 1.8505\n",
            "Epoch 443: val_loss improved from 1.83662 to 1.83339, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8550 - mean_absolute_error: 0.9551 - mean_squared_error: 1.8550 - val_loss: 1.8334 - val_mean_absolute_error: 0.9468 - val_mean_squared_error: 1.8334\n",
            "Epoch 444/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.8602 - mean_absolute_error: 0.9580 - mean_squared_error: 1.8602\n",
            "Epoch 444: val_loss did not improve from 1.83339\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8508 - mean_absolute_error: 0.9552 - mean_squared_error: 1.8508 - val_loss: 1.8410 - val_mean_absolute_error: 0.9453 - val_mean_squared_error: 1.8410\n",
            "Epoch 445/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.8394 - mean_absolute_error: 0.9506 - mean_squared_error: 1.8394\n",
            "Epoch 445: val_loss did not improve from 1.83339\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8501 - mean_absolute_error: 0.9536 - mean_squared_error: 1.8501 - val_loss: 1.8456 - val_mean_absolute_error: 0.9516 - val_mean_squared_error: 1.8456\n",
            "Epoch 446/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.8557 - mean_absolute_error: 0.9559 - mean_squared_error: 1.8557\n",
            "Epoch 446: val_loss did not improve from 1.83339\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8488 - mean_absolute_error: 0.9525 - mean_squared_error: 1.8488 - val_loss: 1.8343 - val_mean_absolute_error: 0.9473 - val_mean_squared_error: 1.8343\n",
            "Epoch 447/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.8464 - mean_absolute_error: 0.9534 - mean_squared_error: 1.8464\n",
            "Epoch 447: val_loss improved from 1.83339 to 1.83153, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8432 - mean_absolute_error: 0.9525 - mean_squared_error: 1.8432 - val_loss: 1.8315 - val_mean_absolute_error: 0.9478 - val_mean_squared_error: 1.8315\n",
            "Epoch 448/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.8479 - mean_absolute_error: 0.9552 - mean_squared_error: 1.8479\n",
            "Epoch 448: val_loss improved from 1.83153 to 1.82453, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8479 - mean_absolute_error: 0.9552 - mean_squared_error: 1.8479 - val_loss: 1.8245 - val_mean_absolute_error: 0.9429 - val_mean_squared_error: 1.8245\n",
            "Epoch 449/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.8323 - mean_absolute_error: 0.9497 - mean_squared_error: 1.8323\n",
            "Epoch 449: val_loss did not improve from 1.82453\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8398 - mean_absolute_error: 0.9513 - mean_squared_error: 1.8398 - val_loss: 1.8289 - val_mean_absolute_error: 0.9447 - val_mean_squared_error: 1.8289\n",
            "Epoch 450/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.8354 - mean_absolute_error: 0.9483 - mean_squared_error: 1.8354\n",
            "Epoch 450: val_loss did not improve from 1.82453\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.8396 - mean_absolute_error: 0.9498 - mean_squared_error: 1.8396 - val_loss: 1.8533 - val_mean_absolute_error: 0.9736 - val_mean_squared_error: 1.8533\n",
            "Epoch 451/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.8314 - mean_absolute_error: 0.9493 - mean_squared_error: 1.8314\n",
            "Epoch 451: val_loss improved from 1.82453 to 1.82119, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8369 - mean_absolute_error: 0.9503 - mean_squared_error: 1.8369 - val_loss: 1.8212 - val_mean_absolute_error: 0.9497 - val_mean_squared_error: 1.8212\n",
            "Epoch 452/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.8250 - mean_absolute_error: 0.9505 - mean_squared_error: 1.8250\n",
            "Epoch 452: val_loss did not improve from 1.82119\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8288 - mean_absolute_error: 0.9504 - mean_squared_error: 1.8288 - val_loss: 1.8336 - val_mean_absolute_error: 0.9470 - val_mean_squared_error: 1.8336\n",
            "Epoch 453/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.8315 - mean_absolute_error: 0.9477 - mean_squared_error: 1.8315\n",
            "Epoch 453: val_loss did not improve from 1.82119\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8328 - mean_absolute_error: 0.9484 - mean_squared_error: 1.8328 - val_loss: 1.8230 - val_mean_absolute_error: 0.9543 - val_mean_squared_error: 1.8230\n",
            "Epoch 454/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.8261 - mean_absolute_error: 0.9437 - mean_squared_error: 1.8261\n",
            "Epoch 454: val_loss did not improve from 1.82119\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8273 - mean_absolute_error: 0.9440 - mean_squared_error: 1.8273 - val_loss: 1.8473 - val_mean_absolute_error: 0.9723 - val_mean_squared_error: 1.8473\n",
            "Epoch 455/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.8142 - mean_absolute_error: 0.9432 - mean_squared_error: 1.8142\n",
            "Epoch 455: val_loss did not improve from 1.82119\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8261 - mean_absolute_error: 0.9474 - mean_squared_error: 1.8261 - val_loss: 1.8378 - val_mean_absolute_error: 0.9659 - val_mean_squared_error: 1.8378\n",
            "Epoch 456/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.8366 - mean_absolute_error: 0.9510 - mean_squared_error: 1.8366\n",
            "Epoch 456: val_loss improved from 1.82119 to 1.81705, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8275 - mean_absolute_error: 0.9487 - mean_squared_error: 1.8275 - val_loss: 1.8170 - val_mean_absolute_error: 0.9521 - val_mean_squared_error: 1.8170\n",
            "Epoch 457/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.8217 - mean_absolute_error: 0.9470 - mean_squared_error: 1.8217\n",
            "Epoch 457: val_loss improved from 1.81705 to 1.81026, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8231 - mean_absolute_error: 0.9459 - mean_squared_error: 1.8231 - val_loss: 1.8103 - val_mean_absolute_error: 0.9462 - val_mean_squared_error: 1.8103\n",
            "Epoch 458/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.8220 - mean_absolute_error: 0.9450 - mean_squared_error: 1.8220\n",
            "Epoch 458: val_loss did not improve from 1.81026\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.8220 - mean_absolute_error: 0.9450 - mean_squared_error: 1.8220 - val_loss: 1.8146 - val_mean_absolute_error: 0.9519 - val_mean_squared_error: 1.8146\n",
            "Epoch 459/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.8402 - mean_absolute_error: 0.9517 - mean_squared_error: 1.8402\n",
            "Epoch 459: val_loss did not improve from 1.81026\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8217 - mean_absolute_error: 0.9476 - mean_squared_error: 1.8217 - val_loss: 1.8236 - val_mean_absolute_error: 0.9390 - val_mean_squared_error: 1.8236\n",
            "Epoch 460/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.8157 - mean_absolute_error: 0.9418 - mean_squared_error: 1.8157\n",
            "Epoch 460: val_loss did not improve from 1.81026\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8199 - mean_absolute_error: 0.9435 - mean_squared_error: 1.8199 - val_loss: 1.8177 - val_mean_absolute_error: 0.9566 - val_mean_squared_error: 1.8177\n",
            "Epoch 461/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.8167 - mean_absolute_error: 0.9444 - mean_squared_error: 1.8167\n",
            "Epoch 461: val_loss improved from 1.81026 to 1.80354, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8146 - mean_absolute_error: 0.9438 - mean_squared_error: 1.8146 - val_loss: 1.8035 - val_mean_absolute_error: 0.9381 - val_mean_squared_error: 1.8035\n",
            "Epoch 462/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.8220 - mean_absolute_error: 0.9446 - mean_squared_error: 1.8220\n",
            "Epoch 462: val_loss improved from 1.80354 to 1.79856, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8202 - mean_absolute_error: 0.9444 - mean_squared_error: 1.8202 - val_loss: 1.7986 - val_mean_absolute_error: 0.9369 - val_mean_squared_error: 1.7986\n",
            "Epoch 463/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.8031 - mean_absolute_error: 0.9404 - mean_squared_error: 1.8031\n",
            "Epoch 463: val_loss did not improve from 1.79856\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.8107 - mean_absolute_error: 0.9418 - mean_squared_error: 1.8107 - val_loss: 1.8039 - val_mean_absolute_error: 0.9364 - val_mean_squared_error: 1.8039\n",
            "Epoch 464/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.8074 - mean_absolute_error: 0.9392 - mean_squared_error: 1.8074\n",
            "Epoch 464: val_loss did not improve from 1.79856\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8131 - mean_absolute_error: 0.9414 - mean_squared_error: 1.8131 - val_loss: 1.8005 - val_mean_absolute_error: 0.9454 - val_mean_squared_error: 1.8005\n",
            "Epoch 465/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.8000 - mean_absolute_error: 0.9418 - mean_squared_error: 1.8000\n",
            "Epoch 465: val_loss did not improve from 1.79856\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8074 - mean_absolute_error: 0.9433 - mean_squared_error: 1.8074 - val_loss: 1.8554 - val_mean_absolute_error: 0.9562 - val_mean_squared_error: 1.8554\n",
            "Epoch 466/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.8052 - mean_absolute_error: 0.9406 - mean_squared_error: 1.8052\n",
            "Epoch 466: val_loss improved from 1.79856 to 1.79119, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8052 - mean_absolute_error: 0.9406 - mean_squared_error: 1.8052 - val_loss: 1.7912 - val_mean_absolute_error: 0.9376 - val_mean_squared_error: 1.7912\n",
            "Epoch 467/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.8121 - mean_absolute_error: 0.9411 - mean_squared_error: 1.8121\n",
            "Epoch 467: val_loss did not improve from 1.79119\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8031 - mean_absolute_error: 0.9391 - mean_squared_error: 1.8031 - val_loss: 1.7928 - val_mean_absolute_error: 0.9347 - val_mean_squared_error: 1.7928\n",
            "Epoch 468/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.7613 - mean_absolute_error: 0.9296 - mean_squared_error: 1.7613\n",
            "Epoch 468: val_loss did not improve from 1.79119\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8038 - mean_absolute_error: 0.9398 - mean_squared_error: 1.8038 - val_loss: 1.7915 - val_mean_absolute_error: 0.9415 - val_mean_squared_error: 1.7915\n",
            "Epoch 469/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.7971 - mean_absolute_error: 0.9371 - mean_squared_error: 1.7971\n",
            "Epoch 469: val_loss improved from 1.79119 to 1.78558, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7971 - mean_absolute_error: 0.9371 - mean_squared_error: 1.7971 - val_loss: 1.7856 - val_mean_absolute_error: 0.9318 - val_mean_squared_error: 1.7856\n",
            "Epoch 470/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.8092 - mean_absolute_error: 0.9415 - mean_squared_error: 1.8092\n",
            "Epoch 470: val_loss did not improve from 1.78558\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7967 - mean_absolute_error: 0.9377 - mean_squared_error: 1.7967 - val_loss: 1.8076 - val_mean_absolute_error: 0.9384 - val_mean_squared_error: 1.8076\n",
            "Epoch 471/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.7895 - mean_absolute_error: 0.9359 - mean_squared_error: 1.7895\n",
            "Epoch 471: val_loss did not improve from 1.78558\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7956 - mean_absolute_error: 0.9372 - mean_squared_error: 1.7956 - val_loss: 1.7964 - val_mean_absolute_error: 0.9322 - val_mean_squared_error: 1.7964\n",
            "Epoch 472/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.7632 - mean_absolute_error: 0.9321 - mean_squared_error: 1.7632\n",
            "Epoch 472: val_loss improved from 1.78558 to 1.77904, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7942 - mean_absolute_error: 0.9370 - mean_squared_error: 1.7942 - val_loss: 1.7790 - val_mean_absolute_error: 0.9337 - val_mean_squared_error: 1.7790\n",
            "Epoch 473/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.7658 - mean_absolute_error: 0.9321 - mean_squared_error: 1.7658\n",
            "Epoch 473: val_loss did not improve from 1.77904\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7898 - mean_absolute_error: 0.9341 - mean_squared_error: 1.7898 - val_loss: 1.7791 - val_mean_absolute_error: 0.9302 - val_mean_squared_error: 1.7791\n",
            "Epoch 474/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.7751 - mean_absolute_error: 0.9293 - mean_squared_error: 1.7751\n",
            "Epoch 474: val_loss improved from 1.77904 to 1.77686, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7887 - mean_absolute_error: 0.9333 - mean_squared_error: 1.7887 - val_loss: 1.7769 - val_mean_absolute_error: 0.9295 - val_mean_squared_error: 1.7769\n",
            "Epoch 475/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.7951 - mean_absolute_error: 0.9359 - mean_squared_error: 1.7951\n",
            "Epoch 475: val_loss did not improve from 1.77686\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7889 - mean_absolute_error: 0.9344 - mean_squared_error: 1.7889 - val_loss: 1.7916 - val_mean_absolute_error: 0.9319 - val_mean_squared_error: 1.7916\n",
            "Epoch 476/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.7744 - mean_absolute_error: 0.9314 - mean_squared_error: 1.7744\n",
            "Epoch 476: val_loss did not improve from 1.77686\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7801 - mean_absolute_error: 0.9335 - mean_squared_error: 1.7801 - val_loss: 1.7923 - val_mean_absolute_error: 0.9499 - val_mean_squared_error: 1.7923\n",
            "Epoch 477/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.7788 - mean_absolute_error: 0.9336 - mean_squared_error: 1.7788\n",
            "Epoch 477: val_loss improved from 1.77686 to 1.77528, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7862 - mean_absolute_error: 0.9350 - mean_squared_error: 1.7862 - val_loss: 1.7753 - val_mean_absolute_error: 0.9297 - val_mean_squared_error: 1.7753\n",
            "Epoch 478/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.7841 - mean_absolute_error: 0.9317 - mean_squared_error: 1.7841\n",
            "Epoch 478: val_loss did not improve from 1.77528\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7834 - mean_absolute_error: 0.9323 - mean_squared_error: 1.7834 - val_loss: 1.7786 - val_mean_absolute_error: 0.9407 - val_mean_squared_error: 1.7786\n",
            "Epoch 479/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.7713 - mean_absolute_error: 0.9270 - mean_squared_error: 1.7713\n",
            "Epoch 479: val_loss improved from 1.77528 to 1.77414, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7766 - mean_absolute_error: 0.9287 - mean_squared_error: 1.7766 - val_loss: 1.7741 - val_mean_absolute_error: 0.9382 - val_mean_squared_error: 1.7741\n",
            "Epoch 480/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.7843 - mean_absolute_error: 0.9327 - mean_squared_error: 1.7843\n",
            "Epoch 480: val_loss improved from 1.77414 to 1.76589, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7785 - mean_absolute_error: 0.9319 - mean_squared_error: 1.7785 - val_loss: 1.7659 - val_mean_absolute_error: 0.9223 - val_mean_squared_error: 1.7659\n",
            "Epoch 481/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.7723 - mean_absolute_error: 0.9279 - mean_squared_error: 1.7723\n",
            "Epoch 481: val_loss improved from 1.76589 to 1.76444, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7766 - mean_absolute_error: 0.9284 - mean_squared_error: 1.7766 - val_loss: 1.7644 - val_mean_absolute_error: 0.9220 - val_mean_squared_error: 1.7644\n",
            "Epoch 482/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.7950 - mean_absolute_error: 0.9342 - mean_squared_error: 1.7950\n",
            "Epoch 482: val_loss improved from 1.76444 to 1.75915, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7729 - mean_absolute_error: 0.9277 - mean_squared_error: 1.7729 - val_loss: 1.7592 - val_mean_absolute_error: 0.9262 - val_mean_squared_error: 1.7592\n",
            "Epoch 483/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.7503 - mean_absolute_error: 0.9243 - mean_squared_error: 1.7503\n",
            "Epoch 483: val_loss did not improve from 1.75915\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7654 - mean_absolute_error: 0.9271 - mean_squared_error: 1.7654 - val_loss: 1.7697 - val_mean_absolute_error: 0.9245 - val_mean_squared_error: 1.7697\n",
            "Epoch 484/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.7651 - mean_absolute_error: 0.9253 - mean_squared_error: 1.7651\n",
            "Epoch 484: val_loss improved from 1.75915 to 1.75642, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7651 - mean_absolute_error: 0.9253 - mean_squared_error: 1.7651 - val_loss: 1.7564 - val_mean_absolute_error: 0.9269 - val_mean_squared_error: 1.7564\n",
            "Epoch 485/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.7452 - mean_absolute_error: 0.9193 - mean_squared_error: 1.7452\n",
            "Epoch 485: val_loss improved from 1.75642 to 1.75390, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7593 - mean_absolute_error: 0.9238 - mean_squared_error: 1.7593 - val_loss: 1.7539 - val_mean_absolute_error: 0.9243 - val_mean_squared_error: 1.7539\n",
            "Epoch 486/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.7532 - mean_absolute_error: 0.9242 - mean_squared_error: 1.7532\n",
            "Epoch 486: val_loss did not improve from 1.75390\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7590 - mean_absolute_error: 0.9260 - mean_squared_error: 1.7590 - val_loss: 1.7539 - val_mean_absolute_error: 0.9186 - val_mean_squared_error: 1.7539\n",
            "Epoch 487/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.7748 - mean_absolute_error: 0.9275 - mean_squared_error: 1.7748\n",
            "Epoch 487: val_loss did not improve from 1.75390\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7617 - mean_absolute_error: 0.9242 - mean_squared_error: 1.7617 - val_loss: 1.7563 - val_mean_absolute_error: 0.9309 - val_mean_squared_error: 1.7563\n",
            "Epoch 488/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.7602 - mean_absolute_error: 0.9217 - mean_squared_error: 1.7602\n",
            "Epoch 488: val_loss improved from 1.75390 to 1.74882, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7613 - mean_absolute_error: 0.9225 - mean_squared_error: 1.7613 - val_loss: 1.7488 - val_mean_absolute_error: 0.9183 - val_mean_squared_error: 1.7488\n",
            "Epoch 489/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.7563 - mean_absolute_error: 0.9217 - mean_squared_error: 1.7563\n",
            "Epoch 489: val_loss did not improve from 1.74882\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7563 - mean_absolute_error: 0.9217 - mean_squared_error: 1.7563 - val_loss: 1.7506 - val_mean_absolute_error: 0.9270 - val_mean_squared_error: 1.7506\n",
            "Epoch 490/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.7595 - mean_absolute_error: 0.9226 - mean_squared_error: 1.7595\n",
            "Epoch 490: val_loss improved from 1.74882 to 1.74332, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7517 - mean_absolute_error: 0.9206 - mean_squared_error: 1.7517 - val_loss: 1.7433 - val_mean_absolute_error: 0.9217 - val_mean_squared_error: 1.7433\n",
            "Epoch 491/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.7409 - mean_absolute_error: 0.9153 - mean_squared_error: 1.7409\n",
            "Epoch 491: val_loss did not improve from 1.74332\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7484 - mean_absolute_error: 0.9176 - mean_squared_error: 1.7484 - val_loss: 1.7836 - val_mean_absolute_error: 0.9520 - val_mean_squared_error: 1.7836\n",
            "Epoch 492/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.7565 - mean_absolute_error: 0.9251 - mean_squared_error: 1.7565\n",
            "Epoch 492: val_loss improved from 1.74332 to 1.74289, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7518 - mean_absolute_error: 0.9235 - mean_squared_error: 1.7518 - val_loss: 1.7429 - val_mean_absolute_error: 0.9239 - val_mean_squared_error: 1.7429\n",
            "Epoch 493/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.7449 - mean_absolute_error: 0.9156 - mean_squared_error: 1.7449\n",
            "Epoch 493: val_loss did not improve from 1.74289\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7452 - mean_absolute_error: 0.9164 - mean_squared_error: 1.7452 - val_loss: 1.7491 - val_mean_absolute_error: 0.9299 - val_mean_squared_error: 1.7491\n",
            "Epoch 494/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.7311 - mean_absolute_error: 0.9157 - mean_squared_error: 1.7311\n",
            "Epoch 494: val_loss improved from 1.74289 to 1.73501, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7422 - mean_absolute_error: 0.9172 - mean_squared_error: 1.7422 - val_loss: 1.7350 - val_mean_absolute_error: 0.9178 - val_mean_squared_error: 1.7350\n",
            "Epoch 495/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.7655 - mean_absolute_error: 0.9281 - mean_squared_error: 1.7655\n",
            "Epoch 495: val_loss improved from 1.73501 to 1.73221, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7451 - mean_absolute_error: 0.9210 - mean_squared_error: 1.7451 - val_loss: 1.7322 - val_mean_absolute_error: 0.9164 - val_mean_squared_error: 1.7322\n",
            "Epoch 496/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.7415 - mean_absolute_error: 0.9158 - mean_squared_error: 1.7415\n",
            "Epoch 496: val_loss improved from 1.73221 to 1.73158, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7385 - mean_absolute_error: 0.9154 - mean_squared_error: 1.7385 - val_loss: 1.7316 - val_mean_absolute_error: 0.9179 - val_mean_squared_error: 1.7316\n",
            "Epoch 497/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.7326 - mean_absolute_error: 0.9146 - mean_squared_error: 1.7326\n",
            "Epoch 497: val_loss improved from 1.73158 to 1.72712, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.7360 - mean_absolute_error: 0.9146 - mean_squared_error: 1.7360 - val_loss: 1.7271 - val_mean_absolute_error: 0.9130 - val_mean_squared_error: 1.7271\n",
            "Epoch 498/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.7268 - mean_absolute_error: 0.9109 - mean_squared_error: 1.7268\n",
            "Epoch 498: val_loss did not improve from 1.72712\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7356 - mean_absolute_error: 0.9145 - mean_squared_error: 1.7356 - val_loss: 1.7570 - val_mean_absolute_error: 0.9171 - val_mean_squared_error: 1.7570\n",
            "Epoch 499/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.7420 - mean_absolute_error: 0.9130 - mean_squared_error: 1.7420\n",
            "Epoch 499: val_loss improved from 1.72712 to 1.72553, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7309 - mean_absolute_error: 0.9110 - mean_squared_error: 1.7309 - val_loss: 1.7255 - val_mean_absolute_error: 0.9158 - val_mean_squared_error: 1.7255\n",
            "Epoch 500/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.7485 - mean_absolute_error: 0.9184 - mean_squared_error: 1.7485\n",
            "Epoch 500: val_loss improved from 1.72553 to 1.71851, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.7288 - mean_absolute_error: 0.9130 - mean_squared_error: 1.7288 - val_loss: 1.7185 - val_mean_absolute_error: 0.9055 - val_mean_squared_error: 1.7185\n",
            "Epoch 501/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.7363 - mean_absolute_error: 0.9116 - mean_squared_error: 1.7363\n",
            "Epoch 501: val_loss did not improve from 1.71851\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7265 - mean_absolute_error: 0.9099 - mean_squared_error: 1.7265 - val_loss: 1.7289 - val_mean_absolute_error: 0.9225 - val_mean_squared_error: 1.7289\n",
            "Epoch 502/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.7230 - mean_absolute_error: 0.9098 - mean_squared_error: 1.7230\n",
            "Epoch 502: val_loss did not improve from 1.71851\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.7267 - mean_absolute_error: 0.9109 - mean_squared_error: 1.7267 - val_loss: 1.7219 - val_mean_absolute_error: 0.9161 - val_mean_squared_error: 1.7219\n",
            "Epoch 503/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.7205 - mean_absolute_error: 0.9096 - mean_squared_error: 1.7205\n",
            "Epoch 503: val_loss improved from 1.71851 to 1.71293, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7205 - mean_absolute_error: 0.9096 - mean_squared_error: 1.7205 - val_loss: 1.7129 - val_mean_absolute_error: 0.9074 - val_mean_squared_error: 1.7129\n",
            "Epoch 504/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.7172 - mean_absolute_error: 0.9086 - mean_squared_error: 1.7172\n",
            "Epoch 504: val_loss did not improve from 1.71293\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7181 - mean_absolute_error: 0.9085 - mean_squared_error: 1.7181 - val_loss: 1.7268 - val_mean_absolute_error: 0.9234 - val_mean_squared_error: 1.7268\n",
            "Epoch 505/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.7318 - mean_absolute_error: 0.9094 - mean_squared_error: 1.7318\n",
            "Epoch 505: val_loss improved from 1.71293 to 1.71058, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7136 - mean_absolute_error: 0.9052 - mean_squared_error: 1.7136 - val_loss: 1.7106 - val_mean_absolute_error: 0.9086 - val_mean_squared_error: 1.7106\n",
            "Epoch 506/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.6909 - mean_absolute_error: 0.8987 - mean_squared_error: 1.6909\n",
            "Epoch 506: val_loss improved from 1.71058 to 1.70899, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7114 - mean_absolute_error: 0.9031 - mean_squared_error: 1.7114 - val_loss: 1.7090 - val_mean_absolute_error: 0.9072 - val_mean_squared_error: 1.7090\n",
            "Epoch 507/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.7086 - mean_absolute_error: 0.9076 - mean_squared_error: 1.7086\n",
            "Epoch 507: val_loss did not improve from 1.70899\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7091 - mean_absolute_error: 0.9076 - mean_squared_error: 1.7091 - val_loss: 1.7690 - val_mean_absolute_error: 0.9555 - val_mean_squared_error: 1.7690\n",
            "Epoch 508/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.7225 - mean_absolute_error: 0.9102 - mean_squared_error: 1.7225\n",
            "Epoch 508: val_loss improved from 1.70899 to 1.70788, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7146 - mean_absolute_error: 0.9070 - mean_squared_error: 1.7146 - val_loss: 1.7079 - val_mean_absolute_error: 0.9045 - val_mean_squared_error: 1.7079\n",
            "Epoch 509/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.7049 - mean_absolute_error: 0.9021 - mean_squared_error: 1.7049\n",
            "Epoch 509: val_loss improved from 1.70788 to 1.70032, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7061 - mean_absolute_error: 0.9022 - mean_squared_error: 1.7061 - val_loss: 1.7003 - val_mean_absolute_error: 0.8999 - val_mean_squared_error: 1.7003\n",
            "Epoch 510/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.6934 - mean_absolute_error: 0.8969 - mean_squared_error: 1.6934\n",
            "Epoch 510: val_loss did not improve from 1.70032\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7015 - mean_absolute_error: 0.8999 - mean_squared_error: 1.7015 - val_loss: 1.7066 - val_mean_absolute_error: 0.9131 - val_mean_squared_error: 1.7066\n",
            "Epoch 511/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.7095 - mean_absolute_error: 0.9017 - mean_squared_error: 1.7095\n",
            "Epoch 511: val_loss did not improve from 1.70032\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7003 - mean_absolute_error: 0.8984 - mean_squared_error: 1.7003 - val_loss: 1.7082 - val_mean_absolute_error: 0.9148 - val_mean_squared_error: 1.7082\n",
            "Epoch 512/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.7021 - mean_absolute_error: 0.9015 - mean_squared_error: 1.7021\n",
            "Epoch 512: val_loss improved from 1.70032 to 1.69824, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7018 - mean_absolute_error: 0.9015 - mean_squared_error: 1.7018 - val_loss: 1.6982 - val_mean_absolute_error: 0.8994 - val_mean_squared_error: 1.6982\n",
            "Epoch 513/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.7253 - mean_absolute_error: 0.9045 - mean_squared_error: 1.7253\n",
            "Epoch 513: val_loss improved from 1.69824 to 1.69274, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7001 - mean_absolute_error: 0.9001 - mean_squared_error: 1.7001 - val_loss: 1.6927 - val_mean_absolute_error: 0.9033 - val_mean_squared_error: 1.6927\n",
            "Epoch 514/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.6881 - mean_absolute_error: 0.8962 - mean_squared_error: 1.6881\n",
            "Epoch 514: val_loss improved from 1.69274 to 1.69027, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6951 - mean_absolute_error: 0.8987 - mean_squared_error: 1.6951 - val_loss: 1.6903 - val_mean_absolute_error: 0.8960 - val_mean_squared_error: 1.6903\n",
            "Epoch 515/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.7011 - mean_absolute_error: 0.8989 - mean_squared_error: 1.7011\n",
            "Epoch 515: val_loss did not improve from 1.69027\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6899 - mean_absolute_error: 0.8955 - mean_squared_error: 1.6899 - val_loss: 1.6943 - val_mean_absolute_error: 0.8926 - val_mean_squared_error: 1.6943\n",
            "Epoch 516/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.6894 - mean_absolute_error: 0.8940 - mean_squared_error: 1.6894\n",
            "Epoch 516: val_loss improved from 1.69027 to 1.68568, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6867 - mean_absolute_error: 0.8948 - mean_squared_error: 1.6867 - val_loss: 1.6857 - val_mean_absolute_error: 0.8980 - val_mean_squared_error: 1.6857\n",
            "Epoch 517/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.6813 - mean_absolute_error: 0.8935 - mean_squared_error: 1.6813\n",
            "Epoch 517: val_loss improved from 1.68568 to 1.68372, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6842 - mean_absolute_error: 0.8928 - mean_squared_error: 1.6842 - val_loss: 1.6837 - val_mean_absolute_error: 0.8970 - val_mean_squared_error: 1.6837\n",
            "Epoch 518/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.6955 - mean_absolute_error: 0.8977 - mean_squared_error: 1.6955\n",
            "Epoch 518: val_loss improved from 1.68372 to 1.67781, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6860 - mean_absolute_error: 0.8951 - mean_squared_error: 1.6860 - val_loss: 1.6778 - val_mean_absolute_error: 0.8909 - val_mean_squared_error: 1.6778\n",
            "Epoch 519/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.6898 - mean_absolute_error: 0.8942 - mean_squared_error: 1.6898\n",
            "Epoch 519: val_loss improved from 1.67781 to 1.67483, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6878 - mean_absolute_error: 0.8942 - mean_squared_error: 1.6878 - val_loss: 1.6748 - val_mean_absolute_error: 0.8899 - val_mean_squared_error: 1.6748\n",
            "Epoch 520/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.6789 - mean_absolute_error: 0.8928 - mean_squared_error: 1.6789\n",
            "Epoch 520: val_loss did not improve from 1.67483\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6785 - mean_absolute_error: 0.8928 - mean_squared_error: 1.6785 - val_loss: 1.6770 - val_mean_absolute_error: 0.8892 - val_mean_squared_error: 1.6770\n",
            "Epoch 521/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.6799 - mean_absolute_error: 0.8924 - mean_squared_error: 1.6799\n",
            "Epoch 521: val_loss did not improve from 1.67483\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6754 - mean_absolute_error: 0.8901 - mean_squared_error: 1.6754 - val_loss: 1.6851 - val_mean_absolute_error: 0.8846 - val_mean_squared_error: 1.6851\n",
            "Epoch 522/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.6799 - mean_absolute_error: 0.8935 - mean_squared_error: 1.6799\n",
            "Epoch 522: val_loss improved from 1.67483 to 1.67482, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6742 - mean_absolute_error: 0.8894 - mean_squared_error: 1.6742 - val_loss: 1.6748 - val_mean_absolute_error: 0.8869 - val_mean_squared_error: 1.6748\n",
            "Epoch 523/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.6691 - mean_absolute_error: 0.8882 - mean_squared_error: 1.6691\n",
            "Epoch 523: val_loss improved from 1.67482 to 1.66520, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6691 - mean_absolute_error: 0.8882 - mean_squared_error: 1.6691 - val_loss: 1.6652 - val_mean_absolute_error: 0.8892 - val_mean_squared_error: 1.6652\n",
            "Epoch 524/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.6671 - mean_absolute_error: 0.8873 - mean_squared_error: 1.6671\n",
            "Epoch 524: val_loss improved from 1.66520 to 1.66474, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6675 - mean_absolute_error: 0.8881 - mean_squared_error: 1.6675 - val_loss: 1.6647 - val_mean_absolute_error: 0.8909 - val_mean_squared_error: 1.6647\n",
            "Epoch 525/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.6658 - mean_absolute_error: 0.8855 - mean_squared_error: 1.6658\n",
            "Epoch 525: val_loss improved from 1.66474 to 1.66002, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6651 - mean_absolute_error: 0.8852 - mean_squared_error: 1.6651 - val_loss: 1.6600 - val_mean_absolute_error: 0.8855 - val_mean_squared_error: 1.6600\n",
            "Epoch 526/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.6625 - mean_absolute_error: 0.8805 - mean_squared_error: 1.6625\n",
            "Epoch 526: val_loss did not improve from 1.66002\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6604 - mean_absolute_error: 0.8820 - mean_squared_error: 1.6604 - val_loss: 1.6731 - val_mean_absolute_error: 0.8907 - val_mean_squared_error: 1.6731\n",
            "Epoch 527/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.6664 - mean_absolute_error: 0.8839 - mean_squared_error: 1.6664\n",
            "Epoch 527: val_loss did not improve from 1.66002\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6585 - mean_absolute_error: 0.8844 - mean_squared_error: 1.6585 - val_loss: 1.6702 - val_mean_absolute_error: 0.9009 - val_mean_squared_error: 1.6702\n",
            "Epoch 528/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.6649 - mean_absolute_error: 0.8868 - mean_squared_error: 1.6649\n",
            "Epoch 528: val_loss did not improve from 1.66002\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6634 - mean_absolute_error: 0.8861 - mean_squared_error: 1.6634 - val_loss: 1.6847 - val_mean_absolute_error: 0.9141 - val_mean_squared_error: 1.6847\n",
            "Epoch 529/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.6588 - mean_absolute_error: 0.8823 - mean_squared_error: 1.6588\n",
            "Epoch 529: val_loss did not improve from 1.66002\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6554 - mean_absolute_error: 0.8820 - mean_squared_error: 1.6554 - val_loss: 1.6634 - val_mean_absolute_error: 0.8978 - val_mean_squared_error: 1.6634\n",
            "Epoch 530/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.6526 - mean_absolute_error: 0.8819 - mean_squared_error: 1.6526\n",
            "Epoch 530: val_loss improved from 1.66002 to 1.65600, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6526 - mean_absolute_error: 0.8819 - mean_squared_error: 1.6526 - val_loss: 1.6560 - val_mean_absolute_error: 0.8774 - val_mean_squared_error: 1.6560\n",
            "Epoch 531/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.6661 - mean_absolute_error: 0.8848 - mean_squared_error: 1.6661\n",
            "Epoch 531: val_loss improved from 1.65600 to 1.64638, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6533 - mean_absolute_error: 0.8821 - mean_squared_error: 1.6533 - val_loss: 1.6464 - val_mean_absolute_error: 0.8817 - val_mean_squared_error: 1.6464\n",
            "Epoch 532/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.6562 - mean_absolute_error: 0.8800 - mean_squared_error: 1.6562\n",
            "Epoch 532: val_loss did not improve from 1.64638\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6470 - mean_absolute_error: 0.8788 - mean_squared_error: 1.6470 - val_loss: 1.6469 - val_mean_absolute_error: 0.8758 - val_mean_squared_error: 1.6469\n",
            "Epoch 533/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.6476 - mean_absolute_error: 0.8786 - mean_squared_error: 1.6476\n",
            "Epoch 533: val_loss improved from 1.64638 to 1.64285, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6457 - mean_absolute_error: 0.8791 - mean_squared_error: 1.6457 - val_loss: 1.6428 - val_mean_absolute_error: 0.8822 - val_mean_squared_error: 1.6428\n",
            "Epoch 534/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.6268 - mean_absolute_error: 0.8734 - mean_squared_error: 1.6268\n",
            "Epoch 534: val_loss did not improve from 1.64285\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6401 - mean_absolute_error: 0.8770 - mean_squared_error: 1.6401 - val_loss: 1.6435 - val_mean_absolute_error: 0.8858 - val_mean_squared_error: 1.6435\n",
            "Epoch 535/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.6452 - mean_absolute_error: 0.8789 - mean_squared_error: 1.6452\n",
            "Epoch 535: val_loss improved from 1.64285 to 1.63769, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6384 - mean_absolute_error: 0.8756 - mean_squared_error: 1.6384 - val_loss: 1.6377 - val_mean_absolute_error: 0.8791 - val_mean_squared_error: 1.6377\n",
            "Epoch 536/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.6242 - mean_absolute_error: 0.8733 - mean_squared_error: 1.6242\n",
            "Epoch 536: val_loss did not improve from 1.63769\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6381 - mean_absolute_error: 0.8772 - mean_squared_error: 1.6381 - val_loss: 1.6554 - val_mean_absolute_error: 0.8995 - val_mean_squared_error: 1.6554\n",
            "Epoch 537/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.6597 - mean_absolute_error: 0.8850 - mean_squared_error: 1.6597\n",
            "Epoch 537: val_loss did not improve from 1.63769\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6393 - mean_absolute_error: 0.8776 - mean_squared_error: 1.6393 - val_loss: 1.6555 - val_mean_absolute_error: 0.8816 - val_mean_squared_error: 1.6555\n",
            "Epoch 538/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.6278 - mean_absolute_error: 0.8730 - mean_squared_error: 1.6278\n",
            "Epoch 538: val_loss improved from 1.63769 to 1.63246, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6333 - mean_absolute_error: 0.8746 - mean_squared_error: 1.6333 - val_loss: 1.6325 - val_mean_absolute_error: 0.8801 - val_mean_squared_error: 1.6325\n",
            "Epoch 539/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.6396 - mean_absolute_error: 0.8759 - mean_squared_error: 1.6396\n",
            "Epoch 539: val_loss did not improve from 1.63246\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6317 - mean_absolute_error: 0.8725 - mean_squared_error: 1.6317 - val_loss: 1.6325 - val_mean_absolute_error: 0.8717 - val_mean_squared_error: 1.6325\n",
            "Epoch 540/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.6293 - mean_absolute_error: 0.8721 - mean_squared_error: 1.6293\n",
            "Epoch 540: val_loss did not improve from 1.63246\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6257 - mean_absolute_error: 0.8716 - mean_squared_error: 1.6257 - val_loss: 1.6399 - val_mean_absolute_error: 0.8798 - val_mean_squared_error: 1.6399\n",
            "Epoch 541/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.6204 - mean_absolute_error: 0.8695 - mean_squared_error: 1.6204\n",
            "Epoch 541: val_loss did not improve from 1.63246\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6223 - mean_absolute_error: 0.8713 - mean_squared_error: 1.6223 - val_loss: 1.6947 - val_mean_absolute_error: 0.9298 - val_mean_squared_error: 1.6947\n",
            "Epoch 542/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.6280 - mean_absolute_error: 0.8760 - mean_squared_error: 1.6280\n",
            "Epoch 542: val_loss improved from 1.63246 to 1.61963, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6259 - mean_absolute_error: 0.8748 - mean_squared_error: 1.6259 - val_loss: 1.6196 - val_mean_absolute_error: 0.8699 - val_mean_squared_error: 1.6196\n",
            "Epoch 543/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.6025 - mean_absolute_error: 0.8649 - mean_squared_error: 1.6025\n",
            "Epoch 543: val_loss did not improve from 1.61963\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6176 - mean_absolute_error: 0.8671 - mean_squared_error: 1.6176 - val_loss: 1.6212 - val_mean_absolute_error: 0.8755 - val_mean_squared_error: 1.6212\n",
            "Epoch 544/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.6262 - mean_absolute_error: 0.8750 - mean_squared_error: 1.6262\n",
            "Epoch 544: val_loss improved from 1.61963 to 1.61721, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6171 - mean_absolute_error: 0.8709 - mean_squared_error: 1.6171 - val_loss: 1.6172 - val_mean_absolute_error: 0.8698 - val_mean_squared_error: 1.6172\n",
            "Epoch 545/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.6124 - mean_absolute_error: 0.8675 - mean_squared_error: 1.6124\n",
            "Epoch 545: val_loss improved from 1.61721 to 1.61689, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6112 - mean_absolute_error: 0.8671 - mean_squared_error: 1.6112 - val_loss: 1.6169 - val_mean_absolute_error: 0.8745 - val_mean_squared_error: 1.6169\n",
            "Epoch 546/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.6126 - mean_absolute_error: 0.8670 - mean_squared_error: 1.6126\n",
            "Epoch 546: val_loss improved from 1.61689 to 1.61280, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6120 - mean_absolute_error: 0.8669 - mean_squared_error: 1.6120 - val_loss: 1.6128 - val_mean_absolute_error: 0.8683 - val_mean_squared_error: 1.6128\n",
            "Epoch 547/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.6159 - mean_absolute_error: 0.8702 - mean_squared_error: 1.6159\n",
            "Epoch 547: val_loss did not improve from 1.61280\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6085 - mean_absolute_error: 0.8662 - mean_squared_error: 1.6085 - val_loss: 1.6215 - val_mean_absolute_error: 0.8654 - val_mean_squared_error: 1.6215\n",
            "Epoch 548/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.6210 - mean_absolute_error: 0.8714 - mean_squared_error: 1.6210\n",
            "Epoch 548: val_loss improved from 1.61280 to 1.61215, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6072 - mean_absolute_error: 0.8664 - mean_squared_error: 1.6072 - val_loss: 1.6121 - val_mean_absolute_error: 0.8737 - val_mean_squared_error: 1.6121\n",
            "Epoch 549/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.6119 - mean_absolute_error: 0.8694 - mean_squared_error: 1.6119\n",
            "Epoch 549: val_loss improved from 1.61215 to 1.61089, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6115 - mean_absolute_error: 0.8689 - mean_squared_error: 1.6115 - val_loss: 1.6109 - val_mean_absolute_error: 0.8751 - val_mean_squared_error: 1.6109\n",
            "Epoch 550/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.6013 - mean_absolute_error: 0.8631 - mean_squared_error: 1.6013\n",
            "Epoch 550: val_loss did not improve from 1.61089\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6012 - mean_absolute_error: 0.8642 - mean_squared_error: 1.6012 - val_loss: 1.6133 - val_mean_absolute_error: 0.8799 - val_mean_squared_error: 1.6133\n",
            "Epoch 551/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.6049 - mean_absolute_error: 0.8631 - mean_squared_error: 1.6049\n",
            "Epoch 551: val_loss improved from 1.61089 to 1.60410, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6004 - mean_absolute_error: 0.8629 - mean_squared_error: 1.6004 - val_loss: 1.6041 - val_mean_absolute_error: 0.8697 - val_mean_squared_error: 1.6041\n",
            "Epoch 552/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.5937 - mean_absolute_error: 0.8585 - mean_squared_error: 1.5937\n",
            "Epoch 552: val_loss did not improve from 1.60410\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5955 - mean_absolute_error: 0.8596 - mean_squared_error: 1.5955 - val_loss: 1.6110 - val_mean_absolute_error: 0.8800 - val_mean_squared_error: 1.6110\n",
            "Epoch 553/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.5961 - mean_absolute_error: 0.8609 - mean_squared_error: 1.5961\n",
            "Epoch 553: val_loss improved from 1.60410 to 1.59428, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5952 - mean_absolute_error: 0.8608 - mean_squared_error: 1.5952 - val_loss: 1.5943 - val_mean_absolute_error: 0.8597 - val_mean_squared_error: 1.5943\n",
            "Epoch 554/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.5796 - mean_absolute_error: 0.8582 - mean_squared_error: 1.5796\n",
            "Epoch 554: val_loss did not improve from 1.59428\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5894 - mean_absolute_error: 0.8603 - mean_squared_error: 1.5894 - val_loss: 1.6198 - val_mean_absolute_error: 0.8880 - val_mean_squared_error: 1.6198\n",
            "Epoch 555/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.5940 - mean_absolute_error: 0.8628 - mean_squared_error: 1.5940\n",
            "Epoch 555: val_loss improved from 1.59428 to 1.59172, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5950 - mean_absolute_error: 0.8621 - mean_squared_error: 1.5950 - val_loss: 1.5917 - val_mean_absolute_error: 0.8612 - val_mean_squared_error: 1.5917\n",
            "Epoch 556/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.5876 - mean_absolute_error: 0.8640 - mean_squared_error: 1.5876\n",
            "Epoch 556: val_loss did not improve from 1.59172\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5885 - mean_absolute_error: 0.8629 - mean_squared_error: 1.5885 - val_loss: 1.5976 - val_mean_absolute_error: 0.8527 - val_mean_squared_error: 1.5976\n",
            "Epoch 557/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.5863 - mean_absolute_error: 0.8574 - mean_squared_error: 1.5863\n",
            "Epoch 557: val_loss improved from 1.59172 to 1.58536, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5829 - mean_absolute_error: 0.8562 - mean_squared_error: 1.5829 - val_loss: 1.5854 - val_mean_absolute_error: 0.8565 - val_mean_squared_error: 1.5854\n",
            "Epoch 558/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.5633 - mean_absolute_error: 0.8504 - mean_squared_error: 1.5633\n",
            "Epoch 558: val_loss did not improve from 1.58536\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5820 - mean_absolute_error: 0.8561 - mean_squared_error: 1.5820 - val_loss: 1.5868 - val_mean_absolute_error: 0.8587 - val_mean_squared_error: 1.5868\n",
            "Epoch 559/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.5679 - mean_absolute_error: 0.8530 - mean_squared_error: 1.5679\n",
            "Epoch 559: val_loss did not improve from 1.58536\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5781 - mean_absolute_error: 0.8573 - mean_squared_error: 1.5781 - val_loss: 1.6120 - val_mean_absolute_error: 0.8675 - val_mean_squared_error: 1.6120\n",
            "Epoch 560/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.5901 - mean_absolute_error: 0.8589 - mean_squared_error: 1.5901\n",
            "Epoch 560: val_loss improved from 1.58536 to 1.58037, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5785 - mean_absolute_error: 0.8565 - mean_squared_error: 1.5785 - val_loss: 1.5804 - val_mean_absolute_error: 0.8578 - val_mean_squared_error: 1.5804\n",
            "Epoch 561/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.5784 - mean_absolute_error: 0.8577 - mean_squared_error: 1.5784\n",
            "Epoch 561: val_loss did not improve from 1.58037\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5783 - mean_absolute_error: 0.8575 - mean_squared_error: 1.5783 - val_loss: 1.5854 - val_mean_absolute_error: 0.8559 - val_mean_squared_error: 1.5854\n",
            "Epoch 562/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.5902 - mean_absolute_error: 0.8601 - mean_squared_error: 1.5902\n",
            "Epoch 562: val_loss improved from 1.58037 to 1.57618, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5845 - mean_absolute_error: 0.8575 - mean_squared_error: 1.5845 - val_loss: 1.5762 - val_mean_absolute_error: 0.8550 - val_mean_squared_error: 1.5762\n",
            "Epoch 563/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.5694 - mean_absolute_error: 0.8532 - mean_squared_error: 1.5694\n",
            "Epoch 563: val_loss did not improve from 1.57618\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5705 - mean_absolute_error: 0.8521 - mean_squared_error: 1.5705 - val_loss: 1.5822 - val_mean_absolute_error: 0.8679 - val_mean_squared_error: 1.5822\n",
            "Epoch 564/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.5703 - mean_absolute_error: 0.8536 - mean_squared_error: 1.5703\n",
            "Epoch 564: val_loss did not improve from 1.57618\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5692 - mean_absolute_error: 0.8521 - mean_squared_error: 1.5692 - val_loss: 1.5843 - val_mean_absolute_error: 0.8709 - val_mean_squared_error: 1.5843\n",
            "Epoch 565/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.5609 - mean_absolute_error: 0.8493 - mean_squared_error: 1.5609\n",
            "Epoch 565: val_loss improved from 1.57618 to 1.57356, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.5678 - mean_absolute_error: 0.8515 - mean_squared_error: 1.5678 - val_loss: 1.5736 - val_mean_absolute_error: 0.8582 - val_mean_squared_error: 1.5736\n",
            "Epoch 566/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.5710 - mean_absolute_error: 0.8540 - mean_squared_error: 1.5710\n",
            "Epoch 566: val_loss improved from 1.57356 to 1.57109, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.5659 - mean_absolute_error: 0.8529 - mean_squared_error: 1.5659 - val_loss: 1.5711 - val_mean_absolute_error: 0.8586 - val_mean_squared_error: 1.5711\n",
            "Epoch 567/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.5593 - mean_absolute_error: 0.8506 - mean_squared_error: 1.5593\n",
            "Epoch 567: val_loss improved from 1.57109 to 1.56976, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.5639 - mean_absolute_error: 0.8518 - mean_squared_error: 1.5639 - val_loss: 1.5698 - val_mean_absolute_error: 0.8591 - val_mean_squared_error: 1.5698\n",
            "Epoch 568/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.5673 - mean_absolute_error: 0.8540 - mean_squared_error: 1.5673\n",
            "Epoch 568: val_loss improved from 1.56976 to 1.56517, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5630 - mean_absolute_error: 0.8536 - mean_squared_error: 1.5630 - val_loss: 1.5652 - val_mean_absolute_error: 0.8478 - val_mean_squared_error: 1.5652\n",
            "Epoch 569/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.5677 - mean_absolute_error: 0.8521 - mean_squared_error: 1.5677\n",
            "Epoch 569: val_loss improved from 1.56517 to 1.56137, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5551 - mean_absolute_error: 0.8496 - mean_squared_error: 1.5551 - val_loss: 1.5614 - val_mean_absolute_error: 0.8467 - val_mean_squared_error: 1.5614\n",
            "Epoch 570/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.5736 - mean_absolute_error: 0.8565 - mean_squared_error: 1.5736\n",
            "Epoch 570: val_loss did not improve from 1.56137\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5598 - mean_absolute_error: 0.8522 - mean_squared_error: 1.5598 - val_loss: 1.5618 - val_mean_absolute_error: 0.8516 - val_mean_squared_error: 1.5618\n",
            "Epoch 571/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.5502 - mean_absolute_error: 0.8463 - mean_squared_error: 1.5502\n",
            "Epoch 571: val_loss did not improve from 1.56137\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5587 - mean_absolute_error: 0.8484 - mean_squared_error: 1.5587 - val_loss: 1.5616 - val_mean_absolute_error: 0.8572 - val_mean_squared_error: 1.5616\n",
            "Epoch 572/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.5351 - mean_absolute_error: 0.8403 - mean_squared_error: 1.5351\n",
            "Epoch 572: val_loss improved from 1.56137 to 1.55950, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5463 - mean_absolute_error: 0.8443 - mean_squared_error: 1.5463 - val_loss: 1.5595 - val_mean_absolute_error: 0.8548 - val_mean_squared_error: 1.5595\n",
            "Epoch 573/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.5428 - mean_absolute_error: 0.8449 - mean_squared_error: 1.5428\n",
            "Epoch 573: val_loss improved from 1.55950 to 1.55768, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5501 - mean_absolute_error: 0.8463 - mean_squared_error: 1.5501 - val_loss: 1.5577 - val_mean_absolute_error: 0.8555 - val_mean_squared_error: 1.5577\n",
            "Epoch 574/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.5443 - mean_absolute_error: 0.8480 - mean_squared_error: 1.5443\n",
            "Epoch 574: val_loss did not improve from 1.55768\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5457 - mean_absolute_error: 0.8474 - mean_squared_error: 1.5457 - val_loss: 1.5671 - val_mean_absolute_error: 0.8480 - val_mean_squared_error: 1.5671\n",
            "Epoch 575/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.5448 - mean_absolute_error: 0.8454 - mean_squared_error: 1.5448\n",
            "Epoch 575: val_loss improved from 1.55768 to 1.55063, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5495 - mean_absolute_error: 0.8463 - mean_squared_error: 1.5495 - val_loss: 1.5506 - val_mean_absolute_error: 0.8498 - val_mean_squared_error: 1.5506\n",
            "Epoch 576/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.5538 - mean_absolute_error: 0.8489 - mean_squared_error: 1.5538\n",
            "Epoch 576: val_loss did not improve from 1.55063\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5440 - mean_absolute_error: 0.8465 - mean_squared_error: 1.5440 - val_loss: 1.5522 - val_mean_absolute_error: 0.8550 - val_mean_squared_error: 1.5522\n",
            "Epoch 577/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.5491 - mean_absolute_error: 0.8469 - mean_squared_error: 1.5491\n",
            "Epoch 577: val_loss improved from 1.55063 to 1.54577, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5374 - mean_absolute_error: 0.8438 - mean_squared_error: 1.5374 - val_loss: 1.5458 - val_mean_absolute_error: 0.8460 - val_mean_squared_error: 1.5458\n",
            "Epoch 578/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.5312 - mean_absolute_error: 0.8396 - mean_squared_error: 1.5312\n",
            "Epoch 578: val_loss did not improve from 1.54577\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5403 - mean_absolute_error: 0.8426 - mean_squared_error: 1.5403 - val_loss: 1.5468 - val_mean_absolute_error: 0.8516 - val_mean_squared_error: 1.5468\n",
            "Epoch 579/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.5253 - mean_absolute_error: 0.8406 - mean_squared_error: 1.5253\n",
            "Epoch 579: val_loss did not improve from 1.54577\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5330 - mean_absolute_error: 0.8431 - mean_squared_error: 1.5330 - val_loss: 1.5535 - val_mean_absolute_error: 0.8542 - val_mean_squared_error: 1.5535\n",
            "Epoch 580/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.5352 - mean_absolute_error: 0.8447 - mean_squared_error: 1.5352\n",
            "Epoch 580: val_loss improved from 1.54577 to 1.53857, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5366 - mean_absolute_error: 0.8442 - mean_squared_error: 1.5366 - val_loss: 1.5386 - val_mean_absolute_error: 0.8403 - val_mean_squared_error: 1.5386\n",
            "Epoch 581/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.5310 - mean_absolute_error: 0.8447 - mean_squared_error: 1.5310\n",
            "Epoch 581: val_loss did not improve from 1.53857\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5355 - mean_absolute_error: 0.8455 - mean_squared_error: 1.5355 - val_loss: 1.5411 - val_mean_absolute_error: 0.8429 - val_mean_squared_error: 1.5411\n",
            "Epoch 582/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.5314 - mean_absolute_error: 0.8406 - mean_squared_error: 1.5314\n",
            "Epoch 582: val_loss did not improve from 1.53857\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5305 - mean_absolute_error: 0.8421 - mean_squared_error: 1.5305 - val_loss: 1.5652 - val_mean_absolute_error: 0.8743 - val_mean_squared_error: 1.5652\n",
            "Epoch 583/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.5318 - mean_absolute_error: 0.8429 - mean_squared_error: 1.5318\n",
            "Epoch 583: val_loss improved from 1.53857 to 1.53819, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5325 - mean_absolute_error: 0.8418 - mean_squared_error: 1.5325 - val_loss: 1.5382 - val_mean_absolute_error: 0.8514 - val_mean_squared_error: 1.5382\n",
            "Epoch 584/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.5058 - mean_absolute_error: 0.8379 - mean_squared_error: 1.5058\n",
            "Epoch 584: val_loss did not improve from 1.53819\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5208 - mean_absolute_error: 0.8411 - mean_squared_error: 1.5208 - val_loss: 1.5421 - val_mean_absolute_error: 0.8514 - val_mean_squared_error: 1.5421\n",
            "Epoch 585/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.5198 - mean_absolute_error: 0.8352 - mean_squared_error: 1.5198\n",
            "Epoch 585: val_loss improved from 1.53819 to 1.53448, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5229 - mean_absolute_error: 0.8379 - mean_squared_error: 1.5229 - val_loss: 1.5345 - val_mean_absolute_error: 0.8464 - val_mean_squared_error: 1.5345\n",
            "Epoch 586/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.5104 - mean_absolute_error: 0.8380 - mean_squared_error: 1.5104\n",
            "Epoch 586: val_loss improved from 1.53448 to 1.53119, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5207 - mean_absolute_error: 0.8410 - mean_squared_error: 1.5207 - val_loss: 1.5312 - val_mean_absolute_error: 0.8487 - val_mean_squared_error: 1.5312\n",
            "Epoch 587/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.5319 - mean_absolute_error: 0.8456 - mean_squared_error: 1.5319\n",
            "Epoch 587: val_loss improved from 1.53119 to 1.52880, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5256 - mean_absolute_error: 0.8428 - mean_squared_error: 1.5256 - val_loss: 1.5288 - val_mean_absolute_error: 0.8367 - val_mean_squared_error: 1.5288\n",
            "Epoch 588/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.5349 - mean_absolute_error: 0.8408 - mean_squared_error: 1.5349\n",
            "Epoch 588: val_loss improved from 1.52880 to 1.52769, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5162 - mean_absolute_error: 0.8348 - mean_squared_error: 1.5162 - val_loss: 1.5277 - val_mean_absolute_error: 0.8471 - val_mean_squared_error: 1.5277\n",
            "Epoch 589/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.5264 - mean_absolute_error: 0.8412 - mean_squared_error: 1.5264\n",
            "Epoch 589: val_loss did not improve from 1.52769\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5150 - mean_absolute_error: 0.8367 - mean_squared_error: 1.5150 - val_loss: 1.5280 - val_mean_absolute_error: 0.8492 - val_mean_squared_error: 1.5280\n",
            "Epoch 590/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.5263 - mean_absolute_error: 0.8403 - mean_squared_error: 1.5263\n",
            "Epoch 590: val_loss improved from 1.52769 to 1.52125, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5175 - mean_absolute_error: 0.8404 - mean_squared_error: 1.5175 - val_loss: 1.5212 - val_mean_absolute_error: 0.8425 - val_mean_squared_error: 1.5212\n",
            "Epoch 591/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.5130 - mean_absolute_error: 0.8357 - mean_squared_error: 1.5130\n",
            "Epoch 591: val_loss improved from 1.52125 to 1.51745, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5143 - mean_absolute_error: 0.8357 - mean_squared_error: 1.5143 - val_loss: 1.5175 - val_mean_absolute_error: 0.8364 - val_mean_squared_error: 1.5175\n",
            "Epoch 592/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.4973 - mean_absolute_error: 0.8319 - mean_squared_error: 1.4973\n",
            "Epoch 592: val_loss did not improve from 1.51745\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5123 - mean_absolute_error: 0.8354 - mean_squared_error: 1.5123 - val_loss: 1.5203 - val_mean_absolute_error: 0.8431 - val_mean_squared_error: 1.5203\n",
            "Epoch 593/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.5153 - mean_absolute_error: 0.8372 - mean_squared_error: 1.5153\n",
            "Epoch 593: val_loss did not improve from 1.51745\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5083 - mean_absolute_error: 0.8350 - mean_squared_error: 1.5083 - val_loss: 1.5181 - val_mean_absolute_error: 0.8431 - val_mean_squared_error: 1.5181\n",
            "Epoch 594/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.5104 - mean_absolute_error: 0.8371 - mean_squared_error: 1.5104\n",
            "Epoch 594: val_loss improved from 1.51745 to 1.51496, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5100 - mean_absolute_error: 0.8377 - mean_squared_error: 1.5100 - val_loss: 1.5150 - val_mean_absolute_error: 0.8412 - val_mean_squared_error: 1.5150\n",
            "Epoch 595/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.4987 - mean_absolute_error: 0.8300 - mean_squared_error: 1.4987\n",
            "Epoch 595: val_loss did not improve from 1.51496\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5018 - mean_absolute_error: 0.8311 - mean_squared_error: 1.5018 - val_loss: 1.5321 - val_mean_absolute_error: 0.8611 - val_mean_squared_error: 1.5321\n",
            "Epoch 596/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.4989 - mean_absolute_error: 0.8326 - mean_squared_error: 1.4989\n",
            "Epoch 596: val_loss improved from 1.51496 to 1.50988, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5024 - mean_absolute_error: 0.8337 - mean_squared_error: 1.5024 - val_loss: 1.5099 - val_mean_absolute_error: 0.8379 - val_mean_squared_error: 1.5099\n",
            "Epoch 597/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.5137 - mean_absolute_error: 0.8378 - mean_squared_error: 1.5137\n",
            "Epoch 597: val_loss did not improve from 1.50988\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5074 - mean_absolute_error: 0.8360 - mean_squared_error: 1.5074 - val_loss: 1.5143 - val_mean_absolute_error: 0.8460 - val_mean_squared_error: 1.5143\n",
            "Epoch 598/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.4996 - mean_absolute_error: 0.8334 - mean_squared_error: 1.4996\n",
            "Epoch 598: val_loss improved from 1.50988 to 1.50496, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5010 - mean_absolute_error: 0.8345 - mean_squared_error: 1.5010 - val_loss: 1.5050 - val_mean_absolute_error: 0.8351 - val_mean_squared_error: 1.5050\n",
            "Epoch 599/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.4873 - mean_absolute_error: 0.8273 - mean_squared_error: 1.4873\n",
            "Epoch 599: val_loss did not improve from 1.50496\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4947 - mean_absolute_error: 0.8296 - mean_squared_error: 1.4947 - val_loss: 1.5121 - val_mean_absolute_error: 0.8396 - val_mean_squared_error: 1.5121\n",
            "Epoch 600/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.5022 - mean_absolute_error: 0.8371 - mean_squared_error: 1.5022\n",
            "Epoch 600: val_loss improved from 1.50496 to 1.50335, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4963 - mean_absolute_error: 0.8352 - mean_squared_error: 1.4963 - val_loss: 1.5033 - val_mean_absolute_error: 0.8382 - val_mean_squared_error: 1.5033\n",
            "Epoch 601/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.4892 - mean_absolute_error: 0.8292 - mean_squared_error: 1.4892\n",
            "Epoch 601: val_loss did not improve from 1.50335\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4916 - mean_absolute_error: 0.8300 - mean_squared_error: 1.4916 - val_loss: 1.5125 - val_mean_absolute_error: 0.8490 - val_mean_squared_error: 1.5125\n",
            "Epoch 602/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.4849 - mean_absolute_error: 0.8298 - mean_squared_error: 1.4849\n",
            "Epoch 602: val_loss improved from 1.50335 to 1.50218, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4896 - mean_absolute_error: 0.8329 - mean_squared_error: 1.4896 - val_loss: 1.5022 - val_mean_absolute_error: 0.8398 - val_mean_squared_error: 1.5022\n",
            "Epoch 603/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.4786 - mean_absolute_error: 0.8272 - mean_squared_error: 1.4786\n",
            "Epoch 603: val_loss improved from 1.50218 to 1.49766, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4893 - mean_absolute_error: 0.8306 - mean_squared_error: 1.4893 - val_loss: 1.4977 - val_mean_absolute_error: 0.8345 - val_mean_squared_error: 1.4977\n",
            "Epoch 604/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.4867 - mean_absolute_error: 0.8319 - mean_squared_error: 1.4867\n",
            "Epoch 604: val_loss did not improve from 1.49766\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4852 - mean_absolute_error: 0.8303 - mean_squared_error: 1.4852 - val_loss: 1.4996 - val_mean_absolute_error: 0.8333 - val_mean_squared_error: 1.4996\n",
            "Epoch 605/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.4642 - mean_absolute_error: 0.8225 - mean_squared_error: 1.4642\n",
            "Epoch 605: val_loss did not improve from 1.49766\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4871 - mean_absolute_error: 0.8310 - mean_squared_error: 1.4871 - val_loss: 1.5027 - val_mean_absolute_error: 0.8446 - val_mean_squared_error: 1.5027\n",
            "Epoch 606/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.4816 - mean_absolute_error: 0.8273 - mean_squared_error: 1.4816\n",
            "Epoch 606: val_loss did not improve from 1.49766\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4820 - mean_absolute_error: 0.8270 - mean_squared_error: 1.4820 - val_loss: 1.5057 - val_mean_absolute_error: 0.8507 - val_mean_squared_error: 1.5057\n",
            "Epoch 607/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.4955 - mean_absolute_error: 0.8351 - mean_squared_error: 1.4955\n",
            "Epoch 607: val_loss improved from 1.49766 to 1.49121, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4891 - mean_absolute_error: 0.8337 - mean_squared_error: 1.4891 - val_loss: 1.4912 - val_mean_absolute_error: 0.8345 - val_mean_squared_error: 1.4912\n",
            "Epoch 608/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.4819 - mean_absolute_error: 0.8277 - mean_squared_error: 1.4819\n",
            "Epoch 608: val_loss did not improve from 1.49121\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4819 - mean_absolute_error: 0.8277 - mean_squared_error: 1.4819 - val_loss: 1.4914 - val_mean_absolute_error: 0.8361 - val_mean_squared_error: 1.4914\n",
            "Epoch 609/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.4831 - mean_absolute_error: 0.8292 - mean_squared_error: 1.4831\n",
            "Epoch 609: val_loss improved from 1.49121 to 1.48741, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4819 - mean_absolute_error: 0.8289 - mean_squared_error: 1.4819 - val_loss: 1.4874 - val_mean_absolute_error: 0.8304 - val_mean_squared_error: 1.4874\n",
            "Epoch 610/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.4851 - mean_absolute_error: 0.8299 - mean_squared_error: 1.4851\n",
            "Epoch 610: val_loss did not improve from 1.48741\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4768 - mean_absolute_error: 0.8274 - mean_squared_error: 1.4768 - val_loss: 1.4911 - val_mean_absolute_error: 0.8391 - val_mean_squared_error: 1.4911\n",
            "Epoch 611/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.4711 - mean_absolute_error: 0.8275 - mean_squared_error: 1.4711\n",
            "Epoch 611: val_loss improved from 1.48741 to 1.48286, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4731 - mean_absolute_error: 0.8276 - mean_squared_error: 1.4731 - val_loss: 1.4829 - val_mean_absolute_error: 0.8287 - val_mean_squared_error: 1.4829\n",
            "Epoch 612/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.4670 - mean_absolute_error: 0.8295 - mean_squared_error: 1.4670\n",
            "Epoch 612: val_loss did not improve from 1.48286\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4692 - mean_absolute_error: 0.8298 - mean_squared_error: 1.4692 - val_loss: 1.4879 - val_mean_absolute_error: 0.8381 - val_mean_squared_error: 1.4879\n",
            "Epoch 613/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.4820 - mean_absolute_error: 0.8317 - mean_squared_error: 1.4820\n",
            "Epoch 613: val_loss did not improve from 1.48286\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4718 - mean_absolute_error: 0.8274 - mean_squared_error: 1.4718 - val_loss: 1.4855 - val_mean_absolute_error: 0.8296 - val_mean_squared_error: 1.4855\n",
            "Epoch 614/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.4740 - mean_absolute_error: 0.8264 - mean_squared_error: 1.4740\n",
            "Epoch 614: val_loss improved from 1.48286 to 1.47998, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4710 - mean_absolute_error: 0.8244 - mean_squared_error: 1.4710 - val_loss: 1.4800 - val_mean_absolute_error: 0.8309 - val_mean_squared_error: 1.4800\n",
            "Epoch 615/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.4669 - mean_absolute_error: 0.8269 - mean_squared_error: 1.4669\n",
            "Epoch 615: val_loss did not improve from 1.47998\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4695 - mean_absolute_error: 0.8268 - mean_squared_error: 1.4695 - val_loss: 1.4832 - val_mean_absolute_error: 0.8393 - val_mean_squared_error: 1.4832\n",
            "Epoch 616/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.4637 - mean_absolute_error: 0.8262 - mean_squared_error: 1.4637\n",
            "Epoch 616: val_loss did not improve from 1.47998\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4660 - mean_absolute_error: 0.8258 - mean_squared_error: 1.4660 - val_loss: 1.4954 - val_mean_absolute_error: 0.8406 - val_mean_squared_error: 1.4954\n",
            "Epoch 617/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.4661 - mean_absolute_error: 0.8277 - mean_squared_error: 1.4661\n",
            "Epoch 617: val_loss did not improve from 1.47998\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4701 - mean_absolute_error: 0.8286 - mean_squared_error: 1.4701 - val_loss: 1.4927 - val_mean_absolute_error: 0.8507 - val_mean_squared_error: 1.4927\n",
            "Epoch 618/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.4620 - mean_absolute_error: 0.8243 - mean_squared_error: 1.4620\n",
            "Epoch 618: val_loss improved from 1.47998 to 1.47380, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4638 - mean_absolute_error: 0.8251 - mean_squared_error: 1.4638 - val_loss: 1.4738 - val_mean_absolute_error: 0.8308 - val_mean_squared_error: 1.4738\n",
            "Epoch 619/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.4607 - mean_absolute_error: 0.8229 - mean_squared_error: 1.4607\n",
            "Epoch 619: val_loss improved from 1.47380 to 1.47367, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4601 - mean_absolute_error: 0.8241 - mean_squared_error: 1.4601 - val_loss: 1.4737 - val_mean_absolute_error: 0.8325 - val_mean_squared_error: 1.4737\n",
            "Epoch 620/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.4600 - mean_absolute_error: 0.8217 - mean_squared_error: 1.4600\n",
            "Epoch 620: val_loss did not improve from 1.47367\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4619 - mean_absolute_error: 0.8230 - mean_squared_error: 1.4619 - val_loss: 1.4745 - val_mean_absolute_error: 0.8346 - val_mean_squared_error: 1.4745\n",
            "Epoch 621/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.4629 - mean_absolute_error: 0.8256 - mean_squared_error: 1.4629\n",
            "Epoch 621: val_loss improved from 1.47367 to 1.47061, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4619 - mean_absolute_error: 0.8259 - mean_squared_error: 1.4619 - val_loss: 1.4706 - val_mean_absolute_error: 0.8233 - val_mean_squared_error: 1.4706\n",
            "Epoch 622/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.4575 - mean_absolute_error: 0.8236 - mean_squared_error: 1.4575\n",
            "Epoch 622: val_loss improved from 1.47061 to 1.46665, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4567 - mean_absolute_error: 0.8235 - mean_squared_error: 1.4567 - val_loss: 1.4666 - val_mean_absolute_error: 0.8273 - val_mean_squared_error: 1.4666\n",
            "Epoch 623/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.4733 - mean_absolute_error: 0.8285 - mean_squared_error: 1.4733\n",
            "Epoch 623: val_loss did not improve from 1.46665\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4576 - mean_absolute_error: 0.8221 - mean_squared_error: 1.4576 - val_loss: 1.4740 - val_mean_absolute_error: 0.8376 - val_mean_squared_error: 1.4740\n",
            "Epoch 624/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.4540 - mean_absolute_error: 0.8220 - mean_squared_error: 1.4540\n",
            "Epoch 624: val_loss did not improve from 1.46665\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4535 - mean_absolute_error: 0.8219 - mean_squared_error: 1.4535 - val_loss: 1.4717 - val_mean_absolute_error: 0.8368 - val_mean_squared_error: 1.4717\n",
            "Epoch 625/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.4649 - mean_absolute_error: 0.8242 - mean_squared_error: 1.4649\n",
            "Epoch 625: val_loss did not improve from 1.46665\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.4545 - mean_absolute_error: 0.8204 - mean_squared_error: 1.4545 - val_loss: 1.4669 - val_mean_absolute_error: 0.8319 - val_mean_squared_error: 1.4669\n",
            "Epoch 626/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.4593 - mean_absolute_error: 0.8257 - mean_squared_error: 1.4593\n",
            "Epoch 626: val_loss improved from 1.46665 to 1.46395, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.4526 - mean_absolute_error: 0.8245 - mean_squared_error: 1.4526 - val_loss: 1.4640 - val_mean_absolute_error: 0.8315 - val_mean_squared_error: 1.4640\n",
            "Epoch 627/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.4502 - mean_absolute_error: 0.8214 - mean_squared_error: 1.4502\n",
            "Epoch 627: val_loss did not improve from 1.46395\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.4502 - mean_absolute_error: 0.8214 - mean_squared_error: 1.4502 - val_loss: 1.4878 - val_mean_absolute_error: 0.8525 - val_mean_squared_error: 1.4878\n",
            "Epoch 628/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.4668 - mean_absolute_error: 0.8323 - mean_squared_error: 1.4668\n",
            "Epoch 628: val_loss improved from 1.46395 to 1.45710, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4482 - mean_absolute_error: 0.8257 - mean_squared_error: 1.4482 - val_loss: 1.4571 - val_mean_absolute_error: 0.8221 - val_mean_squared_error: 1.4571\n",
            "Epoch 629/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.4580 - mean_absolute_error: 0.8301 - mean_squared_error: 1.4580\n",
            "Epoch 629: val_loss did not improve from 1.45710\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4432 - mean_absolute_error: 0.8247 - mean_squared_error: 1.4432 - val_loss: 1.4661 - val_mean_absolute_error: 0.8210 - val_mean_squared_error: 1.4661\n",
            "Epoch 630/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.4533 - mean_absolute_error: 0.8213 - mean_squared_error: 1.4533\n",
            "Epoch 630: val_loss did not improve from 1.45710\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4470 - mean_absolute_error: 0.8205 - mean_squared_error: 1.4470 - val_loss: 1.4603 - val_mean_absolute_error: 0.8318 - val_mean_squared_error: 1.4603\n",
            "Epoch 631/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.4428 - mean_absolute_error: 0.8200 - mean_squared_error: 1.4428\n",
            "Epoch 631: val_loss did not improve from 1.45710\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4432 - mean_absolute_error: 0.8199 - mean_squared_error: 1.4432 - val_loss: 1.4595 - val_mean_absolute_error: 0.8344 - val_mean_squared_error: 1.4595\n",
            "Epoch 632/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.4311 - mean_absolute_error: 0.8179 - mean_squared_error: 1.4311\n",
            "Epoch 632: val_loss improved from 1.45710 to 1.45620, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4434 - mean_absolute_error: 0.8221 - mean_squared_error: 1.4434 - val_loss: 1.4562 - val_mean_absolute_error: 0.8302 - val_mean_squared_error: 1.4562\n",
            "Epoch 633/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.4310 - mean_absolute_error: 0.8180 - mean_squared_error: 1.4310\n",
            "Epoch 633: val_loss improved from 1.45620 to 1.45191, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4394 - mean_absolute_error: 0.8203 - mean_squared_error: 1.4394 - val_loss: 1.4519 - val_mean_absolute_error: 0.8247 - val_mean_squared_error: 1.4519\n",
            "Epoch 634/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.4353 - mean_absolute_error: 0.8192 - mean_squared_error: 1.4353\n",
            "Epoch 634: val_loss did not improve from 1.45191\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4383 - mean_absolute_error: 0.8198 - mean_squared_error: 1.4383 - val_loss: 1.4560 - val_mean_absolute_error: 0.8231 - val_mean_squared_error: 1.4560\n",
            "Epoch 635/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.4536 - mean_absolute_error: 0.8248 - mean_squared_error: 1.4536\n",
            "Epoch 635: val_loss did not improve from 1.45191\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4419 - mean_absolute_error: 0.8214 - mean_squared_error: 1.4419 - val_loss: 1.4684 - val_mean_absolute_error: 0.8453 - val_mean_squared_error: 1.4684\n",
            "Epoch 636/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.4365 - mean_absolute_error: 0.8219 - mean_squared_error: 1.4365\n",
            "Epoch 636: val_loss improved from 1.45191 to 1.44889, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4399 - mean_absolute_error: 0.8229 - mean_squared_error: 1.4399 - val_loss: 1.4489 - val_mean_absolute_error: 0.8275 - val_mean_squared_error: 1.4489\n",
            "Epoch 637/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.4494 - mean_absolute_error: 0.8240 - mean_squared_error: 1.4494\n",
            "Epoch 637: val_loss improved from 1.44889 to 1.44549, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4382 - mean_absolute_error: 0.8203 - mean_squared_error: 1.4382 - val_loss: 1.4455 - val_mean_absolute_error: 0.8228 - val_mean_squared_error: 1.4455\n",
            "Epoch 638/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.4296 - mean_absolute_error: 0.8173 - mean_squared_error: 1.4296\n",
            "Epoch 638: val_loss did not improve from 1.44549\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4322 - mean_absolute_error: 0.8179 - mean_squared_error: 1.4322 - val_loss: 1.4492 - val_mean_absolute_error: 0.8300 - val_mean_squared_error: 1.4492\n",
            "Epoch 639/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.4515 - mean_absolute_error: 0.8237 - mean_squared_error: 1.4515\n",
            "Epoch 639: val_loss did not improve from 1.44549\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4399 - mean_absolute_error: 0.8215 - mean_squared_error: 1.4399 - val_loss: 1.4493 - val_mean_absolute_error: 0.8287 - val_mean_squared_error: 1.4493\n",
            "Epoch 640/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.4296 - mean_absolute_error: 0.8148 - mean_squared_error: 1.4296\n",
            "Epoch 640: val_loss improved from 1.44549 to 1.44378, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4316 - mean_absolute_error: 0.8168 - mean_squared_error: 1.4316 - val_loss: 1.4438 - val_mean_absolute_error: 0.8258 - val_mean_squared_error: 1.4438\n",
            "Epoch 641/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.4289 - mean_absolute_error: 0.8178 - mean_squared_error: 1.4289\n",
            "Epoch 641: val_loss improved from 1.44378 to 1.44351, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4279 - mean_absolute_error: 0.8165 - mean_squared_error: 1.4279 - val_loss: 1.4435 - val_mean_absolute_error: 0.8282 - val_mean_squared_error: 1.4435\n",
            "Epoch 642/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.4147 - mean_absolute_error: 0.8134 - mean_squared_error: 1.4147\n",
            "Epoch 642: val_loss did not improve from 1.44351\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4278 - mean_absolute_error: 0.8169 - mean_squared_error: 1.4278 - val_loss: 1.4455 - val_mean_absolute_error: 0.8303 - val_mean_squared_error: 1.4455\n",
            "Epoch 643/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.4266 - mean_absolute_error: 0.8183 - mean_squared_error: 1.4266\n",
            "Epoch 643: val_loss improved from 1.44351 to 1.44300, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4270 - mean_absolute_error: 0.8183 - mean_squared_error: 1.4270 - val_loss: 1.4430 - val_mean_absolute_error: 0.8292 - val_mean_squared_error: 1.4430\n",
            "Epoch 644/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.4218 - mean_absolute_error: 0.8166 - mean_squared_error: 1.4218\n",
            "Epoch 644: val_loss improved from 1.44300 to 1.43799, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4246 - mean_absolute_error: 0.8175 - mean_squared_error: 1.4246 - val_loss: 1.4380 - val_mean_absolute_error: 0.8243 - val_mean_squared_error: 1.4380\n",
            "Epoch 645/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.4099 - mean_absolute_error: 0.8130 - mean_squared_error: 1.4099\n",
            "Epoch 645: val_loss improved from 1.43799 to 1.43695, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4255 - mean_absolute_error: 0.8186 - mean_squared_error: 1.4255 - val_loss: 1.4370 - val_mean_absolute_error: 0.8226 - val_mean_squared_error: 1.4370\n",
            "Epoch 646/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.4306 - mean_absolute_error: 0.8217 - mean_squared_error: 1.4306\n",
            "Epoch 646: val_loss did not improve from 1.43695\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4229 - mean_absolute_error: 0.8187 - mean_squared_error: 1.4229 - val_loss: 1.4389 - val_mean_absolute_error: 0.8237 - val_mean_squared_error: 1.4389\n",
            "Epoch 647/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.4279 - mean_absolute_error: 0.8176 - mean_squared_error: 1.4279\n",
            "Epoch 647: val_loss did not improve from 1.43695\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4251 - mean_absolute_error: 0.8177 - mean_squared_error: 1.4251 - val_loss: 1.4511 - val_mean_absolute_error: 0.8422 - val_mean_squared_error: 1.4511\n",
            "Epoch 648/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.4259 - mean_absolute_error: 0.8188 - mean_squared_error: 1.4259\n",
            "Epoch 648: val_loss did not improve from 1.43695\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4229 - mean_absolute_error: 0.8177 - mean_squared_error: 1.4229 - val_loss: 1.4437 - val_mean_absolute_error: 0.8357 - val_mean_squared_error: 1.4437\n",
            "Epoch 649/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.4124 - mean_absolute_error: 0.8178 - mean_squared_error: 1.4124\n",
            "Epoch 649: val_loss improved from 1.43695 to 1.43078, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4201 - mean_absolute_error: 0.8199 - mean_squared_error: 1.4201 - val_loss: 1.4308 - val_mean_absolute_error: 0.8216 - val_mean_squared_error: 1.4308\n",
            "Epoch 650/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.4037 - mean_absolute_error: 0.8160 - mean_squared_error: 1.4037\n",
            "Epoch 650: val_loss did not improve from 1.43078\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4147 - mean_absolute_error: 0.8181 - mean_squared_error: 1.4147 - val_loss: 1.4313 - val_mean_absolute_error: 0.8236 - val_mean_squared_error: 1.4313\n",
            "Epoch 651/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.4189 - mean_absolute_error: 0.8209 - mean_squared_error: 1.4189\n",
            "Epoch 651: val_loss did not improve from 1.43078\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4151 - mean_absolute_error: 0.8165 - mean_squared_error: 1.4151 - val_loss: 1.4381 - val_mean_absolute_error: 0.8339 - val_mean_squared_error: 1.4381\n",
            "Epoch 652/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.4455 - mean_absolute_error: 0.8286 - mean_squared_error: 1.4455\n",
            "Epoch 652: val_loss did not improve from 1.43078\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4190 - mean_absolute_error: 0.8209 - mean_squared_error: 1.4190 - val_loss: 1.4445 - val_mean_absolute_error: 0.8246 - val_mean_squared_error: 1.4445\n",
            "Epoch 653/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.4250 - mean_absolute_error: 0.8212 - mean_squared_error: 1.4250\n",
            "Epoch 653: val_loss improved from 1.43078 to 1.42776, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4132 - mean_absolute_error: 0.8159 - mean_squared_error: 1.4132 - val_loss: 1.4278 - val_mean_absolute_error: 0.8229 - val_mean_squared_error: 1.4278\n",
            "Epoch 654/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.4068 - mean_absolute_error: 0.8151 - mean_squared_error: 1.4068\n",
            "Epoch 654: val_loss did not improve from 1.42776\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4113 - mean_absolute_error: 0.8173 - mean_squared_error: 1.4113 - val_loss: 1.4282 - val_mean_absolute_error: 0.8267 - val_mean_squared_error: 1.4282\n",
            "Epoch 655/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.4192 - mean_absolute_error: 0.8172 - mean_squared_error: 1.4192\n",
            "Epoch 655: val_loss improved from 1.42776 to 1.42255, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4158 - mean_absolute_error: 0.8161 - mean_squared_error: 1.4158 - val_loss: 1.4225 - val_mean_absolute_error: 0.8186 - val_mean_squared_error: 1.4225\n",
            "Epoch 656/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.4108 - mean_absolute_error: 0.8124 - mean_squared_error: 1.4108\n",
            "Epoch 656: val_loss improved from 1.42255 to 1.42201, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4150 - mean_absolute_error: 0.8142 - mean_squared_error: 1.4150 - val_loss: 1.4220 - val_mean_absolute_error: 0.8172 - val_mean_squared_error: 1.4220\n",
            "Epoch 657/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.4105 - mean_absolute_error: 0.8158 - mean_squared_error: 1.4105\n",
            "Epoch 657: val_loss did not improve from 1.42201\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4093 - mean_absolute_error: 0.8140 - mean_squared_error: 1.4093 - val_loss: 1.4240 - val_mean_absolute_error: 0.8254 - val_mean_squared_error: 1.4240\n",
            "Epoch 658/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.4049 - mean_absolute_error: 0.8125 - mean_squared_error: 1.4049\n",
            "Epoch 658: val_loss did not improve from 1.42201\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4074 - mean_absolute_error: 0.8143 - mean_squared_error: 1.4074 - val_loss: 1.4239 - val_mean_absolute_error: 0.8254 - val_mean_squared_error: 1.4239\n",
            "Epoch 659/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.4115 - mean_absolute_error: 0.8169 - mean_squared_error: 1.4115\n",
            "Epoch 659: val_loss did not improve from 1.42201\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4076 - mean_absolute_error: 0.8157 - mean_squared_error: 1.4076 - val_loss: 1.4297 - val_mean_absolute_error: 0.8349 - val_mean_squared_error: 1.4297\n",
            "Epoch 660/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.4026 - mean_absolute_error: 0.8133 - mean_squared_error: 1.4026\n",
            "Epoch 660: val_loss improved from 1.42201 to 1.41953, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4057 - mean_absolute_error: 0.8139 - mean_squared_error: 1.4057 - val_loss: 1.4195 - val_mean_absolute_error: 0.8222 - val_mean_squared_error: 1.4195\n",
            "Epoch 661/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.4027 - mean_absolute_error: 0.8136 - mean_squared_error: 1.4027\n",
            "Epoch 661: val_loss did not improve from 1.41953\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4056 - mean_absolute_error: 0.8148 - mean_squared_error: 1.4056 - val_loss: 1.4299 - val_mean_absolute_error: 0.8345 - val_mean_squared_error: 1.4299\n",
            "Epoch 662/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.3941 - mean_absolute_error: 0.8113 - mean_squared_error: 1.3941\n",
            "Epoch 662: val_loss did not improve from 1.41953\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4035 - mean_absolute_error: 0.8137 - mean_squared_error: 1.4035 - val_loss: 1.4200 - val_mean_absolute_error: 0.8277 - val_mean_squared_error: 1.4200\n",
            "Epoch 663/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.3925 - mean_absolute_error: 0.8121 - mean_squared_error: 1.3925\n",
            "Epoch 663: val_loss did not improve from 1.41953\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4013 - mean_absolute_error: 0.8144 - mean_squared_error: 1.4013 - val_loss: 1.4273 - val_mean_absolute_error: 0.8337 - val_mean_squared_error: 1.4273\n",
            "Epoch 664/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.4053 - mean_absolute_error: 0.8160 - mean_squared_error: 1.4053\n",
            "Epoch 664: val_loss improved from 1.41953 to 1.41535, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4037 - mean_absolute_error: 0.8171 - mean_squared_error: 1.4037 - val_loss: 1.4154 - val_mean_absolute_error: 0.8226 - val_mean_squared_error: 1.4154\n",
            "Epoch 665/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.3962 - mean_absolute_error: 0.8125 - mean_squared_error: 1.3962\n",
            "Epoch 665: val_loss did not improve from 1.41535\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4050 - mean_absolute_error: 0.8154 - mean_squared_error: 1.4050 - val_loss: 1.4192 - val_mean_absolute_error: 0.8285 - val_mean_squared_error: 1.4192\n",
            "Epoch 666/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.4001 - mean_absolute_error: 0.8143 - mean_squared_error: 1.4001\n",
            "Epoch 666: val_loss did not improve from 1.41535\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3978 - mean_absolute_error: 0.8140 - mean_squared_error: 1.3978 - val_loss: 1.4228 - val_mean_absolute_error: 0.8306 - val_mean_squared_error: 1.4228\n",
            "Epoch 667/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.4023 - mean_absolute_error: 0.8149 - mean_squared_error: 1.4023\n",
            "Epoch 667: val_loss improved from 1.41535 to 1.41079, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4021 - mean_absolute_error: 0.8141 - mean_squared_error: 1.4021 - val_loss: 1.4108 - val_mean_absolute_error: 0.8204 - val_mean_squared_error: 1.4108\n",
            "Epoch 668/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.4027 - mean_absolute_error: 0.8192 - mean_squared_error: 1.4027\n",
            "Epoch 668: val_loss did not improve from 1.41079\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3993 - mean_absolute_error: 0.8165 - mean_squared_error: 1.3993 - val_loss: 1.4143 - val_mean_absolute_error: 0.8178 - val_mean_squared_error: 1.4143\n",
            "Epoch 669/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.3951 - mean_absolute_error: 0.8129 - mean_squared_error: 1.3951\n",
            "Epoch 669: val_loss did not improve from 1.41079\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3951 - mean_absolute_error: 0.8129 - mean_squared_error: 1.3951 - val_loss: 1.4153 - val_mean_absolute_error: 0.8275 - val_mean_squared_error: 1.4153\n",
            "Epoch 670/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.4033 - mean_absolute_error: 0.8159 - mean_squared_error: 1.4033\n",
            "Epoch 670: val_loss improved from 1.41079 to 1.40878, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3976 - mean_absolute_error: 0.8141 - mean_squared_error: 1.3976 - val_loss: 1.4088 - val_mean_absolute_error: 0.8225 - val_mean_squared_error: 1.4088\n",
            "Epoch 671/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.3825 - mean_absolute_error: 0.8089 - mean_squared_error: 1.3825\n",
            "Epoch 671: val_loss improved from 1.40878 to 1.40793, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3967 - mean_absolute_error: 0.8138 - mean_squared_error: 1.3967 - val_loss: 1.4079 - val_mean_absolute_error: 0.8183 - val_mean_squared_error: 1.4079\n",
            "Epoch 672/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.3861 - mean_absolute_error: 0.8099 - mean_squared_error: 1.3861\n",
            "Epoch 672: val_loss did not improve from 1.40793\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3883 - mean_absolute_error: 0.8106 - mean_squared_error: 1.3883 - val_loss: 1.4469 - val_mean_absolute_error: 0.8549 - val_mean_squared_error: 1.4469\n",
            "Epoch 673/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.3933 - mean_absolute_error: 0.8120 - mean_squared_error: 1.3933\n",
            "Epoch 673: val_loss improved from 1.40793 to 1.40491, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3960 - mean_absolute_error: 0.8129 - mean_squared_error: 1.3960 - val_loss: 1.4049 - val_mean_absolute_error: 0.8208 - val_mean_squared_error: 1.4049\n",
            "Epoch 674/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.3922 - mean_absolute_error: 0.8115 - mean_squared_error: 1.3922\n",
            "Epoch 674: val_loss did not improve from 1.40491\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3889 - mean_absolute_error: 0.8113 - mean_squared_error: 1.3889 - val_loss: 1.4187 - val_mean_absolute_error: 0.8353 - val_mean_squared_error: 1.4187\n",
            "Epoch 675/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.3754 - mean_absolute_error: 0.8083 - mean_squared_error: 1.3754\n",
            "Epoch 675: val_loss improved from 1.40491 to 1.40243, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3952 - mean_absolute_error: 0.8135 - mean_squared_error: 1.3952 - val_loss: 1.4024 - val_mean_absolute_error: 0.8202 - val_mean_squared_error: 1.4024\n",
            "Epoch 676/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.3931 - mean_absolute_error: 0.8138 - mean_squared_error: 1.3931\n",
            "Epoch 676: val_loss did not improve from 1.40243\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3939 - mean_absolute_error: 0.8137 - mean_squared_error: 1.3939 - val_loss: 1.4048 - val_mean_absolute_error: 0.8261 - val_mean_squared_error: 1.4048\n",
            "Epoch 677/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.3980 - mean_absolute_error: 0.8169 - mean_squared_error: 1.3980\n",
            "Epoch 677: val_loss improved from 1.40243 to 1.39928, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3905 - mean_absolute_error: 0.8157 - mean_squared_error: 1.3905 - val_loss: 1.3993 - val_mean_absolute_error: 0.8182 - val_mean_squared_error: 1.3993\n",
            "Epoch 678/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.3668 - mean_absolute_error: 0.8035 - mean_squared_error: 1.3668\n",
            "Epoch 678: val_loss did not improve from 1.39928\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3839 - mean_absolute_error: 0.8084 - mean_squared_error: 1.3839 - val_loss: 1.4000 - val_mean_absolute_error: 0.8206 - val_mean_squared_error: 1.4000\n",
            "Epoch 679/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.3847 - mean_absolute_error: 0.8109 - mean_squared_error: 1.3847\n",
            "Epoch 679: val_loss did not improve from 1.39928\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3849 - mean_absolute_error: 0.8109 - mean_squared_error: 1.3849 - val_loss: 1.4167 - val_mean_absolute_error: 0.8346 - val_mean_squared_error: 1.4167\n",
            "Epoch 680/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.3858 - mean_absolute_error: 0.8116 - mean_squared_error: 1.3858\n",
            "Epoch 680: val_loss improved from 1.39928 to 1.39793, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3836 - mean_absolute_error: 0.8111 - mean_squared_error: 1.3836 - val_loss: 1.3979 - val_mean_absolute_error: 0.8208 - val_mean_squared_error: 1.3979\n",
            "Epoch 681/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.3853 - mean_absolute_error: 0.8114 - mean_squared_error: 1.3853\n",
            "Epoch 681: val_loss did not improve from 1.39793\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3844 - mean_absolute_error: 0.8115 - mean_squared_error: 1.3844 - val_loss: 1.4110 - val_mean_absolute_error: 0.8335 - val_mean_squared_error: 1.4110\n",
            "Epoch 682/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.3835 - mean_absolute_error: 0.8110 - mean_squared_error: 1.3835\n",
            "Epoch 682: val_loss did not improve from 1.39793\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3835 - mean_absolute_error: 0.8110 - mean_squared_error: 1.3835 - val_loss: 1.4024 - val_mean_absolute_error: 0.8247 - val_mean_squared_error: 1.4024\n",
            "Epoch 683/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.3816 - mean_absolute_error: 0.8105 - mean_squared_error: 1.3816\n",
            "Epoch 683: val_loss did not improve from 1.39793\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3827 - mean_absolute_error: 0.8107 - mean_squared_error: 1.3827 - val_loss: 1.4022 - val_mean_absolute_error: 0.8265 - val_mean_squared_error: 1.4022\n",
            "Epoch 684/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.3798 - mean_absolute_error: 0.8118 - mean_squared_error: 1.3798\n",
            "Epoch 684: val_loss improved from 1.39793 to 1.39607, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3794 - mean_absolute_error: 0.8112 - mean_squared_error: 1.3794 - val_loss: 1.3961 - val_mean_absolute_error: 0.8233 - val_mean_squared_error: 1.3961\n",
            "Epoch 685/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.3864 - mean_absolute_error: 0.8131 - mean_squared_error: 1.3864\n",
            "Epoch 685: val_loss improved from 1.39607 to 1.39016, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3795 - mean_absolute_error: 0.8110 - mean_squared_error: 1.3795 - val_loss: 1.3902 - val_mean_absolute_error: 0.8152 - val_mean_squared_error: 1.3902\n",
            "Epoch 686/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.3636 - mean_absolute_error: 0.8040 - mean_squared_error: 1.3636\n",
            "Epoch 686: val_loss did not improve from 1.39016\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3770 - mean_absolute_error: 0.8080 - mean_squared_error: 1.3770 - val_loss: 1.4038 - val_mean_absolute_error: 0.8304 - val_mean_squared_error: 1.4038\n",
            "Epoch 687/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.3818 - mean_absolute_error: 0.8133 - mean_squared_error: 1.3818\n",
            "Epoch 687: val_loss did not improve from 1.39016\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3767 - mean_absolute_error: 0.8096 - mean_squared_error: 1.3767 - val_loss: 1.4051 - val_mean_absolute_error: 0.8202 - val_mean_squared_error: 1.4051\n",
            "Epoch 688/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.3878 - mean_absolute_error: 0.8136 - mean_squared_error: 1.3878\n",
            "Epoch 688: val_loss improved from 1.39016 to 1.38987, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3788 - mean_absolute_error: 0.8095 - mean_squared_error: 1.3788 - val_loss: 1.3899 - val_mean_absolute_error: 0.8170 - val_mean_squared_error: 1.3899\n",
            "Epoch 689/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.3803 - mean_absolute_error: 0.8103 - mean_squared_error: 1.3803\n",
            "Epoch 689: val_loss improved from 1.38987 to 1.38736, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3730 - mean_absolute_error: 0.8092 - mean_squared_error: 1.3730 - val_loss: 1.3874 - val_mean_absolute_error: 0.8180 - val_mean_squared_error: 1.3874\n",
            "Epoch 690/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.3902 - mean_absolute_error: 0.8152 - mean_squared_error: 1.3902\n",
            "Epoch 690: val_loss did not improve from 1.38736\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3758 - mean_absolute_error: 0.8100 - mean_squared_error: 1.3758 - val_loss: 1.3914 - val_mean_absolute_error: 0.8193 - val_mean_squared_error: 1.3914\n",
            "Epoch 691/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.3775 - mean_absolute_error: 0.8099 - mean_squared_error: 1.3775\n",
            "Epoch 691: val_loss improved from 1.38736 to 1.38294, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3715 - mean_absolute_error: 0.8075 - mean_squared_error: 1.3715 - val_loss: 1.3829 - val_mean_absolute_error: 0.8130 - val_mean_squared_error: 1.3829\n",
            "Epoch 692/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.3712 - mean_absolute_error: 0.8062 - mean_squared_error: 1.3712\n",
            "Epoch 692: val_loss did not improve from 1.38294\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3715 - mean_absolute_error: 0.8065 - mean_squared_error: 1.3715 - val_loss: 1.3909 - val_mean_absolute_error: 0.8235 - val_mean_squared_error: 1.3909\n",
            "Epoch 693/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.3719 - mean_absolute_error: 0.8108 - mean_squared_error: 1.3719\n",
            "Epoch 693: val_loss improved from 1.38294 to 1.38219, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3722 - mean_absolute_error: 0.8110 - mean_squared_error: 1.3722 - val_loss: 1.3822 - val_mean_absolute_error: 0.8139 - val_mean_squared_error: 1.3822\n",
            "Epoch 694/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.3699 - mean_absolute_error: 0.8065 - mean_squared_error: 1.3699\n",
            "Epoch 694: val_loss did not improve from 1.38219\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3711 - mean_absolute_error: 0.8073 - mean_squared_error: 1.3711 - val_loss: 1.3870 - val_mean_absolute_error: 0.8222 - val_mean_squared_error: 1.3870\n",
            "Epoch 695/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.3734 - mean_absolute_error: 0.8073 - mean_squared_error: 1.3734\n",
            "Epoch 695: val_loss did not improve from 1.38219\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3676 - mean_absolute_error: 0.8055 - mean_squared_error: 1.3676 - val_loss: 1.3851 - val_mean_absolute_error: 0.8232 - val_mean_squared_error: 1.3851\n",
            "Epoch 696/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.3792 - mean_absolute_error: 0.8109 - mean_squared_error: 1.3792\n",
            "Epoch 696: val_loss did not improve from 1.38219\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3700 - mean_absolute_error: 0.8110 - mean_squared_error: 1.3700 - val_loss: 1.4116 - val_mean_absolute_error: 0.8445 - val_mean_squared_error: 1.4116\n",
            "Epoch 697/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.3632 - mean_absolute_error: 0.8093 - mean_squared_error: 1.3632\n",
            "Epoch 697: val_loss did not improve from 1.38219\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3662 - mean_absolute_error: 0.8104 - mean_squared_error: 1.3662 - val_loss: 1.4225 - val_mean_absolute_error: 0.8492 - val_mean_squared_error: 1.4225\n",
            "Epoch 698/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.3560 - mean_absolute_error: 0.8084 - mean_squared_error: 1.3560\n",
            "Epoch 698: val_loss improved from 1.38219 to 1.37701, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3625 - mean_absolute_error: 0.8099 - mean_squared_error: 1.3625 - val_loss: 1.3770 - val_mean_absolute_error: 0.8109 - val_mean_squared_error: 1.3770\n",
            "Epoch 699/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.3656 - mean_absolute_error: 0.8056 - mean_squared_error: 1.3656\n",
            "Epoch 699: val_loss did not improve from 1.37701\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3658 - mean_absolute_error: 0.8058 - mean_squared_error: 1.3658 - val_loss: 1.3798 - val_mean_absolute_error: 0.8164 - val_mean_squared_error: 1.3798\n",
            "Epoch 700/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.3644 - mean_absolute_error: 0.8072 - mean_squared_error: 1.3644\n",
            "Epoch 700: val_loss did not improve from 1.37701\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3644 - mean_absolute_error: 0.8072 - mean_squared_error: 1.3644 - val_loss: 1.3872 - val_mean_absolute_error: 0.8252 - val_mean_squared_error: 1.3872\n",
            "Epoch 701/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.3569 - mean_absolute_error: 0.8062 - mean_squared_error: 1.3569\n",
            "Epoch 701: val_loss did not improve from 1.37701\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3588 - mean_absolute_error: 0.8073 - mean_squared_error: 1.3588 - val_loss: 1.3771 - val_mean_absolute_error: 0.8198 - val_mean_squared_error: 1.3771\n",
            "Epoch 702/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.3636 - mean_absolute_error: 0.8073 - mean_squared_error: 1.3636\n",
            "Epoch 702: val_loss did not improve from 1.37701\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3636 - mean_absolute_error: 0.8073 - mean_squared_error: 1.3636 - val_loss: 1.3792 - val_mean_absolute_error: 0.8167 - val_mean_squared_error: 1.3792\n",
            "Epoch 703/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.3736 - mean_absolute_error: 0.8096 - mean_squared_error: 1.3736\n",
            "Epoch 703: val_loss improved from 1.37701 to 1.37320, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3600 - mean_absolute_error: 0.8070 - mean_squared_error: 1.3600 - val_loss: 1.3732 - val_mean_absolute_error: 0.8138 - val_mean_squared_error: 1.3732\n",
            "Epoch 704/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.3680 - mean_absolute_error: 0.8085 - mean_squared_error: 1.3680\n",
            "Epoch 704: val_loss did not improve from 1.37320\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3582 - mean_absolute_error: 0.8057 - mean_squared_error: 1.3582 - val_loss: 1.3887 - val_mean_absolute_error: 0.8290 - val_mean_squared_error: 1.3887\n",
            "Epoch 705/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.3788 - mean_absolute_error: 0.8098 - mean_squared_error: 1.3788\n",
            "Epoch 705: val_loss improved from 1.37320 to 1.37211, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3576 - mean_absolute_error: 0.8039 - mean_squared_error: 1.3576 - val_loss: 1.3721 - val_mean_absolute_error: 0.8172 - val_mean_squared_error: 1.3721\n",
            "Epoch 706/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.3616 - mean_absolute_error: 0.8080 - mean_squared_error: 1.3616\n",
            "Epoch 706: val_loss did not improve from 1.37211\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3595 - mean_absolute_error: 0.8070 - mean_squared_error: 1.3595 - val_loss: 1.3738 - val_mean_absolute_error: 0.8191 - val_mean_squared_error: 1.3738\n",
            "Epoch 707/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.3543 - mean_absolute_error: 0.8066 - mean_squared_error: 1.3543\n",
            "Epoch 707: val_loss improved from 1.37211 to 1.37119, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3545 - mean_absolute_error: 0.8068 - mean_squared_error: 1.3545 - val_loss: 1.3712 - val_mean_absolute_error: 0.8093 - val_mean_squared_error: 1.3712\n",
            "Epoch 708/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.3627 - mean_absolute_error: 0.8063 - mean_squared_error: 1.3627\n",
            "Epoch 708: val_loss improved from 1.37119 to 1.36687, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3558 - mean_absolute_error: 0.8047 - mean_squared_error: 1.3558 - val_loss: 1.3669 - val_mean_absolute_error: 0.8132 - val_mean_squared_error: 1.3669\n",
            "Epoch 709/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.3599 - mean_absolute_error: 0.8039 - mean_squared_error: 1.3599\n",
            "Epoch 709: val_loss did not improve from 1.36687\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3509 - mean_absolute_error: 0.8028 - mean_squared_error: 1.3509 - val_loss: 1.3712 - val_mean_absolute_error: 0.8151 - val_mean_squared_error: 1.3712\n",
            "Epoch 710/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.3600 - mean_absolute_error: 0.8078 - mean_squared_error: 1.3600\n",
            "Epoch 710: val_loss did not improve from 1.36687\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3576 - mean_absolute_error: 0.8076 - mean_squared_error: 1.3576 - val_loss: 1.3719 - val_mean_absolute_error: 0.8202 - val_mean_squared_error: 1.3719\n",
            "Epoch 711/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.3536 - mean_absolute_error: 0.8068 - mean_squared_error: 1.3536\n",
            "Epoch 711: val_loss improved from 1.36687 to 1.36205, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3482 - mean_absolute_error: 0.8053 - mean_squared_error: 1.3482 - val_loss: 1.3621 - val_mean_absolute_error: 0.8073 - val_mean_squared_error: 1.3621\n",
            "Epoch 712/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.3438 - mean_absolute_error: 0.8032 - mean_squared_error: 1.3438\n",
            "Epoch 712: val_loss did not improve from 1.36205\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3533 - mean_absolute_error: 0.8061 - mean_squared_error: 1.3533 - val_loss: 1.3624 - val_mean_absolute_error: 0.8108 - val_mean_squared_error: 1.3624\n",
            "Epoch 713/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.3496 - mean_absolute_error: 0.8031 - mean_squared_error: 1.3496\n",
            "Epoch 713: val_loss improved from 1.36205 to 1.35899, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3545 - mean_absolute_error: 0.8051 - mean_squared_error: 1.3545 - val_loss: 1.3590 - val_mean_absolute_error: 0.8073 - val_mean_squared_error: 1.3590\n",
            "Epoch 714/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.3558 - mean_absolute_error: 0.8062 - mean_squared_error: 1.3558\n",
            "Epoch 714: val_loss did not improve from 1.35899\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3475 - mean_absolute_error: 0.8043 - mean_squared_error: 1.3475 - val_loss: 1.3913 - val_mean_absolute_error: 0.8378 - val_mean_squared_error: 1.3913\n",
            "Epoch 715/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.3451 - mean_absolute_error: 0.8045 - mean_squared_error: 1.3451\n",
            "Epoch 715: val_loss did not improve from 1.35899\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3472 - mean_absolute_error: 0.8040 - mean_squared_error: 1.3472 - val_loss: 1.3595 - val_mean_absolute_error: 0.8079 - val_mean_squared_error: 1.3595\n",
            "Epoch 716/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.3452 - mean_absolute_error: 0.8026 - mean_squared_error: 1.3452\n",
            "Epoch 716: val_loss did not improve from 1.35899\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3454 - mean_absolute_error: 0.8017 - mean_squared_error: 1.3454 - val_loss: 1.3664 - val_mean_absolute_error: 0.8168 - val_mean_squared_error: 1.3664\n",
            "Epoch 717/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.3327 - mean_absolute_error: 0.8014 - mean_squared_error: 1.3327\n",
            "Epoch 717: val_loss improved from 1.35899 to 1.35855, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3444 - mean_absolute_error: 0.8029 - mean_squared_error: 1.3444 - val_loss: 1.3585 - val_mean_absolute_error: 0.8145 - val_mean_squared_error: 1.3585\n",
            "Epoch 718/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.3378 - mean_absolute_error: 0.8013 - mean_squared_error: 1.3378\n",
            "Epoch 718: val_loss did not improve from 1.35855\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3442 - mean_absolute_error: 0.8028 - mean_squared_error: 1.3442 - val_loss: 1.3597 - val_mean_absolute_error: 0.8148 - val_mean_squared_error: 1.3597\n",
            "Epoch 719/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.3291 - mean_absolute_error: 0.7998 - mean_squared_error: 1.3291\n",
            "Epoch 719: val_loss did not improve from 1.35855\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3475 - mean_absolute_error: 0.8046 - mean_squared_error: 1.3475 - val_loss: 1.3729 - val_mean_absolute_error: 0.8257 - val_mean_squared_error: 1.3729\n",
            "Epoch 720/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.3405 - mean_absolute_error: 0.8026 - mean_squared_error: 1.3405\n",
            "Epoch 720: val_loss improved from 1.35855 to 1.35405, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3441 - mean_absolute_error: 0.8033 - mean_squared_error: 1.3441 - val_loss: 1.3540 - val_mean_absolute_error: 0.8104 - val_mean_squared_error: 1.3540\n",
            "Epoch 721/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.3330 - mean_absolute_error: 0.7966 - mean_squared_error: 1.3330\n",
            "Epoch 721: val_loss improved from 1.35405 to 1.35385, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3410 - mean_absolute_error: 0.7998 - mean_squared_error: 1.3410 - val_loss: 1.3539 - val_mean_absolute_error: 0.8129 - val_mean_squared_error: 1.3539\n",
            "Epoch 722/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.3332 - mean_absolute_error: 0.8012 - mean_squared_error: 1.3332\n",
            "Epoch 722: val_loss improved from 1.35385 to 1.35141, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3436 - mean_absolute_error: 0.8031 - mean_squared_error: 1.3436 - val_loss: 1.3514 - val_mean_absolute_error: 0.8090 - val_mean_squared_error: 1.3514\n",
            "Epoch 723/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.3406 - mean_absolute_error: 0.8001 - mean_squared_error: 1.3406\n",
            "Epoch 723: val_loss did not improve from 1.35141\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3420 - mean_absolute_error: 0.8011 - mean_squared_error: 1.3420 - val_loss: 1.3607 - val_mean_absolute_error: 0.8212 - val_mean_squared_error: 1.3607\n",
            "Epoch 724/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.3382 - mean_absolute_error: 0.8015 - mean_squared_error: 1.3382\n",
            "Epoch 724: val_loss did not improve from 1.35141\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3374 - mean_absolute_error: 0.8007 - mean_squared_error: 1.3374 - val_loss: 1.3530 - val_mean_absolute_error: 0.8114 - val_mean_squared_error: 1.3530\n",
            "Epoch 725/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.3358 - mean_absolute_error: 0.8005 - mean_squared_error: 1.3358\n",
            "Epoch 725: val_loss improved from 1.35141 to 1.35083, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3359 - mean_absolute_error: 0.8002 - mean_squared_error: 1.3359 - val_loss: 1.3508 - val_mean_absolute_error: 0.8110 - val_mean_squared_error: 1.3508\n",
            "Epoch 726/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.3259 - mean_absolute_error: 0.8009 - mean_squared_error: 1.3259\n",
            "Epoch 726: val_loss did not improve from 1.35083\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3354 - mean_absolute_error: 0.8024 - mean_squared_error: 1.3354 - val_loss: 1.3578 - val_mean_absolute_error: 0.8188 - val_mean_squared_error: 1.3578\n",
            "Epoch 727/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.3475 - mean_absolute_error: 0.8047 - mean_squared_error: 1.3475\n",
            "Epoch 727: val_loss improved from 1.35083 to 1.34542, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3401 - mean_absolute_error: 0.8014 - mean_squared_error: 1.3401 - val_loss: 1.3454 - val_mean_absolute_error: 0.8088 - val_mean_squared_error: 1.3454\n",
            "Epoch 728/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.3321 - mean_absolute_error: 0.7992 - mean_squared_error: 1.3321\n",
            "Epoch 728: val_loss did not improve from 1.34542\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3315 - mean_absolute_error: 0.7990 - mean_squared_error: 1.3315 - val_loss: 1.3478 - val_mean_absolute_error: 0.8151 - val_mean_squared_error: 1.3478\n",
            "Epoch 729/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.3494 - mean_absolute_error: 0.8065 - mean_squared_error: 1.3494\n",
            "Epoch 729: val_loss improved from 1.34542 to 1.34510, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3339 - mean_absolute_error: 0.8012 - mean_squared_error: 1.3339 - val_loss: 1.3451 - val_mean_absolute_error: 0.8031 - val_mean_squared_error: 1.3451\n",
            "Epoch 730/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.3413 - mean_absolute_error: 0.8031 - mean_squared_error: 1.3413\n",
            "Epoch 730: val_loss did not improve from 1.34510\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3336 - mean_absolute_error: 0.8009 - mean_squared_error: 1.3336 - val_loss: 1.4319 - val_mean_absolute_error: 0.8729 - val_mean_squared_error: 1.4319\n",
            "Epoch 731/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.3448 - mean_absolute_error: 0.8048 - mean_squared_error: 1.3448\n",
            "Epoch 731: val_loss did not improve from 1.34510\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3322 - mean_absolute_error: 0.8011 - mean_squared_error: 1.3322 - val_loss: 1.3497 - val_mean_absolute_error: 0.8163 - val_mean_squared_error: 1.3497\n",
            "Epoch 732/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.3229 - mean_absolute_error: 0.7970 - mean_squared_error: 1.3229\n",
            "Epoch 732: val_loss did not improve from 1.34510\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3302 - mean_absolute_error: 0.7992 - mean_squared_error: 1.3302 - val_loss: 1.3478 - val_mean_absolute_error: 0.8135 - val_mean_squared_error: 1.3478\n",
            "Epoch 733/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.3365 - mean_absolute_error: 0.8008 - mean_squared_error: 1.3365\n",
            "Epoch 733: val_loss did not improve from 1.34510\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3283 - mean_absolute_error: 0.7984 - mean_squared_error: 1.3283 - val_loss: 1.3452 - val_mean_absolute_error: 0.8111 - val_mean_squared_error: 1.3452\n",
            "Epoch 734/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.3246 - mean_absolute_error: 0.7983 - mean_squared_error: 1.3246\n",
            "Epoch 734: val_loss improved from 1.34510 to 1.33884, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3247 - mean_absolute_error: 0.7982 - mean_squared_error: 1.3247 - val_loss: 1.3388 - val_mean_absolute_error: 0.8072 - val_mean_squared_error: 1.3388\n",
            "Epoch 735/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.3140 - mean_absolute_error: 0.7959 - mean_squared_error: 1.3140\n",
            "Epoch 735: val_loss did not improve from 1.33884\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3246 - mean_absolute_error: 0.7984 - mean_squared_error: 1.3246 - val_loss: 1.3451 - val_mean_absolute_error: 0.8066 - val_mean_squared_error: 1.3451\n",
            "Epoch 736/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.3338 - mean_absolute_error: 0.8025 - mean_squared_error: 1.3338\n",
            "Epoch 736: val_loss did not improve from 1.33884\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3252 - mean_absolute_error: 0.8006 - mean_squared_error: 1.3252 - val_loss: 1.3463 - val_mean_absolute_error: 0.8185 - val_mean_squared_error: 1.3463\n",
            "Epoch 737/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.3209 - mean_absolute_error: 0.7958 - mean_squared_error: 1.3209\n",
            "Epoch 737: val_loss improved from 1.33884 to 1.33409, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3229 - mean_absolute_error: 0.7969 - mean_squared_error: 1.3229 - val_loss: 1.3341 - val_mean_absolute_error: 0.8065 - val_mean_squared_error: 1.3341\n",
            "Epoch 738/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.3229 - mean_absolute_error: 0.7983 - mean_squared_error: 1.3229\n",
            "Epoch 738: val_loss did not improve from 1.33409\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3229 - mean_absolute_error: 0.7983 - mean_squared_error: 1.3229 - val_loss: 1.3661 - val_mean_absolute_error: 0.8320 - val_mean_squared_error: 1.3661\n",
            "Epoch 739/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.3198 - mean_absolute_error: 0.7959 - mean_squared_error: 1.3198\n",
            "Epoch 739: val_loss improved from 1.33409 to 1.33092, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3219 - mean_absolute_error: 0.7962 - mean_squared_error: 1.3219 - val_loss: 1.3309 - val_mean_absolute_error: 0.8062 - val_mean_squared_error: 1.3309\n",
            "Epoch 740/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.3231 - mean_absolute_error: 0.8002 - mean_squared_error: 1.3231\n",
            "Epoch 740: val_loss improved from 1.33092 to 1.32970, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3231 - mean_absolute_error: 0.7997 - mean_squared_error: 1.3231 - val_loss: 1.3297 - val_mean_absolute_error: 0.8038 - val_mean_squared_error: 1.3297\n",
            "Epoch 741/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.3072 - mean_absolute_error: 0.7929 - mean_squared_error: 1.3072\n",
            "Epoch 741: val_loss improved from 1.32970 to 1.32958, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.3183 - mean_absolute_error: 0.7948 - mean_squared_error: 1.3183 - val_loss: 1.3296 - val_mean_absolute_error: 0.8075 - val_mean_squared_error: 1.3296\n",
            "Epoch 742/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.3292 - mean_absolute_error: 0.8023 - mean_squared_error: 1.3292\n",
            "Epoch 742: val_loss did not improve from 1.32958\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3199 - mean_absolute_error: 0.7998 - mean_squared_error: 1.3199 - val_loss: 1.3415 - val_mean_absolute_error: 0.8157 - val_mean_squared_error: 1.3415\n",
            "Epoch 743/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.2948 - mean_absolute_error: 0.7896 - mean_squared_error: 1.2948\n",
            "Epoch 743: val_loss did not improve from 1.32958\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3195 - mean_absolute_error: 0.7981 - mean_squared_error: 1.3195 - val_loss: 1.3325 - val_mean_absolute_error: 0.8165 - val_mean_squared_error: 1.3325\n",
            "Epoch 744/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.3154 - mean_absolute_error: 0.7961 - mean_squared_error: 1.3154\n",
            "Epoch 744: val_loss did not improve from 1.32958\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3131 - mean_absolute_error: 0.7957 - mean_squared_error: 1.3131 - val_loss: 1.3395 - val_mean_absolute_error: 0.8161 - val_mean_squared_error: 1.3395\n",
            "Epoch 745/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.3205 - mean_absolute_error: 0.7972 - mean_squared_error: 1.3205\n",
            "Epoch 745: val_loss improved from 1.32958 to 1.32511, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3155 - mean_absolute_error: 0.7960 - mean_squared_error: 1.3155 - val_loss: 1.3251 - val_mean_absolute_error: 0.8074 - val_mean_squared_error: 1.3251\n",
            "Epoch 746/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.3172 - mean_absolute_error: 0.7965 - mean_squared_error: 1.3172\n",
            "Epoch 746: val_loss did not improve from 1.32511\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3145 - mean_absolute_error: 0.7951 - mean_squared_error: 1.3145 - val_loss: 1.3320 - val_mean_absolute_error: 0.8123 - val_mean_squared_error: 1.3320\n",
            "Epoch 747/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.3126 - mean_absolute_error: 0.7991 - mean_squared_error: 1.3126\n",
            "Epoch 747: val_loss improved from 1.32511 to 1.31886, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3103 - mean_absolute_error: 0.7980 - mean_squared_error: 1.3103 - val_loss: 1.3189 - val_mean_absolute_error: 0.8002 - val_mean_squared_error: 1.3189\n",
            "Epoch 748/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.3147 - mean_absolute_error: 0.7952 - mean_squared_error: 1.3147\n",
            "Epoch 748: val_loss did not improve from 1.31886\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.3121 - mean_absolute_error: 0.7945 - mean_squared_error: 1.3121 - val_loss: 1.3211 - val_mean_absolute_error: 0.8050 - val_mean_squared_error: 1.3211\n",
            "Epoch 749/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.3246 - mean_absolute_error: 0.7988 - mean_squared_error: 1.3246\n",
            "Epoch 749: val_loss improved from 1.31886 to 1.31750, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3060 - mean_absolute_error: 0.7955 - mean_squared_error: 1.3060 - val_loss: 1.3175 - val_mean_absolute_error: 0.8022 - val_mean_squared_error: 1.3175\n",
            "Epoch 750/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.3061 - mean_absolute_error: 0.7922 - mean_squared_error: 1.3061\n",
            "Epoch 750: val_loss did not improve from 1.31750\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3055 - mean_absolute_error: 0.7922 - mean_squared_error: 1.3055 - val_loss: 1.3176 - val_mean_absolute_error: 0.8056 - val_mean_squared_error: 1.3176\n",
            "Epoch 751/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.3032 - mean_absolute_error: 0.7931 - mean_squared_error: 1.3032\n",
            "Epoch 751: val_loss did not improve from 1.31750\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3072 - mean_absolute_error: 0.7934 - mean_squared_error: 1.3072 - val_loss: 1.3319 - val_mean_absolute_error: 0.8115 - val_mean_squared_error: 1.3319\n",
            "Epoch 752/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.3125 - mean_absolute_error: 0.7977 - mean_squared_error: 1.3125\n",
            "Epoch 752: val_loss did not improve from 1.31750\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3061 - mean_absolute_error: 0.7959 - mean_squared_error: 1.3061 - val_loss: 1.3307 - val_mean_absolute_error: 0.8144 - val_mean_squared_error: 1.3307\n",
            "Epoch 753/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.3118 - mean_absolute_error: 0.7957 - mean_squared_error: 1.3118\n",
            "Epoch 753: val_loss did not improve from 1.31750\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3066 - mean_absolute_error: 0.7940 - mean_squared_error: 1.3066 - val_loss: 1.3214 - val_mean_absolute_error: 0.8072 - val_mean_squared_error: 1.3214\n",
            "Epoch 754/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.3062 - mean_absolute_error: 0.7940 - mean_squared_error: 1.3062\n",
            "Epoch 754: val_loss improved from 1.31750 to 1.31537, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3012 - mean_absolute_error: 0.7930 - mean_squared_error: 1.3012 - val_loss: 1.3154 - val_mean_absolute_error: 0.8063 - val_mean_squared_error: 1.3154\n",
            "Epoch 755/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.2985 - mean_absolute_error: 0.7906 - mean_squared_error: 1.2985\n",
            "Epoch 755: val_loss improved from 1.31537 to 1.31262, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2998 - mean_absolute_error: 0.7916 - mean_squared_error: 1.2998 - val_loss: 1.3126 - val_mean_absolute_error: 0.8054 - val_mean_squared_error: 1.3126\n",
            "Epoch 756/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.2980 - mean_absolute_error: 0.7889 - mean_squared_error: 1.2980\n",
            "Epoch 756: val_loss did not improve from 1.31262\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3002 - mean_absolute_error: 0.7904 - mean_squared_error: 1.3002 - val_loss: 1.3200 - val_mean_absolute_error: 0.8133 - val_mean_squared_error: 1.3200\n",
            "Epoch 757/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.2942 - mean_absolute_error: 0.7917 - mean_squared_error: 1.2942\n",
            "Epoch 757: val_loss improved from 1.31262 to 1.30485, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2959 - mean_absolute_error: 0.7932 - mean_squared_error: 1.2959 - val_loss: 1.3049 - val_mean_absolute_error: 0.7953 - val_mean_squared_error: 1.3049\n",
            "Epoch 758/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.2910 - mean_absolute_error: 0.7852 - mean_squared_error: 1.2910\n",
            "Epoch 758: val_loss did not improve from 1.30485\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2973 - mean_absolute_error: 0.7877 - mean_squared_error: 1.2973 - val_loss: 1.3125 - val_mean_absolute_error: 0.8095 - val_mean_squared_error: 1.3125\n",
            "Epoch 759/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.3037 - mean_absolute_error: 0.7941 - mean_squared_error: 1.3037\n",
            "Epoch 759: val_loss did not improve from 1.30485\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2979 - mean_absolute_error: 0.7930 - mean_squared_error: 1.2979 - val_loss: 1.3052 - val_mean_absolute_error: 0.7965 - val_mean_squared_error: 1.3052\n",
            "Epoch 760/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.2972 - mean_absolute_error: 0.7929 - mean_squared_error: 1.2972\n",
            "Epoch 760: val_loss improved from 1.30485 to 1.30373, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2971 - mean_absolute_error: 0.7921 - mean_squared_error: 1.2971 - val_loss: 1.3037 - val_mean_absolute_error: 0.7963 - val_mean_squared_error: 1.3037\n",
            "Epoch 761/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.2932 - mean_absolute_error: 0.7901 - mean_squared_error: 1.2932\n",
            "Epoch 761: val_loss did not improve from 1.30373\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2932 - mean_absolute_error: 0.7901 - mean_squared_error: 1.2932 - val_loss: 1.3263 - val_mean_absolute_error: 0.8160 - val_mean_squared_error: 1.3263\n",
            "Epoch 762/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.2947 - mean_absolute_error: 0.7918 - mean_squared_error: 1.2947\n",
            "Epoch 762: val_loss improved from 1.30373 to 1.30245, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2911 - mean_absolute_error: 0.7905 - mean_squared_error: 1.2911 - val_loss: 1.3025 - val_mean_absolute_error: 0.7985 - val_mean_squared_error: 1.3025\n",
            "Epoch 763/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.2843 - mean_absolute_error: 0.7855 - mean_squared_error: 1.2843\n",
            "Epoch 763: val_loss did not improve from 1.30245\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2876 - mean_absolute_error: 0.7868 - mean_squared_error: 1.2876 - val_loss: 1.3069 - val_mean_absolute_error: 0.8043 - val_mean_squared_error: 1.3069\n",
            "Epoch 764/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.2899 - mean_absolute_error: 0.7888 - mean_squared_error: 1.2899\n",
            "Epoch 764: val_loss improved from 1.30245 to 1.29856, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2892 - mean_absolute_error: 0.7898 - mean_squared_error: 1.2892 - val_loss: 1.2986 - val_mean_absolute_error: 0.8014 - val_mean_squared_error: 1.2986\n",
            "Epoch 765/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.2891 - mean_absolute_error: 0.7899 - mean_squared_error: 1.2891\n",
            "Epoch 765: val_loss did not improve from 1.29856\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2916 - mean_absolute_error: 0.7912 - mean_squared_error: 1.2916 - val_loss: 1.3090 - val_mean_absolute_error: 0.7998 - val_mean_squared_error: 1.3090\n",
            "Epoch 766/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.3011 - mean_absolute_error: 0.7892 - mean_squared_error: 1.3011\n",
            "Epoch 766: val_loss improved from 1.29856 to 1.29651, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2899 - mean_absolute_error: 0.7879 - mean_squared_error: 1.2899 - val_loss: 1.2965 - val_mean_absolute_error: 0.7981 - val_mean_squared_error: 1.2965\n",
            "Epoch 767/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.2726 - mean_absolute_error: 0.7847 - mean_squared_error: 1.2726\n",
            "Epoch 767: val_loss did not improve from 1.29651\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2814 - mean_absolute_error: 0.7881 - mean_squared_error: 1.2814 - val_loss: 1.3108 - val_mean_absolute_error: 0.8099 - val_mean_squared_error: 1.3108\n",
            "Epoch 768/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.2900 - mean_absolute_error: 0.7902 - mean_squared_error: 1.2900\n",
            "Epoch 768: val_loss did not improve from 1.29651\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2900 - mean_absolute_error: 0.7891 - mean_squared_error: 1.2900 - val_loss: 1.3264 - val_mean_absolute_error: 0.8217 - val_mean_squared_error: 1.3264\n",
            "Epoch 769/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.2852 - mean_absolute_error: 0.7910 - mean_squared_error: 1.2852\n",
            "Epoch 769: val_loss improved from 1.29651 to 1.28983, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2858 - mean_absolute_error: 0.7913 - mean_squared_error: 1.2858 - val_loss: 1.2898 - val_mean_absolute_error: 0.7978 - val_mean_squared_error: 1.2898\n",
            "Epoch 770/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.2761 - mean_absolute_error: 0.7880 - mean_squared_error: 1.2761\n",
            "Epoch 770: val_loss improved from 1.28983 to 1.28675, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2838 - mean_absolute_error: 0.7895 - mean_squared_error: 1.2838 - val_loss: 1.2868 - val_mean_absolute_error: 0.7931 - val_mean_squared_error: 1.2868\n",
            "Epoch 771/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.2799 - mean_absolute_error: 0.7918 - mean_squared_error: 1.2799\n",
            "Epoch 771: val_loss did not improve from 1.28675\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2746 - mean_absolute_error: 0.7893 - mean_squared_error: 1.2746 - val_loss: 1.2994 - val_mean_absolute_error: 0.8057 - val_mean_squared_error: 1.2994\n",
            "Epoch 772/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.2828 - mean_absolute_error: 0.7881 - mean_squared_error: 1.2828\n",
            "Epoch 772: val_loss did not improve from 1.28675\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2789 - mean_absolute_error: 0.7867 - mean_squared_error: 1.2789 - val_loss: 1.3136 - val_mean_absolute_error: 0.8140 - val_mean_squared_error: 1.3136\n",
            "Epoch 773/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.2617 - mean_absolute_error: 0.7847 - mean_squared_error: 1.2617\n",
            "Epoch 773: val_loss did not improve from 1.28675\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2827 - mean_absolute_error: 0.7910 - mean_squared_error: 1.2827 - val_loss: 1.2971 - val_mean_absolute_error: 0.8021 - val_mean_squared_error: 1.2971\n",
            "Epoch 774/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.2795 - mean_absolute_error: 0.7896 - mean_squared_error: 1.2795\n",
            "Epoch 774: val_loss did not improve from 1.28675\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2766 - mean_absolute_error: 0.7879 - mean_squared_error: 1.2766 - val_loss: 1.2974 - val_mean_absolute_error: 0.7991 - val_mean_squared_error: 1.2974\n",
            "Epoch 775/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.2693 - mean_absolute_error: 0.7835 - mean_squared_error: 1.2693\n",
            "Epoch 775: val_loss improved from 1.28675 to 1.28148, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2730 - mean_absolute_error: 0.7847 - mean_squared_error: 1.2730 - val_loss: 1.2815 - val_mean_absolute_error: 0.7959 - val_mean_squared_error: 1.2815\n",
            "Epoch 776/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.2688 - mean_absolute_error: 0.7848 - mean_squared_error: 1.2688\n",
            "Epoch 776: val_loss did not improve from 1.28148\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2709 - mean_absolute_error: 0.7858 - mean_squared_error: 1.2709 - val_loss: 1.3224 - val_mean_absolute_error: 0.8209 - val_mean_squared_error: 1.3224\n",
            "Epoch 777/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.2747 - mean_absolute_error: 0.7850 - mean_squared_error: 1.2747\n",
            "Epoch 777: val_loss did not improve from 1.28148\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2730 - mean_absolute_error: 0.7857 - mean_squared_error: 1.2730 - val_loss: 1.2854 - val_mean_absolute_error: 0.7992 - val_mean_squared_error: 1.2854\n",
            "Epoch 778/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.2693 - mean_absolute_error: 0.7825 - mean_squared_error: 1.2693\n",
            "Epoch 778: val_loss improved from 1.28148 to 1.27901, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2688 - mean_absolute_error: 0.7823 - mean_squared_error: 1.2688 - val_loss: 1.2790 - val_mean_absolute_error: 0.7968 - val_mean_squared_error: 1.2790\n",
            "Epoch 779/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.2659 - mean_absolute_error: 0.7831 - mean_squared_error: 1.2659\n",
            "Epoch 779: val_loss improved from 1.27901 to 1.27394, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2636 - mean_absolute_error: 0.7826 - mean_squared_error: 1.2636 - val_loss: 1.2739 - val_mean_absolute_error: 0.7887 - val_mean_squared_error: 1.2739\n",
            "Epoch 780/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.2669 - mean_absolute_error: 0.7818 - mean_squared_error: 1.2669\n",
            "Epoch 780: val_loss did not improve from 1.27394\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2701 - mean_absolute_error: 0.7834 - mean_squared_error: 1.2701 - val_loss: 1.3137 - val_mean_absolute_error: 0.8176 - val_mean_squared_error: 1.3137\n",
            "Epoch 781/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.2745 - mean_absolute_error: 0.7879 - mean_squared_error: 1.2745\n",
            "Epoch 781: val_loss did not improve from 1.27394\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2722 - mean_absolute_error: 0.7854 - mean_squared_error: 1.2722 - val_loss: 1.2901 - val_mean_absolute_error: 0.8039 - val_mean_squared_error: 1.2901\n",
            "Epoch 782/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.2781 - mean_absolute_error: 0.7847 - mean_squared_error: 1.2781\n",
            "Epoch 782: val_loss did not improve from 1.27394\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2637 - mean_absolute_error: 0.7816 - mean_squared_error: 1.2637 - val_loss: 1.2753 - val_mean_absolute_error: 0.7947 - val_mean_squared_error: 1.2753\n",
            "Epoch 783/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.2698 - mean_absolute_error: 0.7839 - mean_squared_error: 1.2698\n",
            "Epoch 783: val_loss improved from 1.27394 to 1.26855, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2670 - mean_absolute_error: 0.7831 - mean_squared_error: 1.2670 - val_loss: 1.2686 - val_mean_absolute_error: 0.7899 - val_mean_squared_error: 1.2686\n",
            "Epoch 784/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.2666 - mean_absolute_error: 0.7853 - mean_squared_error: 1.2666\n",
            "Epoch 784: val_loss did not improve from 1.26855\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2622 - mean_absolute_error: 0.7827 - mean_squared_error: 1.2622 - val_loss: 1.2742 - val_mean_absolute_error: 0.7986 - val_mean_squared_error: 1.2742\n",
            "Epoch 785/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.2556 - mean_absolute_error: 0.7814 - mean_squared_error: 1.2556\n",
            "Epoch 785: val_loss improved from 1.26855 to 1.26486, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2590 - mean_absolute_error: 0.7820 - mean_squared_error: 1.2590 - val_loss: 1.2649 - val_mean_absolute_error: 0.7885 - val_mean_squared_error: 1.2649\n",
            "Epoch 786/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.2500 - mean_absolute_error: 0.7781 - mean_squared_error: 1.2500\n",
            "Epoch 786: val_loss did not improve from 1.26486\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2556 - mean_absolute_error: 0.7790 - mean_squared_error: 1.2556 - val_loss: 1.3014 - val_mean_absolute_error: 0.8133 - val_mean_squared_error: 1.3014\n",
            "Epoch 787/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.2475 - mean_absolute_error: 0.7778 - mean_squared_error: 1.2475\n",
            "Epoch 787: val_loss improved from 1.26486 to 1.26217, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2585 - mean_absolute_error: 0.7815 - mean_squared_error: 1.2585 - val_loss: 1.2622 - val_mean_absolute_error: 0.7856 - val_mean_squared_error: 1.2622\n",
            "Epoch 788/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.2363 - mean_absolute_error: 0.7743 - mean_squared_error: 1.2363\n",
            "Epoch 788: val_loss did not improve from 1.26217\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2543 - mean_absolute_error: 0.7775 - mean_squared_error: 1.2543 - val_loss: 1.2622 - val_mean_absolute_error: 0.7902 - val_mean_squared_error: 1.2622\n",
            "Epoch 789/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.2567 - mean_absolute_error: 0.7800 - mean_squared_error: 1.2567\n",
            "Epoch 789: val_loss improved from 1.26217 to 1.26110, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2533 - mean_absolute_error: 0.7787 - mean_squared_error: 1.2533 - val_loss: 1.2611 - val_mean_absolute_error: 0.7901 - val_mean_squared_error: 1.2611\n",
            "Epoch 790/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.2542 - mean_absolute_error: 0.7791 - mean_squared_error: 1.2542\n",
            "Epoch 790: val_loss did not improve from 1.26110\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2542 - mean_absolute_error: 0.7791 - mean_squared_error: 1.2542 - val_loss: 1.2635 - val_mean_absolute_error: 0.7971 - val_mean_squared_error: 1.2635\n",
            "Epoch 791/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.2441 - mean_absolute_error: 0.7768 - mean_squared_error: 1.2441\n",
            "Epoch 791: val_loss did not improve from 1.26110\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2520 - mean_absolute_error: 0.7790 - mean_squared_error: 1.2520 - val_loss: 1.2620 - val_mean_absolute_error: 0.7956 - val_mean_squared_error: 1.2620\n",
            "Epoch 792/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.2387 - mean_absolute_error: 0.7742 - mean_squared_error: 1.2387\n",
            "Epoch 792: val_loss did not improve from 1.26110\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2511 - mean_absolute_error: 0.7777 - mean_squared_error: 1.2511 - val_loss: 1.2662 - val_mean_absolute_error: 0.7947 - val_mean_squared_error: 1.2662\n",
            "Epoch 793/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.2467 - mean_absolute_error: 0.7753 - mean_squared_error: 1.2467\n",
            "Epoch 793: val_loss improved from 1.26110 to 1.25742, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2495 - mean_absolute_error: 0.7768 - mean_squared_error: 1.2495 - val_loss: 1.2574 - val_mean_absolute_error: 0.7871 - val_mean_squared_error: 1.2574\n",
            "Epoch 794/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.2611 - mean_absolute_error: 0.7813 - mean_squared_error: 1.2611\n",
            "Epoch 794: val_loss did not improve from 1.25742\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2471 - mean_absolute_error: 0.7776 - mean_squared_error: 1.2471 - val_loss: 1.2629 - val_mean_absolute_error: 0.7987 - val_mean_squared_error: 1.2629\n",
            "Epoch 795/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.2447 - mean_absolute_error: 0.7793 - mean_squared_error: 1.2447\n",
            "Epoch 795: val_loss improved from 1.25742 to 1.25700, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2474 - mean_absolute_error: 0.7794 - mean_squared_error: 1.2474 - val_loss: 1.2570 - val_mean_absolute_error: 0.7899 - val_mean_squared_error: 1.2570\n",
            "Epoch 796/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.2455 - mean_absolute_error: 0.7783 - mean_squared_error: 1.2455\n",
            "Epoch 796: val_loss improved from 1.25700 to 1.24878, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2456 - mean_absolute_error: 0.7775 - mean_squared_error: 1.2456 - val_loss: 1.2488 - val_mean_absolute_error: 0.7800 - val_mean_squared_error: 1.2488\n",
            "Epoch 797/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.2454 - mean_absolute_error: 0.7748 - mean_squared_error: 1.2454\n",
            "Epoch 797: val_loss did not improve from 1.24878\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2421 - mean_absolute_error: 0.7742 - mean_squared_error: 1.2421 - val_loss: 1.2562 - val_mean_absolute_error: 0.7924 - val_mean_squared_error: 1.2562\n",
            "Epoch 798/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.2385 - mean_absolute_error: 0.7751 - mean_squared_error: 1.2385\n",
            "Epoch 798: val_loss did not improve from 1.24878\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2434 - mean_absolute_error: 0.7758 - mean_squared_error: 1.2434 - val_loss: 1.2517 - val_mean_absolute_error: 0.7864 - val_mean_squared_error: 1.2517\n",
            "Epoch 799/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.2386 - mean_absolute_error: 0.7748 - mean_squared_error: 1.2386\n",
            "Epoch 799: val_loss did not improve from 1.24878\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2370 - mean_absolute_error: 0.7736 - mean_squared_error: 1.2370 - val_loss: 1.2524 - val_mean_absolute_error: 0.7869 - val_mean_squared_error: 1.2524\n",
            "Epoch 800/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.2287 - mean_absolute_error: 0.7707 - mean_squared_error: 1.2287\n",
            "Epoch 800: val_loss improved from 1.24878 to 1.24752, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2384 - mean_absolute_error: 0.7743 - mean_squared_error: 1.2384 - val_loss: 1.2475 - val_mean_absolute_error: 0.7881 - val_mean_squared_error: 1.2475\n",
            "Epoch 801/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.2490 - mean_absolute_error: 0.7812 - mean_squared_error: 1.2490\n",
            "Epoch 801: val_loss improved from 1.24752 to 1.24285, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.2472 - mean_absolute_error: 0.7800 - mean_squared_error: 1.2472 - val_loss: 1.2428 - val_mean_absolute_error: 0.7834 - val_mean_squared_error: 1.2428\n",
            "Epoch 802/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.2367 - mean_absolute_error: 0.7727 - mean_squared_error: 1.2367\n",
            "Epoch 802: val_loss did not improve from 1.24285\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.2359 - mean_absolute_error: 0.7720 - mean_squared_error: 1.2359 - val_loss: 1.2465 - val_mean_absolute_error: 0.7876 - val_mean_squared_error: 1.2465\n",
            "Epoch 803/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.2361 - mean_absolute_error: 0.7754 - mean_squared_error: 1.2361\n",
            "Epoch 803: val_loss did not improve from 1.24285\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.2355 - mean_absolute_error: 0.7750 - mean_squared_error: 1.2355 - val_loss: 1.2483 - val_mean_absolute_error: 0.7858 - val_mean_squared_error: 1.2483\n",
            "Epoch 804/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.2309 - mean_absolute_error: 0.7704 - mean_squared_error: 1.2309\n",
            "Epoch 804: val_loss improved from 1.24285 to 1.24018, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2333 - mean_absolute_error: 0.7717 - mean_squared_error: 1.2333 - val_loss: 1.2402 - val_mean_absolute_error: 0.7838 - val_mean_squared_error: 1.2402\n",
            "Epoch 805/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.2225 - mean_absolute_error: 0.7709 - mean_squared_error: 1.2225\n",
            "Epoch 805: val_loss improved from 1.24018 to 1.23755, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2331 - mean_absolute_error: 0.7719 - mean_squared_error: 1.2331 - val_loss: 1.2376 - val_mean_absolute_error: 0.7758 - val_mean_squared_error: 1.2376\n",
            "Epoch 806/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.2333 - mean_absolute_error: 0.7721 - mean_squared_error: 1.2333\n",
            "Epoch 806: val_loss did not improve from 1.23755\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2328 - mean_absolute_error: 0.7719 - mean_squared_error: 1.2328 - val_loss: 1.2383 - val_mean_absolute_error: 0.7863 - val_mean_squared_error: 1.2383\n",
            "Epoch 807/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.2290 - mean_absolute_error: 0.7723 - mean_squared_error: 1.2290\n",
            "Epoch 807: val_loss did not improve from 1.23755\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2290 - mean_absolute_error: 0.7723 - mean_squared_error: 1.2290 - val_loss: 1.2502 - val_mean_absolute_error: 0.7895 - val_mean_squared_error: 1.2502\n",
            "Epoch 808/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.2235 - mean_absolute_error: 0.7716 - mean_squared_error: 1.2235\n",
            "Epoch 808: val_loss improved from 1.23755 to 1.23215, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2252 - mean_absolute_error: 0.7719 - mean_squared_error: 1.2252 - val_loss: 1.2321 - val_mean_absolute_error: 0.7782 - val_mean_squared_error: 1.2321\n",
            "Epoch 809/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.2267 - mean_absolute_error: 0.7686 - mean_squared_error: 1.2267\n",
            "Epoch 809: val_loss did not improve from 1.23215\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2288 - mean_absolute_error: 0.7695 - mean_squared_error: 1.2288 - val_loss: 1.2370 - val_mean_absolute_error: 0.7843 - val_mean_squared_error: 1.2370\n",
            "Epoch 810/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.2116 - mean_absolute_error: 0.7649 - mean_squared_error: 1.2116\n",
            "Epoch 810: val_loss improved from 1.23215 to 1.22912, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2248 - mean_absolute_error: 0.7695 - mean_squared_error: 1.2248 - val_loss: 1.2291 - val_mean_absolute_error: 0.7740 - val_mean_squared_error: 1.2291\n",
            "Epoch 811/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.2156 - mean_absolute_error: 0.7644 - mean_squared_error: 1.2156\n",
            "Epoch 811: val_loss improved from 1.22912 to 1.22837, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2255 - mean_absolute_error: 0.7684 - mean_squared_error: 1.2255 - val_loss: 1.2284 - val_mean_absolute_error: 0.7785 - val_mean_squared_error: 1.2284\n",
            "Epoch 812/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.2307 - mean_absolute_error: 0.7711 - mean_squared_error: 1.2307\n",
            "Epoch 812: val_loss did not improve from 1.22837\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2246 - mean_absolute_error: 0.7688 - mean_squared_error: 1.2246 - val_loss: 1.2365 - val_mean_absolute_error: 0.7877 - val_mean_squared_error: 1.2365\n",
            "Epoch 813/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.2188 - mean_absolute_error: 0.7698 - mean_squared_error: 1.2188\n",
            "Epoch 813: val_loss improved from 1.22837 to 1.22733, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2249 - mean_absolute_error: 0.7713 - mean_squared_error: 1.2249 - val_loss: 1.2273 - val_mean_absolute_error: 0.7784 - val_mean_squared_error: 1.2273\n",
            "Epoch 814/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.2286 - mean_absolute_error: 0.7710 - mean_squared_error: 1.2286\n",
            "Epoch 814: val_loss improved from 1.22733 to 1.22653, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2234 - mean_absolute_error: 0.7692 - mean_squared_error: 1.2234 - val_loss: 1.2265 - val_mean_absolute_error: 0.7810 - val_mean_squared_error: 1.2265\n",
            "Epoch 815/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.2237 - mean_absolute_error: 0.7685 - mean_squared_error: 1.2237\n",
            "Epoch 815: val_loss did not improve from 1.22653\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2223 - mean_absolute_error: 0.7679 - mean_squared_error: 1.2223 - val_loss: 1.2332 - val_mean_absolute_error: 0.7904 - val_mean_squared_error: 1.2332\n",
            "Epoch 816/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.2173 - mean_absolute_error: 0.7666 - mean_squared_error: 1.2173\n",
            "Epoch 816: val_loss did not improve from 1.22653\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2173 - mean_absolute_error: 0.7666 - mean_squared_error: 1.2173 - val_loss: 1.2366 - val_mean_absolute_error: 0.7883 - val_mean_squared_error: 1.2366\n",
            "Epoch 817/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.2182 - mean_absolute_error: 0.7693 - mean_squared_error: 1.2182\n",
            "Epoch 817: val_loss did not improve from 1.22653\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2148 - mean_absolute_error: 0.7682 - mean_squared_error: 1.2148 - val_loss: 1.2358 - val_mean_absolute_error: 0.7828 - val_mean_squared_error: 1.2358\n",
            "Epoch 818/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.2163 - mean_absolute_error: 0.7665 - mean_squared_error: 1.2163\n",
            "Epoch 818: val_loss did not improve from 1.22653\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2148 - mean_absolute_error: 0.7658 - mean_squared_error: 1.2148 - val_loss: 1.2564 - val_mean_absolute_error: 0.8042 - val_mean_squared_error: 1.2564\n",
            "Epoch 819/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.2196 - mean_absolute_error: 0.7654 - mean_squared_error: 1.2196\n",
            "Epoch 819: val_loss improved from 1.22653 to 1.22035, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2120 - mean_absolute_error: 0.7650 - mean_squared_error: 1.2120 - val_loss: 1.2203 - val_mean_absolute_error: 0.7774 - val_mean_squared_error: 1.2203\n",
            "Epoch 820/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.2040 - mean_absolute_error: 0.7640 - mean_squared_error: 1.2040\n",
            "Epoch 820: val_loss improved from 1.22035 to 1.21544, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2083 - mean_absolute_error: 0.7643 - mean_squared_error: 1.2083 - val_loss: 1.2154 - val_mean_absolute_error: 0.7712 - val_mean_squared_error: 1.2154\n",
            "Epoch 821/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.2149 - mean_absolute_error: 0.7640 - mean_squared_error: 1.2149\n",
            "Epoch 821: val_loss did not improve from 1.21544\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2119 - mean_absolute_error: 0.7639 - mean_squared_error: 1.2119 - val_loss: 1.2218 - val_mean_absolute_error: 0.7822 - val_mean_squared_error: 1.2218\n",
            "Epoch 822/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.2093 - mean_absolute_error: 0.7657 - mean_squared_error: 1.2093\n",
            "Epoch 822: val_loss improved from 1.21544 to 1.21340, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2070 - mean_absolute_error: 0.7650 - mean_squared_error: 1.2070 - val_loss: 1.2134 - val_mean_absolute_error: 0.7720 - val_mean_squared_error: 1.2134\n",
            "Epoch 823/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.2080 - mean_absolute_error: 0.7615 - mean_squared_error: 1.2080\n",
            "Epoch 823: val_loss improved from 1.21340 to 1.21290, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2068 - mean_absolute_error: 0.7612 - mean_squared_error: 1.2068 - val_loss: 1.2129 - val_mean_absolute_error: 0.7747 - val_mean_squared_error: 1.2129\n",
            "Epoch 824/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.2050 - mean_absolute_error: 0.7631 - mean_squared_error: 1.2050\n",
            "Epoch 824: val_loss did not improve from 1.21290\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2071 - mean_absolute_error: 0.7633 - mean_squared_error: 1.2071 - val_loss: 1.2288 - val_mean_absolute_error: 0.7813 - val_mean_squared_error: 1.2288\n",
            "Epoch 825/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.2088 - mean_absolute_error: 0.7621 - mean_squared_error: 1.2088\n",
            "Epoch 825: val_loss improved from 1.21290 to 1.21105, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2043 - mean_absolute_error: 0.7619 - mean_squared_error: 1.2043 - val_loss: 1.2111 - val_mean_absolute_error: 0.7753 - val_mean_squared_error: 1.2111\n",
            "Epoch 826/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.1990 - mean_absolute_error: 0.7590 - mean_squared_error: 1.1990\n",
            "Epoch 826: val_loss improved from 1.21105 to 1.20911, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2049 - mean_absolute_error: 0.7610 - mean_squared_error: 1.2049 - val_loss: 1.2091 - val_mean_absolute_error: 0.7739 - val_mean_squared_error: 1.2091\n",
            "Epoch 827/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.1990 - mean_absolute_error: 0.7612 - mean_squared_error: 1.1990\n",
            "Epoch 827: val_loss improved from 1.20911 to 1.20851, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2035 - mean_absolute_error: 0.7629 - mean_squared_error: 1.2035 - val_loss: 1.2085 - val_mean_absolute_error: 0.7725 - val_mean_squared_error: 1.2085\n",
            "Epoch 828/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.2060 - mean_absolute_error: 0.7616 - mean_squared_error: 1.2060\n",
            "Epoch 828: val_loss did not improve from 1.20851\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1999 - mean_absolute_error: 0.7594 - mean_squared_error: 1.1999 - val_loss: 1.2089 - val_mean_absolute_error: 0.7754 - val_mean_squared_error: 1.2089\n",
            "Epoch 829/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.1973 - mean_absolute_error: 0.7596 - mean_squared_error: 1.1973\n",
            "Epoch 829: val_loss improved from 1.20851 to 1.20640, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2004 - mean_absolute_error: 0.7608 - mean_squared_error: 1.2004 - val_loss: 1.2064 - val_mean_absolute_error: 0.7699 - val_mean_squared_error: 1.2064\n",
            "Epoch 830/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.2055 - mean_absolute_error: 0.7625 - mean_squared_error: 1.2055\n",
            "Epoch 830: val_loss did not improve from 1.20640\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1993 - mean_absolute_error: 0.7616 - mean_squared_error: 1.1993 - val_loss: 1.2081 - val_mean_absolute_error: 0.7795 - val_mean_squared_error: 1.2081\n",
            "Epoch 831/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.1959 - mean_absolute_error: 0.7576 - mean_squared_error: 1.1959\n",
            "Epoch 831: val_loss improved from 1.20640 to 1.20464, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1967 - mean_absolute_error: 0.7580 - mean_squared_error: 1.1967 - val_loss: 1.2046 - val_mean_absolute_error: 0.7717 - val_mean_squared_error: 1.2046\n",
            "Epoch 832/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.1893 - mean_absolute_error: 0.7592 - mean_squared_error: 1.1893\n",
            "Epoch 832: val_loss improved from 1.20464 to 1.20338, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1919 - mean_absolute_error: 0.7608 - mean_squared_error: 1.1919 - val_loss: 1.2034 - val_mean_absolute_error: 0.7707 - val_mean_squared_error: 1.2034\n",
            "Epoch 833/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.1895 - mean_absolute_error: 0.7562 - mean_squared_error: 1.1895\n",
            "Epoch 833: val_loss improved from 1.20338 to 1.19745, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1957 - mean_absolute_error: 0.7591 - mean_squared_error: 1.1957 - val_loss: 1.1974 - val_mean_absolute_error: 0.7658 - val_mean_squared_error: 1.1974\n",
            "Epoch 834/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.1817 - mean_absolute_error: 0.7532 - mean_squared_error: 1.1817\n",
            "Epoch 834: val_loss did not improve from 1.19745\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1923 - mean_absolute_error: 0.7568 - mean_squared_error: 1.1923 - val_loss: 1.1984 - val_mean_absolute_error: 0.7710 - val_mean_squared_error: 1.1984\n",
            "Epoch 835/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.1860 - mean_absolute_error: 0.7567 - mean_squared_error: 1.1860\n",
            "Epoch 835: val_loss did not improve from 1.19745\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1936 - mean_absolute_error: 0.7590 - mean_squared_error: 1.1936 - val_loss: 1.2205 - val_mean_absolute_error: 0.7816 - val_mean_squared_error: 1.2205\n",
            "Epoch 836/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.1844 - mean_absolute_error: 0.7570 - mean_squared_error: 1.1844\n",
            "Epoch 836: val_loss improved from 1.19745 to 1.19385, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1900 - mean_absolute_error: 0.7595 - mean_squared_error: 1.1900 - val_loss: 1.1938 - val_mean_absolute_error: 0.7665 - val_mean_squared_error: 1.1938\n",
            "Epoch 837/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.1875 - mean_absolute_error: 0.7577 - mean_squared_error: 1.1875\n",
            "Epoch 837: val_loss improved from 1.19385 to 1.19282, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1904 - mean_absolute_error: 0.7591 - mean_squared_error: 1.1904 - val_loss: 1.1928 - val_mean_absolute_error: 0.7640 - val_mean_squared_error: 1.1928\n",
            "Epoch 838/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.1834 - mean_absolute_error: 0.7520 - mean_squared_error: 1.1834\n",
            "Epoch 838: val_loss did not improve from 1.19282\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1834 - mean_absolute_error: 0.7520 - mean_squared_error: 1.1834 - val_loss: 1.2042 - val_mean_absolute_error: 0.7753 - val_mean_squared_error: 1.2042\n",
            "Epoch 839/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.2005 - mean_absolute_error: 0.7613 - mean_squared_error: 1.2005\n",
            "Epoch 839: val_loss improved from 1.19282 to 1.19067, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1859 - mean_absolute_error: 0.7566 - mean_squared_error: 1.1859 - val_loss: 1.1907 - val_mean_absolute_error: 0.7674 - val_mean_squared_error: 1.1907\n",
            "Epoch 840/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.1773 - mean_absolute_error: 0.7513 - mean_squared_error: 1.1773\n",
            "Epoch 840: val_loss did not improve from 1.19067\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1832 - mean_absolute_error: 0.7538 - mean_squared_error: 1.1832 - val_loss: 1.1945 - val_mean_absolute_error: 0.7659 - val_mean_squared_error: 1.1945\n",
            "Epoch 841/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.1790 - mean_absolute_error: 0.7513 - mean_squared_error: 1.1790\n",
            "Epoch 841: val_loss improved from 1.19067 to 1.18664, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1823 - mean_absolute_error: 0.7520 - mean_squared_error: 1.1823 - val_loss: 1.1866 - val_mean_absolute_error: 0.7639 - val_mean_squared_error: 1.1866\n",
            "Epoch 842/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.1859 - mean_absolute_error: 0.7551 - mean_squared_error: 1.1859\n",
            "Epoch 842: val_loss did not improve from 1.18664\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1800 - mean_absolute_error: 0.7531 - mean_squared_error: 1.1800 - val_loss: 1.1884 - val_mean_absolute_error: 0.7619 - val_mean_squared_error: 1.1884\n",
            "Epoch 843/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.1798 - mean_absolute_error: 0.7513 - mean_squared_error: 1.1798\n",
            "Epoch 843: val_loss did not improve from 1.18664\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1794 - mean_absolute_error: 0.7512 - mean_squared_error: 1.1794 - val_loss: 1.1912 - val_mean_absolute_error: 0.7658 - val_mean_squared_error: 1.1912\n",
            "Epoch 844/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.1893 - mean_absolute_error: 0.7552 - mean_squared_error: 1.1893\n",
            "Epoch 844: val_loss improved from 1.18664 to 1.18177, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1791 - mean_absolute_error: 0.7529 - mean_squared_error: 1.1791 - val_loss: 1.1818 - val_mean_absolute_error: 0.7584 - val_mean_squared_error: 1.1818\n",
            "Epoch 845/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.1739 - mean_absolute_error: 0.7493 - mean_squared_error: 1.1739\n",
            "Epoch 845: val_loss did not improve from 1.18177\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1786 - mean_absolute_error: 0.7499 - mean_squared_error: 1.1786 - val_loss: 1.1830 - val_mean_absolute_error: 0.7624 - val_mean_squared_error: 1.1830\n",
            "Epoch 846/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.1786 - mean_absolute_error: 0.7504 - mean_squared_error: 1.1786\n",
            "Epoch 846: val_loss improved from 1.18177 to 1.18146, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1743 - mean_absolute_error: 0.7501 - mean_squared_error: 1.1743 - val_loss: 1.1815 - val_mean_absolute_error: 0.7609 - val_mean_squared_error: 1.1815\n",
            "Epoch 847/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.1833 - mean_absolute_error: 0.7551 - mean_squared_error: 1.1833\n",
            "Epoch 847: val_loss improved from 1.18146 to 1.17857, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1759 - mean_absolute_error: 0.7522 - mean_squared_error: 1.1759 - val_loss: 1.1786 - val_mean_absolute_error: 0.7544 - val_mean_squared_error: 1.1786\n",
            "Epoch 848/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.1818 - mean_absolute_error: 0.7545 - mean_squared_error: 1.1818\n",
            "Epoch 848: val_loss did not improve from 1.17857\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1727 - mean_absolute_error: 0.7518 - mean_squared_error: 1.1727 - val_loss: 1.1826 - val_mean_absolute_error: 0.7678 - val_mean_squared_error: 1.1826\n",
            "Epoch 849/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.1655 - mean_absolute_error: 0.7497 - mean_squared_error: 1.1655\n",
            "Epoch 849: val_loss did not improve from 1.17857\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1706 - mean_absolute_error: 0.7523 - mean_squared_error: 1.1706 - val_loss: 1.1828 - val_mean_absolute_error: 0.7614 - val_mean_squared_error: 1.1828\n",
            "Epoch 850/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.1681 - mean_absolute_error: 0.7476 - mean_squared_error: 1.1681\n",
            "Epoch 850: val_loss did not improve from 1.17857\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1681 - mean_absolute_error: 0.7476 - mean_squared_error: 1.1681 - val_loss: 1.1939 - val_mean_absolute_error: 0.7694 - val_mean_squared_error: 1.1939\n",
            "Epoch 851/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.1736 - mean_absolute_error: 0.7507 - mean_squared_error: 1.1736\n",
            "Epoch 851: val_loss did not improve from 1.17857\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1706 - mean_absolute_error: 0.7496 - mean_squared_error: 1.1706 - val_loss: 1.1907 - val_mean_absolute_error: 0.7691 - val_mean_squared_error: 1.1907\n",
            "Epoch 852/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.1676 - mean_absolute_error: 0.7473 - mean_squared_error: 1.1676\n",
            "Epoch 852: val_loss improved from 1.17857 to 1.17246, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1682 - mean_absolute_error: 0.7472 - mean_squared_error: 1.1682 - val_loss: 1.1725 - val_mean_absolute_error: 0.7573 - val_mean_squared_error: 1.1725\n",
            "Epoch 853/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.1608 - mean_absolute_error: 0.7446 - mean_squared_error: 1.1608\n",
            "Epoch 853: val_loss did not improve from 1.17246\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1638 - mean_absolute_error: 0.7457 - mean_squared_error: 1.1638 - val_loss: 1.1962 - val_mean_absolute_error: 0.7757 - val_mean_squared_error: 1.1962\n",
            "Epoch 854/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.1657 - mean_absolute_error: 0.7460 - mean_squared_error: 1.1657\n",
            "Epoch 854: val_loss did not improve from 1.17246\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1640 - mean_absolute_error: 0.7461 - mean_squared_error: 1.1640 - val_loss: 1.1789 - val_mean_absolute_error: 0.7623 - val_mean_squared_error: 1.1789\n",
            "Epoch 855/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.1585 - mean_absolute_error: 0.7428 - mean_squared_error: 1.1585\n",
            "Epoch 855: val_loss improved from 1.17246 to 1.16827, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.1597 - mean_absolute_error: 0.7445 - mean_squared_error: 1.1597 - val_loss: 1.1683 - val_mean_absolute_error: 0.7577 - val_mean_squared_error: 1.1683\n",
            "Epoch 856/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.1706 - mean_absolute_error: 0.7486 - mean_squared_error: 1.1706\n",
            "Epoch 856: val_loss improved from 1.16827 to 1.16789, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.1630 - mean_absolute_error: 0.7449 - mean_squared_error: 1.1630 - val_loss: 1.1679 - val_mean_absolute_error: 0.7591 - val_mean_squared_error: 1.1679\n",
            "Epoch 857/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.1596 - mean_absolute_error: 0.7450 - mean_squared_error: 1.1596\n",
            "Epoch 857: val_loss did not improve from 1.16789\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.1626 - mean_absolute_error: 0.7457 - mean_squared_error: 1.1626 - val_loss: 1.1680 - val_mean_absolute_error: 0.7576 - val_mean_squared_error: 1.1680\n",
            "Epoch 858/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.1587 - mean_absolute_error: 0.7450 - mean_squared_error: 1.1587\n",
            "Epoch 858: val_loss improved from 1.16789 to 1.16253, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.1585 - mean_absolute_error: 0.7453 - mean_squared_error: 1.1585 - val_loss: 1.1625 - val_mean_absolute_error: 0.7526 - val_mean_squared_error: 1.1625\n",
            "Epoch 859/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.1671 - mean_absolute_error: 0.7479 - mean_squared_error: 1.1671\n",
            "Epoch 859: val_loss improved from 1.16253 to 1.16200, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.1588 - mean_absolute_error: 0.7450 - mean_squared_error: 1.1588 - val_loss: 1.1620 - val_mean_absolute_error: 0.7533 - val_mean_squared_error: 1.1620\n",
            "Epoch 860/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.1667 - mean_absolute_error: 0.7489 - mean_squared_error: 1.1667\n",
            "Epoch 860: val_loss did not improve from 1.16200\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1566 - mean_absolute_error: 0.7445 - mean_squared_error: 1.1566 - val_loss: 1.1765 - val_mean_absolute_error: 0.7620 - val_mean_squared_error: 1.1765\n",
            "Epoch 861/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.1584 - mean_absolute_error: 0.7438 - mean_squared_error: 1.1584\n",
            "Epoch 861: val_loss improved from 1.16200 to 1.16033, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1558 - mean_absolute_error: 0.7432 - mean_squared_error: 1.1558 - val_loss: 1.1603 - val_mean_absolute_error: 0.7544 - val_mean_squared_error: 1.1603\n",
            "Epoch 862/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.1523 - mean_absolute_error: 0.7442 - mean_squared_error: 1.1523\n",
            "Epoch 862: val_loss improved from 1.16033 to 1.15988, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1572 - mean_absolute_error: 0.7453 - mean_squared_error: 1.1572 - val_loss: 1.1599 - val_mean_absolute_error: 0.7529 - val_mean_squared_error: 1.1599\n",
            "Epoch 863/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.1597 - mean_absolute_error: 0.7445 - mean_squared_error: 1.1597\n",
            "Epoch 863: val_loss improved from 1.15988 to 1.15791, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1538 - mean_absolute_error: 0.7427 - mean_squared_error: 1.1538 - val_loss: 1.1579 - val_mean_absolute_error: 0.7542 - val_mean_squared_error: 1.1579\n",
            "Epoch 864/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.1432 - mean_absolute_error: 0.7405 - mean_squared_error: 1.1432\n",
            "Epoch 864: val_loss did not improve from 1.15791\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1507 - mean_absolute_error: 0.7425 - mean_squared_error: 1.1507 - val_loss: 1.1593 - val_mean_absolute_error: 0.7551 - val_mean_squared_error: 1.1593\n",
            "Epoch 865/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.1541 - mean_absolute_error: 0.7452 - mean_squared_error: 1.1541\n",
            "Epoch 865: val_loss did not improve from 1.15791\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1473 - mean_absolute_error: 0.7431 - mean_squared_error: 1.1473 - val_loss: 1.1703 - val_mean_absolute_error: 0.7594 - val_mean_squared_error: 1.1703\n",
            "Epoch 866/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.1496 - mean_absolute_error: 0.7402 - mean_squared_error: 1.1496\n",
            "Epoch 866: val_loss did not improve from 1.15791\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1501 - mean_absolute_error: 0.7413 - mean_squared_error: 1.1501 - val_loss: 1.1666 - val_mean_absolute_error: 0.7688 - val_mean_squared_error: 1.1666\n",
            "Epoch 867/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.1455 - mean_absolute_error: 0.7390 - mean_squared_error: 1.1455\n",
            "Epoch 867: val_loss improved from 1.15791 to 1.14964, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1465 - mean_absolute_error: 0.7407 - mean_squared_error: 1.1465 - val_loss: 1.1496 - val_mean_absolute_error: 0.7489 - val_mean_squared_error: 1.1496\n",
            "Epoch 868/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.1363 - mean_absolute_error: 0.7333 - mean_squared_error: 1.1363\n",
            "Epoch 868: val_loss did not improve from 1.14964\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1444 - mean_absolute_error: 0.7377 - mean_squared_error: 1.1444 - val_loss: 1.1712 - val_mean_absolute_error: 0.7650 - val_mean_squared_error: 1.1712\n",
            "Epoch 869/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.1409 - mean_absolute_error: 0.7379 - mean_squared_error: 1.1409\n",
            "Epoch 869: val_loss improved from 1.14964 to 1.14832, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1417 - mean_absolute_error: 0.7380 - mean_squared_error: 1.1417 - val_loss: 1.1483 - val_mean_absolute_error: 0.7484 - val_mean_squared_error: 1.1483\n",
            "Epoch 870/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.1384 - mean_absolute_error: 0.7369 - mean_squared_error: 1.1384\n",
            "Epoch 870: val_loss improved from 1.14832 to 1.14542, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1405 - mean_absolute_error: 0.7374 - mean_squared_error: 1.1405 - val_loss: 1.1454 - val_mean_absolute_error: 0.7447 - val_mean_squared_error: 1.1454\n",
            "Epoch 871/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.1458 - mean_absolute_error: 0.7381 - mean_squared_error: 1.1458\n",
            "Epoch 871: val_loss did not improve from 1.14542\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1409 - mean_absolute_error: 0.7368 - mean_squared_error: 1.1409 - val_loss: 1.1745 - val_mean_absolute_error: 0.7662 - val_mean_squared_error: 1.1745\n",
            "Epoch 872/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.1365 - mean_absolute_error: 0.7366 - mean_squared_error: 1.1365\n",
            "Epoch 872: val_loss improved from 1.14542 to 1.14338, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1409 - mean_absolute_error: 0.7384 - mean_squared_error: 1.1409 - val_loss: 1.1434 - val_mean_absolute_error: 0.7464 - val_mean_squared_error: 1.1434\n",
            "Epoch 873/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.1330 - mean_absolute_error: 0.7364 - mean_squared_error: 1.1330\n",
            "Epoch 873: val_loss improved from 1.14338 to 1.14276, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1375 - mean_absolute_error: 0.7376 - mean_squared_error: 1.1375 - val_loss: 1.1428 - val_mean_absolute_error: 0.7477 - val_mean_squared_error: 1.1428\n",
            "Epoch 874/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.1342 - mean_absolute_error: 0.7363 - mean_squared_error: 1.1342\n",
            "Epoch 874: val_loss did not improve from 1.14276\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1426 - mean_absolute_error: 0.7377 - mean_squared_error: 1.1426 - val_loss: 1.1439 - val_mean_absolute_error: 0.7510 - val_mean_squared_error: 1.1439\n",
            "Epoch 875/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.1354 - mean_absolute_error: 0.7361 - mean_squared_error: 1.1354\n",
            "Epoch 875: val_loss did not improve from 1.14276\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1334 - mean_absolute_error: 0.7364 - mean_squared_error: 1.1334 - val_loss: 1.1438 - val_mean_absolute_error: 0.7544 - val_mean_squared_error: 1.1438\n",
            "Epoch 876/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.1326 - mean_absolute_error: 0.7365 - mean_squared_error: 1.1326\n",
            "Epoch 876: val_loss did not improve from 1.14276\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1314 - mean_absolute_error: 0.7364 - mean_squared_error: 1.1314 - val_loss: 1.1437 - val_mean_absolute_error: 0.7453 - val_mean_squared_error: 1.1437\n",
            "Epoch 877/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.1275 - mean_absolute_error: 0.7381 - mean_squared_error: 1.1275\n",
            "Epoch 877: val_loss did not improve from 1.14276\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1355 - mean_absolute_error: 0.7384 - mean_squared_error: 1.1355 - val_loss: 1.1615 - val_mean_absolute_error: 0.7588 - val_mean_squared_error: 1.1615\n",
            "Epoch 878/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.1310 - mean_absolute_error: 0.7339 - mean_squared_error: 1.1310\n",
            "Epoch 878: val_loss improved from 1.14276 to 1.13726, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1303 - mean_absolute_error: 0.7336 - mean_squared_error: 1.1303 - val_loss: 1.1373 - val_mean_absolute_error: 0.7440 - val_mean_squared_error: 1.1373\n",
            "Epoch 879/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.1322 - mean_absolute_error: 0.7359 - mean_squared_error: 1.1322\n",
            "Epoch 879: val_loss did not improve from 1.13726\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1293 - mean_absolute_error: 0.7347 - mean_squared_error: 1.1293 - val_loss: 1.1376 - val_mean_absolute_error: 0.7454 - val_mean_squared_error: 1.1376\n",
            "Epoch 880/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.1336 - mean_absolute_error: 0.7347 - mean_squared_error: 1.1336\n",
            "Epoch 880: val_loss improved from 1.13726 to 1.13492, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1292 - mean_absolute_error: 0.7338 - mean_squared_error: 1.1292 - val_loss: 1.1349 - val_mean_absolute_error: 0.7453 - val_mean_squared_error: 1.1349\n",
            "Epoch 881/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.1315 - mean_absolute_error: 0.7337 - mean_squared_error: 1.1315\n",
            "Epoch 881: val_loss did not improve from 1.13492\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1295 - mean_absolute_error: 0.7331 - mean_squared_error: 1.1295 - val_loss: 1.1399 - val_mean_absolute_error: 0.7497 - val_mean_squared_error: 1.1399\n",
            "Epoch 882/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.1283 - mean_absolute_error: 0.7340 - mean_squared_error: 1.1283\n",
            "Epoch 882: val_loss did not improve from 1.13492\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1283 - mean_absolute_error: 0.7340 - mean_squared_error: 1.1283 - val_loss: 1.1367 - val_mean_absolute_error: 0.7458 - val_mean_squared_error: 1.1367\n",
            "Epoch 883/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.1315 - mean_absolute_error: 0.7351 - mean_squared_error: 1.1315\n",
            "Epoch 883: val_loss improved from 1.13492 to 1.12808, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1254 - mean_absolute_error: 0.7331 - mean_squared_error: 1.1254 - val_loss: 1.1281 - val_mean_absolute_error: 0.7423 - val_mean_squared_error: 1.1281\n",
            "Epoch 884/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.1286 - mean_absolute_error: 0.7329 - mean_squared_error: 1.1286\n",
            "Epoch 884: val_loss improved from 1.12808 to 1.12617, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1199 - mean_absolute_error: 0.7302 - mean_squared_error: 1.1199 - val_loss: 1.1262 - val_mean_absolute_error: 0.7410 - val_mean_squared_error: 1.1262\n",
            "Epoch 885/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.1203 - mean_absolute_error: 0.7294 - mean_squared_error: 1.1203\n",
            "Epoch 885: val_loss improved from 1.12617 to 1.12417, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1163 - mean_absolute_error: 0.7287 - mean_squared_error: 1.1163 - val_loss: 1.1242 - val_mean_absolute_error: 0.7379 - val_mean_squared_error: 1.1242\n",
            "Epoch 886/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.1199 - mean_absolute_error: 0.7311 - mean_squared_error: 1.1199\n",
            "Epoch 886: val_loss did not improve from 1.12417\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1160 - mean_absolute_error: 0.7315 - mean_squared_error: 1.1160 - val_loss: 1.1280 - val_mean_absolute_error: 0.7437 - val_mean_squared_error: 1.1280\n",
            "Epoch 887/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.1152 - mean_absolute_error: 0.7278 - mean_squared_error: 1.1152\n",
            "Epoch 887: val_loss did not improve from 1.12417\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1169 - mean_absolute_error: 0.7284 - mean_squared_error: 1.1169 - val_loss: 1.1321 - val_mean_absolute_error: 0.7538 - val_mean_squared_error: 1.1321\n",
            "Epoch 888/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.1303 - mean_absolute_error: 0.7364 - mean_squared_error: 1.1303\n",
            "Epoch 888: val_loss improved from 1.12417 to 1.12111, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1205 - mean_absolute_error: 0.7320 - mean_squared_error: 1.1205 - val_loss: 1.1211 - val_mean_absolute_error: 0.7369 - val_mean_squared_error: 1.1211\n",
            "Epoch 889/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.1098 - mean_absolute_error: 0.7279 - mean_squared_error: 1.1098\n",
            "Epoch 889: val_loss improved from 1.12111 to 1.11749, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1134 - mean_absolute_error: 0.7285 - mean_squared_error: 1.1134 - val_loss: 1.1175 - val_mean_absolute_error: 0.7310 - val_mean_squared_error: 1.1175\n",
            "Epoch 890/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.1082 - mean_absolute_error: 0.7279 - mean_squared_error: 1.1082\n",
            "Epoch 890: val_loss did not improve from 1.11749\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1120 - mean_absolute_error: 0.7280 - mean_squared_error: 1.1120 - val_loss: 1.1199 - val_mean_absolute_error: 0.7433 - val_mean_squared_error: 1.1199\n",
            "Epoch 891/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.1123 - mean_absolute_error: 0.7289 - mean_squared_error: 1.1123\n",
            "Epoch 891: val_loss improved from 1.11749 to 1.11572, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1110 - mean_absolute_error: 0.7294 - mean_squared_error: 1.1110 - val_loss: 1.1157 - val_mean_absolute_error: 0.7346 - val_mean_squared_error: 1.1157\n",
            "Epoch 892/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.1199 - mean_absolute_error: 0.7311 - mean_squared_error: 1.1199\n",
            "Epoch 892: val_loss improved from 1.11572 to 1.11460, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1129 - mean_absolute_error: 0.7280 - mean_squared_error: 1.1129 - val_loss: 1.1146 - val_mean_absolute_error: 0.7351 - val_mean_squared_error: 1.1146\n",
            "Epoch 893/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.1079 - mean_absolute_error: 0.7256 - mean_squared_error: 1.1079\n",
            "Epoch 893: val_loss did not improve from 1.11460\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1072 - mean_absolute_error: 0.7256 - mean_squared_error: 1.1072 - val_loss: 1.1335 - val_mean_absolute_error: 0.7476 - val_mean_squared_error: 1.1335\n",
            "Epoch 894/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.1183 - mean_absolute_error: 0.7312 - mean_squared_error: 1.1183\n",
            "Epoch 894: val_loss did not improve from 1.11460\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1072 - mean_absolute_error: 0.7266 - mean_squared_error: 1.1072 - val_loss: 1.1188 - val_mean_absolute_error: 0.7389 - val_mean_squared_error: 1.1188\n",
            "Epoch 895/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.1042 - mean_absolute_error: 0.7238 - mean_squared_error: 1.1042\n",
            "Epoch 895: val_loss improved from 1.11460 to 1.11114, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1055 - mean_absolute_error: 0.7229 - mean_squared_error: 1.1055 - val_loss: 1.1111 - val_mean_absolute_error: 0.7361 - val_mean_squared_error: 1.1111\n",
            "Epoch 896/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.1021 - mean_absolute_error: 0.7244 - mean_squared_error: 1.1021\n",
            "Epoch 896: val_loss did not improve from 1.11114\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1021 - mean_absolute_error: 0.7244 - mean_squared_error: 1.1021 - val_loss: 1.1130 - val_mean_absolute_error: 0.7411 - val_mean_squared_error: 1.1130\n",
            "Epoch 897/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.1079 - mean_absolute_error: 0.7228 - mean_squared_error: 1.1079\n",
            "Epoch 897: val_loss did not improve from 1.11114\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1036 - mean_absolute_error: 0.7222 - mean_squared_error: 1.1036 - val_loss: 1.1195 - val_mean_absolute_error: 0.7409 - val_mean_squared_error: 1.1195\n",
            "Epoch 898/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.0988 - mean_absolute_error: 0.7217 - mean_squared_error: 1.0988\n",
            "Epoch 898: val_loss did not improve from 1.11114\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1018 - mean_absolute_error: 0.7236 - mean_squared_error: 1.1018 - val_loss: 1.1124 - val_mean_absolute_error: 0.7391 - val_mean_squared_error: 1.1124\n",
            "Epoch 899/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.1007 - mean_absolute_error: 0.7245 - mean_squared_error: 1.1007\n",
            "Epoch 899: val_loss improved from 1.11114 to 1.10480, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0997 - mean_absolute_error: 0.7250 - mean_squared_error: 1.0997 - val_loss: 1.1048 - val_mean_absolute_error: 0.7288 - val_mean_squared_error: 1.1048\n",
            "Epoch 900/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.0988 - mean_absolute_error: 0.7215 - mean_squared_error: 1.0988\n",
            "Epoch 900: val_loss did not improve from 1.10480\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0988 - mean_absolute_error: 0.7208 - mean_squared_error: 1.0988 - val_loss: 1.1128 - val_mean_absolute_error: 0.7412 - val_mean_squared_error: 1.1128\n",
            "Epoch 901/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.0941 - mean_absolute_error: 0.7204 - mean_squared_error: 1.0941\n",
            "Epoch 901: val_loss did not improve from 1.10480\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0946 - mean_absolute_error: 0.7219 - mean_squared_error: 1.0946 - val_loss: 1.1141 - val_mean_absolute_error: 0.7376 - val_mean_squared_error: 1.1141\n",
            "Epoch 902/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.0942 - mean_absolute_error: 0.7211 - mean_squared_error: 1.0942\n",
            "Epoch 902: val_loss did not improve from 1.10480\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0932 - mean_absolute_error: 0.7212 - mean_squared_error: 1.0932 - val_loss: 1.1264 - val_mean_absolute_error: 0.7573 - val_mean_squared_error: 1.1264\n",
            "Epoch 903/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.0958 - mean_absolute_error: 0.7208 - mean_squared_error: 1.0958\n",
            "Epoch 903: val_loss did not improve from 1.10480\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0946 - mean_absolute_error: 0.7209 - mean_squared_error: 1.0946 - val_loss: 1.1264 - val_mean_absolute_error: 0.7449 - val_mean_squared_error: 1.1264\n",
            "Epoch 904/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.0991 - mean_absolute_error: 0.7241 - mean_squared_error: 1.0991\n",
            "Epoch 904: val_loss did not improve from 1.10480\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0947 - mean_absolute_error: 0.7215 - mean_squared_error: 1.0947 - val_loss: 1.1111 - val_mean_absolute_error: 0.7338 - val_mean_squared_error: 1.1111\n",
            "Epoch 905/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.0887 - mean_absolute_error: 0.7196 - mean_squared_error: 1.0887\n",
            "Epoch 905: val_loss did not improve from 1.10480\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0921 - mean_absolute_error: 0.7210 - mean_squared_error: 1.0921 - val_loss: 1.1406 - val_mean_absolute_error: 0.7539 - val_mean_squared_error: 1.1406\n",
            "Epoch 906/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.0874 - mean_absolute_error: 0.7191 - mean_squared_error: 1.0874\n",
            "Epoch 906: val_loss improved from 1.10480 to 1.10040, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0927 - mean_absolute_error: 0.7204 - mean_squared_error: 1.0927 - val_loss: 1.1004 - val_mean_absolute_error: 0.7338 - val_mean_squared_error: 1.1004\n",
            "Epoch 907/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.0884 - mean_absolute_error: 0.7223 - mean_squared_error: 1.0884\n",
            "Epoch 907: val_loss did not improve from 1.10040\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0914 - mean_absolute_error: 0.7223 - mean_squared_error: 1.0914 - val_loss: 1.1018 - val_mean_absolute_error: 0.7285 - val_mean_squared_error: 1.1018\n",
            "Epoch 908/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.0950 - mean_absolute_error: 0.7217 - mean_squared_error: 1.0950\n",
            "Epoch 908: val_loss improved from 1.10040 to 1.09748, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0918 - mean_absolute_error: 0.7207 - mean_squared_error: 1.0918 - val_loss: 1.0975 - val_mean_absolute_error: 0.7278 - val_mean_squared_error: 1.0975\n",
            "Epoch 909/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.0971 - mean_absolute_error: 0.7211 - mean_squared_error: 1.0971\n",
            "Epoch 909: val_loss improved from 1.09748 to 1.09024, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0843 - mean_absolute_error: 0.7163 - mean_squared_error: 1.0843 - val_loss: 1.0902 - val_mean_absolute_error: 0.7268 - val_mean_squared_error: 1.0902\n",
            "Epoch 910/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.0837 - mean_absolute_error: 0.7177 - mean_squared_error: 1.0837\n",
            "Epoch 910: val_loss did not improve from 1.09024\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0837 - mean_absolute_error: 0.7177 - mean_squared_error: 1.0837 - val_loss: 1.1062 - val_mean_absolute_error: 0.7363 - val_mean_squared_error: 1.1062\n",
            "Epoch 911/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.0787 - mean_absolute_error: 0.7147 - mean_squared_error: 1.0787\n",
            "Epoch 911: val_loss did not improve from 1.09024\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0873 - mean_absolute_error: 0.7181 - mean_squared_error: 1.0873 - val_loss: 1.0930 - val_mean_absolute_error: 0.7305 - val_mean_squared_error: 1.0930\n",
            "Epoch 912/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.0775 - mean_absolute_error: 0.7164 - mean_squared_error: 1.0775\n",
            "Epoch 912: val_loss did not improve from 1.09024\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0798 - mean_absolute_error: 0.7179 - mean_squared_error: 1.0798 - val_loss: 1.0943 - val_mean_absolute_error: 0.7310 - val_mean_squared_error: 1.0943\n",
            "Epoch 913/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.0719 - mean_absolute_error: 0.7140 - mean_squared_error: 1.0719\n",
            "Epoch 913: val_loss improved from 1.09024 to 1.08749, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0750 - mean_absolute_error: 0.7149 - mean_squared_error: 1.0750 - val_loss: 1.0875 - val_mean_absolute_error: 0.7304 - val_mean_squared_error: 1.0875\n",
            "Epoch 914/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.0855 - mean_absolute_error: 0.7181 - mean_squared_error: 1.0855\n",
            "Epoch 914: val_loss did not improve from 1.08749\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0785 - mean_absolute_error: 0.7168 - mean_squared_error: 1.0785 - val_loss: 1.0972 - val_mean_absolute_error: 0.7307 - val_mean_squared_error: 1.0972\n",
            "Epoch 915/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.0711 - mean_absolute_error: 0.7149 - mean_squared_error: 1.0711\n",
            "Epoch 915: val_loss did not improve from 1.08749\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0777 - mean_absolute_error: 0.7167 - mean_squared_error: 1.0777 - val_loss: 1.1122 - val_mean_absolute_error: 0.7419 - val_mean_squared_error: 1.1122\n",
            "Epoch 916/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.0751 - mean_absolute_error: 0.7153 - mean_squared_error: 1.0751\n",
            "Epoch 916: val_loss improved from 1.08749 to 1.08207, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0734 - mean_absolute_error: 0.7141 - mean_squared_error: 1.0734 - val_loss: 1.0821 - val_mean_absolute_error: 0.7290 - val_mean_squared_error: 1.0821\n",
            "Epoch 917/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.0788 - mean_absolute_error: 0.7186 - mean_squared_error: 1.0788\n",
            "Epoch 917: val_loss improved from 1.08207 to 1.07939, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0758 - mean_absolute_error: 0.7174 - mean_squared_error: 1.0758 - val_loss: 1.0794 - val_mean_absolute_error: 0.7258 - val_mean_squared_error: 1.0794\n",
            "Epoch 918/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.0744 - mean_absolute_error: 0.7121 - mean_squared_error: 1.0744\n",
            "Epoch 918: val_loss improved from 1.07939 to 1.07735, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.0708 - mean_absolute_error: 0.7123 - mean_squared_error: 1.0708 - val_loss: 1.0773 - val_mean_absolute_error: 0.7221 - val_mean_squared_error: 1.0773\n",
            "Epoch 919/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.0644 - mean_absolute_error: 0.7098 - mean_squared_error: 1.0644\n",
            "Epoch 919: val_loss did not improve from 1.07735\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.0673 - mean_absolute_error: 0.7112 - mean_squared_error: 1.0673 - val_loss: 1.0775 - val_mean_absolute_error: 0.7252 - val_mean_squared_error: 1.0775\n",
            "Epoch 920/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.0670 - mean_absolute_error: 0.7152 - mean_squared_error: 1.0670\n",
            "Epoch 920: val_loss did not improve from 1.07735\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0693 - mean_absolute_error: 0.7155 - mean_squared_error: 1.0693 - val_loss: 1.0787 - val_mean_absolute_error: 0.7205 - val_mean_squared_error: 1.0787\n",
            "Epoch 921/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.0681 - mean_absolute_error: 0.7146 - mean_squared_error: 1.0681\n",
            "Epoch 921: val_loss did not improve from 1.07735\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0680 - mean_absolute_error: 0.7145 - mean_squared_error: 1.0680 - val_loss: 1.0806 - val_mean_absolute_error: 0.7292 - val_mean_squared_error: 1.0806\n",
            "Epoch 922/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.0651 - mean_absolute_error: 0.7143 - mean_squared_error: 1.0651\n",
            "Epoch 922: val_loss improved from 1.07735 to 1.07236, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0648 - mean_absolute_error: 0.7132 - mean_squared_error: 1.0648 - val_loss: 1.0724 - val_mean_absolute_error: 0.7214 - val_mean_squared_error: 1.0724\n",
            "Epoch 923/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.0629 - mean_absolute_error: 0.7119 - mean_squared_error: 1.0629\n",
            "Epoch 923: val_loss did not improve from 1.07236\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0647 - mean_absolute_error: 0.7125 - mean_squared_error: 1.0647 - val_loss: 1.0731 - val_mean_absolute_error: 0.7209 - val_mean_squared_error: 1.0731\n",
            "Epoch 924/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.0694 - mean_absolute_error: 0.7151 - mean_squared_error: 1.0694\n",
            "Epoch 924: val_loss did not improve from 1.07236\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0687 - mean_absolute_error: 0.7150 - mean_squared_error: 1.0687 - val_loss: 1.0929 - val_mean_absolute_error: 0.7343 - val_mean_squared_error: 1.0929\n",
            "Epoch 925/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.0573 - mean_absolute_error: 0.7094 - mean_squared_error: 1.0573\n",
            "Epoch 925: val_loss did not improve from 1.07236\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0621 - mean_absolute_error: 0.7112 - mean_squared_error: 1.0621 - val_loss: 1.0771 - val_mean_absolute_error: 0.7227 - val_mean_squared_error: 1.0771\n",
            "Epoch 926/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.0584 - mean_absolute_error: 0.7115 - mean_squared_error: 1.0584\n",
            "Epoch 926: val_loss improved from 1.07236 to 1.06716, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0599 - mean_absolute_error: 0.7105 - mean_squared_error: 1.0599 - val_loss: 1.0672 - val_mean_absolute_error: 0.7173 - val_mean_squared_error: 1.0672\n",
            "Epoch 927/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.0564 - mean_absolute_error: 0.7080 - mean_squared_error: 1.0564\n",
            "Epoch 927: val_loss did not improve from 1.06716\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0561 - mean_absolute_error: 0.7087 - mean_squared_error: 1.0561 - val_loss: 1.0673 - val_mean_absolute_error: 0.7206 - val_mean_squared_error: 1.0673\n",
            "Epoch 928/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.0571 - mean_absolute_error: 0.7068 - mean_squared_error: 1.0571\n",
            "Epoch 928: val_loss improved from 1.06716 to 1.06385, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0563 - mean_absolute_error: 0.7065 - mean_squared_error: 1.0563 - val_loss: 1.0639 - val_mean_absolute_error: 0.7225 - val_mean_squared_error: 1.0639\n",
            "Epoch 929/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.0613 - mean_absolute_error: 0.7161 - mean_squared_error: 1.0613\n",
            "Epoch 929: val_loss improved from 1.06385 to 1.06147, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0549 - mean_absolute_error: 0.7132 - mean_squared_error: 1.0549 - val_loss: 1.0615 - val_mean_absolute_error: 0.7174 - val_mean_squared_error: 1.0615\n",
            "Epoch 930/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.0522 - mean_absolute_error: 0.7055 - mean_squared_error: 1.0522\n",
            "Epoch 930: val_loss improved from 1.06147 to 1.05966, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0540 - mean_absolute_error: 0.7064 - mean_squared_error: 1.0540 - val_loss: 1.0597 - val_mean_absolute_error: 0.7174 - val_mean_squared_error: 1.0597\n",
            "Epoch 931/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.0468 - mean_absolute_error: 0.7037 - mean_squared_error: 1.0468\n",
            "Epoch 931: val_loss did not improve from 1.05966\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0500 - mean_absolute_error: 0.7070 - mean_squared_error: 1.0500 - val_loss: 1.0610 - val_mean_absolute_error: 0.7206 - val_mean_squared_error: 1.0610\n",
            "Epoch 932/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.0465 - mean_absolute_error: 0.7057 - mean_squared_error: 1.0465\n",
            "Epoch 932: val_loss improved from 1.05966 to 1.05500, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0489 - mean_absolute_error: 0.7056 - mean_squared_error: 1.0489 - val_loss: 1.0550 - val_mean_absolute_error: 0.7126 - val_mean_squared_error: 1.0550\n",
            "Epoch 933/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.0469 - mean_absolute_error: 0.7057 - mean_squared_error: 1.0469\n",
            "Epoch 933: val_loss did not improve from 1.05500\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0489 - mean_absolute_error: 0.7060 - mean_squared_error: 1.0489 - val_loss: 1.0570 - val_mean_absolute_error: 0.7155 - val_mean_squared_error: 1.0570\n",
            "Epoch 934/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.0489 - mean_absolute_error: 0.7055 - mean_squared_error: 1.0489\n",
            "Epoch 934: val_loss did not improve from 1.05500\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0426 - mean_absolute_error: 0.7030 - mean_squared_error: 1.0426 - val_loss: 1.0748 - val_mean_absolute_error: 0.7291 - val_mean_squared_error: 1.0748\n",
            "Epoch 935/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.0448 - mean_absolute_error: 0.7054 - mean_squared_error: 1.0448\n",
            "Epoch 935: val_loss improved from 1.05500 to 1.05229, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0409 - mean_absolute_error: 0.7048 - mean_squared_error: 1.0409 - val_loss: 1.0523 - val_mean_absolute_error: 0.7158 - val_mean_squared_error: 1.0523\n",
            "Epoch 936/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.0429 - mean_absolute_error: 0.7026 - mean_squared_error: 1.0429\n",
            "Epoch 936: val_loss improved from 1.05229 to 1.04955, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0429 - mean_absolute_error: 0.7023 - mean_squared_error: 1.0429 - val_loss: 1.0496 - val_mean_absolute_error: 0.7109 - val_mean_squared_error: 1.0496\n",
            "Epoch 937/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.0472 - mean_absolute_error: 0.7047 - mean_squared_error: 1.0472\n",
            "Epoch 937: val_loss did not improve from 1.04955\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0453 - mean_absolute_error: 0.7037 - mean_squared_error: 1.0453 - val_loss: 1.0510 - val_mean_absolute_error: 0.7135 - val_mean_squared_error: 1.0510\n",
            "Epoch 938/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.0424 - mean_absolute_error: 0.7026 - mean_squared_error: 1.0424\n",
            "Epoch 938: val_loss did not improve from 1.04955\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0422 - mean_absolute_error: 0.7023 - mean_squared_error: 1.0422 - val_loss: 1.0622 - val_mean_absolute_error: 0.7208 - val_mean_squared_error: 1.0622\n",
            "Epoch 939/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.0385 - mean_absolute_error: 0.7026 - mean_squared_error: 1.0385\n",
            "Epoch 939: val_loss did not improve from 1.04955\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0391 - mean_absolute_error: 0.7032 - mean_squared_error: 1.0391 - val_loss: 1.0658 - val_mean_absolute_error: 0.7232 - val_mean_squared_error: 1.0658\n",
            "Epoch 940/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.0553 - mean_absolute_error: 0.7089 - mean_squared_error: 1.0553\n",
            "Epoch 940: val_loss improved from 1.04955 to 1.04870, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0376 - mean_absolute_error: 0.7025 - mean_squared_error: 1.0376 - val_loss: 1.0487 - val_mean_absolute_error: 0.7120 - val_mean_squared_error: 1.0487\n",
            "Epoch 941/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.0439 - mean_absolute_error: 0.7021 - mean_squared_error: 1.0439\n",
            "Epoch 941: val_loss did not improve from 1.04870\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0347 - mean_absolute_error: 0.6994 - mean_squared_error: 1.0347 - val_loss: 1.0544 - val_mean_absolute_error: 0.7164 - val_mean_squared_error: 1.0544\n",
            "Epoch 942/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.0144 - mean_absolute_error: 0.6952 - mean_squared_error: 1.0144\n",
            "Epoch 942: val_loss improved from 1.04870 to 1.04734, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0327 - mean_absolute_error: 0.7012 - mean_squared_error: 1.0327 - val_loss: 1.0473 - val_mean_absolute_error: 0.7202 - val_mean_squared_error: 1.0473\n",
            "Epoch 943/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.0411 - mean_absolute_error: 0.7059 - mean_squared_error: 1.0411\n",
            "Epoch 943: val_loss improved from 1.04734 to 1.04014, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0338 - mean_absolute_error: 0.7026 - mean_squared_error: 1.0338 - val_loss: 1.0401 - val_mean_absolute_error: 0.7127 - val_mean_squared_error: 1.0401\n",
            "Epoch 944/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.0377 - mean_absolute_error: 0.7010 - mean_squared_error: 1.0377\n",
            "Epoch 944: val_loss did not improve from 1.04014\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0321 - mean_absolute_error: 0.6992 - mean_squared_error: 1.0321 - val_loss: 1.0693 - val_mean_absolute_error: 0.7265 - val_mean_squared_error: 1.0693\n",
            "Epoch 945/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.0343 - mean_absolute_error: 0.7027 - mean_squared_error: 1.0343\n",
            "Epoch 945: val_loss improved from 1.04014 to 1.03942, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0329 - mean_absolute_error: 0.7025 - mean_squared_error: 1.0329 - val_loss: 1.0394 - val_mean_absolute_error: 0.7132 - val_mean_squared_error: 1.0394\n",
            "Epoch 946/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.0254 - mean_absolute_error: 0.6962 - mean_squared_error: 1.0254\n",
            "Epoch 946: val_loss did not improve from 1.03942\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0252 - mean_absolute_error: 0.6968 - mean_squared_error: 1.0252 - val_loss: 1.0537 - val_mean_absolute_error: 0.7323 - val_mean_squared_error: 1.0537\n",
            "Epoch 947/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.0275 - mean_absolute_error: 0.6981 - mean_squared_error: 1.0275\n",
            "Epoch 947: val_loss did not improve from 1.03942\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0275 - mean_absolute_error: 0.6981 - mean_squared_error: 1.0275 - val_loss: 1.0444 - val_mean_absolute_error: 0.7145 - val_mean_squared_error: 1.0444\n",
            "Epoch 948/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.0139 - mean_absolute_error: 0.6948 - mean_squared_error: 1.0139\n",
            "Epoch 948: val_loss improved from 1.03942 to 1.03429, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0247 - mean_absolute_error: 0.6998 - mean_squared_error: 1.0247 - val_loss: 1.0343 - val_mean_absolute_error: 0.7124 - val_mean_squared_error: 1.0343\n",
            "Epoch 949/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.0233 - mean_absolute_error: 0.6969 - mean_squared_error: 1.0233\n",
            "Epoch 949: val_loss did not improve from 1.03429\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0232 - mean_absolute_error: 0.6967 - mean_squared_error: 1.0232 - val_loss: 1.0365 - val_mean_absolute_error: 0.7111 - val_mean_squared_error: 1.0365\n",
            "Epoch 950/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.0168 - mean_absolute_error: 0.6929 - mean_squared_error: 1.0168\n",
            "Epoch 950: val_loss improved from 1.03429 to 1.03348, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0223 - mean_absolute_error: 0.6963 - mean_squared_error: 1.0223 - val_loss: 1.0335 - val_mean_absolute_error: 0.7056 - val_mean_squared_error: 1.0335\n",
            "Epoch 951/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.0087 - mean_absolute_error: 0.6910 - mean_squared_error: 1.0087\n",
            "Epoch 951: val_loss did not improve from 1.03348\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0219 - mean_absolute_error: 0.6960 - mean_squared_error: 1.0219 - val_loss: 1.0405 - val_mean_absolute_error: 0.7151 - val_mean_squared_error: 1.0405\n",
            "Epoch 952/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.0117 - mean_absolute_error: 0.6951 - mean_squared_error: 1.0117\n",
            "Epoch 952: val_loss did not improve from 1.03348\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0189 - mean_absolute_error: 0.6978 - mean_squared_error: 1.0189 - val_loss: 1.0340 - val_mean_absolute_error: 0.7123 - val_mean_squared_error: 1.0340\n",
            "Epoch 953/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.0168 - mean_absolute_error: 0.6948 - mean_squared_error: 1.0168\n",
            "Epoch 953: val_loss did not improve from 1.03348\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0156 - mean_absolute_error: 0.6952 - mean_squared_error: 1.0156 - val_loss: 1.0444 - val_mean_absolute_error: 0.7137 - val_mean_squared_error: 1.0444\n",
            "Epoch 954/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.0205 - mean_absolute_error: 0.6971 - mean_squared_error: 1.0205\n",
            "Epoch 954: val_loss improved from 1.03348 to 1.02367, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0182 - mean_absolute_error: 0.6964 - mean_squared_error: 1.0182 - val_loss: 1.0237 - val_mean_absolute_error: 0.7064 - val_mean_squared_error: 1.0237\n",
            "Epoch 955/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.0179 - mean_absolute_error: 0.6935 - mean_squared_error: 1.0179\n",
            "Epoch 955: val_loss did not improve from 1.02367\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0144 - mean_absolute_error: 0.6941 - mean_squared_error: 1.0144 - val_loss: 1.0351 - val_mean_absolute_error: 0.7127 - val_mean_squared_error: 1.0351\n",
            "Epoch 956/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.0149 - mean_absolute_error: 0.6964 - mean_squared_error: 1.0149\n",
            "Epoch 956: val_loss improved from 1.02367 to 1.01938, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0119 - mean_absolute_error: 0.6956 - mean_squared_error: 1.0119 - val_loss: 1.0194 - val_mean_absolute_error: 0.7030 - val_mean_squared_error: 1.0194\n",
            "Epoch 957/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.0075 - mean_absolute_error: 0.6939 - mean_squared_error: 1.0075\n",
            "Epoch 957: val_loss did not improve from 1.01938\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0110 - mean_absolute_error: 0.6959 - mean_squared_error: 1.0110 - val_loss: 1.0198 - val_mean_absolute_error: 0.7037 - val_mean_squared_error: 1.0198\n",
            "Epoch 958/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.0026 - mean_absolute_error: 0.6899 - mean_squared_error: 1.0026\n",
            "Epoch 958: val_loss did not improve from 1.01938\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0083 - mean_absolute_error: 0.6914 - mean_squared_error: 1.0083 - val_loss: 1.0252 - val_mean_absolute_error: 0.7096 - val_mean_squared_error: 1.0252\n",
            "Epoch 959/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.0064 - mean_absolute_error: 0.6924 - mean_squared_error: 1.0064\n",
            "Epoch 959: val_loss did not improve from 1.01938\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0056 - mean_absolute_error: 0.6927 - mean_squared_error: 1.0056 - val_loss: 1.0234 - val_mean_absolute_error: 0.7060 - val_mean_squared_error: 1.0234\n",
            "Epoch 960/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.0038 - mean_absolute_error: 0.6920 - mean_squared_error: 1.0038\n",
            "Epoch 960: val_loss did not improve from 1.01938\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0065 - mean_absolute_error: 0.6928 - mean_squared_error: 1.0065 - val_loss: 1.0502 - val_mean_absolute_error: 0.7200 - val_mean_squared_error: 1.0502\n",
            "Epoch 961/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.0088 - mean_absolute_error: 0.6900 - mean_squared_error: 1.0088\n",
            "Epoch 961: val_loss improved from 1.01938 to 1.01411, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0065 - mean_absolute_error: 0.6902 - mean_squared_error: 1.0065 - val_loss: 1.0141 - val_mean_absolute_error: 0.7070 - val_mean_squared_error: 1.0141\n",
            "Epoch 962/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.0061 - mean_absolute_error: 0.6942 - mean_squared_error: 1.0061\n",
            "Epoch 962: val_loss improved from 1.01411 to 1.01144, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0048 - mean_absolute_error: 0.6932 - mean_squared_error: 1.0048 - val_loss: 1.0114 - val_mean_absolute_error: 0.7031 - val_mean_squared_error: 1.0114\n",
            "Epoch 963/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.9950 - mean_absolute_error: 0.6911 - mean_squared_error: 0.9950\n",
            "Epoch 963: val_loss improved from 1.01144 to 1.00933, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9982 - mean_absolute_error: 0.6912 - mean_squared_error: 0.9982 - val_loss: 1.0093 - val_mean_absolute_error: 0.6971 - val_mean_squared_error: 1.0093\n",
            "Epoch 964/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.0013 - mean_absolute_error: 0.6900 - mean_squared_error: 1.0013\n",
            "Epoch 964: val_loss did not improve from 1.00933\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9992 - mean_absolute_error: 0.6898 - mean_squared_error: 0.9992 - val_loss: 1.0095 - val_mean_absolute_error: 0.7008 - val_mean_squared_error: 1.0095\n",
            "Epoch 965/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.0109 - mean_absolute_error: 0.6933 - mean_squared_error: 1.0109\n",
            "Epoch 965: val_loss improved from 1.00933 to 1.00593, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9972 - mean_absolute_error: 0.6875 - mean_squared_error: 0.9972 - val_loss: 1.0059 - val_mean_absolute_error: 0.6989 - val_mean_squared_error: 1.0059\n",
            "Epoch 966/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.9972 - mean_absolute_error: 0.6891 - mean_squared_error: 0.9972\n",
            "Epoch 966: val_loss improved from 1.00593 to 1.00575, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9957 - mean_absolute_error: 0.6883 - mean_squared_error: 0.9957 - val_loss: 1.0057 - val_mean_absolute_error: 0.6972 - val_mean_squared_error: 1.0057\n",
            "Epoch 967/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.9947 - mean_absolute_error: 0.6893 - mean_squared_error: 0.9947\n",
            "Epoch 967: val_loss did not improve from 1.00575\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9973 - mean_absolute_error: 0.6887 - mean_squared_error: 0.9973 - val_loss: 1.0222 - val_mean_absolute_error: 0.7062 - val_mean_squared_error: 1.0222\n",
            "Epoch 968/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.9921 - mean_absolute_error: 0.6883 - mean_squared_error: 0.9921\n",
            "Epoch 968: val_loss did not improve from 1.00575\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9909 - mean_absolute_error: 0.6882 - mean_squared_error: 0.9909 - val_loss: 1.0110 - val_mean_absolute_error: 0.6985 - val_mean_squared_error: 1.0110\n",
            "Epoch 969/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.9876 - mean_absolute_error: 0.6844 - mean_squared_error: 0.9876\n",
            "Epoch 969: val_loss improved from 1.00575 to 1.00333, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.9933 - mean_absolute_error: 0.6872 - mean_squared_error: 0.9933 - val_loss: 1.0033 - val_mean_absolute_error: 0.7042 - val_mean_squared_error: 1.0033\n",
            "Epoch 970/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.0000 - mean_absolute_error: 0.6915 - mean_squared_error: 1.0000\n",
            "Epoch 970: val_loss improved from 1.00333 to 0.99789, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9914 - mean_absolute_error: 0.6885 - mean_squared_error: 0.9914 - val_loss: 0.9979 - val_mean_absolute_error: 0.6971 - val_mean_squared_error: 0.9979\n",
            "Epoch 971/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.9760 - mean_absolute_error: 0.6824 - mean_squared_error: 0.9760\n",
            "Epoch 971: val_loss improved from 0.99789 to 0.99668, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9876 - mean_absolute_error: 0.6868 - mean_squared_error: 0.9876 - val_loss: 0.9967 - val_mean_absolute_error: 0.6969 - val_mean_squared_error: 0.9967\n",
            "Epoch 972/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.9855 - mean_absolute_error: 0.6829 - mean_squared_error: 0.9855\n",
            "Epoch 972: val_loss did not improve from 0.99668\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9855 - mean_absolute_error: 0.6829 - mean_squared_error: 0.9855 - val_loss: 1.0064 - val_mean_absolute_error: 0.7020 - val_mean_squared_error: 1.0064\n",
            "Epoch 973/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.9836 - mean_absolute_error: 0.6876 - mean_squared_error: 0.9836\n",
            "Epoch 973: val_loss did not improve from 0.99668\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9822 - mean_absolute_error: 0.6873 - mean_squared_error: 0.9822 - val_loss: 0.9992 - val_mean_absolute_error: 0.6973 - val_mean_squared_error: 0.9992\n",
            "Epoch 974/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.9829 - mean_absolute_error: 0.6828 - mean_squared_error: 0.9829\n",
            "Epoch 974: val_loss did not improve from 0.99668\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9849 - mean_absolute_error: 0.6837 - mean_squared_error: 0.9849 - val_loss: 0.9987 - val_mean_absolute_error: 0.6975 - val_mean_squared_error: 0.9987\n",
            "Epoch 975/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.9832 - mean_absolute_error: 0.6837 - mean_squared_error: 0.9832\n",
            "Epoch 975: val_loss improved from 0.99668 to 0.99118, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9832 - mean_absolute_error: 0.6837 - mean_squared_error: 0.9832 - val_loss: 0.9912 - val_mean_absolute_error: 0.6962 - val_mean_squared_error: 0.9912\n",
            "Epoch 976/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.9875 - mean_absolute_error: 0.6852 - mean_squared_error: 0.9875\n",
            "Epoch 976: val_loss improved from 0.99118 to 0.98853, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.9807 - mean_absolute_error: 0.6837 - mean_squared_error: 0.9807 - val_loss: 0.9885 - val_mean_absolute_error: 0.6939 - val_mean_squared_error: 0.9885\n",
            "Epoch 977/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.9718 - mean_absolute_error: 0.6817 - mean_squared_error: 0.9718\n",
            "Epoch 977: val_loss did not improve from 0.98853\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.9753 - mean_absolute_error: 0.6826 - mean_squared_error: 0.9753 - val_loss: 0.9958 - val_mean_absolute_error: 0.6966 - val_mean_squared_error: 0.9958\n",
            "Epoch 978/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.9759 - mean_absolute_error: 0.6817 - mean_squared_error: 0.9759\n",
            "Epoch 978: val_loss improved from 0.98853 to 0.98818, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9765 - mean_absolute_error: 0.6823 - mean_squared_error: 0.9765 - val_loss: 0.9882 - val_mean_absolute_error: 0.6974 - val_mean_squared_error: 0.9882\n",
            "Epoch 979/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.9800 - mean_absolute_error: 0.6836 - mean_squared_error: 0.9800\n",
            "Epoch 979: val_loss improved from 0.98818 to 0.98431, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9758 - mean_absolute_error: 0.6821 - mean_squared_error: 0.9758 - val_loss: 0.9843 - val_mean_absolute_error: 0.6927 - val_mean_squared_error: 0.9843\n",
            "Epoch 980/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.9818 - mean_absolute_error: 0.6849 - mean_squared_error: 0.9818\n",
            "Epoch 980: val_loss did not improve from 0.98431\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9806 - mean_absolute_error: 0.6848 - mean_squared_error: 0.9806 - val_loss: 0.9863 - val_mean_absolute_error: 0.6973 - val_mean_squared_error: 0.9863\n",
            "Epoch 981/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.9788 - mean_absolute_error: 0.6853 - mean_squared_error: 0.9788\n",
            "Epoch 981: val_loss improved from 0.98431 to 0.98141, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9755 - mean_absolute_error: 0.6832 - mean_squared_error: 0.9755 - val_loss: 0.9814 - val_mean_absolute_error: 0.6913 - val_mean_squared_error: 0.9814\n",
            "Epoch 982/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.9615 - mean_absolute_error: 0.6791 - mean_squared_error: 0.9615\n",
            "Epoch 982: val_loss did not improve from 0.98141\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9725 - mean_absolute_error: 0.6823 - mean_squared_error: 0.9725 - val_loss: 0.9839 - val_mean_absolute_error: 0.6971 - val_mean_squared_error: 0.9839\n",
            "Epoch 983/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.9648 - mean_absolute_error: 0.6774 - mean_squared_error: 0.9648\n",
            "Epoch 983: val_loss did not improve from 0.98141\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9693 - mean_absolute_error: 0.6794 - mean_squared_error: 0.9693 - val_loss: 0.9931 - val_mean_absolute_error: 0.6973 - val_mean_squared_error: 0.9931\n",
            "Epoch 984/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.9684 - mean_absolute_error: 0.6802 - mean_squared_error: 0.9684\n",
            "Epoch 984: val_loss improved from 0.98141 to 0.97827, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9687 - mean_absolute_error: 0.6803 - mean_squared_error: 0.9687 - val_loss: 0.9783 - val_mean_absolute_error: 0.6935 - val_mean_squared_error: 0.9783\n",
            "Epoch 985/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.9661 - mean_absolute_error: 0.6804 - mean_squared_error: 0.9661\n",
            "Epoch 985: val_loss did not improve from 0.97827\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9649 - mean_absolute_error: 0.6803 - mean_squared_error: 0.9649 - val_loss: 0.9920 - val_mean_absolute_error: 0.6990 - val_mean_squared_error: 0.9920\n",
            "Epoch 986/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.9727 - mean_absolute_error: 0.6846 - mean_squared_error: 0.9727\n",
            "Epoch 986: val_loss did not improve from 0.97827\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9659 - mean_absolute_error: 0.6816 - mean_squared_error: 0.9659 - val_loss: 0.9831 - val_mean_absolute_error: 0.6919 - val_mean_squared_error: 0.9831\n",
            "Epoch 987/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.9660 - mean_absolute_error: 0.6805 - mean_squared_error: 0.9660\n",
            "Epoch 987: val_loss did not improve from 0.97827\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9668 - mean_absolute_error: 0.6781 - mean_squared_error: 0.9668 - val_loss: 0.9833 - val_mean_absolute_error: 0.6968 - val_mean_squared_error: 0.9833\n",
            "Epoch 988/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.9575 - mean_absolute_error: 0.6795 - mean_squared_error: 0.9575\n",
            "Epoch 988: val_loss improved from 0.97827 to 0.97769, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9634 - mean_absolute_error: 0.6797 - mean_squared_error: 0.9634 - val_loss: 0.9777 - val_mean_absolute_error: 0.6914 - val_mean_squared_error: 0.9777\n",
            "Epoch 989/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.9556 - mean_absolute_error: 0.6762 - mean_squared_error: 0.9556\n",
            "Epoch 989: val_loss improved from 0.97769 to 0.97379, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9610 - mean_absolute_error: 0.6783 - mean_squared_error: 0.9610 - val_loss: 0.9738 - val_mean_absolute_error: 0.6937 - val_mean_squared_error: 0.9738\n",
            "Epoch 990/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.9634 - mean_absolute_error: 0.6794 - mean_squared_error: 0.9634\n",
            "Epoch 990: val_loss improved from 0.97379 to 0.97278, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9634 - mean_absolute_error: 0.6794 - mean_squared_error: 0.9634 - val_loss: 0.9728 - val_mean_absolute_error: 0.6961 - val_mean_squared_error: 0.9728\n",
            "Epoch 991/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.9524 - mean_absolute_error: 0.6747 - mean_squared_error: 0.9524\n",
            "Epoch 991: val_loss did not improve from 0.97278\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9552 - mean_absolute_error: 0.6756 - mean_squared_error: 0.9552 - val_loss: 0.9867 - val_mean_absolute_error: 0.6967 - val_mean_squared_error: 0.9867\n",
            "Epoch 992/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.9551 - mean_absolute_error: 0.6757 - mean_squared_error: 0.9551\n",
            "Epoch 992: val_loss improved from 0.97278 to 0.96981, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9576 - mean_absolute_error: 0.6780 - mean_squared_error: 0.9576 - val_loss: 0.9698 - val_mean_absolute_error: 0.6880 - val_mean_squared_error: 0.9698\n",
            "Epoch 993/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.9450 - mean_absolute_error: 0.6729 - mean_squared_error: 0.9450\n",
            "Epoch 993: val_loss did not improve from 0.96981\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9518 - mean_absolute_error: 0.6754 - mean_squared_error: 0.9518 - val_loss: 0.9817 - val_mean_absolute_error: 0.6967 - val_mean_squared_error: 0.9817\n",
            "Epoch 994/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.9510 - mean_absolute_error: 0.6767 - mean_squared_error: 0.9510\n",
            "Epoch 994: val_loss improved from 0.96981 to 0.96368, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9530 - mean_absolute_error: 0.6773 - mean_squared_error: 0.9530 - val_loss: 0.9637 - val_mean_absolute_error: 0.6875 - val_mean_squared_error: 0.9637\n",
            "Epoch 995/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.9581 - mean_absolute_error: 0.6800 - mean_squared_error: 0.9581\n",
            "Epoch 995: val_loss improved from 0.96368 to 0.96184, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9518 - mean_absolute_error: 0.6773 - mean_squared_error: 0.9518 - val_loss: 0.9618 - val_mean_absolute_error: 0.6838 - val_mean_squared_error: 0.9618\n",
            "Epoch 996/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.9622 - mean_absolute_error: 0.6756 - mean_squared_error: 0.9622\n",
            "Epoch 996: val_loss did not improve from 0.96184\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9493 - mean_absolute_error: 0.6725 - mean_squared_error: 0.9493 - val_loss: 0.9641 - val_mean_absolute_error: 0.6875 - val_mean_squared_error: 0.9641\n",
            "Epoch 997/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.9440 - mean_absolute_error: 0.6718 - mean_squared_error: 0.9440\n",
            "Epoch 997: val_loss did not improve from 0.96184\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9473 - mean_absolute_error: 0.6737 - mean_squared_error: 0.9473 - val_loss: 0.9661 - val_mean_absolute_error: 0.6948 - val_mean_squared_error: 0.9661\n",
            "Epoch 998/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.9457 - mean_absolute_error: 0.6764 - mean_squared_error: 0.9457\n",
            "Epoch 998: val_loss did not improve from 0.96184\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9450 - mean_absolute_error: 0.6755 - mean_squared_error: 0.9450 - val_loss: 0.9677 - val_mean_absolute_error: 0.6882 - val_mean_squared_error: 0.9677\n",
            "Epoch 999/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.9436 - mean_absolute_error: 0.6729 - mean_squared_error: 0.9436\n",
            "Epoch 999: val_loss improved from 0.96184 to 0.95562, saving model to best_model5.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9472 - mean_absolute_error: 0.6740 - mean_squared_error: 0.9472 - val_loss: 0.9556 - val_mean_absolute_error: 0.6796 - val_mean_squared_error: 0.9556\n",
            "Epoch 1000/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.9352 - mean_absolute_error: 0.6673 - mean_squared_error: 0.9352\n",
            "Epoch 1000: val_loss did not improve from 0.95562\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9417 - mean_absolute_error: 0.6709 - mean_squared_error: 0.9417 - val_loss: 0.9575 - val_mean_absolute_error: 0.6895 - val_mean_squared_error: 0.9575\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f848ab71d10>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = load_model('best_model5.h5')\n",
        "\n",
        "z_predict_test5 = model5.predict(Z_test)\n",
        "\n",
        "plt.plot(z_predict_test5,z_test,'.')\n",
        "\n",
        "print('MSE:', mean_squared_error(z_test, z_predict_test5))\n",
        "print('MAE:', mean_absolute_error(z_test, z_predict_test5))\n",
        "print('RMSE:', mean_squared_error(z_test, z_predict_test5)**0.5)\n",
        "print('Spearman R:', spearmanr(z_test, z_predict_test5))\n",
        "print('R2:', r2_score(z_test, z_predict_test5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "bAIgHjo2QrLb",
        "outputId": "965a3fe7-92ea-4a07-8d97-3c7638ae592d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 0s 1ms/step\n",
            "MSE: 0.9283389198247768\n",
            "MAE: 0.6750339419843607\n",
            "RMSE: 0.9635034612417211\n",
            "Spearman R: SpearmanrResult(correlation=0.8589514923279434, pvalue=0.0)\n",
            "R2: 0.7396610509311848\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1 capa escondida, 100 neuronas:\n",
        "\n",
        "model6 = Sequential()\n",
        "#model.add(Dense(100, input_dim=2, activation='sigmoid'))\n",
        "model6.add(Dense(100, input_dim=2, activation='sigmoid'))\n",
        "model6.add(Dense(1, activation='linear'))\n",
        "\n",
        "model6.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error', 'mean_squared_error'])\n",
        "model6.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYVt281iUwrn",
        "outputId": "f2589df6-06b1-4a1f-bffe-3660cfd603d0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_11 (Dense)            (None, 100)               300       \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 401\n",
            "Trainable params: 401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ajuste:\n",
        "es6 = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "mc6 = ModelCheckpoint('best_model6.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)"
      ],
      "metadata": {
        "id": "7zlad7-EU3_5"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model6.fit(Z_train, z_train, epochs=1000, batch_size=20, validation_split=0.3, shuffle=True, verbose=True, callbacks=[es6,mc6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFrjD-pyU9cC",
        "outputId": "f279473a-3bb9-47d5-f4c9-3dd889630cd4"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 3.7612 - mean_absolute_error: 1.2601 - mean_squared_error: 3.7612\n",
            "Epoch 1: val_loss improved from inf to 3.42833, saving model to best_model6.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.6723 - mean_absolute_error: 1.2417 - mean_squared_error: 3.6723 - val_loss: 3.4283 - val_mean_absolute_error: 1.1591 - val_mean_squared_error: 3.4283\n",
            "Epoch 2/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 3.4552 - mean_absolute_error: 1.1893 - mean_squared_error: 3.4552\n",
            "Epoch 2: val_loss improved from 3.42833 to 3.27471, saving model to best_model6.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.4683 - mean_absolute_error: 1.1894 - mean_squared_error: 3.4683 - val_loss: 3.2747 - val_mean_absolute_error: 1.1768 - val_mean_squared_error: 3.2747\n",
            "Epoch 3/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 3.3146 - mean_absolute_error: 1.1789 - mean_squared_error: 3.3146\n",
            "Epoch 3: val_loss improved from 3.27471 to 3.18875, saving model to best_model6.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.3243 - mean_absolute_error: 1.1819 - mean_squared_error: 3.3243 - val_loss: 3.1887 - val_mean_absolute_error: 1.1948 - val_mean_squared_error: 3.1887\n",
            "Epoch 4/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 3.2446 - mean_absolute_error: 1.1984 - mean_squared_error: 3.2446\n",
            "Epoch 4: val_loss improved from 3.18875 to 3.09335, saving model to best_model6.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.2392 - mean_absolute_error: 1.1987 - mean_squared_error: 3.2392 - val_loss: 3.0934 - val_mean_absolute_error: 1.1848 - val_mean_squared_error: 3.0934\n",
            "Epoch 5/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 3.2067 - mean_absolute_error: 1.2181 - mean_squared_error: 3.2067\n",
            "Epoch 5: val_loss improved from 3.09335 to 3.06985, saving model to best_model6.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1926 - mean_absolute_error: 1.2168 - mean_squared_error: 3.1926 - val_loss: 3.0698 - val_mean_absolute_error: 1.2075 - val_mean_squared_error: 3.0698\n",
            "Epoch 6/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 3.1526 - mean_absolute_error: 1.2285 - mean_squared_error: 3.1526\n",
            "Epoch 6: val_loss improved from 3.06985 to 3.06012, saving model to best_model6.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1748 - mean_absolute_error: 1.2339 - mean_squared_error: 3.1748 - val_loss: 3.0601 - val_mean_absolute_error: 1.2218 - val_mean_squared_error: 3.0601\n",
            "Epoch 7/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 3.1107 - mean_absolute_error: 1.2361 - mean_squared_error: 3.1107\n",
            "Epoch 7: val_loss improved from 3.06012 to 3.05192, saving model to best_model6.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1593 - mean_absolute_error: 1.2470 - mean_squared_error: 3.1593 - val_loss: 3.0519 - val_mean_absolute_error: 1.2304 - val_mean_squared_error: 3.0519\n",
            "Epoch 8/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 3.1485 - mean_absolute_error: 1.2537 - mean_squared_error: 3.1485\n",
            "Epoch 8: val_loss did not improve from 3.05192\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1644 - mean_absolute_error: 1.2549 - mean_squared_error: 3.1644 - val_loss: 3.0579 - val_mean_absolute_error: 1.2397 - val_mean_squared_error: 3.0579\n",
            "Epoch 9/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 3.2211 - mean_absolute_error: 1.2750 - mean_squared_error: 3.2211\n",
            "Epoch 9: val_loss improved from 3.05192 to 3.03348, saving model to best_model6.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1702 - mean_absolute_error: 1.2655 - mean_squared_error: 3.1702 - val_loss: 3.0335 - val_mean_absolute_error: 1.2320 - val_mean_squared_error: 3.0335\n",
            "Epoch 10/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 3.1623 - mean_absolute_error: 1.2633 - mean_squared_error: 3.1623\n",
            "Epoch 10: val_loss did not improve from 3.03348\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1623 - mean_absolute_error: 1.2633 - mean_squared_error: 3.1623 - val_loss: 3.0401 - val_mean_absolute_error: 1.2370 - val_mean_squared_error: 3.0401\n",
            "Epoch 11/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 3.1552 - mean_absolute_error: 1.2618 - mean_squared_error: 3.1552\n",
            "Epoch 11: val_loss did not improve from 3.03348\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1552 - mean_absolute_error: 1.2618 - mean_squared_error: 3.1552 - val_loss: 3.0508 - val_mean_absolute_error: 1.2431 - val_mean_squared_error: 3.0508\n",
            "Epoch 12/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 3.1611 - mean_absolute_error: 1.2645 - mean_squared_error: 3.1611\n",
            "Epoch 12: val_loss did not improve from 3.03348\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1700 - mean_absolute_error: 1.2660 - mean_squared_error: 3.1700 - val_loss: 3.0336 - val_mean_absolute_error: 1.2365 - val_mean_squared_error: 3.0336\n",
            "Epoch 13/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 3.1717 - mean_absolute_error: 1.2669 - mean_squared_error: 3.1717\n",
            "Epoch 13: val_loss did not improve from 3.03348\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1644 - mean_absolute_error: 1.2673 - mean_squared_error: 3.1644 - val_loss: 3.0341 - val_mean_absolute_error: 1.2370 - val_mean_squared_error: 3.0341\n",
            "Epoch 14/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 3.1742 - mean_absolute_error: 1.2670 - mean_squared_error: 3.1742\n",
            "Epoch 14: val_loss did not improve from 3.03348\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1609 - mean_absolute_error: 1.2692 - mean_squared_error: 3.1609 - val_loss: 3.0344 - val_mean_absolute_error: 1.2350 - val_mean_squared_error: 3.0344\n",
            "Epoch 15/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 3.1653 - mean_absolute_error: 1.2669 - mean_squared_error: 3.1653\n",
            "Epoch 15: val_loss did not improve from 3.03348\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1595 - mean_absolute_error: 1.2660 - mean_squared_error: 3.1595 - val_loss: 3.0353 - val_mean_absolute_error: 1.2371 - val_mean_squared_error: 3.0353\n",
            "Epoch 16/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 3.1622 - mean_absolute_error: 1.2686 - mean_squared_error: 3.1622\n",
            "Epoch 16: val_loss did not improve from 3.03348\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1629 - mean_absolute_error: 1.2670 - mean_squared_error: 3.1629 - val_loss: 3.0671 - val_mean_absolute_error: 1.2503 - val_mean_squared_error: 3.0671\n",
            "Epoch 17/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 3.1618 - mean_absolute_error: 1.2664 - mean_squared_error: 3.1618\n",
            "Epoch 17: val_loss did not improve from 3.03348\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1594 - mean_absolute_error: 1.2661 - mean_squared_error: 3.1594 - val_loss: 3.0395 - val_mean_absolute_error: 1.2361 - val_mean_squared_error: 3.0395\n",
            "Epoch 18/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 3.1487 - mean_absolute_error: 1.2620 - mean_squared_error: 3.1487\n",
            "Epoch 18: val_loss did not improve from 3.03348\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1593 - mean_absolute_error: 1.2647 - mean_squared_error: 3.1593 - val_loss: 3.0552 - val_mean_absolute_error: 1.2464 - val_mean_squared_error: 3.0552\n",
            "Epoch 19/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 3.1990 - mean_absolute_error: 1.2755 - mean_squared_error: 3.1990\n",
            "Epoch 19: val_loss did not improve from 3.03348\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1634 - mean_absolute_error: 1.2696 - mean_squared_error: 3.1634 - val_loss: 3.0405 - val_mean_absolute_error: 1.2374 - val_mean_squared_error: 3.0405\n",
            "Epoch 19: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f848aba1750>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = load_model('best_model6.h5')\n",
        "\n",
        "z_predict_test6 = model6.predict(Z_test)\n",
        "\n",
        "plt.plot(z_predict_test6,z_test,'.')\n",
        "\n",
        "print('MSE:', mean_squared_error(z_test, z_predict_test6))\n",
        "print('MAE:', mean_absolute_error(z_test, z_predict_test6))\n",
        "print('RMSE:', mean_squared_error(z_test, z_predict_test6)**0.5)\n",
        "print('Spearman R:', spearmanr(z_test, z_predict_test6))\n",
        "print('R2:', r2_score(z_test, z_predict_test6))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "oYHl0bUCVCaD",
        "outputId": "754a8453-11b2-4c1d-ed92-aa33f8ba7bc6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 0s 1ms/step\n",
            "MSE: 3.0289539951904043\n",
            "MAE: 1.231689433157667\n",
            "RMSE: 1.7403890355867002\n",
            "Spearman R: SpearmanrResult(correlation=0.5304863496095943, pvalue=1.9883500288311236e-217)\n",
            "R2: 0.15057455521255325\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1 capa escondida, 1000 neuronas:\n",
        "\n",
        "model7 = Sequential()\n",
        "#model.add(Dense(100, input_dim=2, activation='sigmoid'))\n",
        "model7.add(Dense(1000, input_dim=2, activation='sigmoid'))\n",
        "model7.add(Dense(1, activation='linear'))\n",
        "\n",
        "model7.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error', 'mean_squared_error'])\n",
        "model7.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhBMzqQyWT7B",
        "outputId": "f0176c32-92f4-43fb-9cd3-8fd12fa49f8d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_13 (Dense)            (None, 1000)              3000      \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1)                 1001      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,001\n",
            "Trainable params: 4,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ajuste:\n",
        "es7 = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "mc7 = ModelCheckpoint('best_model7.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)"
      ],
      "metadata": {
        "id": "ypyfcKDXWaXL"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model7.fit(Z_train, z_train, epochs=1000, batch_size=20, validation_split=0.3, shuffle=True, verbose=True, callbacks=[es7,mc7])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7r8QSSiWeVJ",
        "outputId": "71106a74-ad22-4201-e2cf-a6c376629ace"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 3.6718 - mean_absolute_error: 1.2505 - mean_squared_error: 3.6718\n",
            "Epoch 1: val_loss improved from inf to 3.40712, saving model to best_model7.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.6444 - mean_absolute_error: 1.2482 - mean_squared_error: 3.6444 - val_loss: 3.4071 - val_mean_absolute_error: 1.3007 - val_mean_squared_error: 3.4071\n",
            "Epoch 2/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 3.3297 - mean_absolute_error: 1.2230 - mean_squared_error: 3.3297\n",
            "Epoch 2: val_loss improved from 3.40712 to 3.09329, saving model to best_model7.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 3.3264 - mean_absolute_error: 1.2239 - mean_squared_error: 3.3264 - val_loss: 3.0933 - val_mean_absolute_error: 1.1834 - val_mean_squared_error: 3.0933\n",
            "Epoch 3/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 3.2368 - mean_absolute_error: 1.2542 - mean_squared_error: 3.2368\n",
            "Epoch 3: val_loss improved from 3.09329 to 3.07061, saving model to best_model7.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.2231 - mean_absolute_error: 1.2513 - mean_squared_error: 3.2231 - val_loss: 3.0706 - val_mean_absolute_error: 1.2155 - val_mean_squared_error: 3.0706\n",
            "Epoch 4/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 3.2214 - mean_absolute_error: 1.2646 - mean_squared_error: 3.2214\n",
            "Epoch 4: val_loss improved from 3.07061 to 3.04164, saving model to best_model7.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.2244 - mean_absolute_error: 1.2656 - mean_squared_error: 3.2244 - val_loss: 3.0416 - val_mean_absolute_error: 1.2275 - val_mean_squared_error: 3.0416\n",
            "Epoch 5/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 3.2485 - mean_absolute_error: 1.2875 - mean_squared_error: 3.2485\n",
            "Epoch 5: val_loss did not improve from 3.04164\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.2435 - mean_absolute_error: 1.2864 - mean_squared_error: 3.2435 - val_loss: 3.0689 - val_mean_absolute_error: 1.2435 - val_mean_squared_error: 3.0689\n",
            "Epoch 6/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 3.1830 - mean_absolute_error: 1.2714 - mean_squared_error: 3.1830\n",
            "Epoch 6: val_loss did not improve from 3.04164\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1924 - mean_absolute_error: 1.2716 - mean_squared_error: 3.1924 - val_loss: 3.1179 - val_mean_absolute_error: 1.2617 - val_mean_squared_error: 3.1179\n",
            "Epoch 7/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 3.2481 - mean_absolute_error: 1.2886 - mean_squared_error: 3.2481\n",
            "Epoch 7: val_loss did not improve from 3.04164\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.2605 - mean_absolute_error: 1.2905 - mean_squared_error: 3.2605 - val_loss: 3.0467 - val_mean_absolute_error: 1.2348 - val_mean_squared_error: 3.0467\n",
            "Epoch 8/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 3.1888 - mean_absolute_error: 1.2711 - mean_squared_error: 3.1888\n",
            "Epoch 8: val_loss did not improve from 3.04164\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1939 - mean_absolute_error: 1.2718 - mean_squared_error: 3.1939 - val_loss: 3.0605 - val_mean_absolute_error: 1.2439 - val_mean_squared_error: 3.0605\n",
            "Epoch 9/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 3.2703 - mean_absolute_error: 1.2922 - mean_squared_error: 3.2703\n",
            "Epoch 9: val_loss improved from 3.04164 to 3.04010, saving model to best_model7.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.2669 - mean_absolute_error: 1.2920 - mean_squared_error: 3.2669 - val_loss: 3.0401 - val_mean_absolute_error: 1.2371 - val_mean_squared_error: 3.0401\n",
            "Epoch 10/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 3.1956 - mean_absolute_error: 1.2820 - mean_squared_error: 3.1956\n",
            "Epoch 10: val_loss did not improve from 3.04010\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 3.2236 - mean_absolute_error: 1.2870 - mean_squared_error: 3.2236 - val_loss: 3.0795 - val_mean_absolute_error: 1.2501 - val_mean_squared_error: 3.0795\n",
            "Epoch 11/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 3.2134 - mean_absolute_error: 1.2829 - mean_squared_error: 3.2134\n",
            "Epoch 11: val_loss did not improve from 3.04010\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 3.2185 - mean_absolute_error: 1.2835 - mean_squared_error: 3.2185 - val_loss: 3.0901 - val_mean_absolute_error: 1.2537 - val_mean_squared_error: 3.0901\n",
            "Epoch 12/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 3.2371 - mean_absolute_error: 1.2881 - mean_squared_error: 3.2371\n",
            "Epoch 12: val_loss improved from 3.04010 to 3.03859, saving model to best_model7.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 3.2363 - mean_absolute_error: 1.2884 - mean_squared_error: 3.2363 - val_loss: 3.0386 - val_mean_absolute_error: 1.2379 - val_mean_squared_error: 3.0386\n",
            "Epoch 13/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 3.2439 - mean_absolute_error: 1.2926 - mean_squared_error: 3.2439\n",
            "Epoch 13: val_loss did not improve from 3.03859\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.2392 - mean_absolute_error: 1.2907 - mean_squared_error: 3.2392 - val_loss: 3.0730 - val_mean_absolute_error: 1.2411 - val_mean_squared_error: 3.0730\n",
            "Epoch 14/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 3.3123 - mean_absolute_error: 1.3098 - mean_squared_error: 3.3123\n",
            "Epoch 14: val_loss did not improve from 3.03859\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.3003 - mean_absolute_error: 1.3077 - mean_squared_error: 3.3003 - val_loss: 3.1896 - val_mean_absolute_error: 1.2673 - val_mean_squared_error: 3.1896\n",
            "Epoch 15/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 3.2395 - mean_absolute_error: 1.2808 - mean_squared_error: 3.2395\n",
            "Epoch 15: val_loss did not improve from 3.03859\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.2295 - mean_absolute_error: 1.2796 - mean_squared_error: 3.2295 - val_loss: 3.1487 - val_mean_absolute_error: 1.2631 - val_mean_squared_error: 3.1487\n",
            "Epoch 16/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 3.2097 - mean_absolute_error: 1.2813 - mean_squared_error: 3.2097\n",
            "Epoch 16: val_loss did not improve from 3.03859\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.2140 - mean_absolute_error: 1.2818 - mean_squared_error: 3.2140 - val_loss: 3.0849 - val_mean_absolute_error: 1.2443 - val_mean_squared_error: 3.0849\n",
            "Epoch 17/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 3.1890 - mean_absolute_error: 1.2717 - mean_squared_error: 3.1890\n",
            "Epoch 17: val_loss did not improve from 3.03859\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.2172 - mean_absolute_error: 1.2781 - mean_squared_error: 3.2172 - val_loss: 3.1361 - val_mean_absolute_error: 1.2719 - val_mean_squared_error: 3.1361\n",
            "Epoch 18/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 3.2205 - mean_absolute_error: 1.2856 - mean_squared_error: 3.2205\n",
            "Epoch 18: val_loss did not improve from 3.03859\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.2395 - mean_absolute_error: 1.2865 - mean_squared_error: 3.2395 - val_loss: 3.0693 - val_mean_absolute_error: 1.2458 - val_mean_squared_error: 3.0693\n",
            "Epoch 19/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 3.2368 - mean_absolute_error: 1.2869 - mean_squared_error: 3.2368\n",
            "Epoch 19: val_loss did not improve from 3.03859\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.2269 - mean_absolute_error: 1.2846 - mean_squared_error: 3.2269 - val_loss: 3.0401 - val_mean_absolute_error: 1.2311 - val_mean_squared_error: 3.0401\n",
            "Epoch 20/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 3.2566 - mean_absolute_error: 1.2855 - mean_squared_error: 3.2566\n",
            "Epoch 20: val_loss did not improve from 3.03859\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.2494 - mean_absolute_error: 1.2860 - mean_squared_error: 3.2494 - val_loss: 3.0441 - val_mean_absolute_error: 1.2334 - val_mean_squared_error: 3.0441\n",
            "Epoch 21/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 3.2554 - mean_absolute_error: 1.2883 - mean_squared_error: 3.2554\n",
            "Epoch 21: val_loss did not improve from 3.03859\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.2621 - mean_absolute_error: 1.2904 - mean_squared_error: 3.2621 - val_loss: 3.1772 - val_mean_absolute_error: 1.2665 - val_mean_squared_error: 3.1772\n",
            "Epoch 22/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 3.2571 - mean_absolute_error: 1.2972 - mean_squared_error: 3.2571\n",
            "Epoch 22: val_loss did not improve from 3.03859\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.2630 - mean_absolute_error: 1.2971 - mean_squared_error: 3.2630 - val_loss: 3.0386 - val_mean_absolute_error: 1.2323 - val_mean_squared_error: 3.0386\n",
            "Epoch 22: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8486dd8810>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = load_model('best_model7.h5')\n",
        "\n",
        "z_predict_test7 = model7.predict(Z_test)\n",
        "\n",
        "plt.plot(z_predict_test7,z_test,'.')\n",
        "\n",
        "print('MSE:', mean_squared_error(z_test, z_predict_test7))\n",
        "print('MAE:', mean_absolute_error(z_test, z_predict_test7))\n",
        "print('RMSE:', mean_squared_error(z_test, z_predict_test7)**0.5)\n",
        "print('Spearman R:', spearmanr(z_test, z_predict_test7))\n",
        "print('R2:', r2_score(z_test, z_predict_test7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "TxKUq4AJWlM9",
        "outputId": "7a6909b0-3b16-4a2d-e9f6-24d2f0f01ce9"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 0s 1ms/step\n",
            "MSE: 3.0343892117795757\n",
            "MAE: 1.2275662277734607\n",
            "RMSE: 1.7419498304427643\n",
            "Spearman R: SpearmanrResult(correlation=0.5317902097544677, pvalue=1.1000477610261494e-218)\n",
            "R2: 0.14905032893638537\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2 capas escondidas, 5 neuronas:\n",
        "\n",
        "model8 = Sequential()\n",
        "#model.add(Dense(100, input_dim=2, activation='sigmoid'))\n",
        "model8.add(Dense(5, input_dim=2, activation='sigmoid'))\n",
        "model8.add(Dense(5, activation='sigmoid'))\n",
        "model8.add(Dense(1, activation='linear'))\n",
        "\n",
        "model8.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error', 'mean_squared_error'])\n",
        "model8.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZgxHrOMkBCk",
        "outputId": "164e955d-525b-4b15-f4bc-c36f37b391ef"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_15 (Dense)            (None, 5)                 15        \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51\n",
            "Trainable params: 51\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ajuste:\n",
        "es8 = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "mc8 = ModelCheckpoint('best_model8.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)"
      ],
      "metadata": {
        "id": "5IvdvYjBkQ0g"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model8.fit(Z_train, z_train, epochs=1000, batch_size=20, validation_split=0.3, shuffle=True, verbose=True, callbacks=[es8,mc8])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2-8PXrGkXma",
        "outputId": "49dbb002-71b5-4e3f-f522-fc0f4b3d17fb"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 3.8695 - mean_absolute_error: 1.2033 - mean_squared_error: 3.8695\n",
            "Epoch 1: val_loss improved from inf to 3.62401, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.8697 - mean_absolute_error: 1.2044 - mean_squared_error: 3.8697 - val_loss: 3.6240 - val_mean_absolute_error: 1.2019 - val_mean_squared_error: 3.6240\n",
            "Epoch 2/1000\n",
            "215/245 [=========================>....] - ETA: 0s - loss: 3.7261 - mean_absolute_error: 1.2337 - mean_squared_error: 3.7261\n",
            "Epoch 2: val_loss improved from 3.62401 to 3.61613, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.7437 - mean_absolute_error: 1.2351 - mean_squared_error: 3.7437 - val_loss: 3.6161 - val_mean_absolute_error: 1.2275 - val_mean_squared_error: 3.6161\n",
            "Epoch 3/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 3.7240 - mean_absolute_error: 1.2455 - mean_squared_error: 3.7240\n",
            "Epoch 3: val_loss improved from 3.61613 to 3.60666, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.7324 - mean_absolute_error: 1.2449 - mean_squared_error: 3.7324 - val_loss: 3.6067 - val_mean_absolute_error: 1.2237 - val_mean_squared_error: 3.6067\n",
            "Epoch 4/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 3.7349 - mean_absolute_error: 1.2427 - mean_squared_error: 3.7349\n",
            "Epoch 4: val_loss improved from 3.60666 to 3.59470, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.7212 - mean_absolute_error: 1.2405 - mean_squared_error: 3.7212 - val_loss: 3.5947 - val_mean_absolute_error: 1.2280 - val_mean_squared_error: 3.5947\n",
            "Epoch 5/1000\n",
            "218/245 [=========================>....] - ETA: 0s - loss: 3.7490 - mean_absolute_error: 1.2499 - mean_squared_error: 3.7490\n",
            "Epoch 5: val_loss improved from 3.59470 to 3.57410, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.7036 - mean_absolute_error: 1.2397 - mean_squared_error: 3.7036 - val_loss: 3.5741 - val_mean_absolute_error: 1.2274 - val_mean_squared_error: 3.5741\n",
            "Epoch 6/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 3.6762 - mean_absolute_error: 1.2327 - mean_squared_error: 3.6762\n",
            "Epoch 6: val_loss improved from 3.57410 to 3.53686, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.6762 - mean_absolute_error: 1.2327 - mean_squared_error: 3.6762 - val_loss: 3.5369 - val_mean_absolute_error: 1.2101 - val_mean_squared_error: 3.5369\n",
            "Epoch 7/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 3.6427 - mean_absolute_error: 1.2235 - mean_squared_error: 3.6427\n",
            "Epoch 7: val_loss improved from 3.53686 to 3.48957, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.6328 - mean_absolute_error: 1.2224 - mean_squared_error: 3.6328 - val_loss: 3.4896 - val_mean_absolute_error: 1.2060 - val_mean_squared_error: 3.4896\n",
            "Epoch 8/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 3.5613 - mean_absolute_error: 1.2080 - mean_squared_error: 3.5613\n",
            "Epoch 8: val_loss improved from 3.48957 to 3.42402, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.5750 - mean_absolute_error: 1.2102 - mean_squared_error: 3.5750 - val_loss: 3.4240 - val_mean_absolute_error: 1.1873 - val_mean_squared_error: 3.4240\n",
            "Epoch 9/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 3.4943 - mean_absolute_error: 1.1907 - mean_squared_error: 3.4943\n",
            "Epoch 9: val_loss improved from 3.42402 to 3.34912, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.5052 - mean_absolute_error: 1.1937 - mean_squared_error: 3.5052 - val_loss: 3.3491 - val_mean_absolute_error: 1.1632 - val_mean_squared_error: 3.3491\n",
            "Epoch 10/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 3.4383 - mean_absolute_error: 1.1731 - mean_squared_error: 3.4383\n",
            "Epoch 10: val_loss improved from 3.34912 to 3.27377, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.4290 - mean_absolute_error: 1.1717 - mean_squared_error: 3.4290 - val_loss: 3.2738 - val_mean_absolute_error: 1.1543 - val_mean_squared_error: 3.2738\n",
            "Epoch 11/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 3.3245 - mean_absolute_error: 1.1703 - mean_squared_error: 3.3245\n",
            "Epoch 11: val_loss improved from 3.27377 to 3.19459, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.3508 - mean_absolute_error: 1.1710 - mean_squared_error: 3.3508 - val_loss: 3.1946 - val_mean_absolute_error: 1.1371 - val_mean_squared_error: 3.1946\n",
            "Epoch 12/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 3.3087 - mean_absolute_error: 1.1682 - mean_squared_error: 3.3087\n",
            "Epoch 12: val_loss improved from 3.19459 to 3.12853, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.2819 - mean_absolute_error: 1.1653 - mean_squared_error: 3.2819 - val_loss: 3.1285 - val_mean_absolute_error: 1.1474 - val_mean_squared_error: 3.1285\n",
            "Epoch 13/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 3.2020 - mean_absolute_error: 1.1686 - mean_squared_error: 3.2020\n",
            "Epoch 13: val_loss improved from 3.12853 to 3.07886, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.2170 - mean_absolute_error: 1.1705 - mean_squared_error: 3.2170 - val_loss: 3.0789 - val_mean_absolute_error: 1.1600 - val_mean_squared_error: 3.0789\n",
            "Epoch 14/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 3.1814 - mean_absolute_error: 1.1850 - mean_squared_error: 3.1814\n",
            "Epoch 14: val_loss improved from 3.07886 to 3.02790, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1657 - mean_absolute_error: 1.1852 - mean_squared_error: 3.1657 - val_loss: 3.0279 - val_mean_absolute_error: 1.1648 - val_mean_squared_error: 3.0279\n",
            "Epoch 15/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 3.1273 - mean_absolute_error: 1.1946 - mean_squared_error: 3.1273\n",
            "Epoch 15: val_loss improved from 3.02790 to 2.99771, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.1277 - mean_absolute_error: 1.1952 - mean_squared_error: 3.1277 - val_loss: 2.9977 - val_mean_absolute_error: 1.1786 - val_mean_squared_error: 2.9977\n",
            "Epoch 16/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 3.0957 - mean_absolute_error: 1.2053 - mean_squared_error: 3.0957\n",
            "Epoch 16: val_loss improved from 2.99771 to 2.97875, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0960 - mean_absolute_error: 1.2051 - mean_squared_error: 3.0960 - val_loss: 2.9787 - val_mean_absolute_error: 1.1914 - val_mean_squared_error: 2.9787\n",
            "Epoch 17/1000\n",
            "214/245 [=========================>....] - ETA: 0s - loss: 3.0935 - mean_absolute_error: 1.2201 - mean_squared_error: 3.0935\n",
            "Epoch 17: val_loss improved from 2.97875 to 2.95902, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0759 - mean_absolute_error: 1.2166 - mean_squared_error: 3.0759 - val_loss: 2.9590 - val_mean_absolute_error: 1.1996 - val_mean_squared_error: 2.9590\n",
            "Epoch 18/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 3.0395 - mean_absolute_error: 1.2219 - mean_squared_error: 3.0395\n",
            "Epoch 18: val_loss improved from 2.95902 to 2.93973, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0559 - mean_absolute_error: 1.2251 - mean_squared_error: 3.0559 - val_loss: 2.9397 - val_mean_absolute_error: 1.1996 - val_mean_squared_error: 2.9397\n",
            "Epoch 19/1000\n",
            "215/245 [=========================>....] - ETA: 0s - loss: 3.0285 - mean_absolute_error: 1.2247 - mean_squared_error: 3.0285\n",
            "Epoch 19: val_loss improved from 2.93973 to 2.93087, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0473 - mean_absolute_error: 1.2297 - mean_squared_error: 3.0473 - val_loss: 2.9309 - val_mean_absolute_error: 1.2094 - val_mean_squared_error: 2.9309\n",
            "Epoch 20/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 3.0706 - mean_absolute_error: 1.2436 - mean_squared_error: 3.0706\n",
            "Epoch 20: val_loss improved from 2.93087 to 2.92404, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0362 - mean_absolute_error: 1.2367 - mean_squared_error: 3.0362 - val_loss: 2.9240 - val_mean_absolute_error: 1.2148 - val_mean_squared_error: 2.9240\n",
            "Epoch 21/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 3.0186 - mean_absolute_error: 1.2386 - mean_squared_error: 3.0186\n",
            "Epoch 21: val_loss improved from 2.92404 to 2.91887, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0277 - mean_absolute_error: 1.2391 - mean_squared_error: 3.0277 - val_loss: 2.9189 - val_mean_absolute_error: 1.2193 - val_mean_squared_error: 2.9189\n",
            "Epoch 22/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 3.0375 - mean_absolute_error: 1.2457 - mean_squared_error: 3.0375\n",
            "Epoch 22: val_loss improved from 2.91887 to 2.91242, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0207 - mean_absolute_error: 1.2440 - mean_squared_error: 3.0207 - val_loss: 2.9124 - val_mean_absolute_error: 1.2211 - val_mean_squared_error: 2.9124\n",
            "Epoch 23/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 3.0184 - mean_absolute_error: 1.2466 - mean_squared_error: 3.0184\n",
            "Epoch 23: val_loss improved from 2.91242 to 2.90923, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0161 - mean_absolute_error: 1.2461 - mean_squared_error: 3.0161 - val_loss: 2.9092 - val_mean_absolute_error: 1.2237 - val_mean_squared_error: 2.9092\n",
            "Epoch 24/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 3.0080 - mean_absolute_error: 1.2465 - mean_squared_error: 3.0080\n",
            "Epoch 24: val_loss improved from 2.90923 to 2.90527, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0105 - mean_absolute_error: 1.2461 - mean_squared_error: 3.0105 - val_loss: 2.9053 - val_mean_absolute_error: 1.2256 - val_mean_squared_error: 2.9053\n",
            "Epoch 25/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 3.0133 - mean_absolute_error: 1.2485 - mean_squared_error: 3.0133\n",
            "Epoch 25: val_loss did not improve from 2.90527\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0047 - mean_absolute_error: 1.2477 - mean_squared_error: 3.0047 - val_loss: 2.9093 - val_mean_absolute_error: 1.2316 - val_mean_squared_error: 2.9093\n",
            "Epoch 26/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 3.0139 - mean_absolute_error: 1.2505 - mean_squared_error: 3.0139\n",
            "Epoch 26: val_loss improved from 2.90527 to 2.89852, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0007 - mean_absolute_error: 1.2497 - mean_squared_error: 3.0007 - val_loss: 2.8985 - val_mean_absolute_error: 1.2266 - val_mean_squared_error: 2.8985\n",
            "Epoch 27/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.9960 - mean_absolute_error: 1.2480 - mean_squared_error: 2.9960\n",
            "Epoch 27: val_loss improved from 2.89852 to 2.89535, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9967 - mean_absolute_error: 1.2488 - mean_squared_error: 2.9967 - val_loss: 2.8954 - val_mean_absolute_error: 1.2277 - val_mean_squared_error: 2.8954\n",
            "Epoch 28/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.9956 - mean_absolute_error: 1.2469 - mean_squared_error: 2.9956\n",
            "Epoch 28: val_loss improved from 2.89535 to 2.89358, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9931 - mean_absolute_error: 1.2482 - mean_squared_error: 2.9931 - val_loss: 2.8936 - val_mean_absolute_error: 1.2292 - val_mean_squared_error: 2.8936\n",
            "Epoch 29/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.9471 - mean_absolute_error: 1.2386 - mean_squared_error: 2.9471\n",
            "Epoch 29: val_loss improved from 2.89358 to 2.89029, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9881 - mean_absolute_error: 1.2482 - mean_squared_error: 2.9881 - val_loss: 2.8903 - val_mean_absolute_error: 1.2291 - val_mean_squared_error: 2.8903\n",
            "Epoch 30/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.9428 - mean_absolute_error: 1.2376 - mean_squared_error: 2.9428\n",
            "Epoch 30: val_loss improved from 2.89029 to 2.88763, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9843 - mean_absolute_error: 1.2458 - mean_squared_error: 2.9843 - val_loss: 2.8876 - val_mean_absolute_error: 1.2292 - val_mean_squared_error: 2.8876\n",
            "Epoch 31/1000\n",
            "215/245 [=========================>....] - ETA: 0s - loss: 3.0068 - mean_absolute_error: 1.2480 - mean_squared_error: 3.0068\n",
            "Epoch 31: val_loss improved from 2.88763 to 2.88274, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9816 - mean_absolute_error: 1.2477 - mean_squared_error: 2.9816 - val_loss: 2.8827 - val_mean_absolute_error: 1.2279 - val_mean_squared_error: 2.8827\n",
            "Epoch 32/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.9554 - mean_absolute_error: 1.2415 - mean_squared_error: 2.9554\n",
            "Epoch 32: val_loss did not improve from 2.88274\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9765 - mean_absolute_error: 1.2460 - mean_squared_error: 2.9765 - val_loss: 2.8830 - val_mean_absolute_error: 1.2298 - val_mean_squared_error: 2.8830\n",
            "Epoch 33/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.9603 - mean_absolute_error: 1.2444 - mean_squared_error: 2.9603\n",
            "Epoch 33: val_loss improved from 2.88274 to 2.87662, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9730 - mean_absolute_error: 1.2463 - mean_squared_error: 2.9730 - val_loss: 2.8766 - val_mean_absolute_error: 1.2269 - val_mean_squared_error: 2.8766\n",
            "Epoch 34/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 2.9617 - mean_absolute_error: 1.2416 - mean_squared_error: 2.9617\n",
            "Epoch 34: val_loss improved from 2.87662 to 2.87271, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9685 - mean_absolute_error: 1.2458 - mean_squared_error: 2.9685 - val_loss: 2.8727 - val_mean_absolute_error: 1.2264 - val_mean_squared_error: 2.8727\n",
            "Epoch 35/1000\n",
            "217/245 [=========================>....] - ETA: 0s - loss: 2.9879 - mean_absolute_error: 1.2469 - mean_squared_error: 2.9879\n",
            "Epoch 35: val_loss improved from 2.87271 to 2.86851, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9624 - mean_absolute_error: 1.2449 - mean_squared_error: 2.9624 - val_loss: 2.8685 - val_mean_absolute_error: 1.2250 - val_mean_squared_error: 2.8685\n",
            "Epoch 36/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 2.9743 - mean_absolute_error: 1.2418 - mean_squared_error: 2.9743\n",
            "Epoch 36: val_loss improved from 2.86851 to 2.86454, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9586 - mean_absolute_error: 1.2422 - mean_squared_error: 2.9586 - val_loss: 2.8645 - val_mean_absolute_error: 1.2234 - val_mean_squared_error: 2.8645\n",
            "Epoch 37/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.9668 - mean_absolute_error: 1.2440 - mean_squared_error: 2.9668\n",
            "Epoch 37: val_loss improved from 2.86454 to 2.86183, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 6ms/step - loss: 2.9548 - mean_absolute_error: 1.2418 - mean_squared_error: 2.9548 - val_loss: 2.8618 - val_mean_absolute_error: 1.2237 - val_mean_squared_error: 2.8618\n",
            "Epoch 38/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.9257 - mean_absolute_error: 1.2338 - mean_squared_error: 2.9257\n",
            "Epoch 38: val_loss improved from 2.86183 to 2.85882, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9496 - mean_absolute_error: 1.2402 - mean_squared_error: 2.9496 - val_loss: 2.8588 - val_mean_absolute_error: 1.2233 - val_mean_squared_error: 2.8588\n",
            "Epoch 39/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.9856 - mean_absolute_error: 1.2519 - mean_squared_error: 2.9856\n",
            "Epoch 39: val_loss improved from 2.85882 to 2.85370, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9447 - mean_absolute_error: 1.2402 - mean_squared_error: 2.9447 - val_loss: 2.8537 - val_mean_absolute_error: 1.2216 - val_mean_squared_error: 2.8537\n",
            "Epoch 40/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.9728 - mean_absolute_error: 1.2468 - mean_squared_error: 2.9728\n",
            "Epoch 40: val_loss improved from 2.85370 to 2.84898, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9403 - mean_absolute_error: 1.2381 - mean_squared_error: 2.9403 - val_loss: 2.8490 - val_mean_absolute_error: 1.2203 - val_mean_squared_error: 2.8490\n",
            "Epoch 41/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.9303 - mean_absolute_error: 1.2358 - mean_squared_error: 2.9303\n",
            "Epoch 41: val_loss improved from 2.84898 to 2.84776, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9356 - mean_absolute_error: 1.2367 - mean_squared_error: 2.9356 - val_loss: 2.8478 - val_mean_absolute_error: 1.2211 - val_mean_squared_error: 2.8478\n",
            "Epoch 42/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.9290 - mean_absolute_error: 1.2346 - mean_squared_error: 2.9290\n",
            "Epoch 42: val_loss improved from 2.84776 to 2.84244, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9312 - mean_absolute_error: 1.2363 - mean_squared_error: 2.9312 - val_loss: 2.8424 - val_mean_absolute_error: 1.2195 - val_mean_squared_error: 2.8424\n",
            "Epoch 43/1000\n",
            "217/245 [=========================>....] - ETA: 0s - loss: 2.9221 - mean_absolute_error: 1.2308 - mean_squared_error: 2.9221\n",
            "Epoch 43: val_loss improved from 2.84244 to 2.84067, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9260 - mean_absolute_error: 1.2330 - mean_squared_error: 2.9260 - val_loss: 2.8407 - val_mean_absolute_error: 1.2193 - val_mean_squared_error: 2.8407\n",
            "Epoch 44/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.9179 - mean_absolute_error: 1.2307 - mean_squared_error: 2.9179\n",
            "Epoch 44: val_loss improved from 2.84067 to 2.83335, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9217 - mean_absolute_error: 1.2335 - mean_squared_error: 2.9217 - val_loss: 2.8334 - val_mean_absolute_error: 1.2171 - val_mean_squared_error: 2.8334\n",
            "Epoch 45/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.9034 - mean_absolute_error: 1.2313 - mean_squared_error: 2.9034\n",
            "Epoch 45: val_loss improved from 2.83335 to 2.82816, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9158 - mean_absolute_error: 1.2314 - mean_squared_error: 2.9158 - val_loss: 2.8282 - val_mean_absolute_error: 1.2152 - val_mean_squared_error: 2.8282\n",
            "Epoch 46/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.9236 - mean_absolute_error: 1.2321 - mean_squared_error: 2.9236\n",
            "Epoch 46: val_loss improved from 2.82816 to 2.82567, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9117 - mean_absolute_error: 1.2302 - mean_squared_error: 2.9117 - val_loss: 2.8257 - val_mean_absolute_error: 1.2157 - val_mean_squared_error: 2.8257\n",
            "Epoch 47/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.9145 - mean_absolute_error: 1.2302 - mean_squared_error: 2.9145\n",
            "Epoch 47: val_loss improved from 2.82567 to 2.81885, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.9053 - mean_absolute_error: 1.2296 - mean_squared_error: 2.9053 - val_loss: 2.8188 - val_mean_absolute_error: 1.2121 - val_mean_squared_error: 2.8188\n",
            "Epoch 48/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.8931 - mean_absolute_error: 1.2251 - mean_squared_error: 2.8931\n",
            "Epoch 48: val_loss improved from 2.81885 to 2.81548, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9015 - mean_absolute_error: 1.2262 - mean_squared_error: 2.9015 - val_loss: 2.8155 - val_mean_absolute_error: 1.2121 - val_mean_squared_error: 2.8155\n",
            "Epoch 49/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.8759 - mean_absolute_error: 1.2229 - mean_squared_error: 2.8759\n",
            "Epoch 49: val_loss improved from 2.81548 to 2.81010, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8957 - mean_absolute_error: 1.2263 - mean_squared_error: 2.8957 - val_loss: 2.8101 - val_mean_absolute_error: 1.2098 - val_mean_squared_error: 2.8101\n",
            "Epoch 50/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.8966 - mean_absolute_error: 1.2216 - mean_squared_error: 2.8966\n",
            "Epoch 50: val_loss improved from 2.81010 to 2.80572, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8910 - mean_absolute_error: 1.2241 - mean_squared_error: 2.8910 - val_loss: 2.8057 - val_mean_absolute_error: 1.2100 - val_mean_squared_error: 2.8057\n",
            "Epoch 51/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 2.9009 - mean_absolute_error: 1.2277 - mean_squared_error: 2.9009\n",
            "Epoch 51: val_loss improved from 2.80572 to 2.80050, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8843 - mean_absolute_error: 1.2234 - mean_squared_error: 2.8843 - val_loss: 2.8005 - val_mean_absolute_error: 1.2079 - val_mean_squared_error: 2.8005\n",
            "Epoch 52/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.8800 - mean_absolute_error: 1.2213 - mean_squared_error: 2.8800\n",
            "Epoch 52: val_loss improved from 2.80050 to 2.79838, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.8800 - mean_absolute_error: 1.2213 - mean_squared_error: 2.8800 - val_loss: 2.7984 - val_mean_absolute_error: 1.2085 - val_mean_squared_error: 2.7984\n",
            "Epoch 53/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.8769 - mean_absolute_error: 1.2242 - mean_squared_error: 2.8769\n",
            "Epoch 53: val_loss improved from 2.79838 to 2.79294, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.8747 - mean_absolute_error: 1.2209 - mean_squared_error: 2.8747 - val_loss: 2.7929 - val_mean_absolute_error: 1.2064 - val_mean_squared_error: 2.7929\n",
            "Epoch 54/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.8970 - mean_absolute_error: 1.2238 - mean_squared_error: 2.8970\n",
            "Epoch 54: val_loss improved from 2.79294 to 2.78818, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.8695 - mean_absolute_error: 1.2179 - mean_squared_error: 2.8695 - val_loss: 2.7882 - val_mean_absolute_error: 1.2052 - val_mean_squared_error: 2.7882\n",
            "Epoch 55/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.8857 - mean_absolute_error: 1.2220 - mean_squared_error: 2.8857\n",
            "Epoch 55: val_loss improved from 2.78818 to 2.78317, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.8643 - mean_absolute_error: 1.2184 - mean_squared_error: 2.8643 - val_loss: 2.7832 - val_mean_absolute_error: 1.2035 - val_mean_squared_error: 2.7832\n",
            "Epoch 56/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.8320 - mean_absolute_error: 1.2057 - mean_squared_error: 2.8320\n",
            "Epoch 56: val_loss improved from 2.78317 to 2.78100, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.8591 - mean_absolute_error: 1.2134 - mean_squared_error: 2.8591 - val_loss: 2.7810 - val_mean_absolute_error: 1.2032 - val_mean_squared_error: 2.7810\n",
            "Epoch 57/1000\n",
            "217/245 [=========================>....] - ETA: 0s - loss: 2.9333 - mean_absolute_error: 1.2329 - mean_squared_error: 2.9333\n",
            "Epoch 57: val_loss improved from 2.78100 to 2.77383, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.8535 - mean_absolute_error: 1.2139 - mean_squared_error: 2.8535 - val_loss: 2.7738 - val_mean_absolute_error: 1.2016 - val_mean_squared_error: 2.7738\n",
            "Epoch 58/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.8425 - mean_absolute_error: 1.2116 - mean_squared_error: 2.8425\n",
            "Epoch 58: val_loss improved from 2.77383 to 2.76827, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.8489 - mean_absolute_error: 1.2122 - mean_squared_error: 2.8489 - val_loss: 2.7683 - val_mean_absolute_error: 1.1988 - val_mean_squared_error: 2.7683\n",
            "Epoch 59/1000\n",
            "218/245 [=========================>....] - ETA: 0s - loss: 2.8653 - mean_absolute_error: 1.2164 - mean_squared_error: 2.8653\n",
            "Epoch 59: val_loss improved from 2.76827 to 2.76506, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8430 - mean_absolute_error: 1.2121 - mean_squared_error: 2.8430 - val_loss: 2.7651 - val_mean_absolute_error: 1.1985 - val_mean_squared_error: 2.7651\n",
            "Epoch 60/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 2.8630 - mean_absolute_error: 1.2128 - mean_squared_error: 2.8630\n",
            "Epoch 60: val_loss improved from 2.76506 to 2.76086, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8385 - mean_absolute_error: 1.2096 - mean_squared_error: 2.8385 - val_loss: 2.7609 - val_mean_absolute_error: 1.1971 - val_mean_squared_error: 2.7609\n",
            "Epoch 61/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.8489 - mean_absolute_error: 1.2094 - mean_squared_error: 2.8489\n",
            "Epoch 61: val_loss improved from 2.76086 to 2.75546, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.8331 - mean_absolute_error: 1.2096 - mean_squared_error: 2.8331 - val_loss: 2.7555 - val_mean_absolute_error: 1.1952 - val_mean_squared_error: 2.7555\n",
            "Epoch 62/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.8249 - mean_absolute_error: 1.2040 - mean_squared_error: 2.8249\n",
            "Epoch 62: val_loss improved from 2.75546 to 2.75124, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8280 - mean_absolute_error: 1.2058 - mean_squared_error: 2.8280 - val_loss: 2.7512 - val_mean_absolute_error: 1.1936 - val_mean_squared_error: 2.7512\n",
            "Epoch 63/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.8318 - mean_absolute_error: 1.2093 - mean_squared_error: 2.8318\n",
            "Epoch 63: val_loss improved from 2.75124 to 2.74371, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8234 - mean_absolute_error: 1.2058 - mean_squared_error: 2.8234 - val_loss: 2.7437 - val_mean_absolute_error: 1.1904 - val_mean_squared_error: 2.7437\n",
            "Epoch 64/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.8089 - mean_absolute_error: 1.2026 - mean_squared_error: 2.8089\n",
            "Epoch 64: val_loss improved from 2.74371 to 2.73922, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.8168 - mean_absolute_error: 1.2025 - mean_squared_error: 2.8168 - val_loss: 2.7392 - val_mean_absolute_error: 1.1900 - val_mean_squared_error: 2.7392\n",
            "Epoch 65/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.7749 - mean_absolute_error: 1.1946 - mean_squared_error: 2.7749\n",
            "Epoch 65: val_loss improved from 2.73922 to 2.73804, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.8116 - mean_absolute_error: 1.2013 - mean_squared_error: 2.8116 - val_loss: 2.7380 - val_mean_absolute_error: 1.1895 - val_mean_squared_error: 2.7380\n",
            "Epoch 66/1000\n",
            "214/245 [=========================>....] - ETA: 0s - loss: 2.7658 - mean_absolute_error: 1.1927 - mean_squared_error: 2.7658\n",
            "Epoch 66: val_loss improved from 2.73804 to 2.72992, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.8056 - mean_absolute_error: 1.1993 - mean_squared_error: 2.8056 - val_loss: 2.7299 - val_mean_absolute_error: 1.1872 - val_mean_squared_error: 2.7299\n",
            "Epoch 67/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.7567 - mean_absolute_error: 1.1888 - mean_squared_error: 2.7567\n",
            "Epoch 67: val_loss improved from 2.72992 to 2.72610, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8017 - mean_absolute_error: 1.1986 - mean_squared_error: 2.8017 - val_loss: 2.7261 - val_mean_absolute_error: 1.1863 - val_mean_squared_error: 2.7261\n",
            "Epoch 68/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.8100 - mean_absolute_error: 1.2000 - mean_squared_error: 2.8100\n",
            "Epoch 68: val_loss improved from 2.72610 to 2.72271, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.7949 - mean_absolute_error: 1.1975 - mean_squared_error: 2.7949 - val_loss: 2.7227 - val_mean_absolute_error: 1.1854 - val_mean_squared_error: 2.7227\n",
            "Epoch 69/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.7926 - mean_absolute_error: 1.1950 - mean_squared_error: 2.7926\n",
            "Epoch 69: val_loss improved from 2.72271 to 2.71229, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7888 - mean_absolute_error: 1.1952 - mean_squared_error: 2.7888 - val_loss: 2.7123 - val_mean_absolute_error: 1.1820 - val_mean_squared_error: 2.7123\n",
            "Epoch 70/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.7935 - mean_absolute_error: 1.1920 - mean_squared_error: 2.7935\n",
            "Epoch 70: val_loss improved from 2.71229 to 2.70924, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.7819 - mean_absolute_error: 1.1928 - mean_squared_error: 2.7819 - val_loss: 2.7092 - val_mean_absolute_error: 1.1806 - val_mean_squared_error: 2.7092\n",
            "Epoch 71/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.7967 - mean_absolute_error: 1.1959 - mean_squared_error: 2.7967\n",
            "Epoch 71: val_loss improved from 2.70924 to 2.70079, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.7763 - mean_absolute_error: 1.1913 - mean_squared_error: 2.7763 - val_loss: 2.7008 - val_mean_absolute_error: 1.1773 - val_mean_squared_error: 2.7008\n",
            "Epoch 72/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.8242 - mean_absolute_error: 1.1958 - mean_squared_error: 2.8242\n",
            "Epoch 72: val_loss improved from 2.70079 to 2.69660, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7694 - mean_absolute_error: 1.1878 - mean_squared_error: 2.7694 - val_loss: 2.6966 - val_mean_absolute_error: 1.1761 - val_mean_squared_error: 2.6966\n",
            "Epoch 73/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.7589 - mean_absolute_error: 1.1894 - mean_squared_error: 2.7589\n",
            "Epoch 73: val_loss improved from 2.69660 to 2.68798, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.7625 - mean_absolute_error: 1.1871 - mean_squared_error: 2.7625 - val_loss: 2.6880 - val_mean_absolute_error: 1.1730 - val_mean_squared_error: 2.6880\n",
            "Epoch 74/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.7305 - mean_absolute_error: 1.1804 - mean_squared_error: 2.7305\n",
            "Epoch 74: val_loss improved from 2.68798 to 2.68261, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.7558 - mean_absolute_error: 1.1846 - mean_squared_error: 2.7558 - val_loss: 2.6826 - val_mean_absolute_error: 1.1701 - val_mean_squared_error: 2.6826\n",
            "Epoch 75/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.7818 - mean_absolute_error: 1.1898 - mean_squared_error: 2.7818\n",
            "Epoch 75: val_loss improved from 2.68261 to 2.67522, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.7494 - mean_absolute_error: 1.1824 - mean_squared_error: 2.7494 - val_loss: 2.6752 - val_mean_absolute_error: 1.1688 - val_mean_squared_error: 2.6752\n",
            "Epoch 76/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.7476 - mean_absolute_error: 1.1795 - mean_squared_error: 2.7476\n",
            "Epoch 76: val_loss improved from 2.67522 to 2.66900, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7425 - mean_absolute_error: 1.1799 - mean_squared_error: 2.7425 - val_loss: 2.6690 - val_mean_absolute_error: 1.1673 - val_mean_squared_error: 2.6690\n",
            "Epoch 77/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.7384 - mean_absolute_error: 1.1768 - mean_squared_error: 2.7384\n",
            "Epoch 77: val_loss improved from 2.66900 to 2.66319, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7342 - mean_absolute_error: 1.1774 - mean_squared_error: 2.7342 - val_loss: 2.6632 - val_mean_absolute_error: 1.1659 - val_mean_squared_error: 2.6632\n",
            "Epoch 78/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.7177 - mean_absolute_error: 1.1759 - mean_squared_error: 2.7177\n",
            "Epoch 78: val_loss improved from 2.66319 to 2.66012, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7270 - mean_absolute_error: 1.1762 - mean_squared_error: 2.7270 - val_loss: 2.6601 - val_mean_absolute_error: 1.1647 - val_mean_squared_error: 2.6601\n",
            "Epoch 79/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.7258 - mean_absolute_error: 1.1744 - mean_squared_error: 2.7258\n",
            "Epoch 79: val_loss improved from 2.66012 to 2.64863, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.7215 - mean_absolute_error: 1.1748 - mean_squared_error: 2.7215 - val_loss: 2.6486 - val_mean_absolute_error: 1.1627 - val_mean_squared_error: 2.6486\n",
            "Epoch 80/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.7217 - mean_absolute_error: 1.1745 - mean_squared_error: 2.7217\n",
            "Epoch 80: val_loss improved from 2.64863 to 2.64254, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.7149 - mean_absolute_error: 1.1732 - mean_squared_error: 2.7149 - val_loss: 2.6425 - val_mean_absolute_error: 1.1611 - val_mean_squared_error: 2.6425\n",
            "Epoch 81/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.7358 - mean_absolute_error: 1.1754 - mean_squared_error: 2.7358\n",
            "Epoch 81: val_loss improved from 2.64254 to 2.63664, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.7087 - mean_absolute_error: 1.1734 - mean_squared_error: 2.7087 - val_loss: 2.6366 - val_mean_absolute_error: 1.1600 - val_mean_squared_error: 2.6366\n",
            "Epoch 82/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.6977 - mean_absolute_error: 1.1713 - mean_squared_error: 2.6977\n",
            "Epoch 82: val_loss improved from 2.63664 to 2.63060, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7022 - mean_absolute_error: 1.1713 - mean_squared_error: 2.7022 - val_loss: 2.6306 - val_mean_absolute_error: 1.1583 - val_mean_squared_error: 2.6306\n",
            "Epoch 83/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.7173 - mean_absolute_error: 1.1748 - mean_squared_error: 2.7173\n",
            "Epoch 83: val_loss improved from 2.63060 to 2.62291, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.6950 - mean_absolute_error: 1.1704 - mean_squared_error: 2.6950 - val_loss: 2.6229 - val_mean_absolute_error: 1.1569 - val_mean_squared_error: 2.6229\n",
            "Epoch 84/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.6900 - mean_absolute_error: 1.1690 - mean_squared_error: 2.6900\n",
            "Epoch 84: val_loss improved from 2.62291 to 2.61830, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6898 - mean_absolute_error: 1.1683 - mean_squared_error: 2.6898 - val_loss: 2.6183 - val_mean_absolute_error: 1.1548 - val_mean_squared_error: 2.6183\n",
            "Epoch 85/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.7021 - mean_absolute_error: 1.1721 - mean_squared_error: 2.7021\n",
            "Epoch 85: val_loss improved from 2.61830 to 2.61208, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.6831 - mean_absolute_error: 1.1670 - mean_squared_error: 2.6831 - val_loss: 2.6121 - val_mean_absolute_error: 1.1543 - val_mean_squared_error: 2.6121\n",
            "Epoch 86/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 2.6943 - mean_absolute_error: 1.1683 - mean_squared_error: 2.6943\n",
            "Epoch 86: val_loss improved from 2.61208 to 2.60685, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6775 - mean_absolute_error: 1.1656 - mean_squared_error: 2.6775 - val_loss: 2.6068 - val_mean_absolute_error: 1.1529 - val_mean_squared_error: 2.6068\n",
            "Epoch 87/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.6635 - mean_absolute_error: 1.1618 - mean_squared_error: 2.6635\n",
            "Epoch 87: val_loss improved from 2.60685 to 2.59981, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6711 - mean_absolute_error: 1.1642 - mean_squared_error: 2.6711 - val_loss: 2.5998 - val_mean_absolute_error: 1.1512 - val_mean_squared_error: 2.5998\n",
            "Epoch 88/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.6535 - mean_absolute_error: 1.1583 - mean_squared_error: 2.6535\n",
            "Epoch 88: val_loss improved from 2.59981 to 2.59418, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.6650 - mean_absolute_error: 1.1632 - mean_squared_error: 2.6650 - val_loss: 2.5942 - val_mean_absolute_error: 1.1492 - val_mean_squared_error: 2.5942\n",
            "Epoch 89/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 2.6452 - mean_absolute_error: 1.1583 - mean_squared_error: 2.6452\n",
            "Epoch 89: val_loss improved from 2.59418 to 2.59021, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6590 - mean_absolute_error: 1.1602 - mean_squared_error: 2.6590 - val_loss: 2.5902 - val_mean_absolute_error: 1.1470 - val_mean_squared_error: 2.5902\n",
            "Epoch 90/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.6465 - mean_absolute_error: 1.1606 - mean_squared_error: 2.6465\n",
            "Epoch 90: val_loss improved from 2.59021 to 2.58560, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.6525 - mean_absolute_error: 1.1592 - mean_squared_error: 2.6525 - val_loss: 2.5856 - val_mean_absolute_error: 1.1459 - val_mean_squared_error: 2.5856\n",
            "Epoch 91/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.6125 - mean_absolute_error: 1.1532 - mean_squared_error: 2.6125\n",
            "Epoch 91: val_loss improved from 2.58560 to 2.57622, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6462 - mean_absolute_error: 1.1565 - mean_squared_error: 2.6462 - val_loss: 2.5762 - val_mean_absolute_error: 1.1454 - val_mean_squared_error: 2.5762\n",
            "Epoch 92/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 2.6372 - mean_absolute_error: 1.1558 - mean_squared_error: 2.6372\n",
            "Epoch 92: val_loss improved from 2.57622 to 2.56873, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6401 - mean_absolute_error: 1.1568 - mean_squared_error: 2.6401 - val_loss: 2.5687 - val_mean_absolute_error: 1.1447 - val_mean_squared_error: 2.5687\n",
            "Epoch 93/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.6395 - mean_absolute_error: 1.1564 - mean_squared_error: 2.6395\n",
            "Epoch 93: val_loss improved from 2.56873 to 2.56466, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6349 - mean_absolute_error: 1.1540 - mean_squared_error: 2.6349 - val_loss: 2.5647 - val_mean_absolute_error: 1.1419 - val_mean_squared_error: 2.5647\n",
            "Epoch 94/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.6599 - mean_absolute_error: 1.1602 - mean_squared_error: 2.6599\n",
            "Epoch 94: val_loss improved from 2.56466 to 2.55840, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.6279 - mean_absolute_error: 1.1533 - mean_squared_error: 2.6279 - val_loss: 2.5584 - val_mean_absolute_error: 1.1399 - val_mean_squared_error: 2.5584\n",
            "Epoch 95/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.5918 - mean_absolute_error: 1.1402 - mean_squared_error: 2.5918\n",
            "Epoch 95: val_loss improved from 2.55840 to 2.55451, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6214 - mean_absolute_error: 1.1498 - mean_squared_error: 2.6214 - val_loss: 2.5545 - val_mean_absolute_error: 1.1378 - val_mean_squared_error: 2.5545\n",
            "Epoch 96/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.6229 - mean_absolute_error: 1.1499 - mean_squared_error: 2.6229\n",
            "Epoch 96: val_loss improved from 2.55451 to 2.54740, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6164 - mean_absolute_error: 1.1491 - mean_squared_error: 2.6164 - val_loss: 2.5474 - val_mean_absolute_error: 1.1362 - val_mean_squared_error: 2.5474\n",
            "Epoch 97/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.6133 - mean_absolute_error: 1.1484 - mean_squared_error: 2.6133\n",
            "Epoch 97: val_loss improved from 2.54740 to 2.54277, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6091 - mean_absolute_error: 1.1480 - mean_squared_error: 2.6091 - val_loss: 2.5428 - val_mean_absolute_error: 1.1340 - val_mean_squared_error: 2.5428\n",
            "Epoch 98/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.6035 - mean_absolute_error: 1.1438 - mean_squared_error: 2.6035\n",
            "Epoch 98: val_loss improved from 2.54277 to 2.53498, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6035 - mean_absolute_error: 1.1438 - mean_squared_error: 2.6035 - val_loss: 2.5350 - val_mean_absolute_error: 1.1319 - val_mean_squared_error: 2.5350\n",
            "Epoch 99/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.5995 - mean_absolute_error: 1.1396 - mean_squared_error: 2.5995\n",
            "Epoch 99: val_loss improved from 2.53498 to 2.52883, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5971 - mean_absolute_error: 1.1423 - mean_squared_error: 2.5971 - val_loss: 2.5288 - val_mean_absolute_error: 1.1316 - val_mean_squared_error: 2.5288\n",
            "Epoch 100/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.6252 - mean_absolute_error: 1.1480 - mean_squared_error: 2.6252\n",
            "Epoch 100: val_loss improved from 2.52883 to 2.51910, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5898 - mean_absolute_error: 1.1404 - mean_squared_error: 2.5898 - val_loss: 2.5191 - val_mean_absolute_error: 1.1323 - val_mean_squared_error: 2.5191\n",
            "Epoch 101/1000\n",
            "217/245 [=========================>....] - ETA: 0s - loss: 2.6246 - mean_absolute_error: 1.1464 - mean_squared_error: 2.6246\n",
            "Epoch 101: val_loss improved from 2.51910 to 2.51259, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5835 - mean_absolute_error: 1.1396 - mean_squared_error: 2.5835 - val_loss: 2.5126 - val_mean_absolute_error: 1.1314 - val_mean_squared_error: 2.5126\n",
            "Epoch 102/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.5546 - mean_absolute_error: 1.1350 - mean_squared_error: 2.5546\n",
            "Epoch 102: val_loss improved from 2.51259 to 2.50788, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5762 - mean_absolute_error: 1.1386 - mean_squared_error: 2.5762 - val_loss: 2.5079 - val_mean_absolute_error: 1.1264 - val_mean_squared_error: 2.5079\n",
            "Epoch 103/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.5486 - mean_absolute_error: 1.1331 - mean_squared_error: 2.5486\n",
            "Epoch 103: val_loss improved from 2.50788 to 2.49972, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.5697 - mean_absolute_error: 1.1350 - mean_squared_error: 2.5697 - val_loss: 2.4997 - val_mean_absolute_error: 1.1271 - val_mean_squared_error: 2.4997\n",
            "Epoch 104/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 2.5472 - mean_absolute_error: 1.1321 - mean_squared_error: 2.5472\n",
            "Epoch 104: val_loss improved from 2.49972 to 2.49327, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5651 - mean_absolute_error: 1.1352 - mean_squared_error: 2.5651 - val_loss: 2.4933 - val_mean_absolute_error: 1.1231 - val_mean_squared_error: 2.4933\n",
            "Epoch 105/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 2.5764 - mean_absolute_error: 1.1322 - mean_squared_error: 2.5764\n",
            "Epoch 105: val_loss improved from 2.49327 to 2.48705, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5570 - mean_absolute_error: 1.1316 - mean_squared_error: 2.5570 - val_loss: 2.4870 - val_mean_absolute_error: 1.1205 - val_mean_squared_error: 2.4870\n",
            "Epoch 106/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 2.5414 - mean_absolute_error: 1.1266 - mean_squared_error: 2.5414\n",
            "Epoch 106: val_loss improved from 2.48705 to 2.48257, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5516 - mean_absolute_error: 1.1290 - mean_squared_error: 2.5516 - val_loss: 2.4826 - val_mean_absolute_error: 1.1183 - val_mean_squared_error: 2.4826\n",
            "Epoch 107/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.5388 - mean_absolute_error: 1.1274 - mean_squared_error: 2.5388\n",
            "Epoch 107: val_loss improved from 2.48257 to 2.47385, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.5435 - mean_absolute_error: 1.1270 - mean_squared_error: 2.5435 - val_loss: 2.4739 - val_mean_absolute_error: 1.1160 - val_mean_squared_error: 2.4739\n",
            "Epoch 108/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.5303 - mean_absolute_error: 1.1243 - mean_squared_error: 2.5303\n",
            "Epoch 108: val_loss improved from 2.47385 to 2.46615, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.5362 - mean_absolute_error: 1.1251 - mean_squared_error: 2.5362 - val_loss: 2.4661 - val_mean_absolute_error: 1.1151 - val_mean_squared_error: 2.4661\n",
            "Epoch 109/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 2.5088 - mean_absolute_error: 1.1209 - mean_squared_error: 2.5088\n",
            "Epoch 109: val_loss improved from 2.46615 to 2.46106, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5295 - mean_absolute_error: 1.1225 - mean_squared_error: 2.5295 - val_loss: 2.4611 - val_mean_absolute_error: 1.1129 - val_mean_squared_error: 2.4611\n",
            "Epoch 110/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 2.5221 - mean_absolute_error: 1.1192 - mean_squared_error: 2.5221\n",
            "Epoch 110: val_loss improved from 2.46106 to 2.45194, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5224 - mean_absolute_error: 1.1215 - mean_squared_error: 2.5224 - val_loss: 2.4519 - val_mean_absolute_error: 1.1114 - val_mean_squared_error: 2.4519\n",
            "Epoch 111/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.4992 - mean_absolute_error: 1.1164 - mean_squared_error: 2.4992\n",
            "Epoch 111: val_loss improved from 2.45194 to 2.44517, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5136 - mean_absolute_error: 1.1193 - mean_squared_error: 2.5136 - val_loss: 2.4452 - val_mean_absolute_error: 1.1084 - val_mean_squared_error: 2.4452\n",
            "Epoch 112/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.5077 - mean_absolute_error: 1.1182 - mean_squared_error: 2.5077\n",
            "Epoch 112: val_loss improved from 2.44517 to 2.43872, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5069 - mean_absolute_error: 1.1176 - mean_squared_error: 2.5069 - val_loss: 2.4387 - val_mean_absolute_error: 1.1064 - val_mean_squared_error: 2.4387\n",
            "Epoch 113/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.4777 - mean_absolute_error: 1.1108 - mean_squared_error: 2.4777\n",
            "Epoch 113: val_loss improved from 2.43872 to 2.42911, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4986 - mean_absolute_error: 1.1142 - mean_squared_error: 2.4986 - val_loss: 2.4291 - val_mean_absolute_error: 1.1040 - val_mean_squared_error: 2.4291\n",
            "Epoch 114/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.5258 - mean_absolute_error: 1.1170 - mean_squared_error: 2.5258\n",
            "Epoch 114: val_loss improved from 2.42911 to 2.42031, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4907 - mean_absolute_error: 1.1128 - mean_squared_error: 2.4907 - val_loss: 2.4203 - val_mean_absolute_error: 1.1034 - val_mean_squared_error: 2.4203\n",
            "Epoch 115/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.4719 - mean_absolute_error: 1.1093 - mean_squared_error: 2.4719\n",
            "Epoch 115: val_loss improved from 2.42031 to 2.41211, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.4833 - mean_absolute_error: 1.1104 - mean_squared_error: 2.4833 - val_loss: 2.4121 - val_mean_absolute_error: 1.1009 - val_mean_squared_error: 2.4121\n",
            "Epoch 116/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.4765 - mean_absolute_error: 1.1104 - mean_squared_error: 2.4765\n",
            "Epoch 116: val_loss improved from 2.41211 to 2.40529, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4745 - mean_absolute_error: 1.1094 - mean_squared_error: 2.4745 - val_loss: 2.4053 - val_mean_absolute_error: 1.0983 - val_mean_squared_error: 2.4053\n",
            "Epoch 117/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.4314 - mean_absolute_error: 1.1000 - mean_squared_error: 2.4314\n",
            "Epoch 117: val_loss improved from 2.40529 to 2.39584, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.4668 - mean_absolute_error: 1.1058 - mean_squared_error: 2.4668 - val_loss: 2.3958 - val_mean_absolute_error: 1.0964 - val_mean_squared_error: 2.3958\n",
            "Epoch 118/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.4463 - mean_absolute_error: 1.0967 - mean_squared_error: 2.4463\n",
            "Epoch 118: val_loss improved from 2.39584 to 2.38762, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4564 - mean_absolute_error: 1.1024 - mean_squared_error: 2.4564 - val_loss: 2.3876 - val_mean_absolute_error: 1.0993 - val_mean_squared_error: 2.3876\n",
            "Epoch 119/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.4612 - mean_absolute_error: 1.1085 - mean_squared_error: 2.4612\n",
            "Epoch 119: val_loss improved from 2.38762 to 2.37858, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4502 - mean_absolute_error: 1.1048 - mean_squared_error: 2.4502 - val_loss: 2.3786 - val_mean_absolute_error: 1.0935 - val_mean_squared_error: 2.3786\n",
            "Epoch 120/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.4604 - mean_absolute_error: 1.1042 - mean_squared_error: 2.4604\n",
            "Epoch 120: val_loss improved from 2.37858 to 2.37012, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.4407 - mean_absolute_error: 1.0998 - mean_squared_error: 2.4407 - val_loss: 2.3701 - val_mean_absolute_error: 1.0915 - val_mean_squared_error: 2.3701\n",
            "Epoch 121/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 2.4354 - mean_absolute_error: 1.0950 - mean_squared_error: 2.4354\n",
            "Epoch 121: val_loss improved from 2.37012 to 2.36127, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4321 - mean_absolute_error: 1.0988 - mean_squared_error: 2.4321 - val_loss: 2.3613 - val_mean_absolute_error: 1.0895 - val_mean_squared_error: 2.3613\n",
            "Epoch 122/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.4160 - mean_absolute_error: 1.0928 - mean_squared_error: 2.4160\n",
            "Epoch 122: val_loss improved from 2.36127 to 2.35290, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.4224 - mean_absolute_error: 1.0968 - mean_squared_error: 2.4224 - val_loss: 2.3529 - val_mean_absolute_error: 1.0864 - val_mean_squared_error: 2.3529\n",
            "Epoch 123/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.4087 - mean_absolute_error: 1.0932 - mean_squared_error: 2.4087\n",
            "Epoch 123: val_loss improved from 2.35290 to 2.34228, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4122 - mean_absolute_error: 1.0942 - mean_squared_error: 2.4122 - val_loss: 2.3423 - val_mean_absolute_error: 1.0885 - val_mean_squared_error: 2.3423\n",
            "Epoch 124/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.4026 - mean_absolute_error: 1.0928 - mean_squared_error: 2.4026\n",
            "Epoch 124: val_loss improved from 2.34228 to 2.33203, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4026 - mean_absolute_error: 1.0928 - mean_squared_error: 2.4026 - val_loss: 2.3320 - val_mean_absolute_error: 1.0834 - val_mean_squared_error: 2.3320\n",
            "Epoch 125/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.4019 - mean_absolute_error: 1.0931 - mean_squared_error: 2.4019\n",
            "Epoch 125: val_loss improved from 2.33203 to 2.32554, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3931 - mean_absolute_error: 1.0903 - mean_squared_error: 2.3931 - val_loss: 2.3255 - val_mean_absolute_error: 1.0799 - val_mean_squared_error: 2.3255\n",
            "Epoch 126/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 2.3753 - mean_absolute_error: 1.0840 - mean_squared_error: 2.3753\n",
            "Epoch 126: val_loss improved from 2.32554 to 2.31098, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3824 - mean_absolute_error: 1.0876 - mean_squared_error: 2.3824 - val_loss: 2.3110 - val_mean_absolute_error: 1.0784 - val_mean_squared_error: 2.3110\n",
            "Epoch 127/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.3649 - mean_absolute_error: 1.0845 - mean_squared_error: 2.3649\n",
            "Epoch 127: val_loss improved from 2.31098 to 2.30029, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3722 - mean_absolute_error: 1.0859 - mean_squared_error: 2.3722 - val_loss: 2.3003 - val_mean_absolute_error: 1.0759 - val_mean_squared_error: 2.3003\n",
            "Epoch 128/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.3609 - mean_absolute_error: 1.0824 - mean_squared_error: 2.3609\n",
            "Epoch 128: val_loss improved from 2.30029 to 2.29568, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3591 - mean_absolute_error: 1.0829 - mean_squared_error: 2.3591 - val_loss: 2.2957 - val_mean_absolute_error: 1.0730 - val_mean_squared_error: 2.2957\n",
            "Epoch 129/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.3225 - mean_absolute_error: 1.0771 - mean_squared_error: 2.3225\n",
            "Epoch 129: val_loss improved from 2.29568 to 2.27682, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3489 - mean_absolute_error: 1.0808 - mean_squared_error: 2.3489 - val_loss: 2.2768 - val_mean_absolute_error: 1.0717 - val_mean_squared_error: 2.2768\n",
            "Epoch 130/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.3336 - mean_absolute_error: 1.0762 - mean_squared_error: 2.3336\n",
            "Epoch 130: val_loss improved from 2.27682 to 2.26943, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.3359 - mean_absolute_error: 1.0783 - mean_squared_error: 2.3359 - val_loss: 2.2694 - val_mean_absolute_error: 1.0679 - val_mean_squared_error: 2.2694\n",
            "Epoch 131/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.3237 - mean_absolute_error: 1.0751 - mean_squared_error: 2.3237\n",
            "Epoch 131: val_loss improved from 2.26943 to 2.25687, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3237 - mean_absolute_error: 1.0751 - mean_squared_error: 2.3237 - val_loss: 2.2569 - val_mean_absolute_error: 1.0653 - val_mean_squared_error: 2.2569\n",
            "Epoch 132/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.3153 - mean_absolute_error: 1.0733 - mean_squared_error: 2.3153\n",
            "Epoch 132: val_loss improved from 2.25687 to 2.24107, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 6ms/step - loss: 2.3115 - mean_absolute_error: 1.0724 - mean_squared_error: 2.3115 - val_loss: 2.2411 - val_mean_absolute_error: 1.0642 - val_mean_squared_error: 2.2411\n",
            "Epoch 133/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.3038 - mean_absolute_error: 1.0721 - mean_squared_error: 2.3038\n",
            "Epoch 133: val_loss improved from 2.24107 to 2.23550, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.2962 - mean_absolute_error: 1.0698 - mean_squared_error: 2.2962 - val_loss: 2.2355 - val_mean_absolute_error: 1.0612 - val_mean_squared_error: 2.2355\n",
            "Epoch 134/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.2450 - mean_absolute_error: 1.0586 - mean_squared_error: 2.2450\n",
            "Epoch 134: val_loss improved from 2.23550 to 2.21923, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2876 - mean_absolute_error: 1.0676 - mean_squared_error: 2.2876 - val_loss: 2.2192 - val_mean_absolute_error: 1.0580 - val_mean_squared_error: 2.2192\n",
            "Epoch 135/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.2728 - mean_absolute_error: 1.0655 - mean_squared_error: 2.2728\n",
            "Epoch 135: val_loss improved from 2.21923 to 2.20397, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2728 - mean_absolute_error: 1.0655 - mean_squared_error: 2.2728 - val_loss: 2.2040 - val_mean_absolute_error: 1.0563 - val_mean_squared_error: 2.2040\n",
            "Epoch 136/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.2390 - mean_absolute_error: 1.0552 - mean_squared_error: 2.2390\n",
            "Epoch 136: val_loss improved from 2.20397 to 2.19292, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2592 - mean_absolute_error: 1.0608 - mean_squared_error: 2.2592 - val_loss: 2.1929 - val_mean_absolute_error: 1.0553 - val_mean_squared_error: 2.1929\n",
            "Epoch 137/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.2476 - mean_absolute_error: 1.0588 - mean_squared_error: 2.2476\n",
            "Epoch 137: val_loss improved from 2.19292 to 2.18044, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2458 - mean_absolute_error: 1.0588 - mean_squared_error: 2.2458 - val_loss: 2.1804 - val_mean_absolute_error: 1.0539 - val_mean_squared_error: 2.1804\n",
            "Epoch 138/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 2.2419 - mean_absolute_error: 1.0603 - mean_squared_error: 2.2419\n",
            "Epoch 138: val_loss improved from 2.18044 to 2.16597, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2333 - mean_absolute_error: 1.0571 - mean_squared_error: 2.2333 - val_loss: 2.1660 - val_mean_absolute_error: 1.0462 - val_mean_squared_error: 2.1660\n",
            "Epoch 139/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 2.2223 - mean_absolute_error: 1.0541 - mean_squared_error: 2.2223\n",
            "Epoch 139: val_loss improved from 2.16597 to 2.15477, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2205 - mean_absolute_error: 1.0522 - mean_squared_error: 2.2205 - val_loss: 2.1548 - val_mean_absolute_error: 1.0443 - val_mean_squared_error: 2.1548\n",
            "Epoch 140/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.2070 - mean_absolute_error: 1.0498 - mean_squared_error: 2.2070\n",
            "Epoch 140: val_loss improved from 2.15477 to 2.14473, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.2085 - mean_absolute_error: 1.0503 - mean_squared_error: 2.2085 - val_loss: 2.1447 - val_mean_absolute_error: 1.0419 - val_mean_squared_error: 2.1447\n",
            "Epoch 141/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.1998 - mean_absolute_error: 1.0479 - mean_squared_error: 2.1998\n",
            "Epoch 141: val_loss improved from 2.14473 to 2.13042, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1952 - mean_absolute_error: 1.0471 - mean_squared_error: 2.1952 - val_loss: 2.1304 - val_mean_absolute_error: 1.0392 - val_mean_squared_error: 2.1304\n",
            "Epoch 142/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.1734 - mean_absolute_error: 1.0420 - mean_squared_error: 2.1734\n",
            "Epoch 142: val_loss improved from 2.13042 to 2.11771, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1824 - mean_absolute_error: 1.0445 - mean_squared_error: 2.1824 - val_loss: 2.1177 - val_mean_absolute_error: 1.0379 - val_mean_squared_error: 2.1177\n",
            "Epoch 143/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.1602 - mean_absolute_error: 1.0432 - mean_squared_error: 2.1602\n",
            "Epoch 143: val_loss improved from 2.11771 to 2.10616, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1705 - mean_absolute_error: 1.0425 - mean_squared_error: 2.1705 - val_loss: 2.1062 - val_mean_absolute_error: 1.0338 - val_mean_squared_error: 2.1062\n",
            "Epoch 144/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 2.1782 - mean_absolute_error: 1.0446 - mean_squared_error: 2.1782\n",
            "Epoch 144: val_loss improved from 2.10616 to 2.09508, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1578 - mean_absolute_error: 1.0400 - mean_squared_error: 2.1578 - val_loss: 2.0951 - val_mean_absolute_error: 1.0317 - val_mean_squared_error: 2.0951\n",
            "Epoch 145/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.1428 - mean_absolute_error: 1.0374 - mean_squared_error: 2.1428\n",
            "Epoch 145: val_loss improved from 2.09508 to 2.08330, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1458 - mean_absolute_error: 1.0365 - mean_squared_error: 2.1458 - val_loss: 2.0833 - val_mean_absolute_error: 1.0289 - val_mean_squared_error: 2.0833\n",
            "Epoch 146/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.1355 - mean_absolute_error: 1.0331 - mean_squared_error: 2.1355\n",
            "Epoch 146: val_loss improved from 2.08330 to 2.07161, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1348 - mean_absolute_error: 1.0339 - mean_squared_error: 2.1348 - val_loss: 2.0716 - val_mean_absolute_error: 1.0268 - val_mean_squared_error: 2.0716\n",
            "Epoch 147/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.1378 - mean_absolute_error: 1.0361 - mean_squared_error: 2.1378\n",
            "Epoch 147: val_loss improved from 2.07161 to 2.06050, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1232 - mean_absolute_error: 1.0323 - mean_squared_error: 2.1232 - val_loss: 2.0605 - val_mean_absolute_error: 1.0234 - val_mean_squared_error: 2.0605\n",
            "Epoch 148/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.0930 - mean_absolute_error: 1.0253 - mean_squared_error: 2.0930\n",
            "Epoch 148: val_loss improved from 2.06050 to 2.05139, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1121 - mean_absolute_error: 1.0287 - mean_squared_error: 2.1121 - val_loss: 2.0514 - val_mean_absolute_error: 1.0226 - val_mean_squared_error: 2.0514\n",
            "Epoch 149/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.0992 - mean_absolute_error: 1.0283 - mean_squared_error: 2.0992\n",
            "Epoch 149: val_loss improved from 2.05139 to 2.04274, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1011 - mean_absolute_error: 1.0272 - mean_squared_error: 2.1011 - val_loss: 2.0427 - val_mean_absolute_error: 1.0198 - val_mean_squared_error: 2.0427\n",
            "Epoch 150/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.0919 - mean_absolute_error: 1.0241 - mean_squared_error: 2.0919\n",
            "Epoch 150: val_loss improved from 2.04274 to 2.03010, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0906 - mean_absolute_error: 1.0230 - mean_squared_error: 2.0906 - val_loss: 2.0301 - val_mean_absolute_error: 1.0183 - val_mean_squared_error: 2.0301\n",
            "Epoch 151/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.0888 - mean_absolute_error: 1.0214 - mean_squared_error: 2.0888\n",
            "Epoch 151: val_loss improved from 2.03010 to 2.02064, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0813 - mean_absolute_error: 1.0221 - mean_squared_error: 2.0813 - val_loss: 2.0206 - val_mean_absolute_error: 1.0166 - val_mean_squared_error: 2.0206\n",
            "Epoch 152/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.0709 - mean_absolute_error: 1.0193 - mean_squared_error: 2.0709\n",
            "Epoch 152: val_loss improved from 2.02064 to 2.01362, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0715 - mean_absolute_error: 1.0198 - mean_squared_error: 2.0715 - val_loss: 2.0136 - val_mean_absolute_error: 1.0142 - val_mean_squared_error: 2.0136\n",
            "Epoch 153/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.0606 - mean_absolute_error: 1.0150 - mean_squared_error: 2.0606\n",
            "Epoch 153: val_loss improved from 2.01362 to 2.00608, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0616 - mean_absolute_error: 1.0177 - mean_squared_error: 2.0616 - val_loss: 2.0061 - val_mean_absolute_error: 1.0120 - val_mean_squared_error: 2.0061\n",
            "Epoch 154/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.0514 - mean_absolute_error: 1.0162 - mean_squared_error: 2.0514\n",
            "Epoch 154: val_loss improved from 2.00608 to 1.99514, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0538 - mean_absolute_error: 1.0169 - mean_squared_error: 2.0538 - val_loss: 1.9951 - val_mean_absolute_error: 1.0100 - val_mean_squared_error: 1.9951\n",
            "Epoch 155/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.0402 - mean_absolute_error: 1.0134 - mean_squared_error: 2.0402\n",
            "Epoch 155: val_loss improved from 1.99514 to 1.98478, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0442 - mean_absolute_error: 1.0139 - mean_squared_error: 2.0442 - val_loss: 1.9848 - val_mean_absolute_error: 1.0071 - val_mean_squared_error: 1.9848\n",
            "Epoch 156/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 1.9987 - mean_absolute_error: 1.0061 - mean_squared_error: 1.9987\n",
            "Epoch 156: val_loss improved from 1.98478 to 1.97806, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0347 - mean_absolute_error: 1.0112 - mean_squared_error: 2.0347 - val_loss: 1.9781 - val_mean_absolute_error: 1.0059 - val_mean_squared_error: 1.9781\n",
            "Epoch 157/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.0405 - mean_absolute_error: 1.0116 - mean_squared_error: 2.0405\n",
            "Epoch 157: val_loss improved from 1.97806 to 1.96968, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0283 - mean_absolute_error: 1.0103 - mean_squared_error: 2.0283 - val_loss: 1.9697 - val_mean_absolute_error: 1.0050 - val_mean_squared_error: 1.9697\n",
            "Epoch 158/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.0210 - mean_absolute_error: 1.0096 - mean_squared_error: 2.0210\n",
            "Epoch 158: val_loss improved from 1.96968 to 1.96263, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0194 - mean_absolute_error: 1.0086 - mean_squared_error: 2.0194 - val_loss: 1.9626 - val_mean_absolute_error: 1.0014 - val_mean_squared_error: 1.9626\n",
            "Epoch 159/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.0150 - mean_absolute_error: 1.0072 - mean_squared_error: 2.0150\n",
            "Epoch 159: val_loss improved from 1.96263 to 1.95452, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0112 - mean_absolute_error: 1.0062 - mean_squared_error: 2.0112 - val_loss: 1.9545 - val_mean_absolute_error: 1.0000 - val_mean_squared_error: 1.9545\n",
            "Epoch 160/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.9850 - mean_absolute_error: 0.9961 - mean_squared_error: 1.9850\n",
            "Epoch 160: val_loss improved from 1.95452 to 1.95050, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0042 - mean_absolute_error: 1.0041 - mean_squared_error: 2.0042 - val_loss: 1.9505 - val_mean_absolute_error: 1.0003 - val_mean_squared_error: 1.9505\n",
            "Epoch 161/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.9936 - mean_absolute_error: 1.0018 - mean_squared_error: 1.9936\n",
            "Epoch 161: val_loss improved from 1.95050 to 1.94453, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9986 - mean_absolute_error: 1.0030 - mean_squared_error: 1.9986 - val_loss: 1.9445 - val_mean_absolute_error: 0.9978 - val_mean_squared_error: 1.9445\n",
            "Epoch 162/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.9636 - mean_absolute_error: 0.9976 - mean_squared_error: 1.9636\n",
            "Epoch 162: val_loss improved from 1.94453 to 1.93927, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9909 - mean_absolute_error: 1.0024 - mean_squared_error: 1.9909 - val_loss: 1.9393 - val_mean_absolute_error: 0.9959 - val_mean_squared_error: 1.9393\n",
            "Epoch 163/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 1.9853 - mean_absolute_error: 1.0008 - mean_squared_error: 1.9853\n",
            "Epoch 163: val_loss improved from 1.93927 to 1.92973, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9849 - mean_absolute_error: 0.9993 - mean_squared_error: 1.9849 - val_loss: 1.9297 - val_mean_absolute_error: 0.9941 - val_mean_squared_error: 1.9297\n",
            "Epoch 164/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 1.9795 - mean_absolute_error: 1.0018 - mean_squared_error: 1.9795\n",
            "Epoch 164: val_loss improved from 1.92973 to 1.92544, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9777 - mean_absolute_error: 0.9988 - mean_squared_error: 1.9777 - val_loss: 1.9254 - val_mean_absolute_error: 0.9938 - val_mean_squared_error: 1.9254\n",
            "Epoch 165/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.9727 - mean_absolute_error: 0.9958 - mean_squared_error: 1.9727\n",
            "Epoch 165: val_loss improved from 1.92544 to 1.91932, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9714 - mean_absolute_error: 0.9961 - mean_squared_error: 1.9714 - val_loss: 1.9193 - val_mean_absolute_error: 0.9924 - val_mean_squared_error: 1.9193\n",
            "Epoch 166/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.9738 - mean_absolute_error: 0.9988 - mean_squared_error: 1.9738\n",
            "Epoch 166: val_loss improved from 1.91932 to 1.91387, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9663 - mean_absolute_error: 0.9967 - mean_squared_error: 1.9663 - val_loss: 1.9139 - val_mean_absolute_error: 0.9904 - val_mean_squared_error: 1.9139\n",
            "Epoch 167/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.9557 - mean_absolute_error: 0.9923 - mean_squared_error: 1.9557\n",
            "Epoch 167: val_loss improved from 1.91387 to 1.90657, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9597 - mean_absolute_error: 0.9952 - mean_squared_error: 1.9597 - val_loss: 1.9066 - val_mean_absolute_error: 0.9882 - val_mean_squared_error: 1.9066\n",
            "Epoch 168/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.9580 - mean_absolute_error: 0.9926 - mean_squared_error: 1.9580\n",
            "Epoch 168: val_loss improved from 1.90657 to 1.90178, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9552 - mean_absolute_error: 0.9915 - mean_squared_error: 1.9552 - val_loss: 1.9018 - val_mean_absolute_error: 0.9882 - val_mean_squared_error: 1.9018\n",
            "Epoch 169/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.9406 - mean_absolute_error: 0.9922 - mean_squared_error: 1.9406\n",
            "Epoch 169: val_loss improved from 1.90178 to 1.89866, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9489 - mean_absolute_error: 0.9917 - mean_squared_error: 1.9489 - val_loss: 1.8987 - val_mean_absolute_error: 0.9882 - val_mean_squared_error: 1.8987\n",
            "Epoch 170/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.9508 - mean_absolute_error: 0.9921 - mean_squared_error: 1.9508\n",
            "Epoch 170: val_loss improved from 1.89866 to 1.89191, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9447 - mean_absolute_error: 0.9909 - mean_squared_error: 1.9447 - val_loss: 1.8919 - val_mean_absolute_error: 0.9867 - val_mean_squared_error: 1.8919\n",
            "Epoch 171/1000\n",
            "218/245 [=========================>....] - ETA: 0s - loss: 1.9537 - mean_absolute_error: 0.9941 - mean_squared_error: 1.9537\n",
            "Epoch 171: val_loss improved from 1.89191 to 1.88833, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9389 - mean_absolute_error: 0.9903 - mean_squared_error: 1.9389 - val_loss: 1.8883 - val_mean_absolute_error: 0.9852 - val_mean_squared_error: 1.8883\n",
            "Epoch 172/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.9357 - mean_absolute_error: 0.9895 - mean_squared_error: 1.9357\n",
            "Epoch 172: val_loss improved from 1.88833 to 1.88252, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9349 - mean_absolute_error: 0.9880 - mean_squared_error: 1.9349 - val_loss: 1.8825 - val_mean_absolute_error: 0.9842 - val_mean_squared_error: 1.8825\n",
            "Epoch 173/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.9171 - mean_absolute_error: 0.9833 - mean_squared_error: 1.9171\n",
            "Epoch 173: val_loss improved from 1.88252 to 1.88167, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9300 - mean_absolute_error: 0.9871 - mean_squared_error: 1.9300 - val_loss: 1.8817 - val_mean_absolute_error: 0.9859 - val_mean_squared_error: 1.8817\n",
            "Epoch 174/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.9244 - mean_absolute_error: 0.9876 - mean_squared_error: 1.9244\n",
            "Epoch 174: val_loss improved from 1.88167 to 1.87790, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9244 - mean_absolute_error: 0.9876 - mean_squared_error: 1.9244 - val_loss: 1.8779 - val_mean_absolute_error: 0.9842 - val_mean_squared_error: 1.8779\n",
            "Epoch 175/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.9226 - mean_absolute_error: 0.9865 - mean_squared_error: 1.9226\n",
            "Epoch 175: val_loss improved from 1.87790 to 1.87218, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9202 - mean_absolute_error: 0.9851 - mean_squared_error: 1.9202 - val_loss: 1.8722 - val_mean_absolute_error: 0.9829 - val_mean_squared_error: 1.8722\n",
            "Epoch 176/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 1.8734 - mean_absolute_error: 0.9744 - mean_squared_error: 1.8734\n",
            "Epoch 176: val_loss improved from 1.87218 to 1.86847, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 1.9169 - mean_absolute_error: 0.9849 - mean_squared_error: 1.9169 - val_loss: 1.8685 - val_mean_absolute_error: 0.9819 - val_mean_squared_error: 1.8685\n",
            "Epoch 177/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.9219 - mean_absolute_error: 0.9859 - mean_squared_error: 1.9219\n",
            "Epoch 177: val_loss improved from 1.86847 to 1.86140, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9120 - mean_absolute_error: 0.9843 - mean_squared_error: 1.9120 - val_loss: 1.8614 - val_mean_absolute_error: 0.9809 - val_mean_squared_error: 1.8614\n",
            "Epoch 178/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.9127 - mean_absolute_error: 0.9836 - mean_squared_error: 1.9127\n",
            "Epoch 178: val_loss did not improve from 1.86140\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 1.9087 - mean_absolute_error: 0.9829 - mean_squared_error: 1.9087 - val_loss: 1.8619 - val_mean_absolute_error: 0.9818 - val_mean_squared_error: 1.8619\n",
            "Epoch 179/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.9043 - mean_absolute_error: 0.9836 - mean_squared_error: 1.9043\n",
            "Epoch 179: val_loss improved from 1.86140 to 1.85777, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9044 - mean_absolute_error: 0.9840 - mean_squared_error: 1.9044 - val_loss: 1.8578 - val_mean_absolute_error: 0.9807 - val_mean_squared_error: 1.8578\n",
            "Epoch 180/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.9030 - mean_absolute_error: 0.9814 - mean_squared_error: 1.9030\n",
            "Epoch 180: val_loss did not improve from 1.85777\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8990 - mean_absolute_error: 0.9806 - mean_squared_error: 1.8990 - val_loss: 1.8593 - val_mean_absolute_error: 0.9801 - val_mean_squared_error: 1.8593\n",
            "Epoch 181/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.8959 - mean_absolute_error: 0.9826 - mean_squared_error: 1.8959\n",
            "Epoch 181: val_loss improved from 1.85777 to 1.84884, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8974 - mean_absolute_error: 0.9813 - mean_squared_error: 1.8974 - val_loss: 1.8488 - val_mean_absolute_error: 0.9786 - val_mean_squared_error: 1.8488\n",
            "Epoch 182/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.9008 - mean_absolute_error: 0.9822 - mean_squared_error: 1.9008\n",
            "Epoch 182: val_loss improved from 1.84884 to 1.84581, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8920 - mean_absolute_error: 0.9799 - mean_squared_error: 1.8920 - val_loss: 1.8458 - val_mean_absolute_error: 0.9793 - val_mean_squared_error: 1.8458\n",
            "Epoch 183/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.8928 - mean_absolute_error: 0.9793 - mean_squared_error: 1.8928\n",
            "Epoch 183: val_loss improved from 1.84581 to 1.84385, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8889 - mean_absolute_error: 0.9793 - mean_squared_error: 1.8889 - val_loss: 1.8438 - val_mean_absolute_error: 0.9795 - val_mean_squared_error: 1.8438\n",
            "Epoch 184/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.8813 - mean_absolute_error: 0.9770 - mean_squared_error: 1.8813\n",
            "Epoch 184: val_loss improved from 1.84385 to 1.84035, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8857 - mean_absolute_error: 0.9792 - mean_squared_error: 1.8857 - val_loss: 1.8403 - val_mean_absolute_error: 0.9781 - val_mean_squared_error: 1.8403\n",
            "Epoch 185/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.8692 - mean_absolute_error: 0.9752 - mean_squared_error: 1.8692\n",
            "Epoch 185: val_loss did not improve from 1.84035\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8820 - mean_absolute_error: 0.9788 - mean_squared_error: 1.8820 - val_loss: 1.8408 - val_mean_absolute_error: 0.9770 - val_mean_squared_error: 1.8408\n",
            "Epoch 186/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 1.8833 - mean_absolute_error: 0.9795 - mean_squared_error: 1.8833\n",
            "Epoch 186: val_loss improved from 1.84035 to 1.83617, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8787 - mean_absolute_error: 0.9769 - mean_squared_error: 1.8787 - val_loss: 1.8362 - val_mean_absolute_error: 0.9774 - val_mean_squared_error: 1.8362\n",
            "Epoch 187/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.8689 - mean_absolute_error: 0.9766 - mean_squared_error: 1.8689\n",
            "Epoch 187: val_loss improved from 1.83617 to 1.83207, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8758 - mean_absolute_error: 0.9780 - mean_squared_error: 1.8758 - val_loss: 1.8321 - val_mean_absolute_error: 0.9762 - val_mean_squared_error: 1.8321\n",
            "Epoch 188/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 1.8512 - mean_absolute_error: 0.9721 - mean_squared_error: 1.8512\n",
            "Epoch 188: val_loss improved from 1.83207 to 1.82757, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8719 - mean_absolute_error: 0.9778 - mean_squared_error: 1.8719 - val_loss: 1.8276 - val_mean_absolute_error: 0.9742 - val_mean_squared_error: 1.8276\n",
            "Epoch 189/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.8895 - mean_absolute_error: 0.9820 - mean_squared_error: 1.8895\n",
            "Epoch 189: val_loss improved from 1.82757 to 1.82594, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8689 - mean_absolute_error: 0.9762 - mean_squared_error: 1.8689 - val_loss: 1.8259 - val_mean_absolute_error: 0.9749 - val_mean_squared_error: 1.8259\n",
            "Epoch 190/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.8656 - mean_absolute_error: 0.9754 - mean_squared_error: 1.8656\n",
            "Epoch 190: val_loss did not improve from 1.82594\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8659 - mean_absolute_error: 0.9747 - mean_squared_error: 1.8659 - val_loss: 1.8287 - val_mean_absolute_error: 0.9759 - val_mean_squared_error: 1.8287\n",
            "Epoch 191/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.8579 - mean_absolute_error: 0.9740 - mean_squared_error: 1.8579\n",
            "Epoch 191: val_loss improved from 1.82594 to 1.82172, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8634 - mean_absolute_error: 0.9744 - mean_squared_error: 1.8634 - val_loss: 1.8217 - val_mean_absolute_error: 0.9741 - val_mean_squared_error: 1.8217\n",
            "Epoch 192/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.8571 - mean_absolute_error: 0.9753 - mean_squared_error: 1.8571\n",
            "Epoch 192: val_loss improved from 1.82172 to 1.81840, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8592 - mean_absolute_error: 0.9755 - mean_squared_error: 1.8592 - val_loss: 1.8184 - val_mean_absolute_error: 0.9721 - val_mean_squared_error: 1.8184\n",
            "Epoch 193/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.8563 - mean_absolute_error: 0.9744 - mean_squared_error: 1.8563\n",
            "Epoch 193: val_loss improved from 1.81840 to 1.81476, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8546 - mean_absolute_error: 0.9732 - mean_squared_error: 1.8546 - val_loss: 1.8148 - val_mean_absolute_error: 0.9754 - val_mean_squared_error: 1.8148\n",
            "Epoch 194/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.8642 - mean_absolute_error: 0.9765 - mean_squared_error: 1.8642\n",
            "Epoch 194: val_loss did not improve from 1.81476\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8532 - mean_absolute_error: 0.9743 - mean_squared_error: 1.8532 - val_loss: 1.8173 - val_mean_absolute_error: 0.9735 - val_mean_squared_error: 1.8173\n",
            "Epoch 195/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.8493 - mean_absolute_error: 0.9772 - mean_squared_error: 1.8493\n",
            "Epoch 195: val_loss improved from 1.81476 to 1.81022, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8509 - mean_absolute_error: 0.9745 - mean_squared_error: 1.8509 - val_loss: 1.8102 - val_mean_absolute_error: 0.9732 - val_mean_squared_error: 1.8102\n",
            "Epoch 196/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.8282 - mean_absolute_error: 0.9690 - mean_squared_error: 1.8282\n",
            "Epoch 196: val_loss improved from 1.81022 to 1.80601, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8471 - mean_absolute_error: 0.9739 - mean_squared_error: 1.8471 - val_loss: 1.8060 - val_mean_absolute_error: 0.9712 - val_mean_squared_error: 1.8060\n",
            "Epoch 197/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.8511 - mean_absolute_error: 0.9743 - mean_squared_error: 1.8511\n",
            "Epoch 197: val_loss improved from 1.80601 to 1.80221, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8443 - mean_absolute_error: 0.9723 - mean_squared_error: 1.8443 - val_loss: 1.8022 - val_mean_absolute_error: 0.9703 - val_mean_squared_error: 1.8022\n",
            "Epoch 198/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 1.8487 - mean_absolute_error: 0.9754 - mean_squared_error: 1.8487\n",
            "Epoch 198: val_loss improved from 1.80221 to 1.79979, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8424 - mean_absolute_error: 0.9725 - mean_squared_error: 1.8424 - val_loss: 1.7998 - val_mean_absolute_error: 0.9700 - val_mean_squared_error: 1.7998\n",
            "Epoch 199/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.8310 - mean_absolute_error: 0.9684 - mean_squared_error: 1.8310\n",
            "Epoch 199: val_loss improved from 1.79979 to 1.79915, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8387 - mean_absolute_error: 0.9714 - mean_squared_error: 1.8387 - val_loss: 1.7991 - val_mean_absolute_error: 0.9702 - val_mean_squared_error: 1.7991\n",
            "Epoch 200/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.8575 - mean_absolute_error: 0.9780 - mean_squared_error: 1.8575\n",
            "Epoch 200: val_loss improved from 1.79915 to 1.79549, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8354 - mean_absolute_error: 0.9711 - mean_squared_error: 1.8354 - val_loss: 1.7955 - val_mean_absolute_error: 0.9704 - val_mean_squared_error: 1.7955\n",
            "Epoch 201/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.8281 - mean_absolute_error: 0.9693 - mean_squared_error: 1.8281\n",
            "Epoch 201: val_loss improved from 1.79549 to 1.79247, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8330 - mean_absolute_error: 0.9708 - mean_squared_error: 1.8330 - val_loss: 1.7925 - val_mean_absolute_error: 0.9693 - val_mean_squared_error: 1.7925\n",
            "Epoch 202/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.8265 - mean_absolute_error: 0.9702 - mean_squared_error: 1.8265\n",
            "Epoch 202: val_loss improved from 1.79247 to 1.79239, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8296 - mean_absolute_error: 0.9721 - mean_squared_error: 1.8296 - val_loss: 1.7924 - val_mean_absolute_error: 0.9694 - val_mean_squared_error: 1.7924\n",
            "Epoch 203/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.8353 - mean_absolute_error: 0.9756 - mean_squared_error: 1.8353\n",
            "Epoch 203: val_loss improved from 1.79239 to 1.78990, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8266 - mean_absolute_error: 0.9708 - mean_squared_error: 1.8266 - val_loss: 1.7899 - val_mean_absolute_error: 0.9694 - val_mean_squared_error: 1.7899\n",
            "Epoch 204/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.8281 - mean_absolute_error: 0.9713 - mean_squared_error: 1.8281\n",
            "Epoch 204: val_loss improved from 1.78990 to 1.78446, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8239 - mean_absolute_error: 0.9708 - mean_squared_error: 1.8239 - val_loss: 1.7845 - val_mean_absolute_error: 0.9687 - val_mean_squared_error: 1.7845\n",
            "Epoch 205/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.7979 - mean_absolute_error: 0.9648 - mean_squared_error: 1.7979\n",
            "Epoch 205: val_loss improved from 1.78446 to 1.77929, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8213 - mean_absolute_error: 0.9702 - mean_squared_error: 1.8213 - val_loss: 1.7793 - val_mean_absolute_error: 0.9681 - val_mean_squared_error: 1.7793\n",
            "Epoch 206/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.8125 - mean_absolute_error: 0.9685 - mean_squared_error: 1.8125\n",
            "Epoch 206: val_loss did not improve from 1.77929\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8189 - mean_absolute_error: 0.9708 - mean_squared_error: 1.8189 - val_loss: 1.7794 - val_mean_absolute_error: 0.9684 - val_mean_squared_error: 1.7794\n",
            "Epoch 207/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.8210 - mean_absolute_error: 0.9707 - mean_squared_error: 1.8210\n",
            "Epoch 207: val_loss improved from 1.77929 to 1.77778, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8160 - mean_absolute_error: 0.9690 - mean_squared_error: 1.8160 - val_loss: 1.7778 - val_mean_absolute_error: 0.9693 - val_mean_squared_error: 1.7778\n",
            "Epoch 208/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.8219 - mean_absolute_error: 0.9752 - mean_squared_error: 1.8219\n",
            "Epoch 208: val_loss did not improve from 1.77778\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8131 - mean_absolute_error: 0.9709 - mean_squared_error: 1.8131 - val_loss: 1.7783 - val_mean_absolute_error: 0.9689 - val_mean_squared_error: 1.7783\n",
            "Epoch 209/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.8029 - mean_absolute_error: 0.9682 - mean_squared_error: 1.8029\n",
            "Epoch 209: val_loss improved from 1.77778 to 1.77617, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8109 - mean_absolute_error: 0.9691 - mean_squared_error: 1.8109 - val_loss: 1.7762 - val_mean_absolute_error: 0.9695 - val_mean_squared_error: 1.7762\n",
            "Epoch 210/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.8092 - mean_absolute_error: 0.9713 - mean_squared_error: 1.8092\n",
            "Epoch 210: val_loss improved from 1.77617 to 1.77337, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8073 - mean_absolute_error: 0.9705 - mean_squared_error: 1.8073 - val_loss: 1.7734 - val_mean_absolute_error: 0.9660 - val_mean_squared_error: 1.7734\n",
            "Epoch 211/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.7952 - mean_absolute_error: 0.9648 - mean_squared_error: 1.7952\n",
            "Epoch 211: val_loss improved from 1.77337 to 1.76785, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8055 - mean_absolute_error: 0.9685 - mean_squared_error: 1.8055 - val_loss: 1.7679 - val_mean_absolute_error: 0.9660 - val_mean_squared_error: 1.7679\n",
            "Epoch 212/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.7976 - mean_absolute_error: 0.9672 - mean_squared_error: 1.7976\n",
            "Epoch 212: val_loss improved from 1.76785 to 1.76589, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8025 - mean_absolute_error: 0.9691 - mean_squared_error: 1.8025 - val_loss: 1.7659 - val_mean_absolute_error: 0.9680 - val_mean_squared_error: 1.7659\n",
            "Epoch 213/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.8002 - mean_absolute_error: 0.9686 - mean_squared_error: 1.8002\n",
            "Epoch 213: val_loss improved from 1.76589 to 1.76462, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8002 - mean_absolute_error: 0.9686 - mean_squared_error: 1.8002 - val_loss: 1.7646 - val_mean_absolute_error: 0.9668 - val_mean_squared_error: 1.7646\n",
            "Epoch 214/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.7936 - mean_absolute_error: 0.9688 - mean_squared_error: 1.7936\n",
            "Epoch 214: val_loss did not improve from 1.76462\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7976 - mean_absolute_error: 0.9697 - mean_squared_error: 1.7976 - val_loss: 1.7650 - val_mean_absolute_error: 0.9656 - val_mean_squared_error: 1.7650\n",
            "Epoch 215/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.8070 - mean_absolute_error: 0.9721 - mean_squared_error: 1.8070\n",
            "Epoch 215: val_loss improved from 1.76462 to 1.76232, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7954 - mean_absolute_error: 0.9689 - mean_squared_error: 1.7954 - val_loss: 1.7623 - val_mean_absolute_error: 0.9679 - val_mean_squared_error: 1.7623\n",
            "Epoch 216/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.7834 - mean_absolute_error: 0.9649 - mean_squared_error: 1.7834\n",
            "Epoch 216: val_loss improved from 1.76232 to 1.76145, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7924 - mean_absolute_error: 0.9674 - mean_squared_error: 1.7924 - val_loss: 1.7615 - val_mean_absolute_error: 0.9662 - val_mean_squared_error: 1.7615\n",
            "Epoch 217/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.7961 - mean_absolute_error: 0.9698 - mean_squared_error: 1.7961\n",
            "Epoch 217: val_loss improved from 1.76145 to 1.75257, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7916 - mean_absolute_error: 0.9691 - mean_squared_error: 1.7916 - val_loss: 1.7526 - val_mean_absolute_error: 0.9658 - val_mean_squared_error: 1.7526\n",
            "Epoch 218/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.7870 - mean_absolute_error: 0.9683 - mean_squared_error: 1.7870\n",
            "Epoch 218: val_loss improved from 1.75257 to 1.74987, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7890 - mean_absolute_error: 0.9687 - mean_squared_error: 1.7890 - val_loss: 1.7499 - val_mean_absolute_error: 0.9639 - val_mean_squared_error: 1.7499\n",
            "Epoch 219/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.8231 - mean_absolute_error: 0.9799 - mean_squared_error: 1.8231\n",
            "Epoch 219: val_loss improved from 1.74987 to 1.74886, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7863 - mean_absolute_error: 0.9678 - mean_squared_error: 1.7863 - val_loss: 1.7489 - val_mean_absolute_error: 0.9657 - val_mean_squared_error: 1.7489\n",
            "Epoch 220/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.7894 - mean_absolute_error: 0.9690 - mean_squared_error: 1.7894\n",
            "Epoch 220: val_loss improved from 1.74886 to 1.74731, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7846 - mean_absolute_error: 0.9675 - mean_squared_error: 1.7846 - val_loss: 1.7473 - val_mean_absolute_error: 0.9649 - val_mean_squared_error: 1.7473\n",
            "Epoch 221/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.7869 - mean_absolute_error: 0.9664 - mean_squared_error: 1.7869\n",
            "Epoch 221: val_loss did not improve from 1.74731\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7827 - mean_absolute_error: 0.9663 - mean_squared_error: 1.7827 - val_loss: 1.7486 - val_mean_absolute_error: 0.9650 - val_mean_squared_error: 1.7486\n",
            "Epoch 222/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.7741 - mean_absolute_error: 0.9651 - mean_squared_error: 1.7741\n",
            "Epoch 222: val_loss improved from 1.74731 to 1.74611, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7794 - mean_absolute_error: 0.9677 - mean_squared_error: 1.7794 - val_loss: 1.7461 - val_mean_absolute_error: 0.9642 - val_mean_squared_error: 1.7461\n",
            "Epoch 223/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.7654 - mean_absolute_error: 0.9637 - mean_squared_error: 1.7654\n",
            "Epoch 223: val_loss improved from 1.74611 to 1.74422, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7778 - mean_absolute_error: 0.9673 - mean_squared_error: 1.7778 - val_loss: 1.7442 - val_mean_absolute_error: 0.9646 - val_mean_squared_error: 1.7442\n",
            "Epoch 224/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.7773 - mean_absolute_error: 0.9673 - mean_squared_error: 1.7773\n",
            "Epoch 224: val_loss improved from 1.74422 to 1.73853, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7768 - mean_absolute_error: 0.9681 - mean_squared_error: 1.7768 - val_loss: 1.7385 - val_mean_absolute_error: 0.9627 - val_mean_squared_error: 1.7385\n",
            "Epoch 225/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.7546 - mean_absolute_error: 0.9599 - mean_squared_error: 1.7546\n",
            "Epoch 225: val_loss did not improve from 1.73853\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7738 - mean_absolute_error: 0.9658 - mean_squared_error: 1.7738 - val_loss: 1.7391 - val_mean_absolute_error: 0.9631 - val_mean_squared_error: 1.7391\n",
            "Epoch 226/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.7753 - mean_absolute_error: 0.9659 - mean_squared_error: 1.7753\n",
            "Epoch 226: val_loss improved from 1.73853 to 1.73642, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7719 - mean_absolute_error: 0.9653 - mean_squared_error: 1.7719 - val_loss: 1.7364 - val_mean_absolute_error: 0.9659 - val_mean_squared_error: 1.7364\n",
            "Epoch 227/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.7618 - mean_absolute_error: 0.9642 - mean_squared_error: 1.7618\n",
            "Epoch 227: val_loss improved from 1.73642 to 1.73451, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7699 - mean_absolute_error: 0.9667 - mean_squared_error: 1.7699 - val_loss: 1.7345 - val_mean_absolute_error: 0.9618 - val_mean_squared_error: 1.7345\n",
            "Epoch 228/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 1.7537 - mean_absolute_error: 0.9605 - mean_squared_error: 1.7537\n",
            "Epoch 228: val_loss improved from 1.73451 to 1.73097, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7674 - mean_absolute_error: 0.9661 - mean_squared_error: 1.7674 - val_loss: 1.7310 - val_mean_absolute_error: 0.9623 - val_mean_squared_error: 1.7310\n",
            "Epoch 229/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 1.7758 - mean_absolute_error: 0.9685 - mean_squared_error: 1.7758\n",
            "Epoch 229: val_loss improved from 1.73097 to 1.72865, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7658 - mean_absolute_error: 0.9662 - mean_squared_error: 1.7658 - val_loss: 1.7286 - val_mean_absolute_error: 0.9625 - val_mean_squared_error: 1.7286\n",
            "Epoch 230/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.7482 - mean_absolute_error: 0.9632 - mean_squared_error: 1.7482\n",
            "Epoch 230: val_loss did not improve from 1.72865\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7634 - mean_absolute_error: 0.9661 - mean_squared_error: 1.7634 - val_loss: 1.7301 - val_mean_absolute_error: 0.9600 - val_mean_squared_error: 1.7301\n",
            "Epoch 231/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.7642 - mean_absolute_error: 0.9633 - mean_squared_error: 1.7642\n",
            "Epoch 231: val_loss improved from 1.72865 to 1.72712, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7616 - mean_absolute_error: 0.9640 - mean_squared_error: 1.7616 - val_loss: 1.7271 - val_mean_absolute_error: 0.9625 - val_mean_squared_error: 1.7271\n",
            "Epoch 232/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.7643 - mean_absolute_error: 0.9659 - mean_squared_error: 1.7643\n",
            "Epoch 232: val_loss improved from 1.72712 to 1.72210, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7588 - mean_absolute_error: 0.9636 - mean_squared_error: 1.7588 - val_loss: 1.7221 - val_mean_absolute_error: 0.9628 - val_mean_squared_error: 1.7221\n",
            "Epoch 233/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.7429 - mean_absolute_error: 0.9625 - mean_squared_error: 1.7429\n",
            "Epoch 233: val_loss did not improve from 1.72210\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7557 - mean_absolute_error: 0.9645 - mean_squared_error: 1.7557 - val_loss: 1.7255 - val_mean_absolute_error: 0.9625 - val_mean_squared_error: 1.7255\n",
            "Epoch 234/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.7560 - mean_absolute_error: 0.9663 - mean_squared_error: 1.7560\n",
            "Epoch 234: val_loss improved from 1.72210 to 1.72004, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7539 - mean_absolute_error: 0.9653 - mean_squared_error: 1.7539 - val_loss: 1.7200 - val_mean_absolute_error: 0.9623 - val_mean_squared_error: 1.7200\n",
            "Epoch 235/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.7481 - mean_absolute_error: 0.9629 - mean_squared_error: 1.7481\n",
            "Epoch 235: val_loss improved from 1.72004 to 1.71781, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7522 - mean_absolute_error: 0.9639 - mean_squared_error: 1.7522 - val_loss: 1.7178 - val_mean_absolute_error: 0.9603 - val_mean_squared_error: 1.7178\n",
            "Epoch 236/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.7518 - mean_absolute_error: 0.9640 - mean_squared_error: 1.7518\n",
            "Epoch 236: val_loss improved from 1.71781 to 1.71603, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7509 - mean_absolute_error: 0.9635 - mean_squared_error: 1.7509 - val_loss: 1.7160 - val_mean_absolute_error: 0.9603 - val_mean_squared_error: 1.7160\n",
            "Epoch 237/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.7475 - mean_absolute_error: 0.9611 - mean_squared_error: 1.7475\n",
            "Epoch 237: val_loss improved from 1.71603 to 1.71341, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7494 - mean_absolute_error: 0.9623 - mean_squared_error: 1.7494 - val_loss: 1.7134 - val_mean_absolute_error: 0.9610 - val_mean_squared_error: 1.7134\n",
            "Epoch 238/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.7464 - mean_absolute_error: 0.9628 - mean_squared_error: 1.7464\n",
            "Epoch 238: val_loss improved from 1.71341 to 1.71226, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7456 - mean_absolute_error: 0.9629 - mean_squared_error: 1.7456 - val_loss: 1.7123 - val_mean_absolute_error: 0.9618 - val_mean_squared_error: 1.7123\n",
            "Epoch 239/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.7602 - mean_absolute_error: 0.9685 - mean_squared_error: 1.7602\n",
            "Epoch 239: val_loss improved from 1.71226 to 1.71104, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7447 - mean_absolute_error: 0.9636 - mean_squared_error: 1.7447 - val_loss: 1.7110 - val_mean_absolute_error: 0.9604 - val_mean_squared_error: 1.7110\n",
            "Epoch 240/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.7665 - mean_absolute_error: 0.9692 - mean_squared_error: 1.7665\n",
            "Epoch 240: val_loss improved from 1.71104 to 1.70663, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7424 - mean_absolute_error: 0.9622 - mean_squared_error: 1.7424 - val_loss: 1.7066 - val_mean_absolute_error: 0.9584 - val_mean_squared_error: 1.7066\n",
            "Epoch 241/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.7470 - mean_absolute_error: 0.9636 - mean_squared_error: 1.7470\n",
            "Epoch 241: val_loss improved from 1.70663 to 1.70550, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7393 - mean_absolute_error: 0.9613 - mean_squared_error: 1.7393 - val_loss: 1.7055 - val_mean_absolute_error: 0.9596 - val_mean_squared_error: 1.7055\n",
            "Epoch 242/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.7246 - mean_absolute_error: 0.9583 - mean_squared_error: 1.7246\n",
            "Epoch 242: val_loss did not improve from 1.70550\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7368 - mean_absolute_error: 0.9620 - mean_squared_error: 1.7368 - val_loss: 1.7060 - val_mean_absolute_error: 0.9598 - val_mean_squared_error: 1.7060\n",
            "Epoch 243/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.7258 - mean_absolute_error: 0.9593 - mean_squared_error: 1.7258\n",
            "Epoch 243: val_loss improved from 1.70550 to 1.70139, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7343 - mean_absolute_error: 0.9615 - mean_squared_error: 1.7343 - val_loss: 1.7014 - val_mean_absolute_error: 0.9582 - val_mean_squared_error: 1.7014\n",
            "Epoch 244/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.7324 - mean_absolute_error: 0.9600 - mean_squared_error: 1.7324\n",
            "Epoch 244: val_loss improved from 1.70139 to 1.69859, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7324 - mean_absolute_error: 0.9600 - mean_squared_error: 1.7324 - val_loss: 1.6986 - val_mean_absolute_error: 0.9583 - val_mean_squared_error: 1.6986\n",
            "Epoch 245/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.7228 - mean_absolute_error: 0.9591 - mean_squared_error: 1.7228\n",
            "Epoch 245: val_loss improved from 1.69859 to 1.69687, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7282 - mean_absolute_error: 0.9598 - mean_squared_error: 1.7282 - val_loss: 1.6969 - val_mean_absolute_error: 0.9589 - val_mean_squared_error: 1.6969\n",
            "Epoch 246/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.7192 - mean_absolute_error: 0.9596 - mean_squared_error: 1.7192\n",
            "Epoch 246: val_loss improved from 1.69687 to 1.69654, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7267 - mean_absolute_error: 0.9601 - mean_squared_error: 1.7267 - val_loss: 1.6965 - val_mean_absolute_error: 0.9590 - val_mean_squared_error: 1.6965\n",
            "Epoch 247/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.7187 - mean_absolute_error: 0.9576 - mean_squared_error: 1.7187\n",
            "Epoch 247: val_loss improved from 1.69654 to 1.69005, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7242 - mean_absolute_error: 0.9592 - mean_squared_error: 1.7242 - val_loss: 1.6900 - val_mean_absolute_error: 0.9555 - val_mean_squared_error: 1.6900\n",
            "Epoch 248/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.7236 - mean_absolute_error: 0.9579 - mean_squared_error: 1.7236\n",
            "Epoch 248: val_loss improved from 1.69005 to 1.68966, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7220 - mean_absolute_error: 0.9586 - mean_squared_error: 1.7220 - val_loss: 1.6897 - val_mean_absolute_error: 0.9583 - val_mean_squared_error: 1.6897\n",
            "Epoch 249/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.7257 - mean_absolute_error: 0.9602 - mean_squared_error: 1.7257\n",
            "Epoch 249: val_loss improved from 1.68966 to 1.68786, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7181 - mean_absolute_error: 0.9580 - mean_squared_error: 1.7181 - val_loss: 1.6879 - val_mean_absolute_error: 0.9573 - val_mean_squared_error: 1.6879\n",
            "Epoch 250/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.7190 - mean_absolute_error: 0.9588 - mean_squared_error: 1.7190\n",
            "Epoch 250: val_loss improved from 1.68786 to 1.68546, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7159 - mean_absolute_error: 0.9576 - mean_squared_error: 1.7159 - val_loss: 1.6855 - val_mean_absolute_error: 0.9559 - val_mean_squared_error: 1.6855\n",
            "Epoch 251/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.7138 - mean_absolute_error: 0.9578 - mean_squared_error: 1.7138\n",
            "Epoch 251: val_loss improved from 1.68546 to 1.68212, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7143 - mean_absolute_error: 0.9587 - mean_squared_error: 1.7143 - val_loss: 1.6821 - val_mean_absolute_error: 0.9545 - val_mean_squared_error: 1.6821\n",
            "Epoch 252/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.6932 - mean_absolute_error: 0.9524 - mean_squared_error: 1.6932\n",
            "Epoch 252: val_loss did not improve from 1.68212\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7121 - mean_absolute_error: 0.9568 - mean_squared_error: 1.7121 - val_loss: 1.6824 - val_mean_absolute_error: 0.9553 - val_mean_squared_error: 1.6824\n",
            "Epoch 253/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.7097 - mean_absolute_error: 0.9555 - mean_squared_error: 1.7097\n",
            "Epoch 253: val_loss improved from 1.68212 to 1.67859, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7094 - mean_absolute_error: 0.9562 - mean_squared_error: 1.7094 - val_loss: 1.6786 - val_mean_absolute_error: 0.9552 - val_mean_squared_error: 1.6786\n",
            "Epoch 254/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.7110 - mean_absolute_error: 0.9570 - mean_squared_error: 1.7110\n",
            "Epoch 254: val_loss improved from 1.67859 to 1.67319, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7057 - mean_absolute_error: 0.9559 - mean_squared_error: 1.7057 - val_loss: 1.6732 - val_mean_absolute_error: 0.9540 - val_mean_squared_error: 1.6732\n",
            "Epoch 255/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.6920 - mean_absolute_error: 0.9540 - mean_squared_error: 1.6920\n",
            "Epoch 255: val_loss improved from 1.67319 to 1.67211, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7038 - mean_absolute_error: 0.9567 - mean_squared_error: 1.7038 - val_loss: 1.6721 - val_mean_absolute_error: 0.9537 - val_mean_squared_error: 1.6721\n",
            "Epoch 256/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.7099 - mean_absolute_error: 0.9572 - mean_squared_error: 1.7099\n",
            "Epoch 256: val_loss improved from 1.67211 to 1.67200, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7012 - mean_absolute_error: 0.9541 - mean_squared_error: 1.7012 - val_loss: 1.6720 - val_mean_absolute_error: 0.9549 - val_mean_squared_error: 1.6720\n",
            "Epoch 257/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.6863 - mean_absolute_error: 0.9549 - mean_squared_error: 1.6863\n",
            "Epoch 257: val_loss did not improve from 1.67200\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6974 - mean_absolute_error: 0.9551 - mean_squared_error: 1.6974 - val_loss: 1.6772 - val_mean_absolute_error: 0.9550 - val_mean_squared_error: 1.6772\n",
            "Epoch 258/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.7158 - mean_absolute_error: 0.9608 - mean_squared_error: 1.7158\n",
            "Epoch 258: val_loss improved from 1.67200 to 1.66522, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6971 - mean_absolute_error: 0.9543 - mean_squared_error: 1.6971 - val_loss: 1.6652 - val_mean_absolute_error: 0.9528 - val_mean_squared_error: 1.6652\n",
            "Epoch 259/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.6972 - mean_absolute_error: 0.9538 - mean_squared_error: 1.6972\n",
            "Epoch 259: val_loss improved from 1.66522 to 1.66464, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6942 - mean_absolute_error: 0.9538 - mean_squared_error: 1.6942 - val_loss: 1.6646 - val_mean_absolute_error: 0.9528 - val_mean_squared_error: 1.6646\n",
            "Epoch 260/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.6874 - mean_absolute_error: 0.9529 - mean_squared_error: 1.6874\n",
            "Epoch 260: val_loss did not improve from 1.66464\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6911 - mean_absolute_error: 0.9535 - mean_squared_error: 1.6911 - val_loss: 1.6662 - val_mean_absolute_error: 0.9541 - val_mean_squared_error: 1.6662\n",
            "Epoch 261/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.6830 - mean_absolute_error: 0.9507 - mean_squared_error: 1.6830\n",
            "Epoch 261: val_loss improved from 1.66464 to 1.66428, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6891 - mean_absolute_error: 0.9522 - mean_squared_error: 1.6891 - val_loss: 1.6643 - val_mean_absolute_error: 0.9526 - val_mean_squared_error: 1.6643\n",
            "Epoch 262/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.6996 - mean_absolute_error: 0.9561 - mean_squared_error: 1.6996\n",
            "Epoch 262: val_loss improved from 1.66428 to 1.65862, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6876 - mean_absolute_error: 0.9523 - mean_squared_error: 1.6876 - val_loss: 1.6586 - val_mean_absolute_error: 0.9526 - val_mean_squared_error: 1.6586\n",
            "Epoch 263/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.6709 - mean_absolute_error: 0.9473 - mean_squared_error: 1.6709\n",
            "Epoch 263: val_loss improved from 1.65862 to 1.65447, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6857 - mean_absolute_error: 0.9518 - mean_squared_error: 1.6857 - val_loss: 1.6545 - val_mean_absolute_error: 0.9503 - val_mean_squared_error: 1.6545\n",
            "Epoch 264/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.6854 - mean_absolute_error: 0.9524 - mean_squared_error: 1.6854\n",
            "Epoch 264: val_loss improved from 1.65447 to 1.65117, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6824 - mean_absolute_error: 0.9508 - mean_squared_error: 1.6824 - val_loss: 1.6512 - val_mean_absolute_error: 0.9494 - val_mean_squared_error: 1.6512\n",
            "Epoch 265/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.6683 - mean_absolute_error: 0.9451 - mean_squared_error: 1.6683\n",
            "Epoch 265: val_loss did not improve from 1.65117\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6809 - mean_absolute_error: 0.9498 - mean_squared_error: 1.6809 - val_loss: 1.6519 - val_mean_absolute_error: 0.9511 - val_mean_squared_error: 1.6519\n",
            "Epoch 266/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.6817 - mean_absolute_error: 0.9528 - mean_squared_error: 1.6817\n",
            "Epoch 266: val_loss did not improve from 1.65117\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6788 - mean_absolute_error: 0.9508 - mean_squared_error: 1.6788 - val_loss: 1.6522 - val_mean_absolute_error: 0.9504 - val_mean_squared_error: 1.6522\n",
            "Epoch 267/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.6639 - mean_absolute_error: 0.9454 - mean_squared_error: 1.6639\n",
            "Epoch 267: val_loss improved from 1.65117 to 1.64991, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6756 - mean_absolute_error: 0.9491 - mean_squared_error: 1.6756 - val_loss: 1.6499 - val_mean_absolute_error: 0.9502 - val_mean_squared_error: 1.6499\n",
            "Epoch 268/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.6510 - mean_absolute_error: 0.9446 - mean_squared_error: 1.6510\n",
            "Epoch 268: val_loss improved from 1.64991 to 1.64532, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6747 - mean_absolute_error: 0.9501 - mean_squared_error: 1.6747 - val_loss: 1.6453 - val_mean_absolute_error: 0.9488 - val_mean_squared_error: 1.6453\n",
            "Epoch 269/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.6729 - mean_absolute_error: 0.9488 - mean_squared_error: 1.6729\n",
            "Epoch 269: val_loss did not improve from 1.64532\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6729 - mean_absolute_error: 0.9488 - mean_squared_error: 1.6729 - val_loss: 1.6462 - val_mean_absolute_error: 0.9485 - val_mean_squared_error: 1.6462\n",
            "Epoch 270/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.6745 - mean_absolute_error: 0.9494 - mean_squared_error: 1.6745\n",
            "Epoch 270: val_loss improved from 1.64532 to 1.64488, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6701 - mean_absolute_error: 0.9477 - mean_squared_error: 1.6701 - val_loss: 1.6449 - val_mean_absolute_error: 0.9487 - val_mean_squared_error: 1.6449\n",
            "Epoch 271/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.6688 - mean_absolute_error: 0.9481 - mean_squared_error: 1.6688\n",
            "Epoch 271: val_loss improved from 1.64488 to 1.63972, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6688 - mean_absolute_error: 0.9481 - mean_squared_error: 1.6688 - val_loss: 1.6397 - val_mean_absolute_error: 0.9466 - val_mean_squared_error: 1.6397\n",
            "Epoch 272/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.6809 - mean_absolute_error: 0.9505 - mean_squared_error: 1.6809\n",
            "Epoch 272: val_loss improved from 1.63972 to 1.63897, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6659 - mean_absolute_error: 0.9464 - mean_squared_error: 1.6659 - val_loss: 1.6390 - val_mean_absolute_error: 0.9471 - val_mean_squared_error: 1.6390\n",
            "Epoch 273/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.6695 - mean_absolute_error: 0.9475 - mean_squared_error: 1.6695\n",
            "Epoch 273: val_loss improved from 1.63897 to 1.63735, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6640 - mean_absolute_error: 0.9465 - mean_squared_error: 1.6640 - val_loss: 1.6374 - val_mean_absolute_error: 0.9474 - val_mean_squared_error: 1.6374\n",
            "Epoch 274/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.6651 - mean_absolute_error: 0.9463 - mean_squared_error: 1.6651\n",
            "Epoch 274: val_loss improved from 1.63735 to 1.63651, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6637 - mean_absolute_error: 0.9453 - mean_squared_error: 1.6637 - val_loss: 1.6365 - val_mean_absolute_error: 0.9463 - val_mean_squared_error: 1.6365\n",
            "Epoch 275/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.6716 - mean_absolute_error: 0.9490 - mean_squared_error: 1.6716\n",
            "Epoch 275: val_loss did not improve from 1.63651\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6595 - mean_absolute_error: 0.9461 - mean_squared_error: 1.6595 - val_loss: 1.6370 - val_mean_absolute_error: 0.9457 - val_mean_squared_error: 1.6370\n",
            "Epoch 276/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.6729 - mean_absolute_error: 0.9473 - mean_squared_error: 1.6729\n",
            "Epoch 276: val_loss improved from 1.63651 to 1.63186, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6590 - mean_absolute_error: 0.9443 - mean_squared_error: 1.6590 - val_loss: 1.6319 - val_mean_absolute_error: 0.9459 - val_mean_squared_error: 1.6319\n",
            "Epoch 277/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.6564 - mean_absolute_error: 0.9428 - mean_squared_error: 1.6564\n",
            "Epoch 277: val_loss improved from 1.63186 to 1.63052, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6576 - mean_absolute_error: 0.9435 - mean_squared_error: 1.6576 - val_loss: 1.6305 - val_mean_absolute_error: 0.9457 - val_mean_squared_error: 1.6305\n",
            "Epoch 278/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.6639 - mean_absolute_error: 0.9474 - mean_squared_error: 1.6639\n",
            "Epoch 278: val_loss improved from 1.63052 to 1.62750, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6557 - mean_absolute_error: 0.9446 - mean_squared_error: 1.6557 - val_loss: 1.6275 - val_mean_absolute_error: 0.9447 - val_mean_squared_error: 1.6275\n",
            "Epoch 279/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.6535 - mean_absolute_error: 0.9424 - mean_squared_error: 1.6535\n",
            "Epoch 279: val_loss improved from 1.62750 to 1.62445, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6535 - mean_absolute_error: 0.9424 - mean_squared_error: 1.6535 - val_loss: 1.6244 - val_mean_absolute_error: 0.9435 - val_mean_squared_error: 1.6244\n",
            "Epoch 280/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.6515 - mean_absolute_error: 0.9415 - mean_squared_error: 1.6515\n",
            "Epoch 280: val_loss did not improve from 1.62445\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6515 - mean_absolute_error: 0.9424 - mean_squared_error: 1.6515 - val_loss: 1.6247 - val_mean_absolute_error: 0.9434 - val_mean_squared_error: 1.6247\n",
            "Epoch 281/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 1.6458 - mean_absolute_error: 0.9387 - mean_squared_error: 1.6458\n",
            "Epoch 281: val_loss improved from 1.62445 to 1.62201, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6498 - mean_absolute_error: 0.9418 - mean_squared_error: 1.6498 - val_loss: 1.6220 - val_mean_absolute_error: 0.9427 - val_mean_squared_error: 1.6220\n",
            "Epoch 282/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.6391 - mean_absolute_error: 0.9394 - mean_squared_error: 1.6391\n",
            "Epoch 282: val_loss improved from 1.62201 to 1.62074, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6477 - mean_absolute_error: 0.9420 - mean_squared_error: 1.6477 - val_loss: 1.6207 - val_mean_absolute_error: 0.9425 - val_mean_squared_error: 1.6207\n",
            "Epoch 283/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.6579 - mean_absolute_error: 0.9442 - mean_squared_error: 1.6579\n",
            "Epoch 283: val_loss improved from 1.62074 to 1.61884, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6472 - mean_absolute_error: 0.9407 - mean_squared_error: 1.6472 - val_loss: 1.6188 - val_mean_absolute_error: 0.9404 - val_mean_squared_error: 1.6188\n",
            "Epoch 284/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.6376 - mean_absolute_error: 0.9381 - mean_squared_error: 1.6376\n",
            "Epoch 284: val_loss improved from 1.61884 to 1.61777, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6448 - mean_absolute_error: 0.9402 - mean_squared_error: 1.6448 - val_loss: 1.6178 - val_mean_absolute_error: 0.9406 - val_mean_squared_error: 1.6178\n",
            "Epoch 285/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.6351 - mean_absolute_error: 0.9395 - mean_squared_error: 1.6351\n",
            "Epoch 285: val_loss improved from 1.61777 to 1.61731, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6434 - mean_absolute_error: 0.9398 - mean_squared_error: 1.6434 - val_loss: 1.6173 - val_mean_absolute_error: 0.9407 - val_mean_squared_error: 1.6173\n",
            "Epoch 286/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.6346 - mean_absolute_error: 0.9354 - mean_squared_error: 1.6346\n",
            "Epoch 286: val_loss improved from 1.61731 to 1.61480, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6410 - mean_absolute_error: 0.9384 - mean_squared_error: 1.6410 - val_loss: 1.6148 - val_mean_absolute_error: 0.9402 - val_mean_squared_error: 1.6148\n",
            "Epoch 287/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.6390 - mean_absolute_error: 0.9363 - mean_squared_error: 1.6390\n",
            "Epoch 287: val_loss did not improve from 1.61480\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6385 - mean_absolute_error: 0.9378 - mean_squared_error: 1.6385 - val_loss: 1.6168 - val_mean_absolute_error: 0.9402 - val_mean_squared_error: 1.6168\n",
            "Epoch 288/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.6402 - mean_absolute_error: 0.9357 - mean_squared_error: 1.6402\n",
            "Epoch 288: val_loss did not improve from 1.61480\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6385 - mean_absolute_error: 0.9378 - mean_squared_error: 1.6385 - val_loss: 1.6204 - val_mean_absolute_error: 0.9398 - val_mean_squared_error: 1.6204\n",
            "Epoch 289/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.6381 - mean_absolute_error: 0.9364 - mean_squared_error: 1.6381\n",
            "Epoch 289: val_loss improved from 1.61480 to 1.61391, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6385 - mean_absolute_error: 0.9372 - mean_squared_error: 1.6385 - val_loss: 1.6139 - val_mean_absolute_error: 0.9400 - val_mean_squared_error: 1.6139\n",
            "Epoch 290/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.6402 - mean_absolute_error: 0.9386 - mean_squared_error: 1.6402\n",
            "Epoch 290: val_loss improved from 1.61391 to 1.60845, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6348 - mean_absolute_error: 0.9366 - mean_squared_error: 1.6348 - val_loss: 1.6085 - val_mean_absolute_error: 0.9380 - val_mean_squared_error: 1.6085\n",
            "Epoch 291/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.6344 - mean_absolute_error: 0.9354 - mean_squared_error: 1.6344\n",
            "Epoch 291: val_loss improved from 1.60845 to 1.60807, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6344 - mean_absolute_error: 0.9354 - mean_squared_error: 1.6344 - val_loss: 1.6081 - val_mean_absolute_error: 0.9377 - val_mean_squared_error: 1.6081\n",
            "Epoch 292/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.6347 - mean_absolute_error: 0.9354 - mean_squared_error: 1.6347\n",
            "Epoch 292: val_loss did not improve from 1.60807\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6321 - mean_absolute_error: 0.9359 - mean_squared_error: 1.6321 - val_loss: 1.6112 - val_mean_absolute_error: 0.9392 - val_mean_squared_error: 1.6112\n",
            "Epoch 293/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 1.6083 - mean_absolute_error: 0.9293 - mean_squared_error: 1.6083\n",
            "Epoch 293: val_loss improved from 1.60807 to 1.60352, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6319 - mean_absolute_error: 0.9366 - mean_squared_error: 1.6319 - val_loss: 1.6035 - val_mean_absolute_error: 0.9349 - val_mean_squared_error: 1.6035\n",
            "Epoch 294/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.6390 - mean_absolute_error: 0.9358 - mean_squared_error: 1.6390\n",
            "Epoch 294: val_loss did not improve from 1.60352\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6288 - mean_absolute_error: 0.9328 - mean_squared_error: 1.6288 - val_loss: 1.6067 - val_mean_absolute_error: 0.9368 - val_mean_squared_error: 1.6067\n",
            "Epoch 295/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.6200 - mean_absolute_error: 0.9331 - mean_squared_error: 1.6200\n",
            "Epoch 295: val_loss improved from 1.60352 to 1.60332, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6274 - mean_absolute_error: 0.9335 - mean_squared_error: 1.6274 - val_loss: 1.6033 - val_mean_absolute_error: 0.9347 - val_mean_squared_error: 1.6033\n",
            "Epoch 296/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.6216 - mean_absolute_error: 0.9316 - mean_squared_error: 1.6216\n",
            "Epoch 296: val_loss improved from 1.60332 to 1.60125, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6258 - mean_absolute_error: 0.9326 - mean_squared_error: 1.6258 - val_loss: 1.6012 - val_mean_absolute_error: 0.9348 - val_mean_squared_error: 1.6012\n",
            "Epoch 297/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.6239 - mean_absolute_error: 0.9321 - mean_squared_error: 1.6239\n",
            "Epoch 297: val_loss improved from 1.60125 to 1.60001, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6245 - mean_absolute_error: 0.9324 - mean_squared_error: 1.6245 - val_loss: 1.6000 - val_mean_absolute_error: 0.9340 - val_mean_squared_error: 1.6000\n",
            "Epoch 298/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.6153 - mean_absolute_error: 0.9288 - mean_squared_error: 1.6153\n",
            "Epoch 298: val_loss improved from 1.60001 to 1.59987, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6235 - mean_absolute_error: 0.9322 - mean_squared_error: 1.6235 - val_loss: 1.5999 - val_mean_absolute_error: 0.9328 - val_mean_squared_error: 1.5999\n",
            "Epoch 299/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.6265 - mean_absolute_error: 0.9326 - mean_squared_error: 1.6265\n",
            "Epoch 299: val_loss improved from 1.59987 to 1.59610, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6212 - mean_absolute_error: 0.9307 - mean_squared_error: 1.6212 - val_loss: 1.5961 - val_mean_absolute_error: 0.9320 - val_mean_squared_error: 1.5961\n",
            "Epoch 300/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.6254 - mean_absolute_error: 0.9329 - mean_squared_error: 1.6254\n",
            "Epoch 300: val_loss did not improve from 1.59610\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6201 - mean_absolute_error: 0.9307 - mean_squared_error: 1.6201 - val_loss: 1.5993 - val_mean_absolute_error: 0.9342 - val_mean_squared_error: 1.5993\n",
            "Epoch 301/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.6157 - mean_absolute_error: 0.9274 - mean_squared_error: 1.6157\n",
            "Epoch 301: val_loss improved from 1.59610 to 1.59471, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6186 - mean_absolute_error: 0.9297 - mean_squared_error: 1.6186 - val_loss: 1.5947 - val_mean_absolute_error: 0.9321 - val_mean_squared_error: 1.5947\n",
            "Epoch 302/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.6238 - mean_absolute_error: 0.9313 - mean_squared_error: 1.6238\n",
            "Epoch 302: val_loss improved from 1.59471 to 1.59438, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6172 - mean_absolute_error: 0.9294 - mean_squared_error: 1.6172 - val_loss: 1.5944 - val_mean_absolute_error: 0.9313 - val_mean_squared_error: 1.5944\n",
            "Epoch 303/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.6037 - mean_absolute_error: 0.9260 - mean_squared_error: 1.6037\n",
            "Epoch 303: val_loss did not improve from 1.59438\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6148 - mean_absolute_error: 0.9279 - mean_squared_error: 1.6148 - val_loss: 1.5954 - val_mean_absolute_error: 0.9311 - val_mean_squared_error: 1.5954\n",
            "Epoch 304/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.6164 - mean_absolute_error: 0.9272 - mean_squared_error: 1.6164\n",
            "Epoch 304: val_loss improved from 1.59438 to 1.59176, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6149 - mean_absolute_error: 0.9271 - mean_squared_error: 1.6149 - val_loss: 1.5918 - val_mean_absolute_error: 0.9300 - val_mean_squared_error: 1.5918\n",
            "Epoch 305/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.6094 - mean_absolute_error: 0.9249 - mean_squared_error: 1.6094\n",
            "Epoch 305: val_loss improved from 1.59176 to 1.58891, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6126 - mean_absolute_error: 0.9275 - mean_squared_error: 1.6126 - val_loss: 1.5889 - val_mean_absolute_error: 0.9291 - val_mean_squared_error: 1.5889\n",
            "Epoch 306/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.6150 - mean_absolute_error: 0.9283 - mean_squared_error: 1.6150\n",
            "Epoch 306: val_loss did not improve from 1.58891\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6107 - mean_absolute_error: 0.9268 - mean_squared_error: 1.6107 - val_loss: 1.5903 - val_mean_absolute_error: 0.9292 - val_mean_squared_error: 1.5903\n",
            "Epoch 307/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.6207 - mean_absolute_error: 0.9293 - mean_squared_error: 1.6207\n",
            "Epoch 307: val_loss improved from 1.58891 to 1.58829, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6095 - mean_absolute_error: 0.9256 - mean_squared_error: 1.6095 - val_loss: 1.5883 - val_mean_absolute_error: 0.9287 - val_mean_squared_error: 1.5883\n",
            "Epoch 308/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.6271 - mean_absolute_error: 0.9313 - mean_squared_error: 1.6271\n",
            "Epoch 308: val_loss improved from 1.58829 to 1.58775, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6087 - mean_absolute_error: 0.9247 - mean_squared_error: 1.6087 - val_loss: 1.5878 - val_mean_absolute_error: 0.9290 - val_mean_squared_error: 1.5878\n",
            "Epoch 309/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.6109 - mean_absolute_error: 0.9249 - mean_squared_error: 1.6109\n",
            "Epoch 309: val_loss improved from 1.58775 to 1.58239, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6074 - mean_absolute_error: 0.9252 - mean_squared_error: 1.6074 - val_loss: 1.5824 - val_mean_absolute_error: 0.9253 - val_mean_squared_error: 1.5824\n",
            "Epoch 310/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.6191 - mean_absolute_error: 0.9312 - mean_squared_error: 1.6191\n",
            "Epoch 310: val_loss improved from 1.58239 to 1.58151, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6064 - mean_absolute_error: 0.9262 - mean_squared_error: 1.6064 - val_loss: 1.5815 - val_mean_absolute_error: 0.9253 - val_mean_squared_error: 1.5815\n",
            "Epoch 311/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.6021 - mean_absolute_error: 0.9215 - mean_squared_error: 1.6021\n",
            "Epoch 311: val_loss did not improve from 1.58151\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6034 - mean_absolute_error: 0.9219 - mean_squared_error: 1.6034 - val_loss: 1.5829 - val_mean_absolute_error: 0.9260 - val_mean_squared_error: 1.5829\n",
            "Epoch 312/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.6089 - mean_absolute_error: 0.9255 - mean_squared_error: 1.6089\n",
            "Epoch 312: val_loss improved from 1.58151 to 1.57957, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6028 - mean_absolute_error: 0.9234 - mean_squared_error: 1.6028 - val_loss: 1.5796 - val_mean_absolute_error: 0.9235 - val_mean_squared_error: 1.5796\n",
            "Epoch 313/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.6109 - mean_absolute_error: 0.9227 - mean_squared_error: 1.6109\n",
            "Epoch 313: val_loss did not improve from 1.57957\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6014 - mean_absolute_error: 0.9220 - mean_squared_error: 1.6014 - val_loss: 1.5811 - val_mean_absolute_error: 0.9232 - val_mean_squared_error: 1.5811\n",
            "Epoch 314/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.6164 - mean_absolute_error: 0.9242 - mean_squared_error: 1.6164\n",
            "Epoch 314: val_loss improved from 1.57957 to 1.57756, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5995 - mean_absolute_error: 0.9203 - mean_squared_error: 1.5995 - val_loss: 1.5776 - val_mean_absolute_error: 0.9238 - val_mean_squared_error: 1.5776\n",
            "Epoch 315/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.5974 - mean_absolute_error: 0.9225 - mean_squared_error: 1.5974\n",
            "Epoch 315: val_loss improved from 1.57756 to 1.57314, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5998 - mean_absolute_error: 0.9217 - mean_squared_error: 1.5998 - val_loss: 1.5731 - val_mean_absolute_error: 0.9214 - val_mean_squared_error: 1.5731\n",
            "Epoch 316/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.5956 - mean_absolute_error: 0.9188 - mean_squared_error: 1.5956\n",
            "Epoch 316: val_loss did not improve from 1.57314\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5973 - mean_absolute_error: 0.9206 - mean_squared_error: 1.5973 - val_loss: 1.5744 - val_mean_absolute_error: 0.9216 - val_mean_squared_error: 1.5744\n",
            "Epoch 317/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.6026 - mean_absolute_error: 0.9214 - mean_squared_error: 1.6026\n",
            "Epoch 317: val_loss did not improve from 1.57314\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.5962 - mean_absolute_error: 0.9196 - mean_squared_error: 1.5962 - val_loss: 1.5739 - val_mean_absolute_error: 0.9215 - val_mean_squared_error: 1.5739\n",
            "Epoch 318/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.5961 - mean_absolute_error: 0.9199 - mean_squared_error: 1.5961\n",
            "Epoch 318: val_loss did not improve from 1.57314\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5939 - mean_absolute_error: 0.9179 - mean_squared_error: 1.5939 - val_loss: 1.5738 - val_mean_absolute_error: 0.9223 - val_mean_squared_error: 1.5738\n",
            "Epoch 319/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.6057 - mean_absolute_error: 0.9222 - mean_squared_error: 1.6057\n",
            "Epoch 319: val_loss improved from 1.57314 to 1.56947, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5929 - mean_absolute_error: 0.9182 - mean_squared_error: 1.5929 - val_loss: 1.5695 - val_mean_absolute_error: 0.9198 - val_mean_squared_error: 1.5695\n",
            "Epoch 320/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.5956 - mean_absolute_error: 0.9197 - mean_squared_error: 1.5956\n",
            "Epoch 320: val_loss improved from 1.56947 to 1.56895, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5910 - mean_absolute_error: 0.9180 - mean_squared_error: 1.5910 - val_loss: 1.5689 - val_mean_absolute_error: 0.9191 - val_mean_squared_error: 1.5689\n",
            "Epoch 321/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.5988 - mean_absolute_error: 0.9180 - mean_squared_error: 1.5988\n",
            "Epoch 321: val_loss improved from 1.56895 to 1.56835, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5907 - mean_absolute_error: 0.9152 - mean_squared_error: 1.5907 - val_loss: 1.5684 - val_mean_absolute_error: 0.9204 - val_mean_squared_error: 1.5684\n",
            "Epoch 322/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.5889 - mean_absolute_error: 0.9160 - mean_squared_error: 1.5889\n",
            "Epoch 322: val_loss did not improve from 1.56835\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5882 - mean_absolute_error: 0.9157 - mean_squared_error: 1.5882 - val_loss: 1.5716 - val_mean_absolute_error: 0.9199 - val_mean_squared_error: 1.5716\n",
            "Epoch 323/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.5848 - mean_absolute_error: 0.9155 - mean_squared_error: 1.5848\n",
            "Epoch 323: val_loss improved from 1.56835 to 1.56828, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5864 - mean_absolute_error: 0.9157 - mean_squared_error: 1.5864 - val_loss: 1.5683 - val_mean_absolute_error: 0.9197 - val_mean_squared_error: 1.5683\n",
            "Epoch 324/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.5888 - mean_absolute_error: 0.9174 - mean_squared_error: 1.5888\n",
            "Epoch 324: val_loss improved from 1.56828 to 1.56271, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5870 - mean_absolute_error: 0.9161 - mean_squared_error: 1.5870 - val_loss: 1.5627 - val_mean_absolute_error: 0.9162 - val_mean_squared_error: 1.5627\n",
            "Epoch 325/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.5782 - mean_absolute_error: 0.9116 - mean_squared_error: 1.5782\n",
            "Epoch 325: val_loss did not improve from 1.56271\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5842 - mean_absolute_error: 0.9140 - mean_squared_error: 1.5842 - val_loss: 1.5679 - val_mean_absolute_error: 0.9184 - val_mean_squared_error: 1.5679\n",
            "Epoch 326/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.5879 - mean_absolute_error: 0.9140 - mean_squared_error: 1.5879\n",
            "Epoch 326: val_loss did not improve from 1.56271\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5832 - mean_absolute_error: 0.9132 - mean_squared_error: 1.5832 - val_loss: 1.5645 - val_mean_absolute_error: 0.9176 - val_mean_squared_error: 1.5645\n",
            "Epoch 327/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.5816 - mean_absolute_error: 0.9147 - mean_squared_error: 1.5816\n",
            "Epoch 327: val_loss improved from 1.56271 to 1.55944, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5810 - mean_absolute_error: 0.9136 - mean_squared_error: 1.5810 - val_loss: 1.5594 - val_mean_absolute_error: 0.9147 - val_mean_squared_error: 1.5594\n",
            "Epoch 328/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.5678 - mean_absolute_error: 0.9089 - mean_squared_error: 1.5678\n",
            "Epoch 328: val_loss improved from 1.55944 to 1.55759, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5797 - mean_absolute_error: 0.9112 - mean_squared_error: 1.5797 - val_loss: 1.5576 - val_mean_absolute_error: 0.9135 - val_mean_squared_error: 1.5576\n",
            "Epoch 329/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.5774 - mean_absolute_error: 0.9100 - mean_squared_error: 1.5774\n",
            "Epoch 329: val_loss did not improve from 1.55759\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5783 - mean_absolute_error: 0.9111 - mean_squared_error: 1.5783 - val_loss: 1.5578 - val_mean_absolute_error: 0.9147 - val_mean_squared_error: 1.5578\n",
            "Epoch 330/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.5843 - mean_absolute_error: 0.9145 - mean_squared_error: 1.5843\n",
            "Epoch 330: val_loss improved from 1.55759 to 1.55498, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5773 - mean_absolute_error: 0.9119 - mean_squared_error: 1.5773 - val_loss: 1.5550 - val_mean_absolute_error: 0.9125 - val_mean_squared_error: 1.5550\n",
            "Epoch 331/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.5648 - mean_absolute_error: 0.9053 - mean_squared_error: 1.5648\n",
            "Epoch 331: val_loss improved from 1.55498 to 1.55451, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5752 - mean_absolute_error: 0.9088 - mean_squared_error: 1.5752 - val_loss: 1.5545 - val_mean_absolute_error: 0.9135 - val_mean_squared_error: 1.5545\n",
            "Epoch 332/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.5731 - mean_absolute_error: 0.9099 - mean_squared_error: 1.5731\n",
            "Epoch 332: val_loss improved from 1.55451 to 1.55364, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5734 - mean_absolute_error: 0.9097 - mean_squared_error: 1.5734 - val_loss: 1.5536 - val_mean_absolute_error: 0.9125 - val_mean_squared_error: 1.5536\n",
            "Epoch 333/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.5808 - mean_absolute_error: 0.9127 - mean_squared_error: 1.5808\n",
            "Epoch 333: val_loss improved from 1.55364 to 1.54934, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5728 - mean_absolute_error: 0.9097 - mean_squared_error: 1.5728 - val_loss: 1.5493 - val_mean_absolute_error: 0.9087 - val_mean_squared_error: 1.5493\n",
            "Epoch 334/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.5640 - mean_absolute_error: 0.9047 - mean_squared_error: 1.5640\n",
            "Epoch 334: val_loss did not improve from 1.54934\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5699 - mean_absolute_error: 0.9072 - mean_squared_error: 1.5699 - val_loss: 1.5529 - val_mean_absolute_error: 0.9105 - val_mean_squared_error: 1.5529\n",
            "Epoch 335/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.5680 - mean_absolute_error: 0.9079 - mean_squared_error: 1.5680\n",
            "Epoch 335: val_loss did not improve from 1.54934\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5700 - mean_absolute_error: 0.9072 - mean_squared_error: 1.5700 - val_loss: 1.5510 - val_mean_absolute_error: 0.9110 - val_mean_squared_error: 1.5510\n",
            "Epoch 336/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.5771 - mean_absolute_error: 0.9080 - mean_squared_error: 1.5771\n",
            "Epoch 336: val_loss improved from 1.54934 to 1.54874, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5686 - mean_absolute_error: 0.9065 - mean_squared_error: 1.5686 - val_loss: 1.5487 - val_mean_absolute_error: 0.9095 - val_mean_squared_error: 1.5487\n",
            "Epoch 337/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.5660 - mean_absolute_error: 0.9060 - mean_squared_error: 1.5660\n",
            "Epoch 337: val_loss improved from 1.54874 to 1.54582, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5672 - mean_absolute_error: 0.9061 - mean_squared_error: 1.5672 - val_loss: 1.5458 - val_mean_absolute_error: 0.9091 - val_mean_squared_error: 1.5458\n",
            "Epoch 338/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.5725 - mean_absolute_error: 0.9069 - mean_squared_error: 1.5725\n",
            "Epoch 338: val_loss improved from 1.54582 to 1.54539, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5654 - mean_absolute_error: 0.9050 - mean_squared_error: 1.5654 - val_loss: 1.5454 - val_mean_absolute_error: 0.9086 - val_mean_squared_error: 1.5454\n",
            "Epoch 339/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.5745 - mean_absolute_error: 0.9078 - mean_squared_error: 1.5745\n",
            "Epoch 339: val_loss improved from 1.54539 to 1.54209, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5642 - mean_absolute_error: 0.9052 - mean_squared_error: 1.5642 - val_loss: 1.5421 - val_mean_absolute_error: 0.9063 - val_mean_squared_error: 1.5421\n",
            "Epoch 340/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.5610 - mean_absolute_error: 0.9024 - mean_squared_error: 1.5610\n",
            "Epoch 340: val_loss improved from 1.54209 to 1.54062, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5621 - mean_absolute_error: 0.9027 - mean_squared_error: 1.5621 - val_loss: 1.5406 - val_mean_absolute_error: 0.9052 - val_mean_squared_error: 1.5406\n",
            "Epoch 341/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.5670 - mean_absolute_error: 0.9046 - mean_squared_error: 1.5670\n",
            "Epoch 341: val_loss improved from 1.54062 to 1.54005, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5610 - mean_absolute_error: 0.9029 - mean_squared_error: 1.5610 - val_loss: 1.5401 - val_mean_absolute_error: 0.9058 - val_mean_squared_error: 1.5401\n",
            "Epoch 342/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.5519 - mean_absolute_error: 0.8991 - mean_squared_error: 1.5519\n",
            "Epoch 342: val_loss did not improve from 1.54005\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5577 - mean_absolute_error: 0.9013 - mean_squared_error: 1.5577 - val_loss: 1.5451 - val_mean_absolute_error: 0.9073 - val_mean_squared_error: 1.5451\n",
            "Epoch 343/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.5695 - mean_absolute_error: 0.9047 - mean_squared_error: 1.5695\n",
            "Epoch 343: val_loss improved from 1.54005 to 1.53694, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5580 - mean_absolute_error: 0.9010 - mean_squared_error: 1.5580 - val_loss: 1.5369 - val_mean_absolute_error: 0.9048 - val_mean_squared_error: 1.5369\n",
            "Epoch 344/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.5558 - mean_absolute_error: 0.8991 - mean_squared_error: 1.5558\n",
            "Epoch 344: val_loss improved from 1.53694 to 1.53460, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5558 - mean_absolute_error: 0.8999 - mean_squared_error: 1.5558 - val_loss: 1.5346 - val_mean_absolute_error: 0.9038 - val_mean_squared_error: 1.5346\n",
            "Epoch 345/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.5547 - mean_absolute_error: 0.8996 - mean_squared_error: 1.5547\n",
            "Epoch 345: val_loss improved from 1.53460 to 1.53351, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5545 - mean_absolute_error: 0.8998 - mean_squared_error: 1.5545 - val_loss: 1.5335 - val_mean_absolute_error: 0.9036 - val_mean_squared_error: 1.5335\n",
            "Epoch 346/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.5408 - mean_absolute_error: 0.8961 - mean_squared_error: 1.5408\n",
            "Epoch 346: val_loss improved from 1.53351 to 1.53029, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5535 - mean_absolute_error: 0.9006 - mean_squared_error: 1.5535 - val_loss: 1.5303 - val_mean_absolute_error: 0.9012 - val_mean_squared_error: 1.5303\n",
            "Epoch 347/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.5499 - mean_absolute_error: 0.8982 - mean_squared_error: 1.5499\n",
            "Epoch 347: val_loss did not improve from 1.53029\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5516 - mean_absolute_error: 0.8988 - mean_squared_error: 1.5516 - val_loss: 1.5313 - val_mean_absolute_error: 0.9015 - val_mean_squared_error: 1.5313\n",
            "Epoch 348/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.5570 - mean_absolute_error: 0.9007 - mean_squared_error: 1.5570\n",
            "Epoch 348: val_loss did not improve from 1.53029\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5506 - mean_absolute_error: 0.8986 - mean_squared_error: 1.5506 - val_loss: 1.5311 - val_mean_absolute_error: 0.9008 - val_mean_squared_error: 1.5311\n",
            "Epoch 349/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.5424 - mean_absolute_error: 0.8954 - mean_squared_error: 1.5424\n",
            "Epoch 349: val_loss improved from 1.53029 to 1.53003, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5487 - mean_absolute_error: 0.8961 - mean_squared_error: 1.5487 - val_loss: 1.5300 - val_mean_absolute_error: 0.8996 - val_mean_squared_error: 1.5300\n",
            "Epoch 350/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.5705 - mean_absolute_error: 0.9043 - mean_squared_error: 1.5705\n",
            "Epoch 350: val_loss improved from 1.53003 to 1.52949, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5475 - mean_absolute_error: 0.8959 - mean_squared_error: 1.5475 - val_loss: 1.5295 - val_mean_absolute_error: 0.9000 - val_mean_squared_error: 1.5295\n",
            "Epoch 351/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.5482 - mean_absolute_error: 0.8943 - mean_squared_error: 1.5482\n",
            "Epoch 351: val_loss improved from 1.52949 to 1.52570, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5449 - mean_absolute_error: 0.8951 - mean_squared_error: 1.5449 - val_loss: 1.5257 - val_mean_absolute_error: 0.8978 - val_mean_squared_error: 1.5257\n",
            "Epoch 352/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.5268 - mean_absolute_error: 0.8894 - mean_squared_error: 1.5268\n",
            "Epoch 352: val_loss improved from 1.52570 to 1.52208, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5437 - mean_absolute_error: 0.8936 - mean_squared_error: 1.5437 - val_loss: 1.5221 - val_mean_absolute_error: 0.8970 - val_mean_squared_error: 1.5221\n",
            "Epoch 353/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.5522 - mean_absolute_error: 0.8984 - mean_squared_error: 1.5522\n",
            "Epoch 353: val_loss improved from 1.52208 to 1.51988, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5423 - mean_absolute_error: 0.8948 - mean_squared_error: 1.5423 - val_loss: 1.5199 - val_mean_absolute_error: 0.8954 - val_mean_squared_error: 1.5199\n",
            "Epoch 354/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.5376 - mean_absolute_error: 0.8920 - mean_squared_error: 1.5376\n",
            "Epoch 354: val_loss improved from 1.51988 to 1.51919, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5408 - mean_absolute_error: 0.8928 - mean_squared_error: 1.5408 - val_loss: 1.5192 - val_mean_absolute_error: 0.8948 - val_mean_squared_error: 1.5192\n",
            "Epoch 355/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.5358 - mean_absolute_error: 0.8914 - mean_squared_error: 1.5358\n",
            "Epoch 355: val_loss did not improve from 1.51919\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5398 - mean_absolute_error: 0.8923 - mean_squared_error: 1.5398 - val_loss: 1.5202 - val_mean_absolute_error: 0.8947 - val_mean_squared_error: 1.5202\n",
            "Epoch 356/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.5304 - mean_absolute_error: 0.8896 - mean_squared_error: 1.5304\n",
            "Epoch 356: val_loss improved from 1.51919 to 1.51805, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5379 - mean_absolute_error: 0.8916 - mean_squared_error: 1.5379 - val_loss: 1.5181 - val_mean_absolute_error: 0.8949 - val_mean_squared_error: 1.5181\n",
            "Epoch 357/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.5355 - mean_absolute_error: 0.8940 - mean_squared_error: 1.5355\n",
            "Epoch 357: val_loss improved from 1.51805 to 1.51785, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5365 - mean_absolute_error: 0.8917 - mean_squared_error: 1.5365 - val_loss: 1.5179 - val_mean_absolute_error: 0.8947 - val_mean_squared_error: 1.5179\n",
            "Epoch 358/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.5416 - mean_absolute_error: 0.8912 - mean_squared_error: 1.5416\n",
            "Epoch 358: val_loss improved from 1.51785 to 1.51669, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5348 - mean_absolute_error: 0.8892 - mean_squared_error: 1.5348 - val_loss: 1.5167 - val_mean_absolute_error: 0.8940 - val_mean_squared_error: 1.5167\n",
            "Epoch 359/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.5258 - mean_absolute_error: 0.8861 - mean_squared_error: 1.5258\n",
            "Epoch 359: val_loss did not improve from 1.51669\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5339 - mean_absolute_error: 0.8891 - mean_squared_error: 1.5339 - val_loss: 1.5180 - val_mean_absolute_error: 0.8939 - val_mean_squared_error: 1.5180\n",
            "Epoch 360/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.5279 - mean_absolute_error: 0.8886 - mean_squared_error: 1.5279\n",
            "Epoch 360: val_loss improved from 1.51669 to 1.51259, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5313 - mean_absolute_error: 0.8891 - mean_squared_error: 1.5313 - val_loss: 1.5126 - val_mean_absolute_error: 0.8929 - val_mean_squared_error: 1.5126\n",
            "Epoch 361/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.5305 - mean_absolute_error: 0.8879 - mean_squared_error: 1.5305\n",
            "Epoch 361: val_loss improved from 1.51259 to 1.50893, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5306 - mean_absolute_error: 0.8879 - mean_squared_error: 1.5306 - val_loss: 1.5089 - val_mean_absolute_error: 0.8898 - val_mean_squared_error: 1.5089\n",
            "Epoch 362/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.5353 - mean_absolute_error: 0.8886 - mean_squared_error: 1.5353\n",
            "Epoch 362: val_loss did not improve from 1.50893\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5279 - mean_absolute_error: 0.8868 - mean_squared_error: 1.5279 - val_loss: 1.5093 - val_mean_absolute_error: 0.8910 - val_mean_squared_error: 1.5093\n",
            "Epoch 363/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.5342 - mean_absolute_error: 0.8894 - mean_squared_error: 1.5342\n",
            "Epoch 363: val_loss improved from 1.50893 to 1.50844, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5267 - mean_absolute_error: 0.8867 - mean_squared_error: 1.5267 - val_loss: 1.5084 - val_mean_absolute_error: 0.8914 - val_mean_squared_error: 1.5084\n",
            "Epoch 364/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.5274 - mean_absolute_error: 0.8861 - mean_squared_error: 1.5274\n",
            "Epoch 364: val_loss improved from 1.50844 to 1.50789, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5248 - mean_absolute_error: 0.8854 - mean_squared_error: 1.5248 - val_loss: 1.5079 - val_mean_absolute_error: 0.8907 - val_mean_squared_error: 1.5079\n",
            "Epoch 365/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.5239 - mean_absolute_error: 0.8855 - mean_squared_error: 1.5239\n",
            "Epoch 365: val_loss did not improve from 1.50789\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5239 - mean_absolute_error: 0.8855 - mean_squared_error: 1.5239 - val_loss: 1.5082 - val_mean_absolute_error: 0.8902 - val_mean_squared_error: 1.5082\n",
            "Epoch 366/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.5219 - mean_absolute_error: 0.8839 - mean_squared_error: 1.5219\n",
            "Epoch 366: val_loss improved from 1.50789 to 1.50226, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5217 - mean_absolute_error: 0.8839 - mean_squared_error: 1.5217 - val_loss: 1.5023 - val_mean_absolute_error: 0.8870 - val_mean_squared_error: 1.5023\n",
            "Epoch 367/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.5194 - mean_absolute_error: 0.8849 - mean_squared_error: 1.5194\n",
            "Epoch 367: val_loss did not improve from 1.50226\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5210 - mean_absolute_error: 0.8849 - mean_squared_error: 1.5210 - val_loss: 1.5033 - val_mean_absolute_error: 0.8861 - val_mean_squared_error: 1.5033\n",
            "Epoch 368/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.4991 - mean_absolute_error: 0.8747 - mean_squared_error: 1.4991\n",
            "Epoch 368: val_loss improved from 1.50226 to 1.49645, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5191 - mean_absolute_error: 0.8815 - mean_squared_error: 1.5191 - val_loss: 1.4964 - val_mean_absolute_error: 0.8825 - val_mean_squared_error: 1.4964\n",
            "Epoch 369/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.5197 - mean_absolute_error: 0.8828 - mean_squared_error: 1.5197\n",
            "Epoch 369: val_loss did not improve from 1.49645\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5180 - mean_absolute_error: 0.8811 - mean_squared_error: 1.5180 - val_loss: 1.4995 - val_mean_absolute_error: 0.8865 - val_mean_squared_error: 1.4995\n",
            "Epoch 370/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.5205 - mean_absolute_error: 0.8833 - mean_squared_error: 1.5205\n",
            "Epoch 370: val_loss did not improve from 1.49645\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5156 - mean_absolute_error: 0.8821 - mean_squared_error: 1.5156 - val_loss: 1.4973 - val_mean_absolute_error: 0.8833 - val_mean_squared_error: 1.4973\n",
            "Epoch 371/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.5115 - mean_absolute_error: 0.8803 - mean_squared_error: 1.5115\n",
            "Epoch 371: val_loss did not improve from 1.49645\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5142 - mean_absolute_error: 0.8796 - mean_squared_error: 1.5142 - val_loss: 1.4998 - val_mean_absolute_error: 0.8847 - val_mean_squared_error: 1.4998\n",
            "Epoch 372/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.4997 - mean_absolute_error: 0.8752 - mean_squared_error: 1.4997\n",
            "Epoch 372: val_loss improved from 1.49645 to 1.49197, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5116 - mean_absolute_error: 0.8789 - mean_squared_error: 1.5116 - val_loss: 1.4920 - val_mean_absolute_error: 0.8832 - val_mean_squared_error: 1.4920\n",
            "Epoch 373/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.5181 - mean_absolute_error: 0.8832 - mean_squared_error: 1.5181\n",
            "Epoch 373: val_loss did not improve from 1.49197\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5106 - mean_absolute_error: 0.8801 - mean_squared_error: 1.5106 - val_loss: 1.4931 - val_mean_absolute_error: 0.8818 - val_mean_squared_error: 1.4931\n",
            "Epoch 374/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.5034 - mean_absolute_error: 0.8771 - mean_squared_error: 1.5034\n",
            "Epoch 374: val_loss improved from 1.49197 to 1.48913, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5101 - mean_absolute_error: 0.8786 - mean_squared_error: 1.5101 - val_loss: 1.4891 - val_mean_absolute_error: 0.8793 - val_mean_squared_error: 1.4891\n",
            "Epoch 375/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.5094 - mean_absolute_error: 0.8770 - mean_squared_error: 1.5094\n",
            "Epoch 375: val_loss improved from 1.48913 to 1.48625, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5079 - mean_absolute_error: 0.8764 - mean_squared_error: 1.5079 - val_loss: 1.4862 - val_mean_absolute_error: 0.8791 - val_mean_squared_error: 1.4862\n",
            "Epoch 376/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.5097 - mean_absolute_error: 0.8762 - mean_squared_error: 1.5097\n",
            "Epoch 376: val_loss did not improve from 1.48625\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5056 - mean_absolute_error: 0.8759 - mean_squared_error: 1.5056 - val_loss: 1.4881 - val_mean_absolute_error: 0.8807 - val_mean_squared_error: 1.4881\n",
            "Epoch 377/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.4853 - mean_absolute_error: 0.8702 - mean_squared_error: 1.4853\n",
            "Epoch 377: val_loss improved from 1.48625 to 1.48594, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5045 - mean_absolute_error: 0.8759 - mean_squared_error: 1.5045 - val_loss: 1.4859 - val_mean_absolute_error: 0.8786 - val_mean_squared_error: 1.4859\n",
            "Epoch 378/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.4957 - mean_absolute_error: 0.8731 - mean_squared_error: 1.4957\n",
            "Epoch 378: val_loss improved from 1.48594 to 1.48220, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5023 - mean_absolute_error: 0.8753 - mean_squared_error: 1.5023 - val_loss: 1.4822 - val_mean_absolute_error: 0.8765 - val_mean_squared_error: 1.4822\n",
            "Epoch 379/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.5065 - mean_absolute_error: 0.8745 - mean_squared_error: 1.5065\n",
            "Epoch 379: val_loss improved from 1.48220 to 1.48105, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5005 - mean_absolute_error: 0.8732 - mean_squared_error: 1.5005 - val_loss: 1.4811 - val_mean_absolute_error: 0.8778 - val_mean_squared_error: 1.4811\n",
            "Epoch 380/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.5011 - mean_absolute_error: 0.8747 - mean_squared_error: 1.5011\n",
            "Epoch 380: val_loss improved from 1.48105 to 1.48054, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4984 - mean_absolute_error: 0.8733 - mean_squared_error: 1.4984 - val_loss: 1.4805 - val_mean_absolute_error: 0.8764 - val_mean_squared_error: 1.4805\n",
            "Epoch 381/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.5071 - mean_absolute_error: 0.8753 - mean_squared_error: 1.5071\n",
            "Epoch 381: val_loss improved from 1.48054 to 1.47694, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4981 - mean_absolute_error: 0.8713 - mean_squared_error: 1.4981 - val_loss: 1.4769 - val_mean_absolute_error: 0.8761 - val_mean_squared_error: 1.4769\n",
            "Epoch 382/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.4770 - mean_absolute_error: 0.8683 - mean_squared_error: 1.4770\n",
            "Epoch 382: val_loss improved from 1.47694 to 1.47644, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4965 - mean_absolute_error: 0.8716 - mean_squared_error: 1.4965 - val_loss: 1.4764 - val_mean_absolute_error: 0.8751 - val_mean_squared_error: 1.4764\n",
            "Epoch 383/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.4910 - mean_absolute_error: 0.8683 - mean_squared_error: 1.4910\n",
            "Epoch 383: val_loss improved from 1.47644 to 1.47281, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4940 - mean_absolute_error: 0.8695 - mean_squared_error: 1.4940 - val_loss: 1.4728 - val_mean_absolute_error: 0.8740 - val_mean_squared_error: 1.4728\n",
            "Epoch 384/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.4993 - mean_absolute_error: 0.8733 - mean_squared_error: 1.4993\n",
            "Epoch 384: val_loss did not improve from 1.47281\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4929 - mean_absolute_error: 0.8715 - mean_squared_error: 1.4929 - val_loss: 1.4768 - val_mean_absolute_error: 0.8740 - val_mean_squared_error: 1.4768\n",
            "Epoch 385/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.5021 - mean_absolute_error: 0.8726 - mean_squared_error: 1.5021\n",
            "Epoch 385: val_loss did not improve from 1.47281\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4911 - mean_absolute_error: 0.8690 - mean_squared_error: 1.4911 - val_loss: 1.4734 - val_mean_absolute_error: 0.8715 - val_mean_squared_error: 1.4734\n",
            "Epoch 386/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.4679 - mean_absolute_error: 0.8610 - mean_squared_error: 1.4679\n",
            "Epoch 386: val_loss improved from 1.47281 to 1.46953, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4899 - mean_absolute_error: 0.8671 - mean_squared_error: 1.4899 - val_loss: 1.4695 - val_mean_absolute_error: 0.8717 - val_mean_squared_error: 1.4695\n",
            "Epoch 387/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.4841 - mean_absolute_error: 0.8665 - mean_squared_error: 1.4841\n",
            "Epoch 387: val_loss improved from 1.46953 to 1.46737, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4867 - mean_absolute_error: 0.8676 - mean_squared_error: 1.4867 - val_loss: 1.4674 - val_mean_absolute_error: 0.8699 - val_mean_squared_error: 1.4674\n",
            "Epoch 388/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.4760 - mean_absolute_error: 0.8625 - mean_squared_error: 1.4760\n",
            "Epoch 388: val_loss improved from 1.46737 to 1.46542, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4845 - mean_absolute_error: 0.8653 - mean_squared_error: 1.4845 - val_loss: 1.4654 - val_mean_absolute_error: 0.8702 - val_mean_squared_error: 1.4654\n",
            "Epoch 389/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.4807 - mean_absolute_error: 0.8641 - mean_squared_error: 1.4807\n",
            "Epoch 389: val_loss improved from 1.46542 to 1.46431, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4832 - mean_absolute_error: 0.8646 - mean_squared_error: 1.4832 - val_loss: 1.4643 - val_mean_absolute_error: 0.8697 - val_mean_squared_error: 1.4643\n",
            "Epoch 390/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.4819 - mean_absolute_error: 0.8630 - mean_squared_error: 1.4819\n",
            "Epoch 390: val_loss did not improve from 1.46431\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4815 - mean_absolute_error: 0.8636 - mean_squared_error: 1.4815 - val_loss: 1.4656 - val_mean_absolute_error: 0.8719 - val_mean_squared_error: 1.4656\n",
            "Epoch 391/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.4717 - mean_absolute_error: 0.8620 - mean_squared_error: 1.4717\n",
            "Epoch 391: val_loss improved from 1.46431 to 1.46223, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4804 - mean_absolute_error: 0.8640 - mean_squared_error: 1.4804 - val_loss: 1.4622 - val_mean_absolute_error: 0.8690 - val_mean_squared_error: 1.4622\n",
            "Epoch 392/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.4843 - mean_absolute_error: 0.8644 - mean_squared_error: 1.4843\n",
            "Epoch 392: val_loss improved from 1.46223 to 1.45721, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4794 - mean_absolute_error: 0.8633 - mean_squared_error: 1.4794 - val_loss: 1.4572 - val_mean_absolute_error: 0.8664 - val_mean_squared_error: 1.4572\n",
            "Epoch 393/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.4809 - mean_absolute_error: 0.8668 - mean_squared_error: 1.4809\n",
            "Epoch 393: val_loss improved from 1.45721 to 1.45661, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4765 - mean_absolute_error: 0.8648 - mean_squared_error: 1.4765 - val_loss: 1.4566 - val_mean_absolute_error: 0.8634 - val_mean_squared_error: 1.4566\n",
            "Epoch 394/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.4742 - mean_absolute_error: 0.8604 - mean_squared_error: 1.4742\n",
            "Epoch 394: val_loss improved from 1.45661 to 1.45403, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4747 - mean_absolute_error: 0.8602 - mean_squared_error: 1.4747 - val_loss: 1.4540 - val_mean_absolute_error: 0.8612 - val_mean_squared_error: 1.4540\n",
            "Epoch 395/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.4615 - mean_absolute_error: 0.8561 - mean_squared_error: 1.4615\n",
            "Epoch 395: val_loss improved from 1.45403 to 1.45068, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4742 - mean_absolute_error: 0.8606 - mean_squared_error: 1.4742 - val_loss: 1.4507 - val_mean_absolute_error: 0.8614 - val_mean_squared_error: 1.4507\n",
            "Epoch 396/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.4733 - mean_absolute_error: 0.8590 - mean_squared_error: 1.4733\n",
            "Epoch 396: val_loss did not improve from 1.45068\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4719 - mean_absolute_error: 0.8588 - mean_squared_error: 1.4719 - val_loss: 1.4598 - val_mean_absolute_error: 0.8658 - val_mean_squared_error: 1.4598\n",
            "Epoch 397/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.4591 - mean_absolute_error: 0.8572 - mean_squared_error: 1.4591\n",
            "Epoch 397: val_loss improved from 1.45068 to 1.44904, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4672 - mean_absolute_error: 0.8588 - mean_squared_error: 1.4672 - val_loss: 1.4490 - val_mean_absolute_error: 0.8593 - val_mean_squared_error: 1.4490\n",
            "Epoch 398/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.4810 - mean_absolute_error: 0.8608 - mean_squared_error: 1.4810\n",
            "Epoch 398: val_loss improved from 1.44904 to 1.44727, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4691 - mean_absolute_error: 0.8572 - mean_squared_error: 1.4691 - val_loss: 1.4473 - val_mean_absolute_error: 0.8612 - val_mean_squared_error: 1.4473\n",
            "Epoch 399/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.4676 - mean_absolute_error: 0.8567 - mean_squared_error: 1.4676\n",
            "Epoch 399: val_loss did not improve from 1.44727\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4642 - mean_absolute_error: 0.8562 - mean_squared_error: 1.4642 - val_loss: 1.4503 - val_mean_absolute_error: 0.8641 - val_mean_squared_error: 1.4503\n",
            "Epoch 400/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.4887 - mean_absolute_error: 0.8647 - mean_squared_error: 1.4887\n",
            "Epoch 400: val_loss improved from 1.44727 to 1.44614, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4643 - mean_absolute_error: 0.8564 - mean_squared_error: 1.4643 - val_loss: 1.4461 - val_mean_absolute_error: 0.8608 - val_mean_squared_error: 1.4461\n",
            "Epoch 401/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.4859 - mean_absolute_error: 0.8639 - mean_squared_error: 1.4859\n",
            "Epoch 401: val_loss improved from 1.44614 to 1.44343, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4625 - mean_absolute_error: 0.8574 - mean_squared_error: 1.4625 - val_loss: 1.4434 - val_mean_absolute_error: 0.8593 - val_mean_squared_error: 1.4434\n",
            "Epoch 402/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.4575 - mean_absolute_error: 0.8526 - mean_squared_error: 1.4575\n",
            "Epoch 402: val_loss did not improve from 1.44343\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4585 - mean_absolute_error: 0.8536 - mean_squared_error: 1.4585 - val_loss: 1.4451 - val_mean_absolute_error: 0.8574 - val_mean_squared_error: 1.4451\n",
            "Epoch 403/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.4587 - mean_absolute_error: 0.8518 - mean_squared_error: 1.4587\n",
            "Epoch 403: val_loss improved from 1.44343 to 1.43812, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4587 - mean_absolute_error: 0.8518 - mean_squared_error: 1.4587 - val_loss: 1.4381 - val_mean_absolute_error: 0.8558 - val_mean_squared_error: 1.4381\n",
            "Epoch 404/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.4666 - mean_absolute_error: 0.8568 - mean_squared_error: 1.4666\n",
            "Epoch 404: val_loss did not improve from 1.43812\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4554 - mean_absolute_error: 0.8530 - mean_squared_error: 1.4554 - val_loss: 1.4413 - val_mean_absolute_error: 0.8571 - val_mean_squared_error: 1.4413\n",
            "Epoch 405/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.4251 - mean_absolute_error: 0.8429 - mean_squared_error: 1.4251\n",
            "Epoch 405: val_loss improved from 1.43812 to 1.43592, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4547 - mean_absolute_error: 0.8513 - mean_squared_error: 1.4547 - val_loss: 1.4359 - val_mean_absolute_error: 0.8551 - val_mean_squared_error: 1.4359\n",
            "Epoch 406/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.4533 - mean_absolute_error: 0.8496 - mean_squared_error: 1.4533\n",
            "Epoch 406: val_loss improved from 1.43592 to 1.43239, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4532 - mean_absolute_error: 0.8496 - mean_squared_error: 1.4532 - val_loss: 1.4324 - val_mean_absolute_error: 0.8529 - val_mean_squared_error: 1.4324\n",
            "Epoch 407/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.4457 - mean_absolute_error: 0.8490 - mean_squared_error: 1.4457\n",
            "Epoch 407: val_loss improved from 1.43239 to 1.43105, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4506 - mean_absolute_error: 0.8506 - mean_squared_error: 1.4506 - val_loss: 1.4310 - val_mean_absolute_error: 0.8507 - val_mean_squared_error: 1.4310\n",
            "Epoch 408/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.4521 - mean_absolute_error: 0.8481 - mean_squared_error: 1.4521\n",
            "Epoch 408: val_loss did not improve from 1.43105\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4478 - mean_absolute_error: 0.8480 - mean_squared_error: 1.4478 - val_loss: 1.4354 - val_mean_absolute_error: 0.8527 - val_mean_squared_error: 1.4354\n",
            "Epoch 409/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.4478 - mean_absolute_error: 0.8464 - mean_squared_error: 1.4478\n",
            "Epoch 409: val_loss improved from 1.43105 to 1.42693, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4478 - mean_absolute_error: 0.8464 - mean_squared_error: 1.4478 - val_loss: 1.4269 - val_mean_absolute_error: 0.8502 - val_mean_squared_error: 1.4269\n",
            "Epoch 410/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.4562 - mean_absolute_error: 0.8522 - mean_squared_error: 1.4562\n",
            "Epoch 410: val_loss improved from 1.42693 to 1.42317, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4446 - mean_absolute_error: 0.8475 - mean_squared_error: 1.4446 - val_loss: 1.4232 - val_mean_absolute_error: 0.8464 - val_mean_squared_error: 1.4232\n",
            "Epoch 411/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.4511 - mean_absolute_error: 0.8448 - mean_squared_error: 1.4511\n",
            "Epoch 411: val_loss did not improve from 1.42317\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4420 - mean_absolute_error: 0.8434 - mean_squared_error: 1.4420 - val_loss: 1.4265 - val_mean_absolute_error: 0.8513 - val_mean_squared_error: 1.4265\n",
            "Epoch 412/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.4406 - mean_absolute_error: 0.8444 - mean_squared_error: 1.4406\n",
            "Epoch 412: val_loss did not improve from 1.42317\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4401 - mean_absolute_error: 0.8441 - mean_squared_error: 1.4401 - val_loss: 1.4239 - val_mean_absolute_error: 0.8486 - val_mean_squared_error: 1.4239\n",
            "Epoch 413/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 1.4488 - mean_absolute_error: 0.8449 - mean_squared_error: 1.4488\n",
            "Epoch 413: val_loss improved from 1.42317 to 1.42243, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4390 - mean_absolute_error: 0.8443 - mean_squared_error: 1.4390 - val_loss: 1.4224 - val_mean_absolute_error: 0.8467 - val_mean_squared_error: 1.4224\n",
            "Epoch 414/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.4319 - mean_absolute_error: 0.8419 - mean_squared_error: 1.4319\n",
            "Epoch 414: val_loss improved from 1.42243 to 1.41886, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4375 - mean_absolute_error: 0.8428 - mean_squared_error: 1.4375 - val_loss: 1.4189 - val_mean_absolute_error: 0.8445 - val_mean_squared_error: 1.4189\n",
            "Epoch 415/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.4562 - mean_absolute_error: 0.8454 - mean_squared_error: 1.4562\n",
            "Epoch 415: val_loss improved from 1.41886 to 1.41832, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4362 - mean_absolute_error: 0.8393 - mean_squared_error: 1.4362 - val_loss: 1.4183 - val_mean_absolute_error: 0.8462 - val_mean_squared_error: 1.4183\n",
            "Epoch 416/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.4361 - mean_absolute_error: 0.8399 - mean_squared_error: 1.4361\n",
            "Epoch 416: val_loss improved from 1.41832 to 1.41284, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4320 - mean_absolute_error: 0.8384 - mean_squared_error: 1.4320 - val_loss: 1.4128 - val_mean_absolute_error: 0.8438 - val_mean_squared_error: 1.4128\n",
            "Epoch 417/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.4187 - mean_absolute_error: 0.8386 - mean_squared_error: 1.4187\n",
            "Epoch 417: val_loss did not improve from 1.41284\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4305 - mean_absolute_error: 0.8408 - mean_squared_error: 1.4305 - val_loss: 1.4137 - val_mean_absolute_error: 0.8424 - val_mean_squared_error: 1.4137\n",
            "Epoch 418/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.4479 - mean_absolute_error: 0.8437 - mean_squared_error: 1.4479\n",
            "Epoch 418: val_loss improved from 1.41284 to 1.41081, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4285 - mean_absolute_error: 0.8368 - mean_squared_error: 1.4285 - val_loss: 1.4108 - val_mean_absolute_error: 0.8424 - val_mean_squared_error: 1.4108\n",
            "Epoch 419/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.4252 - mean_absolute_error: 0.8380 - mean_squared_error: 1.4252\n",
            "Epoch 419: val_loss improved from 1.41081 to 1.40979, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4272 - mean_absolute_error: 0.8379 - mean_squared_error: 1.4272 - val_loss: 1.4098 - val_mean_absolute_error: 0.8413 - val_mean_squared_error: 1.4098\n",
            "Epoch 420/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.4269 - mean_absolute_error: 0.8355 - mean_squared_error: 1.4269\n",
            "Epoch 420: val_loss improved from 1.40979 to 1.40548, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4253 - mean_absolute_error: 0.8351 - mean_squared_error: 1.4253 - val_loss: 1.4055 - val_mean_absolute_error: 0.8383 - val_mean_squared_error: 1.4055\n",
            "Epoch 421/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.4232 - mean_absolute_error: 0.8333 - mean_squared_error: 1.4232\n",
            "Epoch 421: val_loss did not improve from 1.40548\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4224 - mean_absolute_error: 0.8336 - mean_squared_error: 1.4224 - val_loss: 1.4092 - val_mean_absolute_error: 0.8395 - val_mean_squared_error: 1.4092\n",
            "Epoch 422/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.4192 - mean_absolute_error: 0.8324 - mean_squared_error: 1.4192\n",
            "Epoch 422: val_loss improved from 1.40548 to 1.40328, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4205 - mean_absolute_error: 0.8323 - mean_squared_error: 1.4205 - val_loss: 1.4033 - val_mean_absolute_error: 0.8359 - val_mean_squared_error: 1.4033\n",
            "Epoch 423/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.4304 - mean_absolute_error: 0.8362 - mean_squared_error: 1.4304\n",
            "Epoch 423: val_loss improved from 1.40328 to 1.40093, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4193 - mean_absolute_error: 0.8324 - mean_squared_error: 1.4193 - val_loss: 1.4009 - val_mean_absolute_error: 0.8347 - val_mean_squared_error: 1.4009\n",
            "Epoch 424/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.4380 - mean_absolute_error: 0.8372 - mean_squared_error: 1.4380\n",
            "Epoch 424: val_loss improved from 1.40093 to 1.39788, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4172 - mean_absolute_error: 0.8299 - mean_squared_error: 1.4172 - val_loss: 1.3979 - val_mean_absolute_error: 0.8339 - val_mean_squared_error: 1.3979\n",
            "Epoch 425/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 1.4219 - mean_absolute_error: 0.8275 - mean_squared_error: 1.4219\n",
            "Epoch 425: val_loss did not improve from 1.39788\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4139 - mean_absolute_error: 0.8273 - mean_squared_error: 1.4139 - val_loss: 1.4033 - val_mean_absolute_error: 0.8390 - val_mean_squared_error: 1.4033\n",
            "Epoch 426/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.4164 - mean_absolute_error: 0.8319 - mean_squared_error: 1.4164\n",
            "Epoch 426: val_loss improved from 1.39788 to 1.39572, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4128 - mean_absolute_error: 0.8309 - mean_squared_error: 1.4128 - val_loss: 1.3957 - val_mean_absolute_error: 0.8317 - val_mean_squared_error: 1.3957\n",
            "Epoch 427/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.4149 - mean_absolute_error: 0.8278 - mean_squared_error: 1.4149\n",
            "Epoch 427: val_loss did not improve from 1.39572\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4098 - mean_absolute_error: 0.8266 - mean_squared_error: 1.4098 - val_loss: 1.3992 - val_mean_absolute_error: 0.8351 - val_mean_squared_error: 1.3992\n",
            "Epoch 428/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.4216 - mean_absolute_error: 0.8315 - mean_squared_error: 1.4216\n",
            "Epoch 428: val_loss improved from 1.39572 to 1.38721, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4075 - mean_absolute_error: 0.8262 - mean_squared_error: 1.4075 - val_loss: 1.3872 - val_mean_absolute_error: 0.8271 - val_mean_squared_error: 1.3872\n",
            "Epoch 429/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.4181 - mean_absolute_error: 0.8275 - mean_squared_error: 1.4181\n",
            "Epoch 429: val_loss did not improve from 1.38721\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4062 - mean_absolute_error: 0.8249 - mean_squared_error: 1.4062 - val_loss: 1.3932 - val_mean_absolute_error: 0.8310 - val_mean_squared_error: 1.3932\n",
            "Epoch 430/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.4007 - mean_absolute_error: 0.8203 - mean_squared_error: 1.4007\n",
            "Epoch 430: val_loss did not improve from 1.38721\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4032 - mean_absolute_error: 0.8226 - mean_squared_error: 1.4032 - val_loss: 1.3950 - val_mean_absolute_error: 0.8314 - val_mean_squared_error: 1.3950\n",
            "Epoch 431/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.3977 - mean_absolute_error: 0.8240 - mean_squared_error: 1.3977\n",
            "Epoch 431: val_loss did not improve from 1.38721\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4024 - mean_absolute_error: 0.8243 - mean_squared_error: 1.4024 - val_loss: 1.3894 - val_mean_absolute_error: 0.8289 - val_mean_squared_error: 1.3894\n",
            "Epoch 432/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.4026 - mean_absolute_error: 0.8209 - mean_squared_error: 1.4026\n",
            "Epoch 432: val_loss improved from 1.38721 to 1.38070, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4010 - mean_absolute_error: 0.8205 - mean_squared_error: 1.4010 - val_loss: 1.3807 - val_mean_absolute_error: 0.8246 - val_mean_squared_error: 1.3807\n",
            "Epoch 433/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.3938 - mean_absolute_error: 0.8204 - mean_squared_error: 1.3938\n",
            "Epoch 433: val_loss improved from 1.38070 to 1.37767, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3972 - mean_absolute_error: 0.8206 - mean_squared_error: 1.3972 - val_loss: 1.3777 - val_mean_absolute_error: 0.8223 - val_mean_squared_error: 1.3777\n",
            "Epoch 434/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.4022 - mean_absolute_error: 0.8194 - mean_squared_error: 1.4022\n",
            "Epoch 434: val_loss did not improve from 1.37767\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3957 - mean_absolute_error: 0.8175 - mean_squared_error: 1.3957 - val_loss: 1.3784 - val_mean_absolute_error: 0.8236 - val_mean_squared_error: 1.3784\n",
            "Epoch 435/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.3933 - mean_absolute_error: 0.8179 - mean_squared_error: 1.3933\n",
            "Epoch 435: val_loss improved from 1.37767 to 1.37323, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3937 - mean_absolute_error: 0.8181 - mean_squared_error: 1.3937 - val_loss: 1.3732 - val_mean_absolute_error: 0.8202 - val_mean_squared_error: 1.3732\n",
            "Epoch 436/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.3993 - mean_absolute_error: 0.8191 - mean_squared_error: 1.3993\n",
            "Epoch 436: val_loss did not improve from 1.37323\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3924 - mean_absolute_error: 0.8165 - mean_squared_error: 1.3924 - val_loss: 1.3742 - val_mean_absolute_error: 0.8207 - val_mean_squared_error: 1.3742\n",
            "Epoch 437/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.3774 - mean_absolute_error: 0.8150 - mean_squared_error: 1.3774\n",
            "Epoch 437: val_loss did not improve from 1.37323\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3877 - mean_absolute_error: 0.8165 - mean_squared_error: 1.3877 - val_loss: 1.3802 - val_mean_absolute_error: 0.8244 - val_mean_squared_error: 1.3802\n",
            "Epoch 438/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.3896 - mean_absolute_error: 0.8159 - mean_squared_error: 1.3896\n",
            "Epoch 438: val_loss improved from 1.37323 to 1.36823, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3859 - mean_absolute_error: 0.8142 - mean_squared_error: 1.3859 - val_loss: 1.3682 - val_mean_absolute_error: 0.8178 - val_mean_squared_error: 1.3682\n",
            "Epoch 439/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.3921 - mean_absolute_error: 0.8153 - mean_squared_error: 1.3921\n",
            "Epoch 439: val_loss did not improve from 1.36823\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3859 - mean_absolute_error: 0.8142 - mean_squared_error: 1.3859 - val_loss: 1.3709 - val_mean_absolute_error: 0.8196 - val_mean_squared_error: 1.3709\n",
            "Epoch 440/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.3829 - mean_absolute_error: 0.8117 - mean_squared_error: 1.3829\n",
            "Epoch 440: val_loss improved from 1.36823 to 1.36714, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3825 - mean_absolute_error: 0.8115 - mean_squared_error: 1.3825 - val_loss: 1.3671 - val_mean_absolute_error: 0.8186 - val_mean_squared_error: 1.3671\n",
            "Epoch 441/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.3751 - mean_absolute_error: 0.8108 - mean_squared_error: 1.3751\n",
            "Epoch 441: val_loss improved from 1.36714 to 1.36368, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3801 - mean_absolute_error: 0.8119 - mean_squared_error: 1.3801 - val_loss: 1.3637 - val_mean_absolute_error: 0.8147 - val_mean_squared_error: 1.3637\n",
            "Epoch 442/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.3879 - mean_absolute_error: 0.8119 - mean_squared_error: 1.3879\n",
            "Epoch 442: val_loss improved from 1.36368 to 1.36317, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3777 - mean_absolute_error: 0.8090 - mean_squared_error: 1.3777 - val_loss: 1.3632 - val_mean_absolute_error: 0.8162 - val_mean_squared_error: 1.3632\n",
            "Epoch 443/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.3658 - mean_absolute_error: 0.8062 - mean_squared_error: 1.3658\n",
            "Epoch 443: val_loss improved from 1.36317 to 1.36053, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3753 - mean_absolute_error: 0.8106 - mean_squared_error: 1.3753 - val_loss: 1.3605 - val_mean_absolute_error: 0.8160 - val_mean_squared_error: 1.3605\n",
            "Epoch 444/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.3745 - mean_absolute_error: 0.8084 - mean_squared_error: 1.3745\n",
            "Epoch 444: val_loss improved from 1.36053 to 1.35771, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3733 - mean_absolute_error: 0.8076 - mean_squared_error: 1.3733 - val_loss: 1.3577 - val_mean_absolute_error: 0.8153 - val_mean_squared_error: 1.3577\n",
            "Epoch 445/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.3819 - mean_absolute_error: 0.8151 - mean_squared_error: 1.3819\n",
            "Epoch 445: val_loss did not improve from 1.35771\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3709 - mean_absolute_error: 0.8103 - mean_squared_error: 1.3709 - val_loss: 1.3589 - val_mean_absolute_error: 0.8158 - val_mean_squared_error: 1.3589\n",
            "Epoch 446/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.3651 - mean_absolute_error: 0.8057 - mean_squared_error: 1.3651\n",
            "Epoch 446: val_loss improved from 1.35771 to 1.35075, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3694 - mean_absolute_error: 0.8060 - mean_squared_error: 1.3694 - val_loss: 1.3508 - val_mean_absolute_error: 0.8106 - val_mean_squared_error: 1.3508\n",
            "Epoch 447/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.3669 - mean_absolute_error: 0.8054 - mean_squared_error: 1.3669\n",
            "Epoch 447: val_loss improved from 1.35075 to 1.34856, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3671 - mean_absolute_error: 0.8061 - mean_squared_error: 1.3671 - val_loss: 1.3486 - val_mean_absolute_error: 0.8109 - val_mean_squared_error: 1.3486\n",
            "Epoch 448/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.3675 - mean_absolute_error: 0.8073 - mean_squared_error: 1.3675\n",
            "Epoch 448: val_loss did not improve from 1.34856\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3638 - mean_absolute_error: 0.8065 - mean_squared_error: 1.3638 - val_loss: 1.3540 - val_mean_absolute_error: 0.8140 - val_mean_squared_error: 1.3540\n",
            "Epoch 449/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.3549 - mean_absolute_error: 0.8017 - mean_squared_error: 1.3549\n",
            "Epoch 449: val_loss improved from 1.34856 to 1.34672, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3616 - mean_absolute_error: 0.8040 - mean_squared_error: 1.3616 - val_loss: 1.3467 - val_mean_absolute_error: 0.8088 - val_mean_squared_error: 1.3467\n",
            "Epoch 450/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.3537 - mean_absolute_error: 0.8016 - mean_squared_error: 1.3537\n",
            "Epoch 450: val_loss improved from 1.34672 to 1.34163, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3595 - mean_absolute_error: 0.8036 - mean_squared_error: 1.3595 - val_loss: 1.3416 - val_mean_absolute_error: 0.8076 - val_mean_squared_error: 1.3416\n",
            "Epoch 451/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.3698 - mean_absolute_error: 0.8089 - mean_squared_error: 1.3698\n",
            "Epoch 451: val_loss did not improve from 1.34163\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3564 - mean_absolute_error: 0.8045 - mean_squared_error: 1.3564 - val_loss: 1.3483 - val_mean_absolute_error: 0.8121 - val_mean_squared_error: 1.3483\n",
            "Epoch 452/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.3792 - mean_absolute_error: 0.8101 - mean_squared_error: 1.3792\n",
            "Epoch 452: val_loss improved from 1.34163 to 1.34061, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3555 - mean_absolute_error: 0.8025 - mean_squared_error: 1.3555 - val_loss: 1.3406 - val_mean_absolute_error: 0.8060 - val_mean_squared_error: 1.3406\n",
            "Epoch 453/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.3553 - mean_absolute_error: 0.8034 - mean_squared_error: 1.3553\n",
            "Epoch 453: val_loss improved from 1.34061 to 1.33978, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3525 - mean_absolute_error: 0.8020 - mean_squared_error: 1.3525 - val_loss: 1.3398 - val_mean_absolute_error: 0.8064 - val_mean_squared_error: 1.3398\n",
            "Epoch 454/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.3384 - mean_absolute_error: 0.7976 - mean_squared_error: 1.3384\n",
            "Epoch 454: val_loss did not improve from 1.33978\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3495 - mean_absolute_error: 0.8005 - mean_squared_error: 1.3495 - val_loss: 1.3400 - val_mean_absolute_error: 0.8081 - val_mean_squared_error: 1.3400\n",
            "Epoch 455/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.3529 - mean_absolute_error: 0.8015 - mean_squared_error: 1.3529\n",
            "Epoch 455: val_loss improved from 1.33978 to 1.33727, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3482 - mean_absolute_error: 0.7994 - mean_squared_error: 1.3482 - val_loss: 1.3373 - val_mean_absolute_error: 0.8069 - val_mean_squared_error: 1.3373\n",
            "Epoch 456/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.3764 - mean_absolute_error: 0.8095 - mean_squared_error: 1.3764\n",
            "Epoch 456: val_loss improved from 1.33727 to 1.32979, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3473 - mean_absolute_error: 0.8005 - mean_squared_error: 1.3473 - val_loss: 1.3298 - val_mean_absolute_error: 0.8027 - val_mean_squared_error: 1.3298\n",
            "Epoch 457/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.3538 - mean_absolute_error: 0.8033 - mean_squared_error: 1.3538\n",
            "Epoch 457: val_loss did not improve from 1.32979\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3424 - mean_absolute_error: 0.8000 - mean_squared_error: 1.3424 - val_loss: 1.3386 - val_mean_absolute_error: 0.8085 - val_mean_squared_error: 1.3386\n",
            "Epoch 458/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.3422 - mean_absolute_error: 0.7977 - mean_squared_error: 1.3422\n",
            "Epoch 458: val_loss improved from 1.32979 to 1.32817, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3422 - mean_absolute_error: 0.7977 - mean_squared_error: 1.3422 - val_loss: 1.3282 - val_mean_absolute_error: 0.8039 - val_mean_squared_error: 1.3282\n",
            "Epoch 459/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.3435 - mean_absolute_error: 0.7994 - mean_squared_error: 1.3435\n",
            "Epoch 459: val_loss did not improve from 1.32817\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3390 - mean_absolute_error: 0.7977 - mean_squared_error: 1.3390 - val_loss: 1.3284 - val_mean_absolute_error: 0.8045 - val_mean_squared_error: 1.3284\n",
            "Epoch 460/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.3409 - mean_absolute_error: 0.7964 - mean_squared_error: 1.3409\n",
            "Epoch 460: val_loss improved from 1.32817 to 1.32561, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3369 - mean_absolute_error: 0.7963 - mean_squared_error: 1.3369 - val_loss: 1.3256 - val_mean_absolute_error: 0.8047 - val_mean_squared_error: 1.3256\n",
            "Epoch 461/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.3342 - mean_absolute_error: 0.7976 - mean_squared_error: 1.3342\n",
            "Epoch 461: val_loss improved from 1.32561 to 1.32141, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3356 - mean_absolute_error: 0.7982 - mean_squared_error: 1.3356 - val_loss: 1.3214 - val_mean_absolute_error: 0.8021 - val_mean_squared_error: 1.3214\n",
            "Epoch 462/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.3268 - mean_absolute_error: 0.7932 - mean_squared_error: 1.3268\n",
            "Epoch 462: val_loss did not improve from 1.32141\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3326 - mean_absolute_error: 0.7954 - mean_squared_error: 1.3326 - val_loss: 1.3231 - val_mean_absolute_error: 0.8044 - val_mean_squared_error: 1.3231\n",
            "Epoch 463/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.3227 - mean_absolute_error: 0.7925 - mean_squared_error: 1.3227\n",
            "Epoch 463: val_loss improved from 1.32141 to 1.32099, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3309 - mean_absolute_error: 0.7958 - mean_squared_error: 1.3309 - val_loss: 1.3210 - val_mean_absolute_error: 0.8028 - val_mean_squared_error: 1.3210\n",
            "Epoch 464/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.3214 - mean_absolute_error: 0.7943 - mean_squared_error: 1.3214\n",
            "Epoch 464: val_loss improved from 1.32099 to 1.31534, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3305 - mean_absolute_error: 0.7969 - mean_squared_error: 1.3305 - val_loss: 1.3153 - val_mean_absolute_error: 0.7982 - val_mean_squared_error: 1.3153\n",
            "Epoch 465/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.3312 - mean_absolute_error: 0.7952 - mean_squared_error: 1.3312\n",
            "Epoch 465: val_loss did not improve from 1.31534\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3275 - mean_absolute_error: 0.7950 - mean_squared_error: 1.3275 - val_loss: 1.3225 - val_mean_absolute_error: 0.8055 - val_mean_squared_error: 1.3225\n",
            "Epoch 466/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.3206 - mean_absolute_error: 0.7930 - mean_squared_error: 1.3206\n",
            "Epoch 466: val_loss did not improve from 1.31534\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3249 - mean_absolute_error: 0.7943 - mean_squared_error: 1.3249 - val_loss: 1.3164 - val_mean_absolute_error: 0.8024 - val_mean_squared_error: 1.3164\n",
            "Epoch 467/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.3086 - mean_absolute_error: 0.7890 - mean_squared_error: 1.3086\n",
            "Epoch 467: val_loss improved from 1.31534 to 1.31091, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3215 - mean_absolute_error: 0.7923 - mean_squared_error: 1.3215 - val_loss: 1.3109 - val_mean_absolute_error: 0.7998 - val_mean_squared_error: 1.3109\n",
            "Epoch 468/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.3076 - mean_absolute_error: 0.7890 - mean_squared_error: 1.3076\n",
            "Epoch 468: val_loss improved from 1.31091 to 1.30740, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3194 - mean_absolute_error: 0.7933 - mean_squared_error: 1.3194 - val_loss: 1.3074 - val_mean_absolute_error: 0.7986 - val_mean_squared_error: 1.3074\n",
            "Epoch 469/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.3181 - mean_absolute_error: 0.7936 - mean_squared_error: 1.3181\n",
            "Epoch 469: val_loss did not improve from 1.30740\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3180 - mean_absolute_error: 0.7939 - mean_squared_error: 1.3180 - val_loss: 1.3074 - val_mean_absolute_error: 0.7983 - val_mean_squared_error: 1.3074\n",
            "Epoch 470/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.3162 - mean_absolute_error: 0.7935 - mean_squared_error: 1.3162\n",
            "Epoch 470: val_loss improved from 1.30740 to 1.30692, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3156 - mean_absolute_error: 0.7925 - mean_squared_error: 1.3156 - val_loss: 1.3069 - val_mean_absolute_error: 0.7988 - val_mean_squared_error: 1.3069\n",
            "Epoch 471/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.3119 - mean_absolute_error: 0.7921 - mean_squared_error: 1.3119\n",
            "Epoch 471: val_loss did not improve from 1.30692\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3133 - mean_absolute_error: 0.7919 - mean_squared_error: 1.3133 - val_loss: 1.3126 - val_mean_absolute_error: 0.8052 - val_mean_squared_error: 1.3126\n",
            "Epoch 472/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.3178 - mean_absolute_error: 0.7955 - mean_squared_error: 1.3178\n",
            "Epoch 472: val_loss improved from 1.30692 to 1.30526, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3116 - mean_absolute_error: 0.7934 - mean_squared_error: 1.3116 - val_loss: 1.3053 - val_mean_absolute_error: 0.7994 - val_mean_squared_error: 1.3053\n",
            "Epoch 473/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.3054 - mean_absolute_error: 0.7875 - mean_squared_error: 1.3054\n",
            "Epoch 473: val_loss improved from 1.30526 to 1.30180, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3095 - mean_absolute_error: 0.7899 - mean_squared_error: 1.3095 - val_loss: 1.3018 - val_mean_absolute_error: 0.7990 - val_mean_squared_error: 1.3018\n",
            "Epoch 474/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.3029 - mean_absolute_error: 0.7924 - mean_squared_error: 1.3029\n",
            "Epoch 474: val_loss improved from 1.30180 to 1.29758, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3068 - mean_absolute_error: 0.7916 - mean_squared_error: 1.3068 - val_loss: 1.2976 - val_mean_absolute_error: 0.7971 - val_mean_squared_error: 1.2976\n",
            "Epoch 475/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.3135 - mean_absolute_error: 0.7930 - mean_squared_error: 1.3135\n",
            "Epoch 475: val_loss improved from 1.29758 to 1.29573, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3059 - mean_absolute_error: 0.7908 - mean_squared_error: 1.3059 - val_loss: 1.2957 - val_mean_absolute_error: 0.7982 - val_mean_squared_error: 1.2957\n",
            "Epoch 476/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.3008 - mean_absolute_error: 0.7896 - mean_squared_error: 1.3008\n",
            "Epoch 476: val_loss improved from 1.29573 to 1.29338, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3026 - mean_absolute_error: 0.7912 - mean_squared_error: 1.3026 - val_loss: 1.2934 - val_mean_absolute_error: 0.7949 - val_mean_squared_error: 1.2934\n",
            "Epoch 477/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.2969 - mean_absolute_error: 0.7888 - mean_squared_error: 1.2969\n",
            "Epoch 477: val_loss improved from 1.29338 to 1.29170, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3019 - mean_absolute_error: 0.7902 - mean_squared_error: 1.3019 - val_loss: 1.2917 - val_mean_absolute_error: 0.7952 - val_mean_squared_error: 1.2917\n",
            "Epoch 478/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.2982 - mean_absolute_error: 0.7891 - mean_squared_error: 1.2982\n",
            "Epoch 478: val_loss did not improve from 1.29170\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2989 - mean_absolute_error: 0.7893 - mean_squared_error: 1.2989 - val_loss: 1.2956 - val_mean_absolute_error: 0.7987 - val_mean_squared_error: 1.2956\n",
            "Epoch 479/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.2857 - mean_absolute_error: 0.7856 - mean_squared_error: 1.2857\n",
            "Epoch 479: val_loss improved from 1.29170 to 1.28753, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2982 - mean_absolute_error: 0.7896 - mean_squared_error: 1.2982 - val_loss: 1.2875 - val_mean_absolute_error: 0.7959 - val_mean_squared_error: 1.2875\n",
            "Epoch 480/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.3017 - mean_absolute_error: 0.7922 - mean_squared_error: 1.3017\n",
            "Epoch 480: val_loss improved from 1.28753 to 1.28631, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2957 - mean_absolute_error: 0.7897 - mean_squared_error: 1.2957 - val_loss: 1.2863 - val_mean_absolute_error: 0.7959 - val_mean_squared_error: 1.2863\n",
            "Epoch 481/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.2943 - mean_absolute_error: 0.7884 - mean_squared_error: 1.2943\n",
            "Epoch 481: val_loss improved from 1.28631 to 1.28240, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2934 - mean_absolute_error: 0.7896 - mean_squared_error: 1.2934 - val_loss: 1.2824 - val_mean_absolute_error: 0.7931 - val_mean_squared_error: 1.2824\n",
            "Epoch 482/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.2865 - mean_absolute_error: 0.7876 - mean_squared_error: 1.2865\n",
            "Epoch 482: val_loss did not improve from 1.28240\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2905 - mean_absolute_error: 0.7883 - mean_squared_error: 1.2905 - val_loss: 1.2837 - val_mean_absolute_error: 0.7946 - val_mean_squared_error: 1.2837\n",
            "Epoch 483/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.2866 - mean_absolute_error: 0.7874 - mean_squared_error: 1.2866\n",
            "Epoch 483: val_loss did not improve from 1.28240\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2897 - mean_absolute_error: 0.7884 - mean_squared_error: 1.2897 - val_loss: 1.2827 - val_mean_absolute_error: 0.7973 - val_mean_squared_error: 1.2827\n",
            "Epoch 484/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.2844 - mean_absolute_error: 0.7880 - mean_squared_error: 1.2844\n",
            "Epoch 484: val_loss improved from 1.28240 to 1.28112, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2844 - mean_absolute_error: 0.7880 - mean_squared_error: 1.2844 - val_loss: 1.2811 - val_mean_absolute_error: 0.7965 - val_mean_squared_error: 1.2811\n",
            "Epoch 485/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.2791 - mean_absolute_error: 0.7874 - mean_squared_error: 1.2791\n",
            "Epoch 485: val_loss improved from 1.28112 to 1.27524, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2839 - mean_absolute_error: 0.7886 - mean_squared_error: 1.2839 - val_loss: 1.2752 - val_mean_absolute_error: 0.7917 - val_mean_squared_error: 1.2752\n",
            "Epoch 486/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.3042 - mean_absolute_error: 0.7949 - mean_squared_error: 1.3042\n",
            "Epoch 486: val_loss did not improve from 1.27524\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2827 - mean_absolute_error: 0.7877 - mean_squared_error: 1.2827 - val_loss: 1.2790 - val_mean_absolute_error: 0.7948 - val_mean_squared_error: 1.2790\n",
            "Epoch 487/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.2801 - mean_absolute_error: 0.7877 - mean_squared_error: 1.2801\n",
            "Epoch 487: val_loss did not improve from 1.27524\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2794 - mean_absolute_error: 0.7877 - mean_squared_error: 1.2794 - val_loss: 1.2790 - val_mean_absolute_error: 0.7928 - val_mean_squared_error: 1.2790\n",
            "Epoch 488/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.2827 - mean_absolute_error: 0.7868 - mean_squared_error: 1.2827\n",
            "Epoch 488: val_loss improved from 1.27524 to 1.27198, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2792 - mean_absolute_error: 0.7867 - mean_squared_error: 1.2792 - val_loss: 1.2720 - val_mean_absolute_error: 0.7922 - val_mean_squared_error: 1.2720\n",
            "Epoch 489/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.2766 - mean_absolute_error: 0.7870 - mean_squared_error: 1.2766\n",
            "Epoch 489: val_loss did not improve from 1.27198\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2767 - mean_absolute_error: 0.7873 - mean_squared_error: 1.2767 - val_loss: 1.2928 - val_mean_absolute_error: 0.8061 - val_mean_squared_error: 1.2928\n",
            "Epoch 490/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.2801 - mean_absolute_error: 0.7868 - mean_squared_error: 1.2801\n",
            "Epoch 490: val_loss improved from 1.27198 to 1.27137, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2760 - mean_absolute_error: 0.7866 - mean_squared_error: 1.2760 - val_loss: 1.2714 - val_mean_absolute_error: 0.7941 - val_mean_squared_error: 1.2714\n",
            "Epoch 491/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.2738 - mean_absolute_error: 0.7861 - mean_squared_error: 1.2738\n",
            "Epoch 491: val_loss improved from 1.27137 to 1.26992, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2733 - mean_absolute_error: 0.7873 - mean_squared_error: 1.2733 - val_loss: 1.2699 - val_mean_absolute_error: 0.7945 - val_mean_squared_error: 1.2699\n",
            "Epoch 492/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.2697 - mean_absolute_error: 0.7854 - mean_squared_error: 1.2697\n",
            "Epoch 492: val_loss improved from 1.26992 to 1.26718, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2703 - mean_absolute_error: 0.7859 - mean_squared_error: 1.2703 - val_loss: 1.2672 - val_mean_absolute_error: 0.7948 - val_mean_squared_error: 1.2672\n",
            "Epoch 493/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.2767 - mean_absolute_error: 0.7910 - mean_squared_error: 1.2767\n",
            "Epoch 493: val_loss did not improve from 1.26718\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2677 - mean_absolute_error: 0.7871 - mean_squared_error: 1.2677 - val_loss: 1.2750 - val_mean_absolute_error: 0.7973 - val_mean_squared_error: 1.2750\n",
            "Epoch 494/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.2798 - mean_absolute_error: 0.7872 - mean_squared_error: 1.2798\n",
            "Epoch 494: val_loss improved from 1.26718 to 1.26451, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2684 - mean_absolute_error: 0.7850 - mean_squared_error: 1.2684 - val_loss: 1.2645 - val_mean_absolute_error: 0.7961 - val_mean_squared_error: 1.2645\n",
            "Epoch 495/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.2560 - mean_absolute_error: 0.7829 - mean_squared_error: 1.2560\n",
            "Epoch 495: val_loss improved from 1.26451 to 1.25774, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2657 - mean_absolute_error: 0.7871 - mean_squared_error: 1.2657 - val_loss: 1.2577 - val_mean_absolute_error: 0.7900 - val_mean_squared_error: 1.2577\n",
            "Epoch 496/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.2549 - mean_absolute_error: 0.7815 - mean_squared_error: 1.2549\n",
            "Epoch 496: val_loss did not improve from 1.25774\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2634 - mean_absolute_error: 0.7850 - mean_squared_error: 1.2634 - val_loss: 1.2592 - val_mean_absolute_error: 0.7927 - val_mean_squared_error: 1.2592\n",
            "Epoch 497/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.2627 - mean_absolute_error: 0.7872 - mean_squared_error: 1.2627\n",
            "Epoch 497: val_loss did not improve from 1.25774\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2623 - mean_absolute_error: 0.7859 - mean_squared_error: 1.2623 - val_loss: 1.2588 - val_mean_absolute_error: 0.7923 - val_mean_squared_error: 1.2588\n",
            "Epoch 498/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.2530 - mean_absolute_error: 0.7827 - mean_squared_error: 1.2530\n",
            "Epoch 498: val_loss improved from 1.25774 to 1.25078, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2596 - mean_absolute_error: 0.7836 - mean_squared_error: 1.2596 - val_loss: 1.2508 - val_mean_absolute_error: 0.7901 - val_mean_squared_error: 1.2508\n",
            "Epoch 499/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.2312 - mean_absolute_error: 0.7779 - mean_squared_error: 1.2312\n",
            "Epoch 499: val_loss did not improve from 1.25078\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2565 - mean_absolute_error: 0.7858 - mean_squared_error: 1.2565 - val_loss: 1.2562 - val_mean_absolute_error: 0.7928 - val_mean_squared_error: 1.2562\n",
            "Epoch 500/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.2554 - mean_absolute_error: 0.7838 - mean_squared_error: 1.2554\n",
            "Epoch 500: val_loss did not improve from 1.25078\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2544 - mean_absolute_error: 0.7837 - mean_squared_error: 1.2544 - val_loss: 1.2533 - val_mean_absolute_error: 0.7921 - val_mean_squared_error: 1.2533\n",
            "Epoch 501/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.2485 - mean_absolute_error: 0.7823 - mean_squared_error: 1.2485\n",
            "Epoch 501: val_loss improved from 1.25078 to 1.24544, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2520 - mean_absolute_error: 0.7836 - mean_squared_error: 1.2520 - val_loss: 1.2454 - val_mean_absolute_error: 0.7900 - val_mean_squared_error: 1.2454\n",
            "Epoch 502/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.2586 - mean_absolute_error: 0.7872 - mean_squared_error: 1.2586\n",
            "Epoch 502: val_loss improved from 1.24544 to 1.24374, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2515 - mean_absolute_error: 0.7833 - mean_squared_error: 1.2515 - val_loss: 1.2437 - val_mean_absolute_error: 0.7907 - val_mean_squared_error: 1.2437\n",
            "Epoch 503/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.2337 - mean_absolute_error: 0.7793 - mean_squared_error: 1.2337\n",
            "Epoch 503: val_loss did not improve from 1.24374\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2496 - mean_absolute_error: 0.7837 - mean_squared_error: 1.2496 - val_loss: 1.2446 - val_mean_absolute_error: 0.7912 - val_mean_squared_error: 1.2446\n",
            "Epoch 504/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.2523 - mean_absolute_error: 0.7853 - mean_squared_error: 1.2523\n",
            "Epoch 504: val_loss improved from 1.24374 to 1.24161, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2490 - mean_absolute_error: 0.7839 - mean_squared_error: 1.2490 - val_loss: 1.2416 - val_mean_absolute_error: 0.7894 - val_mean_squared_error: 1.2416\n",
            "Epoch 505/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.2425 - mean_absolute_error: 0.7821 - mean_squared_error: 1.2425\n",
            "Epoch 505: val_loss did not improve from 1.24161\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2472 - mean_absolute_error: 0.7832 - mean_squared_error: 1.2472 - val_loss: 1.2428 - val_mean_absolute_error: 0.7889 - val_mean_squared_error: 1.2428\n",
            "Epoch 506/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.2405 - mean_absolute_error: 0.7825 - mean_squared_error: 1.2405\n",
            "Epoch 506: val_loss improved from 1.24161 to 1.23819, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2451 - mean_absolute_error: 0.7844 - mean_squared_error: 1.2451 - val_loss: 1.2382 - val_mean_absolute_error: 0.7884 - val_mean_squared_error: 1.2382\n",
            "Epoch 507/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.2451 - mean_absolute_error: 0.7842 - mean_squared_error: 1.2451\n",
            "Epoch 507: val_loss did not improve from 1.23819\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2433 - mean_absolute_error: 0.7831 - mean_squared_error: 1.2433 - val_loss: 1.2393 - val_mean_absolute_error: 0.7908 - val_mean_squared_error: 1.2393\n",
            "Epoch 508/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.2382 - mean_absolute_error: 0.7833 - mean_squared_error: 1.2382\n",
            "Epoch 508: val_loss did not improve from 1.23819\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2412 - mean_absolute_error: 0.7834 - mean_squared_error: 1.2412 - val_loss: 1.2406 - val_mean_absolute_error: 0.7909 - val_mean_squared_error: 1.2406\n",
            "Epoch 509/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.2434 - mean_absolute_error: 0.7838 - mean_squared_error: 1.2434\n",
            "Epoch 509: val_loss improved from 1.23819 to 1.22857, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2384 - mean_absolute_error: 0.7820 - mean_squared_error: 1.2384 - val_loss: 1.2286 - val_mean_absolute_error: 0.7877 - val_mean_squared_error: 1.2286\n",
            "Epoch 510/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.2568 - mean_absolute_error: 0.7893 - mean_squared_error: 1.2568\n",
            "Epoch 510: val_loss did not improve from 1.22857\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2371 - mean_absolute_error: 0.7824 - mean_squared_error: 1.2371 - val_loss: 1.2353 - val_mean_absolute_error: 0.7917 - val_mean_squared_error: 1.2353\n",
            "Epoch 511/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.2328 - mean_absolute_error: 0.7821 - mean_squared_error: 1.2328\n",
            "Epoch 511: val_loss did not improve from 1.22857\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2360 - mean_absolute_error: 0.7835 - mean_squared_error: 1.2360 - val_loss: 1.2334 - val_mean_absolute_error: 0.7897 - val_mean_squared_error: 1.2334\n",
            "Epoch 512/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.2426 - mean_absolute_error: 0.7826 - mean_squared_error: 1.2426\n",
            "Epoch 512: val_loss improved from 1.22857 to 1.22563, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2346 - mean_absolute_error: 0.7817 - mean_squared_error: 1.2346 - val_loss: 1.2256 - val_mean_absolute_error: 0.7881 - val_mean_squared_error: 1.2256\n",
            "Epoch 513/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.2351 - mean_absolute_error: 0.7834 - mean_squared_error: 1.2351\n",
            "Epoch 513: val_loss improved from 1.22563 to 1.22452, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2324 - mean_absolute_error: 0.7824 - mean_squared_error: 1.2324 - val_loss: 1.2245 - val_mean_absolute_error: 0.7891 - val_mean_squared_error: 1.2245\n",
            "Epoch 514/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.2237 - mean_absolute_error: 0.7804 - mean_squared_error: 1.2237\n",
            "Epoch 514: val_loss did not improve from 1.22452\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2286 - mean_absolute_error: 0.7823 - mean_squared_error: 1.2286 - val_loss: 1.2324 - val_mean_absolute_error: 0.7894 - val_mean_squared_error: 1.2324\n",
            "Epoch 515/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.2214 - mean_absolute_error: 0.7797 - mean_squared_error: 1.2214\n",
            "Epoch 515: val_loss did not improve from 1.22452\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2277 - mean_absolute_error: 0.7813 - mean_squared_error: 1.2277 - val_loss: 1.2251 - val_mean_absolute_error: 0.7877 - val_mean_squared_error: 1.2251\n",
            "Epoch 516/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.2295 - mean_absolute_error: 0.7810 - mean_squared_error: 1.2295\n",
            "Epoch 516: val_loss did not improve from 1.22452\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2248 - mean_absolute_error: 0.7807 - mean_squared_error: 1.2248 - val_loss: 1.2269 - val_mean_absolute_error: 0.7891 - val_mean_squared_error: 1.2269\n",
            "Epoch 517/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.2155 - mean_absolute_error: 0.7791 - mean_squared_error: 1.2155\n",
            "Epoch 517: val_loss improved from 1.22452 to 1.21640, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2230 - mean_absolute_error: 0.7805 - mean_squared_error: 1.2230 - val_loss: 1.2164 - val_mean_absolute_error: 0.7854 - val_mean_squared_error: 1.2164\n",
            "Epoch 518/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.2191 - mean_absolute_error: 0.7784 - mean_squared_error: 1.2191\n",
            "Epoch 518: val_loss did not improve from 1.21640\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2212 - mean_absolute_error: 0.7797 - mean_squared_error: 1.2212 - val_loss: 1.2192 - val_mean_absolute_error: 0.7883 - val_mean_squared_error: 1.2192\n",
            "Epoch 519/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.2118 - mean_absolute_error: 0.7784 - mean_squared_error: 1.2118\n",
            "Epoch 519: val_loss improved from 1.21640 to 1.21431, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2190 - mean_absolute_error: 0.7808 - mean_squared_error: 1.2190 - val_loss: 1.2143 - val_mean_absolute_error: 0.7847 - val_mean_squared_error: 1.2143\n",
            "Epoch 520/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.2180 - mean_absolute_error: 0.7792 - mean_squared_error: 1.2180\n",
            "Epoch 520: val_loss improved from 1.21431 to 1.21239, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2184 - mean_absolute_error: 0.7800 - mean_squared_error: 1.2184 - val_loss: 1.2124 - val_mean_absolute_error: 0.7854 - val_mean_squared_error: 1.2124\n",
            "Epoch 521/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.2261 - mean_absolute_error: 0.7837 - mean_squared_error: 1.2261\n",
            "Epoch 521: val_loss improved from 1.21239 to 1.21001, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2152 - mean_absolute_error: 0.7800 - mean_squared_error: 1.2152 - val_loss: 1.2100 - val_mean_absolute_error: 0.7864 - val_mean_squared_error: 1.2100\n",
            "Epoch 522/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.2207 - mean_absolute_error: 0.7813 - mean_squared_error: 1.2207\n",
            "Epoch 522: val_loss improved from 1.21001 to 1.20794, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2147 - mean_absolute_error: 0.7787 - mean_squared_error: 1.2147 - val_loss: 1.2079 - val_mean_absolute_error: 0.7857 - val_mean_squared_error: 1.2079\n",
            "Epoch 523/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.2139 - mean_absolute_error: 0.7803 - mean_squared_error: 1.2139\n",
            "Epoch 523: val_loss improved from 1.20794 to 1.20566, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2130 - mean_absolute_error: 0.7795 - mean_squared_error: 1.2130 - val_loss: 1.2057 - val_mean_absolute_error: 0.7862 - val_mean_squared_error: 1.2057\n",
            "Epoch 524/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.2159 - mean_absolute_error: 0.7824 - mean_squared_error: 1.2159\n",
            "Epoch 524: val_loss improved from 1.20566 to 1.20070, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2104 - mean_absolute_error: 0.7799 - mean_squared_error: 1.2104 - val_loss: 1.2007 - val_mean_absolute_error: 0.7828 - val_mean_squared_error: 1.2007\n",
            "Epoch 525/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.2094 - mean_absolute_error: 0.7788 - mean_squared_error: 1.2094\n",
            "Epoch 525: val_loss did not improve from 1.20070\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2084 - mean_absolute_error: 0.7786 - mean_squared_error: 1.2084 - val_loss: 1.2033 - val_mean_absolute_error: 0.7848 - val_mean_squared_error: 1.2033\n",
            "Epoch 526/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.1978 - mean_absolute_error: 0.7772 - mean_squared_error: 1.1978\n",
            "Epoch 526: val_loss did not improve from 1.20070\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2072 - mean_absolute_error: 0.7788 - mean_squared_error: 1.2072 - val_loss: 1.2058 - val_mean_absolute_error: 0.7865 - val_mean_squared_error: 1.2058\n",
            "Epoch 527/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.2044 - mean_absolute_error: 0.7784 - mean_squared_error: 1.2044\n",
            "Epoch 527: val_loss did not improve from 1.20070\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2044 - mean_absolute_error: 0.7784 - mean_squared_error: 1.2044 - val_loss: 1.2024 - val_mean_absolute_error: 0.7868 - val_mean_squared_error: 1.2024\n",
            "Epoch 528/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.2215 - mean_absolute_error: 0.7850 - mean_squared_error: 1.2215\n",
            "Epoch 528: val_loss improved from 1.20070 to 1.19516, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2022 - mean_absolute_error: 0.7786 - mean_squared_error: 1.2022 - val_loss: 1.1952 - val_mean_absolute_error: 0.7834 - val_mean_squared_error: 1.1952\n",
            "Epoch 529/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.2025 - mean_absolute_error: 0.7776 - mean_squared_error: 1.2025\n",
            "Epoch 529: val_loss did not improve from 1.19516\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2008 - mean_absolute_error: 0.7773 - mean_squared_error: 1.2008 - val_loss: 1.2038 - val_mean_absolute_error: 0.7879 - val_mean_squared_error: 1.2038\n",
            "Epoch 530/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.2021 - mean_absolute_error: 0.7798 - mean_squared_error: 1.2021\n",
            "Epoch 530: val_loss did not improve from 1.19516\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1994 - mean_absolute_error: 0.7790 - mean_squared_error: 1.1994 - val_loss: 1.1954 - val_mean_absolute_error: 0.7834 - val_mean_squared_error: 1.1954\n",
            "Epoch 531/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.1852 - mean_absolute_error: 0.7737 - mean_squared_error: 1.1852\n",
            "Epoch 531: val_loss improved from 1.19516 to 1.19029, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1968 - mean_absolute_error: 0.7771 - mean_squared_error: 1.1968 - val_loss: 1.1903 - val_mean_absolute_error: 0.7831 - val_mean_squared_error: 1.1903\n",
            "Epoch 532/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.1899 - mean_absolute_error: 0.7746 - mean_squared_error: 1.1899\n",
            "Epoch 532: val_loss improved from 1.19029 to 1.18922, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1956 - mean_absolute_error: 0.7769 - mean_squared_error: 1.1956 - val_loss: 1.1892 - val_mean_absolute_error: 0.7840 - val_mean_squared_error: 1.1892\n",
            "Epoch 533/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.1946 - mean_absolute_error: 0.7766 - mean_squared_error: 1.1946\n",
            "Epoch 533: val_loss improved from 1.18922 to 1.18605, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1905 - mean_absolute_error: 0.7761 - mean_squared_error: 1.1905 - val_loss: 1.1861 - val_mean_absolute_error: 0.7831 - val_mean_squared_error: 1.1861\n",
            "Epoch 534/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.2000 - mean_absolute_error: 0.7806 - mean_squared_error: 1.2000\n",
            "Epoch 534: val_loss improved from 1.18605 to 1.18543, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1916 - mean_absolute_error: 0.7771 - mean_squared_error: 1.1916 - val_loss: 1.1854 - val_mean_absolute_error: 0.7819 - val_mean_squared_error: 1.1854\n",
            "Epoch 535/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.1938 - mean_absolute_error: 0.7789 - mean_squared_error: 1.1938\n",
            "Epoch 535: val_loss did not improve from 1.18543\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1898 - mean_absolute_error: 0.7770 - mean_squared_error: 1.1898 - val_loss: 1.1858 - val_mean_absolute_error: 0.7813 - val_mean_squared_error: 1.1858\n",
            "Epoch 536/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.1859 - mean_absolute_error: 0.7746 - mean_squared_error: 1.1859\n",
            "Epoch 536: val_loss did not improve from 1.18543\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1862 - mean_absolute_error: 0.7750 - mean_squared_error: 1.1862 - val_loss: 1.1899 - val_mean_absolute_error: 0.7868 - val_mean_squared_error: 1.1899\n",
            "Epoch 537/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.1809 - mean_absolute_error: 0.7740 - mean_squared_error: 1.1809\n",
            "Epoch 537: val_loss improved from 1.18543 to 1.17332, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1880 - mean_absolute_error: 0.7764 - mean_squared_error: 1.1880 - val_loss: 1.1733 - val_mean_absolute_error: 0.7789 - val_mean_squared_error: 1.1733\n",
            "Epoch 538/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.1848 - mean_absolute_error: 0.7765 - mean_squared_error: 1.1848\n",
            "Epoch 538: val_loss improved from 1.17332 to 1.17296, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1837 - mean_absolute_error: 0.7764 - mean_squared_error: 1.1837 - val_loss: 1.1730 - val_mean_absolute_error: 0.7791 - val_mean_squared_error: 1.1730\n",
            "Epoch 539/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.1788 - mean_absolute_error: 0.7736 - mean_squared_error: 1.1788\n",
            "Epoch 539: val_loss did not improve from 1.17296\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1810 - mean_absolute_error: 0.7738 - mean_squared_error: 1.1810 - val_loss: 1.1818 - val_mean_absolute_error: 0.7819 - val_mean_squared_error: 1.1818\n",
            "Epoch 540/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.1813 - mean_absolute_error: 0.7759 - mean_squared_error: 1.1813\n",
            "Epoch 540: val_loss improved from 1.17296 to 1.16971, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1809 - mean_absolute_error: 0.7761 - mean_squared_error: 1.1809 - val_loss: 1.1697 - val_mean_absolute_error: 0.7788 - val_mean_squared_error: 1.1697\n",
            "Epoch 541/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.1779 - mean_absolute_error: 0.7734 - mean_squared_error: 1.1779\n",
            "Epoch 541: val_loss did not improve from 1.16971\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1771 - mean_absolute_error: 0.7743 - mean_squared_error: 1.1771 - val_loss: 1.1708 - val_mean_absolute_error: 0.7777 - val_mean_squared_error: 1.1708\n",
            "Epoch 542/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.1744 - mean_absolute_error: 0.7750 - mean_squared_error: 1.1744\n",
            "Epoch 542: val_loss did not improve from 1.16971\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1766 - mean_absolute_error: 0.7747 - mean_squared_error: 1.1766 - val_loss: 1.1748 - val_mean_absolute_error: 0.7791 - val_mean_squared_error: 1.1748\n",
            "Epoch 543/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.1696 - mean_absolute_error: 0.7709 - mean_squared_error: 1.1696\n",
            "Epoch 543: val_loss improved from 1.16971 to 1.16602, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1735 - mean_absolute_error: 0.7724 - mean_squared_error: 1.1735 - val_loss: 1.1660 - val_mean_absolute_error: 0.7805 - val_mean_squared_error: 1.1660\n",
            "Epoch 544/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.1749 - mean_absolute_error: 0.7748 - mean_squared_error: 1.1749\n",
            "Epoch 544: val_loss improved from 1.16602 to 1.15988, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1724 - mean_absolute_error: 0.7737 - mean_squared_error: 1.1724 - val_loss: 1.1599 - val_mean_absolute_error: 0.7773 - val_mean_squared_error: 1.1599\n",
            "Epoch 545/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.1842 - mean_absolute_error: 0.7805 - mean_squared_error: 1.1842\n",
            "Epoch 545: val_loss did not improve from 1.15988\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1713 - mean_absolute_error: 0.7757 - mean_squared_error: 1.1713 - val_loss: 1.1615 - val_mean_absolute_error: 0.7759 - val_mean_squared_error: 1.1615\n",
            "Epoch 546/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.1732 - mean_absolute_error: 0.7723 - mean_squared_error: 1.1732\n",
            "Epoch 546: val_loss improved from 1.15988 to 1.15795, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1681 - mean_absolute_error: 0.7718 - mean_squared_error: 1.1681 - val_loss: 1.1579 - val_mean_absolute_error: 0.7776 - val_mean_squared_error: 1.1579\n",
            "Epoch 547/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.1523 - mean_absolute_error: 0.7702 - mean_squared_error: 1.1523\n",
            "Epoch 547: val_loss improved from 1.15795 to 1.15392, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1663 - mean_absolute_error: 0.7734 - mean_squared_error: 1.1663 - val_loss: 1.1539 - val_mean_absolute_error: 0.7741 - val_mean_squared_error: 1.1539\n",
            "Epoch 548/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.1579 - mean_absolute_error: 0.7695 - mean_squared_error: 1.1579\n",
            "Epoch 548: val_loss improved from 1.15392 to 1.15179, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1639 - mean_absolute_error: 0.7711 - mean_squared_error: 1.1639 - val_loss: 1.1518 - val_mean_absolute_error: 0.7762 - val_mean_squared_error: 1.1518\n",
            "Epoch 549/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.1510 - mean_absolute_error: 0.7669 - mean_squared_error: 1.1510\n",
            "Epoch 549: val_loss did not improve from 1.15179\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1601 - mean_absolute_error: 0.7700 - mean_squared_error: 1.1601 - val_loss: 1.1576 - val_mean_absolute_error: 0.7781 - val_mean_squared_error: 1.1576\n",
            "Epoch 550/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.1585 - mean_absolute_error: 0.7716 - mean_squared_error: 1.1585\n",
            "Epoch 550: val_loss improved from 1.15179 to 1.14826, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1612 - mean_absolute_error: 0.7730 - mean_squared_error: 1.1612 - val_loss: 1.1483 - val_mean_absolute_error: 0.7751 - val_mean_squared_error: 1.1483\n",
            "Epoch 551/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.1573 - mean_absolute_error: 0.7715 - mean_squared_error: 1.1573\n",
            "Epoch 551: val_loss improved from 1.14826 to 1.14766, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1584 - mean_absolute_error: 0.7716 - mean_squared_error: 1.1584 - val_loss: 1.1477 - val_mean_absolute_error: 0.7739 - val_mean_squared_error: 1.1477\n",
            "Epoch 552/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.1578 - mean_absolute_error: 0.7702 - mean_squared_error: 1.1578\n",
            "Epoch 552: val_loss improved from 1.14766 to 1.14711, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1562 - mean_absolute_error: 0.7697 - mean_squared_error: 1.1562 - val_loss: 1.1471 - val_mean_absolute_error: 0.7758 - val_mean_squared_error: 1.1471\n",
            "Epoch 553/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.1490 - mean_absolute_error: 0.7675 - mean_squared_error: 1.1490\n",
            "Epoch 553: val_loss did not improve from 1.14711\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1527 - mean_absolute_error: 0.7694 - mean_squared_error: 1.1527 - val_loss: 1.1483 - val_mean_absolute_error: 0.7769 - val_mean_squared_error: 1.1483\n",
            "Epoch 554/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.1538 - mean_absolute_error: 0.7721 - mean_squared_error: 1.1538\n",
            "Epoch 554: val_loss improved from 1.14711 to 1.14034, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1528 - mean_absolute_error: 0.7714 - mean_squared_error: 1.1528 - val_loss: 1.1403 - val_mean_absolute_error: 0.7727 - val_mean_squared_error: 1.1403\n",
            "Epoch 555/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.1445 - mean_absolute_error: 0.7676 - mean_squared_error: 1.1445\n",
            "Epoch 555: val_loss improved from 1.14034 to 1.13428, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1500 - mean_absolute_error: 0.7698 - mean_squared_error: 1.1500 - val_loss: 1.1343 - val_mean_absolute_error: 0.7704 - val_mean_squared_error: 1.1343\n",
            "Epoch 556/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.1393 - mean_absolute_error: 0.7666 - mean_squared_error: 1.1393\n",
            "Epoch 556: val_loss did not improve from 1.13428\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1469 - mean_absolute_error: 0.7692 - mean_squared_error: 1.1469 - val_loss: 1.1459 - val_mean_absolute_error: 0.7751 - val_mean_squared_error: 1.1459\n",
            "Epoch 557/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.1450 - mean_absolute_error: 0.7682 - mean_squared_error: 1.1450\n",
            "Epoch 557: val_loss improved from 1.13428 to 1.13329, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1460 - mean_absolute_error: 0.7685 - mean_squared_error: 1.1460 - val_loss: 1.1333 - val_mean_absolute_error: 0.7715 - val_mean_squared_error: 1.1333\n",
            "Epoch 558/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.1394 - mean_absolute_error: 0.7658 - mean_squared_error: 1.1394\n",
            "Epoch 558: val_loss did not improve from 1.13329\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1424 - mean_absolute_error: 0.7669 - mean_squared_error: 1.1424 - val_loss: 1.1354 - val_mean_absolute_error: 0.7715 - val_mean_squared_error: 1.1354\n",
            "Epoch 559/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.1421 - mean_absolute_error: 0.7684 - mean_squared_error: 1.1421\n",
            "Epoch 559: val_loss improved from 1.13329 to 1.12790, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1431 - mean_absolute_error: 0.7690 - mean_squared_error: 1.1431 - val_loss: 1.1279 - val_mean_absolute_error: 0.7690 - val_mean_squared_error: 1.1279\n",
            "Epoch 560/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.1370 - mean_absolute_error: 0.7661 - mean_squared_error: 1.1370\n",
            "Epoch 560: val_loss improved from 1.12790 to 1.12706, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1406 - mean_absolute_error: 0.7675 - mean_squared_error: 1.1406 - val_loss: 1.1271 - val_mean_absolute_error: 0.7704 - val_mean_squared_error: 1.1271\n",
            "Epoch 561/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.1485 - mean_absolute_error: 0.7708 - mean_squared_error: 1.1485\n",
            "Epoch 561: val_loss improved from 1.12706 to 1.12565, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1387 - mean_absolute_error: 0.7669 - mean_squared_error: 1.1387 - val_loss: 1.1256 - val_mean_absolute_error: 0.7697 - val_mean_squared_error: 1.1256\n",
            "Epoch 562/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.1432 - mean_absolute_error: 0.7679 - mean_squared_error: 1.1432\n",
            "Epoch 562: val_loss improved from 1.12565 to 1.12252, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1356 - mean_absolute_error: 0.7670 - mean_squared_error: 1.1356 - val_loss: 1.1225 - val_mean_absolute_error: 0.7700 - val_mean_squared_error: 1.1225\n",
            "Epoch 563/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.1330 - mean_absolute_error: 0.7658 - mean_squared_error: 1.1330\n",
            "Epoch 563: val_loss did not improve from 1.12252\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1330 - mean_absolute_error: 0.7658 - mean_squared_error: 1.1330 - val_loss: 1.1320 - val_mean_absolute_error: 0.7710 - val_mean_squared_error: 1.1320\n",
            "Epoch 564/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.1224 - mean_absolute_error: 0.7637 - mean_squared_error: 1.1224\n",
            "Epoch 564: val_loss improved from 1.12252 to 1.12093, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1316 - mean_absolute_error: 0.7664 - mean_squared_error: 1.1316 - val_loss: 1.1209 - val_mean_absolute_error: 0.7675 - val_mean_squared_error: 1.1209\n",
            "Epoch 565/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.1323 - mean_absolute_error: 0.7665 - mean_squared_error: 1.1323\n",
            "Epoch 565: val_loss improved from 1.12093 to 1.11480, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1295 - mean_absolute_error: 0.7656 - mean_squared_error: 1.1295 - val_loss: 1.1148 - val_mean_absolute_error: 0.7660 - val_mean_squared_error: 1.1148\n",
            "Epoch 566/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.1206 - mean_absolute_error: 0.7625 - mean_squared_error: 1.1206\n",
            "Epoch 566: val_loss improved from 1.11480 to 1.11047, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1274 - mean_absolute_error: 0.7646 - mean_squared_error: 1.1274 - val_loss: 1.1105 - val_mean_absolute_error: 0.7666 - val_mean_squared_error: 1.1105\n",
            "Epoch 567/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.1312 - mean_absolute_error: 0.7675 - mean_squared_error: 1.1312\n",
            "Epoch 567: val_loss improved from 1.11047 to 1.10633, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1252 - mean_absolute_error: 0.7647 - mean_squared_error: 1.1252 - val_loss: 1.1063 - val_mean_absolute_error: 0.7648 - val_mean_squared_error: 1.1063\n",
            "Epoch 568/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.1291 - mean_absolute_error: 0.7671 - mean_squared_error: 1.1291\n",
            "Epoch 568: val_loss did not improve from 1.10633\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1231 - mean_absolute_error: 0.7639 - mean_squared_error: 1.1231 - val_loss: 1.1079 - val_mean_absolute_error: 0.7653 - val_mean_squared_error: 1.1079\n",
            "Epoch 569/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.1208 - mean_absolute_error: 0.7628 - mean_squared_error: 1.1208\n",
            "Epoch 569: val_loss did not improve from 1.10633\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1220 - mean_absolute_error: 0.7635 - mean_squared_error: 1.1220 - val_loss: 1.1093 - val_mean_absolute_error: 0.7646 - val_mean_squared_error: 1.1093\n",
            "Epoch 570/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.1210 - mean_absolute_error: 0.7628 - mean_squared_error: 1.1210\n",
            "Epoch 570: val_loss improved from 1.10633 to 1.10606, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1190 - mean_absolute_error: 0.7629 - mean_squared_error: 1.1190 - val_loss: 1.1061 - val_mean_absolute_error: 0.7641 - val_mean_squared_error: 1.1061\n",
            "Epoch 571/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.1150 - mean_absolute_error: 0.7605 - mean_squared_error: 1.1150\n",
            "Epoch 571: val_loss did not improve from 1.10606\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1174 - mean_absolute_error: 0.7616 - mean_squared_error: 1.1174 - val_loss: 1.1156 - val_mean_absolute_error: 0.7679 - val_mean_squared_error: 1.1156\n",
            "Epoch 572/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.1195 - mean_absolute_error: 0.7642 - mean_squared_error: 1.1195\n",
            "Epoch 572: val_loss improved from 1.10606 to 1.09788, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1161 - mean_absolute_error: 0.7636 - mean_squared_error: 1.1161 - val_loss: 1.0979 - val_mean_absolute_error: 0.7656 - val_mean_squared_error: 1.0979\n",
            "Epoch 573/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.1025 - mean_absolute_error: 0.7579 - mean_squared_error: 1.1025\n",
            "Epoch 573: val_loss improved from 1.09788 to 1.09393, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1137 - mean_absolute_error: 0.7624 - mean_squared_error: 1.1137 - val_loss: 1.0939 - val_mean_absolute_error: 0.7629 - val_mean_squared_error: 1.0939\n",
            "Epoch 574/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.1055 - mean_absolute_error: 0.7597 - mean_squared_error: 1.1055\n",
            "Epoch 574: val_loss did not improve from 1.09393\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1110 - mean_absolute_error: 0.7618 - mean_squared_error: 1.1110 - val_loss: 1.0968 - val_mean_absolute_error: 0.7609 - val_mean_squared_error: 1.0968\n",
            "Epoch 575/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.1136 - mean_absolute_error: 0.7621 - mean_squared_error: 1.1136\n",
            "Epoch 575: val_loss improved from 1.09393 to 1.08974, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1080 - mean_absolute_error: 0.7607 - mean_squared_error: 1.1080 - val_loss: 1.0897 - val_mean_absolute_error: 0.7597 - val_mean_squared_error: 1.0897\n",
            "Epoch 576/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.1003 - mean_absolute_error: 0.7577 - mean_squared_error: 1.1003\n",
            "Epoch 576: val_loss improved from 1.08974 to 1.08853, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1066 - mean_absolute_error: 0.7598 - mean_squared_error: 1.1066 - val_loss: 1.0885 - val_mean_absolute_error: 0.7602 - val_mean_squared_error: 1.0885\n",
            "Epoch 577/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.0827 - mean_absolute_error: 0.7517 - mean_squared_error: 1.0827\n",
            "Epoch 577: val_loss did not improve from 1.08853\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1054 - mean_absolute_error: 0.7596 - mean_squared_error: 1.1054 - val_loss: 1.0888 - val_mean_absolute_error: 0.7611 - val_mean_squared_error: 1.0888\n",
            "Epoch 578/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.1085 - mean_absolute_error: 0.7620 - mean_squared_error: 1.1085\n",
            "Epoch 578: val_loss improved from 1.08853 to 1.08681, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1011 - mean_absolute_error: 0.7591 - mean_squared_error: 1.1011 - val_loss: 1.0868 - val_mean_absolute_error: 0.7605 - val_mean_squared_error: 1.0868\n",
            "Epoch 579/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.0938 - mean_absolute_error: 0.7582 - mean_squared_error: 1.0938\n",
            "Epoch 579: val_loss improved from 1.08681 to 1.08328, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1003 - mean_absolute_error: 0.7598 - mean_squared_error: 1.1003 - val_loss: 1.0833 - val_mean_absolute_error: 0.7570 - val_mean_squared_error: 1.0833\n",
            "Epoch 580/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.1016 - mean_absolute_error: 0.7584 - mean_squared_error: 1.1016\n",
            "Epoch 580: val_loss improved from 1.08328 to 1.07870, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0992 - mean_absolute_error: 0.7574 - mean_squared_error: 1.0992 - val_loss: 1.0787 - val_mean_absolute_error: 0.7587 - val_mean_squared_error: 1.0787\n",
            "Epoch 581/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.0866 - mean_absolute_error: 0.7556 - mean_squared_error: 1.0866\n",
            "Epoch 581: val_loss improved from 1.07870 to 1.07742, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0949 - mean_absolute_error: 0.7583 - mean_squared_error: 1.0949 - val_loss: 1.0774 - val_mean_absolute_error: 0.7604 - val_mean_squared_error: 1.0774\n",
            "Epoch 582/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.0862 - mean_absolute_error: 0.7544 - mean_squared_error: 1.0862\n",
            "Epoch 582: val_loss did not improve from 1.07742\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0933 - mean_absolute_error: 0.7578 - mean_squared_error: 1.0933 - val_loss: 1.0837 - val_mean_absolute_error: 0.7570 - val_mean_squared_error: 1.0837\n",
            "Epoch 583/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.1086 - mean_absolute_error: 0.7645 - mean_squared_error: 1.1086\n",
            "Epoch 583: val_loss did not improve from 1.07742\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0916 - mean_absolute_error: 0.7572 - mean_squared_error: 1.0916 - val_loss: 1.0793 - val_mean_absolute_error: 0.7553 - val_mean_squared_error: 1.0793\n",
            "Epoch 584/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.0926 - mean_absolute_error: 0.7569 - mean_squared_error: 1.0926\n",
            "Epoch 584: val_loss improved from 1.07742 to 1.07151, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0900 - mean_absolute_error: 0.7563 - mean_squared_error: 1.0900 - val_loss: 1.0715 - val_mean_absolute_error: 0.7554 - val_mean_squared_error: 1.0715\n",
            "Epoch 585/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.0883 - mean_absolute_error: 0.7560 - mean_squared_error: 1.0883\n",
            "Epoch 585: val_loss did not improve from 1.07151\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0883 - mean_absolute_error: 0.7560 - mean_squared_error: 1.0883 - val_loss: 1.0751 - val_mean_absolute_error: 0.7560 - val_mean_squared_error: 1.0751\n",
            "Epoch 586/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.0721 - mean_absolute_error: 0.7515 - mean_squared_error: 1.0721\n",
            "Epoch 586: val_loss improved from 1.07151 to 1.06281, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0862 - mean_absolute_error: 0.7565 - mean_squared_error: 1.0862 - val_loss: 1.0628 - val_mean_absolute_error: 0.7520 - val_mean_squared_error: 1.0628\n",
            "Epoch 587/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.0828 - mean_absolute_error: 0.7550 - mean_squared_error: 1.0828\n",
            "Epoch 587: val_loss improved from 1.06281 to 1.06103, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0828 - mean_absolute_error: 0.7550 - mean_squared_error: 1.0828 - val_loss: 1.0610 - val_mean_absolute_error: 0.7549 - val_mean_squared_error: 1.0610\n",
            "Epoch 588/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.0837 - mean_absolute_error: 0.7547 - mean_squared_error: 1.0837\n",
            "Epoch 588: val_loss improved from 1.06103 to 1.06099, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0845 - mean_absolute_error: 0.7552 - mean_squared_error: 1.0845 - val_loss: 1.0610 - val_mean_absolute_error: 0.7512 - val_mean_squared_error: 1.0610\n",
            "Epoch 589/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.0834 - mean_absolute_error: 0.7557 - mean_squared_error: 1.0834\n",
            "Epoch 589: val_loss improved from 1.06099 to 1.05566, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0788 - mean_absolute_error: 0.7537 - mean_squared_error: 1.0788 - val_loss: 1.0557 - val_mean_absolute_error: 0.7506 - val_mean_squared_error: 1.0557\n",
            "Epoch 590/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.0805 - mean_absolute_error: 0.7543 - mean_squared_error: 1.0805\n",
            "Epoch 590: val_loss improved from 1.05566 to 1.05447, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0757 - mean_absolute_error: 0.7526 - mean_squared_error: 1.0757 - val_loss: 1.0545 - val_mean_absolute_error: 0.7515 - val_mean_squared_error: 1.0545\n",
            "Epoch 591/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.0612 - mean_absolute_error: 0.7480 - mean_squared_error: 1.0612\n",
            "Epoch 591: val_loss improved from 1.05447 to 1.05071, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0764 - mean_absolute_error: 0.7534 - mean_squared_error: 1.0764 - val_loss: 1.0507 - val_mean_absolute_error: 0.7495 - val_mean_squared_error: 1.0507\n",
            "Epoch 592/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.0721 - mean_absolute_error: 0.7519 - mean_squared_error: 1.0721\n",
            "Epoch 592: val_loss did not improve from 1.05071\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0724 - mean_absolute_error: 0.7525 - mean_squared_error: 1.0724 - val_loss: 1.0533 - val_mean_absolute_error: 0.7497 - val_mean_squared_error: 1.0533\n",
            "Epoch 593/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.0685 - mean_absolute_error: 0.7524 - mean_squared_error: 1.0685\n",
            "Epoch 593: val_loss improved from 1.05071 to 1.04554, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0692 - mean_absolute_error: 0.7525 - mean_squared_error: 1.0692 - val_loss: 1.0455 - val_mean_absolute_error: 0.7478 - val_mean_squared_error: 1.0455\n",
            "Epoch 594/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.0638 - mean_absolute_error: 0.7490 - mean_squared_error: 1.0638\n",
            "Epoch 594: val_loss did not improve from 1.04554\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0688 - mean_absolute_error: 0.7508 - mean_squared_error: 1.0688 - val_loss: 1.0545 - val_mean_absolute_error: 0.7508 - val_mean_squared_error: 1.0545\n",
            "Epoch 595/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.0635 - mean_absolute_error: 0.7500 - mean_squared_error: 1.0635\n",
            "Epoch 595: val_loss did not improve from 1.04554\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0654 - mean_absolute_error: 0.7505 - mean_squared_error: 1.0654 - val_loss: 1.0577 - val_mean_absolute_error: 0.7504 - val_mean_squared_error: 1.0577\n",
            "Epoch 596/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.0637 - mean_absolute_error: 0.7490 - mean_squared_error: 1.0637\n",
            "Epoch 596: val_loss improved from 1.04554 to 1.03817, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0631 - mean_absolute_error: 0.7495 - mean_squared_error: 1.0631 - val_loss: 1.0382 - val_mean_absolute_error: 0.7481 - val_mean_squared_error: 1.0382\n",
            "Epoch 597/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.0594 - mean_absolute_error: 0.7485 - mean_squared_error: 1.0594\n",
            "Epoch 597: val_loss improved from 1.03817 to 1.03475, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0623 - mean_absolute_error: 0.7491 - mean_squared_error: 1.0623 - val_loss: 1.0348 - val_mean_absolute_error: 0.7468 - val_mean_squared_error: 1.0348\n",
            "Epoch 598/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.0551 - mean_absolute_error: 0.7476 - mean_squared_error: 1.0551\n",
            "Epoch 598: val_loss did not improve from 1.03475\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0591 - mean_absolute_error: 0.7501 - mean_squared_error: 1.0591 - val_loss: 1.0363 - val_mean_absolute_error: 0.7436 - val_mean_squared_error: 1.0363\n",
            "Epoch 599/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.0574 - mean_absolute_error: 0.7489 - mean_squared_error: 1.0574\n",
            "Epoch 599: val_loss did not improve from 1.03475\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0566 - mean_absolute_error: 0.7482 - mean_squared_error: 1.0566 - val_loss: 1.0387 - val_mean_absolute_error: 0.7439 - val_mean_squared_error: 1.0387\n",
            "Epoch 600/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.0592 - mean_absolute_error: 0.7478 - mean_squared_error: 1.0592\n",
            "Epoch 600: val_loss improved from 1.03475 to 1.02918, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0559 - mean_absolute_error: 0.7464 - mean_squared_error: 1.0559 - val_loss: 1.0292 - val_mean_absolute_error: 0.7447 - val_mean_squared_error: 1.0292\n",
            "Epoch 601/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.0528 - mean_absolute_error: 0.7478 - mean_squared_error: 1.0528\n",
            "Epoch 601: val_loss improved from 1.02918 to 1.02635, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0537 - mean_absolute_error: 0.7481 - mean_squared_error: 1.0537 - val_loss: 1.0263 - val_mean_absolute_error: 0.7434 - val_mean_squared_error: 1.0263\n",
            "Epoch 602/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.0538 - mean_absolute_error: 0.7472 - mean_squared_error: 1.0538\n",
            "Epoch 602: val_loss did not improve from 1.02635\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0505 - mean_absolute_error: 0.7462 - mean_squared_error: 1.0505 - val_loss: 1.0273 - val_mean_absolute_error: 0.7420 - val_mean_squared_error: 1.0273\n",
            "Epoch 603/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.0432 - mean_absolute_error: 0.7428 - mean_squared_error: 1.0432\n",
            "Epoch 603: val_loss did not improve from 1.02635\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0479 - mean_absolute_error: 0.7449 - mean_squared_error: 1.0479 - val_loss: 1.0273 - val_mean_absolute_error: 0.7428 - val_mean_squared_error: 1.0273\n",
            "Epoch 604/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.0448 - mean_absolute_error: 0.7454 - mean_squared_error: 1.0448\n",
            "Epoch 604: val_loss improved from 1.02635 to 1.02122, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0466 - mean_absolute_error: 0.7454 - mean_squared_error: 1.0466 - val_loss: 1.0212 - val_mean_absolute_error: 0.7405 - val_mean_squared_error: 1.0212\n",
            "Epoch 605/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.0405 - mean_absolute_error: 0.7435 - mean_squared_error: 1.0405\n",
            "Epoch 605: val_loss improved from 1.02122 to 1.01578, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0444 - mean_absolute_error: 0.7453 - mean_squared_error: 1.0444 - val_loss: 1.0158 - val_mean_absolute_error: 0.7389 - val_mean_squared_error: 1.0158\n",
            "Epoch 606/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.0491 - mean_absolute_error: 0.7459 - mean_squared_error: 1.0491\n",
            "Epoch 606: val_loss improved from 1.01578 to 1.01510, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0439 - mean_absolute_error: 0.7442 - mean_squared_error: 1.0439 - val_loss: 1.0151 - val_mean_absolute_error: 0.7430 - val_mean_squared_error: 1.0151\n",
            "Epoch 607/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.0452 - mean_absolute_error: 0.7476 - mean_squared_error: 1.0452\n",
            "Epoch 607: val_loss improved from 1.01510 to 1.01110, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0402 - mean_absolute_error: 0.7443 - mean_squared_error: 1.0402 - val_loss: 1.0111 - val_mean_absolute_error: 0.7375 - val_mean_squared_error: 1.0111\n",
            "Epoch 608/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.0369 - mean_absolute_error: 0.7418 - mean_squared_error: 1.0369\n",
            "Epoch 608: val_loss did not improve from 1.01110\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0398 - mean_absolute_error: 0.7424 - mean_squared_error: 1.0398 - val_loss: 1.0166 - val_mean_absolute_error: 0.7395 - val_mean_squared_error: 1.0166\n",
            "Epoch 609/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.0397 - mean_absolute_error: 0.7425 - mean_squared_error: 1.0397\n",
            "Epoch 609: val_loss did not improve from 1.01110\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0374 - mean_absolute_error: 0.7425 - mean_squared_error: 1.0374 - val_loss: 1.0166 - val_mean_absolute_error: 0.7398 - val_mean_squared_error: 1.0166\n",
            "Epoch 610/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.0386 - mean_absolute_error: 0.7437 - mean_squared_error: 1.0386\n",
            "Epoch 610: val_loss improved from 1.01110 to 1.00869, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0359 - mean_absolute_error: 0.7425 - mean_squared_error: 1.0359 - val_loss: 1.0087 - val_mean_absolute_error: 0.7351 - val_mean_squared_error: 1.0087\n",
            "Epoch 611/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.0203 - mean_absolute_error: 0.7359 - mean_squared_error: 1.0203\n",
            "Epoch 611: val_loss improved from 1.00869 to 1.00746, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0327 - mean_absolute_error: 0.7409 - mean_squared_error: 1.0327 - val_loss: 1.0075 - val_mean_absolute_error: 0.7364 - val_mean_squared_error: 1.0075\n",
            "Epoch 612/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.0293 - mean_absolute_error: 0.7404 - mean_squared_error: 1.0293\n",
            "Epoch 612: val_loss improved from 1.00746 to 1.00353, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0305 - mean_absolute_error: 0.7411 - mean_squared_error: 1.0305 - val_loss: 1.0035 - val_mean_absolute_error: 0.7354 - val_mean_squared_error: 1.0035\n",
            "Epoch 613/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.0327 - mean_absolute_error: 0.7411 - mean_squared_error: 1.0327\n",
            "Epoch 613: val_loss improved from 1.00353 to 1.00194, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0284 - mean_absolute_error: 0.7400 - mean_squared_error: 1.0284 - val_loss: 1.0019 - val_mean_absolute_error: 0.7346 - val_mean_squared_error: 1.0019\n",
            "Epoch 614/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.0319 - mean_absolute_error: 0.7435 - mean_squared_error: 1.0319\n",
            "Epoch 614: val_loss improved from 1.00194 to 0.99657, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0272 - mean_absolute_error: 0.7404 - mean_squared_error: 1.0272 - val_loss: 0.9966 - val_mean_absolute_error: 0.7350 - val_mean_squared_error: 0.9966\n",
            "Epoch 615/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.0306 - mean_absolute_error: 0.7414 - mean_squared_error: 1.0306\n",
            "Epoch 615: val_loss improved from 0.99657 to 0.99401, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0238 - mean_absolute_error: 0.7381 - mean_squared_error: 1.0238 - val_loss: 0.9940 - val_mean_absolute_error: 0.7348 - val_mean_squared_error: 0.9940\n",
            "Epoch 616/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.0249 - mean_absolute_error: 0.7392 - mean_squared_error: 1.0249\n",
            "Epoch 616: val_loss improved from 0.99401 to 0.99180, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0222 - mean_absolute_error: 0.7382 - mean_squared_error: 1.0222 - val_loss: 0.9918 - val_mean_absolute_error: 0.7346 - val_mean_squared_error: 0.9918\n",
            "Epoch 617/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.0197 - mean_absolute_error: 0.7389 - mean_squared_error: 1.0197\n",
            "Epoch 617: val_loss did not improve from 0.99180\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0197 - mean_absolute_error: 0.7389 - mean_squared_error: 1.0197 - val_loss: 0.9929 - val_mean_absolute_error: 0.7322 - val_mean_squared_error: 0.9929\n",
            "Epoch 618/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.0111 - mean_absolute_error: 0.7339 - mean_squared_error: 1.0111\n",
            "Epoch 618: val_loss improved from 0.99180 to 0.98764, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0183 - mean_absolute_error: 0.7379 - mean_squared_error: 1.0183 - val_loss: 0.9876 - val_mean_absolute_error: 0.7334 - val_mean_squared_error: 0.9876\n",
            "Epoch 619/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.0215 - mean_absolute_error: 0.7394 - mean_squared_error: 1.0215\n",
            "Epoch 619: val_loss improved from 0.98764 to 0.98471, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0154 - mean_absolute_error: 0.7367 - mean_squared_error: 1.0154 - val_loss: 0.9847 - val_mean_absolute_error: 0.7291 - val_mean_squared_error: 0.9847\n",
            "Epoch 620/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.0153 - mean_absolute_error: 0.7369 - mean_squared_error: 1.0153\n",
            "Epoch 620: val_loss did not improve from 0.98471\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0153 - mean_absolute_error: 0.7369 - mean_squared_error: 1.0153 - val_loss: 0.9860 - val_mean_absolute_error: 0.7289 - val_mean_squared_error: 0.9860\n",
            "Epoch 621/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.0111 - mean_absolute_error: 0.7326 - mean_squared_error: 1.0111\n",
            "Epoch 621: val_loss improved from 0.98471 to 0.97986, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0130 - mean_absolute_error: 0.7344 - mean_squared_error: 1.0130 - val_loss: 0.9799 - val_mean_absolute_error: 0.7309 - val_mean_squared_error: 0.9799\n",
            "Epoch 622/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.0176 - mean_absolute_error: 0.7357 - mean_squared_error: 1.0176\n",
            "Epoch 622: val_loss did not improve from 0.97986\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0132 - mean_absolute_error: 0.7355 - mean_squared_error: 1.0132 - val_loss: 0.9801 - val_mean_absolute_error: 0.7298 - val_mean_squared_error: 0.9801\n",
            "Epoch 623/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.0111 - mean_absolute_error: 0.7359 - mean_squared_error: 1.0111\n",
            "Epoch 623: val_loss improved from 0.97986 to 0.97339, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0093 - mean_absolute_error: 0.7350 - mean_squared_error: 1.0093 - val_loss: 0.9734 - val_mean_absolute_error: 0.7302 - val_mean_squared_error: 0.9734\n",
            "Epoch 624/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.0135 - mean_absolute_error: 0.7368 - mean_squared_error: 1.0135\n",
            "Epoch 624: val_loss did not improve from 0.97339\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0069 - mean_absolute_error: 0.7343 - mean_squared_error: 1.0069 - val_loss: 0.9763 - val_mean_absolute_error: 0.7279 - val_mean_squared_error: 0.9763\n",
            "Epoch 625/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.0086 - mean_absolute_error: 0.7364 - mean_squared_error: 1.0086\n",
            "Epoch 625: val_loss improved from 0.97339 to 0.97212, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.0048 - mean_absolute_error: 0.7356 - mean_squared_error: 1.0048 - val_loss: 0.9721 - val_mean_absolute_error: 0.7271 - val_mean_squared_error: 0.9721\n",
            "Epoch 626/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.9993 - mean_absolute_error: 0.7307 - mean_squared_error: 0.9993\n",
            "Epoch 626: val_loss did not improve from 0.97212\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0030 - mean_absolute_error: 0.7319 - mean_squared_error: 1.0030 - val_loss: 0.9748 - val_mean_absolute_error: 0.7271 - val_mean_squared_error: 0.9748\n",
            "Epoch 627/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.0122 - mean_absolute_error: 0.7380 - mean_squared_error: 1.0122\n",
            "Epoch 627: val_loss improved from 0.97212 to 0.97041, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.0025 - mean_absolute_error: 0.7342 - mean_squared_error: 1.0025 - val_loss: 0.9704 - val_mean_absolute_error: 0.7256 - val_mean_squared_error: 0.9704\n",
            "Epoch 628/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.9894 - mean_absolute_error: 0.7277 - mean_squared_error: 0.9894\n",
            "Epoch 628: val_loss improved from 0.97041 to 0.96385, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9972 - mean_absolute_error: 0.7310 - mean_squared_error: 0.9972 - val_loss: 0.9638 - val_mean_absolute_error: 0.7261 - val_mean_squared_error: 0.9638\n",
            "Epoch 629/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.9945 - mean_absolute_error: 0.7307 - mean_squared_error: 0.9945\n",
            "Epoch 629: val_loss improved from 0.96385 to 0.96119, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9971 - mean_absolute_error: 0.7320 - mean_squared_error: 0.9971 - val_loss: 0.9612 - val_mean_absolute_error: 0.7248 - val_mean_squared_error: 0.9612\n",
            "Epoch 630/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.9886 - mean_absolute_error: 0.7277 - mean_squared_error: 0.9886\n",
            "Epoch 630: val_loss improved from 0.96119 to 0.95919, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9945 - mean_absolute_error: 0.7307 - mean_squared_error: 0.9945 - val_loss: 0.9592 - val_mean_absolute_error: 0.7222 - val_mean_squared_error: 0.9592\n",
            "Epoch 631/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.9898 - mean_absolute_error: 0.7301 - mean_squared_error: 0.9898\n",
            "Epoch 631: val_loss improved from 0.95919 to 0.95647, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9918 - mean_absolute_error: 0.7313 - mean_squared_error: 0.9918 - val_loss: 0.9565 - val_mean_absolute_error: 0.7227 - val_mean_squared_error: 0.9565\n",
            "Epoch 632/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.9960 - mean_absolute_error: 0.7314 - mean_squared_error: 0.9960\n",
            "Epoch 632: val_loss improved from 0.95647 to 0.95618, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9913 - mean_absolute_error: 0.7291 - mean_squared_error: 0.9913 - val_loss: 0.9562 - val_mean_absolute_error: 0.7212 - val_mean_squared_error: 0.9562\n",
            "Epoch 633/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.9914 - mean_absolute_error: 0.7297 - mean_squared_error: 0.9914\n",
            "Epoch 633: val_loss improved from 0.95618 to 0.95410, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9862 - mean_absolute_error: 0.7288 - mean_squared_error: 0.9862 - val_loss: 0.9541 - val_mean_absolute_error: 0.7241 - val_mean_squared_error: 0.9541\n",
            "Epoch 634/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.9850 - mean_absolute_error: 0.7266 - mean_squared_error: 0.9850\n",
            "Epoch 634: val_loss did not improve from 0.95410\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9851 - mean_absolute_error: 0.7280 - mean_squared_error: 0.9851 - val_loss: 0.9558 - val_mean_absolute_error: 0.7210 - val_mean_squared_error: 0.9558\n",
            "Epoch 635/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.9857 - mean_absolute_error: 0.7286 - mean_squared_error: 0.9857\n",
            "Epoch 635: val_loss improved from 0.95410 to 0.95197, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9835 - mean_absolute_error: 0.7275 - mean_squared_error: 0.9835 - val_loss: 0.9520 - val_mean_absolute_error: 0.7200 - val_mean_squared_error: 0.9520\n",
            "Epoch 636/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.9791 - mean_absolute_error: 0.7269 - mean_squared_error: 0.9791\n",
            "Epoch 636: val_loss improved from 0.95197 to 0.95089, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9816 - mean_absolute_error: 0.7274 - mean_squared_error: 0.9816 - val_loss: 0.9509 - val_mean_absolute_error: 0.7200 - val_mean_squared_error: 0.9509\n",
            "Epoch 637/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.9864 - mean_absolute_error: 0.7278 - mean_squared_error: 0.9864\n",
            "Epoch 637: val_loss improved from 0.95089 to 0.94711, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9823 - mean_absolute_error: 0.7266 - mean_squared_error: 0.9823 - val_loss: 0.9471 - val_mean_absolute_error: 0.7212 - val_mean_squared_error: 0.9471\n",
            "Epoch 638/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.9801 - mean_absolute_error: 0.7288 - mean_squared_error: 0.9801\n",
            "Epoch 638: val_loss improved from 0.94711 to 0.94443, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9782 - mean_absolute_error: 0.7278 - mean_squared_error: 0.9782 - val_loss: 0.9444 - val_mean_absolute_error: 0.7169 - val_mean_squared_error: 0.9444\n",
            "Epoch 639/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.9757 - mean_absolute_error: 0.7250 - mean_squared_error: 0.9757\n",
            "Epoch 639: val_loss improved from 0.94443 to 0.94314, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9770 - mean_absolute_error: 0.7256 - mean_squared_error: 0.9770 - val_loss: 0.9431 - val_mean_absolute_error: 0.7171 - val_mean_squared_error: 0.9431\n",
            "Epoch 640/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.9741 - mean_absolute_error: 0.7252 - mean_squared_error: 0.9741\n",
            "Epoch 640: val_loss improved from 0.94314 to 0.93984, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9749 - mean_absolute_error: 0.7251 - mean_squared_error: 0.9749 - val_loss: 0.9398 - val_mean_absolute_error: 0.7197 - val_mean_squared_error: 0.9398\n",
            "Epoch 641/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.9627 - mean_absolute_error: 0.7211 - mean_squared_error: 0.9627\n",
            "Epoch 641: val_loss did not improve from 0.93984\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9727 - mean_absolute_error: 0.7260 - mean_squared_error: 0.9727 - val_loss: 0.9412 - val_mean_absolute_error: 0.7166 - val_mean_squared_error: 0.9412\n",
            "Epoch 642/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.9814 - mean_absolute_error: 0.7269 - mean_squared_error: 0.9814\n",
            "Epoch 642: val_loss improved from 0.93984 to 0.93865, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9704 - mean_absolute_error: 0.7245 - mean_squared_error: 0.9704 - val_loss: 0.9386 - val_mean_absolute_error: 0.7159 - val_mean_squared_error: 0.9386\n",
            "Epoch 643/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.9547 - mean_absolute_error: 0.7177 - mean_squared_error: 0.9547\n",
            "Epoch 643: val_loss improved from 0.93865 to 0.93440, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9690 - mean_absolute_error: 0.7242 - mean_squared_error: 0.9690 - val_loss: 0.9344 - val_mean_absolute_error: 0.7138 - val_mean_squared_error: 0.9344\n",
            "Epoch 644/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.9774 - mean_absolute_error: 0.7260 - mean_squared_error: 0.9774\n",
            "Epoch 644: val_loss improved from 0.93440 to 0.92794, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9665 - mean_absolute_error: 0.7227 - mean_squared_error: 0.9665 - val_loss: 0.9279 - val_mean_absolute_error: 0.7122 - val_mean_squared_error: 0.9279\n",
            "Epoch 645/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.9643 - mean_absolute_error: 0.7236 - mean_squared_error: 0.9643\n",
            "Epoch 645: val_loss did not improve from 0.92794\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9652 - mean_absolute_error: 0.7235 - mean_squared_error: 0.9652 - val_loss: 0.9465 - val_mean_absolute_error: 0.7156 - val_mean_squared_error: 0.9465\n",
            "Epoch 646/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.9681 - mean_absolute_error: 0.7251 - mean_squared_error: 0.9681\n",
            "Epoch 646: val_loss did not improve from 0.92794\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9655 - mean_absolute_error: 0.7233 - mean_squared_error: 0.9655 - val_loss: 0.9340 - val_mean_absolute_error: 0.7121 - val_mean_squared_error: 0.9340\n",
            "Epoch 647/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.9636 - mean_absolute_error: 0.7226 - mean_squared_error: 0.9636\n",
            "Epoch 647: val_loss did not improve from 0.92794\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9610 - mean_absolute_error: 0.7216 - mean_squared_error: 0.9610 - val_loss: 0.9305 - val_mean_absolute_error: 0.7135 - val_mean_squared_error: 0.9305\n",
            "Epoch 648/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.9632 - mean_absolute_error: 0.7232 - mean_squared_error: 0.9632\n",
            "Epoch 648: val_loss improved from 0.92794 to 0.92169, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9604 - mean_absolute_error: 0.7222 - mean_squared_error: 0.9604 - val_loss: 0.9217 - val_mean_absolute_error: 0.7101 - val_mean_squared_error: 0.9217\n",
            "Epoch 649/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.9592 - mean_absolute_error: 0.7214 - mean_squared_error: 0.9592\n",
            "Epoch 649: val_loss improved from 0.92169 to 0.92051, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9568 - mean_absolute_error: 0.7210 - mean_squared_error: 0.9568 - val_loss: 0.9205 - val_mean_absolute_error: 0.7100 - val_mean_squared_error: 0.9205\n",
            "Epoch 650/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.9585 - mean_absolute_error: 0.7192 - mean_squared_error: 0.9585\n",
            "Epoch 650: val_loss improved from 0.92051 to 0.91983, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9546 - mean_absolute_error: 0.7184 - mean_squared_error: 0.9546 - val_loss: 0.9198 - val_mean_absolute_error: 0.7120 - val_mean_squared_error: 0.9198\n",
            "Epoch 651/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.9500 - mean_absolute_error: 0.7206 - mean_squared_error: 0.9500\n",
            "Epoch 651: val_loss improved from 0.91983 to 0.91583, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9508 - mean_absolute_error: 0.7202 - mean_squared_error: 0.9508 - val_loss: 0.9158 - val_mean_absolute_error: 0.7078 - val_mean_squared_error: 0.9158\n",
            "Epoch 652/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.9507 - mean_absolute_error: 0.7183 - mean_squared_error: 0.9507\n",
            "Epoch 652: val_loss improved from 0.91583 to 0.91460, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9520 - mean_absolute_error: 0.7189 - mean_squared_error: 0.9520 - val_loss: 0.9146 - val_mean_absolute_error: 0.7078 - val_mean_squared_error: 0.9146\n",
            "Epoch 653/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.9511 - mean_absolute_error: 0.7180 - mean_squared_error: 0.9511\n",
            "Epoch 653: val_loss improved from 0.91460 to 0.91063, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9492 - mean_absolute_error: 0.7180 - mean_squared_error: 0.9492 - val_loss: 0.9106 - val_mean_absolute_error: 0.7086 - val_mean_squared_error: 0.9106\n",
            "Epoch 654/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.9487 - mean_absolute_error: 0.7180 - mean_squared_error: 0.9487\n",
            "Epoch 654: val_loss improved from 0.91063 to 0.91063, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9487 - mean_absolute_error: 0.7180 - mean_squared_error: 0.9487 - val_loss: 0.9106 - val_mean_absolute_error: 0.7066 - val_mean_squared_error: 0.9106\n",
            "Epoch 655/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.9414 - mean_absolute_error: 0.7152 - mean_squared_error: 0.9414\n",
            "Epoch 655: val_loss improved from 0.91063 to 0.91006, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9465 - mean_absolute_error: 0.7181 - mean_squared_error: 0.9465 - val_loss: 0.9101 - val_mean_absolute_error: 0.7093 - val_mean_squared_error: 0.9101\n",
            "Epoch 656/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.9362 - mean_absolute_error: 0.7158 - mean_squared_error: 0.9362\n",
            "Epoch 656: val_loss improved from 0.91006 to 0.90679, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9447 - mean_absolute_error: 0.7179 - mean_squared_error: 0.9447 - val_loss: 0.9068 - val_mean_absolute_error: 0.7070 - val_mean_squared_error: 0.9068\n",
            "Epoch 657/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.9407 - mean_absolute_error: 0.7160 - mean_squared_error: 0.9407\n",
            "Epoch 657: val_loss improved from 0.90679 to 0.90455, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9413 - mean_absolute_error: 0.7165 - mean_squared_error: 0.9413 - val_loss: 0.9045 - val_mean_absolute_error: 0.7050 - val_mean_squared_error: 0.9045\n",
            "Epoch 658/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.9380 - mean_absolute_error: 0.7157 - mean_squared_error: 0.9380\n",
            "Epoch 658: val_loss improved from 0.90455 to 0.90090, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9407 - mean_absolute_error: 0.7162 - mean_squared_error: 0.9407 - val_loss: 0.9009 - val_mean_absolute_error: 0.7045 - val_mean_squared_error: 0.9009\n",
            "Epoch 659/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.9318 - mean_absolute_error: 0.7122 - mean_squared_error: 0.9318\n",
            "Epoch 659: val_loss did not improve from 0.90090\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9385 - mean_absolute_error: 0.7147 - mean_squared_error: 0.9385 - val_loss: 0.9033 - val_mean_absolute_error: 0.7047 - val_mean_squared_error: 0.9033\n",
            "Epoch 660/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.9259 - mean_absolute_error: 0.7101 - mean_squared_error: 0.9259\n",
            "Epoch 660: val_loss improved from 0.90090 to 0.89858, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9367 - mean_absolute_error: 0.7148 - mean_squared_error: 0.9367 - val_loss: 0.8986 - val_mean_absolute_error: 0.7038 - val_mean_squared_error: 0.8986\n",
            "Epoch 661/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.9370 - mean_absolute_error: 0.7170 - mean_squared_error: 0.9370\n",
            "Epoch 661: val_loss improved from 0.89858 to 0.89690, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9349 - mean_absolute_error: 0.7151 - mean_squared_error: 0.9349 - val_loss: 0.8969 - val_mean_absolute_error: 0.7019 - val_mean_squared_error: 0.8969\n",
            "Epoch 662/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.9241 - mean_absolute_error: 0.7103 - mean_squared_error: 0.9241\n",
            "Epoch 662: val_loss improved from 0.89690 to 0.89540, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9329 - mean_absolute_error: 0.7139 - mean_squared_error: 0.9329 - val_loss: 0.8954 - val_mean_absolute_error: 0.7043 - val_mean_squared_error: 0.8954\n",
            "Epoch 663/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.9365 - mean_absolute_error: 0.7139 - mean_squared_error: 0.9365\n",
            "Epoch 663: val_loss did not improve from 0.89540\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9305 - mean_absolute_error: 0.7133 - mean_squared_error: 0.9305 - val_loss: 0.9024 - val_mean_absolute_error: 0.7042 - val_mean_squared_error: 0.9024\n",
            "Epoch 664/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.9286 - mean_absolute_error: 0.7127 - mean_squared_error: 0.9286\n",
            "Epoch 664: val_loss improved from 0.89540 to 0.89170, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9279 - mean_absolute_error: 0.7127 - mean_squared_error: 0.9279 - val_loss: 0.8917 - val_mean_absolute_error: 0.6999 - val_mean_squared_error: 0.8917\n",
            "Epoch 665/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.9197 - mean_absolute_error: 0.7098 - mean_squared_error: 0.9197\n",
            "Epoch 665: val_loss did not improve from 0.89170\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9267 - mean_absolute_error: 0.7123 - mean_squared_error: 0.9267 - val_loss: 0.8921 - val_mean_absolute_error: 0.6993 - val_mean_squared_error: 0.8921\n",
            "Epoch 666/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.9271 - mean_absolute_error: 0.7136 - mean_squared_error: 0.9271\n",
            "Epoch 666: val_loss improved from 0.89170 to 0.88552, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9245 - mean_absolute_error: 0.7124 - mean_squared_error: 0.9245 - val_loss: 0.8855 - val_mean_absolute_error: 0.6972 - val_mean_squared_error: 0.8855\n",
            "Epoch 667/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.9229 - mean_absolute_error: 0.7099 - mean_squared_error: 0.9229\n",
            "Epoch 667: val_loss did not improve from 0.88552\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9243 - mean_absolute_error: 0.7110 - mean_squared_error: 0.9243 - val_loss: 0.8895 - val_mean_absolute_error: 0.6993 - val_mean_squared_error: 0.8895\n",
            "Epoch 668/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.9351 - mean_absolute_error: 0.7167 - mean_squared_error: 0.9351\n",
            "Epoch 668: val_loss did not improve from 0.88552\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9220 - mean_absolute_error: 0.7114 - mean_squared_error: 0.9220 - val_loss: 0.8886 - val_mean_absolute_error: 0.6984 - val_mean_squared_error: 0.8886\n",
            "Epoch 669/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.9174 - mean_absolute_error: 0.7086 - mean_squared_error: 0.9174\n",
            "Epoch 669: val_loss improved from 0.88552 to 0.88440, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9209 - mean_absolute_error: 0.7095 - mean_squared_error: 0.9209 - val_loss: 0.8844 - val_mean_absolute_error: 0.6982 - val_mean_squared_error: 0.8844\n",
            "Epoch 670/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.9214 - mean_absolute_error: 0.7117 - mean_squared_error: 0.9214\n",
            "Epoch 670: val_loss did not improve from 0.88440\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9167 - mean_absolute_error: 0.7094 - mean_squared_error: 0.9167 - val_loss: 0.9001 - val_mean_absolute_error: 0.7015 - val_mean_squared_error: 0.9001\n",
            "Epoch 671/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.9225 - mean_absolute_error: 0.7120 - mean_squared_error: 0.9225\n",
            "Epoch 671: val_loss improved from 0.88440 to 0.88349, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9176 - mean_absolute_error: 0.7101 - mean_squared_error: 0.9176 - val_loss: 0.8835 - val_mean_absolute_error: 0.6964 - val_mean_squared_error: 0.8835\n",
            "Epoch 672/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.9203 - mean_absolute_error: 0.7107 - mean_squared_error: 0.9203\n",
            "Epoch 672: val_loss improved from 0.88349 to 0.87596, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9136 - mean_absolute_error: 0.7080 - mean_squared_error: 0.9136 - val_loss: 0.8760 - val_mean_absolute_error: 0.6939 - val_mean_squared_error: 0.8760\n",
            "Epoch 673/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.9080 - mean_absolute_error: 0.7067 - mean_squared_error: 0.9080\n",
            "Epoch 673: val_loss did not improve from 0.87596\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9106 - mean_absolute_error: 0.7076 - mean_squared_error: 0.9106 - val_loss: 0.8851 - val_mean_absolute_error: 0.6974 - val_mean_squared_error: 0.8851\n",
            "Epoch 674/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.9110 - mean_absolute_error: 0.7066 - mean_squared_error: 0.9110\n",
            "Epoch 674: val_loss improved from 0.87596 to 0.87527, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9106 - mean_absolute_error: 0.7073 - mean_squared_error: 0.9106 - val_loss: 0.8753 - val_mean_absolute_error: 0.6954 - val_mean_squared_error: 0.8753\n",
            "Epoch 675/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.9069 - mean_absolute_error: 0.7052 - mean_squared_error: 0.9069\n",
            "Epoch 675: val_loss improved from 0.87527 to 0.87036, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9074 - mean_absolute_error: 0.7056 - mean_squared_error: 0.9074 - val_loss: 0.8704 - val_mean_absolute_error: 0.6965 - val_mean_squared_error: 0.8704\n",
            "Epoch 676/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.9088 - mean_absolute_error: 0.7088 - mean_squared_error: 0.9088\n",
            "Epoch 676: val_loss improved from 0.87036 to 0.86956, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9069 - mean_absolute_error: 0.7070 - mean_squared_error: 0.9069 - val_loss: 0.8696 - val_mean_absolute_error: 0.6916 - val_mean_squared_error: 0.8696\n",
            "Epoch 677/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.9178 - mean_absolute_error: 0.7098 - mean_squared_error: 0.9178\n",
            "Epoch 677: val_loss improved from 0.86956 to 0.86708, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9046 - mean_absolute_error: 0.7038 - mean_squared_error: 0.9046 - val_loss: 0.8671 - val_mean_absolute_error: 0.6948 - val_mean_squared_error: 0.8671\n",
            "Epoch 678/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.9008 - mean_absolute_error: 0.7037 - mean_squared_error: 0.9008\n",
            "Epoch 678: val_loss did not improve from 0.86708\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9025 - mean_absolute_error: 0.7045 - mean_squared_error: 0.9025 - val_loss: 0.8694 - val_mean_absolute_error: 0.6943 - val_mean_squared_error: 0.8694\n",
            "Epoch 679/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.9036 - mean_absolute_error: 0.7067 - mean_squared_error: 0.9036\n",
            "Epoch 679: val_loss improved from 0.86708 to 0.86130, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8997 - mean_absolute_error: 0.7051 - mean_squared_error: 0.8997 - val_loss: 0.8613 - val_mean_absolute_error: 0.6918 - val_mean_squared_error: 0.8613\n",
            "Epoch 680/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.9093 - mean_absolute_error: 0.7084 - mean_squared_error: 0.9093\n",
            "Epoch 680: val_loss improved from 0.86130 to 0.85949, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8991 - mean_absolute_error: 0.7049 - mean_squared_error: 0.8991 - val_loss: 0.8595 - val_mean_absolute_error: 0.6904 - val_mean_squared_error: 0.8595\n",
            "Epoch 681/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.8976 - mean_absolute_error: 0.7035 - mean_squared_error: 0.8976\n",
            "Epoch 681: val_loss improved from 0.85949 to 0.85821, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8968 - mean_absolute_error: 0.7035 - mean_squared_error: 0.8968 - val_loss: 0.8582 - val_mean_absolute_error: 0.6909 - val_mean_squared_error: 0.8582\n",
            "Epoch 682/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.8966 - mean_absolute_error: 0.7025 - mean_squared_error: 0.8966\n",
            "Epoch 682: val_loss did not improve from 0.85821\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8948 - mean_absolute_error: 0.7015 - mean_squared_error: 0.8948 - val_loss: 0.8695 - val_mean_absolute_error: 0.6919 - val_mean_squared_error: 0.8695\n",
            "Epoch 683/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.8951 - mean_absolute_error: 0.7016 - mean_squared_error: 0.8951\n",
            "Epoch 683: val_loss improved from 0.85821 to 0.85567, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8936 - mean_absolute_error: 0.7013 - mean_squared_error: 0.8936 - val_loss: 0.8557 - val_mean_absolute_error: 0.6914 - val_mean_squared_error: 0.8557\n",
            "Epoch 684/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.8916 - mean_absolute_error: 0.7023 - mean_squared_error: 0.8916\n",
            "Epoch 684: val_loss did not improve from 0.85567\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8921 - mean_absolute_error: 0.7023 - mean_squared_error: 0.8921 - val_loss: 0.8577 - val_mean_absolute_error: 0.6896 - val_mean_squared_error: 0.8577\n",
            "Epoch 685/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.8871 - mean_absolute_error: 0.7014 - mean_squared_error: 0.8871\n",
            "Epoch 685: val_loss improved from 0.85567 to 0.84930, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8893 - mean_absolute_error: 0.7017 - mean_squared_error: 0.8893 - val_loss: 0.8493 - val_mean_absolute_error: 0.6865 - val_mean_squared_error: 0.8493\n",
            "Epoch 686/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.8867 - mean_absolute_error: 0.6980 - mean_squared_error: 0.8867\n",
            "Epoch 686: val_loss did not improve from 0.84930\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8867 - mean_absolute_error: 0.6980 - mean_squared_error: 0.8867 - val_loss: 0.8497 - val_mean_absolute_error: 0.6911 - val_mean_squared_error: 0.8497\n",
            "Epoch 687/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.8792 - mean_absolute_error: 0.6993 - mean_squared_error: 0.8792\n",
            "Epoch 687: val_loss improved from 0.84930 to 0.84648, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8863 - mean_absolute_error: 0.7005 - mean_squared_error: 0.8863 - val_loss: 0.8465 - val_mean_absolute_error: 0.6867 - val_mean_squared_error: 0.8465\n",
            "Epoch 688/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.8797 - mean_absolute_error: 0.6995 - mean_squared_error: 0.8797\n",
            "Epoch 688: val_loss did not improve from 0.84648\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8833 - mean_absolute_error: 0.7003 - mean_squared_error: 0.8833 - val_loss: 0.8485 - val_mean_absolute_error: 0.6854 - val_mean_squared_error: 0.8485\n",
            "Epoch 689/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.8798 - mean_absolute_error: 0.6967 - mean_squared_error: 0.8798\n",
            "Epoch 689: val_loss did not improve from 0.84648\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8818 - mean_absolute_error: 0.6979 - mean_squared_error: 0.8818 - val_loss: 0.8468 - val_mean_absolute_error: 0.6865 - val_mean_squared_error: 0.8468\n",
            "Epoch 690/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 0.8767 - mean_absolute_error: 0.6957 - mean_squared_error: 0.8767\n",
            "Epoch 690: val_loss improved from 0.84648 to 0.84507, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8798 - mean_absolute_error: 0.6982 - mean_squared_error: 0.8798 - val_loss: 0.8451 - val_mean_absolute_error: 0.6865 - val_mean_squared_error: 0.8451\n",
            "Epoch 691/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.8721 - mean_absolute_error: 0.6961 - mean_squared_error: 0.8721\n",
            "Epoch 691: val_loss improved from 0.84507 to 0.83875, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8776 - mean_absolute_error: 0.6980 - mean_squared_error: 0.8776 - val_loss: 0.8387 - val_mean_absolute_error: 0.6832 - val_mean_squared_error: 0.8387\n",
            "Epoch 692/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.8821 - mean_absolute_error: 0.6992 - mean_squared_error: 0.8821\n",
            "Epoch 692: val_loss did not improve from 0.83875\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8768 - mean_absolute_error: 0.6965 - mean_squared_error: 0.8768 - val_loss: 0.8402 - val_mean_absolute_error: 0.6834 - val_mean_squared_error: 0.8402\n",
            "Epoch 693/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.8737 - mean_absolute_error: 0.6965 - mean_squared_error: 0.8737\n",
            "Epoch 693: val_loss improved from 0.83875 to 0.83457, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.8737 - mean_absolute_error: 0.6965 - mean_squared_error: 0.8737 - val_loss: 0.8346 - val_mean_absolute_error: 0.6828 - val_mean_squared_error: 0.8346\n",
            "Epoch 694/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.8727 - mean_absolute_error: 0.6962 - mean_squared_error: 0.8727\n",
            "Epoch 694: val_loss did not improve from 0.83457\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8724 - mean_absolute_error: 0.6957 - mean_squared_error: 0.8724 - val_loss: 0.8395 - val_mean_absolute_error: 0.6825 - val_mean_squared_error: 0.8395\n",
            "Epoch 695/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.8718 - mean_absolute_error: 0.6964 - mean_squared_error: 0.8718\n",
            "Epoch 695: val_loss did not improve from 0.83457\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8700 - mean_absolute_error: 0.6957 - mean_squared_error: 0.8700 - val_loss: 0.8379 - val_mean_absolute_error: 0.6817 - val_mean_squared_error: 0.8379\n",
            "Epoch 696/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.8671 - mean_absolute_error: 0.6942 - mean_squared_error: 0.8671\n",
            "Epoch 696: val_loss did not improve from 0.83457\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8683 - mean_absolute_error: 0.6941 - mean_squared_error: 0.8683 - val_loss: 0.8394 - val_mean_absolute_error: 0.6822 - val_mean_squared_error: 0.8394\n",
            "Epoch 697/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.8682 - mean_absolute_error: 0.6944 - mean_squared_error: 0.8682\n",
            "Epoch 697: val_loss improved from 0.83457 to 0.82958, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8663 - mean_absolute_error: 0.6937 - mean_squared_error: 0.8663 - val_loss: 0.8296 - val_mean_absolute_error: 0.6817 - val_mean_squared_error: 0.8296\n",
            "Epoch 698/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.8647 - mean_absolute_error: 0.6936 - mean_squared_error: 0.8647\n",
            "Epoch 698: val_loss did not improve from 0.82958\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8628 - mean_absolute_error: 0.6930 - mean_squared_error: 0.8628 - val_loss: 0.8411 - val_mean_absolute_error: 0.6828 - val_mean_squared_error: 0.8411\n",
            "Epoch 699/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 0.8681 - mean_absolute_error: 0.6921 - mean_squared_error: 0.8681\n",
            "Epoch 699: val_loss improved from 0.82958 to 0.82565, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8628 - mean_absolute_error: 0.6916 - mean_squared_error: 0.8628 - val_loss: 0.8256 - val_mean_absolute_error: 0.6809 - val_mean_squared_error: 0.8256\n",
            "Epoch 700/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.8652 - mean_absolute_error: 0.6940 - mean_squared_error: 0.8652\n",
            "Epoch 700: val_loss did not improve from 0.82565\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8623 - mean_absolute_error: 0.6936 - mean_squared_error: 0.8623 - val_loss: 0.8294 - val_mean_absolute_error: 0.6782 - val_mean_squared_error: 0.8294\n",
            "Epoch 701/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.8676 - mean_absolute_error: 0.6948 - mean_squared_error: 0.8676\n",
            "Epoch 701: val_loss improved from 0.82565 to 0.82194, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8579 - mean_absolute_error: 0.6905 - mean_squared_error: 0.8579 - val_loss: 0.8219 - val_mean_absolute_error: 0.6770 - val_mean_squared_error: 0.8219\n",
            "Epoch 702/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.8613 - mean_absolute_error: 0.6921 - mean_squared_error: 0.8613\n",
            "Epoch 702: val_loss improved from 0.82194 to 0.81979, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8572 - mean_absolute_error: 0.6900 - mean_squared_error: 0.8572 - val_loss: 0.8198 - val_mean_absolute_error: 0.6799 - val_mean_squared_error: 0.8198\n",
            "Epoch 703/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 0.8529 - mean_absolute_error: 0.6887 - mean_squared_error: 0.8529\n",
            "Epoch 703: val_loss did not improve from 0.81979\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8525 - mean_absolute_error: 0.6893 - mean_squared_error: 0.8525 - val_loss: 0.8207 - val_mean_absolute_error: 0.6782 - val_mean_squared_error: 0.8207\n",
            "Epoch 704/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.8508 - mean_absolute_error: 0.6878 - mean_squared_error: 0.8508\n",
            "Epoch 704: val_loss improved from 0.81979 to 0.81794, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8531 - mean_absolute_error: 0.6894 - mean_squared_error: 0.8531 - val_loss: 0.8179 - val_mean_absolute_error: 0.6763 - val_mean_squared_error: 0.8179\n",
            "Epoch 705/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.8510 - mean_absolute_error: 0.6886 - mean_squared_error: 0.8510\n",
            "Epoch 705: val_loss improved from 0.81794 to 0.81151, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8519 - mean_absolute_error: 0.6891 - mean_squared_error: 0.8519 - val_loss: 0.8115 - val_mean_absolute_error: 0.6752 - val_mean_squared_error: 0.8115\n",
            "Epoch 706/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.8460 - mean_absolute_error: 0.6862 - mean_squared_error: 0.8460\n",
            "Epoch 706: val_loss improved from 0.81151 to 0.81131, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8475 - mean_absolute_error: 0.6864 - mean_squared_error: 0.8475 - val_loss: 0.8113 - val_mean_absolute_error: 0.6755 - val_mean_squared_error: 0.8113\n",
            "Epoch 707/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.8418 - mean_absolute_error: 0.6864 - mean_squared_error: 0.8418\n",
            "Epoch 707: val_loss improved from 0.81131 to 0.80879, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8464 - mean_absolute_error: 0.6885 - mean_squared_error: 0.8464 - val_loss: 0.8088 - val_mean_absolute_error: 0.6722 - val_mean_squared_error: 0.8088\n",
            "Epoch 708/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.8507 - mean_absolute_error: 0.6903 - mean_squared_error: 0.8507\n",
            "Epoch 708: val_loss did not improve from 0.80879\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8439 - mean_absolute_error: 0.6871 - mean_squared_error: 0.8439 - val_loss: 0.8109 - val_mean_absolute_error: 0.6718 - val_mean_squared_error: 0.8109\n",
            "Epoch 709/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.8421 - mean_absolute_error: 0.6846 - mean_squared_error: 0.8421\n",
            "Epoch 709: val_loss did not improve from 0.80879\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8425 - mean_absolute_error: 0.6852 - mean_squared_error: 0.8425 - val_loss: 0.8088 - val_mean_absolute_error: 0.6728 - val_mean_squared_error: 0.8088\n",
            "Epoch 710/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.8365 - mean_absolute_error: 0.6838 - mean_squared_error: 0.8365\n",
            "Epoch 710: val_loss did not improve from 0.80879\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8423 - mean_absolute_error: 0.6861 - mean_squared_error: 0.8423 - val_loss: 0.8143 - val_mean_absolute_error: 0.6757 - val_mean_squared_error: 0.8143\n",
            "Epoch 711/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.8399 - mean_absolute_error: 0.6853 - mean_squared_error: 0.8399\n",
            "Epoch 711: val_loss improved from 0.80879 to 0.80153, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8386 - mean_absolute_error: 0.6853 - mean_squared_error: 0.8386 - val_loss: 0.8015 - val_mean_absolute_error: 0.6705 - val_mean_squared_error: 0.8015\n",
            "Epoch 712/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.8279 - mean_absolute_error: 0.6801 - mean_squared_error: 0.8279\n",
            "Epoch 712: val_loss did not improve from 0.80153\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8358 - mean_absolute_error: 0.6842 - mean_squared_error: 0.8358 - val_loss: 0.8036 - val_mean_absolute_error: 0.6697 - val_mean_squared_error: 0.8036\n",
            "Epoch 713/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.8285 - mean_absolute_error: 0.6810 - mean_squared_error: 0.8285\n",
            "Epoch 713: val_loss improved from 0.80153 to 0.79989, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8323 - mean_absolute_error: 0.6825 - mean_squared_error: 0.8323 - val_loss: 0.7999 - val_mean_absolute_error: 0.6712 - val_mean_squared_error: 0.7999\n",
            "Epoch 714/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 0.8213 - mean_absolute_error: 0.6763 - mean_squared_error: 0.8213\n",
            "Epoch 714: val_loss improved from 0.79989 to 0.79909, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8330 - mean_absolute_error: 0.6813 - mean_squared_error: 0.8330 - val_loss: 0.7991 - val_mean_absolute_error: 0.6691 - val_mean_squared_error: 0.7991\n",
            "Epoch 715/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.8261 - mean_absolute_error: 0.6804 - mean_squared_error: 0.8261\n",
            "Epoch 715: val_loss did not improve from 0.79909\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8289 - mean_absolute_error: 0.6814 - mean_squared_error: 0.8289 - val_loss: 0.8054 - val_mean_absolute_error: 0.6702 - val_mean_squared_error: 0.8054\n",
            "Epoch 716/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.8346 - mean_absolute_error: 0.6833 - mean_squared_error: 0.8346\n",
            "Epoch 716: val_loss improved from 0.79909 to 0.79176, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8266 - mean_absolute_error: 0.6804 - mean_squared_error: 0.8266 - val_loss: 0.7918 - val_mean_absolute_error: 0.6684 - val_mean_squared_error: 0.7918\n",
            "Epoch 717/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.8240 - mean_absolute_error: 0.6799 - mean_squared_error: 0.8240\n",
            "Epoch 717: val_loss did not improve from 0.79176\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8249 - mean_absolute_error: 0.6806 - mean_squared_error: 0.8249 - val_loss: 0.7938 - val_mean_absolute_error: 0.6674 - val_mean_squared_error: 0.7938\n",
            "Epoch 718/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.8197 - mean_absolute_error: 0.6781 - mean_squared_error: 0.8197\n",
            "Epoch 718: val_loss improved from 0.79176 to 0.78983, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8242 - mean_absolute_error: 0.6812 - mean_squared_error: 0.8242 - val_loss: 0.7898 - val_mean_absolute_error: 0.6660 - val_mean_squared_error: 0.7898\n",
            "Epoch 719/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.8224 - mean_absolute_error: 0.6804 - mean_squared_error: 0.8224\n",
            "Epoch 719: val_loss improved from 0.78983 to 0.78629, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8223 - mean_absolute_error: 0.6799 - mean_squared_error: 0.8223 - val_loss: 0.7863 - val_mean_absolute_error: 0.6654 - val_mean_squared_error: 0.7863\n",
            "Epoch 720/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.8135 - mean_absolute_error: 0.6739 - mean_squared_error: 0.8135\n",
            "Epoch 720: val_loss did not improve from 0.78629\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8191 - mean_absolute_error: 0.6770 - mean_squared_error: 0.8191 - val_loss: 0.7910 - val_mean_absolute_error: 0.6676 - val_mean_squared_error: 0.7910\n",
            "Epoch 721/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.8162 - mean_absolute_error: 0.6775 - mean_squared_error: 0.8162\n",
            "Epoch 721: val_loss improved from 0.78629 to 0.78058, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8172 - mean_absolute_error: 0.6782 - mean_squared_error: 0.8172 - val_loss: 0.7806 - val_mean_absolute_error: 0.6631 - val_mean_squared_error: 0.7806\n",
            "Epoch 722/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.8145 - mean_absolute_error: 0.6766 - mean_squared_error: 0.8145\n",
            "Epoch 722: val_loss improved from 0.78058 to 0.78039, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8144 - mean_absolute_error: 0.6765 - mean_squared_error: 0.8144 - val_loss: 0.7804 - val_mean_absolute_error: 0.6586 - val_mean_squared_error: 0.7804\n",
            "Epoch 723/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.8084 - mean_absolute_error: 0.6737 - mean_squared_error: 0.8084\n",
            "Epoch 723: val_loss did not improve from 0.78039\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8134 - mean_absolute_error: 0.6754 - mean_squared_error: 0.8134 - val_loss: 0.7835 - val_mean_absolute_error: 0.6626 - val_mean_squared_error: 0.7835\n",
            "Epoch 724/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.8147 - mean_absolute_error: 0.6765 - mean_squared_error: 0.8147\n",
            "Epoch 724: val_loss improved from 0.78039 to 0.77615, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8111 - mean_absolute_error: 0.6753 - mean_squared_error: 0.8111 - val_loss: 0.7761 - val_mean_absolute_error: 0.6624 - val_mean_squared_error: 0.7761\n",
            "Epoch 725/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.8123 - mean_absolute_error: 0.6755 - mean_squared_error: 0.8123\n",
            "Epoch 725: val_loss did not improve from 0.77615\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8089 - mean_absolute_error: 0.6735 - mean_squared_error: 0.8089 - val_loss: 0.7794 - val_mean_absolute_error: 0.6666 - val_mean_squared_error: 0.7794\n",
            "Epoch 726/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.8067 - mean_absolute_error: 0.6743 - mean_squared_error: 0.8067\n",
            "Epoch 726: val_loss did not improve from 0.77615\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8067 - mean_absolute_error: 0.6743 - mean_squared_error: 0.8067 - val_loss: 0.7861 - val_mean_absolute_error: 0.6637 - val_mean_squared_error: 0.7861\n",
            "Epoch 727/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.8065 - mean_absolute_error: 0.6729 - mean_squared_error: 0.8065\n",
            "Epoch 727: val_loss improved from 0.77615 to 0.77172, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8063 - mean_absolute_error: 0.6737 - mean_squared_error: 0.8063 - val_loss: 0.7717 - val_mean_absolute_error: 0.6612 - val_mean_squared_error: 0.7717\n",
            "Epoch 728/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.7997 - mean_absolute_error: 0.6695 - mean_squared_error: 0.7997\n",
            "Epoch 728: val_loss improved from 0.77172 to 0.76880, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8021 - mean_absolute_error: 0.6715 - mean_squared_error: 0.8021 - val_loss: 0.7688 - val_mean_absolute_error: 0.6613 - val_mean_squared_error: 0.7688\n",
            "Epoch 729/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.8012 - mean_absolute_error: 0.6735 - mean_squared_error: 0.8012\n",
            "Epoch 729: val_loss improved from 0.76880 to 0.76501, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8000 - mean_absolute_error: 0.6724 - mean_squared_error: 0.8000 - val_loss: 0.7650 - val_mean_absolute_error: 0.6565 - val_mean_squared_error: 0.7650\n",
            "Epoch 730/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.7939 - mean_absolute_error: 0.6670 - mean_squared_error: 0.7939\n",
            "Epoch 730: val_loss improved from 0.76501 to 0.76339, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.7966 - mean_absolute_error: 0.6686 - mean_squared_error: 0.7966 - val_loss: 0.7634 - val_mean_absolute_error: 0.6582 - val_mean_squared_error: 0.7634\n",
            "Epoch 731/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.7888 - mean_absolute_error: 0.6660 - mean_squared_error: 0.7888\n",
            "Epoch 731: val_loss did not improve from 0.76339\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7955 - mean_absolute_error: 0.6692 - mean_squared_error: 0.7955 - val_loss: 0.7663 - val_mean_absolute_error: 0.6587 - val_mean_squared_error: 0.7663\n",
            "Epoch 732/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.7937 - mean_absolute_error: 0.6695 - mean_squared_error: 0.7937\n",
            "Epoch 732: val_loss improved from 0.76339 to 0.76018, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.7948 - mean_absolute_error: 0.6703 - mean_squared_error: 0.7948 - val_loss: 0.7602 - val_mean_absolute_error: 0.6572 - val_mean_squared_error: 0.7602\n",
            "Epoch 733/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.7961 - mean_absolute_error: 0.6715 - mean_squared_error: 0.7961\n",
            "Epoch 733: val_loss improved from 0.76018 to 0.75692, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7903 - mean_absolute_error: 0.6678 - mean_squared_error: 0.7903 - val_loss: 0.7569 - val_mean_absolute_error: 0.6513 - val_mean_squared_error: 0.7569\n",
            "Epoch 734/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.7937 - mean_absolute_error: 0.6700 - mean_squared_error: 0.7937\n",
            "Epoch 734: val_loss did not improve from 0.75692\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7880 - mean_absolute_error: 0.6672 - mean_squared_error: 0.7880 - val_loss: 0.7714 - val_mean_absolute_error: 0.6547 - val_mean_squared_error: 0.7714\n",
            "Epoch 735/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.7811 - mean_absolute_error: 0.6613 - mean_squared_error: 0.7811\n",
            "Epoch 735: val_loss improved from 0.75692 to 0.75677, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.7875 - mean_absolute_error: 0.6648 - mean_squared_error: 0.7875 - val_loss: 0.7568 - val_mean_absolute_error: 0.6548 - val_mean_squared_error: 0.7568\n",
            "Epoch 736/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.7865 - mean_absolute_error: 0.6678 - mean_squared_error: 0.7865\n",
            "Epoch 736: val_loss improved from 0.75677 to 0.75222, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.7846 - mean_absolute_error: 0.6671 - mean_squared_error: 0.7846 - val_loss: 0.7522 - val_mean_absolute_error: 0.6507 - val_mean_squared_error: 0.7522\n",
            "Epoch 737/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.7755 - mean_absolute_error: 0.6618 - mean_squared_error: 0.7755\n",
            "Epoch 737: val_loss improved from 0.75222 to 0.74939, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.7823 - mean_absolute_error: 0.6644 - mean_squared_error: 0.7823 - val_loss: 0.7494 - val_mean_absolute_error: 0.6522 - val_mean_squared_error: 0.7494\n",
            "Epoch 738/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.7795 - mean_absolute_error: 0.6642 - mean_squared_error: 0.7795\n",
            "Epoch 738: val_loss did not improve from 0.74939\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7800 - mean_absolute_error: 0.6641 - mean_squared_error: 0.7800 - val_loss: 0.7530 - val_mean_absolute_error: 0.6506 - val_mean_squared_error: 0.7530\n",
            "Epoch 739/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.7738 - mean_absolute_error: 0.6604 - mean_squared_error: 0.7738\n",
            "Epoch 739: val_loss did not improve from 0.74939\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.7785 - mean_absolute_error: 0.6629 - mean_squared_error: 0.7785 - val_loss: 0.7497 - val_mean_absolute_error: 0.6512 - val_mean_squared_error: 0.7497\n",
            "Epoch 740/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.7719 - mean_absolute_error: 0.6606 - mean_squared_error: 0.7719\n",
            "Epoch 740: val_loss did not improve from 0.74939\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.7736 - mean_absolute_error: 0.6613 - mean_squared_error: 0.7736 - val_loss: 0.7518 - val_mean_absolute_error: 0.6519 - val_mean_squared_error: 0.7518\n",
            "Epoch 741/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.7752 - mean_absolute_error: 0.6622 - mean_squared_error: 0.7752\n",
            "Epoch 741: val_loss improved from 0.74939 to 0.74342, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.7737 - mean_absolute_error: 0.6619 - mean_squared_error: 0.7737 - val_loss: 0.7434 - val_mean_absolute_error: 0.6475 - val_mean_squared_error: 0.7434\n",
            "Epoch 742/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.7711 - mean_absolute_error: 0.6607 - mean_squared_error: 0.7711\n",
            "Epoch 742: val_loss improved from 0.74342 to 0.74103, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7702 - mean_absolute_error: 0.6609 - mean_squared_error: 0.7702 - val_loss: 0.7410 - val_mean_absolute_error: 0.6501 - val_mean_squared_error: 0.7410\n",
            "Epoch 743/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.7721 - mean_absolute_error: 0.6605 - mean_squared_error: 0.7721\n",
            "Epoch 743: val_loss improved from 0.74103 to 0.73803, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7690 - mean_absolute_error: 0.6593 - mean_squared_error: 0.7690 - val_loss: 0.7380 - val_mean_absolute_error: 0.6476 - val_mean_squared_error: 0.7380\n",
            "Epoch 744/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.7703 - mean_absolute_error: 0.6615 - mean_squared_error: 0.7703\n",
            "Epoch 744: val_loss improved from 0.73803 to 0.73627, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.7669 - mean_absolute_error: 0.6600 - mean_squared_error: 0.7669 - val_loss: 0.7363 - val_mean_absolute_error: 0.6468 - val_mean_squared_error: 0.7363\n",
            "Epoch 745/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7647 - mean_absolute_error: 0.6580 - mean_squared_error: 0.7647\n",
            "Epoch 745: val_loss did not improve from 0.73627\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.7647 - mean_absolute_error: 0.6580 - mean_squared_error: 0.7647 - val_loss: 0.7371 - val_mean_absolute_error: 0.6450 - val_mean_squared_error: 0.7371\n",
            "Epoch 746/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.7624 - mean_absolute_error: 0.6561 - mean_squared_error: 0.7624\n",
            "Epoch 746: val_loss did not improve from 0.73627\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.7629 - mean_absolute_error: 0.6567 - mean_squared_error: 0.7629 - val_loss: 0.7373 - val_mean_absolute_error: 0.6468 - val_mean_squared_error: 0.7373\n",
            "Epoch 747/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.7554 - mean_absolute_error: 0.6538 - mean_squared_error: 0.7554\n",
            "Epoch 747: val_loss improved from 0.73627 to 0.72910, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7612 - mean_absolute_error: 0.6570 - mean_squared_error: 0.7612 - val_loss: 0.7291 - val_mean_absolute_error: 0.6456 - val_mean_squared_error: 0.7291\n",
            "Epoch 748/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.7587 - mean_absolute_error: 0.6559 - mean_squared_error: 0.7587\n",
            "Epoch 748: val_loss improved from 0.72910 to 0.72732, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.7573 - mean_absolute_error: 0.6553 - mean_squared_error: 0.7573 - val_loss: 0.7273 - val_mean_absolute_error: 0.6426 - val_mean_squared_error: 0.7273\n",
            "Epoch 749/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 0.7687 - mean_absolute_error: 0.6602 - mean_squared_error: 0.7687\n",
            "Epoch 749: val_loss improved from 0.72732 to 0.72414, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7559 - mean_absolute_error: 0.6552 - mean_squared_error: 0.7559 - val_loss: 0.7241 - val_mean_absolute_error: 0.6436 - val_mean_squared_error: 0.7241\n",
            "Epoch 750/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.7485 - mean_absolute_error: 0.6523 - mean_squared_error: 0.7485\n",
            "Epoch 750: val_loss improved from 0.72414 to 0.72341, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.7535 - mean_absolute_error: 0.6545 - mean_squared_error: 0.7535 - val_loss: 0.7234 - val_mean_absolute_error: 0.6410 - val_mean_squared_error: 0.7234\n",
            "Epoch 751/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7509 - mean_absolute_error: 0.6538 - mean_squared_error: 0.7509\n",
            "Epoch 751: val_loss did not improve from 0.72341\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7509 - mean_absolute_error: 0.6538 - mean_squared_error: 0.7509 - val_loss: 0.7244 - val_mean_absolute_error: 0.6402 - val_mean_squared_error: 0.7244\n",
            "Epoch 752/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 0.7472 - mean_absolute_error: 0.6524 - mean_squared_error: 0.7472\n",
            "Epoch 752: val_loss improved from 0.72341 to 0.72019, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7482 - mean_absolute_error: 0.6518 - mean_squared_error: 0.7482 - val_loss: 0.7202 - val_mean_absolute_error: 0.6399 - val_mean_squared_error: 0.7202\n",
            "Epoch 753/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.7425 - mean_absolute_error: 0.6483 - mean_squared_error: 0.7425\n",
            "Epoch 753: val_loss did not improve from 0.72019\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7467 - mean_absolute_error: 0.6507 - mean_squared_error: 0.7467 - val_loss: 0.7218 - val_mean_absolute_error: 0.6391 - val_mean_squared_error: 0.7218\n",
            "Epoch 754/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.7439 - mean_absolute_error: 0.6496 - mean_squared_error: 0.7439\n",
            "Epoch 754: val_loss improved from 0.72019 to 0.71478, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7431 - mean_absolute_error: 0.6495 - mean_squared_error: 0.7431 - val_loss: 0.7148 - val_mean_absolute_error: 0.6391 - val_mean_squared_error: 0.7148\n",
            "Epoch 755/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.7427 - mean_absolute_error: 0.6490 - mean_squared_error: 0.7427\n",
            "Epoch 755: val_loss improved from 0.71478 to 0.71249, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7424 - mean_absolute_error: 0.6494 - mean_squared_error: 0.7424 - val_loss: 0.7125 - val_mean_absolute_error: 0.6384 - val_mean_squared_error: 0.7125\n",
            "Epoch 756/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.7460 - mean_absolute_error: 0.6505 - mean_squared_error: 0.7460\n",
            "Epoch 756: val_loss improved from 0.71249 to 0.71149, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.7392 - mean_absolute_error: 0.6482 - mean_squared_error: 0.7392 - val_loss: 0.7115 - val_mean_absolute_error: 0.6342 - val_mean_squared_error: 0.7115\n",
            "Epoch 757/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.7370 - mean_absolute_error: 0.6481 - mean_squared_error: 0.7370\n",
            "Epoch 757: val_loss improved from 0.71149 to 0.70846, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7366 - mean_absolute_error: 0.6476 - mean_squared_error: 0.7366 - val_loss: 0.7085 - val_mean_absolute_error: 0.6326 - val_mean_squared_error: 0.7085\n",
            "Epoch 758/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.7370 - mean_absolute_error: 0.6470 - mean_squared_error: 0.7370\n",
            "Epoch 758: val_loss did not improve from 0.70846\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.7334 - mean_absolute_error: 0.6457 - mean_squared_error: 0.7334 - val_loss: 0.7188 - val_mean_absolute_error: 0.6383 - val_mean_squared_error: 0.7188\n",
            "Epoch 759/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.7295 - mean_absolute_error: 0.6436 - mean_squared_error: 0.7295\n",
            "Epoch 759: val_loss improved from 0.70846 to 0.70480, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7324 - mean_absolute_error: 0.6450 - mean_squared_error: 0.7324 - val_loss: 0.7048 - val_mean_absolute_error: 0.6352 - val_mean_squared_error: 0.7048\n",
            "Epoch 760/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7304 - mean_absolute_error: 0.6448 - mean_squared_error: 0.7304\n",
            "Epoch 760: val_loss improved from 0.70480 to 0.69972, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7304 - mean_absolute_error: 0.6448 - mean_squared_error: 0.7304 - val_loss: 0.6997 - val_mean_absolute_error: 0.6313 - val_mean_squared_error: 0.6997\n",
            "Epoch 761/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.7337 - mean_absolute_error: 0.6469 - mean_squared_error: 0.7337\n",
            "Epoch 761: val_loss improved from 0.69972 to 0.69914, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7280 - mean_absolute_error: 0.6445 - mean_squared_error: 0.7280 - val_loss: 0.6991 - val_mean_absolute_error: 0.6294 - val_mean_squared_error: 0.6991\n",
            "Epoch 762/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.7227 - mean_absolute_error: 0.6421 - mean_squared_error: 0.7227\n",
            "Epoch 762: val_loss improved from 0.69914 to 0.69614, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7229 - mean_absolute_error: 0.6422 - mean_squared_error: 0.7229 - val_loss: 0.6961 - val_mean_absolute_error: 0.6289 - val_mean_squared_error: 0.6961\n",
            "Epoch 763/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.7171 - mean_absolute_error: 0.6387 - mean_squared_error: 0.7171\n",
            "Epoch 763: val_loss did not improve from 0.69614\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7197 - mean_absolute_error: 0.6404 - mean_squared_error: 0.7197 - val_loss: 0.7106 - val_mean_absolute_error: 0.6354 - val_mean_squared_error: 0.7106\n",
            "Epoch 764/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.7204 - mean_absolute_error: 0.6405 - mean_squared_error: 0.7204\n",
            "Epoch 764: val_loss improved from 0.69614 to 0.69606, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7181 - mean_absolute_error: 0.6397 - mean_squared_error: 0.7181 - val_loss: 0.6961 - val_mean_absolute_error: 0.6309 - val_mean_squared_error: 0.6961\n",
            "Epoch 765/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.7167 - mean_absolute_error: 0.6405 - mean_squared_error: 0.7167\n",
            "Epoch 765: val_loss improved from 0.69606 to 0.68950, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7162 - mean_absolute_error: 0.6392 - mean_squared_error: 0.7162 - val_loss: 0.6895 - val_mean_absolute_error: 0.6250 - val_mean_squared_error: 0.6895\n",
            "Epoch 766/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.7141 - mean_absolute_error: 0.6376 - mean_squared_error: 0.7141\n",
            "Epoch 766: val_loss did not improve from 0.68950\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7145 - mean_absolute_error: 0.6377 - mean_squared_error: 0.7145 - val_loss: 0.6928 - val_mean_absolute_error: 0.6266 - val_mean_squared_error: 0.6928\n",
            "Epoch 767/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 0.7078 - mean_absolute_error: 0.6351 - mean_squared_error: 0.7078\n",
            "Epoch 767: val_loss improved from 0.68950 to 0.68861, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7089 - mean_absolute_error: 0.6351 - mean_squared_error: 0.7089 - val_loss: 0.6886 - val_mean_absolute_error: 0.6290 - val_mean_squared_error: 0.6886\n",
            "Epoch 768/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.7104 - mean_absolute_error: 0.6376 - mean_squared_error: 0.7104\n",
            "Epoch 768: val_loss improved from 0.68861 to 0.68296, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.7101 - mean_absolute_error: 0.6377 - mean_squared_error: 0.7101 - val_loss: 0.6830 - val_mean_absolute_error: 0.6246 - val_mean_squared_error: 0.6830\n",
            "Epoch 769/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.7015 - mean_absolute_error: 0.6323 - mean_squared_error: 0.7015\n",
            "Epoch 769: val_loss did not improve from 0.68296\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7040 - mean_absolute_error: 0.6340 - mean_squared_error: 0.7040 - val_loss: 0.6834 - val_mean_absolute_error: 0.6222 - val_mean_squared_error: 0.6834\n",
            "Epoch 770/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.7027 - mean_absolute_error: 0.6334 - mean_squared_error: 0.7027\n",
            "Epoch 770: val_loss did not improve from 0.68296\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7029 - mean_absolute_error: 0.6336 - mean_squared_error: 0.7029 - val_loss: 0.6833 - val_mean_absolute_error: 0.6230 - val_mean_squared_error: 0.6833\n",
            "Epoch 771/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.7013 - mean_absolute_error: 0.6325 - mean_squared_error: 0.7013\n",
            "Epoch 771: val_loss improved from 0.68296 to 0.68047, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7011 - mean_absolute_error: 0.6324 - mean_squared_error: 0.7011 - val_loss: 0.6805 - val_mean_absolute_error: 0.6229 - val_mean_squared_error: 0.6805\n",
            "Epoch 772/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.6955 - mean_absolute_error: 0.6306 - mean_squared_error: 0.6955\n",
            "Epoch 772: val_loss improved from 0.68047 to 0.67447, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6974 - mean_absolute_error: 0.6313 - mean_squared_error: 0.6974 - val_loss: 0.6745 - val_mean_absolute_error: 0.6210 - val_mean_squared_error: 0.6745\n",
            "Epoch 773/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.6846 - mean_absolute_error: 0.6259 - mean_squared_error: 0.6846\n",
            "Epoch 773: val_loss did not improve from 0.67447\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6949 - mean_absolute_error: 0.6302 - mean_squared_error: 0.6949 - val_loss: 0.6818 - val_mean_absolute_error: 0.6220 - val_mean_squared_error: 0.6818\n",
            "Epoch 774/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.6928 - mean_absolute_error: 0.6294 - mean_squared_error: 0.6928\n",
            "Epoch 774: val_loss improved from 0.67447 to 0.66863, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6931 - mean_absolute_error: 0.6296 - mean_squared_error: 0.6931 - val_loss: 0.6686 - val_mean_absolute_error: 0.6183 - val_mean_squared_error: 0.6686\n",
            "Epoch 775/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.6918 - mean_absolute_error: 0.6293 - mean_squared_error: 0.6918\n",
            "Epoch 775: val_loss improved from 0.66863 to 0.66779, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6900 - mean_absolute_error: 0.6285 - mean_squared_error: 0.6900 - val_loss: 0.6678 - val_mean_absolute_error: 0.6159 - val_mean_squared_error: 0.6678\n",
            "Epoch 776/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.6856 - mean_absolute_error: 0.6254 - mean_squared_error: 0.6856\n",
            "Epoch 776: val_loss did not improve from 0.66779\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6861 - mean_absolute_error: 0.6256 - mean_squared_error: 0.6861 - val_loss: 0.6719 - val_mean_absolute_error: 0.6177 - val_mean_squared_error: 0.6719\n",
            "Epoch 777/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.6851 - mean_absolute_error: 0.6265 - mean_squared_error: 0.6851\n",
            "Epoch 777: val_loss improved from 0.66779 to 0.66296, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6844 - mean_absolute_error: 0.6261 - mean_squared_error: 0.6844 - val_loss: 0.6630 - val_mean_absolute_error: 0.6135 - val_mean_squared_error: 0.6630\n",
            "Epoch 778/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.6818 - mean_absolute_error: 0.6228 - mean_squared_error: 0.6818\n",
            "Epoch 778: val_loss improved from 0.66296 to 0.66234, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6818 - mean_absolute_error: 0.6232 - mean_squared_error: 0.6818 - val_loss: 0.6623 - val_mean_absolute_error: 0.6177 - val_mean_squared_error: 0.6623\n",
            "Epoch 779/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.6814 - mean_absolute_error: 0.6244 - mean_squared_error: 0.6814\n",
            "Epoch 779: val_loss improved from 0.66234 to 0.65868, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6789 - mean_absolute_error: 0.6227 - mean_squared_error: 0.6789 - val_loss: 0.6587 - val_mean_absolute_error: 0.6137 - val_mean_squared_error: 0.6587\n",
            "Epoch 780/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 0.6816 - mean_absolute_error: 0.6246 - mean_squared_error: 0.6816\n",
            "Epoch 780: val_loss improved from 0.65868 to 0.65646, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6781 - mean_absolute_error: 0.6228 - mean_squared_error: 0.6781 - val_loss: 0.6565 - val_mean_absolute_error: 0.6124 - val_mean_squared_error: 0.6565\n",
            "Epoch 781/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.6745 - mean_absolute_error: 0.6216 - mean_squared_error: 0.6745\n",
            "Epoch 781: val_loss improved from 0.65646 to 0.65223, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6757 - mean_absolute_error: 0.6224 - mean_squared_error: 0.6757 - val_loss: 0.6522 - val_mean_absolute_error: 0.6120 - val_mean_squared_error: 0.6522\n",
            "Epoch 782/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.6696 - mean_absolute_error: 0.6202 - mean_squared_error: 0.6696\n",
            "Epoch 782: val_loss improved from 0.65223 to 0.65208, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6696 - mean_absolute_error: 0.6202 - mean_squared_error: 0.6696 - val_loss: 0.6521 - val_mean_absolute_error: 0.6058 - val_mean_squared_error: 0.6521\n",
            "Epoch 783/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.6684 - mean_absolute_error: 0.6187 - mean_squared_error: 0.6684\n",
            "Epoch 783: val_loss improved from 0.65208 to 0.65143, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6677 - mean_absolute_error: 0.6183 - mean_squared_error: 0.6677 - val_loss: 0.6514 - val_mean_absolute_error: 0.6088 - val_mean_squared_error: 0.6514\n",
            "Epoch 784/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.6658 - mean_absolute_error: 0.6163 - mean_squared_error: 0.6658\n",
            "Epoch 784: val_loss did not improve from 0.65143\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6649 - mean_absolute_error: 0.6163 - mean_squared_error: 0.6649 - val_loss: 0.6593 - val_mean_absolute_error: 0.6105 - val_mean_squared_error: 0.6593\n",
            "Epoch 785/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.6652 - mean_absolute_error: 0.6180 - mean_squared_error: 0.6652\n",
            "Epoch 785: val_loss improved from 0.65143 to 0.64206, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6619 - mean_absolute_error: 0.6167 - mean_squared_error: 0.6619 - val_loss: 0.6421 - val_mean_absolute_error: 0.6060 - val_mean_squared_error: 0.6421\n",
            "Epoch 786/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.6565 - mean_absolute_error: 0.6117 - mean_squared_error: 0.6565\n",
            "Epoch 786: val_loss did not improve from 0.64206\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6573 - mean_absolute_error: 0.6121 - mean_squared_error: 0.6573 - val_loss: 0.6789 - val_mean_absolute_error: 0.6219 - val_mean_squared_error: 0.6789\n",
            "Epoch 787/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.6599 - mean_absolute_error: 0.6166 - mean_squared_error: 0.6599\n",
            "Epoch 787: val_loss improved from 0.64206 to 0.63805, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6579 - mean_absolute_error: 0.6155 - mean_squared_error: 0.6579 - val_loss: 0.6380 - val_mean_absolute_error: 0.6036 - val_mean_squared_error: 0.6380\n",
            "Epoch 788/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.6586 - mean_absolute_error: 0.6131 - mean_squared_error: 0.6586\n",
            "Epoch 788: val_loss improved from 0.63805 to 0.63615, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6548 - mean_absolute_error: 0.6122 - mean_squared_error: 0.6548 - val_loss: 0.6361 - val_mean_absolute_error: 0.6028 - val_mean_squared_error: 0.6361\n",
            "Epoch 789/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.6537 - mean_absolute_error: 0.6115 - mean_squared_error: 0.6537\n",
            "Epoch 789: val_loss improved from 0.63615 to 0.63265, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6518 - mean_absolute_error: 0.6104 - mean_squared_error: 0.6518 - val_loss: 0.6326 - val_mean_absolute_error: 0.6020 - val_mean_squared_error: 0.6326\n",
            "Epoch 790/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.6490 - mean_absolute_error: 0.6101 - mean_squared_error: 0.6490\n",
            "Epoch 790: val_loss did not improve from 0.63265\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6496 - mean_absolute_error: 0.6104 - mean_squared_error: 0.6496 - val_loss: 0.6356 - val_mean_absolute_error: 0.6028 - val_mean_squared_error: 0.6356\n",
            "Epoch 791/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 0.6400 - mean_absolute_error: 0.6065 - mean_squared_error: 0.6400\n",
            "Epoch 791: val_loss did not improve from 0.63265\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6453 - mean_absolute_error: 0.6082 - mean_squared_error: 0.6453 - val_loss: 0.6670 - val_mean_absolute_error: 0.6132 - val_mean_squared_error: 0.6670\n",
            "Epoch 792/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 0.6495 - mean_absolute_error: 0.6091 - mean_squared_error: 0.6495\n",
            "Epoch 792: val_loss improved from 0.63265 to 0.63097, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6444 - mean_absolute_error: 0.6069 - mean_squared_error: 0.6444 - val_loss: 0.6310 - val_mean_absolute_error: 0.6010 - val_mean_squared_error: 0.6310\n",
            "Epoch 793/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.6382 - mean_absolute_error: 0.6032 - mean_squared_error: 0.6382\n",
            "Epoch 793: val_loss improved from 0.63097 to 0.63051, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6411 - mean_absolute_error: 0.6063 - mean_squared_error: 0.6411 - val_loss: 0.6305 - val_mean_absolute_error: 0.6021 - val_mean_squared_error: 0.6305\n",
            "Epoch 794/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 0.6355 - mean_absolute_error: 0.6036 - mean_squared_error: 0.6355\n",
            "Epoch 794: val_loss improved from 0.63051 to 0.62411, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6372 - mean_absolute_error: 0.6053 - mean_squared_error: 0.6372 - val_loss: 0.6241 - val_mean_absolute_error: 0.5965 - val_mean_squared_error: 0.6241\n",
            "Epoch 795/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.6328 - mean_absolute_error: 0.6022 - mean_squared_error: 0.6328\n",
            "Epoch 795: val_loss did not improve from 0.62411\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6344 - mean_absolute_error: 0.6031 - mean_squared_error: 0.6344 - val_loss: 0.6246 - val_mean_absolute_error: 0.5991 - val_mean_squared_error: 0.6246\n",
            "Epoch 796/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.6272 - mean_absolute_error: 0.5975 - mean_squared_error: 0.6272\n",
            "Epoch 796: val_loss improved from 0.62411 to 0.61667, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6305 - mean_absolute_error: 0.5998 - mean_squared_error: 0.6305 - val_loss: 0.6167 - val_mean_absolute_error: 0.5974 - val_mean_squared_error: 0.6167\n",
            "Epoch 797/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.6295 - mean_absolute_error: 0.6021 - mean_squared_error: 0.6295\n",
            "Epoch 797: val_loss improved from 0.61667 to 0.61497, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6279 - mean_absolute_error: 0.6009 - mean_squared_error: 0.6279 - val_loss: 0.6150 - val_mean_absolute_error: 0.5903 - val_mean_squared_error: 0.6150\n",
            "Epoch 798/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.6273 - mean_absolute_error: 0.5992 - mean_squared_error: 0.6273\n",
            "Epoch 798: val_loss improved from 0.61497 to 0.61152, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6253 - mean_absolute_error: 0.5983 - mean_squared_error: 0.6253 - val_loss: 0.6115 - val_mean_absolute_error: 0.5922 - val_mean_squared_error: 0.6115\n",
            "Epoch 799/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.6229 - mean_absolute_error: 0.5970 - mean_squared_error: 0.6229\n",
            "Epoch 799: val_loss improved from 0.61152 to 0.60941, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6239 - mean_absolute_error: 0.5970 - mean_squared_error: 0.6239 - val_loss: 0.6094 - val_mean_absolute_error: 0.5909 - val_mean_squared_error: 0.6094\n",
            "Epoch 800/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.6225 - mean_absolute_error: 0.5952 - mean_squared_error: 0.6225\n",
            "Epoch 800: val_loss did not improve from 0.60941\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6204 - mean_absolute_error: 0.5950 - mean_squared_error: 0.6204 - val_loss: 0.6188 - val_mean_absolute_error: 0.5989 - val_mean_squared_error: 0.6188\n",
            "Epoch 801/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.6187 - mean_absolute_error: 0.5968 - mean_squared_error: 0.6187\n",
            "Epoch 801: val_loss improved from 0.60941 to 0.60324, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6181 - mean_absolute_error: 0.5967 - mean_squared_error: 0.6181 - val_loss: 0.6032 - val_mean_absolute_error: 0.5869 - val_mean_squared_error: 0.6032\n",
            "Epoch 802/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.6174 - mean_absolute_error: 0.5940 - mean_squared_error: 0.6174\n",
            "Epoch 802: val_loss improved from 0.60324 to 0.60159, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6152 - mean_absolute_error: 0.5928 - mean_squared_error: 0.6152 - val_loss: 0.6016 - val_mean_absolute_error: 0.5902 - val_mean_squared_error: 0.6016\n",
            "Epoch 803/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.6149 - mean_absolute_error: 0.5947 - mean_squared_error: 0.6149\n",
            "Epoch 803: val_loss improved from 0.60159 to 0.59965, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6126 - mean_absolute_error: 0.5932 - mean_squared_error: 0.6126 - val_loss: 0.5997 - val_mean_absolute_error: 0.5846 - val_mean_squared_error: 0.5997\n",
            "Epoch 804/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.6110 - mean_absolute_error: 0.5897 - mean_squared_error: 0.6110\n",
            "Epoch 804: val_loss improved from 0.59965 to 0.59565, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6091 - mean_absolute_error: 0.5892 - mean_squared_error: 0.6091 - val_loss: 0.5957 - val_mean_absolute_error: 0.5863 - val_mean_squared_error: 0.5957\n",
            "Epoch 805/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.6026 - mean_absolute_error: 0.5890 - mean_squared_error: 0.6026\n",
            "Epoch 805: val_loss did not improve from 0.59565\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6056 - mean_absolute_error: 0.5901 - mean_squared_error: 0.6056 - val_loss: 0.5989 - val_mean_absolute_error: 0.5828 - val_mean_squared_error: 0.5989\n",
            "Epoch 806/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.6077 - mean_absolute_error: 0.5908 - mean_squared_error: 0.6077\n",
            "Epoch 806: val_loss did not improve from 0.59565\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6025 - mean_absolute_error: 0.5874 - mean_squared_error: 0.6025 - val_loss: 0.6059 - val_mean_absolute_error: 0.5865 - val_mean_squared_error: 0.6059\n",
            "Epoch 807/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.6014 - mean_absolute_error: 0.5866 - mean_squared_error: 0.6014\n",
            "Epoch 807: val_loss improved from 0.59565 to 0.59190, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6010 - mean_absolute_error: 0.5866 - mean_squared_error: 0.6010 - val_loss: 0.5919 - val_mean_absolute_error: 0.5825 - val_mean_squared_error: 0.5919\n",
            "Epoch 808/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.5995 - mean_absolute_error: 0.5861 - mean_squared_error: 0.5995\n",
            "Epoch 808: val_loss improved from 0.59190 to 0.59058, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5983 - mean_absolute_error: 0.5851 - mean_squared_error: 0.5983 - val_loss: 0.5906 - val_mean_absolute_error: 0.5791 - val_mean_squared_error: 0.5906\n",
            "Epoch 809/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.5964 - mean_absolute_error: 0.5850 - mean_squared_error: 0.5964\n",
            "Epoch 809: val_loss improved from 0.59058 to 0.58437, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5968 - mean_absolute_error: 0.5848 - mean_squared_error: 0.5968 - val_loss: 0.5844 - val_mean_absolute_error: 0.5799 - val_mean_squared_error: 0.5844\n",
            "Epoch 810/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.5931 - mean_absolute_error: 0.5821 - mean_squared_error: 0.5931\n",
            "Epoch 810: val_loss did not improve from 0.58437\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5935 - mean_absolute_error: 0.5830 - mean_squared_error: 0.5935 - val_loss: 0.5907 - val_mean_absolute_error: 0.5807 - val_mean_squared_error: 0.5907\n",
            "Epoch 811/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.5880 - mean_absolute_error: 0.5793 - mean_squared_error: 0.5880\n",
            "Epoch 811: val_loss did not improve from 0.58437\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5890 - mean_absolute_error: 0.5802 - mean_squared_error: 0.5890 - val_loss: 0.5942 - val_mean_absolute_error: 0.5855 - val_mean_squared_error: 0.5942\n",
            "Epoch 812/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 0.5854 - mean_absolute_error: 0.5778 - mean_squared_error: 0.5854\n",
            "Epoch 812: val_loss improved from 0.58437 to 0.57870, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5859 - mean_absolute_error: 0.5797 - mean_squared_error: 0.5859 - val_loss: 0.5787 - val_mean_absolute_error: 0.5814 - val_mean_squared_error: 0.5787\n",
            "Epoch 813/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.5810 - mean_absolute_error: 0.5765 - mean_squared_error: 0.5810\n",
            "Epoch 813: val_loss did not improve from 0.57870\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5843 - mean_absolute_error: 0.5784 - mean_squared_error: 0.5843 - val_loss: 0.5793 - val_mean_absolute_error: 0.5763 - val_mean_squared_error: 0.5793\n",
            "Epoch 814/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.5828 - mean_absolute_error: 0.5780 - mean_squared_error: 0.5828\n",
            "Epoch 814: val_loss improved from 0.57870 to 0.57232, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5811 - mean_absolute_error: 0.5772 - mean_squared_error: 0.5811 - val_loss: 0.5723 - val_mean_absolute_error: 0.5710 - val_mean_squared_error: 0.5723\n",
            "Epoch 815/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.5788 - mean_absolute_error: 0.5757 - mean_squared_error: 0.5788\n",
            "Epoch 815: val_loss improved from 0.57232 to 0.57133, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5780 - mean_absolute_error: 0.5751 - mean_squared_error: 0.5780 - val_loss: 0.5713 - val_mean_absolute_error: 0.5724 - val_mean_squared_error: 0.5713\n",
            "Epoch 816/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.5758 - mean_absolute_error: 0.5733 - mean_squared_error: 0.5758\n",
            "Epoch 816: val_loss improved from 0.57133 to 0.56758, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5762 - mean_absolute_error: 0.5733 - mean_squared_error: 0.5762 - val_loss: 0.5676 - val_mean_absolute_error: 0.5741 - val_mean_squared_error: 0.5676\n",
            "Epoch 817/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.5737 - mean_absolute_error: 0.5729 - mean_squared_error: 0.5737\n",
            "Epoch 817: val_loss did not improve from 0.56758\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5740 - mean_absolute_error: 0.5733 - mean_squared_error: 0.5740 - val_loss: 0.5707 - val_mean_absolute_error: 0.5731 - val_mean_squared_error: 0.5707\n",
            "Epoch 818/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.5643 - mean_absolute_error: 0.5702 - mean_squared_error: 0.5643\n",
            "Epoch 818: val_loss improved from 0.56758 to 0.56572, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5697 - mean_absolute_error: 0.5727 - mean_squared_error: 0.5697 - val_loss: 0.5657 - val_mean_absolute_error: 0.5689 - val_mean_squared_error: 0.5657\n",
            "Epoch 819/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.5695 - mean_absolute_error: 0.5715 - mean_squared_error: 0.5695\n",
            "Epoch 819: val_loss improved from 0.56572 to 0.56220, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5678 - mean_absolute_error: 0.5705 - mean_squared_error: 0.5678 - val_loss: 0.5622 - val_mean_absolute_error: 0.5674 - val_mean_squared_error: 0.5622\n",
            "Epoch 820/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.5614 - mean_absolute_error: 0.5655 - mean_squared_error: 0.5614\n",
            "Epoch 820: val_loss improved from 0.56220 to 0.55832, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5654 - mean_absolute_error: 0.5679 - mean_squared_error: 0.5654 - val_loss: 0.5583 - val_mean_absolute_error: 0.5706 - val_mean_squared_error: 0.5583\n",
            "Epoch 821/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.5656 - mean_absolute_error: 0.5719 - mean_squared_error: 0.5656\n",
            "Epoch 821: val_loss did not improve from 0.55832\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5625 - mean_absolute_error: 0.5698 - mean_squared_error: 0.5625 - val_loss: 0.5787 - val_mean_absolute_error: 0.5774 - val_mean_squared_error: 0.5787\n",
            "Epoch 822/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.5627 - mean_absolute_error: 0.5675 - mean_squared_error: 0.5627\n",
            "Epoch 822: val_loss did not improve from 0.55832\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5607 - mean_absolute_error: 0.5666 - mean_squared_error: 0.5607 - val_loss: 0.5645 - val_mean_absolute_error: 0.5716 - val_mean_squared_error: 0.5645\n",
            "Epoch 823/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.5570 - mean_absolute_error: 0.5645 - mean_squared_error: 0.5570\n",
            "Epoch 823: val_loss improved from 0.55832 to 0.54992, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5574 - mean_absolute_error: 0.5650 - mean_squared_error: 0.5574 - val_loss: 0.5499 - val_mean_absolute_error: 0.5612 - val_mean_squared_error: 0.5499\n",
            "Epoch 824/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.5546 - mean_absolute_error: 0.5621 - mean_squared_error: 0.5546\n",
            "Epoch 824: val_loss improved from 0.54992 to 0.54831, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5546 - mean_absolute_error: 0.5626 - mean_squared_error: 0.5546 - val_loss: 0.5483 - val_mean_absolute_error: 0.5633 - val_mean_squared_error: 0.5483\n",
            "Epoch 825/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 0.5544 - mean_absolute_error: 0.5627 - mean_squared_error: 0.5544\n",
            "Epoch 825: val_loss improved from 0.54831 to 0.54633, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5519 - mean_absolute_error: 0.5617 - mean_squared_error: 0.5519 - val_loss: 0.5463 - val_mean_absolute_error: 0.5601 - val_mean_squared_error: 0.5463\n",
            "Epoch 826/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.5505 - mean_absolute_error: 0.5610 - mean_squared_error: 0.5505\n",
            "Epoch 826: val_loss improved from 0.54633 to 0.54547, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5497 - mean_absolute_error: 0.5606 - mean_squared_error: 0.5497 - val_loss: 0.5455 - val_mean_absolute_error: 0.5611 - val_mean_squared_error: 0.5455\n",
            "Epoch 827/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.5456 - mean_absolute_error: 0.5583 - mean_squared_error: 0.5456\n",
            "Epoch 827: val_loss improved from 0.54547 to 0.54087, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5461 - mean_absolute_error: 0.5588 - mean_squared_error: 0.5461 - val_loss: 0.5409 - val_mean_absolute_error: 0.5551 - val_mean_squared_error: 0.5409\n",
            "Epoch 828/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.5513 - mean_absolute_error: 0.5619 - mean_squared_error: 0.5513\n",
            "Epoch 828: val_loss improved from 0.54087 to 0.53888, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5444 - mean_absolute_error: 0.5579 - mean_squared_error: 0.5444 - val_loss: 0.5389 - val_mean_absolute_error: 0.5590 - val_mean_squared_error: 0.5389\n",
            "Epoch 829/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.5400 - mean_absolute_error: 0.5572 - mean_squared_error: 0.5400\n",
            "Epoch 829: val_loss did not improve from 0.53888\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5400 - mean_absolute_error: 0.5572 - mean_squared_error: 0.5400 - val_loss: 0.5455 - val_mean_absolute_error: 0.5548 - val_mean_squared_error: 0.5455\n",
            "Epoch 830/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.5380 - mean_absolute_error: 0.5526 - mean_squared_error: 0.5380\n",
            "Epoch 830: val_loss improved from 0.53888 to 0.53439, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.5393 - mean_absolute_error: 0.5539 - mean_squared_error: 0.5393 - val_loss: 0.5344 - val_mean_absolute_error: 0.5556 - val_mean_squared_error: 0.5344\n",
            "Epoch 831/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.5346 - mean_absolute_error: 0.5539 - mean_squared_error: 0.5346\n",
            "Epoch 831: val_loss improved from 0.53439 to 0.53389, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5354 - mean_absolute_error: 0.5541 - mean_squared_error: 0.5354 - val_loss: 0.5339 - val_mean_absolute_error: 0.5535 - val_mean_squared_error: 0.5339\n",
            "Epoch 832/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.5307 - mean_absolute_error: 0.5514 - mean_squared_error: 0.5307\n",
            "Epoch 832: val_loss did not improve from 0.53389\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5334 - mean_absolute_error: 0.5526 - mean_squared_error: 0.5334 - val_loss: 0.5350 - val_mean_absolute_error: 0.5557 - val_mean_squared_error: 0.5350\n",
            "Epoch 833/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.5355 - mean_absolute_error: 0.5537 - mean_squared_error: 0.5355\n",
            "Epoch 833: val_loss improved from 0.53389 to 0.52619, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5309 - mean_absolute_error: 0.5514 - mean_squared_error: 0.5309 - val_loss: 0.5262 - val_mean_absolute_error: 0.5505 - val_mean_squared_error: 0.5262\n",
            "Epoch 834/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.5264 - mean_absolute_error: 0.5486 - mean_squared_error: 0.5264\n",
            "Epoch 834: val_loss did not improve from 0.52619\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5283 - mean_absolute_error: 0.5501 - mean_squared_error: 0.5283 - val_loss: 0.5285 - val_mean_absolute_error: 0.5514 - val_mean_squared_error: 0.5285\n",
            "Epoch 835/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.5251 - mean_absolute_error: 0.5474 - mean_squared_error: 0.5251\n",
            "Epoch 835: val_loss did not improve from 0.52619\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5260 - mean_absolute_error: 0.5475 - mean_squared_error: 0.5260 - val_loss: 0.5282 - val_mean_absolute_error: 0.5526 - val_mean_squared_error: 0.5282\n",
            "Epoch 836/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.5266 - mean_absolute_error: 0.5487 - mean_squared_error: 0.5266\n",
            "Epoch 836: val_loss improved from 0.52619 to 0.52450, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5232 - mean_absolute_error: 0.5469 - mean_squared_error: 0.5232 - val_loss: 0.5245 - val_mean_absolute_error: 0.5513 - val_mean_squared_error: 0.5245\n",
            "Epoch 837/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.5195 - mean_absolute_error: 0.5440 - mean_squared_error: 0.5195\n",
            "Epoch 837: val_loss improved from 0.52450 to 0.52064, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5220 - mean_absolute_error: 0.5455 - mean_squared_error: 0.5220 - val_loss: 0.5206 - val_mean_absolute_error: 0.5500 - val_mean_squared_error: 0.5206\n",
            "Epoch 838/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.5166 - mean_absolute_error: 0.5453 - mean_squared_error: 0.5166\n",
            "Epoch 838: val_loss improved from 0.52064 to 0.51753, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5181 - mean_absolute_error: 0.5454 - mean_squared_error: 0.5181 - val_loss: 0.5175 - val_mean_absolute_error: 0.5468 - val_mean_squared_error: 0.5175\n",
            "Epoch 839/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.5178 - mean_absolute_error: 0.5443 - mean_squared_error: 0.5178\n",
            "Epoch 839: val_loss did not improve from 0.51753\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5162 - mean_absolute_error: 0.5437 - mean_squared_error: 0.5162 - val_loss: 0.5200 - val_mean_absolute_error: 0.5464 - val_mean_squared_error: 0.5200\n",
            "Epoch 840/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.5149 - mean_absolute_error: 0.5427 - mean_squared_error: 0.5149\n",
            "Epoch 840: val_loss improved from 0.51753 to 0.51024, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5140 - mean_absolute_error: 0.5422 - mean_squared_error: 0.5140 - val_loss: 0.5102 - val_mean_absolute_error: 0.5429 - val_mean_squared_error: 0.5102\n",
            "Epoch 841/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.5094 - mean_absolute_error: 0.5405 - mean_squared_error: 0.5094\n",
            "Epoch 841: val_loss improved from 0.51024 to 0.50766, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5111 - mean_absolute_error: 0.5408 - mean_squared_error: 0.5111 - val_loss: 0.5077 - val_mean_absolute_error: 0.5400 - val_mean_squared_error: 0.5077\n",
            "Epoch 842/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.5058 - mean_absolute_error: 0.5373 - mean_squared_error: 0.5058\n",
            "Epoch 842: val_loss did not improve from 0.50766\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5097 - mean_absolute_error: 0.5393 - mean_squared_error: 0.5097 - val_loss: 0.5087 - val_mean_absolute_error: 0.5418 - val_mean_squared_error: 0.5087\n",
            "Epoch 843/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.5072 - mean_absolute_error: 0.5386 - mean_squared_error: 0.5072\n",
            "Epoch 843: val_loss improved from 0.50766 to 0.50294, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5059 - mean_absolute_error: 0.5378 - mean_squared_error: 0.5059 - val_loss: 0.5029 - val_mean_absolute_error: 0.5376 - val_mean_squared_error: 0.5029\n",
            "Epoch 844/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.5074 - mean_absolute_error: 0.5394 - mean_squared_error: 0.5074\n",
            "Epoch 844: val_loss did not improve from 0.50294\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5045 - mean_absolute_error: 0.5375 - mean_squared_error: 0.5045 - val_loss: 0.5039 - val_mean_absolute_error: 0.5374 - val_mean_squared_error: 0.5039\n",
            "Epoch 845/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.5015 - mean_absolute_error: 0.5350 - mean_squared_error: 0.5015\n",
            "Epoch 845: val_loss did not improve from 0.50294\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5024 - mean_absolute_error: 0.5352 - mean_squared_error: 0.5024 - val_loss: 0.5054 - val_mean_absolute_error: 0.5419 - val_mean_squared_error: 0.5054\n",
            "Epoch 846/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 0.4906 - mean_absolute_error: 0.5283 - mean_squared_error: 0.4906\n",
            "Epoch 846: val_loss improved from 0.50294 to 0.49698, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4972 - mean_absolute_error: 0.5328 - mean_squared_error: 0.4972 - val_loss: 0.4970 - val_mean_absolute_error: 0.5355 - val_mean_squared_error: 0.4970\n",
            "Epoch 847/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.4966 - mean_absolute_error: 0.5337 - mean_squared_error: 0.4966\n",
            "Epoch 847: val_loss improved from 0.49698 to 0.49554, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4967 - mean_absolute_error: 0.5331 - mean_squared_error: 0.4967 - val_loss: 0.4955 - val_mean_absolute_error: 0.5330 - val_mean_squared_error: 0.4955\n",
            "Epoch 848/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.4977 - mean_absolute_error: 0.5336 - mean_squared_error: 0.4977\n",
            "Epoch 848: val_loss improved from 0.49554 to 0.49480, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4957 - mean_absolute_error: 0.5323 - mean_squared_error: 0.4957 - val_loss: 0.4948 - val_mean_absolute_error: 0.5351 - val_mean_squared_error: 0.4948\n",
            "Epoch 849/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.4922 - mean_absolute_error: 0.5287 - mean_squared_error: 0.4922\n",
            "Epoch 849: val_loss improved from 0.49480 to 0.49359, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4929 - mean_absolute_error: 0.5298 - mean_squared_error: 0.4929 - val_loss: 0.4936 - val_mean_absolute_error: 0.5348 - val_mean_squared_error: 0.4936\n",
            "Epoch 850/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.4917 - mean_absolute_error: 0.5308 - mean_squared_error: 0.4917\n",
            "Epoch 850: val_loss improved from 0.49359 to 0.49306, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4905 - mean_absolute_error: 0.5299 - mean_squared_error: 0.4905 - val_loss: 0.4931 - val_mean_absolute_error: 0.5367 - val_mean_squared_error: 0.4931\n",
            "Epoch 851/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.4879 - mean_absolute_error: 0.5305 - mean_squared_error: 0.4879\n",
            "Epoch 851: val_loss did not improve from 0.49306\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4868 - mean_absolute_error: 0.5286 - mean_squared_error: 0.4868 - val_loss: 0.4961 - val_mean_absolute_error: 0.5306 - val_mean_squared_error: 0.4961\n",
            "Epoch 852/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 0.4939 - mean_absolute_error: 0.5311 - mean_squared_error: 0.4939\n",
            "Epoch 852: val_loss improved from 0.49306 to 0.48457, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4858 - mean_absolute_error: 0.5267 - mean_squared_error: 0.4858 - val_loss: 0.4846 - val_mean_absolute_error: 0.5269 - val_mean_squared_error: 0.4846\n",
            "Epoch 853/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.4833 - mean_absolute_error: 0.5248 - mean_squared_error: 0.4833\n",
            "Epoch 853: val_loss improved from 0.48457 to 0.48042, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4833 - mean_absolute_error: 0.5248 - mean_squared_error: 0.4833 - val_loss: 0.4804 - val_mean_absolute_error: 0.5276 - val_mean_squared_error: 0.4804\n",
            "Epoch 854/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.4796 - mean_absolute_error: 0.5218 - mean_squared_error: 0.4796\n",
            "Epoch 854: val_loss did not improve from 0.48042\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4818 - mean_absolute_error: 0.5233 - mean_squared_error: 0.4818 - val_loss: 0.4824 - val_mean_absolute_error: 0.5310 - val_mean_squared_error: 0.4824\n",
            "Epoch 855/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 0.4805 - mean_absolute_error: 0.5268 - mean_squared_error: 0.4805\n",
            "Epoch 855: val_loss improved from 0.48042 to 0.47525, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4791 - mean_absolute_error: 0.5253 - mean_squared_error: 0.4791 - val_loss: 0.4752 - val_mean_absolute_error: 0.5221 - val_mean_squared_error: 0.4752\n",
            "Epoch 856/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.4793 - mean_absolute_error: 0.5222 - mean_squared_error: 0.4793\n",
            "Epoch 856: val_loss improved from 0.47525 to 0.47356, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4759 - mean_absolute_error: 0.5204 - mean_squared_error: 0.4759 - val_loss: 0.4736 - val_mean_absolute_error: 0.5257 - val_mean_squared_error: 0.4736\n",
            "Epoch 857/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.4739 - mean_absolute_error: 0.5198 - mean_squared_error: 0.4739\n",
            "Epoch 857: val_loss improved from 0.47356 to 0.47308, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4739 - mean_absolute_error: 0.5198 - mean_squared_error: 0.4739 - val_loss: 0.4731 - val_mean_absolute_error: 0.5225 - val_mean_squared_error: 0.4731\n",
            "Epoch 858/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.4713 - mean_absolute_error: 0.5198 - mean_squared_error: 0.4713\n",
            "Epoch 858: val_loss improved from 0.47308 to 0.47023, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4715 - mean_absolute_error: 0.5201 - mean_squared_error: 0.4715 - val_loss: 0.4702 - val_mean_absolute_error: 0.5207 - val_mean_squared_error: 0.4702\n",
            "Epoch 859/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.4693 - mean_absolute_error: 0.5184 - mean_squared_error: 0.4693\n",
            "Epoch 859: val_loss did not improve from 0.47023\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4702 - mean_absolute_error: 0.5189 - mean_squared_error: 0.4702 - val_loss: 0.4728 - val_mean_absolute_error: 0.5207 - val_mean_squared_error: 0.4728\n",
            "Epoch 860/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.4686 - mean_absolute_error: 0.5164 - mean_squared_error: 0.4686\n",
            "Epoch 860: val_loss improved from 0.47023 to 0.46510, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4669 - mean_absolute_error: 0.5152 - mean_squared_error: 0.4669 - val_loss: 0.4651 - val_mean_absolute_error: 0.5197 - val_mean_squared_error: 0.4651\n",
            "Epoch 861/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.4619 - mean_absolute_error: 0.5137 - mean_squared_error: 0.4619\n",
            "Epoch 861: val_loss improved from 0.46510 to 0.46283, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4643 - mean_absolute_error: 0.5146 - mean_squared_error: 0.4643 - val_loss: 0.4628 - val_mean_absolute_error: 0.5196 - val_mean_squared_error: 0.4628\n",
            "Epoch 862/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.4637 - mean_absolute_error: 0.5155 - mean_squared_error: 0.4637\n",
            "Epoch 862: val_loss improved from 0.46283 to 0.46124, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4624 - mean_absolute_error: 0.5146 - mean_squared_error: 0.4624 - val_loss: 0.4612 - val_mean_absolute_error: 0.5158 - val_mean_squared_error: 0.4612\n",
            "Epoch 863/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.4604 - mean_absolute_error: 0.5131 - mean_squared_error: 0.4604\n",
            "Epoch 863: val_loss improved from 0.46124 to 0.45946, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4603 - mean_absolute_error: 0.5127 - mean_squared_error: 0.4603 - val_loss: 0.4595 - val_mean_absolute_error: 0.5155 - val_mean_squared_error: 0.4595\n",
            "Epoch 864/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.4570 - mean_absolute_error: 0.5107 - mean_squared_error: 0.4570\n",
            "Epoch 864: val_loss improved from 0.45946 to 0.45562, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4571 - mean_absolute_error: 0.5109 - mean_squared_error: 0.4571 - val_loss: 0.4556 - val_mean_absolute_error: 0.5164 - val_mean_squared_error: 0.4556\n",
            "Epoch 865/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.4550 - mean_absolute_error: 0.5090 - mean_squared_error: 0.4550\n",
            "Epoch 865: val_loss improved from 0.45562 to 0.45379, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4561 - mean_absolute_error: 0.5101 - mean_squared_error: 0.4561 - val_loss: 0.4538 - val_mean_absolute_error: 0.5118 - val_mean_squared_error: 0.4538\n",
            "Epoch 866/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.4516 - mean_absolute_error: 0.5083 - mean_squared_error: 0.4516\n",
            "Epoch 866: val_loss improved from 0.45379 to 0.45286, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4541 - mean_absolute_error: 0.5098 - mean_squared_error: 0.4541 - val_loss: 0.4529 - val_mean_absolute_error: 0.5126 - val_mean_squared_error: 0.4529\n",
            "Epoch 867/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.4486 - mean_absolute_error: 0.5061 - mean_squared_error: 0.4486\n",
            "Epoch 867: val_loss improved from 0.45286 to 0.44846, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4506 - mean_absolute_error: 0.5071 - mean_squared_error: 0.4506 - val_loss: 0.4485 - val_mean_absolute_error: 0.5097 - val_mean_squared_error: 0.4485\n",
            "Epoch 868/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.4516 - mean_absolute_error: 0.5085 - mean_squared_error: 0.4516\n",
            "Epoch 868: val_loss did not improve from 0.44846\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4475 - mean_absolute_error: 0.5067 - mean_squared_error: 0.4475 - val_loss: 0.4512 - val_mean_absolute_error: 0.5069 - val_mean_squared_error: 0.4512\n",
            "Epoch 869/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.4442 - mean_absolute_error: 0.5036 - mean_squared_error: 0.4442\n",
            "Epoch 869: val_loss improved from 0.44846 to 0.44439, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4478 - mean_absolute_error: 0.5056 - mean_squared_error: 0.4478 - val_loss: 0.4444 - val_mean_absolute_error: 0.5053 - val_mean_squared_error: 0.4444\n",
            "Epoch 870/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.4414 - mean_absolute_error: 0.5015 - mean_squared_error: 0.4414\n",
            "Epoch 870: val_loss did not improve from 0.44439\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4441 - mean_absolute_error: 0.5029 - mean_squared_error: 0.4441 - val_loss: 0.4491 - val_mean_absolute_error: 0.5102 - val_mean_squared_error: 0.4491\n",
            "Epoch 871/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.4423 - mean_absolute_error: 0.5028 - mean_squared_error: 0.4423\n",
            "Epoch 871: val_loss improved from 0.44439 to 0.44065, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4425 - mean_absolute_error: 0.5031 - mean_squared_error: 0.4425 - val_loss: 0.4406 - val_mean_absolute_error: 0.5053 - val_mean_squared_error: 0.4406\n",
            "Epoch 872/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.4417 - mean_absolute_error: 0.5015 - mean_squared_error: 0.4417\n",
            "Epoch 872: val_loss did not improve from 0.44065\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4388 - mean_absolute_error: 0.5003 - mean_squared_error: 0.4388 - val_loss: 0.4483 - val_mean_absolute_error: 0.5079 - val_mean_squared_error: 0.4483\n",
            "Epoch 873/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.4421 - mean_absolute_error: 0.5039 - mean_squared_error: 0.4421\n",
            "Epoch 873: val_loss improved from 0.44065 to 0.43627, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4388 - mean_absolute_error: 0.5015 - mean_squared_error: 0.4388 - val_loss: 0.4363 - val_mean_absolute_error: 0.5016 - val_mean_squared_error: 0.4363\n",
            "Epoch 874/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.4399 - mean_absolute_error: 0.5010 - mean_squared_error: 0.4399\n",
            "Epoch 874: val_loss did not improve from 0.43627\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4359 - mean_absolute_error: 0.4990 - mean_squared_error: 0.4359 - val_loss: 0.4377 - val_mean_absolute_error: 0.5052 - val_mean_squared_error: 0.4377\n",
            "Epoch 875/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.4307 - mean_absolute_error: 0.4953 - mean_squared_error: 0.4307\n",
            "Epoch 875: val_loss improved from 0.43627 to 0.43203, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4325 - mean_absolute_error: 0.4975 - mean_squared_error: 0.4325 - val_loss: 0.4320 - val_mean_absolute_error: 0.5004 - val_mean_squared_error: 0.4320\n",
            "Epoch 876/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.4306 - mean_absolute_error: 0.4963 - mean_squared_error: 0.4306\n",
            "Epoch 876: val_loss improved from 0.43203 to 0.42960, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4314 - mean_absolute_error: 0.4968 - mean_squared_error: 0.4314 - val_loss: 0.4296 - val_mean_absolute_error: 0.4997 - val_mean_squared_error: 0.4296\n",
            "Epoch 877/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.4274 - mean_absolute_error: 0.4939 - mean_squared_error: 0.4274\n",
            "Epoch 877: val_loss did not improve from 0.42960\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4292 - mean_absolute_error: 0.4951 - mean_squared_error: 0.4292 - val_loss: 0.4301 - val_mean_absolute_error: 0.5015 - val_mean_squared_error: 0.4301\n",
            "Epoch 878/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.4265 - mean_absolute_error: 0.4953 - mean_squared_error: 0.4265\n",
            "Epoch 878: val_loss did not improve from 0.42960\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4261 - mean_absolute_error: 0.4947 - mean_squared_error: 0.4261 - val_loss: 0.4335 - val_mean_absolute_error: 0.4980 - val_mean_squared_error: 0.4335\n",
            "Epoch 879/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.4266 - mean_absolute_error: 0.4945 - mean_squared_error: 0.4266\n",
            "Epoch 879: val_loss improved from 0.42960 to 0.42747, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4248 - mean_absolute_error: 0.4933 - mean_squared_error: 0.4248 - val_loss: 0.4275 - val_mean_absolute_error: 0.4932 - val_mean_squared_error: 0.4275\n",
            "Epoch 880/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 0.4212 - mean_absolute_error: 0.4907 - mean_squared_error: 0.4212\n",
            "Epoch 880: val_loss improved from 0.42747 to 0.42352, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4232 - mean_absolute_error: 0.4909 - mean_squared_error: 0.4232 - val_loss: 0.4235 - val_mean_absolute_error: 0.4979 - val_mean_squared_error: 0.4235\n",
            "Epoch 881/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.4205 - mean_absolute_error: 0.4905 - mean_squared_error: 0.4205\n",
            "Epoch 881: val_loss improved from 0.42352 to 0.41783, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4197 - mean_absolute_error: 0.4901 - mean_squared_error: 0.4197 - val_loss: 0.4178 - val_mean_absolute_error: 0.4918 - val_mean_squared_error: 0.4178\n",
            "Epoch 882/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.4185 - mean_absolute_error: 0.4882 - mean_squared_error: 0.4185\n",
            "Epoch 882: val_loss did not improve from 0.41783\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4187 - mean_absolute_error: 0.4887 - mean_squared_error: 0.4187 - val_loss: 0.4207 - val_mean_absolute_error: 0.4953 - val_mean_squared_error: 0.4207\n",
            "Epoch 883/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.4168 - mean_absolute_error: 0.4878 - mean_squared_error: 0.4168\n",
            "Epoch 883: val_loss did not improve from 0.41783\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4161 - mean_absolute_error: 0.4871 - mean_squared_error: 0.4161 - val_loss: 0.4209 - val_mean_absolute_error: 0.4923 - val_mean_squared_error: 0.4209\n",
            "Epoch 884/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.4139 - mean_absolute_error: 0.4869 - mean_squared_error: 0.4139\n",
            "Epoch 884: val_loss improved from 0.41783 to 0.41242, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4139 - mean_absolute_error: 0.4869 - mean_squared_error: 0.4139 - val_loss: 0.4124 - val_mean_absolute_error: 0.4883 - val_mean_squared_error: 0.4124\n",
            "Epoch 885/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.4126 - mean_absolute_error: 0.4860 - mean_squared_error: 0.4126\n",
            "Epoch 885: val_loss improved from 0.41242 to 0.41165, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4118 - mean_absolute_error: 0.4856 - mean_squared_error: 0.4118 - val_loss: 0.4116 - val_mean_absolute_error: 0.4886 - val_mean_squared_error: 0.4116\n",
            "Epoch 886/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.4111 - mean_absolute_error: 0.4849 - mean_squared_error: 0.4111\n",
            "Epoch 886: val_loss improved from 0.41165 to 0.40930, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4105 - mean_absolute_error: 0.4839 - mean_squared_error: 0.4105 - val_loss: 0.4093 - val_mean_absolute_error: 0.4877 - val_mean_squared_error: 0.4093\n",
            "Epoch 887/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.4031 - mean_absolute_error: 0.4807 - mean_squared_error: 0.4031\n",
            "Epoch 887: val_loss improved from 0.40930 to 0.40898, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4084 - mean_absolute_error: 0.4835 - mean_squared_error: 0.4084 - val_loss: 0.4090 - val_mean_absolute_error: 0.4842 - val_mean_squared_error: 0.4090\n",
            "Epoch 888/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.4034 - mean_absolute_error: 0.4815 - mean_squared_error: 0.4034\n",
            "Epoch 888: val_loss improved from 0.40898 to 0.40507, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4069 - mean_absolute_error: 0.4827 - mean_squared_error: 0.4069 - val_loss: 0.4051 - val_mean_absolute_error: 0.4852 - val_mean_squared_error: 0.4051\n",
            "Epoch 889/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.4031 - mean_absolute_error: 0.4807 - mean_squared_error: 0.4031\n",
            "Epoch 889: val_loss improved from 0.40507 to 0.40432, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4053 - mean_absolute_error: 0.4818 - mean_squared_error: 0.4053 - val_loss: 0.4043 - val_mean_absolute_error: 0.4838 - val_mean_squared_error: 0.4043\n",
            "Epoch 890/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.4021 - mean_absolute_error: 0.4797 - mean_squared_error: 0.4021\n",
            "Epoch 890: val_loss improved from 0.40432 to 0.40154, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4024 - mean_absolute_error: 0.4798 - mean_squared_error: 0.4024 - val_loss: 0.4015 - val_mean_absolute_error: 0.4811 - val_mean_squared_error: 0.4015\n",
            "Epoch 891/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.4029 - mean_absolute_error: 0.4803 - mean_squared_error: 0.4029\n",
            "Epoch 891: val_loss improved from 0.40154 to 0.40014, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4016 - mean_absolute_error: 0.4795 - mean_squared_error: 0.4016 - val_loss: 0.4001 - val_mean_absolute_error: 0.4825 - val_mean_squared_error: 0.4001\n",
            "Epoch 892/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.3993 - mean_absolute_error: 0.4782 - mean_squared_error: 0.3993\n",
            "Epoch 892: val_loss improved from 0.40014 to 0.39691, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3998 - mean_absolute_error: 0.4782 - mean_squared_error: 0.3998 - val_loss: 0.3969 - val_mean_absolute_error: 0.4798 - val_mean_squared_error: 0.3969\n",
            "Epoch 893/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.3957 - mean_absolute_error: 0.4737 - mean_squared_error: 0.3957\n",
            "Epoch 893: val_loss improved from 0.39691 to 0.39563, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3972 - mean_absolute_error: 0.4771 - mean_squared_error: 0.3972 - val_loss: 0.3956 - val_mean_absolute_error: 0.4805 - val_mean_squared_error: 0.3956\n",
            "Epoch 894/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.3954 - mean_absolute_error: 0.4774 - mean_squared_error: 0.3954\n",
            "Epoch 894: val_loss improved from 0.39563 to 0.39368, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3954 - mean_absolute_error: 0.4761 - mean_squared_error: 0.3954 - val_loss: 0.3937 - val_mean_absolute_error: 0.4781 - val_mean_squared_error: 0.3937\n",
            "Epoch 895/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.3949 - mean_absolute_error: 0.4758 - mean_squared_error: 0.3949\n",
            "Epoch 895: val_loss improved from 0.39368 to 0.39190, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3945 - mean_absolute_error: 0.4751 - mean_squared_error: 0.3945 - val_loss: 0.3919 - val_mean_absolute_error: 0.4762 - val_mean_squared_error: 0.3919\n",
            "Epoch 896/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.3912 - mean_absolute_error: 0.4726 - mean_squared_error: 0.3912\n",
            "Epoch 896: val_loss improved from 0.39190 to 0.38967, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3912 - mean_absolute_error: 0.4726 - mean_squared_error: 0.3912 - val_loss: 0.3897 - val_mean_absolute_error: 0.4757 - val_mean_squared_error: 0.3897\n",
            "Epoch 897/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.3865 - mean_absolute_error: 0.4694 - mean_squared_error: 0.3865\n",
            "Epoch 897: val_loss did not improve from 0.38967\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3895 - mean_absolute_error: 0.4713 - mean_squared_error: 0.3895 - val_loss: 0.3971 - val_mean_absolute_error: 0.4813 - val_mean_squared_error: 0.3971\n",
            "Epoch 898/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.3864 - mean_absolute_error: 0.4701 - mean_squared_error: 0.3864\n",
            "Epoch 898: val_loss improved from 0.38967 to 0.38942, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3882 - mean_absolute_error: 0.4717 - mean_squared_error: 0.3882 - val_loss: 0.3894 - val_mean_absolute_error: 0.4762 - val_mean_squared_error: 0.3894\n",
            "Epoch 899/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.3857 - mean_absolute_error: 0.4699 - mean_squared_error: 0.3857\n",
            "Epoch 899: val_loss improved from 0.38942 to 0.38542, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3864 - mean_absolute_error: 0.4700 - mean_squared_error: 0.3864 - val_loss: 0.3854 - val_mean_absolute_error: 0.4701 - val_mean_squared_error: 0.3854\n",
            "Epoch 900/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.3860 - mean_absolute_error: 0.4707 - mean_squared_error: 0.3860\n",
            "Epoch 900: val_loss improved from 0.38542 to 0.38194, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.3854 - mean_absolute_error: 0.4702 - mean_squared_error: 0.3854 - val_loss: 0.3819 - val_mean_absolute_error: 0.4714 - val_mean_squared_error: 0.3819\n",
            "Epoch 901/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.3839 - mean_absolute_error: 0.4699 - mean_squared_error: 0.3839\n",
            "Epoch 901: val_loss did not improve from 0.38194\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.3826 - mean_absolute_error: 0.4683 - mean_squared_error: 0.3826 - val_loss: 0.3866 - val_mean_absolute_error: 0.4676 - val_mean_squared_error: 0.3866\n",
            "Epoch 902/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.3764 - mean_absolute_error: 0.4643 - mean_squared_error: 0.3764\n",
            "Epoch 902: val_loss did not improve from 0.38194\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.3809 - mean_absolute_error: 0.4663 - mean_squared_error: 0.3809 - val_loss: 0.3823 - val_mean_absolute_error: 0.4699 - val_mean_squared_error: 0.3823\n",
            "Epoch 903/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.3783 - mean_absolute_error: 0.4641 - mean_squared_error: 0.3783\n",
            "Epoch 903: val_loss improved from 0.38194 to 0.37724, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.3795 - mean_absolute_error: 0.4649 - mean_squared_error: 0.3795 - val_loss: 0.3772 - val_mean_absolute_error: 0.4701 - val_mean_squared_error: 0.3772\n",
            "Epoch 904/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.3785 - mean_absolute_error: 0.4654 - mean_squared_error: 0.3785\n",
            "Epoch 904: val_loss improved from 0.37724 to 0.37589, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3786 - mean_absolute_error: 0.4654 - mean_squared_error: 0.3786 - val_loss: 0.3759 - val_mean_absolute_error: 0.4668 - val_mean_squared_error: 0.3759\n",
            "Epoch 905/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.3747 - mean_absolute_error: 0.4626 - mean_squared_error: 0.3747\n",
            "Epoch 905: val_loss improved from 0.37589 to 0.37391, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.3750 - mean_absolute_error: 0.4628 - mean_squared_error: 0.3750 - val_loss: 0.3739 - val_mean_absolute_error: 0.4655 - val_mean_squared_error: 0.3739\n",
            "Epoch 906/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.3777 - mean_absolute_error: 0.4649 - mean_squared_error: 0.3777\n",
            "Epoch 906: val_loss did not improve from 0.37391\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3745 - mean_absolute_error: 0.4633 - mean_squared_error: 0.3745 - val_loss: 0.3742 - val_mean_absolute_error: 0.4655 - val_mean_squared_error: 0.3742\n",
            "Epoch 907/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.3746 - mean_absolute_error: 0.4614 - mean_squared_error: 0.3746\n",
            "Epoch 907: val_loss improved from 0.37391 to 0.36891, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3724 - mean_absolute_error: 0.4599 - mean_squared_error: 0.3724 - val_loss: 0.3689 - val_mean_absolute_error: 0.4625 - val_mean_squared_error: 0.3689\n",
            "Epoch 908/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.3726 - mean_absolute_error: 0.4613 - mean_squared_error: 0.3726\n",
            "Epoch 908: val_loss did not improve from 0.36891\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3702 - mean_absolute_error: 0.4598 - mean_squared_error: 0.3702 - val_loss: 0.3717 - val_mean_absolute_error: 0.4635 - val_mean_squared_error: 0.3717\n",
            "Epoch 909/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.3662 - mean_absolute_error: 0.4570 - mean_squared_error: 0.3662\n",
            "Epoch 909: val_loss improved from 0.36891 to 0.36618, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3689 - mean_absolute_error: 0.4590 - mean_squared_error: 0.3689 - val_loss: 0.3662 - val_mean_absolute_error: 0.4610 - val_mean_squared_error: 0.3662\n",
            "Epoch 910/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.3691 - mean_absolute_error: 0.4600 - mean_squared_error: 0.3691\n",
            "Epoch 910: val_loss improved from 0.36618 to 0.36472, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3672 - mean_absolute_error: 0.4587 - mean_squared_error: 0.3672 - val_loss: 0.3647 - val_mean_absolute_error: 0.4608 - val_mean_squared_error: 0.3647\n",
            "Epoch 911/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.3671 - mean_absolute_error: 0.4585 - mean_squared_error: 0.3671\n",
            "Epoch 911: val_loss improved from 0.36472 to 0.36466, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3668 - mean_absolute_error: 0.4582 - mean_squared_error: 0.3668 - val_loss: 0.3647 - val_mean_absolute_error: 0.4584 - val_mean_squared_error: 0.3647\n",
            "Epoch 912/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.3644 - mean_absolute_error: 0.4564 - mean_squared_error: 0.3644\n",
            "Epoch 912: val_loss improved from 0.36466 to 0.36188, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.3659 - mean_absolute_error: 0.4567 - mean_squared_error: 0.3659 - val_loss: 0.3619 - val_mean_absolute_error: 0.4565 - val_mean_squared_error: 0.3619\n",
            "Epoch 913/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.3625 - mean_absolute_error: 0.4554 - mean_squared_error: 0.3625\n",
            "Epoch 913: val_loss improved from 0.36188 to 0.36053, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3628 - mean_absolute_error: 0.4558 - mean_squared_error: 0.3628 - val_loss: 0.3605 - val_mean_absolute_error: 0.4540 - val_mean_squared_error: 0.3605\n",
            "Epoch 914/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.3609 - mean_absolute_error: 0.4533 - mean_squared_error: 0.3609\n",
            "Epoch 914: val_loss improved from 0.36053 to 0.36020, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3616 - mean_absolute_error: 0.4537 - mean_squared_error: 0.3616 - val_loss: 0.3602 - val_mean_absolute_error: 0.4572 - val_mean_squared_error: 0.3602\n",
            "Epoch 915/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.3594 - mean_absolute_error: 0.4519 - mean_squared_error: 0.3594\n",
            "Epoch 915: val_loss improved from 0.36020 to 0.36018, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3603 - mean_absolute_error: 0.4528 - mean_squared_error: 0.3603 - val_loss: 0.3602 - val_mean_absolute_error: 0.4591 - val_mean_squared_error: 0.3602\n",
            "Epoch 916/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.3566 - mean_absolute_error: 0.4510 - mean_squared_error: 0.3566\n",
            "Epoch 916: val_loss improved from 0.36018 to 0.35580, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3585 - mean_absolute_error: 0.4519 - mean_squared_error: 0.3585 - val_loss: 0.3558 - val_mean_absolute_error: 0.4531 - val_mean_squared_error: 0.3558\n",
            "Epoch 917/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.3563 - mean_absolute_error: 0.4517 - mean_squared_error: 0.3563\n",
            "Epoch 917: val_loss did not improve from 0.35580\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.3565 - mean_absolute_error: 0.4515 - mean_squared_error: 0.3565 - val_loss: 0.3561 - val_mean_absolute_error: 0.4556 - val_mean_squared_error: 0.3561\n",
            "Epoch 918/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.3536 - mean_absolute_error: 0.4487 - mean_squared_error: 0.3536\n",
            "Epoch 918: val_loss improved from 0.35580 to 0.35279, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3550 - mean_absolute_error: 0.4498 - mean_squared_error: 0.3550 - val_loss: 0.3528 - val_mean_absolute_error: 0.4525 - val_mean_squared_error: 0.3528\n",
            "Epoch 919/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.3524 - mean_absolute_error: 0.4494 - mean_squared_error: 0.3524\n",
            "Epoch 919: val_loss did not improve from 0.35279\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3524 - mean_absolute_error: 0.4490 - mean_squared_error: 0.3524 - val_loss: 0.3558 - val_mean_absolute_error: 0.4469 - val_mean_squared_error: 0.3558\n",
            "Epoch 920/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.3502 - mean_absolute_error: 0.4460 - mean_squared_error: 0.3502\n",
            "Epoch 920: val_loss improved from 0.35279 to 0.35126, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3513 - mean_absolute_error: 0.4466 - mean_squared_error: 0.3513 - val_loss: 0.3513 - val_mean_absolute_error: 0.4536 - val_mean_squared_error: 0.3513\n",
            "Epoch 921/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.3492 - mean_absolute_error: 0.4464 - mean_squared_error: 0.3492\n",
            "Epoch 921: val_loss improved from 0.35126 to 0.34862, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3496 - mean_absolute_error: 0.4463 - mean_squared_error: 0.3496 - val_loss: 0.3486 - val_mean_absolute_error: 0.4511 - val_mean_squared_error: 0.3486\n",
            "Epoch 922/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.3498 - mean_absolute_error: 0.4469 - mean_squared_error: 0.3498\n",
            "Epoch 922: val_loss improved from 0.34862 to 0.34641, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3484 - mean_absolute_error: 0.4457 - mean_squared_error: 0.3484 - val_loss: 0.3464 - val_mean_absolute_error: 0.4480 - val_mean_squared_error: 0.3464\n",
            "Epoch 923/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.3437 - mean_absolute_error: 0.4427 - mean_squared_error: 0.3437\n",
            "Epoch 923: val_loss improved from 0.34641 to 0.34605, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3481 - mean_absolute_error: 0.4457 - mean_squared_error: 0.3481 - val_loss: 0.3460 - val_mean_absolute_error: 0.4484 - val_mean_squared_error: 0.3460\n",
            "Epoch 924/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.3446 - mean_absolute_error: 0.4424 - mean_squared_error: 0.3446\n",
            "Epoch 924: val_loss did not improve from 0.34605\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3455 - mean_absolute_error: 0.4434 - mean_squared_error: 0.3455 - val_loss: 0.3500 - val_mean_absolute_error: 0.4492 - val_mean_squared_error: 0.3500\n",
            "Epoch 925/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.3456 - mean_absolute_error: 0.4435 - mean_squared_error: 0.3456\n",
            "Epoch 925: val_loss improved from 0.34605 to 0.34458, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3455 - mean_absolute_error: 0.4437 - mean_squared_error: 0.3455 - val_loss: 0.3446 - val_mean_absolute_error: 0.4443 - val_mean_squared_error: 0.3446\n",
            "Epoch 926/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.3416 - mean_absolute_error: 0.4400 - mean_squared_error: 0.3416\n",
            "Epoch 926: val_loss improved from 0.34458 to 0.34275, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3433 - mean_absolute_error: 0.4410 - mean_squared_error: 0.3433 - val_loss: 0.3428 - val_mean_absolute_error: 0.4458 - val_mean_squared_error: 0.3428\n",
            "Epoch 927/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.3425 - mean_absolute_error: 0.4421 - mean_squared_error: 0.3425\n",
            "Epoch 927: val_loss improved from 0.34275 to 0.34230, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.3428 - mean_absolute_error: 0.4426 - mean_squared_error: 0.3428 - val_loss: 0.3423 - val_mean_absolute_error: 0.4421 - val_mean_squared_error: 0.3423\n",
            "Epoch 928/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.3355 - mean_absolute_error: 0.4370 - mean_squared_error: 0.3355\n",
            "Epoch 928: val_loss improved from 0.34230 to 0.33802, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.3402 - mean_absolute_error: 0.4402 - mean_squared_error: 0.3402 - val_loss: 0.3380 - val_mean_absolute_error: 0.4418 - val_mean_squared_error: 0.3380\n",
            "Epoch 929/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.3399 - mean_absolute_error: 0.4391 - mean_squared_error: 0.3399\n",
            "Epoch 929: val_loss did not improve from 0.33802\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.3387 - mean_absolute_error: 0.4383 - mean_squared_error: 0.3387 - val_loss: 0.3385 - val_mean_absolute_error: 0.4440 - val_mean_squared_error: 0.3385\n",
            "Epoch 930/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.3377 - mean_absolute_error: 0.4388 - mean_squared_error: 0.3377\n",
            "Epoch 930: val_loss improved from 0.33802 to 0.33617, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3375 - mean_absolute_error: 0.4386 - mean_squared_error: 0.3375 - val_loss: 0.3362 - val_mean_absolute_error: 0.4390 - val_mean_squared_error: 0.3362\n",
            "Epoch 931/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.3400 - mean_absolute_error: 0.4387 - mean_squared_error: 0.3400\n",
            "Epoch 931: val_loss improved from 0.33617 to 0.33375, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3370 - mean_absolute_error: 0.4372 - mean_squared_error: 0.3370 - val_loss: 0.3338 - val_mean_absolute_error: 0.4395 - val_mean_squared_error: 0.3338\n",
            "Epoch 932/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.3376 - mean_absolute_error: 0.4379 - mean_squared_error: 0.3376\n",
            "Epoch 932: val_loss did not improve from 0.33375\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3354 - mean_absolute_error: 0.4363 - mean_squared_error: 0.3354 - val_loss: 0.3338 - val_mean_absolute_error: 0.4399 - val_mean_squared_error: 0.3338\n",
            "Epoch 933/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.3345 - mean_absolute_error: 0.4368 - mean_squared_error: 0.3345\n",
            "Epoch 933: val_loss did not improve from 0.33375\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.3344 - mean_absolute_error: 0.4366 - mean_squared_error: 0.3344 - val_loss: 0.3340 - val_mean_absolute_error: 0.4346 - val_mean_squared_error: 0.3340\n",
            "Epoch 934/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.3326 - mean_absolute_error: 0.4340 - mean_squared_error: 0.3326\n",
            "Epoch 934: val_loss did not improve from 0.33375\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3337 - mean_absolute_error: 0.4344 - mean_squared_error: 0.3337 - val_loss: 0.3354 - val_mean_absolute_error: 0.4375 - val_mean_squared_error: 0.3354\n",
            "Epoch 935/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 0.3303 - mean_absolute_error: 0.4329 - mean_squared_error: 0.3303\n",
            "Epoch 935: val_loss improved from 0.33375 to 0.33232, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.3315 - mean_absolute_error: 0.4338 - mean_squared_error: 0.3315 - val_loss: 0.3323 - val_mean_absolute_error: 0.4374 - val_mean_squared_error: 0.3323\n",
            "Epoch 936/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.3318 - mean_absolute_error: 0.4338 - mean_squared_error: 0.3318\n",
            "Epoch 936: val_loss did not improve from 0.33232\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3306 - mean_absolute_error: 0.4328 - mean_squared_error: 0.3306 - val_loss: 0.3343 - val_mean_absolute_error: 0.4381 - val_mean_squared_error: 0.3343\n",
            "Epoch 937/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.3304 - mean_absolute_error: 0.4326 - mean_squared_error: 0.3304\n",
            "Epoch 937: val_loss improved from 0.33232 to 0.32905, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3289 - mean_absolute_error: 0.4313 - mean_squared_error: 0.3289 - val_loss: 0.3291 - val_mean_absolute_error: 0.4343 - val_mean_squared_error: 0.3291\n",
            "Epoch 938/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.3288 - mean_absolute_error: 0.4318 - mean_squared_error: 0.3288\n",
            "Epoch 938: val_loss improved from 0.32905 to 0.32485, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.3282 - mean_absolute_error: 0.4315 - mean_squared_error: 0.3282 - val_loss: 0.3249 - val_mean_absolute_error: 0.4316 - val_mean_squared_error: 0.3249\n",
            "Epoch 939/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 0.3322 - mean_absolute_error: 0.4346 - mean_squared_error: 0.3322\n",
            "Epoch 939: val_loss did not improve from 0.32485\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3275 - mean_absolute_error: 0.4309 - mean_squared_error: 0.3275 - val_loss: 0.3295 - val_mean_absolute_error: 0.4338 - val_mean_squared_error: 0.3295\n",
            "Epoch 940/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.3262 - mean_absolute_error: 0.4291 - mean_squared_error: 0.3262\n",
            "Epoch 940: val_loss did not improve from 0.32485\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3259 - mean_absolute_error: 0.4285 - mean_squared_error: 0.3259 - val_loss: 0.3251 - val_mean_absolute_error: 0.4312 - val_mean_squared_error: 0.3251\n",
            "Epoch 941/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.3236 - mean_absolute_error: 0.4272 - mean_squared_error: 0.3236\n",
            "Epoch 941: val_loss improved from 0.32485 to 0.32288, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3244 - mean_absolute_error: 0.4279 - mean_squared_error: 0.3244 - val_loss: 0.3229 - val_mean_absolute_error: 0.4303 - val_mean_squared_error: 0.3229\n",
            "Epoch 942/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 0.3220 - mean_absolute_error: 0.4264 - mean_squared_error: 0.3220\n",
            "Epoch 942: val_loss did not improve from 0.32288\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3231 - mean_absolute_error: 0.4272 - mean_squared_error: 0.3231 - val_loss: 0.3239 - val_mean_absolute_error: 0.4287 - val_mean_squared_error: 0.3239\n",
            "Epoch 943/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.3228 - mean_absolute_error: 0.4274 - mean_squared_error: 0.3228\n",
            "Epoch 943: val_loss improved from 0.32288 to 0.32007, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3232 - mean_absolute_error: 0.4279 - mean_squared_error: 0.3232 - val_loss: 0.3201 - val_mean_absolute_error: 0.4269 - val_mean_squared_error: 0.3201\n",
            "Epoch 944/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.3195 - mean_absolute_error: 0.4248 - mean_squared_error: 0.3195\n",
            "Epoch 944: val_loss did not improve from 0.32007\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.3208 - mean_absolute_error: 0.4255 - mean_squared_error: 0.3208 - val_loss: 0.3239 - val_mean_absolute_error: 0.4335 - val_mean_squared_error: 0.3239\n",
            "Epoch 945/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.3222 - mean_absolute_error: 0.4260 - mean_squared_error: 0.3222\n",
            "Epoch 945: val_loss improved from 0.32007 to 0.31855, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3193 - mean_absolute_error: 0.4249 - mean_squared_error: 0.3193 - val_loss: 0.3185 - val_mean_absolute_error: 0.4277 - val_mean_squared_error: 0.3185\n",
            "Epoch 946/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.3209 - mean_absolute_error: 0.4251 - mean_squared_error: 0.3209\n",
            "Epoch 946: val_loss improved from 0.31855 to 0.31706, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3187 - mean_absolute_error: 0.4237 - mean_squared_error: 0.3187 - val_loss: 0.3171 - val_mean_absolute_error: 0.4255 - val_mean_squared_error: 0.3171\n",
            "Epoch 947/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.3194 - mean_absolute_error: 0.4241 - mean_squared_error: 0.3194\n",
            "Epoch 947: val_loss did not improve from 0.31706\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3177 - mean_absolute_error: 0.4232 - mean_squared_error: 0.3177 - val_loss: 0.3200 - val_mean_absolute_error: 0.4295 - val_mean_squared_error: 0.3200\n",
            "Epoch 948/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.3180 - mean_absolute_error: 0.4232 - mean_squared_error: 0.3180\n",
            "Epoch 948: val_loss improved from 0.31706 to 0.31579, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.3172 - mean_absolute_error: 0.4226 - mean_squared_error: 0.3172 - val_loss: 0.3158 - val_mean_absolute_error: 0.4254 - val_mean_squared_error: 0.3158\n",
            "Epoch 949/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.3119 - mean_absolute_error: 0.4187 - mean_squared_error: 0.3119\n",
            "Epoch 949: val_loss did not improve from 0.31579\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.3154 - mean_absolute_error: 0.4214 - mean_squared_error: 0.3154 - val_loss: 0.3182 - val_mean_absolute_error: 0.4257 - val_mean_squared_error: 0.3182\n",
            "Epoch 950/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 0.3167 - mean_absolute_error: 0.4211 - mean_squared_error: 0.3167\n",
            "Epoch 950: val_loss did not improve from 0.31579\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3153 - mean_absolute_error: 0.4214 - mean_squared_error: 0.3153 - val_loss: 0.3188 - val_mean_absolute_error: 0.4266 - val_mean_squared_error: 0.3188\n",
            "Epoch 951/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.3162 - mean_absolute_error: 0.4224 - mean_squared_error: 0.3162\n",
            "Epoch 951: val_loss improved from 0.31579 to 0.31343, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.3152 - mean_absolute_error: 0.4216 - mean_squared_error: 0.3152 - val_loss: 0.3134 - val_mean_absolute_error: 0.4244 - val_mean_squared_error: 0.3134\n",
            "Epoch 952/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.3135 - mean_absolute_error: 0.4196 - mean_squared_error: 0.3135\n",
            "Epoch 952: val_loss improved from 0.31343 to 0.31076, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3134 - mean_absolute_error: 0.4196 - mean_squared_error: 0.3134 - val_loss: 0.3108 - val_mean_absolute_error: 0.4208 - val_mean_squared_error: 0.3108\n",
            "Epoch 953/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.3112 - mean_absolute_error: 0.4170 - mean_squared_error: 0.3112\n",
            "Epoch 953: val_loss did not improve from 0.31076\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3112 - mean_absolute_error: 0.4170 - mean_squared_error: 0.3112 - val_loss: 0.3125 - val_mean_absolute_error: 0.4238 - val_mean_squared_error: 0.3125\n",
            "Epoch 954/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.3107 - mean_absolute_error: 0.4182 - mean_squared_error: 0.3107\n",
            "Epoch 954: val_loss improved from 0.31076 to 0.30909, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3107 - mean_absolute_error: 0.4182 - mean_squared_error: 0.3107 - val_loss: 0.3091 - val_mean_absolute_error: 0.4193 - val_mean_squared_error: 0.3091\n",
            "Epoch 955/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.3094 - mean_absolute_error: 0.4166 - mean_squared_error: 0.3094\n",
            "Epoch 955: val_loss improved from 0.30909 to 0.30806, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3094 - mean_absolute_error: 0.4166 - mean_squared_error: 0.3094 - val_loss: 0.3081 - val_mean_absolute_error: 0.4178 - val_mean_squared_error: 0.3081\n",
            "Epoch 956/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.3105 - mean_absolute_error: 0.4168 - mean_squared_error: 0.3105\n",
            "Epoch 956: val_loss improved from 0.30806 to 0.30765, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3088 - mean_absolute_error: 0.4163 - mean_squared_error: 0.3088 - val_loss: 0.3077 - val_mean_absolute_error: 0.4169 - val_mean_squared_error: 0.3077\n",
            "Epoch 957/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.3074 - mean_absolute_error: 0.4149 - mean_squared_error: 0.3074\n",
            "Epoch 957: val_loss did not improve from 0.30765\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.3079 - mean_absolute_error: 0.4151 - mean_squared_error: 0.3079 - val_loss: 0.3078 - val_mean_absolute_error: 0.4161 - val_mean_squared_error: 0.3078\n",
            "Epoch 958/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.3083 - mean_absolute_error: 0.4140 - mean_squared_error: 0.3083\n",
            "Epoch 958: val_loss improved from 0.30765 to 0.30613, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.3068 - mean_absolute_error: 0.4144 - mean_squared_error: 0.3068 - val_loss: 0.3061 - val_mean_absolute_error: 0.4174 - val_mean_squared_error: 0.3061\n",
            "Epoch 959/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.3055 - mean_absolute_error: 0.4137 - mean_squared_error: 0.3055\n",
            "Epoch 959: val_loss did not improve from 0.30613\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.3055 - mean_absolute_error: 0.4137 - mean_squared_error: 0.3055 - val_loss: 0.3062 - val_mean_absolute_error: 0.4185 - val_mean_squared_error: 0.3062\n",
            "Epoch 960/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.3047 - mean_absolute_error: 0.4132 - mean_squared_error: 0.3047\n",
            "Epoch 960: val_loss did not improve from 0.30613\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3053 - mean_absolute_error: 0.4135 - mean_squared_error: 0.3053 - val_loss: 0.3108 - val_mean_absolute_error: 0.4155 - val_mean_squared_error: 0.3108\n",
            "Epoch 961/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.3068 - mean_absolute_error: 0.4148 - mean_squared_error: 0.3068\n",
            "Epoch 961: val_loss improved from 0.30613 to 0.30334, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.3054 - mean_absolute_error: 0.4136 - mean_squared_error: 0.3054 - val_loss: 0.3033 - val_mean_absolute_error: 0.4135 - val_mean_squared_error: 0.3033\n",
            "Epoch 962/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.3028 - mean_absolute_error: 0.4101 - mean_squared_error: 0.3028\n",
            "Epoch 962: val_loss improved from 0.30334 to 0.30273, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.3041 - mean_absolute_error: 0.4111 - mean_squared_error: 0.3041 - val_loss: 0.3027 - val_mean_absolute_error: 0.4139 - val_mean_squared_error: 0.3027\n",
            "Epoch 963/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.3000 - mean_absolute_error: 0.4086 - mean_squared_error: 0.3000\n",
            "Epoch 963: val_loss improved from 0.30273 to 0.30219, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3025 - mean_absolute_error: 0.4110 - mean_squared_error: 0.3025 - val_loss: 0.3022 - val_mean_absolute_error: 0.4149 - val_mean_squared_error: 0.3022\n",
            "Epoch 964/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.3009 - mean_absolute_error: 0.4098 - mean_squared_error: 0.3009\n",
            "Epoch 964: val_loss improved from 0.30219 to 0.30073, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3027 - mean_absolute_error: 0.4113 - mean_squared_error: 0.3027 - val_loss: 0.3007 - val_mean_absolute_error: 0.4127 - val_mean_squared_error: 0.3007\n",
            "Epoch 965/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.3005 - mean_absolute_error: 0.4108 - mean_squared_error: 0.3005\n",
            "Epoch 965: val_loss did not improve from 0.30073\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3005 - mean_absolute_error: 0.4108 - mean_squared_error: 0.3005 - val_loss: 0.3009 - val_mean_absolute_error: 0.4125 - val_mean_squared_error: 0.3009\n",
            "Epoch 966/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.2990 - mean_absolute_error: 0.4077 - mean_squared_error: 0.2990\n",
            "Epoch 966: val_loss improved from 0.30073 to 0.29909, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3004 - mean_absolute_error: 0.4087 - mean_squared_error: 0.3004 - val_loss: 0.2991 - val_mean_absolute_error: 0.4118 - val_mean_squared_error: 0.2991\n",
            "Epoch 967/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.2958 - mean_absolute_error: 0.4067 - mean_squared_error: 0.2958\n",
            "Epoch 967: val_loss improved from 0.29909 to 0.29823, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2990 - mean_absolute_error: 0.4083 - mean_squared_error: 0.2990 - val_loss: 0.2982 - val_mean_absolute_error: 0.4089 - val_mean_squared_error: 0.2982\n",
            "Epoch 968/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.2981 - mean_absolute_error: 0.4083 - mean_squared_error: 0.2981\n",
            "Epoch 968: val_loss did not improve from 0.29823\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2981 - mean_absolute_error: 0.4085 - mean_squared_error: 0.2981 - val_loss: 0.3021 - val_mean_absolute_error: 0.4143 - val_mean_squared_error: 0.3021\n",
            "Epoch 969/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.2974 - mean_absolute_error: 0.4068 - mean_squared_error: 0.2974\n",
            "Epoch 969: val_loss did not improve from 0.29823\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2979 - mean_absolute_error: 0.4071 - mean_squared_error: 0.2979 - val_loss: 0.3035 - val_mean_absolute_error: 0.4114 - val_mean_squared_error: 0.3035\n",
            "Epoch 970/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.3025 - mean_absolute_error: 0.4094 - mean_squared_error: 0.3025\n",
            "Epoch 970: val_loss did not improve from 0.29823\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.2970 - mean_absolute_error: 0.4063 - mean_squared_error: 0.2970 - val_loss: 0.2993 - val_mean_absolute_error: 0.4122 - val_mean_squared_error: 0.2993\n",
            "Epoch 971/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.2947 - mean_absolute_error: 0.4054 - mean_squared_error: 0.2947\n",
            "Epoch 971: val_loss did not improve from 0.29823\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.2950 - mean_absolute_error: 0.4060 - mean_squared_error: 0.2950 - val_loss: 0.2986 - val_mean_absolute_error: 0.4062 - val_mean_squared_error: 0.2986\n",
            "Epoch 972/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.2925 - mean_absolute_error: 0.4028 - mean_squared_error: 0.2925\n",
            "Epoch 972: val_loss improved from 0.29823 to 0.29515, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2944 - mean_absolute_error: 0.4034 - mean_squared_error: 0.2944 - val_loss: 0.2952 - val_mean_absolute_error: 0.4088 - val_mean_squared_error: 0.2952\n",
            "Epoch 973/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.2928 - mean_absolute_error: 0.4022 - mean_squared_error: 0.2928\n",
            "Epoch 973: val_loss did not improve from 0.29515\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.2932 - mean_absolute_error: 0.4025 - mean_squared_error: 0.2932 - val_loss: 0.3015 - val_mean_absolute_error: 0.4127 - val_mean_squared_error: 0.3015\n",
            "Epoch 974/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.2958 - mean_absolute_error: 0.4068 - mean_squared_error: 0.2958\n",
            "Epoch 974: val_loss improved from 0.29515 to 0.29330, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2947 - mean_absolute_error: 0.4058 - mean_squared_error: 0.2947 - val_loss: 0.2933 - val_mean_absolute_error: 0.4055 - val_mean_squared_error: 0.2933\n",
            "Epoch 975/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.2960 - mean_absolute_error: 0.4054 - mean_squared_error: 0.2960\n",
            "Epoch 975: val_loss did not improve from 0.29330\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.2924 - mean_absolute_error: 0.4028 - mean_squared_error: 0.2924 - val_loss: 0.2935 - val_mean_absolute_error: 0.4068 - val_mean_squared_error: 0.2935\n",
            "Epoch 976/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.2906 - mean_absolute_error: 0.4002 - mean_squared_error: 0.2906\n",
            "Epoch 976: val_loss did not improve from 0.29330\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2921 - mean_absolute_error: 0.4019 - mean_squared_error: 0.2921 - val_loss: 0.2938 - val_mean_absolute_error: 0.4077 - val_mean_squared_error: 0.2938\n",
            "Epoch 977/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.2911 - mean_absolute_error: 0.4020 - mean_squared_error: 0.2911\n",
            "Epoch 977: val_loss did not improve from 0.29330\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2906 - mean_absolute_error: 0.4017 - mean_squared_error: 0.2906 - val_loss: 0.2952 - val_mean_absolute_error: 0.4042 - val_mean_squared_error: 0.2952\n",
            "Epoch 978/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.2911 - mean_absolute_error: 0.4015 - mean_squared_error: 0.2911\n",
            "Epoch 978: val_loss improved from 0.29330 to 0.29132, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.2918 - mean_absolute_error: 0.4023 - mean_squared_error: 0.2918 - val_loss: 0.2913 - val_mean_absolute_error: 0.4048 - val_mean_squared_error: 0.2913\n",
            "Epoch 979/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.2889 - mean_absolute_error: 0.4006 - mean_squared_error: 0.2889\n",
            "Epoch 979: val_loss improved from 0.29132 to 0.29036, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2893 - mean_absolute_error: 0.4005 - mean_squared_error: 0.2893 - val_loss: 0.2904 - val_mean_absolute_error: 0.4034 - val_mean_squared_error: 0.2904\n",
            "Epoch 980/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.2886 - mean_absolute_error: 0.4010 - mean_squared_error: 0.2886\n",
            "Epoch 980: val_loss did not improve from 0.29036\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2895 - mean_absolute_error: 0.4007 - mean_squared_error: 0.2895 - val_loss: 0.2915 - val_mean_absolute_error: 0.4020 - val_mean_squared_error: 0.2915\n",
            "Epoch 981/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.2903 - mean_absolute_error: 0.3990 - mean_squared_error: 0.2903\n",
            "Epoch 981: val_loss improved from 0.29036 to 0.28785, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2881 - mean_absolute_error: 0.3979 - mean_squared_error: 0.2881 - val_loss: 0.2878 - val_mean_absolute_error: 0.4021 - val_mean_squared_error: 0.2878\n",
            "Epoch 982/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.2885 - mean_absolute_error: 0.3988 - mean_squared_error: 0.2885\n",
            "Epoch 982: val_loss did not improve from 0.28785\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2885 - mean_absolute_error: 0.3988 - mean_squared_error: 0.2885 - val_loss: 0.2889 - val_mean_absolute_error: 0.4038 - val_mean_squared_error: 0.2889\n",
            "Epoch 983/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.2860 - mean_absolute_error: 0.3978 - mean_squared_error: 0.2860\n",
            "Epoch 983: val_loss improved from 0.28785 to 0.28762, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.2864 - mean_absolute_error: 0.3984 - mean_squared_error: 0.2864 - val_loss: 0.2876 - val_mean_absolute_error: 0.4007 - val_mean_squared_error: 0.2876\n",
            "Epoch 984/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.2842 - mean_absolute_error: 0.3948 - mean_squared_error: 0.2842\n",
            "Epoch 984: val_loss did not improve from 0.28762\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.2858 - mean_absolute_error: 0.3959 - mean_squared_error: 0.2858 - val_loss: 0.2926 - val_mean_absolute_error: 0.4080 - val_mean_squared_error: 0.2926\n",
            "Epoch 985/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.2853 - mean_absolute_error: 0.3963 - mean_squared_error: 0.2853\n",
            "Epoch 985: val_loss did not improve from 0.28762\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2856 - mean_absolute_error: 0.3966 - mean_squared_error: 0.2856 - val_loss: 0.2880 - val_mean_absolute_error: 0.4028 - val_mean_squared_error: 0.2880\n",
            "Epoch 986/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.2861 - mean_absolute_error: 0.3974 - mean_squared_error: 0.2861\n",
            "Epoch 986: val_loss improved from 0.28762 to 0.28475, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.2861 - mean_absolute_error: 0.3974 - mean_squared_error: 0.2861 - val_loss: 0.2847 - val_mean_absolute_error: 0.3997 - val_mean_squared_error: 0.2847\n",
            "Epoch 987/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.2851 - mean_absolute_error: 0.3964 - mean_squared_error: 0.2851\n",
            "Epoch 987: val_loss did not improve from 0.28475\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2835 - mean_absolute_error: 0.3956 - mean_squared_error: 0.2835 - val_loss: 0.2877 - val_mean_absolute_error: 0.3968 - val_mean_squared_error: 0.2877\n",
            "Epoch 988/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.2855 - mean_absolute_error: 0.3961 - mean_squared_error: 0.2855\n",
            "Epoch 988: val_loss improved from 0.28475 to 0.28395, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.2837 - mean_absolute_error: 0.3952 - mean_squared_error: 0.2837 - val_loss: 0.2840 - val_mean_absolute_error: 0.3984 - val_mean_squared_error: 0.2840\n",
            "Epoch 989/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.2865 - mean_absolute_error: 0.3976 - mean_squared_error: 0.2865\n",
            "Epoch 989: val_loss did not improve from 0.28395\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2845 - mean_absolute_error: 0.3965 - mean_squared_error: 0.2845 - val_loss: 0.2852 - val_mean_absolute_error: 0.3985 - val_mean_squared_error: 0.2852\n",
            "Epoch 990/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.2826 - mean_absolute_error: 0.3945 - mean_squared_error: 0.2826\n",
            "Epoch 990: val_loss improved from 0.28395 to 0.28252, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2827 - mean_absolute_error: 0.3941 - mean_squared_error: 0.2827 - val_loss: 0.2825 - val_mean_absolute_error: 0.3945 - val_mean_squared_error: 0.2825\n",
            "Epoch 991/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.2823 - mean_absolute_error: 0.3933 - mean_squared_error: 0.2823\n",
            "Epoch 991: val_loss improved from 0.28252 to 0.28233, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2823 - mean_absolute_error: 0.3933 - mean_squared_error: 0.2823 - val_loss: 0.2823 - val_mean_absolute_error: 0.3980 - val_mean_squared_error: 0.2823\n",
            "Epoch 992/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.2830 - mean_absolute_error: 0.3952 - mean_squared_error: 0.2830\n",
            "Epoch 992: val_loss did not improve from 0.28233\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2814 - mean_absolute_error: 0.3939 - mean_squared_error: 0.2814 - val_loss: 0.2909 - val_mean_absolute_error: 0.4006 - val_mean_squared_error: 0.2909\n",
            "Epoch 993/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.2781 - mean_absolute_error: 0.3901 - mean_squared_error: 0.2781\n",
            "Epoch 993: val_loss improved from 0.28233 to 0.28124, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.2805 - mean_absolute_error: 0.3918 - mean_squared_error: 0.2805 - val_loss: 0.2812 - val_mean_absolute_error: 0.3945 - val_mean_squared_error: 0.2812\n",
            "Epoch 994/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.2783 - mean_absolute_error: 0.3915 - mean_squared_error: 0.2783\n",
            "Epoch 994: val_loss improved from 0.28124 to 0.28041, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2791 - mean_absolute_error: 0.3920 - mean_squared_error: 0.2791 - val_loss: 0.2804 - val_mean_absolute_error: 0.3932 - val_mean_squared_error: 0.2804\n",
            "Epoch 995/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.2781 - mean_absolute_error: 0.3902 - mean_squared_error: 0.2781\n",
            "Epoch 995: val_loss improved from 0.28041 to 0.28015, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2806 - mean_absolute_error: 0.3916 - mean_squared_error: 0.2806 - val_loss: 0.2802 - val_mean_absolute_error: 0.3904 - val_mean_squared_error: 0.2802\n",
            "Epoch 996/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.2820 - mean_absolute_error: 0.3930 - mean_squared_error: 0.2820\n",
            "Epoch 996: val_loss improved from 0.28015 to 0.27812, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.2789 - mean_absolute_error: 0.3909 - mean_squared_error: 0.2789 - val_loss: 0.2781 - val_mean_absolute_error: 0.3932 - val_mean_squared_error: 0.2781\n",
            "Epoch 997/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.2775 - mean_absolute_error: 0.3905 - mean_squared_error: 0.2775\n",
            "Epoch 997: val_loss did not improve from 0.27812\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2775 - mean_absolute_error: 0.3907 - mean_squared_error: 0.2775 - val_loss: 0.2807 - val_mean_absolute_error: 0.3967 - val_mean_squared_error: 0.2807\n",
            "Epoch 998/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.2772 - mean_absolute_error: 0.3898 - mean_squared_error: 0.2772\n",
            "Epoch 998: val_loss improved from 0.27812 to 0.27756, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2768 - mean_absolute_error: 0.3894 - mean_squared_error: 0.2768 - val_loss: 0.2776 - val_mean_absolute_error: 0.3935 - val_mean_squared_error: 0.2776\n",
            "Epoch 999/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.2755 - mean_absolute_error: 0.3885 - mean_squared_error: 0.2755\n",
            "Epoch 999: val_loss improved from 0.27756 to 0.27722, saving model to best_model8.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2767 - mean_absolute_error: 0.3893 - mean_squared_error: 0.2767 - val_loss: 0.2772 - val_mean_absolute_error: 0.3926 - val_mean_squared_error: 0.2772\n",
            "Epoch 1000/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.2776 - mean_absolute_error: 0.3900 - mean_squared_error: 0.2776\n",
            "Epoch 1000: val_loss did not improve from 0.27722\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2763 - mean_absolute_error: 0.3893 - mean_squared_error: 0.2763 - val_loss: 0.2773 - val_mean_absolute_error: 0.3911 - val_mean_squared_error: 0.2773\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f848abb0ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = load_model('best_model8.h5')\n",
        "\n",
        "z_predict_test8 = model8.predict(Z_test)\n",
        "\n",
        "plt.plot(z_predict_test8,z_test,'.')\n",
        "\n",
        "print('MSE:', mean_squared_error(z_test, z_predict_test8))\n",
        "print('MAE:', mean_absolute_error(z_test, z_predict_test8))\n",
        "print('RMSE:', mean_squared_error(z_test, z_predict_test8)**0.5)\n",
        "print('Spearman R:', spearmanr(z_test, z_predict_test8))\n",
        "print('R2:', r2_score(z_test, z_predict_test8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "DxNqiNaNkgvz",
        "outputId": "5d85629a-79fe-4e37-cbf8-c7259e044a68"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 0s 2ms/step\n",
            "MSE: 0.2862738072274866\n",
            "MAE: 0.3922871438123451\n",
            "RMSE: 0.5350456122869214\n",
            "Spearman R: SpearmanrResult(correlation=0.9025548056172005, pvalue=0.0)\n",
            "R2: 0.9197187357677522\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3 capas escondidas, 5 neuronas:\n",
        "\n",
        "model9 = Sequential()\n",
        "#model.add(Dense(100, input_dim=2, activation='sigmoid'))\n",
        "model9.add(Dense(5, input_dim=2, activation='sigmoid'))\n",
        "model9.add(Dense(5, activation='sigmoid'))\n",
        "model9.add(Dense(5, activation='sigmoid'))\n",
        "model9.add(Dense(1, activation='linear'))\n",
        "\n",
        "model9.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error', 'mean_squared_error'])\n",
        "model9.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwF9VF4HqHAU",
        "outputId": "f1c9c369-b8b6-4899-8fd8-d14bd6a7e9cd"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_18 (Dense)            (None, 5)                 15        \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 81\n",
            "Trainable params: 81\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ajuste:\n",
        "es9 = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "mc9 = ModelCheckpoint('best_model9.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)"
      ],
      "metadata": {
        "id": "jk0aVL7aqTzv"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model9.fit(Z_train, z_train, epochs=1000, batch_size=20, validation_split=0.3, shuffle=True, verbose=True, callbacks=[es9,mc9])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FMrzWWSqcnB",
        "outputId": "93ac65ed-0c66-4b1b-ba96-6483a45280ae"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 4.0946 - mean_absolute_error: 1.2812 - mean_squared_error: 4.0946\n",
            "Epoch 1: val_loss improved from inf to 3.63032, saving model to best_model9.h5\n",
            "245/245 [==============================] - 2s 3ms/step - loss: 4.0959 - mean_absolute_error: 1.2780 - mean_squared_error: 4.0959 - val_loss: 3.6303 - val_mean_absolute_error: 1.1900 - val_mean_squared_error: 3.6303\n",
            "Epoch 2/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 3.7161 - mean_absolute_error: 1.2236 - mean_squared_error: 3.7161\n",
            "Epoch 2: val_loss improved from 3.63032 to 3.62205, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.7443 - mean_absolute_error: 1.2317 - mean_squared_error: 3.7443 - val_loss: 3.6220 - val_mean_absolute_error: 1.2386 - val_mean_squared_error: 3.6220\n",
            "Epoch 3/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 3.7231 - mean_absolute_error: 1.2421 - mean_squared_error: 3.7231\n",
            "Epoch 3: val_loss improved from 3.62205 to 3.61677, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.7366 - mean_absolute_error: 1.2456 - mean_squared_error: 3.7366 - val_loss: 3.6168 - val_mean_absolute_error: 1.2355 - val_mean_squared_error: 3.6168\n",
            "Epoch 4/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 3.7440 - mean_absolute_error: 1.2507 - mean_squared_error: 3.7440\n",
            "Epoch 4: val_loss improved from 3.61677 to 3.60917, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 3.7311 - mean_absolute_error: 1.2486 - mean_squared_error: 3.7311 - val_loss: 3.6092 - val_mean_absolute_error: 1.2312 - val_mean_squared_error: 3.6092\n",
            "Epoch 5/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 3.7330 - mean_absolute_error: 1.2460 - mean_squared_error: 3.7330\n",
            "Epoch 5: val_loss improved from 3.60917 to 3.59825, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 3.7233 - mean_absolute_error: 1.2435 - mean_squared_error: 3.7233 - val_loss: 3.5983 - val_mean_absolute_error: 1.2288 - val_mean_squared_error: 3.5983\n",
            "Epoch 6/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 3.7220 - mean_absolute_error: 1.2428 - mean_squared_error: 3.7220\n",
            "Epoch 6: val_loss improved from 3.59825 to 3.57933, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 3.7086 - mean_absolute_error: 1.2390 - mean_squared_error: 3.7086 - val_loss: 3.5793 - val_mean_absolute_error: 1.2225 - val_mean_squared_error: 3.5793\n",
            "Epoch 7/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 3.6755 - mean_absolute_error: 1.2339 - mean_squared_error: 3.6755\n",
            "Epoch 7: val_loss improved from 3.57933 to 3.54951, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.6847 - mean_absolute_error: 1.2357 - mean_squared_error: 3.6847 - val_loss: 3.5495 - val_mean_absolute_error: 1.2176 - val_mean_squared_error: 3.5495\n",
            "Epoch 8/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 3.6403 - mean_absolute_error: 1.2223 - mean_squared_error: 3.6403\n",
            "Epoch 8: val_loss improved from 3.54951 to 3.49897, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.6446 - mean_absolute_error: 1.2217 - mean_squared_error: 3.6446 - val_loss: 3.4990 - val_mean_absolute_error: 1.2077 - val_mean_squared_error: 3.4990\n",
            "Epoch 9/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 3.5945 - mean_absolute_error: 1.2113 - mean_squared_error: 3.5945\n",
            "Epoch 9: val_loss improved from 3.49897 to 3.41406, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.5789 - mean_absolute_error: 1.2081 - mean_squared_error: 3.5789 - val_loss: 3.4141 - val_mean_absolute_error: 1.1817 - val_mean_squared_error: 3.4141\n",
            "Epoch 10/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 3.4824 - mean_absolute_error: 1.1807 - mean_squared_error: 3.4824\n",
            "Epoch 10: val_loss improved from 3.41406 to 3.29392, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.4783 - mean_absolute_error: 1.1789 - mean_squared_error: 3.4783 - val_loss: 3.2939 - val_mean_absolute_error: 1.1518 - val_mean_squared_error: 3.2939\n",
            "Epoch 11/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 3.2761 - mean_absolute_error: 1.1547 - mean_squared_error: 3.2761\n",
            "Epoch 11: val_loss improved from 3.29392 to 3.15995, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.3490 - mean_absolute_error: 1.1657 - mean_squared_error: 3.3490 - val_loss: 3.1599 - val_mean_absolute_error: 1.1465 - val_mean_squared_error: 3.1599\n",
            "Epoch 12/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 3.2011 - mean_absolute_error: 1.1747 - mean_squared_error: 3.2011\n",
            "Epoch 12: val_loss improved from 3.15995 to 3.05389, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.2219 - mean_absolute_error: 1.1778 - mean_squared_error: 3.2219 - val_loss: 3.0539 - val_mean_absolute_error: 1.1672 - val_mean_squared_error: 3.0539\n",
            "Epoch 13/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 3.1232 - mean_absolute_error: 1.1977 - mean_squared_error: 3.1232\n",
            "Epoch 13: val_loss improved from 3.05389 to 2.98747, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.1334 - mean_absolute_error: 1.2006 - mean_squared_error: 3.1334 - val_loss: 2.9875 - val_mean_absolute_error: 1.1920 - val_mean_squared_error: 2.9875\n",
            "Epoch 14/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 3.1001 - mean_absolute_error: 1.2325 - mean_squared_error: 3.1001\n",
            "Epoch 14: val_loss improved from 2.98747 to 2.93883, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0772 - mean_absolute_error: 1.2259 - mean_squared_error: 3.0772 - val_loss: 2.9388 - val_mean_absolute_error: 1.2076 - val_mean_squared_error: 2.9388\n",
            "Epoch 15/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 3.0384 - mean_absolute_error: 1.2356 - mean_squared_error: 3.0384\n",
            "Epoch 15: val_loss improved from 2.93883 to 2.92055, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0554 - mean_absolute_error: 1.2414 - mean_squared_error: 3.0554 - val_loss: 2.9205 - val_mean_absolute_error: 1.2227 - val_mean_squared_error: 2.9205\n",
            "Epoch 16/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 3.0231 - mean_absolute_error: 1.2515 - mean_squared_error: 3.0231\n",
            "Epoch 16: val_loss improved from 2.92055 to 2.91398, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0368 - mean_absolute_error: 1.2537 - mean_squared_error: 3.0368 - val_loss: 2.9140 - val_mean_absolute_error: 1.2341 - val_mean_squared_error: 2.9140\n",
            "Epoch 17/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 3.0115 - mean_absolute_error: 1.2591 - mean_squared_error: 3.0115\n",
            "Epoch 17: val_loss improved from 2.91398 to 2.90505, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0254 - mean_absolute_error: 1.2618 - mean_squared_error: 3.0254 - val_loss: 2.9050 - val_mean_absolute_error: 1.2409 - val_mean_squared_error: 2.9050\n",
            "Epoch 18/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 3.0017 - mean_absolute_error: 1.2640 - mean_squared_error: 3.0017\n",
            "Epoch 18: val_loss improved from 2.90505 to 2.89548, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0167 - mean_absolute_error: 1.2659 - mean_squared_error: 3.0167 - val_loss: 2.8955 - val_mean_absolute_error: 1.2424 - val_mean_squared_error: 2.8955\n",
            "Epoch 19/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.9621 - mean_absolute_error: 1.2574 - mean_squared_error: 2.9621\n",
            "Epoch 19: val_loss improved from 2.89548 to 2.89501, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 3.0065 - mean_absolute_error: 1.2687 - mean_squared_error: 3.0065 - val_loss: 2.8950 - val_mean_absolute_error: 1.2452 - val_mean_squared_error: 2.8950\n",
            "Epoch 20/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 3.0037 - mean_absolute_error: 1.2696 - mean_squared_error: 3.0037\n",
            "Epoch 20: val_loss improved from 2.89501 to 2.88399, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.0007 - mean_absolute_error: 1.2678 - mean_squared_error: 3.0007 - val_loss: 2.8840 - val_mean_absolute_error: 1.2438 - val_mean_squared_error: 2.8840\n",
            "Epoch 21/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.9934 - mean_absolute_error: 1.2670 - mean_squared_error: 2.9934\n",
            "Epoch 21: val_loss improved from 2.88399 to 2.87946, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9941 - mean_absolute_error: 1.2671 - mean_squared_error: 2.9941 - val_loss: 2.8795 - val_mean_absolute_error: 1.2452 - val_mean_squared_error: 2.8795\n",
            "Epoch 22/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.9454 - mean_absolute_error: 1.2567 - mean_squared_error: 2.9454\n",
            "Epoch 22: val_loss improved from 2.87946 to 2.87802, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9852 - mean_absolute_error: 1.2672 - mean_squared_error: 2.9852 - val_loss: 2.8780 - val_mean_absolute_error: 1.2463 - val_mean_squared_error: 2.8780\n",
            "Epoch 23/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.9979 - mean_absolute_error: 1.2697 - mean_squared_error: 2.9979\n",
            "Epoch 23: val_loss improved from 2.87802 to 2.87134, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9793 - mean_absolute_error: 1.2659 - mean_squared_error: 2.9793 - val_loss: 2.8713 - val_mean_absolute_error: 1.2463 - val_mean_squared_error: 2.8713\n",
            "Epoch 24/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.9837 - mean_absolute_error: 1.2687 - mean_squared_error: 2.9837\n",
            "Epoch 24: val_loss improved from 2.87134 to 2.87010, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.9735 - mean_absolute_error: 1.2665 - mean_squared_error: 2.9735 - val_loss: 2.8701 - val_mean_absolute_error: 1.2462 - val_mean_squared_error: 2.8701\n",
            "Epoch 25/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.9519 - mean_absolute_error: 1.2627 - mean_squared_error: 2.9519\n",
            "Epoch 25: val_loss improved from 2.87010 to 2.86525, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.9675 - mean_absolute_error: 1.2665 - mean_squared_error: 2.9675 - val_loss: 2.8653 - val_mean_absolute_error: 1.2443 - val_mean_squared_error: 2.8653\n",
            "Epoch 26/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.9705 - mean_absolute_error: 1.2660 - mean_squared_error: 2.9705\n",
            "Epoch 26: val_loss improved from 2.86525 to 2.85816, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.9593 - mean_absolute_error: 1.2631 - mean_squared_error: 2.9593 - val_loss: 2.8582 - val_mean_absolute_error: 1.2415 - val_mean_squared_error: 2.8582\n",
            "Epoch 27/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.9776 - mean_absolute_error: 1.2659 - mean_squared_error: 2.9776\n",
            "Epoch 27: val_loss did not improve from 2.85816\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.9521 - mean_absolute_error: 1.2598 - mean_squared_error: 2.9521 - val_loss: 2.8610 - val_mean_absolute_error: 1.2460 - val_mean_squared_error: 2.8610\n",
            "Epoch 28/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.9477 - mean_absolute_error: 1.2591 - mean_squared_error: 2.9477\n",
            "Epoch 28: val_loss improved from 2.85816 to 2.84957, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.9477 - mean_absolute_error: 1.2591 - mean_squared_error: 2.9477 - val_loss: 2.8496 - val_mean_absolute_error: 1.2401 - val_mean_squared_error: 2.8496\n",
            "Epoch 29/1000\n",
            "217/245 [=========================>....] - ETA: 0s - loss: 2.9213 - mean_absolute_error: 1.2556 - mean_squared_error: 2.9213\n",
            "Epoch 29: val_loss improved from 2.84957 to 2.84479, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.9411 - mean_absolute_error: 1.2604 - mean_squared_error: 2.9411 - val_loss: 2.8448 - val_mean_absolute_error: 1.2390 - val_mean_squared_error: 2.8448\n",
            "Epoch 30/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.9361 - mean_absolute_error: 1.2568 - mean_squared_error: 2.9361\n",
            "Epoch 30: val_loss improved from 2.84479 to 2.84121, saving model to best_model9.h5\n",
            "245/245 [==============================] - 2s 8ms/step - loss: 2.9338 - mean_absolute_error: 1.2557 - mean_squared_error: 2.9338 - val_loss: 2.8412 - val_mean_absolute_error: 1.2414 - val_mean_squared_error: 2.8412\n",
            "Epoch 31/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.9314 - mean_absolute_error: 1.2566 - mean_squared_error: 2.9314\n",
            "Epoch 31: val_loss improved from 2.84121 to 2.83637, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.9278 - mean_absolute_error: 1.2561 - mean_squared_error: 2.9278 - val_loss: 2.8364 - val_mean_absolute_error: 1.2397 - val_mean_squared_error: 2.8364\n",
            "Epoch 32/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.9210 - mean_absolute_error: 1.2537 - mean_squared_error: 2.9210\n",
            "Epoch 32: val_loss improved from 2.83637 to 2.83014, saving model to best_model9.h5\n",
            "245/245 [==============================] - 2s 8ms/step - loss: 2.9203 - mean_absolute_error: 1.2543 - mean_squared_error: 2.9203 - val_loss: 2.8301 - val_mean_absolute_error: 1.2376 - val_mean_squared_error: 2.8301\n",
            "Epoch 33/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.9119 - mean_absolute_error: 1.2538 - mean_squared_error: 2.9119\n",
            "Epoch 33: val_loss improved from 2.83014 to 2.82440, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.9134 - mean_absolute_error: 1.2538 - mean_squared_error: 2.9134 - val_loss: 2.8244 - val_mean_absolute_error: 1.2356 - val_mean_squared_error: 2.8244\n",
            "Epoch 34/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.8914 - mean_absolute_error: 1.2461 - mean_squared_error: 2.8914\n",
            "Epoch 34: val_loss improved from 2.82440 to 2.82277, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.9064 - mean_absolute_error: 1.2492 - mean_squared_error: 2.9064 - val_loss: 2.8228 - val_mean_absolute_error: 1.2378 - val_mean_squared_error: 2.8228\n",
            "Epoch 35/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.9129 - mean_absolute_error: 1.2531 - mean_squared_error: 2.9129\n",
            "Epoch 35: val_loss improved from 2.82277 to 2.81837, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.8985 - mean_absolute_error: 1.2499 - mean_squared_error: 2.8985 - val_loss: 2.8184 - val_mean_absolute_error: 1.2373 - val_mean_squared_error: 2.8184\n",
            "Epoch 36/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.9233 - mean_absolute_error: 1.2520 - mean_squared_error: 2.9233\n",
            "Epoch 36: val_loss improved from 2.81837 to 2.80849, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.8908 - mean_absolute_error: 1.2479 - mean_squared_error: 2.8908 - val_loss: 2.8085 - val_mean_absolute_error: 1.2336 - val_mean_squared_error: 2.8085\n",
            "Epoch 37/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.8777 - mean_absolute_error: 1.2413 - mean_squared_error: 2.8777\n",
            "Epoch 37: val_loss improved from 2.80849 to 2.80227, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 6ms/step - loss: 2.8832 - mean_absolute_error: 1.2425 - mean_squared_error: 2.8832 - val_loss: 2.8023 - val_mean_absolute_error: 1.2319 - val_mean_squared_error: 2.8023\n",
            "Epoch 38/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.8847 - mean_absolute_error: 1.2429 - mean_squared_error: 2.8847\n",
            "Epoch 38: val_loss improved from 2.80227 to 2.79853, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.8749 - mean_absolute_error: 1.2422 - mean_squared_error: 2.8749 - val_loss: 2.7985 - val_mean_absolute_error: 1.2340 - val_mean_squared_error: 2.7985\n",
            "Epoch 39/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.8670 - mean_absolute_error: 1.2444 - mean_squared_error: 2.8670\n",
            "Epoch 39: val_loss improved from 2.79853 to 2.78913, saving model to best_model9.h5\n",
            "245/245 [==============================] - 2s 6ms/step - loss: 2.8670 - mean_absolute_error: 1.2444 - mean_squared_error: 2.8670 - val_loss: 2.7891 - val_mean_absolute_error: 1.2277 - val_mean_squared_error: 2.7891\n",
            "Epoch 40/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.8723 - mean_absolute_error: 1.2420 - mean_squared_error: 2.8723\n",
            "Epoch 40: val_loss improved from 2.78913 to 2.78296, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8589 - mean_absolute_error: 1.2389 - mean_squared_error: 2.8589 - val_loss: 2.7830 - val_mean_absolute_error: 1.2291 - val_mean_squared_error: 2.7830\n",
            "Epoch 41/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.8559 - mean_absolute_error: 1.2384 - mean_squared_error: 2.8559\n",
            "Epoch 41: val_loss improved from 2.78296 to 2.77593, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8515 - mean_absolute_error: 1.2375 - mean_squared_error: 2.8515 - val_loss: 2.7759 - val_mean_absolute_error: 1.2267 - val_mean_squared_error: 2.7759\n",
            "Epoch 42/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.8686 - mean_absolute_error: 1.2430 - mean_squared_error: 2.8686\n",
            "Epoch 42: val_loss improved from 2.77593 to 2.76926, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8410 - mean_absolute_error: 1.2363 - mean_squared_error: 2.8410 - val_loss: 2.7693 - val_mean_absolute_error: 1.2242 - val_mean_squared_error: 2.7693\n",
            "Epoch 43/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 2.8663 - mean_absolute_error: 1.2379 - mean_squared_error: 2.8663\n",
            "Epoch 43: val_loss improved from 2.76926 to 2.76236, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8333 - mean_absolute_error: 1.2327 - mean_squared_error: 2.8333 - val_loss: 2.7624 - val_mean_absolute_error: 1.2229 - val_mean_squared_error: 2.7624\n",
            "Epoch 44/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.8549 - mean_absolute_error: 1.2367 - mean_squared_error: 2.8549\n",
            "Epoch 44: val_loss improved from 2.76236 to 2.75711, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8222 - mean_absolute_error: 1.2302 - mean_squared_error: 2.8222 - val_loss: 2.7571 - val_mean_absolute_error: 1.2232 - val_mean_squared_error: 2.7571\n",
            "Epoch 45/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.8209 - mean_absolute_error: 1.2304 - mean_squared_error: 2.8209\n",
            "Epoch 45: val_loss improved from 2.75711 to 2.74674, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.8133 - mean_absolute_error: 1.2291 - mean_squared_error: 2.8133 - val_loss: 2.7467 - val_mean_absolute_error: 1.2174 - val_mean_squared_error: 2.7467\n",
            "Epoch 46/1000\n",
            "216/245 [=========================>....] - ETA: 0s - loss: 2.7768 - mean_absolute_error: 1.2212 - mean_squared_error: 2.7768\n",
            "Epoch 46: val_loss improved from 2.74674 to 2.74044, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8050 - mean_absolute_error: 1.2236 - mean_squared_error: 2.8050 - val_loss: 2.7404 - val_mean_absolute_error: 1.2171 - val_mean_squared_error: 2.7404\n",
            "Epoch 47/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.8193 - mean_absolute_error: 1.2303 - mean_squared_error: 2.8193\n",
            "Epoch 47: val_loss improved from 2.74044 to 2.73326, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.7951 - mean_absolute_error: 1.2247 - mean_squared_error: 2.7951 - val_loss: 2.7333 - val_mean_absolute_error: 1.2152 - val_mean_squared_error: 2.7333\n",
            "Epoch 48/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.7940 - mean_absolute_error: 1.2196 - mean_squared_error: 2.7940\n",
            "Epoch 48: val_loss improved from 2.73326 to 2.72691, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.7861 - mean_absolute_error: 1.2188 - mean_squared_error: 2.7861 - val_loss: 2.7269 - val_mean_absolute_error: 1.2120 - val_mean_squared_error: 2.7269\n",
            "Epoch 49/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.7738 - mean_absolute_error: 1.2170 - mean_squared_error: 2.7738\n",
            "Epoch 49: val_loss improved from 2.72691 to 2.71888, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7768 - mean_absolute_error: 1.2189 - mean_squared_error: 2.7768 - val_loss: 2.7189 - val_mean_absolute_error: 1.2109 - val_mean_squared_error: 2.7189\n",
            "Epoch 50/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.7828 - mean_absolute_error: 1.2161 - mean_squared_error: 2.7828\n",
            "Epoch 50: val_loss improved from 2.71888 to 2.71236, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7678 - mean_absolute_error: 1.2133 - mean_squared_error: 2.7678 - val_loss: 2.7124 - val_mean_absolute_error: 1.2096 - val_mean_squared_error: 2.7124\n",
            "Epoch 51/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.7344 - mean_absolute_error: 1.2074 - mean_squared_error: 2.7344\n",
            "Epoch 51: val_loss improved from 2.71236 to 2.70356, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.7586 - mean_absolute_error: 1.2123 - mean_squared_error: 2.7586 - val_loss: 2.7036 - val_mean_absolute_error: 1.2043 - val_mean_squared_error: 2.7036\n",
            "Epoch 52/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.7231 - mean_absolute_error: 1.2063 - mean_squared_error: 2.7231\n",
            "Epoch 52: val_loss improved from 2.70356 to 2.69675, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7488 - mean_absolute_error: 1.2094 - mean_squared_error: 2.7488 - val_loss: 2.6967 - val_mean_absolute_error: 1.2036 - val_mean_squared_error: 2.6967\n",
            "Epoch 53/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.7023 - mean_absolute_error: 1.1990 - mean_squared_error: 2.7023\n",
            "Epoch 53: val_loss improved from 2.69675 to 2.68854, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7412 - mean_absolute_error: 1.2091 - mean_squared_error: 2.7412 - val_loss: 2.6885 - val_mean_absolute_error: 1.2007 - val_mean_squared_error: 2.6885\n",
            "Epoch 54/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.7253 - mean_absolute_error: 1.2023 - mean_squared_error: 2.7253\n",
            "Epoch 54: val_loss improved from 2.68854 to 2.68280, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7332 - mean_absolute_error: 1.2046 - mean_squared_error: 2.7332 - val_loss: 2.6828 - val_mean_absolute_error: 1.1993 - val_mean_squared_error: 2.6828\n",
            "Epoch 55/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 2.7409 - mean_absolute_error: 1.2021 - mean_squared_error: 2.7409\n",
            "Epoch 55: val_loss improved from 2.68280 to 2.67642, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7242 - mean_absolute_error: 1.2024 - mean_squared_error: 2.7242 - val_loss: 2.6764 - val_mean_absolute_error: 1.1982 - val_mean_squared_error: 2.6764\n",
            "Epoch 56/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.7373 - mean_absolute_error: 1.2039 - mean_squared_error: 2.7373\n",
            "Epoch 56: val_loss improved from 2.67642 to 2.66892, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.7158 - mean_absolute_error: 1.2002 - mean_squared_error: 2.7158 - val_loss: 2.6689 - val_mean_absolute_error: 1.1958 - val_mean_squared_error: 2.6689\n",
            "Epoch 57/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.7108 - mean_absolute_error: 1.1953 - mean_squared_error: 2.7108\n",
            "Epoch 57: val_loss improved from 2.66892 to 2.66231, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7085 - mean_absolute_error: 1.1968 - mean_squared_error: 2.7085 - val_loss: 2.6623 - val_mean_absolute_error: 1.1935 - val_mean_squared_error: 2.6623\n",
            "Epoch 58/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.7069 - mean_absolute_error: 1.1959 - mean_squared_error: 2.7069\n",
            "Epoch 58: val_loss improved from 2.66231 to 2.65781, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.7004 - mean_absolute_error: 1.1947 - mean_squared_error: 2.7004 - val_loss: 2.6578 - val_mean_absolute_error: 1.1941 - val_mean_squared_error: 2.6578\n",
            "Epoch 59/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.6563 - mean_absolute_error: 1.1846 - mean_squared_error: 2.6563\n",
            "Epoch 59: val_loss improved from 2.65781 to 2.65090, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.6929 - mean_absolute_error: 1.1922 - mean_squared_error: 2.6929 - val_loss: 2.6509 - val_mean_absolute_error: 1.1880 - val_mean_squared_error: 2.6509\n",
            "Epoch 60/1000\n",
            "217/245 [=========================>....] - ETA: 0s - loss: 2.7011 - mean_absolute_error: 1.1977 - mean_squared_error: 2.7011\n",
            "Epoch 60: val_loss improved from 2.65090 to 2.64291, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6863 - mean_absolute_error: 1.1919 - mean_squared_error: 2.6863 - val_loss: 2.6429 - val_mean_absolute_error: 1.1889 - val_mean_squared_error: 2.6429\n",
            "Epoch 61/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.6864 - mean_absolute_error: 1.1929 - mean_squared_error: 2.6864\n",
            "Epoch 61: val_loss improved from 2.64291 to 2.63783, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 2.6788 - mean_absolute_error: 1.1911 - mean_squared_error: 2.6788 - val_loss: 2.6378 - val_mean_absolute_error: 1.1833 - val_mean_squared_error: 2.6378\n",
            "Epoch 62/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.6833 - mean_absolute_error: 1.1890 - mean_squared_error: 2.6833\n",
            "Epoch 62: val_loss improved from 2.63783 to 2.63261, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6730 - mean_absolute_error: 1.1874 - mean_squared_error: 2.6730 - val_loss: 2.6326 - val_mean_absolute_error: 1.1794 - val_mean_squared_error: 2.6326\n",
            "Epoch 63/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.6689 - mean_absolute_error: 1.1868 - mean_squared_error: 2.6689\n",
            "Epoch 63: val_loss improved from 2.63261 to 2.62629, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6664 - mean_absolute_error: 1.1845 - mean_squared_error: 2.6664 - val_loss: 2.6263 - val_mean_absolute_error: 1.1798 - val_mean_squared_error: 2.6263\n",
            "Epoch 64/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.6571 - mean_absolute_error: 1.1812 - mean_squared_error: 2.6571\n",
            "Epoch 64: val_loss improved from 2.62629 to 2.62142, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6590 - mean_absolute_error: 1.1816 - mean_squared_error: 2.6590 - val_loss: 2.6214 - val_mean_absolute_error: 1.1783 - val_mean_squared_error: 2.6214\n",
            "Epoch 65/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.6473 - mean_absolute_error: 1.1788 - mean_squared_error: 2.6473\n",
            "Epoch 65: val_loss improved from 2.62142 to 2.61642, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6542 - mean_absolute_error: 1.1808 - mean_squared_error: 2.6542 - val_loss: 2.6164 - val_mean_absolute_error: 1.1755 - val_mean_squared_error: 2.6164\n",
            "Epoch 66/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.6498 - mean_absolute_error: 1.1797 - mean_squared_error: 2.6498\n",
            "Epoch 66: val_loss improved from 2.61642 to 2.61278, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6482 - mean_absolute_error: 1.1792 - mean_squared_error: 2.6482 - val_loss: 2.6128 - val_mean_absolute_error: 1.1737 - val_mean_squared_error: 2.6128\n",
            "Epoch 67/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.6336 - mean_absolute_error: 1.1762 - mean_squared_error: 2.6336\n",
            "Epoch 67: val_loss did not improve from 2.61278\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6426 - mean_absolute_error: 1.1771 - mean_squared_error: 2.6426 - val_loss: 2.6137 - val_mean_absolute_error: 1.1761 - val_mean_squared_error: 2.6137\n",
            "Epoch 68/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.6458 - mean_absolute_error: 1.1737 - mean_squared_error: 2.6458\n",
            "Epoch 68: val_loss improved from 2.61278 to 2.60306, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6377 - mean_absolute_error: 1.1736 - mean_squared_error: 2.6377 - val_loss: 2.6031 - val_mean_absolute_error: 1.1721 - val_mean_squared_error: 2.6031\n",
            "Epoch 69/1000\n",
            "218/245 [=========================>....] - ETA: 0s - loss: 2.5998 - mean_absolute_error: 1.1651 - mean_squared_error: 2.5998\n",
            "Epoch 69: val_loss improved from 2.60306 to 2.59729, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6320 - mean_absolute_error: 1.1737 - mean_squared_error: 2.6320 - val_loss: 2.5973 - val_mean_absolute_error: 1.1711 - val_mean_squared_error: 2.5973\n",
            "Epoch 70/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.6410 - mean_absolute_error: 1.1767 - mean_squared_error: 2.6410\n",
            "Epoch 70: val_loss improved from 2.59729 to 2.59402, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6275 - mean_absolute_error: 1.1725 - mean_squared_error: 2.6275 - val_loss: 2.5940 - val_mean_absolute_error: 1.1681 - val_mean_squared_error: 2.5940\n",
            "Epoch 71/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.6262 - mean_absolute_error: 1.1720 - mean_squared_error: 2.6262\n",
            "Epoch 71: val_loss improved from 2.59402 to 2.59092, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6241 - mean_absolute_error: 1.1724 - mean_squared_error: 2.6241 - val_loss: 2.5909 - val_mean_absolute_error: 1.1662 - val_mean_squared_error: 2.5909\n",
            "Epoch 72/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.6101 - mean_absolute_error: 1.1685 - mean_squared_error: 2.6101\n",
            "Epoch 72: val_loss improved from 2.59092 to 2.58865, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6183 - mean_absolute_error: 1.1698 - mean_squared_error: 2.6183 - val_loss: 2.5887 - val_mean_absolute_error: 1.1646 - val_mean_squared_error: 2.5887\n",
            "Epoch 73/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.5762 - mean_absolute_error: 1.1613 - mean_squared_error: 2.5762\n",
            "Epoch 73: val_loss improved from 2.58865 to 2.58365, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6135 - mean_absolute_error: 1.1679 - mean_squared_error: 2.6135 - val_loss: 2.5836 - val_mean_absolute_error: 1.1623 - val_mean_squared_error: 2.5836\n",
            "Epoch 74/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.5949 - mean_absolute_error: 1.1621 - mean_squared_error: 2.5949\n",
            "Epoch 74: val_loss improved from 2.58365 to 2.57991, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6095 - mean_absolute_error: 1.1654 - mean_squared_error: 2.6095 - val_loss: 2.5799 - val_mean_absolute_error: 1.1631 - val_mean_squared_error: 2.5799\n",
            "Epoch 75/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.5902 - mean_absolute_error: 1.1651 - mean_squared_error: 2.5902\n",
            "Epoch 75: val_loss improved from 2.57991 to 2.57684, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6046 - mean_absolute_error: 1.1683 - mean_squared_error: 2.6046 - val_loss: 2.5768 - val_mean_absolute_error: 1.1604 - val_mean_squared_error: 2.5768\n",
            "Epoch 76/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.6168 - mean_absolute_error: 1.1669 - mean_squared_error: 2.6168\n",
            "Epoch 76: val_loss improved from 2.57684 to 2.57250, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6013 - mean_absolute_error: 1.1636 - mean_squared_error: 2.6013 - val_loss: 2.5725 - val_mean_absolute_error: 1.1595 - val_mean_squared_error: 2.5725\n",
            "Epoch 77/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 2.6019 - mean_absolute_error: 1.1655 - mean_squared_error: 2.6019\n",
            "Epoch 77: val_loss improved from 2.57250 to 2.56915, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5970 - mean_absolute_error: 1.1636 - mean_squared_error: 2.5970 - val_loss: 2.5691 - val_mean_absolute_error: 1.1594 - val_mean_squared_error: 2.5691\n",
            "Epoch 78/1000\n",
            "217/245 [=========================>....] - ETA: 0s - loss: 2.5393 - mean_absolute_error: 1.1565 - mean_squared_error: 2.5393\n",
            "Epoch 78: val_loss improved from 2.56915 to 2.56708, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5941 - mean_absolute_error: 1.1634 - mean_squared_error: 2.5941 - val_loss: 2.5671 - val_mean_absolute_error: 1.1572 - val_mean_squared_error: 2.5671\n",
            "Epoch 79/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.6117 - mean_absolute_error: 1.1671 - mean_squared_error: 2.6117\n",
            "Epoch 79: val_loss improved from 2.56708 to 2.56163, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5889 - mean_absolute_error: 1.1625 - mean_squared_error: 2.5889 - val_loss: 2.5616 - val_mean_absolute_error: 1.1559 - val_mean_squared_error: 2.5616\n",
            "Epoch 80/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.5897 - mean_absolute_error: 1.1600 - mean_squared_error: 2.5897\n",
            "Epoch 80: val_loss improved from 2.56163 to 2.55812, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5850 - mean_absolute_error: 1.1595 - mean_squared_error: 2.5850 - val_loss: 2.5581 - val_mean_absolute_error: 1.1547 - val_mean_squared_error: 2.5581\n",
            "Epoch 81/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.5712 - mean_absolute_error: 1.1588 - mean_squared_error: 2.5712\n",
            "Epoch 81: val_loss improved from 2.55812 to 2.55717, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5810 - mean_absolute_error: 1.1593 - mean_squared_error: 2.5810 - val_loss: 2.5572 - val_mean_absolute_error: 1.1538 - val_mean_squared_error: 2.5572\n",
            "Epoch 82/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.5726 - mean_absolute_error: 1.1579 - mean_squared_error: 2.5726\n",
            "Epoch 82: val_loss improved from 2.55717 to 2.55117, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5785 - mean_absolute_error: 1.1579 - mean_squared_error: 2.5785 - val_loss: 2.5512 - val_mean_absolute_error: 1.1503 - val_mean_squared_error: 2.5512\n",
            "Epoch 83/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 2.5911 - mean_absolute_error: 1.1570 - mean_squared_error: 2.5911\n",
            "Epoch 83: val_loss improved from 2.55117 to 2.54924, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5736 - mean_absolute_error: 1.1555 - mean_squared_error: 2.5736 - val_loss: 2.5492 - val_mean_absolute_error: 1.1533 - val_mean_squared_error: 2.5492\n",
            "Epoch 84/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.5418 - mean_absolute_error: 1.1517 - mean_squared_error: 2.5418\n",
            "Epoch 84: val_loss improved from 2.54924 to 2.54358, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5688 - mean_absolute_error: 1.1567 - mean_squared_error: 2.5688 - val_loss: 2.5436 - val_mean_absolute_error: 1.1485 - val_mean_squared_error: 2.5436\n",
            "Epoch 85/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.5693 - mean_absolute_error: 1.1551 - mean_squared_error: 2.5693\n",
            "Epoch 85: val_loss improved from 2.54358 to 2.53911, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5643 - mean_absolute_error: 1.1539 - mean_squared_error: 2.5643 - val_loss: 2.5391 - val_mean_absolute_error: 1.1481 - val_mean_squared_error: 2.5391\n",
            "Epoch 86/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.5640 - mean_absolute_error: 1.1557 - mean_squared_error: 2.5640\n",
            "Epoch 86: val_loss improved from 2.53911 to 2.53622, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5599 - mean_absolute_error: 1.1554 - mean_squared_error: 2.5599 - val_loss: 2.5362 - val_mean_absolute_error: 1.1471 - val_mean_squared_error: 2.5362\n",
            "Epoch 87/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.5726 - mean_absolute_error: 1.1550 - mean_squared_error: 2.5726\n",
            "Epoch 87: val_loss improved from 2.53622 to 2.53167, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5550 - mean_absolute_error: 1.1519 - mean_squared_error: 2.5550 - val_loss: 2.5317 - val_mean_absolute_error: 1.1464 - val_mean_squared_error: 2.5317\n",
            "Epoch 88/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.5385 - mean_absolute_error: 1.1448 - mean_squared_error: 2.5385\n",
            "Epoch 88: val_loss improved from 2.53167 to 2.52676, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5502 - mean_absolute_error: 1.1479 - mean_squared_error: 2.5502 - val_loss: 2.5268 - val_mean_absolute_error: 1.1459 - val_mean_squared_error: 2.5268\n",
            "Epoch 89/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.5274 - mean_absolute_error: 1.1482 - mean_squared_error: 2.5274\n",
            "Epoch 89: val_loss improved from 2.52676 to 2.52148, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5439 - mean_absolute_error: 1.1511 - mean_squared_error: 2.5439 - val_loss: 2.5215 - val_mean_absolute_error: 1.1435 - val_mean_squared_error: 2.5215\n",
            "Epoch 90/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.5324 - mean_absolute_error: 1.1462 - mean_squared_error: 2.5324\n",
            "Epoch 90: val_loss improved from 2.52148 to 2.51434, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5369 - mean_absolute_error: 1.1467 - mean_squared_error: 2.5369 - val_loss: 2.5143 - val_mean_absolute_error: 1.1446 - val_mean_squared_error: 2.5143\n",
            "Epoch 91/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.5208 - mean_absolute_error: 1.1445 - mean_squared_error: 2.5208\n",
            "Epoch 91: val_loss improved from 2.51434 to 2.50818, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5308 - mean_absolute_error: 1.1464 - mean_squared_error: 2.5308 - val_loss: 2.5082 - val_mean_absolute_error: 1.1398 - val_mean_squared_error: 2.5082\n",
            "Epoch 92/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.5280 - mean_absolute_error: 1.1476 - mean_squared_error: 2.5280\n",
            "Epoch 92: val_loss improved from 2.50818 to 2.50391, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5223 - mean_absolute_error: 1.1471 - mean_squared_error: 2.5223 - val_loss: 2.5039 - val_mean_absolute_error: 1.1360 - val_mean_squared_error: 2.5039\n",
            "Epoch 93/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.5236 - mean_absolute_error: 1.1448 - mean_squared_error: 2.5236\n",
            "Epoch 93: val_loss improved from 2.50391 to 2.49214, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5154 - mean_absolute_error: 1.1423 - mean_squared_error: 2.5154 - val_loss: 2.4921 - val_mean_absolute_error: 1.1337 - val_mean_squared_error: 2.4921\n",
            "Epoch 94/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.5000 - mean_absolute_error: 1.1387 - mean_squared_error: 2.5000\n",
            "Epoch 94: val_loss improved from 2.49214 to 2.48610, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5060 - mean_absolute_error: 1.1400 - mean_squared_error: 2.5060 - val_loss: 2.4861 - val_mean_absolute_error: 1.1307 - val_mean_squared_error: 2.4861\n",
            "Epoch 95/1000\n",
            "218/245 [=========================>....] - ETA: 0s - loss: 2.4919 - mean_absolute_error: 1.1355 - mean_squared_error: 2.4919\n",
            "Epoch 95: val_loss improved from 2.48610 to 2.47884, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4962 - mean_absolute_error: 1.1379 - mean_squared_error: 2.4962 - val_loss: 2.4788 - val_mean_absolute_error: 1.1276 - val_mean_squared_error: 2.4788\n",
            "Epoch 96/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.4778 - mean_absolute_error: 1.1290 - mean_squared_error: 2.4778\n",
            "Epoch 96: val_loss improved from 2.47884 to 2.47003, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4883 - mean_absolute_error: 1.1322 - mean_squared_error: 2.4883 - val_loss: 2.4700 - val_mean_absolute_error: 1.1297 - val_mean_squared_error: 2.4700\n",
            "Epoch 97/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.4527 - mean_absolute_error: 1.1279 - mean_squared_error: 2.4527\n",
            "Epoch 97: val_loss improved from 2.47003 to 2.45805, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4759 - mean_absolute_error: 1.1321 - mean_squared_error: 2.4759 - val_loss: 2.4581 - val_mean_absolute_error: 1.1233 - val_mean_squared_error: 2.4581\n",
            "Epoch 98/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.4804 - mean_absolute_error: 1.1297 - mean_squared_error: 2.4804\n",
            "Epoch 98: val_loss improved from 2.45805 to 2.44621, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4651 - mean_absolute_error: 1.1273 - mean_squared_error: 2.4651 - val_loss: 2.4462 - val_mean_absolute_error: 1.1243 - val_mean_squared_error: 2.4462\n",
            "Epoch 99/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.4554 - mean_absolute_error: 1.1243 - mean_squared_error: 2.4554\n",
            "Epoch 99: val_loss improved from 2.44621 to 2.43670, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4526 - mean_absolute_error: 1.1232 - mean_squared_error: 2.4526 - val_loss: 2.4367 - val_mean_absolute_error: 1.1213 - val_mean_squared_error: 2.4367\n",
            "Epoch 100/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.4495 - mean_absolute_error: 1.1247 - mean_squared_error: 2.4495\n",
            "Epoch 100: val_loss improved from 2.43670 to 2.42685, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4400 - mean_absolute_error: 1.1250 - mean_squared_error: 2.4400 - val_loss: 2.4269 - val_mean_absolute_error: 1.1154 - val_mean_squared_error: 2.4269\n",
            "Epoch 101/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.4252 - mean_absolute_error: 1.1189 - mean_squared_error: 2.4252\n",
            "Epoch 101: val_loss improved from 2.42685 to 2.40963, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4283 - mean_absolute_error: 1.1194 - mean_squared_error: 2.4283 - val_loss: 2.4096 - val_mean_absolute_error: 1.1102 - val_mean_squared_error: 2.4096\n",
            "Epoch 102/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 2.4327 - mean_absolute_error: 1.1200 - mean_squared_error: 2.4327\n",
            "Epoch 102: val_loss improved from 2.40963 to 2.39792, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4160 - mean_absolute_error: 1.1141 - mean_squared_error: 2.4160 - val_loss: 2.3979 - val_mean_absolute_error: 1.1071 - val_mean_squared_error: 2.3979\n",
            "Epoch 103/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.3821 - mean_absolute_error: 1.1087 - mean_squared_error: 2.3821\n",
            "Epoch 103: val_loss improved from 2.39792 to 2.39038, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4028 - mean_absolute_error: 1.1118 - mean_squared_error: 2.4028 - val_loss: 2.3904 - val_mean_absolute_error: 1.1053 - val_mean_squared_error: 2.3904\n",
            "Epoch 104/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.4106 - mean_absolute_error: 1.1097 - mean_squared_error: 2.4106\n",
            "Epoch 104: val_loss improved from 2.39038 to 2.37462, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3884 - mean_absolute_error: 1.1071 - mean_squared_error: 2.3884 - val_loss: 2.3746 - val_mean_absolute_error: 1.1043 - val_mean_squared_error: 2.3746\n",
            "Epoch 105/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.3633 - mean_absolute_error: 1.1007 - mean_squared_error: 2.3633\n",
            "Epoch 105: val_loss improved from 2.37462 to 2.36455, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3761 - mean_absolute_error: 1.1037 - mean_squared_error: 2.3761 - val_loss: 2.3646 - val_mean_absolute_error: 1.1013 - val_mean_squared_error: 2.3646\n",
            "Epoch 106/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.3682 - mean_absolute_error: 1.1025 - mean_squared_error: 2.3682\n",
            "Epoch 106: val_loss improved from 2.36455 to 2.35083, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3627 - mean_absolute_error: 1.1014 - mean_squared_error: 2.3627 - val_loss: 2.3508 - val_mean_absolute_error: 1.0956 - val_mean_squared_error: 2.3508\n",
            "Epoch 107/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.3482 - mean_absolute_error: 1.0948 - mean_squared_error: 2.3482\n",
            "Epoch 107: val_loss improved from 2.35083 to 2.33696, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3492 - mean_absolute_error: 1.0956 - mean_squared_error: 2.3492 - val_loss: 2.3370 - val_mean_absolute_error: 1.0915 - val_mean_squared_error: 2.3370\n",
            "Epoch 108/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.3423 - mean_absolute_error: 1.0949 - mean_squared_error: 2.3423\n",
            "Epoch 108: val_loss improved from 2.33696 to 2.32884, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3350 - mean_absolute_error: 1.0932 - mean_squared_error: 2.3350 - val_loss: 2.3288 - val_mean_absolute_error: 1.0864 - val_mean_squared_error: 2.3288\n",
            "Epoch 109/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.3142 - mean_absolute_error: 1.0852 - mean_squared_error: 2.3142\n",
            "Epoch 109: val_loss improved from 2.32884 to 2.31194, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3217 - mean_absolute_error: 1.0865 - mean_squared_error: 2.3217 - val_loss: 2.3119 - val_mean_absolute_error: 1.0821 - val_mean_squared_error: 2.3119\n",
            "Epoch 110/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.3028 - mean_absolute_error: 1.0861 - mean_squared_error: 2.3028\n",
            "Epoch 110: val_loss improved from 2.31194 to 2.30449, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3094 - mean_absolute_error: 1.0877 - mean_squared_error: 2.3094 - val_loss: 2.3045 - val_mean_absolute_error: 1.0764 - val_mean_squared_error: 2.3045\n",
            "Epoch 111/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.3015 - mean_absolute_error: 1.0794 - mean_squared_error: 2.3015\n",
            "Epoch 111: val_loss improved from 2.30449 to 2.29013, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2962 - mean_absolute_error: 1.0780 - mean_squared_error: 2.2962 - val_loss: 2.2901 - val_mean_absolute_error: 1.0779 - val_mean_squared_error: 2.2901\n",
            "Epoch 112/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.2679 - mean_absolute_error: 1.0773 - mean_squared_error: 2.2679\n",
            "Epoch 112: val_loss improved from 2.29013 to 2.28011, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2842 - mean_absolute_error: 1.0801 - mean_squared_error: 2.2842 - val_loss: 2.2801 - val_mean_absolute_error: 1.0699 - val_mean_squared_error: 2.2801\n",
            "Epoch 113/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.2798 - mean_absolute_error: 1.0729 - mean_squared_error: 2.2798\n",
            "Epoch 113: val_loss improved from 2.28011 to 2.26633, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2719 - mean_absolute_error: 1.0723 - mean_squared_error: 2.2719 - val_loss: 2.2663 - val_mean_absolute_error: 1.0659 - val_mean_squared_error: 2.2663\n",
            "Epoch 114/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.2485 - mean_absolute_error: 1.0661 - mean_squared_error: 2.2485\n",
            "Epoch 114: val_loss improved from 2.26633 to 2.25755, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2604 - mean_absolute_error: 1.0687 - mean_squared_error: 2.2604 - val_loss: 2.2575 - val_mean_absolute_error: 1.0624 - val_mean_squared_error: 2.2575\n",
            "Epoch 115/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.2531 - mean_absolute_error: 1.0680 - mean_squared_error: 2.2531\n",
            "Epoch 115: val_loss improved from 2.25755 to 2.24737, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2482 - mean_absolute_error: 1.0674 - mean_squared_error: 2.2482 - val_loss: 2.2474 - val_mean_absolute_error: 1.0592 - val_mean_squared_error: 2.2474\n",
            "Epoch 116/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.2245 - mean_absolute_error: 1.0530 - mean_squared_error: 2.2245\n",
            "Epoch 116: val_loss improved from 2.24737 to 2.23539, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2369 - mean_absolute_error: 1.0583 - mean_squared_error: 2.2369 - val_loss: 2.2354 - val_mean_absolute_error: 1.0560 - val_mean_squared_error: 2.2354\n",
            "Epoch 117/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 2.2733 - mean_absolute_error: 1.0703 - mean_squared_error: 2.2733\n",
            "Epoch 117: val_loss improved from 2.23539 to 2.22655, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2256 - mean_absolute_error: 1.0598 - mean_squared_error: 2.2256 - val_loss: 2.2266 - val_mean_absolute_error: 1.0546 - val_mean_squared_error: 2.2266\n",
            "Epoch 118/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.2152 - mean_absolute_error: 1.0531 - mean_squared_error: 2.2152\n",
            "Epoch 118: val_loss improved from 2.22655 to 2.21762, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2148 - mean_absolute_error: 1.0530 - mean_squared_error: 2.2148 - val_loss: 2.2176 - val_mean_absolute_error: 1.0510 - val_mean_squared_error: 2.2176\n",
            "Epoch 119/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.1897 - mean_absolute_error: 1.0489 - mean_squared_error: 2.1897\n",
            "Epoch 119: val_loss improved from 2.21762 to 2.20573, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2041 - mean_absolute_error: 1.0504 - mean_squared_error: 2.2041 - val_loss: 2.2057 - val_mean_absolute_error: 1.0459 - val_mean_squared_error: 2.2057\n",
            "Epoch 120/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 2.2211 - mean_absolute_error: 1.0559 - mean_squared_error: 2.2211\n",
            "Epoch 120: val_loss improved from 2.20573 to 2.19717, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1932 - mean_absolute_error: 1.0478 - mean_squared_error: 2.1932 - val_loss: 2.1972 - val_mean_absolute_error: 1.0445 - val_mean_squared_error: 2.1972\n",
            "Epoch 121/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.2018 - mean_absolute_error: 1.0490 - mean_squared_error: 2.2018\n",
            "Epoch 121: val_loss improved from 2.19717 to 2.19013, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1833 - mean_absolute_error: 1.0465 - mean_squared_error: 2.1833 - val_loss: 2.1901 - val_mean_absolute_error: 1.0416 - val_mean_squared_error: 2.1901\n",
            "Epoch 122/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.1778 - mean_absolute_error: 1.0419 - mean_squared_error: 2.1778\n",
            "Epoch 122: val_loss improved from 2.19013 to 2.17983, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1746 - mean_absolute_error: 1.0410 - mean_squared_error: 2.1746 - val_loss: 2.1798 - val_mean_absolute_error: 1.0356 - val_mean_squared_error: 2.1798\n",
            "Epoch 123/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.1760 - mean_absolute_error: 1.0403 - mean_squared_error: 2.1760\n",
            "Epoch 123: val_loss improved from 2.17983 to 2.17157, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1641 - mean_absolute_error: 1.0385 - mean_squared_error: 2.1641 - val_loss: 2.1716 - val_mean_absolute_error: 1.0331 - val_mean_squared_error: 2.1716\n",
            "Epoch 124/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.1639 - mean_absolute_error: 1.0346 - mean_squared_error: 2.1639\n",
            "Epoch 124: val_loss improved from 2.17157 to 2.16278, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1535 - mean_absolute_error: 1.0338 - mean_squared_error: 2.1535 - val_loss: 2.1628 - val_mean_absolute_error: 1.0297 - val_mean_squared_error: 2.1628\n",
            "Epoch 125/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.1202 - mean_absolute_error: 1.0222 - mean_squared_error: 2.1202\n",
            "Epoch 125: val_loss improved from 2.16278 to 2.15627, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1439 - mean_absolute_error: 1.0313 - mean_squared_error: 2.1439 - val_loss: 2.1563 - val_mean_absolute_error: 1.0269 - val_mean_squared_error: 2.1563\n",
            "Epoch 126/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.1371 - mean_absolute_error: 1.0291 - mean_squared_error: 2.1371\n",
            "Epoch 126: val_loss improved from 2.15627 to 2.14851, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1362 - mean_absolute_error: 1.0289 - mean_squared_error: 2.1362 - val_loss: 2.1485 - val_mean_absolute_error: 1.0239 - val_mean_squared_error: 2.1485\n",
            "Epoch 127/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.1270 - mean_absolute_error: 1.0242 - mean_squared_error: 2.1270\n",
            "Epoch 127: val_loss improved from 2.14851 to 2.13813, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1255 - mean_absolute_error: 1.0243 - mean_squared_error: 2.1255 - val_loss: 2.1381 - val_mean_absolute_error: 1.0206 - val_mean_squared_error: 2.1381\n",
            "Epoch 128/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.1233 - mean_absolute_error: 1.0240 - mean_squared_error: 2.1233\n",
            "Epoch 128: val_loss improved from 2.13813 to 2.13156, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1166 - mean_absolute_error: 1.0231 - mean_squared_error: 2.1166 - val_loss: 2.1316 - val_mean_absolute_error: 1.0165 - val_mean_squared_error: 2.1316\n",
            "Epoch 129/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.1103 - mean_absolute_error: 1.0210 - mean_squared_error: 2.1103\n",
            "Epoch 129: val_loss improved from 2.13156 to 2.12181, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1081 - mean_absolute_error: 1.0185 - mean_squared_error: 2.1081 - val_loss: 2.1218 - val_mean_absolute_error: 1.0136 - val_mean_squared_error: 2.1218\n",
            "Epoch 130/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.1082 - mean_absolute_error: 1.0190 - mean_squared_error: 2.1082\n",
            "Epoch 130: val_loss improved from 2.12181 to 2.11584, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0996 - mean_absolute_error: 1.0185 - mean_squared_error: 2.0996 - val_loss: 2.1158 - val_mean_absolute_error: 1.0118 - val_mean_squared_error: 2.1158\n",
            "Epoch 131/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.0934 - mean_absolute_error: 1.0166 - mean_squared_error: 2.0934\n",
            "Epoch 131: val_loss improved from 2.11584 to 2.10565, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0902 - mean_absolute_error: 1.0138 - mean_squared_error: 2.0902 - val_loss: 2.1056 - val_mean_absolute_error: 1.0090 - val_mean_squared_error: 2.1056\n",
            "Epoch 132/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.0762 - mean_absolute_error: 1.0102 - mean_squared_error: 2.0762\n",
            "Epoch 132: val_loss improved from 2.10565 to 2.09890, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 6ms/step - loss: 2.0815 - mean_absolute_error: 1.0118 - mean_squared_error: 2.0815 - val_loss: 2.0989 - val_mean_absolute_error: 1.0065 - val_mean_squared_error: 2.0989\n",
            "Epoch 133/1000\n",
            "218/245 [=========================>....] - ETA: 0s - loss: 2.0847 - mean_absolute_error: 1.0080 - mean_squared_error: 2.0847\n",
            "Epoch 133: val_loss improved from 2.09890 to 2.09243, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0716 - mean_absolute_error: 1.0077 - mean_squared_error: 2.0716 - val_loss: 2.0924 - val_mean_absolute_error: 1.0028 - val_mean_squared_error: 2.0924\n",
            "Epoch 134/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.0816 - mean_absolute_error: 1.0089 - mean_squared_error: 2.0816\n",
            "Epoch 134: val_loss improved from 2.09243 to 2.08197, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0625 - mean_absolute_error: 1.0042 - mean_squared_error: 2.0625 - val_loss: 2.0820 - val_mean_absolute_error: 1.0006 - val_mean_squared_error: 2.0820\n",
            "Epoch 135/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.0507 - mean_absolute_error: 0.9996 - mean_squared_error: 2.0507\n",
            "Epoch 135: val_loss improved from 2.08197 to 2.07370, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.0526 - mean_absolute_error: 1.0015 - mean_squared_error: 2.0526 - val_loss: 2.0737 - val_mean_absolute_error: 0.9985 - val_mean_squared_error: 2.0737\n",
            "Epoch 136/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.0691 - mean_absolute_error: 1.0082 - mean_squared_error: 2.0691\n",
            "Epoch 136: val_loss improved from 2.07370 to 2.06601, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0437 - mean_absolute_error: 1.0005 - mean_squared_error: 2.0437 - val_loss: 2.0660 - val_mean_absolute_error: 0.9949 - val_mean_squared_error: 2.0660\n",
            "Epoch 137/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 2.0286 - mean_absolute_error: 0.9936 - mean_squared_error: 2.0286\n",
            "Epoch 137: val_loss improved from 2.06601 to 2.05853, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0349 - mean_absolute_error: 0.9944 - mean_squared_error: 2.0349 - val_loss: 2.0585 - val_mean_absolute_error: 0.9932 - val_mean_squared_error: 2.0585\n",
            "Epoch 138/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.0287 - mean_absolute_error: 0.9943 - mean_squared_error: 2.0287\n",
            "Epoch 138: val_loss improved from 2.05853 to 2.05636, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0253 - mean_absolute_error: 0.9944 - mean_squared_error: 2.0253 - val_loss: 2.0564 - val_mean_absolute_error: 0.9919 - val_mean_squared_error: 2.0564\n",
            "Epoch 139/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.0150 - mean_absolute_error: 0.9902 - mean_squared_error: 2.0150\n",
            "Epoch 139: val_loss improved from 2.05636 to 2.04220, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0179 - mean_absolute_error: 0.9910 - mean_squared_error: 2.0179 - val_loss: 2.0422 - val_mean_absolute_error: 0.9852 - val_mean_squared_error: 2.0422\n",
            "Epoch 140/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.9996 - mean_absolute_error: 0.9836 - mean_squared_error: 1.9996\n",
            "Epoch 140: val_loss improved from 2.04220 to 2.03497, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0095 - mean_absolute_error: 0.9862 - mean_squared_error: 2.0095 - val_loss: 2.0350 - val_mean_absolute_error: 0.9831 - val_mean_squared_error: 2.0350\n",
            "Epoch 141/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.9976 - mean_absolute_error: 0.9796 - mean_squared_error: 1.9976\n",
            "Epoch 141: val_loss improved from 2.03497 to 2.02833, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0007 - mean_absolute_error: 0.9802 - mean_squared_error: 2.0007 - val_loss: 2.0283 - val_mean_absolute_error: 0.9805 - val_mean_squared_error: 2.0283\n",
            "Epoch 142/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.9824 - mean_absolute_error: 0.9759 - mean_squared_error: 1.9824\n",
            "Epoch 142: val_loss improved from 2.02833 to 2.02058, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9918 - mean_absolute_error: 0.9782 - mean_squared_error: 1.9918 - val_loss: 2.0206 - val_mean_absolute_error: 0.9782 - val_mean_squared_error: 2.0206\n",
            "Epoch 143/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.9742 - mean_absolute_error: 0.9732 - mean_squared_error: 1.9742\n",
            "Epoch 143: val_loss improved from 2.02058 to 2.01753, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 1.9834 - mean_absolute_error: 0.9755 - mean_squared_error: 1.9834 - val_loss: 2.0175 - val_mean_absolute_error: 0.9752 - val_mean_squared_error: 2.0175\n",
            "Epoch 144/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.9838 - mean_absolute_error: 0.9774 - mean_squared_error: 1.9838\n",
            "Epoch 144: val_loss improved from 2.01753 to 2.00892, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9777 - mean_absolute_error: 0.9769 - mean_squared_error: 1.9777 - val_loss: 2.0089 - val_mean_absolute_error: 0.9728 - val_mean_squared_error: 2.0089\n",
            "Epoch 145/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.9767 - mean_absolute_error: 0.9691 - mean_squared_error: 1.9767\n",
            "Epoch 145: val_loss improved from 2.00892 to 2.00372, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9705 - mean_absolute_error: 0.9670 - mean_squared_error: 1.9705 - val_loss: 2.0037 - val_mean_absolute_error: 0.9709 - val_mean_squared_error: 2.0037\n",
            "Epoch 146/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 1.9806 - mean_absolute_error: 0.9736 - mean_squared_error: 1.9806\n",
            "Epoch 146: val_loss improved from 2.00372 to 2.00000, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9641 - mean_absolute_error: 0.9669 - mean_squared_error: 1.9641 - val_loss: 2.0000 - val_mean_absolute_error: 0.9648 - val_mean_squared_error: 2.0000\n",
            "Epoch 147/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.9428 - mean_absolute_error: 0.9592 - mean_squared_error: 1.9428\n",
            "Epoch 147: val_loss improved from 2.00000 to 1.99267, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9594 - mean_absolute_error: 0.9643 - mean_squared_error: 1.9594 - val_loss: 1.9927 - val_mean_absolute_error: 0.9622 - val_mean_squared_error: 1.9927\n",
            "Epoch 148/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.9569 - mean_absolute_error: 0.9611 - mean_squared_error: 1.9569\n",
            "Epoch 148: val_loss improved from 1.99267 to 1.98802, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9530 - mean_absolute_error: 0.9603 - mean_squared_error: 1.9530 - val_loss: 1.9880 - val_mean_absolute_error: 0.9591 - val_mean_squared_error: 1.9880\n",
            "Epoch 149/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.9321 - mean_absolute_error: 0.9562 - mean_squared_error: 1.9321\n",
            "Epoch 149: val_loss improved from 1.98802 to 1.98435, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9492 - mean_absolute_error: 0.9596 - mean_squared_error: 1.9492 - val_loss: 1.9843 - val_mean_absolute_error: 0.9533 - val_mean_squared_error: 1.9843\n",
            "Epoch 150/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.9488 - mean_absolute_error: 0.9544 - mean_squared_error: 1.9488\n",
            "Epoch 150: val_loss improved from 1.98435 to 1.98134, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9443 - mean_absolute_error: 0.9543 - mean_squared_error: 1.9443 - val_loss: 1.9813 - val_mean_absolute_error: 0.9540 - val_mean_squared_error: 1.9813\n",
            "Epoch 151/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 1.9193 - mean_absolute_error: 0.9469 - mean_squared_error: 1.9193\n",
            "Epoch 151: val_loss improved from 1.98134 to 1.97694, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9409 - mean_absolute_error: 0.9497 - mean_squared_error: 1.9409 - val_loss: 1.9769 - val_mean_absolute_error: 0.9541 - val_mean_squared_error: 1.9769\n",
            "Epoch 152/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.9347 - mean_absolute_error: 0.9494 - mean_squared_error: 1.9347\n",
            "Epoch 152: val_loss improved from 1.97694 to 1.97430, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9363 - mean_absolute_error: 0.9495 - mean_squared_error: 1.9363 - val_loss: 1.9743 - val_mean_absolute_error: 0.9510 - val_mean_squared_error: 1.9743\n",
            "Epoch 153/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.9149 - mean_absolute_error: 0.9421 - mean_squared_error: 1.9149\n",
            "Epoch 153: val_loss improved from 1.97430 to 1.97104, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9327 - mean_absolute_error: 0.9473 - mean_squared_error: 1.9327 - val_loss: 1.9710 - val_mean_absolute_error: 0.9507 - val_mean_squared_error: 1.9710\n",
            "Epoch 154/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.9280 - mean_absolute_error: 0.9435 - mean_squared_error: 1.9280\n",
            "Epoch 154: val_loss improved from 1.97104 to 1.96762, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9293 - mean_absolute_error: 0.9441 - mean_squared_error: 1.9293 - val_loss: 1.9676 - val_mean_absolute_error: 0.9482 - val_mean_squared_error: 1.9676\n",
            "Epoch 155/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.9346 - mean_absolute_error: 0.9478 - mean_squared_error: 1.9346\n",
            "Epoch 155: val_loss improved from 1.96762 to 1.96476, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9267 - mean_absolute_error: 0.9445 - mean_squared_error: 1.9267 - val_loss: 1.9648 - val_mean_absolute_error: 0.9452 - val_mean_squared_error: 1.9648\n",
            "Epoch 156/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.9361 - mean_absolute_error: 0.9437 - mean_squared_error: 1.9361\n",
            "Epoch 156: val_loss improved from 1.96476 to 1.96386, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9232 - mean_absolute_error: 0.9425 - mean_squared_error: 1.9232 - val_loss: 1.9639 - val_mean_absolute_error: 0.9419 - val_mean_squared_error: 1.9639\n",
            "Epoch 157/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.9237 - mean_absolute_error: 0.9374 - mean_squared_error: 1.9237\n",
            "Epoch 157: val_loss improved from 1.96386 to 1.96000, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9191 - mean_absolute_error: 0.9367 - mean_squared_error: 1.9191 - val_loss: 1.9600 - val_mean_absolute_error: 0.9415 - val_mean_squared_error: 1.9600\n",
            "Epoch 158/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.9179 - mean_absolute_error: 0.9369 - mean_squared_error: 1.9179\n",
            "Epoch 158: val_loss did not improve from 1.96000\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9171 - mean_absolute_error: 0.9374 - mean_squared_error: 1.9171 - val_loss: 1.9601 - val_mean_absolute_error: 0.9430 - val_mean_squared_error: 1.9601\n",
            "Epoch 159/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.9231 - mean_absolute_error: 0.9338 - mean_squared_error: 1.9231\n",
            "Epoch 159: val_loss improved from 1.96000 to 1.95670, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9147 - mean_absolute_error: 0.9344 - mean_squared_error: 1.9147 - val_loss: 1.9567 - val_mean_absolute_error: 0.9363 - val_mean_squared_error: 1.9567\n",
            "Epoch 160/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.9002 - mean_absolute_error: 0.9292 - mean_squared_error: 1.9002\n",
            "Epoch 160: val_loss improved from 1.95670 to 1.95503, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9135 - mean_absolute_error: 0.9340 - mean_squared_error: 1.9135 - val_loss: 1.9550 - val_mean_absolute_error: 0.9354 - val_mean_squared_error: 1.9550\n",
            "Epoch 161/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.8986 - mean_absolute_error: 0.9294 - mean_squared_error: 1.8986\n",
            "Epoch 161: val_loss improved from 1.95503 to 1.95069, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9084 - mean_absolute_error: 0.9286 - mean_squared_error: 1.9084 - val_loss: 1.9507 - val_mean_absolute_error: 0.9336 - val_mean_squared_error: 1.9507\n",
            "Epoch 162/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.9025 - mean_absolute_error: 0.9301 - mean_squared_error: 1.9025\n",
            "Epoch 162: val_loss improved from 1.95069 to 1.94823, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9064 - mean_absolute_error: 0.9287 - mean_squared_error: 1.9064 - val_loss: 1.9482 - val_mean_absolute_error: 0.9304 - val_mean_squared_error: 1.9482\n",
            "Epoch 163/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.8831 - mean_absolute_error: 0.9215 - mean_squared_error: 1.8831\n",
            "Epoch 163: val_loss improved from 1.94823 to 1.94684, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9030 - mean_absolute_error: 0.9253 - mean_squared_error: 1.9030 - val_loss: 1.9468 - val_mean_absolute_error: 0.9253 - val_mean_squared_error: 1.9468\n",
            "Epoch 164/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.8974 - mean_absolute_error: 0.9216 - mean_squared_error: 1.8974\n",
            "Epoch 164: val_loss did not improve from 1.94684\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9006 - mean_absolute_error: 0.9216 - mean_squared_error: 1.9006 - val_loss: 1.9471 - val_mean_absolute_error: 0.9270 - val_mean_squared_error: 1.9471\n",
            "Epoch 165/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.9063 - mean_absolute_error: 0.9271 - mean_squared_error: 1.9063\n",
            "Epoch 165: val_loss improved from 1.94684 to 1.94402, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8980 - mean_absolute_error: 0.9240 - mean_squared_error: 1.8980 - val_loss: 1.9440 - val_mean_absolute_error: 0.9255 - val_mean_squared_error: 1.9440\n",
            "Epoch 166/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.8767 - mean_absolute_error: 0.9127 - mean_squared_error: 1.8767\n",
            "Epoch 166: val_loss improved from 1.94402 to 1.94102, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8957 - mean_absolute_error: 0.9171 - mean_squared_error: 1.8957 - val_loss: 1.9410 - val_mean_absolute_error: 0.9240 - val_mean_squared_error: 1.9410\n",
            "Epoch 167/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.8870 - mean_absolute_error: 0.9161 - mean_squared_error: 1.8870\n",
            "Epoch 167: val_loss did not improve from 1.94102\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8931 - mean_absolute_error: 0.9186 - mean_squared_error: 1.8931 - val_loss: 1.9456 - val_mean_absolute_error: 0.9208 - val_mean_squared_error: 1.9456\n",
            "Epoch 168/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.9008 - mean_absolute_error: 0.9174 - mean_squared_error: 1.9008\n",
            "Epoch 168: val_loss improved from 1.94102 to 1.93788, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8927 - mean_absolute_error: 0.9170 - mean_squared_error: 1.8927 - val_loss: 1.9379 - val_mean_absolute_error: 0.9161 - val_mean_squared_error: 1.9379\n",
            "Epoch 169/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.8809 - mean_absolute_error: 0.9086 - mean_squared_error: 1.8809\n",
            "Epoch 169: val_loss did not improve from 1.93788\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8892 - mean_absolute_error: 0.9109 - mean_squared_error: 1.8892 - val_loss: 1.9402 - val_mean_absolute_error: 0.9214 - val_mean_squared_error: 1.9402\n",
            "Epoch 170/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.8992 - mean_absolute_error: 0.9168 - mean_squared_error: 1.8992\n",
            "Epoch 170: val_loss improved from 1.93788 to 1.93481, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8878 - mean_absolute_error: 0.9155 - mean_squared_error: 1.8878 - val_loss: 1.9348 - val_mean_absolute_error: 0.9139 - val_mean_squared_error: 1.9348\n",
            "Epoch 171/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.8859 - mean_absolute_error: 0.9097 - mean_squared_error: 1.8859\n",
            "Epoch 171: val_loss improved from 1.93481 to 1.93424, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8880 - mean_absolute_error: 0.9109 - mean_squared_error: 1.8880 - val_loss: 1.9342 - val_mean_absolute_error: 0.9101 - val_mean_squared_error: 1.9342\n",
            "Epoch 172/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.8855 - mean_absolute_error: 0.9088 - mean_squared_error: 1.8855\n",
            "Epoch 172: val_loss did not improve from 1.93424\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.8852 - mean_absolute_error: 0.9089 - mean_squared_error: 1.8852 - val_loss: 1.9368 - val_mean_absolute_error: 0.9127 - val_mean_squared_error: 1.9368\n",
            "Epoch 173/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.8650 - mean_absolute_error: 0.9004 - mean_squared_error: 1.8650\n",
            "Epoch 173: val_loss improved from 1.93424 to 1.93213, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.8837 - mean_absolute_error: 0.9038 - mean_squared_error: 1.8837 - val_loss: 1.9321 - val_mean_absolute_error: 0.9162 - val_mean_squared_error: 1.9321\n",
            "Epoch 174/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.8784 - mean_absolute_error: 0.9097 - mean_squared_error: 1.8784\n",
            "Epoch 174: val_loss improved from 1.93213 to 1.93071, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.8824 - mean_absolute_error: 0.9115 - mean_squared_error: 1.8824 - val_loss: 1.9307 - val_mean_absolute_error: 0.9104 - val_mean_squared_error: 1.9307\n",
            "Epoch 175/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.8807 - mean_absolute_error: 0.9049 - mean_squared_error: 1.8807\n",
            "Epoch 175: val_loss improved from 1.93071 to 1.93033, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8817 - mean_absolute_error: 0.9051 - mean_squared_error: 1.8817 - val_loss: 1.9303 - val_mean_absolute_error: 0.9119 - val_mean_squared_error: 1.9303\n",
            "Epoch 176/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.8981 - mean_absolute_error: 0.9123 - mean_squared_error: 1.8981\n",
            "Epoch 176: val_loss did not improve from 1.93033\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8813 - mean_absolute_error: 0.9073 - mean_squared_error: 1.8813 - val_loss: 1.9321 - val_mean_absolute_error: 0.9097 - val_mean_squared_error: 1.9321\n",
            "Epoch 177/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.8813 - mean_absolute_error: 0.9035 - mean_squared_error: 1.8813\n",
            "Epoch 177: val_loss improved from 1.93033 to 1.92804, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8800 - mean_absolute_error: 0.9031 - mean_squared_error: 1.8800 - val_loss: 1.9280 - val_mean_absolute_error: 0.9082 - val_mean_squared_error: 1.9280\n",
            "Epoch 178/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.8918 - mean_absolute_error: 0.9128 - mean_squared_error: 1.8918\n",
            "Epoch 178: val_loss did not improve from 1.92804\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8771 - mean_absolute_error: 0.9060 - mean_squared_error: 1.8771 - val_loss: 1.9287 - val_mean_absolute_error: 0.9058 - val_mean_squared_error: 1.9287\n",
            "Epoch 179/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.8991 - mean_absolute_error: 0.9083 - mean_squared_error: 1.8991\n",
            "Epoch 179: val_loss did not improve from 1.92804\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8767 - mean_absolute_error: 0.9029 - mean_squared_error: 1.8767 - val_loss: 1.9313 - val_mean_absolute_error: 0.9043 - val_mean_squared_error: 1.9313\n",
            "Epoch 180/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.8954 - mean_absolute_error: 0.9050 - mean_squared_error: 1.8954\n",
            "Epoch 180: val_loss improved from 1.92804 to 1.92667, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8756 - mean_absolute_error: 0.9010 - mean_squared_error: 1.8756 - val_loss: 1.9267 - val_mean_absolute_error: 0.9064 - val_mean_squared_error: 1.9267\n",
            "Epoch 181/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.8836 - mean_absolute_error: 0.9042 - mean_squared_error: 1.8836\n",
            "Epoch 181: val_loss improved from 1.92667 to 1.92540, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8754 - mean_absolute_error: 0.9018 - mean_squared_error: 1.8754 - val_loss: 1.9254 - val_mean_absolute_error: 0.9056 - val_mean_squared_error: 1.9254\n",
            "Epoch 182/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.8563 - mean_absolute_error: 0.8953 - mean_squared_error: 1.8563\n",
            "Epoch 182: val_loss did not improve from 1.92540\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8735 - mean_absolute_error: 0.8988 - mean_squared_error: 1.8735 - val_loss: 1.9260 - val_mean_absolute_error: 0.9063 - val_mean_squared_error: 1.9260\n",
            "Epoch 183/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.8407 - mean_absolute_error: 0.8920 - mean_squared_error: 1.8407\n",
            "Epoch 183: val_loss did not improve from 1.92540\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8725 - mean_absolute_error: 0.8999 - mean_squared_error: 1.8725 - val_loss: 1.9260 - val_mean_absolute_error: 0.9080 - val_mean_squared_error: 1.9260\n",
            "Epoch 184/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.8700 - mean_absolute_error: 0.9020 - mean_squared_error: 1.8700\n",
            "Epoch 184: val_loss did not improve from 1.92540\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8704 - mean_absolute_error: 0.9010 - mean_squared_error: 1.8704 - val_loss: 1.9272 - val_mean_absolute_error: 0.9073 - val_mean_squared_error: 1.9272\n",
            "Epoch 185/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.8123 - mean_absolute_error: 0.8822 - mean_squared_error: 1.8123\n",
            "Epoch 185: val_loss improved from 1.92540 to 1.92346, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8701 - mean_absolute_error: 0.8972 - mean_squared_error: 1.8701 - val_loss: 1.9235 - val_mean_absolute_error: 0.9086 - val_mean_squared_error: 1.9235\n",
            "Epoch 186/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 1.8664 - mean_absolute_error: 0.9025 - mean_squared_error: 1.8664\n",
            "Epoch 186: val_loss improved from 1.92346 to 1.92230, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8698 - mean_absolute_error: 0.9042 - mean_squared_error: 1.8698 - val_loss: 1.9223 - val_mean_absolute_error: 0.9029 - val_mean_squared_error: 1.9223\n",
            "Epoch 187/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.8528 - mean_absolute_error: 0.8929 - mean_squared_error: 1.8528\n",
            "Epoch 187: val_loss improved from 1.92230 to 1.92026, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8690 - mean_absolute_error: 0.8964 - mean_squared_error: 1.8690 - val_loss: 1.9203 - val_mean_absolute_error: 0.9028 - val_mean_squared_error: 1.9203\n",
            "Epoch 188/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.8747 - mean_absolute_error: 0.9046 - mean_squared_error: 1.8747\n",
            "Epoch 188: val_loss improved from 1.92026 to 1.92009, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8685 - mean_absolute_error: 0.9015 - mean_squared_error: 1.8685 - val_loss: 1.9201 - val_mean_absolute_error: 0.9019 - val_mean_squared_error: 1.9201\n",
            "Epoch 189/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 1.8563 - mean_absolute_error: 0.8950 - mean_squared_error: 1.8563\n",
            "Epoch 189: val_loss improved from 1.92009 to 1.91949, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8672 - mean_absolute_error: 0.8976 - mean_squared_error: 1.8672 - val_loss: 1.9195 - val_mean_absolute_error: 0.9020 - val_mean_squared_error: 1.9195\n",
            "Epoch 190/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.8672 - mean_absolute_error: 0.8953 - mean_squared_error: 1.8672\n",
            "Epoch 190: val_loss did not improve from 1.91949\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8658 - mean_absolute_error: 0.8968 - mean_squared_error: 1.8658 - val_loss: 1.9212 - val_mean_absolute_error: 0.9033 - val_mean_squared_error: 1.9212\n",
            "Epoch 191/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.8462 - mean_absolute_error: 0.8938 - mean_squared_error: 1.8462\n",
            "Epoch 191: val_loss improved from 1.91949 to 1.91785, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8657 - mean_absolute_error: 0.8971 - mean_squared_error: 1.8657 - val_loss: 1.9178 - val_mean_absolute_error: 0.9035 - val_mean_squared_error: 1.9178\n",
            "Epoch 192/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.8690 - mean_absolute_error: 0.8990 - mean_squared_error: 1.8690\n",
            "Epoch 192: val_loss improved from 1.91785 to 1.91670, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8644 - mean_absolute_error: 0.8980 - mean_squared_error: 1.8644 - val_loss: 1.9167 - val_mean_absolute_error: 0.9001 - val_mean_squared_error: 1.9167\n",
            "Epoch 193/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.8585 - mean_absolute_error: 0.8971 - mean_squared_error: 1.8585\n",
            "Epoch 193: val_loss improved from 1.91670 to 1.91668, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8640 - mean_absolute_error: 0.8959 - mean_squared_error: 1.8640 - val_loss: 1.9167 - val_mean_absolute_error: 0.9048 - val_mean_squared_error: 1.9167\n",
            "Epoch 194/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 1.8625 - mean_absolute_error: 0.8999 - mean_squared_error: 1.8625\n",
            "Epoch 194: val_loss did not improve from 1.91668\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8641 - mean_absolute_error: 0.8988 - mean_squared_error: 1.8641 - val_loss: 1.9178 - val_mean_absolute_error: 0.9038 - val_mean_squared_error: 1.9178\n",
            "Epoch 195/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.8688 - mean_absolute_error: 0.8991 - mean_squared_error: 1.8688\n",
            "Epoch 195: val_loss improved from 1.91668 to 1.91634, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8637 - mean_absolute_error: 0.8981 - mean_squared_error: 1.8637 - val_loss: 1.9163 - val_mean_absolute_error: 0.9023 - val_mean_squared_error: 1.9163\n",
            "Epoch 196/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.8638 - mean_absolute_error: 0.8966 - mean_squared_error: 1.8638\n",
            "Epoch 196: val_loss did not improve from 1.91634\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8625 - mean_absolute_error: 0.8962 - mean_squared_error: 1.8625 - val_loss: 1.9178 - val_mean_absolute_error: 0.8995 - val_mean_squared_error: 1.9178\n",
            "Epoch 197/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.8687 - mean_absolute_error: 0.8999 - mean_squared_error: 1.8687\n",
            "Epoch 197: val_loss improved from 1.91634 to 1.91511, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8627 - mean_absolute_error: 0.8975 - mean_squared_error: 1.8627 - val_loss: 1.9151 - val_mean_absolute_error: 0.9031 - val_mean_squared_error: 1.9151\n",
            "Epoch 198/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.8455 - mean_absolute_error: 0.8902 - mean_squared_error: 1.8455\n",
            "Epoch 198: val_loss improved from 1.91511 to 1.91287, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8609 - mean_absolute_error: 0.8947 - mean_squared_error: 1.8609 - val_loss: 1.9129 - val_mean_absolute_error: 0.8992 - val_mean_squared_error: 1.9129\n",
            "Epoch 199/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.8627 - mean_absolute_error: 0.8969 - mean_squared_error: 1.8627\n",
            "Epoch 199: val_loss did not improve from 1.91287\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8589 - mean_absolute_error: 0.8960 - mean_squared_error: 1.8589 - val_loss: 1.9152 - val_mean_absolute_error: 0.9038 - val_mean_squared_error: 1.9152\n",
            "Epoch 200/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.8742 - mean_absolute_error: 0.8992 - mean_squared_error: 1.8742\n",
            "Epoch 200: val_loss improved from 1.91287 to 1.91274, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8602 - mean_absolute_error: 0.8966 - mean_squared_error: 1.8602 - val_loss: 1.9127 - val_mean_absolute_error: 0.8985 - val_mean_squared_error: 1.9127\n",
            "Epoch 201/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.8598 - mean_absolute_error: 0.8953 - mean_squared_error: 1.8598\n",
            "Epoch 201: val_loss improved from 1.91274 to 1.91226, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8564 - mean_absolute_error: 0.8943 - mean_squared_error: 1.8564 - val_loss: 1.9123 - val_mean_absolute_error: 0.9032 - val_mean_squared_error: 1.9123\n",
            "Epoch 202/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.8647 - mean_absolute_error: 0.8958 - mean_squared_error: 1.8647\n",
            "Epoch 202: val_loss improved from 1.91226 to 1.90961, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8592 - mean_absolute_error: 0.8964 - mean_squared_error: 1.8592 - val_loss: 1.9096 - val_mean_absolute_error: 0.8991 - val_mean_squared_error: 1.9096\n",
            "Epoch 203/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.8588 - mean_absolute_error: 0.8924 - mean_squared_error: 1.8588\n",
            "Epoch 203: val_loss improved from 1.90961 to 1.90896, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8570 - mean_absolute_error: 0.8954 - mean_squared_error: 1.8570 - val_loss: 1.9090 - val_mean_absolute_error: 0.8960 - val_mean_squared_error: 1.9090\n",
            "Epoch 204/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.8531 - mean_absolute_error: 0.8956 - mean_squared_error: 1.8531\n",
            "Epoch 204: val_loss did not improve from 1.90896\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8570 - mean_absolute_error: 0.8958 - mean_squared_error: 1.8570 - val_loss: 1.9094 - val_mean_absolute_error: 0.8971 - val_mean_squared_error: 1.9094\n",
            "Epoch 205/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.8636 - mean_absolute_error: 0.8969 - mean_squared_error: 1.8636\n",
            "Epoch 205: val_loss improved from 1.90896 to 1.90856, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8573 - mean_absolute_error: 0.8951 - mean_squared_error: 1.8573 - val_loss: 1.9086 - val_mean_absolute_error: 0.8992 - val_mean_squared_error: 1.9086\n",
            "Epoch 206/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 1.8305 - mean_absolute_error: 0.8859 - mean_squared_error: 1.8305\n",
            "Epoch 206: val_loss did not improve from 1.90856\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8536 - mean_absolute_error: 0.8929 - mean_squared_error: 1.8536 - val_loss: 1.9095 - val_mean_absolute_error: 0.9016 - val_mean_squared_error: 1.9095\n",
            "Epoch 207/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.8307 - mean_absolute_error: 0.8906 - mean_squared_error: 1.8307\n",
            "Epoch 207: val_loss improved from 1.90856 to 1.90695, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8562 - mean_absolute_error: 0.8954 - mean_squared_error: 1.8562 - val_loss: 1.9069 - val_mean_absolute_error: 0.8997 - val_mean_squared_error: 1.9069\n",
            "Epoch 208/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 1.8474 - mean_absolute_error: 0.8918 - mean_squared_error: 1.8474\n",
            "Epoch 208: val_loss did not improve from 1.90695\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8525 - mean_absolute_error: 0.8930 - mean_squared_error: 1.8525 - val_loss: 1.9091 - val_mean_absolute_error: 0.9045 - val_mean_squared_error: 1.9091\n",
            "Epoch 209/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.8667 - mean_absolute_error: 0.8977 - mean_squared_error: 1.8667\n",
            "Epoch 209: val_loss improved from 1.90695 to 1.90631, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8540 - mean_absolute_error: 0.8966 - mean_squared_error: 1.8540 - val_loss: 1.9063 - val_mean_absolute_error: 0.8959 - val_mean_squared_error: 1.9063\n",
            "Epoch 210/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.8518 - mean_absolute_error: 0.8969 - mean_squared_error: 1.8518\n",
            "Epoch 210: val_loss did not improve from 1.90631\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8523 - mean_absolute_error: 0.8955 - mean_squared_error: 1.8523 - val_loss: 1.9118 - val_mean_absolute_error: 0.8953 - val_mean_squared_error: 1.9118\n",
            "Epoch 211/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.8598 - mean_absolute_error: 0.8920 - mean_squared_error: 1.8598\n",
            "Epoch 211: val_loss did not improve from 1.90631\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8547 - mean_absolute_error: 0.8908 - mean_squared_error: 1.8547 - val_loss: 1.9070 - val_mean_absolute_error: 0.8948 - val_mean_squared_error: 1.9070\n",
            "Epoch 212/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.8501 - mean_absolute_error: 0.8920 - mean_squared_error: 1.8501\n",
            "Epoch 212: val_loss improved from 1.90631 to 1.90386, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8519 - mean_absolute_error: 0.8927 - mean_squared_error: 1.8519 - val_loss: 1.9039 - val_mean_absolute_error: 0.8980 - val_mean_squared_error: 1.9039\n",
            "Epoch 213/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.8409 - mean_absolute_error: 0.8905 - mean_squared_error: 1.8409\n",
            "Epoch 213: val_loss improved from 1.90386 to 1.90361, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8508 - mean_absolute_error: 0.8939 - mean_squared_error: 1.8508 - val_loss: 1.9036 - val_mean_absolute_error: 0.8965 - val_mean_squared_error: 1.9036\n",
            "Epoch 214/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.8543 - mean_absolute_error: 0.8946 - mean_squared_error: 1.8543\n",
            "Epoch 214: val_loss improved from 1.90361 to 1.90262, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8505 - mean_absolute_error: 0.8932 - mean_squared_error: 1.8505 - val_loss: 1.9026 - val_mean_absolute_error: 0.8965 - val_mean_squared_error: 1.9026\n",
            "Epoch 215/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.8318 - mean_absolute_error: 0.8881 - mean_squared_error: 1.8318\n",
            "Epoch 215: val_loss did not improve from 1.90262\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8510 - mean_absolute_error: 0.8935 - mean_squared_error: 1.8510 - val_loss: 1.9046 - val_mean_absolute_error: 0.9026 - val_mean_squared_error: 1.9046\n",
            "Epoch 216/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.8433 - mean_absolute_error: 0.8922 - mean_squared_error: 1.8433\n",
            "Epoch 216: val_loss improved from 1.90262 to 1.90223, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8503 - mean_absolute_error: 0.8933 - mean_squared_error: 1.8503 - val_loss: 1.9022 - val_mean_absolute_error: 0.8940 - val_mean_squared_error: 1.9022\n",
            "Epoch 217/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 1.8405 - mean_absolute_error: 0.8925 - mean_squared_error: 1.8405\n",
            "Epoch 217: val_loss improved from 1.90223 to 1.90119, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8503 - mean_absolute_error: 0.8934 - mean_squared_error: 1.8503 - val_loss: 1.9012 - val_mean_absolute_error: 0.8959 - val_mean_squared_error: 1.9012\n",
            "Epoch 218/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.8399 - mean_absolute_error: 0.8866 - mean_squared_error: 1.8399\n",
            "Epoch 218: val_loss did not improve from 1.90119\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8481 - mean_absolute_error: 0.8894 - mean_squared_error: 1.8481 - val_loss: 1.9044 - val_mean_absolute_error: 0.9074 - val_mean_squared_error: 1.9044\n",
            "Epoch 219/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.8515 - mean_absolute_error: 0.8958 - mean_squared_error: 1.8515\n",
            "Epoch 219: val_loss improved from 1.90119 to 1.90036, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8474 - mean_absolute_error: 0.8957 - mean_squared_error: 1.8474 - val_loss: 1.9004 - val_mean_absolute_error: 0.8945 - val_mean_squared_error: 1.9004\n",
            "Epoch 220/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.8561 - mean_absolute_error: 0.8933 - mean_squared_error: 1.8561\n",
            "Epoch 220: val_loss did not improve from 1.90036\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8477 - mean_absolute_error: 0.8907 - mean_squared_error: 1.8477 - val_loss: 1.9010 - val_mean_absolute_error: 0.9003 - val_mean_squared_error: 1.9010\n",
            "Epoch 221/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.8356 - mean_absolute_error: 0.8918 - mean_squared_error: 1.8356\n",
            "Epoch 221: val_loss did not improve from 1.90036\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8499 - mean_absolute_error: 0.8963 - mean_squared_error: 1.8499 - val_loss: 1.9006 - val_mean_absolute_error: 0.8931 - val_mean_squared_error: 1.9006\n",
            "Epoch 222/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.8495 - mean_absolute_error: 0.8923 - mean_squared_error: 1.8495\n",
            "Epoch 222: val_loss did not improve from 1.90036\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8459 - mean_absolute_error: 0.8923 - mean_squared_error: 1.8459 - val_loss: 1.9037 - val_mean_absolute_error: 0.8956 - val_mean_squared_error: 1.9037\n",
            "Epoch 223/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.8434 - mean_absolute_error: 0.8907 - mean_squared_error: 1.8434\n",
            "Epoch 223: val_loss improved from 1.90036 to 1.89759, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8459 - mean_absolute_error: 0.8893 - mean_squared_error: 1.8459 - val_loss: 1.8976 - val_mean_absolute_error: 0.8982 - val_mean_squared_error: 1.8976\n",
            "Epoch 224/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.8447 - mean_absolute_error: 0.8932 - mean_squared_error: 1.8447\n",
            "Epoch 224: val_loss did not improve from 1.89759\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8451 - mean_absolute_error: 0.8923 - mean_squared_error: 1.8451 - val_loss: 1.8984 - val_mean_absolute_error: 0.8991 - val_mean_squared_error: 1.8984\n",
            "Epoch 225/1000\n",
            "218/245 [=========================>....] - ETA: 0s - loss: 1.8434 - mean_absolute_error: 0.8938 - mean_squared_error: 1.8434\n",
            "Epoch 225: val_loss did not improve from 1.89759\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8433 - mean_absolute_error: 0.8930 - mean_squared_error: 1.8433 - val_loss: 1.8996 - val_mean_absolute_error: 0.8970 - val_mean_squared_error: 1.8996\n",
            "Epoch 226/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.8166 - mean_absolute_error: 0.8866 - mean_squared_error: 1.8166\n",
            "Epoch 226: val_loss did not improve from 1.89759\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8440 - mean_absolute_error: 0.8913 - mean_squared_error: 1.8440 - val_loss: 1.8980 - val_mean_absolute_error: 0.8918 - val_mean_squared_error: 1.8980\n",
            "Epoch 227/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.8404 - mean_absolute_error: 0.8910 - mean_squared_error: 1.8404\n",
            "Epoch 227: val_loss did not improve from 1.89759\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8433 - mean_absolute_error: 0.8920 - mean_squared_error: 1.8433 - val_loss: 1.8979 - val_mean_absolute_error: 0.8982 - val_mean_squared_error: 1.8979\n",
            "Epoch 228/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.8310 - mean_absolute_error: 0.8886 - mean_squared_error: 1.8310\n",
            "Epoch 228: val_loss did not improve from 1.89759\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8429 - mean_absolute_error: 0.8903 - mean_squared_error: 1.8429 - val_loss: 1.8987 - val_mean_absolute_error: 0.9033 - val_mean_squared_error: 1.8987\n",
            "Epoch 229/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.8402 - mean_absolute_error: 0.8921 - mean_squared_error: 1.8402\n",
            "Epoch 229: val_loss improved from 1.89759 to 1.89530, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8434 - mean_absolute_error: 0.8922 - mean_squared_error: 1.8434 - val_loss: 1.8953 - val_mean_absolute_error: 0.8974 - val_mean_squared_error: 1.8953\n",
            "Epoch 230/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.8152 - mean_absolute_error: 0.8864 - mean_squared_error: 1.8152\n",
            "Epoch 230: val_loss improved from 1.89530 to 1.89378, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8424 - mean_absolute_error: 0.8893 - mean_squared_error: 1.8424 - val_loss: 1.8938 - val_mean_absolute_error: 0.8967 - val_mean_squared_error: 1.8938\n",
            "Epoch 231/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.8472 - mean_absolute_error: 0.8924 - mean_squared_error: 1.8472\n",
            "Epoch 231: val_loss did not improve from 1.89378\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8420 - mean_absolute_error: 0.8934 - mean_squared_error: 1.8420 - val_loss: 1.8947 - val_mean_absolute_error: 0.8947 - val_mean_squared_error: 1.8947\n",
            "Epoch 232/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 1.8575 - mean_absolute_error: 0.8994 - mean_squared_error: 1.8575\n",
            "Epoch 232: val_loss improved from 1.89378 to 1.89273, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8417 - mean_absolute_error: 0.8945 - mean_squared_error: 1.8417 - val_loss: 1.8927 - val_mean_absolute_error: 0.8905 - val_mean_squared_error: 1.8927\n",
            "Epoch 233/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.8244 - mean_absolute_error: 0.8886 - mean_squared_error: 1.8244\n",
            "Epoch 233: val_loss did not improve from 1.89273\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8390 - mean_absolute_error: 0.8893 - mean_squared_error: 1.8390 - val_loss: 1.8979 - val_mean_absolute_error: 0.8964 - val_mean_squared_error: 1.8979\n",
            "Epoch 234/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.8607 - mean_absolute_error: 0.8961 - mean_squared_error: 1.8607\n",
            "Epoch 234: val_loss improved from 1.89273 to 1.89234, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8400 - mean_absolute_error: 0.8900 - mean_squared_error: 1.8400 - val_loss: 1.8923 - val_mean_absolute_error: 0.8927 - val_mean_squared_error: 1.8923\n",
            "Epoch 235/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 1.8543 - mean_absolute_error: 0.8918 - mean_squared_error: 1.8543\n",
            "Epoch 235: val_loss improved from 1.89234 to 1.89221, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8395 - mean_absolute_error: 0.8900 - mean_squared_error: 1.8395 - val_loss: 1.8922 - val_mean_absolute_error: 0.8984 - val_mean_squared_error: 1.8922\n",
            "Epoch 236/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.8415 - mean_absolute_error: 0.8902 - mean_squared_error: 1.8415\n",
            "Epoch 236: val_loss improved from 1.89221 to 1.89180, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8411 - mean_absolute_error: 0.8908 - mean_squared_error: 1.8411 - val_loss: 1.8918 - val_mean_absolute_error: 0.8955 - val_mean_squared_error: 1.8918\n",
            "Epoch 237/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 1.8488 - mean_absolute_error: 0.8922 - mean_squared_error: 1.8488\n",
            "Epoch 237: val_loss improved from 1.89180 to 1.89085, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8387 - mean_absolute_error: 0.8905 - mean_squared_error: 1.8387 - val_loss: 1.8908 - val_mean_absolute_error: 0.8973 - val_mean_squared_error: 1.8908\n",
            "Epoch 238/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.8384 - mean_absolute_error: 0.8912 - mean_squared_error: 1.8384\n",
            "Epoch 238: val_loss did not improve from 1.89085\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8384 - mean_absolute_error: 0.8912 - mean_squared_error: 1.8384 - val_loss: 1.8927 - val_mean_absolute_error: 0.8920 - val_mean_squared_error: 1.8927\n",
            "Epoch 239/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.8380 - mean_absolute_error: 0.8896 - mean_squared_error: 1.8380\n",
            "Epoch 239: val_loss improved from 1.89085 to 1.88911, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8380 - mean_absolute_error: 0.8896 - mean_squared_error: 1.8380 - val_loss: 1.8891 - val_mean_absolute_error: 0.8967 - val_mean_squared_error: 1.8891\n",
            "Epoch 240/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.8465 - mean_absolute_error: 0.8929 - mean_squared_error: 1.8465\n",
            "Epoch 240: val_loss improved from 1.88911 to 1.88808, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8384 - mean_absolute_error: 0.8924 - mean_squared_error: 1.8384 - val_loss: 1.8881 - val_mean_absolute_error: 0.8923 - val_mean_squared_error: 1.8881\n",
            "Epoch 241/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.8399 - mean_absolute_error: 0.8912 - mean_squared_error: 1.8399\n",
            "Epoch 241: val_loss did not improve from 1.88808\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8360 - mean_absolute_error: 0.8906 - mean_squared_error: 1.8360 - val_loss: 1.8893 - val_mean_absolute_error: 0.8922 - val_mean_squared_error: 1.8893\n",
            "Epoch 242/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.8426 - mean_absolute_error: 0.8918 - mean_squared_error: 1.8426\n",
            "Epoch 242: val_loss did not improve from 1.88808\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8359 - mean_absolute_error: 0.8895 - mean_squared_error: 1.8359 - val_loss: 1.8888 - val_mean_absolute_error: 0.8893 - val_mean_squared_error: 1.8888\n",
            "Epoch 243/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.8441 - mean_absolute_error: 0.8918 - mean_squared_error: 1.8441\n",
            "Epoch 243: val_loss improved from 1.88808 to 1.88643, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8341 - mean_absolute_error: 0.8895 - mean_squared_error: 1.8341 - val_loss: 1.8864 - val_mean_absolute_error: 0.8942 - val_mean_squared_error: 1.8864\n",
            "Epoch 244/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.8283 - mean_absolute_error: 0.8887 - mean_squared_error: 1.8283\n",
            "Epoch 244: val_loss did not improve from 1.88643\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8353 - mean_absolute_error: 0.8900 - mean_squared_error: 1.8353 - val_loss: 1.8875 - val_mean_absolute_error: 0.8924 - val_mean_squared_error: 1.8875\n",
            "Epoch 245/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.8133 - mean_absolute_error: 0.8856 - mean_squared_error: 1.8133\n",
            "Epoch 245: val_loss improved from 1.88643 to 1.88557, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8342 - mean_absolute_error: 0.8901 - mean_squared_error: 1.8342 - val_loss: 1.8856 - val_mean_absolute_error: 0.8873 - val_mean_squared_error: 1.8856\n",
            "Epoch 246/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.8216 - mean_absolute_error: 0.8856 - mean_squared_error: 1.8216\n",
            "Epoch 246: val_loss improved from 1.88557 to 1.88460, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8335 - mean_absolute_error: 0.8885 - mean_squared_error: 1.8335 - val_loss: 1.8846 - val_mean_absolute_error: 0.8936 - val_mean_squared_error: 1.8846\n",
            "Epoch 247/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.8313 - mean_absolute_error: 0.8940 - mean_squared_error: 1.8313\n",
            "Epoch 247: val_loss improved from 1.88460 to 1.88446, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8328 - mean_absolute_error: 0.8945 - mean_squared_error: 1.8328 - val_loss: 1.8845 - val_mean_absolute_error: 0.8880 - val_mean_squared_error: 1.8845\n",
            "Epoch 248/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.8391 - mean_absolute_error: 0.8898 - mean_squared_error: 1.8391\n",
            "Epoch 248: val_loss improved from 1.88446 to 1.88422, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8307 - mean_absolute_error: 0.8872 - mean_squared_error: 1.8307 - val_loss: 1.8842 - val_mean_absolute_error: 0.8951 - val_mean_squared_error: 1.8842\n",
            "Epoch 249/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.8066 - mean_absolute_error: 0.8829 - mean_squared_error: 1.8066\n",
            "Epoch 249: val_loss did not improve from 1.88422\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8311 - mean_absolute_error: 0.8892 - mean_squared_error: 1.8311 - val_loss: 1.8845 - val_mean_absolute_error: 0.8915 - val_mean_squared_error: 1.8845\n",
            "Epoch 250/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.8649 - mean_absolute_error: 0.9000 - mean_squared_error: 1.8649\n",
            "Epoch 250: val_loss improved from 1.88422 to 1.88255, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8319 - mean_absolute_error: 0.8909 - mean_squared_error: 1.8319 - val_loss: 1.8826 - val_mean_absolute_error: 0.8921 - val_mean_squared_error: 1.8826\n",
            "Epoch 251/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.8237 - mean_absolute_error: 0.8886 - mean_squared_error: 1.8237\n",
            "Epoch 251: val_loss did not improve from 1.88255\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8292 - mean_absolute_error: 0.8899 - mean_squared_error: 1.8292 - val_loss: 1.8845 - val_mean_absolute_error: 0.8934 - val_mean_squared_error: 1.8845\n",
            "Epoch 252/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.8282 - mean_absolute_error: 0.8888 - mean_squared_error: 1.8282\n",
            "Epoch 252: val_loss improved from 1.88255 to 1.88217, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8320 - mean_absolute_error: 0.8889 - mean_squared_error: 1.8320 - val_loss: 1.8822 - val_mean_absolute_error: 0.8883 - val_mean_squared_error: 1.8822\n",
            "Epoch 253/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.8166 - mean_absolute_error: 0.8829 - mean_squared_error: 1.8166\n",
            "Epoch 253: val_loss improved from 1.88217 to 1.87998, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8290 - mean_absolute_error: 0.8869 - mean_squared_error: 1.8290 - val_loss: 1.8800 - val_mean_absolute_error: 0.8911 - val_mean_squared_error: 1.8800\n",
            "Epoch 254/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.8428 - mean_absolute_error: 0.8938 - mean_squared_error: 1.8428\n",
            "Epoch 254: val_loss improved from 1.87998 to 1.87906, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8292 - mean_absolute_error: 0.8900 - mean_squared_error: 1.8292 - val_loss: 1.8791 - val_mean_absolute_error: 0.8927 - val_mean_squared_error: 1.8791\n",
            "Epoch 255/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.8304 - mean_absolute_error: 0.8866 - mean_squared_error: 1.8304\n",
            "Epoch 255: val_loss did not improve from 1.87906\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8270 - mean_absolute_error: 0.8866 - mean_squared_error: 1.8270 - val_loss: 1.8820 - val_mean_absolute_error: 0.9019 - val_mean_squared_error: 1.8820\n",
            "Epoch 256/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.8219 - mean_absolute_error: 0.8942 - mean_squared_error: 1.8219\n",
            "Epoch 256: val_loss improved from 1.87906 to 1.87891, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8282 - mean_absolute_error: 0.8952 - mean_squared_error: 1.8282 - val_loss: 1.8789 - val_mean_absolute_error: 0.8911 - val_mean_squared_error: 1.8789\n",
            "Epoch 257/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.8344 - mean_absolute_error: 0.8899 - mean_squared_error: 1.8344\n",
            "Epoch 257: val_loss did not improve from 1.87891\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.8283 - mean_absolute_error: 0.8876 - mean_squared_error: 1.8283 - val_loss: 1.8794 - val_mean_absolute_error: 0.8895 - val_mean_squared_error: 1.8794\n",
            "Epoch 258/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.8272 - mean_absolute_error: 0.8893 - mean_squared_error: 1.8272\n",
            "Epoch 258: val_loss improved from 1.87891 to 1.87702, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.8266 - mean_absolute_error: 0.8892 - mean_squared_error: 1.8266 - val_loss: 1.8770 - val_mean_absolute_error: 0.8934 - val_mean_squared_error: 1.8770\n",
            "Epoch 259/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.8369 - mean_absolute_error: 0.8919 - mean_squared_error: 1.8369\n",
            "Epoch 259: val_loss improved from 1.87702 to 1.87643, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.8254 - mean_absolute_error: 0.8883 - mean_squared_error: 1.8254 - val_loss: 1.8764 - val_mean_absolute_error: 0.8932 - val_mean_squared_error: 1.8764\n",
            "Epoch 260/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.8273 - mean_absolute_error: 0.8907 - mean_squared_error: 1.8273\n",
            "Epoch 260: val_loss improved from 1.87643 to 1.87538, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8251 - mean_absolute_error: 0.8895 - mean_squared_error: 1.8251 - val_loss: 1.8754 - val_mean_absolute_error: 0.8917 - val_mean_squared_error: 1.8754\n",
            "Epoch 261/1000\n",
            "219/245 [=========================>....] - ETA: 0s - loss: 1.7848 - mean_absolute_error: 0.8771 - mean_squared_error: 1.7848\n",
            "Epoch 261: val_loss did not improve from 1.87538\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8234 - mean_absolute_error: 0.8866 - mean_squared_error: 1.8234 - val_loss: 1.8754 - val_mean_absolute_error: 0.8936 - val_mean_squared_error: 1.8754\n",
            "Epoch 262/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 1.8488 - mean_absolute_error: 0.8954 - mean_squared_error: 1.8488\n",
            "Epoch 262: val_loss improved from 1.87538 to 1.87408, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8233 - mean_absolute_error: 0.8898 - mean_squared_error: 1.8233 - val_loss: 1.8741 - val_mean_absolute_error: 0.8923 - val_mean_squared_error: 1.8741\n",
            "Epoch 263/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.8168 - mean_absolute_error: 0.8822 - mean_squared_error: 1.8168\n",
            "Epoch 263: val_loss did not improve from 1.87408\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8235 - mean_absolute_error: 0.8884 - mean_squared_error: 1.8235 - val_loss: 1.8742 - val_mean_absolute_error: 0.8940 - val_mean_squared_error: 1.8742\n",
            "Epoch 264/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.8148 - mean_absolute_error: 0.8885 - mean_squared_error: 1.8148\n",
            "Epoch 264: val_loss improved from 1.87408 to 1.87236, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8235 - mean_absolute_error: 0.8902 - mean_squared_error: 1.8235 - val_loss: 1.8724 - val_mean_absolute_error: 0.8917 - val_mean_squared_error: 1.8724\n",
            "Epoch 265/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.8165 - mean_absolute_error: 0.8867 - mean_squared_error: 1.8165\n",
            "Epoch 265: val_loss did not improve from 1.87236\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8218 - mean_absolute_error: 0.8884 - mean_squared_error: 1.8218 - val_loss: 1.8750 - val_mean_absolute_error: 0.8967 - val_mean_squared_error: 1.8750\n",
            "Epoch 266/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.8367 - mean_absolute_error: 0.8932 - mean_squared_error: 1.8367\n",
            "Epoch 266: val_loss improved from 1.87236 to 1.87100, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8224 - mean_absolute_error: 0.8911 - mean_squared_error: 1.8224 - val_loss: 1.8710 - val_mean_absolute_error: 0.8876 - val_mean_squared_error: 1.8710\n",
            "Epoch 267/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.8275 - mean_absolute_error: 0.8892 - mean_squared_error: 1.8275\n",
            "Epoch 267: val_loss improved from 1.87100 to 1.86966, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8207 - mean_absolute_error: 0.8871 - mean_squared_error: 1.8207 - val_loss: 1.8697 - val_mean_absolute_error: 0.8915 - val_mean_squared_error: 1.8697\n",
            "Epoch 268/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.8490 - mean_absolute_error: 0.8962 - mean_squared_error: 1.8490\n",
            "Epoch 268: val_loss improved from 1.86966 to 1.86923, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8208 - mean_absolute_error: 0.8890 - mean_squared_error: 1.8208 - val_loss: 1.8692 - val_mean_absolute_error: 0.8921 - val_mean_squared_error: 1.8692\n",
            "Epoch 269/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.8058 - mean_absolute_error: 0.8846 - mean_squared_error: 1.8058\n",
            "Epoch 269: val_loss did not improve from 1.86923\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8195 - mean_absolute_error: 0.8888 - mean_squared_error: 1.8195 - val_loss: 1.8740 - val_mean_absolute_error: 0.8944 - val_mean_squared_error: 1.8740\n",
            "Epoch 270/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.8113 - mean_absolute_error: 0.8854 - mean_squared_error: 1.8113\n",
            "Epoch 270: val_loss improved from 1.86923 to 1.86746, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8192 - mean_absolute_error: 0.8875 - mean_squared_error: 1.8192 - val_loss: 1.8675 - val_mean_absolute_error: 0.8918 - val_mean_squared_error: 1.8675\n",
            "Epoch 271/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.8287 - mean_absolute_error: 0.8913 - mean_squared_error: 1.8287\n",
            "Epoch 271: val_loss improved from 1.86746 to 1.86698, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8188 - mean_absolute_error: 0.8876 - mean_squared_error: 1.8188 - val_loss: 1.8670 - val_mean_absolute_error: 0.8940 - val_mean_squared_error: 1.8670\n",
            "Epoch 272/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.8087 - mean_absolute_error: 0.8880 - mean_squared_error: 1.8087\n",
            "Epoch 272: val_loss did not improve from 1.86698\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8171 - mean_absolute_error: 0.8902 - mean_squared_error: 1.8171 - val_loss: 1.8681 - val_mean_absolute_error: 0.8918 - val_mean_squared_error: 1.8681\n",
            "Epoch 273/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.7989 - mean_absolute_error: 0.8841 - mean_squared_error: 1.7989\n",
            "Epoch 273: val_loss improved from 1.86698 to 1.86557, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8158 - mean_absolute_error: 0.8887 - mean_squared_error: 1.8158 - val_loss: 1.8656 - val_mean_absolute_error: 0.8893 - val_mean_squared_error: 1.8656\n",
            "Epoch 274/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.7970 - mean_absolute_error: 0.8834 - mean_squared_error: 1.7970\n",
            "Epoch 274: val_loss did not improve from 1.86557\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8143 - mean_absolute_error: 0.8870 - mean_squared_error: 1.8143 - val_loss: 1.8692 - val_mean_absolute_error: 0.8952 - val_mean_squared_error: 1.8692\n",
            "Epoch 275/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.8314 - mean_absolute_error: 0.8947 - mean_squared_error: 1.8314\n",
            "Epoch 275: val_loss improved from 1.86557 to 1.86426, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8153 - mean_absolute_error: 0.8911 - mean_squared_error: 1.8153 - val_loss: 1.8643 - val_mean_absolute_error: 0.8855 - val_mean_squared_error: 1.8643\n",
            "Epoch 276/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.8157 - mean_absolute_error: 0.8833 - mean_squared_error: 1.8157\n",
            "Epoch 276: val_loss improved from 1.86426 to 1.86311, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8132 - mean_absolute_error: 0.8843 - mean_squared_error: 1.8132 - val_loss: 1.8631 - val_mean_absolute_error: 0.8929 - val_mean_squared_error: 1.8631\n",
            "Epoch 277/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.8116 - mean_absolute_error: 0.8896 - mean_squared_error: 1.8116\n",
            "Epoch 277: val_loss improved from 1.86311 to 1.86145, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8124 - mean_absolute_error: 0.8903 - mean_squared_error: 1.8124 - val_loss: 1.8615 - val_mean_absolute_error: 0.8858 - val_mean_squared_error: 1.8615\n",
            "Epoch 278/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.8018 - mean_absolute_error: 0.8851 - mean_squared_error: 1.8018\n",
            "Epoch 278: val_loss did not improve from 1.86145\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8114 - mean_absolute_error: 0.8865 - mean_squared_error: 1.8114 - val_loss: 1.8634 - val_mean_absolute_error: 0.8867 - val_mean_squared_error: 1.8634\n",
            "Epoch 279/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.7788 - mean_absolute_error: 0.8776 - mean_squared_error: 1.7788\n",
            "Epoch 279: val_loss improved from 1.86145 to 1.85963, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8118 - mean_absolute_error: 0.8847 - mean_squared_error: 1.8118 - val_loss: 1.8596 - val_mean_absolute_error: 0.8914 - val_mean_squared_error: 1.8596\n",
            "Epoch 280/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.7965 - mean_absolute_error: 0.8863 - mean_squared_error: 1.7965\n",
            "Epoch 280: val_loss improved from 1.85963 to 1.85893, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8108 - mean_absolute_error: 0.8905 - mean_squared_error: 1.8108 - val_loss: 1.8589 - val_mean_absolute_error: 0.8855 - val_mean_squared_error: 1.8589\n",
            "Epoch 281/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.8246 - mean_absolute_error: 0.8865 - mean_squared_error: 1.8246\n",
            "Epoch 281: val_loss improved from 1.85893 to 1.85823, saving model to best_model9.h5\n",
            "245/245 [==============================] - 2s 6ms/step - loss: 1.8095 - mean_absolute_error: 0.8849 - mean_squared_error: 1.8095 - val_loss: 1.8582 - val_mean_absolute_error: 0.8892 - val_mean_squared_error: 1.8582\n",
            "Epoch 282/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.8088 - mean_absolute_error: 0.8874 - mean_squared_error: 1.8088\n",
            "Epoch 282: val_loss did not improve from 1.85823\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8086 - mean_absolute_error: 0.8874 - mean_squared_error: 1.8086 - val_loss: 1.8607 - val_mean_absolute_error: 0.8929 - val_mean_squared_error: 1.8607\n",
            "Epoch 283/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.8035 - mean_absolute_error: 0.8876 - mean_squared_error: 1.8035\n",
            "Epoch 283: val_loss improved from 1.85823 to 1.85600, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 6ms/step - loss: 1.8086 - mean_absolute_error: 0.8884 - mean_squared_error: 1.8086 - val_loss: 1.8560 - val_mean_absolute_error: 0.8872 - val_mean_squared_error: 1.8560\n",
            "Epoch 284/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.8015 - mean_absolute_error: 0.8848 - mean_squared_error: 1.8015\n",
            "Epoch 284: val_loss did not improve from 1.85600\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8083 - mean_absolute_error: 0.8874 - mean_squared_error: 1.8083 - val_loss: 1.8567 - val_mean_absolute_error: 0.8922 - val_mean_squared_error: 1.8567\n",
            "Epoch 285/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.8147 - mean_absolute_error: 0.8904 - mean_squared_error: 1.8147\n",
            "Epoch 285: val_loss improved from 1.85600 to 1.85430, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8069 - mean_absolute_error: 0.8887 - mean_squared_error: 1.8069 - val_loss: 1.8543 - val_mean_absolute_error: 0.8861 - val_mean_squared_error: 1.8543\n",
            "Epoch 286/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.8058 - mean_absolute_error: 0.8847 - mean_squared_error: 1.8058\n",
            "Epoch 286: val_loss did not improve from 1.85430\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8037 - mean_absolute_error: 0.8849 - mean_squared_error: 1.8037 - val_loss: 1.8578 - val_mean_absolute_error: 0.8913 - val_mean_squared_error: 1.8578\n",
            "Epoch 287/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.8300 - mean_absolute_error: 0.8925 - mean_squared_error: 1.8300\n",
            "Epoch 287: val_loss improved from 1.85430 to 1.85214, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8050 - mean_absolute_error: 0.8869 - mean_squared_error: 1.8050 - val_loss: 1.8521 - val_mean_absolute_error: 0.8841 - val_mean_squared_error: 1.8521\n",
            "Epoch 288/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.8266 - mean_absolute_error: 0.8924 - mean_squared_error: 1.8266\n",
            "Epoch 288: val_loss improved from 1.85214 to 1.85157, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8030 - mean_absolute_error: 0.8861 - mean_squared_error: 1.8030 - val_loss: 1.8516 - val_mean_absolute_error: 0.8890 - val_mean_squared_error: 1.8516\n",
            "Epoch 289/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.7816 - mean_absolute_error: 0.8820 - mean_squared_error: 1.7816\n",
            "Epoch 289: val_loss improved from 1.85157 to 1.85081, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8034 - mean_absolute_error: 0.8866 - mean_squared_error: 1.8034 - val_loss: 1.8508 - val_mean_absolute_error: 0.8856 - val_mean_squared_error: 1.8508\n",
            "Epoch 290/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.8067 - mean_absolute_error: 0.8864 - mean_squared_error: 1.8067\n",
            "Epoch 290: val_loss improved from 1.85081 to 1.84918, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.8017 - mean_absolute_error: 0.8850 - mean_squared_error: 1.8017 - val_loss: 1.8492 - val_mean_absolute_error: 0.8859 - val_mean_squared_error: 1.8492\n",
            "Epoch 291/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.8270 - mean_absolute_error: 0.8926 - mean_squared_error: 1.8270\n",
            "Epoch 291: val_loss improved from 1.84918 to 1.84843, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.8006 - mean_absolute_error: 0.8854 - mean_squared_error: 1.8006 - val_loss: 1.8484 - val_mean_absolute_error: 0.8895 - val_mean_squared_error: 1.8484\n",
            "Epoch 292/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.8153 - mean_absolute_error: 0.8887 - mean_squared_error: 1.8153\n",
            "Epoch 292: val_loss improved from 1.84843 to 1.84721, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.8011 - mean_absolute_error: 0.8861 - mean_squared_error: 1.8011 - val_loss: 1.8472 - val_mean_absolute_error: 0.8881 - val_mean_squared_error: 1.8472\n",
            "Epoch 293/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.7873 - mean_absolute_error: 0.8799 - mean_squared_error: 1.7873\n",
            "Epoch 293: val_loss improved from 1.84721 to 1.84706, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7988 - mean_absolute_error: 0.8849 - mean_squared_error: 1.7988 - val_loss: 1.8471 - val_mean_absolute_error: 0.8916 - val_mean_squared_error: 1.8471\n",
            "Epoch 294/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 1.8141 - mean_absolute_error: 0.8956 - mean_squared_error: 1.8141\n",
            "Epoch 294: val_loss did not improve from 1.84706\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.7997 - mean_absolute_error: 0.8892 - mean_squared_error: 1.7997 - val_loss: 1.8471 - val_mean_absolute_error: 0.8824 - val_mean_squared_error: 1.8471\n",
            "Epoch 295/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.7980 - mean_absolute_error: 0.8864 - mean_squared_error: 1.7980\n",
            "Epoch 295: val_loss improved from 1.84706 to 1.84554, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7980 - mean_absolute_error: 0.8864 - mean_squared_error: 1.7980 - val_loss: 1.8455 - val_mean_absolute_error: 0.8826 - val_mean_squared_error: 1.8455\n",
            "Epoch 296/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.8233 - mean_absolute_error: 0.8914 - mean_squared_error: 1.8233\n",
            "Epoch 296: val_loss improved from 1.84554 to 1.84384, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7967 - mean_absolute_error: 0.8859 - mean_squared_error: 1.7967 - val_loss: 1.8438 - val_mean_absolute_error: 0.8886 - val_mean_squared_error: 1.8438\n",
            "Epoch 297/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.7934 - mean_absolute_error: 0.8820 - mean_squared_error: 1.7934\n",
            "Epoch 297: val_loss improved from 1.84384 to 1.84235, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7961 - mean_absolute_error: 0.8823 - mean_squared_error: 1.7961 - val_loss: 1.8423 - val_mean_absolute_error: 0.8887 - val_mean_squared_error: 1.8423\n",
            "Epoch 298/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.7903 - mean_absolute_error: 0.8843 - mean_squared_error: 1.7903\n",
            "Epoch 298: val_loss improved from 1.84235 to 1.84118, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7963 - mean_absolute_error: 0.8855 - mean_squared_error: 1.7963 - val_loss: 1.8412 - val_mean_absolute_error: 0.8878 - val_mean_squared_error: 1.8412\n",
            "Epoch 299/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.7840 - mean_absolute_error: 0.8861 - mean_squared_error: 1.7840\n",
            "Epoch 299: val_loss did not improve from 1.84118\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7925 - mean_absolute_error: 0.8868 - mean_squared_error: 1.7925 - val_loss: 1.8445 - val_mean_absolute_error: 0.8813 - val_mean_squared_error: 1.8445\n",
            "Epoch 300/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.7863 - mean_absolute_error: 0.8832 - mean_squared_error: 1.7863\n",
            "Epoch 300: val_loss improved from 1.84118 to 1.83888, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7938 - mean_absolute_error: 0.8859 - mean_squared_error: 1.7938 - val_loss: 1.8389 - val_mean_absolute_error: 0.8864 - val_mean_squared_error: 1.8389\n",
            "Epoch 301/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.7936 - mean_absolute_error: 0.8825 - mean_squared_error: 1.7936\n",
            "Epoch 301: val_loss did not improve from 1.83888\n",
            "245/245 [==============================] - 1s 6ms/step - loss: 1.7901 - mean_absolute_error: 0.8814 - mean_squared_error: 1.7901 - val_loss: 1.8487 - val_mean_absolute_error: 0.8907 - val_mean_squared_error: 1.8487\n",
            "Epoch 302/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.7993 - mean_absolute_error: 0.8893 - mean_squared_error: 1.7993\n",
            "Epoch 302: val_loss did not improve from 1.83888\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7922 - mean_absolute_error: 0.8882 - mean_squared_error: 1.7922 - val_loss: 1.8390 - val_mean_absolute_error: 0.8891 - val_mean_squared_error: 1.8390\n",
            "Epoch 303/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.7903 - mean_absolute_error: 0.8835 - mean_squared_error: 1.7903\n",
            "Epoch 303: val_loss improved from 1.83888 to 1.83773, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7903 - mean_absolute_error: 0.8835 - mean_squared_error: 1.7903 - val_loss: 1.8377 - val_mean_absolute_error: 0.8899 - val_mean_squared_error: 1.8377\n",
            "Epoch 304/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.7992 - mean_absolute_error: 0.8876 - mean_squared_error: 1.7992\n",
            "Epoch 304: val_loss did not improve from 1.83773\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7896 - mean_absolute_error: 0.8842 - mean_squared_error: 1.7896 - val_loss: 1.8394 - val_mean_absolute_error: 0.8905 - val_mean_squared_error: 1.8394\n",
            "Epoch 305/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.8022 - mean_absolute_error: 0.8895 - mean_squared_error: 1.8022\n",
            "Epoch 305: val_loss improved from 1.83773 to 1.83492, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7878 - mean_absolute_error: 0.8856 - mean_squared_error: 1.7878 - val_loss: 1.8349 - val_mean_absolute_error: 0.8838 - val_mean_squared_error: 1.8349\n",
            "Epoch 306/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.7846 - mean_absolute_error: 0.8849 - mean_squared_error: 1.7846\n",
            "Epoch 306: val_loss improved from 1.83492 to 1.83453, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7877 - mean_absolute_error: 0.8849 - mean_squared_error: 1.7877 - val_loss: 1.8345 - val_mean_absolute_error: 0.8776 - val_mean_squared_error: 1.8345\n",
            "Epoch 307/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.7696 - mean_absolute_error: 0.8780 - mean_squared_error: 1.7696\n",
            "Epoch 307: val_loss improved from 1.83453 to 1.83231, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7855 - mean_absolute_error: 0.8816 - mean_squared_error: 1.7855 - val_loss: 1.8323 - val_mean_absolute_error: 0.8863 - val_mean_squared_error: 1.8323\n",
            "Epoch 308/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.7827 - mean_absolute_error: 0.8850 - mean_squared_error: 1.7827\n",
            "Epoch 308: val_loss improved from 1.83231 to 1.83196, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7853 - mean_absolute_error: 0.8871 - mean_squared_error: 1.7853 - val_loss: 1.8320 - val_mean_absolute_error: 0.8807 - val_mean_squared_error: 1.8320\n",
            "Epoch 309/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.7944 - mean_absolute_error: 0.8819 - mean_squared_error: 1.7944\n",
            "Epoch 309: val_loss improved from 1.83196 to 1.83153, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7847 - mean_absolute_error: 0.8810 - mean_squared_error: 1.7847 - val_loss: 1.8315 - val_mean_absolute_error: 0.8811 - val_mean_squared_error: 1.8315\n",
            "Epoch 310/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.7824 - mean_absolute_error: 0.8832 - mean_squared_error: 1.7824\n",
            "Epoch 310: val_loss improved from 1.83153 to 1.82992, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7820 - mean_absolute_error: 0.8831 - mean_squared_error: 1.7820 - val_loss: 1.8299 - val_mean_absolute_error: 0.8848 - val_mean_squared_error: 1.8299\n",
            "Epoch 311/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.7740 - mean_absolute_error: 0.8802 - mean_squared_error: 1.7740\n",
            "Epoch 311: val_loss did not improve from 1.82992\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7807 - mean_absolute_error: 0.8828 - mean_squared_error: 1.7807 - val_loss: 1.8303 - val_mean_absolute_error: 0.8855 - val_mean_squared_error: 1.8303\n",
            "Epoch 312/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.7658 - mean_absolute_error: 0.8826 - mean_squared_error: 1.7658\n",
            "Epoch 312: val_loss improved from 1.82992 to 1.82848, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7815 - mean_absolute_error: 0.8851 - mean_squared_error: 1.7815 - val_loss: 1.8285 - val_mean_absolute_error: 0.8801 - val_mean_squared_error: 1.8285\n",
            "Epoch 313/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.7762 - mean_absolute_error: 0.8800 - mean_squared_error: 1.7762\n",
            "Epoch 313: val_loss improved from 1.82848 to 1.82791, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7796 - mean_absolute_error: 0.8800 - mean_squared_error: 1.7796 - val_loss: 1.8279 - val_mean_absolute_error: 0.8854 - val_mean_squared_error: 1.8279\n",
            "Epoch 314/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.7858 - mean_absolute_error: 0.8838 - mean_squared_error: 1.7858\n",
            "Epoch 314: val_loss improved from 1.82791 to 1.82585, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7798 - mean_absolute_error: 0.8833 - mean_squared_error: 1.7798 - val_loss: 1.8259 - val_mean_absolute_error: 0.8833 - val_mean_squared_error: 1.8259\n",
            "Epoch 315/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.7754 - mean_absolute_error: 0.8850 - mean_squared_error: 1.7754\n",
            "Epoch 315: val_loss did not improve from 1.82585\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7777 - mean_absolute_error: 0.8849 - mean_squared_error: 1.7777 - val_loss: 1.8281 - val_mean_absolute_error: 0.8878 - val_mean_squared_error: 1.8281\n",
            "Epoch 316/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.7691 - mean_absolute_error: 0.8784 - mean_squared_error: 1.7691\n",
            "Epoch 316: val_loss improved from 1.82585 to 1.82226, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7771 - mean_absolute_error: 0.8788 - mean_squared_error: 1.7771 - val_loss: 1.8223 - val_mean_absolute_error: 0.8822 - val_mean_squared_error: 1.8223\n",
            "Epoch 317/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.7771 - mean_absolute_error: 0.8841 - mean_squared_error: 1.7771\n",
            "Epoch 317: val_loss improved from 1.82226 to 1.82081, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7771 - mean_absolute_error: 0.8841 - mean_squared_error: 1.7771 - val_loss: 1.8208 - val_mean_absolute_error: 0.8799 - val_mean_squared_error: 1.8208\n",
            "Epoch 318/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.7646 - mean_absolute_error: 0.8817 - mean_squared_error: 1.7646\n",
            "Epoch 318: val_loss did not improve from 1.82081\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7758 - mean_absolute_error: 0.8826 - mean_squared_error: 1.7758 - val_loss: 1.8227 - val_mean_absolute_error: 0.8793 - val_mean_squared_error: 1.8227\n",
            "Epoch 319/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.7712 - mean_absolute_error: 0.8797 - mean_squared_error: 1.7712\n",
            "Epoch 319: val_loss improved from 1.82081 to 1.81910, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7738 - mean_absolute_error: 0.8802 - mean_squared_error: 1.7738 - val_loss: 1.8191 - val_mean_absolute_error: 0.8791 - val_mean_squared_error: 1.8191\n",
            "Epoch 320/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.7892 - mean_absolute_error: 0.8836 - mean_squared_error: 1.7892\n",
            "Epoch 320: val_loss did not improve from 1.81910\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7718 - mean_absolute_error: 0.8782 - mean_squared_error: 1.7718 - val_loss: 1.8200 - val_mean_absolute_error: 0.8825 - val_mean_squared_error: 1.8200\n",
            "Epoch 321/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.7579 - mean_absolute_error: 0.8754 - mean_squared_error: 1.7579\n",
            "Epoch 321: val_loss improved from 1.81910 to 1.81742, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7715 - mean_absolute_error: 0.8810 - mean_squared_error: 1.7715 - val_loss: 1.8174 - val_mean_absolute_error: 0.8792 - val_mean_squared_error: 1.8174\n",
            "Epoch 322/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.7523 - mean_absolute_error: 0.8767 - mean_squared_error: 1.7523\n",
            "Epoch 322: val_loss improved from 1.81742 to 1.81625, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7698 - mean_absolute_error: 0.8807 - mean_squared_error: 1.7698 - val_loss: 1.8163 - val_mean_absolute_error: 0.8755 - val_mean_squared_error: 1.8163\n",
            "Epoch 323/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.7633 - mean_absolute_error: 0.8806 - mean_squared_error: 1.7633\n",
            "Epoch 323: val_loss improved from 1.81625 to 1.81406, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7690 - mean_absolute_error: 0.8823 - mean_squared_error: 1.7690 - val_loss: 1.8141 - val_mean_absolute_error: 0.8769 - val_mean_squared_error: 1.8141\n",
            "Epoch 324/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.7832 - mean_absolute_error: 0.8824 - mean_squared_error: 1.7832\n",
            "Epoch 324: val_loss improved from 1.81406 to 1.81376, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7693 - mean_absolute_error: 0.8814 - mean_squared_error: 1.7693 - val_loss: 1.8138 - val_mean_absolute_error: 0.8778 - val_mean_squared_error: 1.8138\n",
            "Epoch 325/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.7659 - mean_absolute_error: 0.8800 - mean_squared_error: 1.7659\n",
            "Epoch 325: val_loss improved from 1.81376 to 1.81275, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7659 - mean_absolute_error: 0.8800 - mean_squared_error: 1.7659 - val_loss: 1.8128 - val_mean_absolute_error: 0.8812 - val_mean_squared_error: 1.8128\n",
            "Epoch 326/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.8078 - mean_absolute_error: 0.8917 - mean_squared_error: 1.8078\n",
            "Epoch 326: val_loss improved from 1.81275 to 1.81249, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7655 - mean_absolute_error: 0.8808 - mean_squared_error: 1.7655 - val_loss: 1.8125 - val_mean_absolute_error: 0.8756 - val_mean_squared_error: 1.8125\n",
            "Epoch 327/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.7668 - mean_absolute_error: 0.8797 - mean_squared_error: 1.7668\n",
            "Epoch 327: val_loss improved from 1.81249 to 1.80873, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7638 - mean_absolute_error: 0.8786 - mean_squared_error: 1.7638 - val_loss: 1.8087 - val_mean_absolute_error: 0.8799 - val_mean_squared_error: 1.8087\n",
            "Epoch 328/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 1.7610 - mean_absolute_error: 0.8777 - mean_squared_error: 1.7610\n",
            "Epoch 328: val_loss improved from 1.80873 to 1.80744, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7638 - mean_absolute_error: 0.8775 - mean_squared_error: 1.7638 - val_loss: 1.8074 - val_mean_absolute_error: 0.8782 - val_mean_squared_error: 1.8074\n",
            "Epoch 329/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.7593 - mean_absolute_error: 0.8786 - mean_squared_error: 1.7593\n",
            "Epoch 329: val_loss improved from 1.80744 to 1.80732, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7632 - mean_absolute_error: 0.8805 - mean_squared_error: 1.7632 - val_loss: 1.8073 - val_mean_absolute_error: 0.8762 - val_mean_squared_error: 1.8073\n",
            "Epoch 330/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.7271 - mean_absolute_error: 0.8719 - mean_squared_error: 1.7271\n",
            "Epoch 330: val_loss improved from 1.80732 to 1.80626, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7612 - mean_absolute_error: 0.8803 - mean_squared_error: 1.7612 - val_loss: 1.8063 - val_mean_absolute_error: 0.8783 - val_mean_squared_error: 1.8063\n",
            "Epoch 331/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.7615 - mean_absolute_error: 0.8778 - mean_squared_error: 1.7615\n",
            "Epoch 331: val_loss improved from 1.80626 to 1.80386, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7607 - mean_absolute_error: 0.8767 - mean_squared_error: 1.7607 - val_loss: 1.8039 - val_mean_absolute_error: 0.8777 - val_mean_squared_error: 1.8039\n",
            "Epoch 332/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.7499 - mean_absolute_error: 0.8757 - mean_squared_error: 1.7499\n",
            "Epoch 332: val_loss improved from 1.80386 to 1.80369, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7593 - mean_absolute_error: 0.8789 - mean_squared_error: 1.7593 - val_loss: 1.8037 - val_mean_absolute_error: 0.8790 - val_mean_squared_error: 1.8037\n",
            "Epoch 333/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.7591 - mean_absolute_error: 0.8804 - mean_squared_error: 1.7591\n",
            "Epoch 333: val_loss improved from 1.80369 to 1.80127, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7591 - mean_absolute_error: 0.8804 - mean_squared_error: 1.7591 - val_loss: 1.8013 - val_mean_absolute_error: 0.8749 - val_mean_squared_error: 1.8013\n",
            "Epoch 334/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.7406 - mean_absolute_error: 0.8703 - mean_squared_error: 1.7406\n",
            "Epoch 334: val_loss did not improve from 1.80127\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7571 - mean_absolute_error: 0.8754 - mean_squared_error: 1.7571 - val_loss: 1.8026 - val_mean_absolute_error: 0.8835 - val_mean_squared_error: 1.8026\n",
            "Epoch 335/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.7434 - mean_absolute_error: 0.8747 - mean_squared_error: 1.7434\n",
            "Epoch 335: val_loss improved from 1.80127 to 1.79996, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7536 - mean_absolute_error: 0.8768 - mean_squared_error: 1.7536 - val_loss: 1.8000 - val_mean_absolute_error: 0.8739 - val_mean_squared_error: 1.8000\n",
            "Epoch 336/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.7462 - mean_absolute_error: 0.8727 - mean_squared_error: 1.7462\n",
            "Epoch 336: val_loss did not improve from 1.79996\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7536 - mean_absolute_error: 0.8766 - mean_squared_error: 1.7536 - val_loss: 1.8005 - val_mean_absolute_error: 0.8805 - val_mean_squared_error: 1.8005\n",
            "Epoch 337/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.7575 - mean_absolute_error: 0.8815 - mean_squared_error: 1.7575\n",
            "Epoch 337: val_loss improved from 1.79996 to 1.79605, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7535 - mean_absolute_error: 0.8797 - mean_squared_error: 1.7535 - val_loss: 1.7961 - val_mean_absolute_error: 0.8770 - val_mean_squared_error: 1.7961\n",
            "Epoch 338/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.7629 - mean_absolute_error: 0.8793 - mean_squared_error: 1.7629\n",
            "Epoch 338: val_loss improved from 1.79605 to 1.79593, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7520 - mean_absolute_error: 0.8763 - mean_squared_error: 1.7520 - val_loss: 1.7959 - val_mean_absolute_error: 0.8793 - val_mean_squared_error: 1.7959\n",
            "Epoch 339/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.7456 - mean_absolute_error: 0.8779 - mean_squared_error: 1.7456\n",
            "Epoch 339: val_loss did not improve from 1.79593\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7504 - mean_absolute_error: 0.8790 - mean_squared_error: 1.7504 - val_loss: 1.7982 - val_mean_absolute_error: 0.8736 - val_mean_squared_error: 1.7982\n",
            "Epoch 340/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.7398 - mean_absolute_error: 0.8734 - mean_squared_error: 1.7398\n",
            "Epoch 340: val_loss improved from 1.79593 to 1.79200, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7482 - mean_absolute_error: 0.8751 - mean_squared_error: 1.7482 - val_loss: 1.7920 - val_mean_absolute_error: 0.8760 - val_mean_squared_error: 1.7920\n",
            "Epoch 341/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.7799 - mean_absolute_error: 0.8846 - mean_squared_error: 1.7799\n",
            "Epoch 341: val_loss did not improve from 1.79200\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7493 - mean_absolute_error: 0.8774 - mean_squared_error: 1.7493 - val_loss: 1.7990 - val_mean_absolute_error: 0.8716 - val_mean_squared_error: 1.7990\n",
            "Epoch 342/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.7619 - mean_absolute_error: 0.8802 - mean_squared_error: 1.7619\n",
            "Epoch 342: val_loss improved from 1.79200 to 1.78985, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7487 - mean_absolute_error: 0.8777 - mean_squared_error: 1.7487 - val_loss: 1.7898 - val_mean_absolute_error: 0.8740 - val_mean_squared_error: 1.7898\n",
            "Epoch 343/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.7405 - mean_absolute_error: 0.8713 - mean_squared_error: 1.7405\n",
            "Epoch 343: val_loss improved from 1.78985 to 1.78875, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7443 - mean_absolute_error: 0.8730 - mean_squared_error: 1.7443 - val_loss: 1.7888 - val_mean_absolute_error: 0.8816 - val_mean_squared_error: 1.7888\n",
            "Epoch 344/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.7974 - mean_absolute_error: 0.8919 - mean_squared_error: 1.7974\n",
            "Epoch 344: val_loss improved from 1.78875 to 1.78563, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7463 - mean_absolute_error: 0.8780 - mean_squared_error: 1.7463 - val_loss: 1.7856 - val_mean_absolute_error: 0.8753 - val_mean_squared_error: 1.7856\n",
            "Epoch 345/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.7344 - mean_absolute_error: 0.8740 - mean_squared_error: 1.7344\n",
            "Epoch 345: val_loss improved from 1.78563 to 1.78392, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7443 - mean_absolute_error: 0.8747 - mean_squared_error: 1.7443 - val_loss: 1.7839 - val_mean_absolute_error: 0.8737 - val_mean_squared_error: 1.7839\n",
            "Epoch 346/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.7028 - mean_absolute_error: 0.8677 - mean_squared_error: 1.7028\n",
            "Epoch 346: val_loss improved from 1.78392 to 1.78279, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7414 - mean_absolute_error: 0.8745 - mean_squared_error: 1.7414 - val_loss: 1.7828 - val_mean_absolute_error: 0.8733 - val_mean_squared_error: 1.7828\n",
            "Epoch 347/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.7360 - mean_absolute_error: 0.8787 - mean_squared_error: 1.7360\n",
            "Epoch 347: val_loss improved from 1.78279 to 1.78183, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7395 - mean_absolute_error: 0.8788 - mean_squared_error: 1.7395 - val_loss: 1.7818 - val_mean_absolute_error: 0.8704 - val_mean_squared_error: 1.7818\n",
            "Epoch 348/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.7283 - mean_absolute_error: 0.8713 - mean_squared_error: 1.7283\n",
            "Epoch 348: val_loss improved from 1.78183 to 1.77992, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7400 - mean_absolute_error: 0.8740 - mean_squared_error: 1.7400 - val_loss: 1.7799 - val_mean_absolute_error: 0.8699 - val_mean_squared_error: 1.7799\n",
            "Epoch 349/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.7473 - mean_absolute_error: 0.8745 - mean_squared_error: 1.7473\n",
            "Epoch 349: val_loss improved from 1.77992 to 1.77773, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7384 - mean_absolute_error: 0.8727 - mean_squared_error: 1.7384 - val_loss: 1.7777 - val_mean_absolute_error: 0.8739 - val_mean_squared_error: 1.7777\n",
            "Epoch 350/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.7284 - mean_absolute_error: 0.8728 - mean_squared_error: 1.7284\n",
            "Epoch 350: val_loss improved from 1.77773 to 1.77734, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7357 - mean_absolute_error: 0.8739 - mean_squared_error: 1.7357 - val_loss: 1.7773 - val_mean_absolute_error: 0.8708 - val_mean_squared_error: 1.7773\n",
            "Epoch 351/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.7352 - mean_absolute_error: 0.8760 - mean_squared_error: 1.7352\n",
            "Epoch 351: val_loss improved from 1.77734 to 1.77684, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7357 - mean_absolute_error: 0.8760 - mean_squared_error: 1.7357 - val_loss: 1.7768 - val_mean_absolute_error: 0.8687 - val_mean_squared_error: 1.7768\n",
            "Epoch 352/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.7054 - mean_absolute_error: 0.8660 - mean_squared_error: 1.7054\n",
            "Epoch 352: val_loss improved from 1.77684 to 1.77496, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7328 - mean_absolute_error: 0.8709 - mean_squared_error: 1.7328 - val_loss: 1.7750 - val_mean_absolute_error: 0.8746 - val_mean_squared_error: 1.7750\n",
            "Epoch 353/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.7130 - mean_absolute_error: 0.8724 - mean_squared_error: 1.7130\n",
            "Epoch 353: val_loss improved from 1.77496 to 1.77277, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7335 - mean_absolute_error: 0.8758 - mean_squared_error: 1.7335 - val_loss: 1.7728 - val_mean_absolute_error: 0.8675 - val_mean_squared_error: 1.7728\n",
            "Epoch 354/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.7235 - mean_absolute_error: 0.8725 - mean_squared_error: 1.7235\n",
            "Epoch 354: val_loss improved from 1.77277 to 1.77008, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7295 - mean_absolute_error: 0.8760 - mean_squared_error: 1.7295 - val_loss: 1.7701 - val_mean_absolute_error: 0.8691 - val_mean_squared_error: 1.7701\n",
            "Epoch 355/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.7225 - mean_absolute_error: 0.8688 - mean_squared_error: 1.7225\n",
            "Epoch 355: val_loss improved from 1.77008 to 1.76904, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7283 - mean_absolute_error: 0.8706 - mean_squared_error: 1.7283 - val_loss: 1.7690 - val_mean_absolute_error: 0.8671 - val_mean_squared_error: 1.7690\n",
            "Epoch 356/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.7281 - mean_absolute_error: 0.8753 - mean_squared_error: 1.7281\n",
            "Epoch 356: val_loss did not improve from 1.76904\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7265 - mean_absolute_error: 0.8748 - mean_squared_error: 1.7265 - val_loss: 1.7731 - val_mean_absolute_error: 0.8646 - val_mean_squared_error: 1.7731\n",
            "Epoch 357/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.7266 - mean_absolute_error: 0.8718 - mean_squared_error: 1.7266\n",
            "Epoch 357: val_loss did not improve from 1.76904\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7260 - mean_absolute_error: 0.8715 - mean_squared_error: 1.7260 - val_loss: 1.7741 - val_mean_absolute_error: 0.8659 - val_mean_squared_error: 1.7741\n",
            "Epoch 358/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.7256 - mean_absolute_error: 0.8716 - mean_squared_error: 1.7256\n",
            "Epoch 358: val_loss improved from 1.76904 to 1.76752, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7250 - mean_absolute_error: 0.8717 - mean_squared_error: 1.7250 - val_loss: 1.7675 - val_mean_absolute_error: 0.8669 - val_mean_squared_error: 1.7675\n",
            "Epoch 359/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.7197 - mean_absolute_error: 0.8722 - mean_squared_error: 1.7197\n",
            "Epoch 359: val_loss improved from 1.76752 to 1.76203, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7231 - mean_absolute_error: 0.8722 - mean_squared_error: 1.7231 - val_loss: 1.7620 - val_mean_absolute_error: 0.8691 - val_mean_squared_error: 1.7620\n",
            "Epoch 360/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.7206 - mean_absolute_error: 0.8739 - mean_squared_error: 1.7206\n",
            "Epoch 360: val_loss improved from 1.76203 to 1.76016, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7208 - mean_absolute_error: 0.8726 - mean_squared_error: 1.7208 - val_loss: 1.7602 - val_mean_absolute_error: 0.8658 - val_mean_squared_error: 1.7602\n",
            "Epoch 361/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.7376 - mean_absolute_error: 0.8776 - mean_squared_error: 1.7376\n",
            "Epoch 361: val_loss did not improve from 1.76016\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7189 - mean_absolute_error: 0.8732 - mean_squared_error: 1.7189 - val_loss: 1.7633 - val_mean_absolute_error: 0.8737 - val_mean_squared_error: 1.7633\n",
            "Epoch 362/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.7010 - mean_absolute_error: 0.8624 - mean_squared_error: 1.7010\n",
            "Epoch 362: val_loss improved from 1.76016 to 1.75566, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7181 - mean_absolute_error: 0.8668 - mean_squared_error: 1.7181 - val_loss: 1.7557 - val_mean_absolute_error: 0.8734 - val_mean_squared_error: 1.7557\n",
            "Epoch 363/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.7111 - mean_absolute_error: 0.8703 - mean_squared_error: 1.7111\n",
            "Epoch 363: val_loss did not improve from 1.75566\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7165 - mean_absolute_error: 0.8728 - mean_squared_error: 1.7165 - val_loss: 1.7558 - val_mean_absolute_error: 0.8706 - val_mean_squared_error: 1.7558\n",
            "Epoch 364/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.7250 - mean_absolute_error: 0.8747 - mean_squared_error: 1.7250\n",
            "Epoch 364: val_loss improved from 1.75566 to 1.75221, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7150 - mean_absolute_error: 0.8728 - mean_squared_error: 1.7150 - val_loss: 1.7522 - val_mean_absolute_error: 0.8674 - val_mean_squared_error: 1.7522\n",
            "Epoch 365/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.7026 - mean_absolute_error: 0.8660 - mean_squared_error: 1.7026\n",
            "Epoch 365: val_loss improved from 1.75221 to 1.74960, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7121 - mean_absolute_error: 0.8690 - mean_squared_error: 1.7121 - val_loss: 1.7496 - val_mean_absolute_error: 0.8670 - val_mean_squared_error: 1.7496\n",
            "Epoch 366/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.6999 - mean_absolute_error: 0.8678 - mean_squared_error: 1.6999\n",
            "Epoch 366: val_loss improved from 1.74960 to 1.74823, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7111 - mean_absolute_error: 0.8697 - mean_squared_error: 1.7111 - val_loss: 1.7482 - val_mean_absolute_error: 0.8657 - val_mean_squared_error: 1.7482\n",
            "Epoch 367/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.7192 - mean_absolute_error: 0.8743 - mean_squared_error: 1.7192\n",
            "Epoch 367: val_loss improved from 1.74823 to 1.74644, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7105 - mean_absolute_error: 0.8726 - mean_squared_error: 1.7105 - val_loss: 1.7464 - val_mean_absolute_error: 0.8674 - val_mean_squared_error: 1.7464\n",
            "Epoch 368/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.7030 - mean_absolute_error: 0.8674 - mean_squared_error: 1.7030\n",
            "Epoch 368: val_loss improved from 1.74644 to 1.74613, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7093 - mean_absolute_error: 0.8702 - mean_squared_error: 1.7093 - val_loss: 1.7461 - val_mean_absolute_error: 0.8630 - val_mean_squared_error: 1.7461\n",
            "Epoch 369/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.6932 - mean_absolute_error: 0.8655 - mean_squared_error: 1.6932\n",
            "Epoch 369: val_loss did not improve from 1.74613\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7039 - mean_absolute_error: 0.8693 - mean_squared_error: 1.7039 - val_loss: 1.7561 - val_mean_absolute_error: 0.8608 - val_mean_squared_error: 1.7561\n",
            "Epoch 370/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.6949 - mean_absolute_error: 0.8654 - mean_squared_error: 1.6949\n",
            "Epoch 370: val_loss did not improve from 1.74613\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7042 - mean_absolute_error: 0.8670 - mean_squared_error: 1.7042 - val_loss: 1.7503 - val_mean_absolute_error: 0.8634 - val_mean_squared_error: 1.7503\n",
            "Epoch 371/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.7034 - mean_absolute_error: 0.8654 - mean_squared_error: 1.7034\n",
            "Epoch 371: val_loss improved from 1.74613 to 1.73923, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7013 - mean_absolute_error: 0.8678 - mean_squared_error: 1.7013 - val_loss: 1.7392 - val_mean_absolute_error: 0.8640 - val_mean_squared_error: 1.7392\n",
            "Epoch 372/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.6960 - mean_absolute_error: 0.8665 - mean_squared_error: 1.6960\n",
            "Epoch 372: val_loss improved from 1.73923 to 1.73639, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7006 - mean_absolute_error: 0.8691 - mean_squared_error: 1.7006 - val_loss: 1.7364 - val_mean_absolute_error: 0.8730 - val_mean_squared_error: 1.7364\n",
            "Epoch 373/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.7119 - mean_absolute_error: 0.8733 - mean_squared_error: 1.7119\n",
            "Epoch 373: val_loss improved from 1.73639 to 1.73580, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6985 - mean_absolute_error: 0.8712 - mean_squared_error: 1.6985 - val_loss: 1.7358 - val_mean_absolute_error: 0.8700 - val_mean_squared_error: 1.7358\n",
            "Epoch 374/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.6943 - mean_absolute_error: 0.8665 - mean_squared_error: 1.6943\n",
            "Epoch 374: val_loss did not improve from 1.73580\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6947 - mean_absolute_error: 0.8673 - mean_squared_error: 1.6947 - val_loss: 1.7384 - val_mean_absolute_error: 0.8642 - val_mean_squared_error: 1.7384\n",
            "Epoch 375/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.6953 - mean_absolute_error: 0.8686 - mean_squared_error: 1.6953\n",
            "Epoch 375: val_loss improved from 1.73580 to 1.72905, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6953 - mean_absolute_error: 0.8686 - mean_squared_error: 1.6953 - val_loss: 1.7291 - val_mean_absolute_error: 0.8647 - val_mean_squared_error: 1.7291\n",
            "Epoch 376/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.6871 - mean_absolute_error: 0.8645 - mean_squared_error: 1.6871\n",
            "Epoch 376: val_loss improved from 1.72905 to 1.72773, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6926 - mean_absolute_error: 0.8677 - mean_squared_error: 1.6926 - val_loss: 1.7277 - val_mean_absolute_error: 0.8604 - val_mean_squared_error: 1.7277\n",
            "Epoch 377/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.6832 - mean_absolute_error: 0.8634 - mean_squared_error: 1.6832\n",
            "Epoch 377: val_loss improved from 1.72773 to 1.72650, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6890 - mean_absolute_error: 0.8658 - mean_squared_error: 1.6890 - val_loss: 1.7265 - val_mean_absolute_error: 0.8666 - val_mean_squared_error: 1.7265\n",
            "Epoch 378/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.6911 - mean_absolute_error: 0.8678 - mean_squared_error: 1.6911\n",
            "Epoch 378: val_loss improved from 1.72650 to 1.72463, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6886 - mean_absolute_error: 0.8667 - mean_squared_error: 1.6886 - val_loss: 1.7246 - val_mean_absolute_error: 0.8630 - val_mean_squared_error: 1.7246\n",
            "Epoch 379/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.6805 - mean_absolute_error: 0.8669 - mean_squared_error: 1.6805\n",
            "Epoch 379: val_loss improved from 1.72463 to 1.71980, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6874 - mean_absolute_error: 0.8686 - mean_squared_error: 1.6874 - val_loss: 1.7198 - val_mean_absolute_error: 0.8607 - val_mean_squared_error: 1.7198\n",
            "Epoch 380/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.6772 - mean_absolute_error: 0.8642 - mean_squared_error: 1.6772\n",
            "Epoch 380: val_loss did not improve from 1.71980\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6834 - mean_absolute_error: 0.8667 - mean_squared_error: 1.6834 - val_loss: 1.7222 - val_mean_absolute_error: 0.8592 - val_mean_squared_error: 1.7222\n",
            "Epoch 381/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.6821 - mean_absolute_error: 0.8660 - mean_squared_error: 1.6821\n",
            "Epoch 381: val_loss improved from 1.71980 to 1.71371, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6817 - mean_absolute_error: 0.8654 - mean_squared_error: 1.6817 - val_loss: 1.7137 - val_mean_absolute_error: 0.8608 - val_mean_squared_error: 1.7137\n",
            "Epoch 382/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.6914 - mean_absolute_error: 0.8701 - mean_squared_error: 1.6914\n",
            "Epoch 382: val_loss improved from 1.71371 to 1.71220, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6790 - mean_absolute_error: 0.8673 - mean_squared_error: 1.6790 - val_loss: 1.7122 - val_mean_absolute_error: 0.8579 - val_mean_squared_error: 1.7122\n",
            "Epoch 383/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.6795 - mean_absolute_error: 0.8603 - mean_squared_error: 1.6795\n",
            "Epoch 383: val_loss improved from 1.71220 to 1.70909, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6770 - mean_absolute_error: 0.8607 - mean_squared_error: 1.6770 - val_loss: 1.7091 - val_mean_absolute_error: 0.8638 - val_mean_squared_error: 1.7091\n",
            "Epoch 384/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.6685 - mean_absolute_error: 0.8634 - mean_squared_error: 1.6685\n",
            "Epoch 384: val_loss improved from 1.70909 to 1.70679, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6743 - mean_absolute_error: 0.8645 - mean_squared_error: 1.6743 - val_loss: 1.7068 - val_mean_absolute_error: 0.8663 - val_mean_squared_error: 1.7068\n",
            "Epoch 385/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.6845 - mean_absolute_error: 0.8717 - mean_squared_error: 1.6845\n",
            "Epoch 385: val_loss improved from 1.70679 to 1.70385, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6723 - mean_absolute_error: 0.8677 - mean_squared_error: 1.6723 - val_loss: 1.7038 - val_mean_absolute_error: 0.8581 - val_mean_squared_error: 1.7038\n",
            "Epoch 386/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.6632 - mean_absolute_error: 0.8598 - mean_squared_error: 1.6632\n",
            "Epoch 386: val_loss improved from 1.70385 to 1.70282, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6712 - mean_absolute_error: 0.8619 - mean_squared_error: 1.6712 - val_loss: 1.7028 - val_mean_absolute_error: 0.8625 - val_mean_squared_error: 1.7028\n",
            "Epoch 387/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.6657 - mean_absolute_error: 0.8640 - mean_squared_error: 1.6657\n",
            "Epoch 387: val_loss improved from 1.70282 to 1.69733, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6698 - mean_absolute_error: 0.8654 - mean_squared_error: 1.6698 - val_loss: 1.6973 - val_mean_absolute_error: 0.8577 - val_mean_squared_error: 1.6973\n",
            "Epoch 388/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.6598 - mean_absolute_error: 0.8612 - mean_squared_error: 1.6598\n",
            "Epoch 388: val_loss improved from 1.69733 to 1.69714, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6650 - mean_absolute_error: 0.8626 - mean_squared_error: 1.6650 - val_loss: 1.6971 - val_mean_absolute_error: 0.8577 - val_mean_squared_error: 1.6971\n",
            "Epoch 389/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.6411 - mean_absolute_error: 0.8549 - mean_squared_error: 1.6411\n",
            "Epoch 389: val_loss improved from 1.69714 to 1.69214, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6624 - mean_absolute_error: 0.8593 - mean_squared_error: 1.6624 - val_loss: 1.6921 - val_mean_absolute_error: 0.8649 - val_mean_squared_error: 1.6921\n",
            "Epoch 390/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.6636 - mean_absolute_error: 0.8647 - mean_squared_error: 1.6636\n",
            "Epoch 390: val_loss improved from 1.69214 to 1.69007, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6619 - mean_absolute_error: 0.8635 - mean_squared_error: 1.6619 - val_loss: 1.6901 - val_mean_absolute_error: 0.8548 - val_mean_squared_error: 1.6901\n",
            "Epoch 391/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.6266 - mean_absolute_error: 0.8560 - mean_squared_error: 1.6266\n",
            "Epoch 391: val_loss improved from 1.69007 to 1.68900, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6603 - mean_absolute_error: 0.8624 - mean_squared_error: 1.6603 - val_loss: 1.6890 - val_mean_absolute_error: 0.8575 - val_mean_squared_error: 1.6890\n",
            "Epoch 392/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.6579 - mean_absolute_error: 0.8619 - mean_squared_error: 1.6579\n",
            "Epoch 392: val_loss improved from 1.68900 to 1.68770, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6543 - mean_absolute_error: 0.8619 - mean_squared_error: 1.6543 - val_loss: 1.6877 - val_mean_absolute_error: 0.8622 - val_mean_squared_error: 1.6877\n",
            "Epoch 393/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.6328 - mean_absolute_error: 0.8571 - mean_squared_error: 1.6328\n",
            "Epoch 393: val_loss improved from 1.68770 to 1.68281, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6546 - mean_absolute_error: 0.8628 - mean_squared_error: 1.6546 - val_loss: 1.6828 - val_mean_absolute_error: 0.8501 - val_mean_squared_error: 1.6828\n",
            "Epoch 394/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.6501 - mean_absolute_error: 0.8542 - mean_squared_error: 1.6501\n",
            "Epoch 394: val_loss improved from 1.68281 to 1.67895, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6501 - mean_absolute_error: 0.8542 - mean_squared_error: 1.6501 - val_loss: 1.6790 - val_mean_absolute_error: 0.8631 - val_mean_squared_error: 1.6790\n",
            "Epoch 395/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.6374 - mean_absolute_error: 0.8582 - mean_squared_error: 1.6374\n",
            "Epoch 395: val_loss improved from 1.67895 to 1.67539, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6474 - mean_absolute_error: 0.8612 - mean_squared_error: 1.6474 - val_loss: 1.6754 - val_mean_absolute_error: 0.8511 - val_mean_squared_error: 1.6754\n",
            "Epoch 396/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.6335 - mean_absolute_error: 0.8580 - mean_squared_error: 1.6335\n",
            "Epoch 396: val_loss did not improve from 1.67539\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6455 - mean_absolute_error: 0.8620 - mean_squared_error: 1.6455 - val_loss: 1.6779 - val_mean_absolute_error: 0.8487 - val_mean_squared_error: 1.6779\n",
            "Epoch 397/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.6425 - mean_absolute_error: 0.8553 - mean_squared_error: 1.6425\n",
            "Epoch 397: val_loss improved from 1.67539 to 1.66838, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6425 - mean_absolute_error: 0.8553 - mean_squared_error: 1.6425 - val_loss: 1.6684 - val_mean_absolute_error: 0.8504 - val_mean_squared_error: 1.6684\n",
            "Epoch 398/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.6371 - mean_absolute_error: 0.8555 - mean_squared_error: 1.6371\n",
            "Epoch 398: val_loss improved from 1.66838 to 1.66449, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6400 - mean_absolute_error: 0.8564 - mean_squared_error: 1.6400 - val_loss: 1.6645 - val_mean_absolute_error: 0.8540 - val_mean_squared_error: 1.6645\n",
            "Epoch 399/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.6275 - mean_absolute_error: 0.8562 - mean_squared_error: 1.6275\n",
            "Epoch 399: val_loss improved from 1.66449 to 1.66122, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6366 - mean_absolute_error: 0.8570 - mean_squared_error: 1.6366 - val_loss: 1.6612 - val_mean_absolute_error: 0.8503 - val_mean_squared_error: 1.6612\n",
            "Epoch 400/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.6390 - mean_absolute_error: 0.8585 - mean_squared_error: 1.6390\n",
            "Epoch 400: val_loss did not improve from 1.66122\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6347 - mean_absolute_error: 0.8569 - mean_squared_error: 1.6347 - val_loss: 1.6614 - val_mean_absolute_error: 0.8464 - val_mean_squared_error: 1.6614\n",
            "Epoch 401/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 1.6051 - mean_absolute_error: 0.8463 - mean_squared_error: 1.6051\n",
            "Epoch 401: val_loss improved from 1.66122 to 1.65568, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6309 - mean_absolute_error: 0.8559 - mean_squared_error: 1.6309 - val_loss: 1.6557 - val_mean_absolute_error: 0.8473 - val_mean_squared_error: 1.6557\n",
            "Epoch 402/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.6253 - mean_absolute_error: 0.8503 - mean_squared_error: 1.6253\n",
            "Epoch 402: val_loss improved from 1.65568 to 1.65211, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6289 - mean_absolute_error: 0.8525 - mean_squared_error: 1.6289 - val_loss: 1.6521 - val_mean_absolute_error: 0.8492 - val_mean_squared_error: 1.6521\n",
            "Epoch 403/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.6196 - mean_absolute_error: 0.8546 - mean_squared_error: 1.6196\n",
            "Epoch 403: val_loss did not improve from 1.65211\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6231 - mean_absolute_error: 0.8548 - mean_squared_error: 1.6231 - val_loss: 1.6533 - val_mean_absolute_error: 0.8526 - val_mean_squared_error: 1.6533\n",
            "Epoch 404/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.6288 - mean_absolute_error: 0.8556 - mean_squared_error: 1.6288\n",
            "Epoch 404: val_loss improved from 1.65211 to 1.64509, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6217 - mean_absolute_error: 0.8546 - mean_squared_error: 1.6217 - val_loss: 1.6451 - val_mean_absolute_error: 0.8419 - val_mean_squared_error: 1.6451\n",
            "Epoch 405/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.6357 - mean_absolute_error: 0.8555 - mean_squared_error: 1.6357\n",
            "Epoch 405: val_loss did not improve from 1.64509\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6173 - mean_absolute_error: 0.8500 - mean_squared_error: 1.6173 - val_loss: 1.6451 - val_mean_absolute_error: 0.8410 - val_mean_squared_error: 1.6451\n",
            "Epoch 406/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.6199 - mean_absolute_error: 0.8522 - mean_squared_error: 1.6199\n",
            "Epoch 406: val_loss improved from 1.64509 to 1.63832, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6142 - mean_absolute_error: 0.8502 - mean_squared_error: 1.6142 - val_loss: 1.6383 - val_mean_absolute_error: 0.8491 - val_mean_squared_error: 1.6383\n",
            "Epoch 407/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.6033 - mean_absolute_error: 0.8453 - mean_squared_error: 1.6033\n",
            "Epoch 407: val_loss improved from 1.63832 to 1.63342, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6107 - mean_absolute_error: 0.8481 - mean_squared_error: 1.6107 - val_loss: 1.6334 - val_mean_absolute_error: 0.8450 - val_mean_squared_error: 1.6334\n",
            "Epoch 408/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.6027 - mean_absolute_error: 0.8502 - mean_squared_error: 1.6027\n",
            "Epoch 408: val_loss improved from 1.63342 to 1.62957, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6090 - mean_absolute_error: 0.8517 - mean_squared_error: 1.6090 - val_loss: 1.6296 - val_mean_absolute_error: 0.8398 - val_mean_squared_error: 1.6296\n",
            "Epoch 409/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.5903 - mean_absolute_error: 0.8462 - mean_squared_error: 1.5903\n",
            "Epoch 409: val_loss improved from 1.62957 to 1.62526, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6041 - mean_absolute_error: 0.8481 - mean_squared_error: 1.6041 - val_loss: 1.6253 - val_mean_absolute_error: 0.8413 - val_mean_squared_error: 1.6253\n",
            "Epoch 410/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.6111 - mean_absolute_error: 0.8483 - mean_squared_error: 1.6111\n",
            "Epoch 410: val_loss did not improve from 1.62526\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6021 - mean_absolute_error: 0.8465 - mean_squared_error: 1.6021 - val_loss: 1.6262 - val_mean_absolute_error: 0.8531 - val_mean_squared_error: 1.6262\n",
            "Epoch 411/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.5861 - mean_absolute_error: 0.8406 - mean_squared_error: 1.5861\n",
            "Epoch 411: val_loss improved from 1.62526 to 1.61867, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5976 - mean_absolute_error: 0.8453 - mean_squared_error: 1.5976 - val_loss: 1.6187 - val_mean_absolute_error: 0.8422 - val_mean_squared_error: 1.6187\n",
            "Epoch 412/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.5901 - mean_absolute_error: 0.8470 - mean_squared_error: 1.5901\n",
            "Epoch 412: val_loss improved from 1.61867 to 1.61427, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5939 - mean_absolute_error: 0.8467 - mean_squared_error: 1.5939 - val_loss: 1.6143 - val_mean_absolute_error: 0.8402 - val_mean_squared_error: 1.6143\n",
            "Epoch 413/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.5926 - mean_absolute_error: 0.8464 - mean_squared_error: 1.5926\n",
            "Epoch 413: val_loss improved from 1.61427 to 1.60918, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5897 - mean_absolute_error: 0.8455 - mean_squared_error: 1.5897 - val_loss: 1.6092 - val_mean_absolute_error: 0.8370 - val_mean_squared_error: 1.6092\n",
            "Epoch 414/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.5895 - mean_absolute_error: 0.8411 - mean_squared_error: 1.5895\n",
            "Epoch 414: val_loss improved from 1.60918 to 1.60639, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5871 - mean_absolute_error: 0.8401 - mean_squared_error: 1.5871 - val_loss: 1.6064 - val_mean_absolute_error: 0.8389 - val_mean_squared_error: 1.6064\n",
            "Epoch 415/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.5827 - mean_absolute_error: 0.8408 - mean_squared_error: 1.5827\n",
            "Epoch 415: val_loss improved from 1.60639 to 1.60447, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5829 - mean_absolute_error: 0.8427 - mean_squared_error: 1.5829 - val_loss: 1.6045 - val_mean_absolute_error: 0.8329 - val_mean_squared_error: 1.6045\n",
            "Epoch 416/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.5844 - mean_absolute_error: 0.8428 - mean_squared_error: 1.5844\n",
            "Epoch 416: val_loss improved from 1.60447 to 1.59829, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.5792 - mean_absolute_error: 0.8419 - mean_squared_error: 1.5792 - val_loss: 1.5983 - val_mean_absolute_error: 0.8392 - val_mean_squared_error: 1.5983\n",
            "Epoch 417/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.5551 - mean_absolute_error: 0.8360 - mean_squared_error: 1.5551\n",
            "Epoch 417: val_loss improved from 1.59829 to 1.59295, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5759 - mean_absolute_error: 0.8395 - mean_squared_error: 1.5759 - val_loss: 1.5929 - val_mean_absolute_error: 0.8332 - val_mean_squared_error: 1.5929\n",
            "Epoch 418/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.5718 - mean_absolute_error: 0.8400 - mean_squared_error: 1.5718\n",
            "Epoch 418: val_loss improved from 1.59295 to 1.59105, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.5718 - mean_absolute_error: 0.8400 - mean_squared_error: 1.5718 - val_loss: 1.5911 - val_mean_absolute_error: 0.8282 - val_mean_squared_error: 1.5911\n",
            "Epoch 419/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.5601 - mean_absolute_error: 0.8362 - mean_squared_error: 1.5601\n",
            "Epoch 419: val_loss improved from 1.59105 to 1.58572, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5678 - mean_absolute_error: 0.8371 - mean_squared_error: 1.5678 - val_loss: 1.5857 - val_mean_absolute_error: 0.8306 - val_mean_squared_error: 1.5857\n",
            "Epoch 420/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.5621 - mean_absolute_error: 0.8371 - mean_squared_error: 1.5621\n",
            "Epoch 420: val_loss improved from 1.58572 to 1.58097, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5621 - mean_absolute_error: 0.8371 - mean_squared_error: 1.5621 - val_loss: 1.5810 - val_mean_absolute_error: 0.8250 - val_mean_squared_error: 1.5810\n",
            "Epoch 421/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.5601 - mean_absolute_error: 0.8347 - mean_squared_error: 1.5601\n",
            "Epoch 421: val_loss improved from 1.58097 to 1.57721, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5601 - mean_absolute_error: 0.8347 - mean_squared_error: 1.5601 - val_loss: 1.5772 - val_mean_absolute_error: 0.8274 - val_mean_squared_error: 1.5772\n",
            "Epoch 422/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.5476 - mean_absolute_error: 0.8315 - mean_squared_error: 1.5476\n",
            "Epoch 422: val_loss improved from 1.57721 to 1.57157, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5552 - mean_absolute_error: 0.8321 - mean_squared_error: 1.5552 - val_loss: 1.5716 - val_mean_absolute_error: 0.8320 - val_mean_squared_error: 1.5716\n",
            "Epoch 423/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.5550 - mean_absolute_error: 0.8315 - mean_squared_error: 1.5550\n",
            "Epoch 423: val_loss improved from 1.57157 to 1.56975, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5505 - mean_absolute_error: 0.8313 - mean_squared_error: 1.5505 - val_loss: 1.5697 - val_mean_absolute_error: 0.8315 - val_mean_squared_error: 1.5697\n",
            "Epoch 424/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.5526 - mean_absolute_error: 0.8352 - mean_squared_error: 1.5526\n",
            "Epoch 424: val_loss improved from 1.56975 to 1.56528, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5474 - mean_absolute_error: 0.8341 - mean_squared_error: 1.5474 - val_loss: 1.5653 - val_mean_absolute_error: 0.8226 - val_mean_squared_error: 1.5653\n",
            "Epoch 425/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.5361 - mean_absolute_error: 0.8294 - mean_squared_error: 1.5361\n",
            "Epoch 425: val_loss improved from 1.56528 to 1.55974, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5437 - mean_absolute_error: 0.8321 - mean_squared_error: 1.5437 - val_loss: 1.5597 - val_mean_absolute_error: 0.8193 - val_mean_squared_error: 1.5597\n",
            "Epoch 426/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.5353 - mean_absolute_error: 0.8277 - mean_squared_error: 1.5353\n",
            "Epoch 426: val_loss improved from 1.55974 to 1.55306, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5374 - mean_absolute_error: 0.8267 - mean_squared_error: 1.5374 - val_loss: 1.5531 - val_mean_absolute_error: 0.8268 - val_mean_squared_error: 1.5531\n",
            "Epoch 427/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.5194 - mean_absolute_error: 0.8248 - mean_squared_error: 1.5194\n",
            "Epoch 427: val_loss improved from 1.55306 to 1.54860, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5317 - mean_absolute_error: 0.8274 - mean_squared_error: 1.5317 - val_loss: 1.5486 - val_mean_absolute_error: 0.8245 - val_mean_squared_error: 1.5486\n",
            "Epoch 428/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.5239 - mean_absolute_error: 0.8277 - mean_squared_error: 1.5239\n",
            "Epoch 428: val_loss improved from 1.54860 to 1.54247, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5291 - mean_absolute_error: 0.8272 - mean_squared_error: 1.5291 - val_loss: 1.5425 - val_mean_absolute_error: 0.8221 - val_mean_squared_error: 1.5425\n",
            "Epoch 429/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.5146 - mean_absolute_error: 0.8205 - mean_squared_error: 1.5146\n",
            "Epoch 429: val_loss improved from 1.54247 to 1.53870, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5242 - mean_absolute_error: 0.8233 - mean_squared_error: 1.5242 - val_loss: 1.5387 - val_mean_absolute_error: 0.8228 - val_mean_squared_error: 1.5387\n",
            "Epoch 430/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.5445 - mean_absolute_error: 0.8321 - mean_squared_error: 1.5445\n",
            "Epoch 430: val_loss improved from 1.53870 to 1.53422, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5206 - mean_absolute_error: 0.8244 - mean_squared_error: 1.5206 - val_loss: 1.5342 - val_mean_absolute_error: 0.8211 - val_mean_squared_error: 1.5342\n",
            "Epoch 431/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.5182 - mean_absolute_error: 0.8229 - mean_squared_error: 1.5182\n",
            "Epoch 431: val_loss did not improve from 1.53422\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5133 - mean_absolute_error: 0.8216 - mean_squared_error: 1.5133 - val_loss: 1.5424 - val_mean_absolute_error: 0.8163 - val_mean_squared_error: 1.5424\n",
            "Epoch 432/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.5017 - mean_absolute_error: 0.8170 - mean_squared_error: 1.5017\n",
            "Epoch 432: val_loss improved from 1.53422 to 1.52564, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5105 - mean_absolute_error: 0.8194 - mean_squared_error: 1.5105 - val_loss: 1.5256 - val_mean_absolute_error: 0.8182 - val_mean_squared_error: 1.5256\n",
            "Epoch 433/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.5030 - mean_absolute_error: 0.8178 - mean_squared_error: 1.5030\n",
            "Epoch 433: val_loss improved from 1.52564 to 1.51973, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5053 - mean_absolute_error: 0.8199 - mean_squared_error: 1.5053 - val_loss: 1.5197 - val_mean_absolute_error: 0.8129 - val_mean_squared_error: 1.5197\n",
            "Epoch 434/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.4940 - mean_absolute_error: 0.8153 - mean_squared_error: 1.4940\n",
            "Epoch 434: val_loss improved from 1.51973 to 1.51483, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5003 - mean_absolute_error: 0.8170 - mean_squared_error: 1.5003 - val_loss: 1.5148 - val_mean_absolute_error: 0.8145 - val_mean_squared_error: 1.5148\n",
            "Epoch 435/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.4886 - mean_absolute_error: 0.8086 - mean_squared_error: 1.4886\n",
            "Epoch 435: val_loss did not improve from 1.51483\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4960 - mean_absolute_error: 0.8149 - mean_squared_error: 1.4960 - val_loss: 1.5157 - val_mean_absolute_error: 0.8203 - val_mean_squared_error: 1.5157\n",
            "Epoch 436/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.4896 - mean_absolute_error: 0.8138 - mean_squared_error: 1.4896\n",
            "Epoch 436: val_loss improved from 1.51483 to 1.50590, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4911 - mean_absolute_error: 0.8148 - mean_squared_error: 1.4911 - val_loss: 1.5059 - val_mean_absolute_error: 0.8096 - val_mean_squared_error: 1.5059\n",
            "Epoch 437/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.5012 - mean_absolute_error: 0.8185 - mean_squared_error: 1.5012\n",
            "Epoch 437: val_loss improved from 1.50590 to 1.49973, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4862 - mean_absolute_error: 0.8141 - mean_squared_error: 1.4862 - val_loss: 1.4997 - val_mean_absolute_error: 0.8092 - val_mean_squared_error: 1.4997\n",
            "Epoch 438/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.4815 - mean_absolute_error: 0.8106 - mean_squared_error: 1.4815\n",
            "Epoch 438: val_loss improved from 1.49973 to 1.49744, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4814 - mean_absolute_error: 0.8123 - mean_squared_error: 1.4814 - val_loss: 1.4974 - val_mean_absolute_error: 0.8084 - val_mean_squared_error: 1.4974\n",
            "Epoch 439/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 1.4966 - mean_absolute_error: 0.8186 - mean_squared_error: 1.4966\n",
            "Epoch 439: val_loss improved from 1.49744 to 1.49014, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4745 - mean_absolute_error: 0.8113 - mean_squared_error: 1.4745 - val_loss: 1.4901 - val_mean_absolute_error: 0.8070 - val_mean_squared_error: 1.4901\n",
            "Epoch 440/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.4697 - mean_absolute_error: 0.8050 - mean_squared_error: 1.4697\n",
            "Epoch 440: val_loss improved from 1.49014 to 1.48378, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4693 - mean_absolute_error: 0.8061 - mean_squared_error: 1.4693 - val_loss: 1.4838 - val_mean_absolute_error: 0.8076 - val_mean_squared_error: 1.4838\n",
            "Epoch 441/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.4735 - mean_absolute_error: 0.8102 - mean_squared_error: 1.4735\n",
            "Epoch 441: val_loss improved from 1.48378 to 1.48023, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4640 - mean_absolute_error: 0.8080 - mean_squared_error: 1.4640 - val_loss: 1.4802 - val_mean_absolute_error: 0.8026 - val_mean_squared_error: 1.4802\n",
            "Epoch 442/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.4490 - mean_absolute_error: 0.8030 - mean_squared_error: 1.4490\n",
            "Epoch 442: val_loss improved from 1.48023 to 1.47406, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4604 - mean_absolute_error: 0.8044 - mean_squared_error: 1.4604 - val_loss: 1.4741 - val_mean_absolute_error: 0.8030 - val_mean_squared_error: 1.4741\n",
            "Epoch 443/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.4511 - mean_absolute_error: 0.8024 - mean_squared_error: 1.4511\n",
            "Epoch 443: val_loss improved from 1.47406 to 1.47255, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4539 - mean_absolute_error: 0.8017 - mean_squared_error: 1.4539 - val_loss: 1.4726 - val_mean_absolute_error: 0.8037 - val_mean_squared_error: 1.4726\n",
            "Epoch 444/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.4483 - mean_absolute_error: 0.8045 - mean_squared_error: 1.4483\n",
            "Epoch 444: val_loss improved from 1.47255 to 1.46249, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4486 - mean_absolute_error: 0.8044 - mean_squared_error: 1.4486 - val_loss: 1.4625 - val_mean_absolute_error: 0.7977 - val_mean_squared_error: 1.4625\n",
            "Epoch 445/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.4463 - mean_absolute_error: 0.8001 - mean_squared_error: 1.4463\n",
            "Epoch 445: val_loss improved from 1.46249 to 1.46112, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4424 - mean_absolute_error: 0.7994 - mean_squared_error: 1.4424 - val_loss: 1.4611 - val_mean_absolute_error: 0.8003 - val_mean_squared_error: 1.4611\n",
            "Epoch 446/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.4399 - mean_absolute_error: 0.7968 - mean_squared_error: 1.4399\n",
            "Epoch 446: val_loss improved from 1.46112 to 1.45256, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4389 - mean_absolute_error: 0.7989 - mean_squared_error: 1.4389 - val_loss: 1.4526 - val_mean_absolute_error: 0.7928 - val_mean_squared_error: 1.4526\n",
            "Epoch 447/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.4356 - mean_absolute_error: 0.7970 - mean_squared_error: 1.4356\n",
            "Epoch 447: val_loss improved from 1.45256 to 1.44761, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4329 - mean_absolute_error: 0.7963 - mean_squared_error: 1.4329 - val_loss: 1.4476 - val_mean_absolute_error: 0.7981 - val_mean_squared_error: 1.4476\n",
            "Epoch 448/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.4229 - mean_absolute_error: 0.7934 - mean_squared_error: 1.4229\n",
            "Epoch 448: val_loss improved from 1.44761 to 1.44001, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4271 - mean_absolute_error: 0.7943 - mean_squared_error: 1.4271 - val_loss: 1.4400 - val_mean_absolute_error: 0.7933 - val_mean_squared_error: 1.4400\n",
            "Epoch 449/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.4173 - mean_absolute_error: 0.7942 - mean_squared_error: 1.4173\n",
            "Epoch 449: val_loss improved from 1.44001 to 1.43382, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4207 - mean_absolute_error: 0.7951 - mean_squared_error: 1.4207 - val_loss: 1.4338 - val_mean_absolute_error: 0.7871 - val_mean_squared_error: 1.4338\n",
            "Epoch 450/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.4150 - mean_absolute_error: 0.7903 - mean_squared_error: 1.4150\n",
            "Epoch 450: val_loss improved from 1.43382 to 1.42831, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4143 - mean_absolute_error: 0.7897 - mean_squared_error: 1.4143 - val_loss: 1.4283 - val_mean_absolute_error: 0.7920 - val_mean_squared_error: 1.4283\n",
            "Epoch 451/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.4103 - mean_absolute_error: 0.7901 - mean_squared_error: 1.4103\n",
            "Epoch 451: val_loss improved from 1.42831 to 1.42409, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4084 - mean_absolute_error: 0.7888 - mean_squared_error: 1.4084 - val_loss: 1.4241 - val_mean_absolute_error: 0.7907 - val_mean_squared_error: 1.4241\n",
            "Epoch 452/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.3944 - mean_absolute_error: 0.7840 - mean_squared_error: 1.3944\n",
            "Epoch 452: val_loss improved from 1.42409 to 1.41720, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4022 - mean_absolute_error: 0.7861 - mean_squared_error: 1.4022 - val_loss: 1.4172 - val_mean_absolute_error: 0.7893 - val_mean_squared_error: 1.4172\n",
            "Epoch 453/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.4031 - mean_absolute_error: 0.7874 - mean_squared_error: 1.4031\n",
            "Epoch 453: val_loss improved from 1.41720 to 1.41238, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3964 - mean_absolute_error: 0.7856 - mean_squared_error: 1.3964 - val_loss: 1.4124 - val_mean_absolute_error: 0.7896 - val_mean_squared_error: 1.4124\n",
            "Epoch 454/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.3918 - mean_absolute_error: 0.7832 - mean_squared_error: 1.3918\n",
            "Epoch 454: val_loss improved from 1.41238 to 1.40614, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3912 - mean_absolute_error: 0.7850 - mean_squared_error: 1.3912 - val_loss: 1.4061 - val_mean_absolute_error: 0.7823 - val_mean_squared_error: 1.4061\n",
            "Epoch 455/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.3876 - mean_absolute_error: 0.7840 - mean_squared_error: 1.3876\n",
            "Epoch 455: val_loss improved from 1.40614 to 1.40059, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3846 - mean_absolute_error: 0.7822 - mean_squared_error: 1.3846 - val_loss: 1.4006 - val_mean_absolute_error: 0.7840 - val_mean_squared_error: 1.4006\n",
            "Epoch 456/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.3780 - mean_absolute_error: 0.7771 - mean_squared_error: 1.3780\n",
            "Epoch 456: val_loss improved from 1.40059 to 1.39371, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3780 - mean_absolute_error: 0.7771 - mean_squared_error: 1.3780 - val_loss: 1.3937 - val_mean_absolute_error: 0.7851 - val_mean_squared_error: 1.3937\n",
            "Epoch 457/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.3741 - mean_absolute_error: 0.7803 - mean_squared_error: 1.3741\n",
            "Epoch 457: val_loss improved from 1.39371 to 1.38754, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3705 - mean_absolute_error: 0.7791 - mean_squared_error: 1.3705 - val_loss: 1.3875 - val_mean_absolute_error: 0.7797 - val_mean_squared_error: 1.3875\n",
            "Epoch 458/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.3694 - mean_absolute_error: 0.7802 - mean_squared_error: 1.3694\n",
            "Epoch 458: val_loss did not improve from 1.38754\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3652 - mean_absolute_error: 0.7784 - mean_squared_error: 1.3652 - val_loss: 1.3878 - val_mean_absolute_error: 0.7737 - val_mean_squared_error: 1.3878\n",
            "Epoch 459/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.3638 - mean_absolute_error: 0.7760 - mean_squared_error: 1.3638\n",
            "Epoch 459: val_loss improved from 1.38754 to 1.37208, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3590 - mean_absolute_error: 0.7747 - mean_squared_error: 1.3590 - val_loss: 1.3721 - val_mean_absolute_error: 0.7749 - val_mean_squared_error: 1.3721\n",
            "Epoch 460/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.3550 - mean_absolute_error: 0.7742 - mean_squared_error: 1.3550\n",
            "Epoch 460: val_loss improved from 1.37208 to 1.36718, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3520 - mean_absolute_error: 0.7735 - mean_squared_error: 1.3520 - val_loss: 1.3672 - val_mean_absolute_error: 0.7723 - val_mean_squared_error: 1.3672\n",
            "Epoch 461/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.3524 - mean_absolute_error: 0.7716 - mean_squared_error: 1.3524\n",
            "Epoch 461: val_loss improved from 1.36718 to 1.36327, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3459 - mean_absolute_error: 0.7706 - mean_squared_error: 1.3459 - val_loss: 1.3633 - val_mean_absolute_error: 0.7693 - val_mean_squared_error: 1.3633\n",
            "Epoch 462/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.3367 - mean_absolute_error: 0.7660 - mean_squared_error: 1.3367\n",
            "Epoch 462: val_loss improved from 1.36327 to 1.35598, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3389 - mean_absolute_error: 0.7674 - mean_squared_error: 1.3389 - val_loss: 1.3560 - val_mean_absolute_error: 0.7699 - val_mean_squared_error: 1.3560\n",
            "Epoch 463/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.3395 - mean_absolute_error: 0.7690 - mean_squared_error: 1.3395\n",
            "Epoch 463: val_loss improved from 1.35598 to 1.35053, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3313 - mean_absolute_error: 0.7672 - mean_squared_error: 1.3313 - val_loss: 1.3505 - val_mean_absolute_error: 0.7693 - val_mean_squared_error: 1.3505\n",
            "Epoch 464/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.3257 - mean_absolute_error: 0.7640 - mean_squared_error: 1.3257\n",
            "Epoch 464: val_loss improved from 1.35053 to 1.34451, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3257 - mean_absolute_error: 0.7640 - mean_squared_error: 1.3257 - val_loss: 1.3445 - val_mean_absolute_error: 0.7721 - val_mean_squared_error: 1.3445\n",
            "Epoch 465/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.3087 - mean_absolute_error: 0.7599 - mean_squared_error: 1.3087\n",
            "Epoch 465: val_loss improved from 1.34451 to 1.34129, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3186 - mean_absolute_error: 0.7631 - mean_squared_error: 1.3186 - val_loss: 1.3413 - val_mean_absolute_error: 0.7708 - val_mean_squared_error: 1.3413\n",
            "Epoch 466/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.3309 - mean_absolute_error: 0.7690 - mean_squared_error: 1.3309\n",
            "Epoch 466: val_loss improved from 1.34129 to 1.33226, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3130 - mean_absolute_error: 0.7629 - mean_squared_error: 1.3130 - val_loss: 1.3323 - val_mean_absolute_error: 0.7620 - val_mean_squared_error: 1.3323\n",
            "Epoch 467/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.3028 - mean_absolute_error: 0.7594 - mean_squared_error: 1.3028\n",
            "Epoch 467: val_loss improved from 1.33226 to 1.32628, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3059 - mean_absolute_error: 0.7603 - mean_squared_error: 1.3059 - val_loss: 1.3263 - val_mean_absolute_error: 0.7623 - val_mean_squared_error: 1.3263\n",
            "Epoch 468/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.3055 - mean_absolute_error: 0.7568 - mean_squared_error: 1.3055\n",
            "Epoch 468: val_loss improved from 1.32628 to 1.31741, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3005 - mean_absolute_error: 0.7561 - mean_squared_error: 1.3005 - val_loss: 1.3174 - val_mean_absolute_error: 0.7611 - val_mean_squared_error: 1.3174\n",
            "Epoch 469/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.2859 - mean_absolute_error: 0.7539 - mean_squared_error: 1.2859\n",
            "Epoch 469: val_loss improved from 1.31741 to 1.31304, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2940 - mean_absolute_error: 0.7564 - mean_squared_error: 1.2940 - val_loss: 1.3130 - val_mean_absolute_error: 0.7645 - val_mean_squared_error: 1.3130\n",
            "Epoch 470/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.2762 - mean_absolute_error: 0.7546 - mean_squared_error: 1.2762\n",
            "Epoch 470: val_loss improved from 1.31304 to 1.30443, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2882 - mean_absolute_error: 0.7564 - mean_squared_error: 1.2882 - val_loss: 1.3044 - val_mean_absolute_error: 0.7561 - val_mean_squared_error: 1.3044\n",
            "Epoch 471/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.2900 - mean_absolute_error: 0.7548 - mean_squared_error: 1.2900\n",
            "Epoch 471: val_loss improved from 1.30443 to 1.29957, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2806 - mean_absolute_error: 0.7520 - mean_squared_error: 1.2806 - val_loss: 1.2996 - val_mean_absolute_error: 0.7580 - val_mean_squared_error: 1.2996\n",
            "Epoch 472/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.2701 - mean_absolute_error: 0.7514 - mean_squared_error: 1.2701\n",
            "Epoch 472: val_loss improved from 1.29957 to 1.29366, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2750 - mean_absolute_error: 0.7528 - mean_squared_error: 1.2750 - val_loss: 1.2937 - val_mean_absolute_error: 0.7532 - val_mean_squared_error: 1.2937\n",
            "Epoch 473/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.2719 - mean_absolute_error: 0.7469 - mean_squared_error: 1.2719\n",
            "Epoch 473: val_loss improved from 1.29366 to 1.28730, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2691 - mean_absolute_error: 0.7472 - mean_squared_error: 1.2691 - val_loss: 1.2873 - val_mean_absolute_error: 0.7562 - val_mean_squared_error: 1.2873\n",
            "Epoch 474/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.2503 - mean_absolute_error: 0.7463 - mean_squared_error: 1.2503\n",
            "Epoch 474: val_loss improved from 1.28730 to 1.28285, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2619 - mean_absolute_error: 0.7485 - mean_squared_error: 1.2619 - val_loss: 1.2828 - val_mean_absolute_error: 0.7478 - val_mean_squared_error: 1.2828\n",
            "Epoch 475/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.2529 - mean_absolute_error: 0.7455 - mean_squared_error: 1.2529\n",
            "Epoch 475: val_loss improved from 1.28285 to 1.27673, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2556 - mean_absolute_error: 0.7458 - mean_squared_error: 1.2556 - val_loss: 1.2767 - val_mean_absolute_error: 0.7426 - val_mean_squared_error: 1.2767\n",
            "Epoch 476/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.2726 - mean_absolute_error: 0.7495 - mean_squared_error: 1.2726\n",
            "Epoch 476: val_loss improved from 1.27673 to 1.26962, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2497 - mean_absolute_error: 0.7428 - mean_squared_error: 1.2497 - val_loss: 1.2696 - val_mean_absolute_error: 0.7422 - val_mean_squared_error: 1.2696\n",
            "Epoch 477/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.2455 - mean_absolute_error: 0.7401 - mean_squared_error: 1.2455\n",
            "Epoch 477: val_loss improved from 1.26962 to 1.26543, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2437 - mean_absolute_error: 0.7408 - mean_squared_error: 1.2437 - val_loss: 1.2654 - val_mean_absolute_error: 0.7460 - val_mean_squared_error: 1.2654\n",
            "Epoch 478/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.2416 - mean_absolute_error: 0.7406 - mean_squared_error: 1.2416\n",
            "Epoch 478: val_loss did not improve from 1.26543\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2376 - mean_absolute_error: 0.7400 - mean_squared_error: 1.2376 - val_loss: 1.2655 - val_mean_absolute_error: 0.7484 - val_mean_squared_error: 1.2655\n",
            "Epoch 479/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.2006 - mean_absolute_error: 0.7289 - mean_squared_error: 1.2006\n",
            "Epoch 479: val_loss improved from 1.26543 to 1.25708, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2328 - mean_absolute_error: 0.7372 - mean_squared_error: 1.2328 - val_loss: 1.2571 - val_mean_absolute_error: 0.7459 - val_mean_squared_error: 1.2571\n",
            "Epoch 480/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.2283 - mean_absolute_error: 0.7334 - mean_squared_error: 1.2283\n",
            "Epoch 480: val_loss improved from 1.25708 to 1.25060, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2266 - mean_absolute_error: 0.7346 - mean_squared_error: 1.2266 - val_loss: 1.2506 - val_mean_absolute_error: 0.7486 - val_mean_squared_error: 1.2506\n",
            "Epoch 481/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.2214 - mean_absolute_error: 0.7362 - mean_squared_error: 1.2214\n",
            "Epoch 481: val_loss improved from 1.25060 to 1.24623, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2218 - mean_absolute_error: 0.7376 - mean_squared_error: 1.2218 - val_loss: 1.2462 - val_mean_absolute_error: 0.7361 - val_mean_squared_error: 1.2462\n",
            "Epoch 482/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.2184 - mean_absolute_error: 0.7324 - mean_squared_error: 1.2184\n",
            "Epoch 482: val_loss improved from 1.24623 to 1.24038, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2157 - mean_absolute_error: 0.7322 - mean_squared_error: 1.2157 - val_loss: 1.2404 - val_mean_absolute_error: 0.7310 - val_mean_squared_error: 1.2404\n",
            "Epoch 483/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.1972 - mean_absolute_error: 0.7282 - mean_squared_error: 1.1972\n",
            "Epoch 483: val_loss improved from 1.24038 to 1.23286, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2108 - mean_absolute_error: 0.7314 - mean_squared_error: 1.2108 - val_loss: 1.2329 - val_mean_absolute_error: 0.7310 - val_mean_squared_error: 1.2329\n",
            "Epoch 484/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.1952 - mean_absolute_error: 0.7251 - mean_squared_error: 1.1952\n",
            "Epoch 484: val_loss did not improve from 1.23286\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2041 - mean_absolute_error: 0.7297 - mean_squared_error: 1.2041 - val_loss: 1.2366 - val_mean_absolute_error: 0.7360 - val_mean_squared_error: 1.2366\n",
            "Epoch 485/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.1887 - mean_absolute_error: 0.7174 - mean_squared_error: 1.1887\n",
            "Epoch 485: val_loss improved from 1.23286 to 1.22446, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1996 - mean_absolute_error: 0.7214 - mean_squared_error: 1.1996 - val_loss: 1.2245 - val_mean_absolute_error: 0.7339 - val_mean_squared_error: 1.2245\n",
            "Epoch 486/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.1986 - mean_absolute_error: 0.7263 - mean_squared_error: 1.1986\n",
            "Epoch 486: val_loss improved from 1.22446 to 1.21859, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1944 - mean_absolute_error: 0.7260 - mean_squared_error: 1.1944 - val_loss: 1.2186 - val_mean_absolute_error: 0.7297 - val_mean_squared_error: 1.2186\n",
            "Epoch 487/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.1884 - mean_absolute_error: 0.7224 - mean_squared_error: 1.1884\n",
            "Epoch 487: val_loss improved from 1.21859 to 1.21656, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1884 - mean_absolute_error: 0.7224 - mean_squared_error: 1.1884 - val_loss: 1.2166 - val_mean_absolute_error: 0.7264 - val_mean_squared_error: 1.2166\n",
            "Epoch 488/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.1818 - mean_absolute_error: 0.7217 - mean_squared_error: 1.1818\n",
            "Epoch 488: val_loss improved from 1.21656 to 1.21289, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1848 - mean_absolute_error: 0.7229 - mean_squared_error: 1.1848 - val_loss: 1.2129 - val_mean_absolute_error: 0.7290 - val_mean_squared_error: 1.2129\n",
            "Epoch 489/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.1742 - mean_absolute_error: 0.7161 - mean_squared_error: 1.1742\n",
            "Epoch 489: val_loss improved from 1.21289 to 1.20408, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1793 - mean_absolute_error: 0.7189 - mean_squared_error: 1.1793 - val_loss: 1.2041 - val_mean_absolute_error: 0.7241 - val_mean_squared_error: 1.2041\n",
            "Epoch 490/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.1617 - mean_absolute_error: 0.7112 - mean_squared_error: 1.1617\n",
            "Epoch 490: val_loss improved from 1.20408 to 1.20067, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1735 - mean_absolute_error: 0.7176 - mean_squared_error: 1.1735 - val_loss: 1.2007 - val_mean_absolute_error: 0.7217 - val_mean_squared_error: 1.2007\n",
            "Epoch 491/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.1682 - mean_absolute_error: 0.7188 - mean_squared_error: 1.1682\n",
            "Epoch 491: val_loss did not improve from 1.20067\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1689 - mean_absolute_error: 0.7186 - mean_squared_error: 1.1689 - val_loss: 1.2018 - val_mean_absolute_error: 0.7228 - val_mean_squared_error: 1.2018\n",
            "Epoch 492/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.1718 - mean_absolute_error: 0.7137 - mean_squared_error: 1.1718\n",
            "Epoch 492: val_loss improved from 1.20067 to 1.19532, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1654 - mean_absolute_error: 0.7114 - mean_squared_error: 1.1654 - val_loss: 1.1953 - val_mean_absolute_error: 0.7245 - val_mean_squared_error: 1.1953\n",
            "Epoch 493/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.1630 - mean_absolute_error: 0.7152 - mean_squared_error: 1.1630\n",
            "Epoch 493: val_loss improved from 1.19532 to 1.18716, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1599 - mean_absolute_error: 0.7142 - mean_squared_error: 1.1599 - val_loss: 1.1872 - val_mean_absolute_error: 0.7136 - val_mean_squared_error: 1.1872\n",
            "Epoch 494/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.1568 - mean_absolute_error: 0.7088 - mean_squared_error: 1.1568\n",
            "Epoch 494: val_loss improved from 1.18716 to 1.18514, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1549 - mean_absolute_error: 0.7096 - mean_squared_error: 1.1549 - val_loss: 1.1851 - val_mean_absolute_error: 0.7212 - val_mean_squared_error: 1.1851\n",
            "Epoch 495/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.1540 - mean_absolute_error: 0.7119 - mean_squared_error: 1.1540\n",
            "Epoch 495: val_loss improved from 1.18514 to 1.17879, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1503 - mean_absolute_error: 0.7092 - mean_squared_error: 1.1503 - val_loss: 1.1788 - val_mean_absolute_error: 0.7159 - val_mean_squared_error: 1.1788\n",
            "Epoch 496/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.1432 - mean_absolute_error: 0.7087 - mean_squared_error: 1.1432\n",
            "Epoch 496: val_loss improved from 1.17879 to 1.17681, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1453 - mean_absolute_error: 0.7084 - mean_squared_error: 1.1453 - val_loss: 1.1768 - val_mean_absolute_error: 0.7145 - val_mean_squared_error: 1.1768\n",
            "Epoch 497/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.1448 - mean_absolute_error: 0.7078 - mean_squared_error: 1.1448\n",
            "Epoch 497: val_loss did not improve from 1.17681\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1423 - mean_absolute_error: 0.7059 - mean_squared_error: 1.1423 - val_loss: 1.1776 - val_mean_absolute_error: 0.7172 - val_mean_squared_error: 1.1776\n",
            "Epoch 498/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.1334 - mean_absolute_error: 0.7034 - mean_squared_error: 1.1334\n",
            "Epoch 498: val_loss improved from 1.17681 to 1.16641, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1375 - mean_absolute_error: 0.7043 - mean_squared_error: 1.1375 - val_loss: 1.1664 - val_mean_absolute_error: 0.7109 - val_mean_squared_error: 1.1664\n",
            "Epoch 499/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.1319 - mean_absolute_error: 0.7027 - mean_squared_error: 1.1319\n",
            "Epoch 499: val_loss improved from 1.16641 to 1.16252, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1324 - mean_absolute_error: 0.7036 - mean_squared_error: 1.1324 - val_loss: 1.1625 - val_mean_absolute_error: 0.7107 - val_mean_squared_error: 1.1625\n",
            "Epoch 500/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.1274 - mean_absolute_error: 0.7005 - mean_squared_error: 1.1274\n",
            "Epoch 500: val_loss improved from 1.16252 to 1.15915, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1271 - mean_absolute_error: 0.6997 - mean_squared_error: 1.1271 - val_loss: 1.1592 - val_mean_absolute_error: 0.7124 - val_mean_squared_error: 1.1592\n",
            "Epoch 501/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.1220 - mean_absolute_error: 0.7014 - mean_squared_error: 1.1220\n",
            "Epoch 501: val_loss did not improve from 1.15915\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1214 - mean_absolute_error: 0.7014 - mean_squared_error: 1.1214 - val_loss: 1.1610 - val_mean_absolute_error: 0.7089 - val_mean_squared_error: 1.1610\n",
            "Epoch 502/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.1061 - mean_absolute_error: 0.6957 - mean_squared_error: 1.1061\n",
            "Epoch 502: val_loss improved from 1.15915 to 1.15608, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1184 - mean_absolute_error: 0.6979 - mean_squared_error: 1.1184 - val_loss: 1.1561 - val_mean_absolute_error: 0.7125 - val_mean_squared_error: 1.1561\n",
            "Epoch 503/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.1173 - mean_absolute_error: 0.6997 - mean_squared_error: 1.1173\n",
            "Epoch 503: val_loss improved from 1.15608 to 1.15098, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1140 - mean_absolute_error: 0.6970 - mean_squared_error: 1.1140 - val_loss: 1.1510 - val_mean_absolute_error: 0.7109 - val_mean_squared_error: 1.1510\n",
            "Epoch 504/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.1069 - mean_absolute_error: 0.6956 - mean_squared_error: 1.1069\n",
            "Epoch 504: val_loss did not improve from 1.15098\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1095 - mean_absolute_error: 0.6955 - mean_squared_error: 1.1095 - val_loss: 1.1618 - val_mean_absolute_error: 0.7143 - val_mean_squared_error: 1.1618\n",
            "Epoch 505/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.1195 - mean_absolute_error: 0.6981 - mean_squared_error: 1.1195\n",
            "Epoch 505: val_loss improved from 1.15098 to 1.13979, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1067 - mean_absolute_error: 0.6948 - mean_squared_error: 1.1067 - val_loss: 1.1398 - val_mean_absolute_error: 0.7017 - val_mean_squared_error: 1.1398\n",
            "Epoch 506/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.1057 - mean_absolute_error: 0.6947 - mean_squared_error: 1.1057\n",
            "Epoch 506: val_loss improved from 1.13979 to 1.13918, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1016 - mean_absolute_error: 0.6931 - mean_squared_error: 1.1016 - val_loss: 1.1392 - val_mean_absolute_error: 0.7065 - val_mean_squared_error: 1.1392\n",
            "Epoch 507/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.0913 - mean_absolute_error: 0.6913 - mean_squared_error: 1.0913\n",
            "Epoch 507: val_loss improved from 1.13918 to 1.13183, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0991 - mean_absolute_error: 0.6935 - mean_squared_error: 1.0991 - val_loss: 1.1318 - val_mean_absolute_error: 0.6990 - val_mean_squared_error: 1.1318\n",
            "Epoch 508/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.0994 - mean_absolute_error: 0.6939 - mean_squared_error: 1.0994\n",
            "Epoch 508: val_loss improved from 1.13183 to 1.12873, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0946 - mean_absolute_error: 0.6909 - mean_squared_error: 1.0946 - val_loss: 1.1287 - val_mean_absolute_error: 0.6982 - val_mean_squared_error: 1.1287\n",
            "Epoch 509/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.0821 - mean_absolute_error: 0.6839 - mean_squared_error: 1.0821\n",
            "Epoch 509: val_loss improved from 1.12873 to 1.12521, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0892 - mean_absolute_error: 0.6878 - mean_squared_error: 1.0892 - val_loss: 1.1252 - val_mean_absolute_error: 0.6964 - val_mean_squared_error: 1.1252\n",
            "Epoch 510/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.0794 - mean_absolute_error: 0.6879 - mean_squared_error: 1.0794\n",
            "Epoch 510: val_loss improved from 1.12521 to 1.12156, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0864 - mean_absolute_error: 0.6893 - mean_squared_error: 1.0864 - val_loss: 1.1216 - val_mean_absolute_error: 0.6973 - val_mean_squared_error: 1.1216\n",
            "Epoch 511/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.0932 - mean_absolute_error: 0.6906 - mean_squared_error: 1.0932\n",
            "Epoch 511: val_loss did not improve from 1.12156\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0818 - mean_absolute_error: 0.6867 - mean_squared_error: 1.0818 - val_loss: 1.1241 - val_mean_absolute_error: 0.7017 - val_mean_squared_error: 1.1241\n",
            "Epoch 512/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.0801 - mean_absolute_error: 0.6873 - mean_squared_error: 1.0801\n",
            "Epoch 512: val_loss improved from 1.12156 to 1.11753, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0792 - mean_absolute_error: 0.6873 - mean_squared_error: 1.0792 - val_loss: 1.1175 - val_mean_absolute_error: 0.6947 - val_mean_squared_error: 1.1175\n",
            "Epoch 513/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.0666 - mean_absolute_error: 0.6809 - mean_squared_error: 1.0666\n",
            "Epoch 513: val_loss improved from 1.11753 to 1.11491, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0756 - mean_absolute_error: 0.6841 - mean_squared_error: 1.0756 - val_loss: 1.1149 - val_mean_absolute_error: 0.6974 - val_mean_squared_error: 1.1149\n",
            "Epoch 514/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.0634 - mean_absolute_error: 0.6819 - mean_squared_error: 1.0634\n",
            "Epoch 514: val_loss improved from 1.11491 to 1.10813, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0712 - mean_absolute_error: 0.6844 - mean_squared_error: 1.0712 - val_loss: 1.1081 - val_mean_absolute_error: 0.6916 - val_mean_squared_error: 1.1081\n",
            "Epoch 515/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.0639 - mean_absolute_error: 0.6826 - mean_squared_error: 1.0639\n",
            "Epoch 515: val_loss improved from 1.10813 to 1.10682, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0676 - mean_absolute_error: 0.6831 - mean_squared_error: 1.0676 - val_loss: 1.1068 - val_mean_absolute_error: 0.6916 - val_mean_squared_error: 1.1068\n",
            "Epoch 516/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.0609 - mean_absolute_error: 0.6812 - mean_squared_error: 1.0609\n",
            "Epoch 516: val_loss improved from 1.10682 to 1.10543, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0630 - mean_absolute_error: 0.6820 - mean_squared_error: 1.0630 - val_loss: 1.1054 - val_mean_absolute_error: 0.6943 - val_mean_squared_error: 1.1054\n",
            "Epoch 517/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.0674 - mean_absolute_error: 0.6841 - mean_squared_error: 1.0674\n",
            "Epoch 517: val_loss improved from 1.10543 to 1.10104, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0591 - mean_absolute_error: 0.6812 - mean_squared_error: 1.0591 - val_loss: 1.1010 - val_mean_absolute_error: 0.6895 - val_mean_squared_error: 1.1010\n",
            "Epoch 518/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.0607 - mean_absolute_error: 0.6823 - mean_squared_error: 1.0607\n",
            "Epoch 518: val_loss did not improve from 1.10104\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0577 - mean_absolute_error: 0.6804 - mean_squared_error: 1.0577 - val_loss: 1.1038 - val_mean_absolute_error: 0.6942 - val_mean_squared_error: 1.1038\n",
            "Epoch 519/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.0587 - mean_absolute_error: 0.6817 - mean_squared_error: 1.0587\n",
            "Epoch 519: val_loss improved from 1.10104 to 1.09461, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0544 - mean_absolute_error: 0.6802 - mean_squared_error: 1.0544 - val_loss: 1.0946 - val_mean_absolute_error: 0.6873 - val_mean_squared_error: 1.0946\n",
            "Epoch 520/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.0502 - mean_absolute_error: 0.6777 - mean_squared_error: 1.0502\n",
            "Epoch 520: val_loss improved from 1.09461 to 1.09092, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0502 - mean_absolute_error: 0.6777 - mean_squared_error: 1.0502 - val_loss: 1.0909 - val_mean_absolute_error: 0.6879 - val_mean_squared_error: 1.0909\n",
            "Epoch 521/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.0472 - mean_absolute_error: 0.6774 - mean_squared_error: 1.0472\n",
            "Epoch 521: val_loss improved from 1.09092 to 1.09084, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0470 - mean_absolute_error: 0.6770 - mean_squared_error: 1.0470 - val_loss: 1.0908 - val_mean_absolute_error: 0.6897 - val_mean_squared_error: 1.0908\n",
            "Epoch 522/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.0432 - mean_absolute_error: 0.6750 - mean_squared_error: 1.0432\n",
            "Epoch 522: val_loss improved from 1.09084 to 1.08478, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0432 - mean_absolute_error: 0.6750 - mean_squared_error: 1.0432 - val_loss: 1.0848 - val_mean_absolute_error: 0.6850 - val_mean_squared_error: 1.0848\n",
            "Epoch 523/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.0451 - mean_absolute_error: 0.6757 - mean_squared_error: 1.0451\n",
            "Epoch 523: val_loss improved from 1.08478 to 1.08116, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0404 - mean_absolute_error: 0.6747 - mean_squared_error: 1.0404 - val_loss: 1.0812 - val_mean_absolute_error: 0.6838 - val_mean_squared_error: 1.0812\n",
            "Epoch 524/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.0328 - mean_absolute_error: 0.6753 - mean_squared_error: 1.0328\n",
            "Epoch 524: val_loss improved from 1.08116 to 1.07914, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0369 - mean_absolute_error: 0.6750 - mean_squared_error: 1.0369 - val_loss: 1.0791 - val_mean_absolute_error: 0.6835 - val_mean_squared_error: 1.0791\n",
            "Epoch 525/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.0476 - mean_absolute_error: 0.6776 - mean_squared_error: 1.0476\n",
            "Epoch 525: val_loss improved from 1.07914 to 1.07694, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0337 - mean_absolute_error: 0.6723 - mean_squared_error: 1.0337 - val_loss: 1.0769 - val_mean_absolute_error: 0.6840 - val_mean_squared_error: 1.0769\n",
            "Epoch 526/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.0323 - mean_absolute_error: 0.6733 - mean_squared_error: 1.0323\n",
            "Epoch 526: val_loss improved from 1.07694 to 1.07453, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0295 - mean_absolute_error: 0.6727 - mean_squared_error: 1.0295 - val_loss: 1.0745 - val_mean_absolute_error: 0.6827 - val_mean_squared_error: 1.0745\n",
            "Epoch 527/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.0234 - mean_absolute_error: 0.6691 - mean_squared_error: 1.0234\n",
            "Epoch 527: val_loss improved from 1.07453 to 1.06964, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0262 - mean_absolute_error: 0.6697 - mean_squared_error: 1.0262 - val_loss: 1.0696 - val_mean_absolute_error: 0.6815 - val_mean_squared_error: 1.0696\n",
            "Epoch 528/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.0409 - mean_absolute_error: 0.6742 - mean_squared_error: 1.0409\n",
            "Epoch 528: val_loss did not improve from 1.06964\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0249 - mean_absolute_error: 0.6709 - mean_squared_error: 1.0249 - val_loss: 1.0702 - val_mean_absolute_error: 0.6820 - val_mean_squared_error: 1.0702\n",
            "Epoch 529/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.0257 - mean_absolute_error: 0.6702 - mean_squared_error: 1.0257\n",
            "Epoch 529: val_loss improved from 1.06964 to 1.06507, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0209 - mean_absolute_error: 0.6692 - mean_squared_error: 1.0209 - val_loss: 1.0651 - val_mean_absolute_error: 0.6784 - val_mean_squared_error: 1.0651\n",
            "Epoch 530/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.0159 - mean_absolute_error: 0.6663 - mean_squared_error: 1.0159\n",
            "Epoch 530: val_loss improved from 1.06507 to 1.06432, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0174 - mean_absolute_error: 0.6680 - mean_squared_error: 1.0174 - val_loss: 1.0643 - val_mean_absolute_error: 0.6792 - val_mean_squared_error: 1.0643\n",
            "Epoch 531/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.0218 - mean_absolute_error: 0.6695 - mean_squared_error: 1.0218\n",
            "Epoch 531: val_loss improved from 1.06432 to 1.06395, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0150 - mean_absolute_error: 0.6666 - mean_squared_error: 1.0150 - val_loss: 1.0639 - val_mean_absolute_error: 0.6814 - val_mean_squared_error: 1.0639\n",
            "Epoch 532/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.0171 - mean_absolute_error: 0.6684 - mean_squared_error: 1.0171\n",
            "Epoch 532: val_loss improved from 1.06395 to 1.06119, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0117 - mean_absolute_error: 0.6663 - mean_squared_error: 1.0117 - val_loss: 1.0612 - val_mean_absolute_error: 0.6784 - val_mean_squared_error: 1.0612\n",
            "Epoch 533/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.0069 - mean_absolute_error: 0.6625 - mean_squared_error: 1.0069\n",
            "Epoch 533: val_loss improved from 1.06119 to 1.05850, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0082 - mean_absolute_error: 0.6644 - mean_squared_error: 1.0082 - val_loss: 1.0585 - val_mean_absolute_error: 0.6768 - val_mean_squared_error: 1.0585\n",
            "Epoch 534/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.0099 - mean_absolute_error: 0.6653 - mean_squared_error: 1.0099\n",
            "Epoch 534: val_loss improved from 1.05850 to 1.05320, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0052 - mean_absolute_error: 0.6637 - mean_squared_error: 1.0052 - val_loss: 1.0532 - val_mean_absolute_error: 0.6741 - val_mean_squared_error: 1.0532\n",
            "Epoch 535/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.0070 - mean_absolute_error: 0.6655 - mean_squared_error: 1.0070\n",
            "Epoch 535: val_loss improved from 1.05320 to 1.05092, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0029 - mean_absolute_error: 0.6625 - mean_squared_error: 1.0029 - val_loss: 1.0509 - val_mean_absolute_error: 0.6791 - val_mean_squared_error: 1.0509\n",
            "Epoch 536/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.0039 - mean_absolute_error: 0.6648 - mean_squared_error: 1.0039\n",
            "Epoch 536: val_loss did not improve from 1.05092\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9996 - mean_absolute_error: 0.6619 - mean_squared_error: 0.9996 - val_loss: 1.0575 - val_mean_absolute_error: 0.6801 - val_mean_squared_error: 1.0575\n",
            "Epoch 537/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.9985 - mean_absolute_error: 0.6628 - mean_squared_error: 0.9985\n",
            "Epoch 537: val_loss improved from 1.05092 to 1.04752, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9953 - mean_absolute_error: 0.6610 - mean_squared_error: 0.9953 - val_loss: 1.0475 - val_mean_absolute_error: 0.6741 - val_mean_squared_error: 1.0475\n",
            "Epoch 538/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.9976 - mean_absolute_error: 0.6620 - mean_squared_error: 0.9976\n",
            "Epoch 538: val_loss improved from 1.04752 to 1.04344, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9937 - mean_absolute_error: 0.6607 - mean_squared_error: 0.9937 - val_loss: 1.0434 - val_mean_absolute_error: 0.6724 - val_mean_squared_error: 1.0434\n",
            "Epoch 539/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.9762 - mean_absolute_error: 0.6533 - mean_squared_error: 0.9762\n",
            "Epoch 539: val_loss did not improve from 1.04344\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9917 - mean_absolute_error: 0.6588 - mean_squared_error: 0.9917 - val_loss: 1.0468 - val_mean_absolute_error: 0.6770 - val_mean_squared_error: 1.0468\n",
            "Epoch 540/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 0.9863 - mean_absolute_error: 0.6567 - mean_squared_error: 0.9863\n",
            "Epoch 540: val_loss improved from 1.04344 to 1.03701, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9881 - mean_absolute_error: 0.6575 - mean_squared_error: 0.9881 - val_loss: 1.0370 - val_mean_absolute_error: 0.6713 - val_mean_squared_error: 1.0370\n",
            "Epoch 541/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.9868 - mean_absolute_error: 0.6573 - mean_squared_error: 0.9868\n",
            "Epoch 541: val_loss improved from 1.03701 to 1.03311, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9843 - mean_absolute_error: 0.6562 - mean_squared_error: 0.9843 - val_loss: 1.0331 - val_mean_absolute_error: 0.6680 - val_mean_squared_error: 1.0331\n",
            "Epoch 542/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.9894 - mean_absolute_error: 0.6601 - mean_squared_error: 0.9894\n",
            "Epoch 542: val_loss did not improve from 1.03311\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9832 - mean_absolute_error: 0.6567 - mean_squared_error: 0.9832 - val_loss: 1.0354 - val_mean_absolute_error: 0.6702 - val_mean_squared_error: 1.0354\n",
            "Epoch 543/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.9815 - mean_absolute_error: 0.6561 - mean_squared_error: 0.9815\n",
            "Epoch 543: val_loss improved from 1.03311 to 1.02990, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9811 - mean_absolute_error: 0.6556 - mean_squared_error: 0.9811 - val_loss: 1.0299 - val_mean_absolute_error: 0.6684 - val_mean_squared_error: 1.0299\n",
            "Epoch 544/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.9681 - mean_absolute_error: 0.6534 - mean_squared_error: 0.9681\n",
            "Epoch 544: val_loss improved from 1.02990 to 1.02632, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9780 - mean_absolute_error: 0.6541 - mean_squared_error: 0.9780 - val_loss: 1.0263 - val_mean_absolute_error: 0.6668 - val_mean_squared_error: 1.0263\n",
            "Epoch 545/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.9771 - mean_absolute_error: 0.6540 - mean_squared_error: 0.9771\n",
            "Epoch 545: val_loss improved from 1.02632 to 1.02450, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9739 - mean_absolute_error: 0.6529 - mean_squared_error: 0.9739 - val_loss: 1.0245 - val_mean_absolute_error: 0.6659 - val_mean_squared_error: 1.0245\n",
            "Epoch 546/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.9777 - mean_absolute_error: 0.6533 - mean_squared_error: 0.9777\n",
            "Epoch 546: val_loss did not improve from 1.02450\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9722 - mean_absolute_error: 0.6517 - mean_squared_error: 0.9722 - val_loss: 1.0257 - val_mean_absolute_error: 0.6664 - val_mean_squared_error: 1.0257\n",
            "Epoch 547/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.9713 - mean_absolute_error: 0.6534 - mean_squared_error: 0.9713\n",
            "Epoch 547: val_loss improved from 1.02450 to 1.02379, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9692 - mean_absolute_error: 0.6524 - mean_squared_error: 0.9692 - val_loss: 1.0238 - val_mean_absolute_error: 0.6668 - val_mean_squared_error: 1.0238\n",
            "Epoch 548/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.9570 - mean_absolute_error: 0.6444 - mean_squared_error: 0.9570\n",
            "Epoch 548: val_loss improved from 1.02379 to 1.01784, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9668 - mean_absolute_error: 0.6497 - mean_squared_error: 0.9668 - val_loss: 1.0178 - val_mean_absolute_error: 0.6643 - val_mean_squared_error: 1.0178\n",
            "Epoch 549/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.9739 - mean_absolute_error: 0.6529 - mean_squared_error: 0.9739\n",
            "Epoch 549: val_loss improved from 1.01784 to 1.01477, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9645 - mean_absolute_error: 0.6500 - mean_squared_error: 0.9645 - val_loss: 1.0148 - val_mean_absolute_error: 0.6643 - val_mean_squared_error: 1.0148\n",
            "Epoch 550/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.9627 - mean_absolute_error: 0.6487 - mean_squared_error: 0.9627\n",
            "Epoch 550: val_loss did not improve from 1.01477\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9607 - mean_absolute_error: 0.6485 - mean_squared_error: 0.9607 - val_loss: 1.0169 - val_mean_absolute_error: 0.6659 - val_mean_squared_error: 1.0169\n",
            "Epoch 551/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.9660 - mean_absolute_error: 0.6509 - mean_squared_error: 0.9660\n",
            "Epoch 551: val_loss improved from 1.01477 to 1.01313, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9592 - mean_absolute_error: 0.6482 - mean_squared_error: 0.9592 - val_loss: 1.0131 - val_mean_absolute_error: 0.6622 - val_mean_squared_error: 1.0131\n",
            "Epoch 552/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.9540 - mean_absolute_error: 0.6444 - mean_squared_error: 0.9540\n",
            "Epoch 552: val_loss improved from 1.01313 to 1.01053, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9570 - mean_absolute_error: 0.6460 - mean_squared_error: 0.9570 - val_loss: 1.0105 - val_mean_absolute_error: 0.6627 - val_mean_squared_error: 1.0105\n",
            "Epoch 553/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.9675 - mean_absolute_error: 0.6492 - mean_squared_error: 0.9675\n",
            "Epoch 553: val_loss improved from 1.01053 to 1.01007, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9541 - mean_absolute_error: 0.6455 - mean_squared_error: 0.9541 - val_loss: 1.0101 - val_mean_absolute_error: 0.6590 - val_mean_squared_error: 1.0101\n",
            "Epoch 554/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.9472 - mean_absolute_error: 0.6422 - mean_squared_error: 0.9472\n",
            "Epoch 554: val_loss did not improve from 1.01007\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9501 - mean_absolute_error: 0.6436 - mean_squared_error: 0.9501 - val_loss: 1.0128 - val_mean_absolute_error: 0.6648 - val_mean_squared_error: 1.0128\n",
            "Epoch 555/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.9468 - mean_absolute_error: 0.6400 - mean_squared_error: 0.9468\n",
            "Epoch 555: val_loss improved from 1.01007 to 1.00209, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9480 - mean_absolute_error: 0.6417 - mean_squared_error: 0.9480 - val_loss: 1.0021 - val_mean_absolute_error: 0.6596 - val_mean_squared_error: 1.0021\n",
            "Epoch 556/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.9493 - mean_absolute_error: 0.6440 - mean_squared_error: 0.9493\n",
            "Epoch 556: val_loss did not improve from 1.00209\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9458 - mean_absolute_error: 0.6422 - mean_squared_error: 0.9458 - val_loss: 1.0031 - val_mean_absolute_error: 0.6579 - val_mean_squared_error: 1.0031\n",
            "Epoch 557/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.9430 - mean_absolute_error: 0.6409 - mean_squared_error: 0.9430\n",
            "Epoch 557: val_loss improved from 1.00209 to 0.99647, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9428 - mean_absolute_error: 0.6405 - mean_squared_error: 0.9428 - val_loss: 0.9965 - val_mean_absolute_error: 0.6548 - val_mean_squared_error: 0.9965\n",
            "Epoch 558/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.9434 - mean_absolute_error: 0.6449 - mean_squared_error: 0.9434\n",
            "Epoch 558: val_loss did not improve from 0.99647\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9420 - mean_absolute_error: 0.6407 - mean_squared_error: 0.9420 - val_loss: 0.9977 - val_mean_absolute_error: 0.6579 - val_mean_squared_error: 0.9977\n",
            "Epoch 559/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.9429 - mean_absolute_error: 0.6423 - mean_squared_error: 0.9429\n",
            "Epoch 559: val_loss improved from 0.99647 to 0.99445, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9389 - mean_absolute_error: 0.6402 - mean_squared_error: 0.9389 - val_loss: 0.9944 - val_mean_absolute_error: 0.6533 - val_mean_squared_error: 0.9944\n",
            "Epoch 560/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.9418 - mean_absolute_error: 0.6418 - mean_squared_error: 0.9418\n",
            "Epoch 560: val_loss improved from 0.99445 to 0.99225, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9359 - mean_absolute_error: 0.6378 - mean_squared_error: 0.9359 - val_loss: 0.9922 - val_mean_absolute_error: 0.6544 - val_mean_squared_error: 0.9922\n",
            "Epoch 561/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.9339 - mean_absolute_error: 0.6377 - mean_squared_error: 0.9339\n",
            "Epoch 561: val_loss did not improve from 0.99225\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9339 - mean_absolute_error: 0.6377 - mean_squared_error: 0.9339 - val_loss: 0.9957 - val_mean_absolute_error: 0.6541 - val_mean_squared_error: 0.9957\n",
            "Epoch 562/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.9268 - mean_absolute_error: 0.6337 - mean_squared_error: 0.9268\n",
            "Epoch 562: val_loss improved from 0.99225 to 0.99171, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9306 - mean_absolute_error: 0.6350 - mean_squared_error: 0.9306 - val_loss: 0.9917 - val_mean_absolute_error: 0.6572 - val_mean_squared_error: 0.9917\n",
            "Epoch 563/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.9177 - mean_absolute_error: 0.6321 - mean_squared_error: 0.9177\n",
            "Epoch 563: val_loss improved from 0.99171 to 0.98715, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9289 - mean_absolute_error: 0.6354 - mean_squared_error: 0.9289 - val_loss: 0.9872 - val_mean_absolute_error: 0.6521 - val_mean_squared_error: 0.9872\n",
            "Epoch 564/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 0.9492 - mean_absolute_error: 0.6454 - mean_squared_error: 0.9492\n",
            "Epoch 564: val_loss improved from 0.98715 to 0.98650, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9263 - mean_absolute_error: 0.6344 - mean_squared_error: 0.9263 - val_loss: 0.9865 - val_mean_absolute_error: 0.6523 - val_mean_squared_error: 0.9865\n",
            "Epoch 565/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.9271 - mean_absolute_error: 0.6349 - mean_squared_error: 0.9271\n",
            "Epoch 565: val_loss improved from 0.98650 to 0.98410, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9239 - mean_absolute_error: 0.6335 - mean_squared_error: 0.9239 - val_loss: 0.9841 - val_mean_absolute_error: 0.6521 - val_mean_squared_error: 0.9841\n",
            "Epoch 566/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.9235 - mean_absolute_error: 0.6336 - mean_squared_error: 0.9235\n",
            "Epoch 566: val_loss improved from 0.98410 to 0.98050, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9217 - mean_absolute_error: 0.6333 - mean_squared_error: 0.9217 - val_loss: 0.9805 - val_mean_absolute_error: 0.6476 - val_mean_squared_error: 0.9805\n",
            "Epoch 567/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.9194 - mean_absolute_error: 0.6303 - mean_squared_error: 0.9194\n",
            "Epoch 567: val_loss improved from 0.98050 to 0.97662, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9197 - mean_absolute_error: 0.6321 - mean_squared_error: 0.9197 - val_loss: 0.9766 - val_mean_absolute_error: 0.6459 - val_mean_squared_error: 0.9766\n",
            "Epoch 568/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.9225 - mean_absolute_error: 0.6325 - mean_squared_error: 0.9225\n",
            "Epoch 568: val_loss did not improve from 0.97662\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9165 - mean_absolute_error: 0.6306 - mean_squared_error: 0.9165 - val_loss: 0.9812 - val_mean_absolute_error: 0.6477 - val_mean_squared_error: 0.9812\n",
            "Epoch 569/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.9115 - mean_absolute_error: 0.6280 - mean_squared_error: 0.9115\n",
            "Epoch 569: val_loss improved from 0.97662 to 0.97434, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9154 - mean_absolute_error: 0.6298 - mean_squared_error: 0.9154 - val_loss: 0.9743 - val_mean_absolute_error: 0.6465 - val_mean_squared_error: 0.9743\n",
            "Epoch 570/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.9131 - mean_absolute_error: 0.6298 - mean_squared_error: 0.9131\n",
            "Epoch 570: val_loss improved from 0.97434 to 0.97334, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9113 - mean_absolute_error: 0.6281 - mean_squared_error: 0.9113 - val_loss: 0.9733 - val_mean_absolute_error: 0.6459 - val_mean_squared_error: 0.9733\n",
            "Epoch 571/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.9058 - mean_absolute_error: 0.6272 - mean_squared_error: 0.9058\n",
            "Epoch 571: val_loss improved from 0.97334 to 0.96838, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.9091 - mean_absolute_error: 0.6280 - mean_squared_error: 0.9091 - val_loss: 0.9684 - val_mean_absolute_error: 0.6434 - val_mean_squared_error: 0.9684\n",
            "Epoch 572/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.9104 - mean_absolute_error: 0.6275 - mean_squared_error: 0.9104\n",
            "Epoch 572: val_loss did not improve from 0.96838\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9066 - mean_absolute_error: 0.6269 - mean_squared_error: 0.9066 - val_loss: 0.9716 - val_mean_absolute_error: 0.6499 - val_mean_squared_error: 0.9716\n",
            "Epoch 573/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.9048 - mean_absolute_error: 0.6265 - mean_squared_error: 0.9048\n",
            "Epoch 573: val_loss improved from 0.96838 to 0.96665, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9069 - mean_absolute_error: 0.6268 - mean_squared_error: 0.9069 - val_loss: 0.9667 - val_mean_absolute_error: 0.6443 - val_mean_squared_error: 0.9667\n",
            "Epoch 574/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.8928 - mean_absolute_error: 0.6218 - mean_squared_error: 0.8928\n",
            "Epoch 574: val_loss improved from 0.96665 to 0.96444, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9031 - mean_absolute_error: 0.6255 - mean_squared_error: 0.9031 - val_loss: 0.9644 - val_mean_absolute_error: 0.6408 - val_mean_squared_error: 0.9644\n",
            "Epoch 575/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.9017 - mean_absolute_error: 0.6244 - mean_squared_error: 0.9017\n",
            "Epoch 575: val_loss improved from 0.96444 to 0.96207, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9021 - mean_absolute_error: 0.6253 - mean_squared_error: 0.9021 - val_loss: 0.9621 - val_mean_absolute_error: 0.6403 - val_mean_squared_error: 0.9621\n",
            "Epoch 576/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.8899 - mean_absolute_error: 0.6200 - mean_squared_error: 0.8899\n",
            "Epoch 576: val_loss improved from 0.96207 to 0.96117, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8971 - mean_absolute_error: 0.6233 - mean_squared_error: 0.8971 - val_loss: 0.9612 - val_mean_absolute_error: 0.6404 - val_mean_squared_error: 0.9612\n",
            "Epoch 577/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.8937 - mean_absolute_error: 0.6222 - mean_squared_error: 0.8937\n",
            "Epoch 577: val_loss improved from 0.96117 to 0.95747, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8957 - mean_absolute_error: 0.6222 - mean_squared_error: 0.8957 - val_loss: 0.9575 - val_mean_absolute_error: 0.6379 - val_mean_squared_error: 0.9575\n",
            "Epoch 578/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.8936 - mean_absolute_error: 0.6221 - mean_squared_error: 0.8936\n",
            "Epoch 578: val_loss did not improve from 0.95747\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8936 - mean_absolute_error: 0.6221 - mean_squared_error: 0.8936 - val_loss: 0.9606 - val_mean_absolute_error: 0.6395 - val_mean_squared_error: 0.9606\n",
            "Epoch 579/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.8931 - mean_absolute_error: 0.6226 - mean_squared_error: 0.8931\n",
            "Epoch 579: val_loss improved from 0.95747 to 0.95511, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8915 - mean_absolute_error: 0.6206 - mean_squared_error: 0.8915 - val_loss: 0.9551 - val_mean_absolute_error: 0.6369 - val_mean_squared_error: 0.9551\n",
            "Epoch 580/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.8865 - mean_absolute_error: 0.6184 - mean_squared_error: 0.8865\n",
            "Epoch 580: val_loss improved from 0.95511 to 0.95218, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8890 - mean_absolute_error: 0.6192 - mean_squared_error: 0.8890 - val_loss: 0.9522 - val_mean_absolute_error: 0.6382 - val_mean_squared_error: 0.9522\n",
            "Epoch 581/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.8887 - mean_absolute_error: 0.6198 - mean_squared_error: 0.8887\n",
            "Epoch 581: val_loss did not improve from 0.95218\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8862 - mean_absolute_error: 0.6188 - mean_squared_error: 0.8862 - val_loss: 0.9522 - val_mean_absolute_error: 0.6370 - val_mean_squared_error: 0.9522\n",
            "Epoch 582/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 0.8740 - mean_absolute_error: 0.6131 - mean_squared_error: 0.8740\n",
            "Epoch 582: val_loss improved from 0.95218 to 0.94736, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8838 - mean_absolute_error: 0.6182 - mean_squared_error: 0.8838 - val_loss: 0.9474 - val_mean_absolute_error: 0.6348 - val_mean_squared_error: 0.9474\n",
            "Epoch 583/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.8894 - mean_absolute_error: 0.6196 - mean_squared_error: 0.8894\n",
            "Epoch 583: val_loss improved from 0.94736 to 0.94496, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8817 - mean_absolute_error: 0.6176 - mean_squared_error: 0.8817 - val_loss: 0.9450 - val_mean_absolute_error: 0.6348 - val_mean_squared_error: 0.9450\n",
            "Epoch 584/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.8832 - mean_absolute_error: 0.6175 - mean_squared_error: 0.8832\n",
            "Epoch 584: val_loss did not improve from 0.94496\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8783 - mean_absolute_error: 0.6155 - mean_squared_error: 0.8783 - val_loss: 0.9484 - val_mean_absolute_error: 0.6356 - val_mean_squared_error: 0.9484\n",
            "Epoch 585/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.8714 - mean_absolute_error: 0.6123 - mean_squared_error: 0.8714\n",
            "Epoch 585: val_loss did not improve from 0.94496\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8760 - mean_absolute_error: 0.6147 - mean_squared_error: 0.8760 - val_loss: 0.9470 - val_mean_absolute_error: 0.6352 - val_mean_squared_error: 0.9470\n",
            "Epoch 586/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.8732 - mean_absolute_error: 0.6141 - mean_squared_error: 0.8732\n",
            "Epoch 586: val_loss improved from 0.94496 to 0.94282, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8751 - mean_absolute_error: 0.6143 - mean_squared_error: 0.8751 - val_loss: 0.9428 - val_mean_absolute_error: 0.6353 - val_mean_squared_error: 0.9428\n",
            "Epoch 587/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.8750 - mean_absolute_error: 0.6170 - mean_squared_error: 0.8750\n",
            "Epoch 587: val_loss did not improve from 0.94282\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8713 - mean_absolute_error: 0.6138 - mean_squared_error: 0.8713 - val_loss: 0.9468 - val_mean_absolute_error: 0.6342 - val_mean_squared_error: 0.9468\n",
            "Epoch 588/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.8674 - mean_absolute_error: 0.6117 - mean_squared_error: 0.8674\n",
            "Epoch 588: val_loss improved from 0.94282 to 0.93753, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.8688 - mean_absolute_error: 0.6121 - mean_squared_error: 0.8688 - val_loss: 0.9375 - val_mean_absolute_error: 0.6303 - val_mean_squared_error: 0.9375\n",
            "Epoch 589/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.8711 - mean_absolute_error: 0.6127 - mean_squared_error: 0.8711\n",
            "Epoch 589: val_loss improved from 0.93753 to 0.93671, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.8674 - mean_absolute_error: 0.6112 - mean_squared_error: 0.8674 - val_loss: 0.9367 - val_mean_absolute_error: 0.6299 - val_mean_squared_error: 0.9367\n",
            "Epoch 590/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.8681 - mean_absolute_error: 0.6122 - mean_squared_error: 0.8681\n",
            "Epoch 590: val_loss improved from 0.93671 to 0.93521, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8651 - mean_absolute_error: 0.6114 - mean_squared_error: 0.8651 - val_loss: 0.9352 - val_mean_absolute_error: 0.6297 - val_mean_squared_error: 0.9352\n",
            "Epoch 591/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.8602 - mean_absolute_error: 0.6078 - mean_squared_error: 0.8602\n",
            "Epoch 591: val_loss improved from 0.93521 to 0.92964, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8620 - mean_absolute_error: 0.6084 - mean_squared_error: 0.8620 - val_loss: 0.9296 - val_mean_absolute_error: 0.6284 - val_mean_squared_error: 0.9296\n",
            "Epoch 592/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.8589 - mean_absolute_error: 0.6072 - mean_squared_error: 0.8589\n",
            "Epoch 592: val_loss did not improve from 0.92964\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8589 - mean_absolute_error: 0.6072 - mean_squared_error: 0.8589 - val_loss: 0.9302 - val_mean_absolute_error: 0.6276 - val_mean_squared_error: 0.9302\n",
            "Epoch 593/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.8599 - mean_absolute_error: 0.6092 - mean_squared_error: 0.8599\n",
            "Epoch 593: val_loss improved from 0.92964 to 0.92701, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8577 - mean_absolute_error: 0.6072 - mean_squared_error: 0.8577 - val_loss: 0.9270 - val_mean_absolute_error: 0.6279 - val_mean_squared_error: 0.9270\n",
            "Epoch 594/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.8574 - mean_absolute_error: 0.6071 - mean_squared_error: 0.8574\n",
            "Epoch 594: val_loss improved from 0.92701 to 0.92601, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8558 - mean_absolute_error: 0.6067 - mean_squared_error: 0.8558 - val_loss: 0.9260 - val_mean_absolute_error: 0.6259 - val_mean_squared_error: 0.9260\n",
            "Epoch 595/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.8509 - mean_absolute_error: 0.6050 - mean_squared_error: 0.8509\n",
            "Epoch 595: val_loss improved from 0.92601 to 0.92415, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8526 - mean_absolute_error: 0.6057 - mean_squared_error: 0.8526 - val_loss: 0.9242 - val_mean_absolute_error: 0.6255 - val_mean_squared_error: 0.9242\n",
            "Epoch 596/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.8515 - mean_absolute_error: 0.6057 - mean_squared_error: 0.8515\n",
            "Epoch 596: val_loss improved from 0.92415 to 0.91898, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8500 - mean_absolute_error: 0.6050 - mean_squared_error: 0.8500 - val_loss: 0.9190 - val_mean_absolute_error: 0.6247 - val_mean_squared_error: 0.9190\n",
            "Epoch 597/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.8463 - mean_absolute_error: 0.6059 - mean_squared_error: 0.8463\n",
            "Epoch 597: val_loss did not improve from 0.91898\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8493 - mean_absolute_error: 0.6050 - mean_squared_error: 0.8493 - val_loss: 0.9244 - val_mean_absolute_error: 0.6242 - val_mean_squared_error: 0.9244\n",
            "Epoch 598/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.8485 - mean_absolute_error: 0.6039 - mean_squared_error: 0.8485\n",
            "Epoch 598: val_loss improved from 0.91898 to 0.91819, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8447 - mean_absolute_error: 0.6023 - mean_squared_error: 0.8447 - val_loss: 0.9182 - val_mean_absolute_error: 0.6220 - val_mean_squared_error: 0.9182\n",
            "Epoch 599/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.8475 - mean_absolute_error: 0.6029 - mean_squared_error: 0.8475\n",
            "Epoch 599: val_loss improved from 0.91819 to 0.91687, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8430 - mean_absolute_error: 0.6017 - mean_squared_error: 0.8430 - val_loss: 0.9169 - val_mean_absolute_error: 0.6216 - val_mean_squared_error: 0.9169\n",
            "Epoch 600/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.8325 - mean_absolute_error: 0.5978 - mean_squared_error: 0.8325\n",
            "Epoch 600: val_loss improved from 0.91687 to 0.91314, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8403 - mean_absolute_error: 0.6009 - mean_squared_error: 0.8403 - val_loss: 0.9131 - val_mean_absolute_error: 0.6210 - val_mean_squared_error: 0.9131\n",
            "Epoch 601/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.8353 - mean_absolute_error: 0.5982 - mean_squared_error: 0.8353\n",
            "Epoch 601: val_loss improved from 0.91314 to 0.91042, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8401 - mean_absolute_error: 0.6009 - mean_squared_error: 0.8401 - val_loss: 0.9104 - val_mean_absolute_error: 0.6215 - val_mean_squared_error: 0.9104\n",
            "Epoch 602/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.8400 - mean_absolute_error: 0.6017 - mean_squared_error: 0.8400\n",
            "Epoch 602: val_loss improved from 0.91042 to 0.90841, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8362 - mean_absolute_error: 0.5992 - mean_squared_error: 0.8362 - val_loss: 0.9084 - val_mean_absolute_error: 0.6186 - val_mean_squared_error: 0.9084\n",
            "Epoch 603/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.8369 - mean_absolute_error: 0.6000 - mean_squared_error: 0.8369\n",
            "Epoch 603: val_loss did not improve from 0.90841\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8336 - mean_absolute_error: 0.5989 - mean_squared_error: 0.8336 - val_loss: 0.9095 - val_mean_absolute_error: 0.6201 - val_mean_squared_error: 0.9095\n",
            "Epoch 604/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.8278 - mean_absolute_error: 0.5962 - mean_squared_error: 0.8278\n",
            "Epoch 604: val_loss did not improve from 0.90841\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8309 - mean_absolute_error: 0.5972 - mean_squared_error: 0.8309 - val_loss: 0.9112 - val_mean_absolute_error: 0.6197 - val_mean_squared_error: 0.9112\n",
            "Epoch 605/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.8406 - mean_absolute_error: 0.6007 - mean_squared_error: 0.8406\n",
            "Epoch 605: val_loss improved from 0.90841 to 0.90393, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8292 - mean_absolute_error: 0.5968 - mean_squared_error: 0.8292 - val_loss: 0.9039 - val_mean_absolute_error: 0.6165 - val_mean_squared_error: 0.9039\n",
            "Epoch 606/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.8300 - mean_absolute_error: 0.5967 - mean_squared_error: 0.8300\n",
            "Epoch 606: val_loss improved from 0.90393 to 0.90313, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8260 - mean_absolute_error: 0.5942 - mean_squared_error: 0.8260 - val_loss: 0.9031 - val_mean_absolute_error: 0.6165 - val_mean_squared_error: 0.9031\n",
            "Epoch 607/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.8181 - mean_absolute_error: 0.5913 - mean_squared_error: 0.8181\n",
            "Epoch 607: val_loss improved from 0.90313 to 0.90130, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8225 - mean_absolute_error: 0.5923 - mean_squared_error: 0.8225 - val_loss: 0.9013 - val_mean_absolute_error: 0.6154 - val_mean_squared_error: 0.9013\n",
            "Epoch 608/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.8158 - mean_absolute_error: 0.5912 - mean_squared_error: 0.8158\n",
            "Epoch 608: val_loss improved from 0.90130 to 0.89619, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8208 - mean_absolute_error: 0.5931 - mean_squared_error: 0.8208 - val_loss: 0.8962 - val_mean_absolute_error: 0.6138 - val_mean_squared_error: 0.8962\n",
            "Epoch 609/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.8274 - mean_absolute_error: 0.5945 - mean_squared_error: 0.8274\n",
            "Epoch 609: val_loss did not improve from 0.89619\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8175 - mean_absolute_error: 0.5921 - mean_squared_error: 0.8175 - val_loss: 0.8974 - val_mean_absolute_error: 0.6136 - val_mean_squared_error: 0.8974\n",
            "Epoch 610/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.8158 - mean_absolute_error: 0.5918 - mean_squared_error: 0.8158\n",
            "Epoch 610: val_loss improved from 0.89619 to 0.89215, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8169 - mean_absolute_error: 0.5919 - mean_squared_error: 0.8169 - val_loss: 0.8921 - val_mean_absolute_error: 0.6115 - val_mean_squared_error: 0.8921\n",
            "Epoch 611/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.8135 - mean_absolute_error: 0.5900 - mean_squared_error: 0.8135\n",
            "Epoch 611: val_loss improved from 0.89215 to 0.88903, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8140 - mean_absolute_error: 0.5893 - mean_squared_error: 0.8140 - val_loss: 0.8890 - val_mean_absolute_error: 0.6099 - val_mean_squared_error: 0.8890\n",
            "Epoch 612/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.8108 - mean_absolute_error: 0.5887 - mean_squared_error: 0.8108\n",
            "Epoch 612: val_loss did not improve from 0.88903\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8111 - mean_absolute_error: 0.5891 - mean_squared_error: 0.8111 - val_loss: 0.8896 - val_mean_absolute_error: 0.6093 - val_mean_squared_error: 0.8896\n",
            "Epoch 613/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.8139 - mean_absolute_error: 0.5916 - mean_squared_error: 0.8139\n",
            "Epoch 613: val_loss did not improve from 0.88903\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8072 - mean_absolute_error: 0.5887 - mean_squared_error: 0.8072 - val_loss: 0.8898 - val_mean_absolute_error: 0.6137 - val_mean_squared_error: 0.8898\n",
            "Epoch 614/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.8068 - mean_absolute_error: 0.5869 - mean_squared_error: 0.8068\n",
            "Epoch 614: val_loss improved from 0.88903 to 0.88313, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8063 - mean_absolute_error: 0.5870 - mean_squared_error: 0.8063 - val_loss: 0.8831 - val_mean_absolute_error: 0.6073 - val_mean_squared_error: 0.8831\n",
            "Epoch 615/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.8056 - mean_absolute_error: 0.5855 - mean_squared_error: 0.8056\n",
            "Epoch 615: val_loss improved from 0.88313 to 0.88135, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8025 - mean_absolute_error: 0.5852 - mean_squared_error: 0.8025 - val_loss: 0.8814 - val_mean_absolute_error: 0.6076 - val_mean_squared_error: 0.8814\n",
            "Epoch 616/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.8108 - mean_absolute_error: 0.5896 - mean_squared_error: 0.8108\n",
            "Epoch 616: val_loss improved from 0.88135 to 0.87784, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8018 - mean_absolute_error: 0.5858 - mean_squared_error: 0.8018 - val_loss: 0.8778 - val_mean_absolute_error: 0.6051 - val_mean_squared_error: 0.8778\n",
            "Epoch 617/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.7973 - mean_absolute_error: 0.5835 - mean_squared_error: 0.7973\n",
            "Epoch 617: val_loss improved from 0.87784 to 0.87625, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.7974 - mean_absolute_error: 0.5833 - mean_squared_error: 0.7974 - val_loss: 0.8762 - val_mean_absolute_error: 0.6058 - val_mean_squared_error: 0.8762\n",
            "Epoch 618/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.7985 - mean_absolute_error: 0.5838 - mean_squared_error: 0.7985\n",
            "Epoch 618: val_loss improved from 0.87625 to 0.87446, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.7962 - mean_absolute_error: 0.5836 - mean_squared_error: 0.7962 - val_loss: 0.8745 - val_mean_absolute_error: 0.6034 - val_mean_squared_error: 0.8745\n",
            "Epoch 619/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.7875 - mean_absolute_error: 0.5790 - mean_squared_error: 0.7875\n",
            "Epoch 619: val_loss improved from 0.87446 to 0.87151, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7930 - mean_absolute_error: 0.5809 - mean_squared_error: 0.7930 - val_loss: 0.8715 - val_mean_absolute_error: 0.6020 - val_mean_squared_error: 0.8715\n",
            "Epoch 620/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.7945 - mean_absolute_error: 0.5800 - mean_squared_error: 0.7945\n",
            "Epoch 620: val_loss improved from 0.87151 to 0.86928, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.7904 - mean_absolute_error: 0.5798 - mean_squared_error: 0.7904 - val_loss: 0.8693 - val_mean_absolute_error: 0.6017 - val_mean_squared_error: 0.8693\n",
            "Epoch 621/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.7906 - mean_absolute_error: 0.5806 - mean_squared_error: 0.7906\n",
            "Epoch 621: val_loss did not improve from 0.86928\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.7877 - mean_absolute_error: 0.5789 - mean_squared_error: 0.7877 - val_loss: 0.8716 - val_mean_absolute_error: 0.6023 - val_mean_squared_error: 0.8716\n",
            "Epoch 622/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.7869 - mean_absolute_error: 0.5800 - mean_squared_error: 0.7869\n",
            "Epoch 622: val_loss did not improve from 0.86928\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7856 - mean_absolute_error: 0.5791 - mean_squared_error: 0.7856 - val_loss: 0.8707 - val_mean_absolute_error: 0.6013 - val_mean_squared_error: 0.8707\n",
            "Epoch 623/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.7816 - mean_absolute_error: 0.5776 - mean_squared_error: 0.7816\n",
            "Epoch 623: val_loss improved from 0.86928 to 0.86344, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.7830 - mean_absolute_error: 0.5778 - mean_squared_error: 0.7830 - val_loss: 0.8634 - val_mean_absolute_error: 0.5980 - val_mean_squared_error: 0.8634\n",
            "Epoch 624/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.7801 - mean_absolute_error: 0.5761 - mean_squared_error: 0.7801\n",
            "Epoch 624: val_loss did not improve from 0.86344\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7804 - mean_absolute_error: 0.5758 - mean_squared_error: 0.7804 - val_loss: 0.8638 - val_mean_absolute_error: 0.5989 - val_mean_squared_error: 0.8638\n",
            "Epoch 625/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.7777 - mean_absolute_error: 0.5760 - mean_squared_error: 0.7777\n",
            "Epoch 625: val_loss improved from 0.86344 to 0.85985, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.7778 - mean_absolute_error: 0.5755 - mean_squared_error: 0.7778 - val_loss: 0.8599 - val_mean_absolute_error: 0.5967 - val_mean_squared_error: 0.8599\n",
            "Epoch 626/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.7757 - mean_absolute_error: 0.5731 - mean_squared_error: 0.7757\n",
            "Epoch 626: val_loss did not improve from 0.85985\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7746 - mean_absolute_error: 0.5732 - mean_squared_error: 0.7746 - val_loss: 0.8601 - val_mean_absolute_error: 0.5956 - val_mean_squared_error: 0.8601\n",
            "Epoch 627/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.7778 - mean_absolute_error: 0.5751 - mean_squared_error: 0.7778\n",
            "Epoch 627: val_loss improved from 0.85985 to 0.85512, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7715 - mean_absolute_error: 0.5722 - mean_squared_error: 0.7715 - val_loss: 0.8551 - val_mean_absolute_error: 0.5952 - val_mean_squared_error: 0.8551\n",
            "Epoch 628/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 0.7543 - mean_absolute_error: 0.5631 - mean_squared_error: 0.7543\n",
            "Epoch 628: val_loss improved from 0.85512 to 0.85210, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7705 - mean_absolute_error: 0.5713 - mean_squared_error: 0.7705 - val_loss: 0.8521 - val_mean_absolute_error: 0.5929 - val_mean_squared_error: 0.8521\n",
            "Epoch 629/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.7712 - mean_absolute_error: 0.5725 - mean_squared_error: 0.7712\n",
            "Epoch 629: val_loss did not improve from 0.85210\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7680 - mean_absolute_error: 0.5709 - mean_squared_error: 0.7680 - val_loss: 0.8570 - val_mean_absolute_error: 0.5958 - val_mean_squared_error: 0.8570\n",
            "Epoch 630/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.7640 - mean_absolute_error: 0.5684 - mean_squared_error: 0.7640\n",
            "Epoch 630: val_loss improved from 0.85210 to 0.84916, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7645 - mean_absolute_error: 0.5688 - mean_squared_error: 0.7645 - val_loss: 0.8492 - val_mean_absolute_error: 0.5932 - val_mean_squared_error: 0.8492\n",
            "Epoch 631/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.7607 - mean_absolute_error: 0.5693 - mean_squared_error: 0.7607\n",
            "Epoch 631: val_loss improved from 0.84916 to 0.84612, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7613 - mean_absolute_error: 0.5675 - mean_squared_error: 0.7613 - val_loss: 0.8461 - val_mean_absolute_error: 0.5894 - val_mean_squared_error: 0.8461\n",
            "Epoch 632/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.7579 - mean_absolute_error: 0.5656 - mean_squared_error: 0.7579\n",
            "Epoch 632: val_loss improved from 0.84612 to 0.84419, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.7609 - mean_absolute_error: 0.5666 - mean_squared_error: 0.7609 - val_loss: 0.8442 - val_mean_absolute_error: 0.5885 - val_mean_squared_error: 0.8442\n",
            "Epoch 633/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.7641 - mean_absolute_error: 0.5714 - mean_squared_error: 0.7641\n",
            "Epoch 633: val_loss improved from 0.84419 to 0.84027, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7571 - mean_absolute_error: 0.5671 - mean_squared_error: 0.7571 - val_loss: 0.8403 - val_mean_absolute_error: 0.5871 - val_mean_squared_error: 0.8403\n",
            "Epoch 634/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.7540 - mean_absolute_error: 0.5640 - mean_squared_error: 0.7540\n",
            "Epoch 634: val_loss did not improve from 0.84027\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.7533 - mean_absolute_error: 0.5640 - mean_squared_error: 0.7533 - val_loss: 0.8440 - val_mean_absolute_error: 0.5875 - val_mean_squared_error: 0.8440\n",
            "Epoch 635/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.7530 - mean_absolute_error: 0.5642 - mean_squared_error: 0.7530\n",
            "Epoch 635: val_loss improved from 0.84027 to 0.83997, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.7517 - mean_absolute_error: 0.5632 - mean_squared_error: 0.7517 - val_loss: 0.8400 - val_mean_absolute_error: 0.5858 - val_mean_squared_error: 0.8400\n",
            "Epoch 636/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.7537 - mean_absolute_error: 0.5649 - mean_squared_error: 0.7537\n",
            "Epoch 636: val_loss improved from 0.83997 to 0.83577, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7501 - mean_absolute_error: 0.5624 - mean_squared_error: 0.7501 - val_loss: 0.8358 - val_mean_absolute_error: 0.5857 - val_mean_squared_error: 0.8358\n",
            "Epoch 637/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.7513 - mean_absolute_error: 0.5634 - mean_squared_error: 0.7513\n",
            "Epoch 637: val_loss did not improve from 0.83577\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.7489 - mean_absolute_error: 0.5620 - mean_squared_error: 0.7489 - val_loss: 0.8363 - val_mean_absolute_error: 0.5832 - val_mean_squared_error: 0.8363\n",
            "Epoch 638/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.7398 - mean_absolute_error: 0.5560 - mean_squared_error: 0.7398\n",
            "Epoch 638: val_loss improved from 0.83577 to 0.83502, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7432 - mean_absolute_error: 0.5592 - mean_squared_error: 0.7432 - val_loss: 0.8350 - val_mean_absolute_error: 0.5833 - val_mean_squared_error: 0.8350\n",
            "Epoch 639/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.7391 - mean_absolute_error: 0.5568 - mean_squared_error: 0.7391\n",
            "Epoch 639: val_loss improved from 0.83502 to 0.83111, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7416 - mean_absolute_error: 0.5581 - mean_squared_error: 0.7416 - val_loss: 0.8311 - val_mean_absolute_error: 0.5853 - val_mean_squared_error: 0.8311\n",
            "Epoch 640/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7390 - mean_absolute_error: 0.5576 - mean_squared_error: 0.7390\n",
            "Epoch 640: val_loss improved from 0.83111 to 0.82641, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.7390 - mean_absolute_error: 0.5576 - mean_squared_error: 0.7390 - val_loss: 0.8264 - val_mean_absolute_error: 0.5802 - val_mean_squared_error: 0.8264\n",
            "Epoch 641/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.7402 - mean_absolute_error: 0.5563 - mean_squared_error: 0.7402\n",
            "Epoch 641: val_loss improved from 0.82641 to 0.82375, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7367 - mean_absolute_error: 0.5554 - mean_squared_error: 0.7367 - val_loss: 0.8238 - val_mean_absolute_error: 0.5821 - val_mean_squared_error: 0.8238\n",
            "Epoch 642/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.7270 - mean_absolute_error: 0.5539 - mean_squared_error: 0.7270\n",
            "Epoch 642: val_loss improved from 0.82375 to 0.82302, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7351 - mean_absolute_error: 0.5563 - mean_squared_error: 0.7351 - val_loss: 0.8230 - val_mean_absolute_error: 0.5797 - val_mean_squared_error: 0.8230\n",
            "Epoch 643/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.7320 - mean_absolute_error: 0.5557 - mean_squared_error: 0.7320\n",
            "Epoch 643: val_loss improved from 0.82302 to 0.82165, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7315 - mean_absolute_error: 0.5545 - mean_squared_error: 0.7315 - val_loss: 0.8216 - val_mean_absolute_error: 0.5812 - val_mean_squared_error: 0.8216\n",
            "Epoch 644/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.7312 - mean_absolute_error: 0.5540 - mean_squared_error: 0.7312\n",
            "Epoch 644: val_loss did not improve from 0.82165\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7296 - mean_absolute_error: 0.5532 - mean_squared_error: 0.7296 - val_loss: 0.8229 - val_mean_absolute_error: 0.5797 - val_mean_squared_error: 0.8229\n",
            "Epoch 645/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.7267 - mean_absolute_error: 0.5513 - mean_squared_error: 0.7267\n",
            "Epoch 645: val_loss improved from 0.82165 to 0.81905, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7265 - mean_absolute_error: 0.5509 - mean_squared_error: 0.7265 - val_loss: 0.8191 - val_mean_absolute_error: 0.5783 - val_mean_squared_error: 0.8191\n",
            "Epoch 646/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.7190 - mean_absolute_error: 0.5519 - mean_squared_error: 0.7190\n",
            "Epoch 646: val_loss improved from 0.81905 to 0.81817, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.7252 - mean_absolute_error: 0.5515 - mean_squared_error: 0.7252 - val_loss: 0.8182 - val_mean_absolute_error: 0.5737 - val_mean_squared_error: 0.8182\n",
            "Epoch 647/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.7277 - mean_absolute_error: 0.5533 - mean_squared_error: 0.7277\n",
            "Epoch 647: val_loss improved from 0.81817 to 0.81532, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7223 - mean_absolute_error: 0.5493 - mean_squared_error: 0.7223 - val_loss: 0.8153 - val_mean_absolute_error: 0.5744 - val_mean_squared_error: 0.8153\n",
            "Epoch 648/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.7073 - mean_absolute_error: 0.5443 - mean_squared_error: 0.7073\n",
            "Epoch 648: val_loss improved from 0.81532 to 0.81531, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7202 - mean_absolute_error: 0.5479 - mean_squared_error: 0.7202 - val_loss: 0.8153 - val_mean_absolute_error: 0.5746 - val_mean_squared_error: 0.8153\n",
            "Epoch 649/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.7221 - mean_absolute_error: 0.5504 - mean_squared_error: 0.7221\n",
            "Epoch 649: val_loss improved from 0.81531 to 0.81158, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7181 - mean_absolute_error: 0.5477 - mean_squared_error: 0.7181 - val_loss: 0.8116 - val_mean_absolute_error: 0.5730 - val_mean_squared_error: 0.8116\n",
            "Epoch 650/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.7077 - mean_absolute_error: 0.5447 - mean_squared_error: 0.7077\n",
            "Epoch 650: val_loss improved from 0.81158 to 0.80765, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7154 - mean_absolute_error: 0.5461 - mean_squared_error: 0.7154 - val_loss: 0.8076 - val_mean_absolute_error: 0.5705 - val_mean_squared_error: 0.8076\n",
            "Epoch 651/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.7230 - mean_absolute_error: 0.5477 - mean_squared_error: 0.7230\n",
            "Epoch 651: val_loss improved from 0.80765 to 0.80741, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7134 - mean_absolute_error: 0.5440 - mean_squared_error: 0.7134 - val_loss: 0.8074 - val_mean_absolute_error: 0.5688 - val_mean_squared_error: 0.8074\n",
            "Epoch 652/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.6971 - mean_absolute_error: 0.5378 - mean_squared_error: 0.6971\n",
            "Epoch 652: val_loss improved from 0.80741 to 0.80374, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.7120 - mean_absolute_error: 0.5440 - mean_squared_error: 0.7120 - val_loss: 0.8037 - val_mean_absolute_error: 0.5703 - val_mean_squared_error: 0.8037\n",
            "Epoch 653/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.7130 - mean_absolute_error: 0.5438 - mean_squared_error: 0.7130\n",
            "Epoch 653: val_loss improved from 0.80374 to 0.80109, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7087 - mean_absolute_error: 0.5426 - mean_squared_error: 0.7087 - val_loss: 0.8011 - val_mean_absolute_error: 0.5685 - val_mean_squared_error: 0.8011\n",
            "Epoch 654/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.7107 - mean_absolute_error: 0.5433 - mean_squared_error: 0.7107\n",
            "Epoch 654: val_loss did not improve from 0.80109\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.7064 - mean_absolute_error: 0.5410 - mean_squared_error: 0.7064 - val_loss: 0.8018 - val_mean_absolute_error: 0.5672 - val_mean_squared_error: 0.8018\n",
            "Epoch 655/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.7136 - mean_absolute_error: 0.5435 - mean_squared_error: 0.7136\n",
            "Epoch 655: val_loss improved from 0.80109 to 0.79801, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7039 - mean_absolute_error: 0.5400 - mean_squared_error: 0.7039 - val_loss: 0.7980 - val_mean_absolute_error: 0.5672 - val_mean_squared_error: 0.7980\n",
            "Epoch 656/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.7086 - mean_absolute_error: 0.5404 - mean_squared_error: 0.7086\n",
            "Epoch 656: val_loss improved from 0.79801 to 0.79778, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7023 - mean_absolute_error: 0.5387 - mean_squared_error: 0.7023 - val_loss: 0.7978 - val_mean_absolute_error: 0.5725 - val_mean_squared_error: 0.7978\n",
            "Epoch 657/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.6996 - mean_absolute_error: 0.5404 - mean_squared_error: 0.6996\n",
            "Epoch 657: val_loss improved from 0.79778 to 0.79638, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.7006 - mean_absolute_error: 0.5389 - mean_squared_error: 0.7006 - val_loss: 0.7964 - val_mean_absolute_error: 0.5645 - val_mean_squared_error: 0.7964\n",
            "Epoch 658/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.6884 - mean_absolute_error: 0.5325 - mean_squared_error: 0.6884\n",
            "Epoch 658: val_loss improved from 0.79638 to 0.79590, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6991 - mean_absolute_error: 0.5374 - mean_squared_error: 0.6991 - val_loss: 0.7959 - val_mean_absolute_error: 0.5681 - val_mean_squared_error: 0.7959\n",
            "Epoch 659/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.6996 - mean_absolute_error: 0.5372 - mean_squared_error: 0.6996\n",
            "Epoch 659: val_loss improved from 0.79590 to 0.79459, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6962 - mean_absolute_error: 0.5358 - mean_squared_error: 0.6962 - val_loss: 0.7946 - val_mean_absolute_error: 0.5666 - val_mean_squared_error: 0.7946\n",
            "Epoch 660/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.6977 - mean_absolute_error: 0.5361 - mean_squared_error: 0.6977\n",
            "Epoch 660: val_loss did not improve from 0.79459\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6939 - mean_absolute_error: 0.5351 - mean_squared_error: 0.6939 - val_loss: 0.7965 - val_mean_absolute_error: 0.5656 - val_mean_squared_error: 0.7965\n",
            "Epoch 661/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.6863 - mean_absolute_error: 0.5325 - mean_squared_error: 0.6863\n",
            "Epoch 661: val_loss improved from 0.79459 to 0.78975, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6929 - mean_absolute_error: 0.5350 - mean_squared_error: 0.6929 - val_loss: 0.7898 - val_mean_absolute_error: 0.5637 - val_mean_squared_error: 0.7898\n",
            "Epoch 662/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.6879 - mean_absolute_error: 0.5315 - mean_squared_error: 0.6879\n",
            "Epoch 662: val_loss did not improve from 0.78975\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6899 - mean_absolute_error: 0.5332 - mean_squared_error: 0.6899 - val_loss: 0.7898 - val_mean_absolute_error: 0.5620 - val_mean_squared_error: 0.7898\n",
            "Epoch 663/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.6899 - mean_absolute_error: 0.5345 - mean_squared_error: 0.6899\n",
            "Epoch 663: val_loss improved from 0.78975 to 0.78763, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6890 - mean_absolute_error: 0.5338 - mean_squared_error: 0.6890 - val_loss: 0.7876 - val_mean_absolute_error: 0.5623 - val_mean_squared_error: 0.7876\n",
            "Epoch 664/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.6868 - mean_absolute_error: 0.5306 - mean_squared_error: 0.6868\n",
            "Epoch 664: val_loss improved from 0.78763 to 0.78568, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6868 - mean_absolute_error: 0.5306 - mean_squared_error: 0.6868 - val_loss: 0.7857 - val_mean_absolute_error: 0.5604 - val_mean_squared_error: 0.7857\n",
            "Epoch 665/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.6884 - mean_absolute_error: 0.5329 - mean_squared_error: 0.6884\n",
            "Epoch 665: val_loss improved from 0.78568 to 0.78341, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6853 - mean_absolute_error: 0.5308 - mean_squared_error: 0.6853 - val_loss: 0.7834 - val_mean_absolute_error: 0.5612 - val_mean_squared_error: 0.7834\n",
            "Epoch 666/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.6934 - mean_absolute_error: 0.5344 - mean_squared_error: 0.6934\n",
            "Epoch 666: val_loss did not improve from 0.78341\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6844 - mean_absolute_error: 0.5305 - mean_squared_error: 0.6844 - val_loss: 0.7856 - val_mean_absolute_error: 0.5583 - val_mean_squared_error: 0.7856\n",
            "Epoch 667/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.6886 - mean_absolute_error: 0.5301 - mean_squared_error: 0.6886\n",
            "Epoch 667: val_loss improved from 0.78341 to 0.78156, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6809 - mean_absolute_error: 0.5282 - mean_squared_error: 0.6809 - val_loss: 0.7816 - val_mean_absolute_error: 0.5590 - val_mean_squared_error: 0.7816\n",
            "Epoch 668/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.6815 - mean_absolute_error: 0.5268 - mean_squared_error: 0.6815\n",
            "Epoch 668: val_loss improved from 0.78156 to 0.77750, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6794 - mean_absolute_error: 0.5263 - mean_squared_error: 0.6794 - val_loss: 0.7775 - val_mean_absolute_error: 0.5574 - val_mean_squared_error: 0.7775\n",
            "Epoch 669/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.6809 - mean_absolute_error: 0.5298 - mean_squared_error: 0.6809\n",
            "Epoch 669: val_loss did not improve from 0.77750\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6784 - mean_absolute_error: 0.5282 - mean_squared_error: 0.6784 - val_loss: 0.7817 - val_mean_absolute_error: 0.5603 - val_mean_squared_error: 0.7817\n",
            "Epoch 670/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.6703 - mean_absolute_error: 0.5224 - mean_squared_error: 0.6703\n",
            "Epoch 670: val_loss improved from 0.77750 to 0.77505, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6751 - mean_absolute_error: 0.5249 - mean_squared_error: 0.6751 - val_loss: 0.7751 - val_mean_absolute_error: 0.5556 - val_mean_squared_error: 0.7751\n",
            "Epoch 671/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.6773 - mean_absolute_error: 0.5253 - mean_squared_error: 0.6773\n",
            "Epoch 671: val_loss did not improve from 0.77505\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6743 - mean_absolute_error: 0.5250 - mean_squared_error: 0.6743 - val_loss: 0.7768 - val_mean_absolute_error: 0.5536 - val_mean_squared_error: 0.7768\n",
            "Epoch 672/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.6749 - mean_absolute_error: 0.5243 - mean_squared_error: 0.6749\n",
            "Epoch 672: val_loss improved from 0.77505 to 0.77142, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6739 - mean_absolute_error: 0.5241 - mean_squared_error: 0.6739 - val_loss: 0.7714 - val_mean_absolute_error: 0.5537 - val_mean_squared_error: 0.7714\n",
            "Epoch 673/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.6803 - mean_absolute_error: 0.5254 - mean_squared_error: 0.6803\n",
            "Epoch 673: val_loss did not improve from 0.77142\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6702 - mean_absolute_error: 0.5220 - mean_squared_error: 0.6702 - val_loss: 0.7723 - val_mean_absolute_error: 0.5545 - val_mean_squared_error: 0.7723\n",
            "Epoch 674/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.6701 - mean_absolute_error: 0.5220 - mean_squared_error: 0.6701\n",
            "Epoch 674: val_loss improved from 0.77142 to 0.77140, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6698 - mean_absolute_error: 0.5219 - mean_squared_error: 0.6698 - val_loss: 0.7714 - val_mean_absolute_error: 0.5522 - val_mean_squared_error: 0.7714\n",
            "Epoch 675/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.6560 - mean_absolute_error: 0.5169 - mean_squared_error: 0.6560\n",
            "Epoch 675: val_loss improved from 0.77140 to 0.76996, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6681 - mean_absolute_error: 0.5213 - mean_squared_error: 0.6681 - val_loss: 0.7700 - val_mean_absolute_error: 0.5516 - val_mean_squared_error: 0.7700\n",
            "Epoch 676/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.6641 - mean_absolute_error: 0.5192 - mean_squared_error: 0.6641\n",
            "Epoch 676: val_loss improved from 0.76996 to 0.76662, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6660 - mean_absolute_error: 0.5199 - mean_squared_error: 0.6660 - val_loss: 0.7666 - val_mean_absolute_error: 0.5522 - val_mean_squared_error: 0.7666\n",
            "Epoch 677/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.6627 - mean_absolute_error: 0.5179 - mean_squared_error: 0.6627\n",
            "Epoch 677: val_loss did not improve from 0.76662\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6650 - mean_absolute_error: 0.5193 - mean_squared_error: 0.6650 - val_loss: 0.7682 - val_mean_absolute_error: 0.5510 - val_mean_squared_error: 0.7682\n",
            "Epoch 678/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.6593 - mean_absolute_error: 0.5146 - mean_squared_error: 0.6593\n",
            "Epoch 678: val_loss did not improve from 0.76662\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6616 - mean_absolute_error: 0.5170 - mean_squared_error: 0.6616 - val_loss: 0.7711 - val_mean_absolute_error: 0.5547 - val_mean_squared_error: 0.7711\n",
            "Epoch 679/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.6596 - mean_absolute_error: 0.5176 - mean_squared_error: 0.6596\n",
            "Epoch 679: val_loss did not improve from 0.76662\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6615 - mean_absolute_error: 0.5172 - mean_squared_error: 0.6615 - val_loss: 0.7691 - val_mean_absolute_error: 0.5498 - val_mean_squared_error: 0.7691\n",
            "Epoch 680/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.6553 - mean_absolute_error: 0.5155 - mean_squared_error: 0.6553\n",
            "Epoch 680: val_loss improved from 0.76662 to 0.76453, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6592 - mean_absolute_error: 0.5160 - mean_squared_error: 0.6592 - val_loss: 0.7645 - val_mean_absolute_error: 0.5481 - val_mean_squared_error: 0.7645\n",
            "Epoch 681/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.6600 - mean_absolute_error: 0.5152 - mean_squared_error: 0.6600\n",
            "Epoch 681: val_loss did not improve from 0.76453\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6584 - mean_absolute_error: 0.5146 - mean_squared_error: 0.6584 - val_loss: 0.7676 - val_mean_absolute_error: 0.5467 - val_mean_squared_error: 0.7676\n",
            "Epoch 682/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.6572 - mean_absolute_error: 0.5147 - mean_squared_error: 0.6572\n",
            "Epoch 682: val_loss improved from 0.76453 to 0.76079, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6578 - mean_absolute_error: 0.5156 - mean_squared_error: 0.6578 - val_loss: 0.7608 - val_mean_absolute_error: 0.5516 - val_mean_squared_error: 0.7608\n",
            "Epoch 683/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.6532 - mean_absolute_error: 0.5140 - mean_squared_error: 0.6532\n",
            "Epoch 683: val_loss improved from 0.76079 to 0.76054, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6552 - mean_absolute_error: 0.5139 - mean_squared_error: 0.6552 - val_loss: 0.7605 - val_mean_absolute_error: 0.5453 - val_mean_squared_error: 0.7605\n",
            "Epoch 684/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.6537 - mean_absolute_error: 0.5127 - mean_squared_error: 0.6537\n",
            "Epoch 684: val_loss improved from 0.76054 to 0.75842, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6537 - mean_absolute_error: 0.5127 - mean_squared_error: 0.6537 - val_loss: 0.7584 - val_mean_absolute_error: 0.5461 - val_mean_squared_error: 0.7584\n",
            "Epoch 685/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.6531 - mean_absolute_error: 0.5125 - mean_squared_error: 0.6531\n",
            "Epoch 685: val_loss improved from 0.75842 to 0.75563, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6531 - mean_absolute_error: 0.5125 - mean_squared_error: 0.6531 - val_loss: 0.7556 - val_mean_absolute_error: 0.5443 - val_mean_squared_error: 0.7556\n",
            "Epoch 686/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.6546 - mean_absolute_error: 0.5125 - mean_squared_error: 0.6546\n",
            "Epoch 686: val_loss did not improve from 0.75563\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6533 - mean_absolute_error: 0.5122 - mean_squared_error: 0.6533 - val_loss: 0.7570 - val_mean_absolute_error: 0.5452 - val_mean_squared_error: 0.7570\n",
            "Epoch 687/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.6522 - mean_absolute_error: 0.5110 - mean_squared_error: 0.6522\n",
            "Epoch 687: val_loss improved from 0.75563 to 0.75553, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6502 - mean_absolute_error: 0.5103 - mean_squared_error: 0.6502 - val_loss: 0.7555 - val_mean_absolute_error: 0.5439 - val_mean_squared_error: 0.7555\n",
            "Epoch 688/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.6533 - mean_absolute_error: 0.5118 - mean_squared_error: 0.6533\n",
            "Epoch 688: val_loss improved from 0.75553 to 0.75466, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6489 - mean_absolute_error: 0.5101 - mean_squared_error: 0.6489 - val_loss: 0.7547 - val_mean_absolute_error: 0.5454 - val_mean_squared_error: 0.7547\n",
            "Epoch 689/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.6514 - mean_absolute_error: 0.5098 - mean_squared_error: 0.6514\n",
            "Epoch 689: val_loss did not improve from 0.75466\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6483 - mean_absolute_error: 0.5086 - mean_squared_error: 0.6483 - val_loss: 0.7554 - val_mean_absolute_error: 0.5478 - val_mean_squared_error: 0.7554\n",
            "Epoch 690/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.6469 - mean_absolute_error: 0.5081 - mean_squared_error: 0.6469\n",
            "Epoch 690: val_loss did not improve from 0.75466\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6469 - mean_absolute_error: 0.5091 - mean_squared_error: 0.6469 - val_loss: 0.7547 - val_mean_absolute_error: 0.5462 - val_mean_squared_error: 0.7547\n",
            "Epoch 691/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.6445 - mean_absolute_error: 0.5062 - mean_squared_error: 0.6445\n",
            "Epoch 691: val_loss improved from 0.75466 to 0.74992, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6442 - mean_absolute_error: 0.5061 - mean_squared_error: 0.6442 - val_loss: 0.7499 - val_mean_absolute_error: 0.5438 - val_mean_squared_error: 0.7499\n",
            "Epoch 692/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.6448 - mean_absolute_error: 0.5072 - mean_squared_error: 0.6448\n",
            "Epoch 692: val_loss improved from 0.74992 to 0.74935, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6436 - mean_absolute_error: 0.5073 - mean_squared_error: 0.6436 - val_loss: 0.7493 - val_mean_absolute_error: 0.5411 - val_mean_squared_error: 0.7493\n",
            "Epoch 693/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.6400 - mean_absolute_error: 0.5058 - mean_squared_error: 0.6400\n",
            "Epoch 693: val_loss improved from 0.74935 to 0.74890, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6429 - mean_absolute_error: 0.5065 - mean_squared_error: 0.6429 - val_loss: 0.7489 - val_mean_absolute_error: 0.5412 - val_mean_squared_error: 0.7489\n",
            "Epoch 694/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.6489 - mean_absolute_error: 0.5081 - mean_squared_error: 0.6489\n",
            "Epoch 694: val_loss improved from 0.74890 to 0.74453, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6405 - mean_absolute_error: 0.5045 - mean_squared_error: 0.6405 - val_loss: 0.7445 - val_mean_absolute_error: 0.5390 - val_mean_squared_error: 0.7445\n",
            "Epoch 695/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.6474 - mean_absolute_error: 0.5073 - mean_squared_error: 0.6474\n",
            "Epoch 695: val_loss did not improve from 0.74453\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6415 - mean_absolute_error: 0.5054 - mean_squared_error: 0.6415 - val_loss: 0.7466 - val_mean_absolute_error: 0.5378 - val_mean_squared_error: 0.7466\n",
            "Epoch 696/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.6362 - mean_absolute_error: 0.5034 - mean_squared_error: 0.6362\n",
            "Epoch 696: val_loss did not improve from 0.74453\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6392 - mean_absolute_error: 0.5046 - mean_squared_error: 0.6392 - val_loss: 0.7449 - val_mean_absolute_error: 0.5397 - val_mean_squared_error: 0.7449\n",
            "Epoch 697/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.6373 - mean_absolute_error: 0.5043 - mean_squared_error: 0.6373\n",
            "Epoch 697: val_loss did not improve from 0.74453\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6381 - mean_absolute_error: 0.5038 - mean_squared_error: 0.6381 - val_loss: 0.7446 - val_mean_absolute_error: 0.5361 - val_mean_squared_error: 0.7446\n",
            "Epoch 698/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.6269 - mean_absolute_error: 0.4988 - mean_squared_error: 0.6269\n",
            "Epoch 698: val_loss improved from 0.74453 to 0.74307, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6381 - mean_absolute_error: 0.5029 - mean_squared_error: 0.6381 - val_loss: 0.7431 - val_mean_absolute_error: 0.5376 - val_mean_squared_error: 0.7431\n",
            "Epoch 699/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.6324 - mean_absolute_error: 0.5009 - mean_squared_error: 0.6324\n",
            "Epoch 699: val_loss did not improve from 0.74307\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6355 - mean_absolute_error: 0.5022 - mean_squared_error: 0.6355 - val_loss: 0.7432 - val_mean_absolute_error: 0.5376 - val_mean_squared_error: 0.7432\n",
            "Epoch 700/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.6342 - mean_absolute_error: 0.5019 - mean_squared_error: 0.6342\n",
            "Epoch 700: val_loss improved from 0.74307 to 0.74186, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6350 - mean_absolute_error: 0.5015 - mean_squared_error: 0.6350 - val_loss: 0.7419 - val_mean_absolute_error: 0.5348 - val_mean_squared_error: 0.7419\n",
            "Epoch 701/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.6351 - mean_absolute_error: 0.5007 - mean_squared_error: 0.6351\n",
            "Epoch 701: val_loss improved from 0.74186 to 0.73991, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6338 - mean_absolute_error: 0.5002 - mean_squared_error: 0.6338 - val_loss: 0.7399 - val_mean_absolute_error: 0.5338 - val_mean_squared_error: 0.7399\n",
            "Epoch 702/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.6351 - mean_absolute_error: 0.5007 - mean_squared_error: 0.6351\n",
            "Epoch 702: val_loss improved from 0.73991 to 0.73783, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6325 - mean_absolute_error: 0.4997 - mean_squared_error: 0.6325 - val_loss: 0.7378 - val_mean_absolute_error: 0.5339 - val_mean_squared_error: 0.7378\n",
            "Epoch 703/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.6243 - mean_absolute_error: 0.4976 - mean_squared_error: 0.6243\n",
            "Epoch 703: val_loss did not improve from 0.73783\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6313 - mean_absolute_error: 0.5002 - mean_squared_error: 0.6313 - val_loss: 0.7384 - val_mean_absolute_error: 0.5329 - val_mean_squared_error: 0.7384\n",
            "Epoch 704/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.6324 - mean_absolute_error: 0.4999 - mean_squared_error: 0.6324\n",
            "Epoch 704: val_loss improved from 0.73783 to 0.73683, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.6305 - mean_absolute_error: 0.4981 - mean_squared_error: 0.6305 - val_loss: 0.7368 - val_mean_absolute_error: 0.5342 - val_mean_squared_error: 0.7368\n",
            "Epoch 705/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.6286 - mean_absolute_error: 0.4971 - mean_squared_error: 0.6286\n",
            "Epoch 705: val_loss did not improve from 0.73683\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6285 - mean_absolute_error: 0.4976 - mean_squared_error: 0.6285 - val_loss: 0.7412 - val_mean_absolute_error: 0.5330 - val_mean_squared_error: 0.7412\n",
            "Epoch 706/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.6266 - mean_absolute_error: 0.4950 - mean_squared_error: 0.6266\n",
            "Epoch 706: val_loss improved from 0.73683 to 0.73324, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.6270 - mean_absolute_error: 0.4957 - mean_squared_error: 0.6270 - val_loss: 0.7332 - val_mean_absolute_error: 0.5314 - val_mean_squared_error: 0.7332\n",
            "Epoch 707/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.6314 - mean_absolute_error: 0.4988 - mean_squared_error: 0.6314\n",
            "Epoch 707: val_loss did not improve from 0.73324\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6269 - mean_absolute_error: 0.4969 - mean_squared_error: 0.6269 - val_loss: 0.7345 - val_mean_absolute_error: 0.5329 - val_mean_squared_error: 0.7345\n",
            "Epoch 708/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.6273 - mean_absolute_error: 0.4954 - mean_squared_error: 0.6273\n",
            "Epoch 708: val_loss did not improve from 0.73324\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6255 - mean_absolute_error: 0.4951 - mean_squared_error: 0.6255 - val_loss: 0.7376 - val_mean_absolute_error: 0.5321 - val_mean_squared_error: 0.7376\n",
            "Epoch 709/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.6237 - mean_absolute_error: 0.4952 - mean_squared_error: 0.6237\n",
            "Epoch 709: val_loss did not improve from 0.73324\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6249 - mean_absolute_error: 0.4960 - mean_squared_error: 0.6249 - val_loss: 0.7354 - val_mean_absolute_error: 0.5301 - val_mean_squared_error: 0.7354\n",
            "Epoch 710/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.6203 - mean_absolute_error: 0.4927 - mean_squared_error: 0.6203\n",
            "Epoch 710: val_loss improved from 0.73324 to 0.73190, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6234 - mean_absolute_error: 0.4935 - mean_squared_error: 0.6234 - val_loss: 0.7319 - val_mean_absolute_error: 0.5311 - val_mean_squared_error: 0.7319\n",
            "Epoch 711/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.6299 - mean_absolute_error: 0.4978 - mean_squared_error: 0.6299\n",
            "Epoch 711: val_loss improved from 0.73190 to 0.73158, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6232 - mean_absolute_error: 0.4948 - mean_squared_error: 0.6232 - val_loss: 0.7316 - val_mean_absolute_error: 0.5284 - val_mean_squared_error: 0.7316\n",
            "Epoch 712/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.6209 - mean_absolute_error: 0.4928 - mean_squared_error: 0.6209\n",
            "Epoch 712: val_loss improved from 0.73158 to 0.73077, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6228 - mean_absolute_error: 0.4935 - mean_squared_error: 0.6228 - val_loss: 0.7308 - val_mean_absolute_error: 0.5318 - val_mean_squared_error: 0.7308\n",
            "Epoch 713/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.6154 - mean_absolute_error: 0.4929 - mean_squared_error: 0.6154\n",
            "Epoch 713: val_loss improved from 0.73077 to 0.72745, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6216 - mean_absolute_error: 0.4945 - mean_squared_error: 0.6216 - val_loss: 0.7275 - val_mean_absolute_error: 0.5261 - val_mean_squared_error: 0.7275\n",
            "Epoch 714/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.6180 - mean_absolute_error: 0.4926 - mean_squared_error: 0.6180\n",
            "Epoch 714: val_loss improved from 0.72745 to 0.72724, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6205 - mean_absolute_error: 0.4925 - mean_squared_error: 0.6205 - val_loss: 0.7272 - val_mean_absolute_error: 0.5280 - val_mean_squared_error: 0.7272\n",
            "Epoch 715/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.6237 - mean_absolute_error: 0.4937 - mean_squared_error: 0.6237\n",
            "Epoch 715: val_loss did not improve from 0.72724\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6200 - mean_absolute_error: 0.4927 - mean_squared_error: 0.6200 - val_loss: 0.7308 - val_mean_absolute_error: 0.5289 - val_mean_squared_error: 0.7308\n",
            "Epoch 716/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.6195 - mean_absolute_error: 0.4913 - mean_squared_error: 0.6195\n",
            "Epoch 716: val_loss improved from 0.72724 to 0.72564, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6185 - mean_absolute_error: 0.4910 - mean_squared_error: 0.6185 - val_loss: 0.7256 - val_mean_absolute_error: 0.5262 - val_mean_squared_error: 0.7256\n",
            "Epoch 717/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.6155 - mean_absolute_error: 0.4905 - mean_squared_error: 0.6155\n",
            "Epoch 717: val_loss improved from 0.72564 to 0.72513, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6172 - mean_absolute_error: 0.4906 - mean_squared_error: 0.6172 - val_loss: 0.7251 - val_mean_absolute_error: 0.5272 - val_mean_squared_error: 0.7251\n",
            "Epoch 718/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.6162 - mean_absolute_error: 0.4901 - mean_squared_error: 0.6162\n",
            "Epoch 718: val_loss did not improve from 0.72513\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6168 - mean_absolute_error: 0.4902 - mean_squared_error: 0.6168 - val_loss: 0.7305 - val_mean_absolute_error: 0.5260 - val_mean_squared_error: 0.7305\n",
            "Epoch 719/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.6161 - mean_absolute_error: 0.4897 - mean_squared_error: 0.6161\n",
            "Epoch 719: val_loss did not improve from 0.72513\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6160 - mean_absolute_error: 0.4899 - mean_squared_error: 0.6160 - val_loss: 0.7267 - val_mean_absolute_error: 0.5267 - val_mean_squared_error: 0.7267\n",
            "Epoch 720/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.6162 - mean_absolute_error: 0.4898 - mean_squared_error: 0.6162\n",
            "Epoch 720: val_loss improved from 0.72513 to 0.72289, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6155 - mean_absolute_error: 0.4896 - mean_squared_error: 0.6155 - val_loss: 0.7229 - val_mean_absolute_error: 0.5250 - val_mean_squared_error: 0.7229\n",
            "Epoch 721/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.6062 - mean_absolute_error: 0.4856 - mean_squared_error: 0.6062\n",
            "Epoch 721: val_loss improved from 0.72289 to 0.72209, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6135 - mean_absolute_error: 0.4890 - mean_squared_error: 0.6135 - val_loss: 0.7221 - val_mean_absolute_error: 0.5236 - val_mean_squared_error: 0.7221\n",
            "Epoch 722/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.5993 - mean_absolute_error: 0.4817 - mean_squared_error: 0.5993\n",
            "Epoch 722: val_loss improved from 0.72209 to 0.71938, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6136 - mean_absolute_error: 0.4877 - mean_squared_error: 0.6136 - val_loss: 0.7194 - val_mean_absolute_error: 0.5219 - val_mean_squared_error: 0.7194\n",
            "Epoch 723/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.6080 - mean_absolute_error: 0.4854 - mean_squared_error: 0.6080\n",
            "Epoch 723: val_loss did not improve from 0.71938\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6138 - mean_absolute_error: 0.4881 - mean_squared_error: 0.6138 - val_loss: 0.7233 - val_mean_absolute_error: 0.5228 - val_mean_squared_error: 0.7233\n",
            "Epoch 724/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.6117 - mean_absolute_error: 0.4894 - mean_squared_error: 0.6117\n",
            "Epoch 724: val_loss did not improve from 0.71938\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6115 - mean_absolute_error: 0.4878 - mean_squared_error: 0.6115 - val_loss: 0.7225 - val_mean_absolute_error: 0.5256 - val_mean_squared_error: 0.7225\n",
            "Epoch 725/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.6120 - mean_absolute_error: 0.4872 - mean_squared_error: 0.6120\n",
            "Epoch 725: val_loss did not improve from 0.71938\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6109 - mean_absolute_error: 0.4860 - mean_squared_error: 0.6109 - val_loss: 0.7200 - val_mean_absolute_error: 0.5232 - val_mean_squared_error: 0.7200\n",
            "Epoch 726/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.6158 - mean_absolute_error: 0.4889 - mean_squared_error: 0.6158\n",
            "Epoch 726: val_loss did not improve from 0.71938\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6098 - mean_absolute_error: 0.4859 - mean_squared_error: 0.6098 - val_loss: 0.7211 - val_mean_absolute_error: 0.5207 - val_mean_squared_error: 0.7211\n",
            "Epoch 727/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.6093 - mean_absolute_error: 0.4857 - mean_squared_error: 0.6093\n",
            "Epoch 727: val_loss improved from 0.71938 to 0.71665, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6096 - mean_absolute_error: 0.4855 - mean_squared_error: 0.6096 - val_loss: 0.7167 - val_mean_absolute_error: 0.5222 - val_mean_squared_error: 0.7167\n",
            "Epoch 728/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.6098 - mean_absolute_error: 0.4857 - mean_squared_error: 0.6098\n",
            "Epoch 728: val_loss did not improve from 0.71665\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6085 - mean_absolute_error: 0.4854 - mean_squared_error: 0.6085 - val_loss: 0.7173 - val_mean_absolute_error: 0.5203 - val_mean_squared_error: 0.7173\n",
            "Epoch 729/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.6020 - mean_absolute_error: 0.4823 - mean_squared_error: 0.6020\n",
            "Epoch 729: val_loss did not improve from 0.71665\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6078 - mean_absolute_error: 0.4847 - mean_squared_error: 0.6078 - val_loss: 0.7182 - val_mean_absolute_error: 0.5209 - val_mean_squared_error: 0.7182\n",
            "Epoch 730/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.6057 - mean_absolute_error: 0.4828 - mean_squared_error: 0.6057\n",
            "Epoch 730: val_loss did not improve from 0.71665\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6065 - mean_absolute_error: 0.4830 - mean_squared_error: 0.6065 - val_loss: 0.7239 - val_mean_absolute_error: 0.5292 - val_mean_squared_error: 0.7239\n",
            "Epoch 731/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.6053 - mean_absolute_error: 0.4831 - mean_squared_error: 0.6053\n",
            "Epoch 731: val_loss improved from 0.71665 to 0.71482, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6062 - mean_absolute_error: 0.4843 - mean_squared_error: 0.6062 - val_loss: 0.7148 - val_mean_absolute_error: 0.5206 - val_mean_squared_error: 0.7148\n",
            "Epoch 732/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.6047 - mean_absolute_error: 0.4847 - mean_squared_error: 0.6047\n",
            "Epoch 732: val_loss did not improve from 0.71482\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6049 - mean_absolute_error: 0.4838 - mean_squared_error: 0.6049 - val_loss: 0.7152 - val_mean_absolute_error: 0.5202 - val_mean_squared_error: 0.7152\n",
            "Epoch 733/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.6048 - mean_absolute_error: 0.4823 - mean_squared_error: 0.6048\n",
            "Epoch 733: val_loss improved from 0.71482 to 0.71202, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6042 - mean_absolute_error: 0.4822 - mean_squared_error: 0.6042 - val_loss: 0.7120 - val_mean_absolute_error: 0.5220 - val_mean_squared_error: 0.7120\n",
            "Epoch 734/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.6058 - mean_absolute_error: 0.4848 - mean_squared_error: 0.6058\n",
            "Epoch 734: val_loss improved from 0.71202 to 0.71156, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6041 - mean_absolute_error: 0.4832 - mean_squared_error: 0.6041 - val_loss: 0.7116 - val_mean_absolute_error: 0.5176 - val_mean_squared_error: 0.7116\n",
            "Epoch 735/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.6061 - mean_absolute_error: 0.4823 - mean_squared_error: 0.6061\n",
            "Epoch 735: val_loss did not improve from 0.71156\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6024 - mean_absolute_error: 0.4810 - mean_squared_error: 0.6024 - val_loss: 0.7136 - val_mean_absolute_error: 0.5218 - val_mean_squared_error: 0.7136\n",
            "Epoch 736/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.6082 - mean_absolute_error: 0.4828 - mean_squared_error: 0.6082\n",
            "Epoch 736: val_loss did not improve from 0.71156\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6029 - mean_absolute_error: 0.4819 - mean_squared_error: 0.6029 - val_loss: 0.7137 - val_mean_absolute_error: 0.5209 - val_mean_squared_error: 0.7137\n",
            "Epoch 737/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.5901 - mean_absolute_error: 0.4783 - mean_squared_error: 0.5901\n",
            "Epoch 737: val_loss improved from 0.71156 to 0.71051, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6012 - mean_absolute_error: 0.4816 - mean_squared_error: 0.6012 - val_loss: 0.7105 - val_mean_absolute_error: 0.5176 - val_mean_squared_error: 0.7105\n",
            "Epoch 738/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.6021 - mean_absolute_error: 0.4801 - mean_squared_error: 0.6021\n",
            "Epoch 738: val_loss did not improve from 0.71051\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6006 - mean_absolute_error: 0.4796 - mean_squared_error: 0.6006 - val_loss: 0.7115 - val_mean_absolute_error: 0.5173 - val_mean_squared_error: 0.7115\n",
            "Epoch 739/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.5988 - mean_absolute_error: 0.4799 - mean_squared_error: 0.5988\n",
            "Epoch 739: val_loss improved from 0.71051 to 0.70815, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.6001 - mean_absolute_error: 0.4801 - mean_squared_error: 0.6001 - val_loss: 0.7081 - val_mean_absolute_error: 0.5178 - val_mean_squared_error: 0.7081\n",
            "Epoch 740/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.5955 - mean_absolute_error: 0.4801 - mean_squared_error: 0.5955\n",
            "Epoch 740: val_loss did not improve from 0.70815\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5993 - mean_absolute_error: 0.4803 - mean_squared_error: 0.5993 - val_loss: 0.7095 - val_mean_absolute_error: 0.5156 - val_mean_squared_error: 0.7095\n",
            "Epoch 741/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.5903 - mean_absolute_error: 0.4760 - mean_squared_error: 0.5903\n",
            "Epoch 741: val_loss improved from 0.70815 to 0.70677, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5989 - mean_absolute_error: 0.4783 - mean_squared_error: 0.5989 - val_loss: 0.7068 - val_mean_absolute_error: 0.5156 - val_mean_squared_error: 0.7068\n",
            "Epoch 742/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.5885 - mean_absolute_error: 0.4774 - mean_squared_error: 0.5885\n",
            "Epoch 742: val_loss improved from 0.70677 to 0.70596, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5979 - mean_absolute_error: 0.4794 - mean_squared_error: 0.5979 - val_loss: 0.7060 - val_mean_absolute_error: 0.5146 - val_mean_squared_error: 0.7060\n",
            "Epoch 743/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.5970 - mean_absolute_error: 0.4769 - mean_squared_error: 0.5970\n",
            "Epoch 743: val_loss did not improve from 0.70596\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5970 - mean_absolute_error: 0.4769 - mean_squared_error: 0.5970 - val_loss: 0.7107 - val_mean_absolute_error: 0.5187 - val_mean_squared_error: 0.7107\n",
            "Epoch 744/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.5968 - mean_absolute_error: 0.4775 - mean_squared_error: 0.5968\n",
            "Epoch 744: val_loss improved from 0.70596 to 0.70590, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5968 - mean_absolute_error: 0.4775 - mean_squared_error: 0.5968 - val_loss: 0.7059 - val_mean_absolute_error: 0.5158 - val_mean_squared_error: 0.7059\n",
            "Epoch 745/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.5958 - mean_absolute_error: 0.4768 - mean_squared_error: 0.5958\n",
            "Epoch 745: val_loss did not improve from 0.70590\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5958 - mean_absolute_error: 0.4766 - mean_squared_error: 0.5958 - val_loss: 0.7062 - val_mean_absolute_error: 0.5148 - val_mean_squared_error: 0.7062\n",
            "Epoch 746/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.5963 - mean_absolute_error: 0.4771 - mean_squared_error: 0.5963\n",
            "Epoch 746: val_loss improved from 0.70590 to 0.70437, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5947 - mean_absolute_error: 0.4766 - mean_squared_error: 0.5947 - val_loss: 0.7044 - val_mean_absolute_error: 0.5141 - val_mean_squared_error: 0.7044\n",
            "Epoch 747/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.5974 - mean_absolute_error: 0.4777 - mean_squared_error: 0.5974\n",
            "Epoch 747: val_loss did not improve from 0.70437\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5942 - mean_absolute_error: 0.4756 - mean_squared_error: 0.5942 - val_loss: 0.7052 - val_mean_absolute_error: 0.5144 - val_mean_squared_error: 0.7052\n",
            "Epoch 748/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.5957 - mean_absolute_error: 0.4764 - mean_squared_error: 0.5957\n",
            "Epoch 748: val_loss did not improve from 0.70437\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5942 - mean_absolute_error: 0.4762 - mean_squared_error: 0.5942 - val_loss: 0.7085 - val_mean_absolute_error: 0.5196 - val_mean_squared_error: 0.7085\n",
            "Epoch 749/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.5952 - mean_absolute_error: 0.4757 - mean_squared_error: 0.5952\n",
            "Epoch 749: val_loss improved from 0.70437 to 0.70349, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5930 - mean_absolute_error: 0.4751 - mean_squared_error: 0.5930 - val_loss: 0.7035 - val_mean_absolute_error: 0.5162 - val_mean_squared_error: 0.7035\n",
            "Epoch 750/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.5923 - mean_absolute_error: 0.4751 - mean_squared_error: 0.5923\n",
            "Epoch 750: val_loss did not improve from 0.70349\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5926 - mean_absolute_error: 0.4752 - mean_squared_error: 0.5926 - val_loss: 0.7044 - val_mean_absolute_error: 0.5140 - val_mean_squared_error: 0.7044\n",
            "Epoch 751/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.5973 - mean_absolute_error: 0.4774 - mean_squared_error: 0.5973\n",
            "Epoch 751: val_loss improved from 0.70349 to 0.70137, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5925 - mean_absolute_error: 0.4758 - mean_squared_error: 0.5925 - val_loss: 0.7014 - val_mean_absolute_error: 0.5118 - val_mean_squared_error: 0.7014\n",
            "Epoch 752/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.5915 - mean_absolute_error: 0.4739 - mean_squared_error: 0.5915\n",
            "Epoch 752: val_loss did not improve from 0.70137\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5915 - mean_absolute_error: 0.4739 - mean_squared_error: 0.5915 - val_loss: 0.7031 - val_mean_absolute_error: 0.5148 - val_mean_squared_error: 0.7031\n",
            "Epoch 753/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.5942 - mean_absolute_error: 0.4747 - mean_squared_error: 0.5942\n",
            "Epoch 753: val_loss did not improve from 0.70137\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5909 - mean_absolute_error: 0.4734 - mean_squared_error: 0.5909 - val_loss: 0.7014 - val_mean_absolute_error: 0.5113 - val_mean_squared_error: 0.7014\n",
            "Epoch 754/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 0.5770 - mean_absolute_error: 0.4695 - mean_squared_error: 0.5770\n",
            "Epoch 754: val_loss improved from 0.70137 to 0.69851, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5902 - mean_absolute_error: 0.4732 - mean_squared_error: 0.5902 - val_loss: 0.6985 - val_mean_absolute_error: 0.5078 - val_mean_squared_error: 0.6985\n",
            "Epoch 755/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.5797 - mean_absolute_error: 0.4681 - mean_squared_error: 0.5797\n",
            "Epoch 755: val_loss improved from 0.69851 to 0.69745, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5896 - mean_absolute_error: 0.4721 - mean_squared_error: 0.5896 - val_loss: 0.6975 - val_mean_absolute_error: 0.5103 - val_mean_squared_error: 0.6975\n",
            "Epoch 756/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.5906 - mean_absolute_error: 0.4720 - mean_squared_error: 0.5906\n",
            "Epoch 756: val_loss did not improve from 0.69745\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5894 - mean_absolute_error: 0.4727 - mean_squared_error: 0.5894 - val_loss: 0.6995 - val_mean_absolute_error: 0.5118 - val_mean_squared_error: 0.6995\n",
            "Epoch 757/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.5881 - mean_absolute_error: 0.4735 - mean_squared_error: 0.5881\n",
            "Epoch 757: val_loss did not improve from 0.69745\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5888 - mean_absolute_error: 0.4733 - mean_squared_error: 0.5888 - val_loss: 0.6984 - val_mean_absolute_error: 0.5126 - val_mean_squared_error: 0.6984\n",
            "Epoch 758/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.5859 - mean_absolute_error: 0.4707 - mean_squared_error: 0.5859\n",
            "Epoch 758: val_loss improved from 0.69745 to 0.69682, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5880 - mean_absolute_error: 0.4717 - mean_squared_error: 0.5880 - val_loss: 0.6968 - val_mean_absolute_error: 0.5112 - val_mean_squared_error: 0.6968\n",
            "Epoch 759/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.5850 - mean_absolute_error: 0.4725 - mean_squared_error: 0.5850\n",
            "Epoch 759: val_loss did not improve from 0.69682\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5862 - mean_absolute_error: 0.4715 - mean_squared_error: 0.5862 - val_loss: 0.6978 - val_mean_absolute_error: 0.5110 - val_mean_squared_error: 0.6978\n",
            "Epoch 760/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.5832 - mean_absolute_error: 0.4708 - mean_squared_error: 0.5832\n",
            "Epoch 760: val_loss improved from 0.69682 to 0.69596, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5860 - mean_absolute_error: 0.4711 - mean_squared_error: 0.5860 - val_loss: 0.6960 - val_mean_absolute_error: 0.5081 - val_mean_squared_error: 0.6960\n",
            "Epoch 761/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.5843 - mean_absolute_error: 0.4694 - mean_squared_error: 0.5843\n",
            "Epoch 761: val_loss did not improve from 0.69596\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5850 - mean_absolute_error: 0.4703 - mean_squared_error: 0.5850 - val_loss: 0.6990 - val_mean_absolute_error: 0.5111 - val_mean_squared_error: 0.6990\n",
            "Epoch 762/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.5918 - mean_absolute_error: 0.4727 - mean_squared_error: 0.5918\n",
            "Epoch 762: val_loss did not improve from 0.69596\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5849 - mean_absolute_error: 0.4700 - mean_squared_error: 0.5849 - val_loss: 0.6962 - val_mean_absolute_error: 0.5115 - val_mean_squared_error: 0.6962\n",
            "Epoch 763/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.5893 - mean_absolute_error: 0.4720 - mean_squared_error: 0.5893\n",
            "Epoch 763: val_loss did not improve from 0.69596\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5842 - mean_absolute_error: 0.4700 - mean_squared_error: 0.5842 - val_loss: 0.6983 - val_mean_absolute_error: 0.5089 - val_mean_squared_error: 0.6983\n",
            "Epoch 764/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.5835 - mean_absolute_error: 0.4701 - mean_squared_error: 0.5835\n",
            "Epoch 764: val_loss improved from 0.69596 to 0.69424, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5835 - mean_absolute_error: 0.4701 - mean_squared_error: 0.5835 - val_loss: 0.6942 - val_mean_absolute_error: 0.5081 - val_mean_squared_error: 0.6942\n",
            "Epoch 765/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.5841 - mean_absolute_error: 0.4678 - mean_squared_error: 0.5841\n",
            "Epoch 765: val_loss improved from 0.69424 to 0.69354, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5829 - mean_absolute_error: 0.4687 - mean_squared_error: 0.5829 - val_loss: 0.6935 - val_mean_absolute_error: 0.5083 - val_mean_squared_error: 0.6935\n",
            "Epoch 766/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.5750 - mean_absolute_error: 0.4661 - mean_squared_error: 0.5750\n",
            "Epoch 766: val_loss did not improve from 0.69354\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5821 - mean_absolute_error: 0.4687 - mean_squared_error: 0.5821 - val_loss: 0.7004 - val_mean_absolute_error: 0.5158 - val_mean_squared_error: 0.7004\n",
            "Epoch 767/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.5807 - mean_absolute_error: 0.4673 - mean_squared_error: 0.5807\n",
            "Epoch 767: val_loss improved from 0.69354 to 0.69204, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5823 - mean_absolute_error: 0.4681 - mean_squared_error: 0.5823 - val_loss: 0.6920 - val_mean_absolute_error: 0.5069 - val_mean_squared_error: 0.6920\n",
            "Epoch 768/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.5839 - mean_absolute_error: 0.4695 - mean_squared_error: 0.5839\n",
            "Epoch 768: val_loss did not improve from 0.69204\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5820 - mean_absolute_error: 0.4687 - mean_squared_error: 0.5820 - val_loss: 0.6921 - val_mean_absolute_error: 0.5073 - val_mean_squared_error: 0.6921\n",
            "Epoch 769/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.5837 - mean_absolute_error: 0.4690 - mean_squared_error: 0.5837\n",
            "Epoch 769: val_loss did not improve from 0.69204\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5815 - mean_absolute_error: 0.4685 - mean_squared_error: 0.5815 - val_loss: 0.6937 - val_mean_absolute_error: 0.5064 - val_mean_squared_error: 0.6937\n",
            "Epoch 770/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.5764 - mean_absolute_error: 0.4664 - mean_squared_error: 0.5764\n",
            "Epoch 770: val_loss improved from 0.69204 to 0.69072, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.5800 - mean_absolute_error: 0.4669 - mean_squared_error: 0.5800 - val_loss: 0.6907 - val_mean_absolute_error: 0.5067 - val_mean_squared_error: 0.6907\n",
            "Epoch 771/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.5755 - mean_absolute_error: 0.4659 - mean_squared_error: 0.5755\n",
            "Epoch 771: val_loss improved from 0.69072 to 0.69033, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.5791 - mean_absolute_error: 0.4676 - mean_squared_error: 0.5791 - val_loss: 0.6903 - val_mean_absolute_error: 0.5077 - val_mean_squared_error: 0.6903\n",
            "Epoch 772/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.5747 - mean_absolute_error: 0.4642 - mean_squared_error: 0.5747\n",
            "Epoch 772: val_loss did not improve from 0.69033\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5794 - mean_absolute_error: 0.4658 - mean_squared_error: 0.5794 - val_loss: 0.6912 - val_mean_absolute_error: 0.5089 - val_mean_squared_error: 0.6912\n",
            "Epoch 773/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.5794 - mean_absolute_error: 0.4653 - mean_squared_error: 0.5794\n",
            "Epoch 773: val_loss improved from 0.69033 to 0.68860, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.5784 - mean_absolute_error: 0.4655 - mean_squared_error: 0.5784 - val_loss: 0.6886 - val_mean_absolute_error: 0.5043 - val_mean_squared_error: 0.6886\n",
            "Epoch 774/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.5796 - mean_absolute_error: 0.4669 - mean_squared_error: 0.5796\n",
            "Epoch 774: val_loss improved from 0.68860 to 0.68853, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5774 - mean_absolute_error: 0.4659 - mean_squared_error: 0.5774 - val_loss: 0.6885 - val_mean_absolute_error: 0.5057 - val_mean_squared_error: 0.6885\n",
            "Epoch 775/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.5777 - mean_absolute_error: 0.4647 - mean_squared_error: 0.5777\n",
            "Epoch 775: val_loss did not improve from 0.68853\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5774 - mean_absolute_error: 0.4657 - mean_squared_error: 0.5774 - val_loss: 0.6935 - val_mean_absolute_error: 0.5095 - val_mean_squared_error: 0.6935\n",
            "Epoch 776/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.5777 - mean_absolute_error: 0.4670 - mean_squared_error: 0.5777\n",
            "Epoch 776: val_loss improved from 0.68853 to 0.68572, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5766 - mean_absolute_error: 0.4663 - mean_squared_error: 0.5766 - val_loss: 0.6857 - val_mean_absolute_error: 0.5017 - val_mean_squared_error: 0.6857\n",
            "Epoch 777/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.5776 - mean_absolute_error: 0.4651 - mean_squared_error: 0.5776\n",
            "Epoch 777: val_loss did not improve from 0.68572\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5755 - mean_absolute_error: 0.4640 - mean_squared_error: 0.5755 - val_loss: 0.6860 - val_mean_absolute_error: 0.5050 - val_mean_squared_error: 0.6860\n",
            "Epoch 778/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.5834 - mean_absolute_error: 0.4677 - mean_squared_error: 0.5834\n",
            "Epoch 778: val_loss did not improve from 0.68572\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5757 - mean_absolute_error: 0.4649 - mean_squared_error: 0.5757 - val_loss: 0.6867 - val_mean_absolute_error: 0.5059 - val_mean_squared_error: 0.6867\n",
            "Epoch 779/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.5719 - mean_absolute_error: 0.4633 - mean_squared_error: 0.5719\n",
            "Epoch 779: val_loss did not improve from 0.68572\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5753 - mean_absolute_error: 0.4647 - mean_squared_error: 0.5753 - val_loss: 0.6864 - val_mean_absolute_error: 0.5028 - val_mean_squared_error: 0.6864\n",
            "Epoch 780/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.5731 - mean_absolute_error: 0.4614 - mean_squared_error: 0.5731\n",
            "Epoch 780: val_loss did not improve from 0.68572\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5753 - mean_absolute_error: 0.4634 - mean_squared_error: 0.5753 - val_loss: 0.6911 - val_mean_absolute_error: 0.5073 - val_mean_squared_error: 0.6911\n",
            "Epoch 781/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.5746 - mean_absolute_error: 0.4651 - mean_squared_error: 0.5746\n",
            "Epoch 781: val_loss did not improve from 0.68572\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5744 - mean_absolute_error: 0.4652 - mean_squared_error: 0.5744 - val_loss: 0.6881 - val_mean_absolute_error: 0.5012 - val_mean_squared_error: 0.6881\n",
            "Epoch 782/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.5776 - mean_absolute_error: 0.4648 - mean_squared_error: 0.5776\n",
            "Epoch 782: val_loss improved from 0.68572 to 0.68254, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5732 - mean_absolute_error: 0.4639 - mean_squared_error: 0.5732 - val_loss: 0.6825 - val_mean_absolute_error: 0.4994 - val_mean_squared_error: 0.6825\n",
            "Epoch 783/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.5763 - mean_absolute_error: 0.4648 - mean_squared_error: 0.5763\n",
            "Epoch 783: val_loss improved from 0.68254 to 0.68110, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5728 - mean_absolute_error: 0.4626 - mean_squared_error: 0.5728 - val_loss: 0.6811 - val_mean_absolute_error: 0.4991 - val_mean_squared_error: 0.6811\n",
            "Epoch 784/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.5774 - mean_absolute_error: 0.4646 - mean_squared_error: 0.5774\n",
            "Epoch 784: val_loss did not improve from 0.68110\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5723 - mean_absolute_error: 0.4624 - mean_squared_error: 0.5723 - val_loss: 0.6827 - val_mean_absolute_error: 0.5011 - val_mean_squared_error: 0.6827\n",
            "Epoch 785/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.5724 - mean_absolute_error: 0.4621 - mean_squared_error: 0.5724\n",
            "Epoch 785: val_loss did not improve from 0.68110\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5724 - mean_absolute_error: 0.4621 - mean_squared_error: 0.5724 - val_loss: 0.6894 - val_mean_absolute_error: 0.5025 - val_mean_squared_error: 0.6894\n",
            "Epoch 786/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.5725 - mean_absolute_error: 0.4623 - mean_squared_error: 0.5725\n",
            "Epoch 786: val_loss did not improve from 0.68110\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5707 - mean_absolute_error: 0.4617 - mean_squared_error: 0.5707 - val_loss: 0.6815 - val_mean_absolute_error: 0.5039 - val_mean_squared_error: 0.6815\n",
            "Epoch 787/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.5690 - mean_absolute_error: 0.4618 - mean_squared_error: 0.5690\n",
            "Epoch 787: val_loss did not improve from 0.68110\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5713 - mean_absolute_error: 0.4623 - mean_squared_error: 0.5713 - val_loss: 0.6818 - val_mean_absolute_error: 0.4996 - val_mean_squared_error: 0.6818\n",
            "Epoch 788/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.5683 - mean_absolute_error: 0.4570 - mean_squared_error: 0.5683\n",
            "Epoch 788: val_loss did not improve from 0.68110\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5697 - mean_absolute_error: 0.4594 - mean_squared_error: 0.5697 - val_loss: 0.6817 - val_mean_absolute_error: 0.4998 - val_mean_squared_error: 0.6817\n",
            "Epoch 789/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.5696 - mean_absolute_error: 0.4619 - mean_squared_error: 0.5696\n",
            "Epoch 789: val_loss improved from 0.68110 to 0.67792, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5701 - mean_absolute_error: 0.4620 - mean_squared_error: 0.5701 - val_loss: 0.6779 - val_mean_absolute_error: 0.4969 - val_mean_squared_error: 0.6779\n",
            "Epoch 790/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.5640 - mean_absolute_error: 0.4587 - mean_squared_error: 0.5640\n",
            "Epoch 790: val_loss improved from 0.67792 to 0.67711, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5689 - mean_absolute_error: 0.4600 - mean_squared_error: 0.5689 - val_loss: 0.6771 - val_mean_absolute_error: 0.4972 - val_mean_squared_error: 0.6771\n",
            "Epoch 791/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.5596 - mean_absolute_error: 0.4555 - mean_squared_error: 0.5596\n",
            "Epoch 791: val_loss improved from 0.67711 to 0.67700, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5690 - mean_absolute_error: 0.4600 - mean_squared_error: 0.5690 - val_loss: 0.6770 - val_mean_absolute_error: 0.4962 - val_mean_squared_error: 0.6770\n",
            "Epoch 792/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.5715 - mean_absolute_error: 0.4597 - mean_squared_error: 0.5715\n",
            "Epoch 792: val_loss improved from 0.67700 to 0.67645, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5686 - mean_absolute_error: 0.4591 - mean_squared_error: 0.5686 - val_loss: 0.6764 - val_mean_absolute_error: 0.4986 - val_mean_squared_error: 0.6764\n",
            "Epoch 793/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.5638 - mean_absolute_error: 0.4580 - mean_squared_error: 0.5638\n",
            "Epoch 793: val_loss did not improve from 0.67645\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5669 - mean_absolute_error: 0.4590 - mean_squared_error: 0.5669 - val_loss: 0.6779 - val_mean_absolute_error: 0.4964 - val_mean_squared_error: 0.6779\n",
            "Epoch 794/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.5671 - mean_absolute_error: 0.4577 - mean_squared_error: 0.5671\n",
            "Epoch 794: val_loss improved from 0.67645 to 0.67554, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5666 - mean_absolute_error: 0.4579 - mean_squared_error: 0.5666 - val_loss: 0.6755 - val_mean_absolute_error: 0.4986 - val_mean_squared_error: 0.6755\n",
            "Epoch 795/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.5663 - mean_absolute_error: 0.4580 - mean_squared_error: 0.5663\n",
            "Epoch 795: val_loss did not improve from 0.67554\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5663 - mean_absolute_error: 0.4580 - mean_squared_error: 0.5663 - val_loss: 0.6769 - val_mean_absolute_error: 0.4999 - val_mean_squared_error: 0.6769\n",
            "Epoch 796/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.5667 - mean_absolute_error: 0.4582 - mean_squared_error: 0.5667\n",
            "Epoch 796: val_loss did not improve from 0.67554\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5661 - mean_absolute_error: 0.4584 - mean_squared_error: 0.5661 - val_loss: 0.6820 - val_mean_absolute_error: 0.5025 - val_mean_squared_error: 0.6820\n",
            "Epoch 797/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.5638 - mean_absolute_error: 0.4574 - mean_squared_error: 0.5638\n",
            "Epoch 797: val_loss did not improve from 0.67554\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5660 - mean_absolute_error: 0.4588 - mean_squared_error: 0.5660 - val_loss: 0.6767 - val_mean_absolute_error: 0.5002 - val_mean_squared_error: 0.6767\n",
            "Epoch 798/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.5635 - mean_absolute_error: 0.4560 - mean_squared_error: 0.5635\n",
            "Epoch 798: val_loss improved from 0.67554 to 0.67354, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5651 - mean_absolute_error: 0.4571 - mean_squared_error: 0.5651 - val_loss: 0.6735 - val_mean_absolute_error: 0.4955 - val_mean_squared_error: 0.6735\n",
            "Epoch 799/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.5520 - mean_absolute_error: 0.4537 - mean_squared_error: 0.5520\n",
            "Epoch 799: val_loss improved from 0.67354 to 0.67306, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5643 - mean_absolute_error: 0.4571 - mean_squared_error: 0.5643 - val_loss: 0.6731 - val_mean_absolute_error: 0.4946 - val_mean_squared_error: 0.6731\n",
            "Epoch 800/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.5737 - mean_absolute_error: 0.4598 - mean_squared_error: 0.5737\n",
            "Epoch 800: val_loss did not improve from 0.67306\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5639 - mean_absolute_error: 0.4568 - mean_squared_error: 0.5639 - val_loss: 0.6733 - val_mean_absolute_error: 0.4969 - val_mean_squared_error: 0.6733\n",
            "Epoch 801/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.5583 - mean_absolute_error: 0.4548 - mean_squared_error: 0.5583\n",
            "Epoch 801: val_loss did not improve from 0.67306\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5629 - mean_absolute_error: 0.4570 - mean_squared_error: 0.5629 - val_loss: 0.6751 - val_mean_absolute_error: 0.4973 - val_mean_squared_error: 0.6751\n",
            "Epoch 802/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.5618 - mean_absolute_error: 0.4548 - mean_squared_error: 0.5618\n",
            "Epoch 802: val_loss did not improve from 0.67306\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5631 - mean_absolute_error: 0.4550 - mean_squared_error: 0.5631 - val_loss: 0.6731 - val_mean_absolute_error: 0.4987 - val_mean_squared_error: 0.6731\n",
            "Epoch 803/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.5641 - mean_absolute_error: 0.4554 - mean_squared_error: 0.5641\n",
            "Epoch 803: val_loss did not improve from 0.67306\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5628 - mean_absolute_error: 0.4562 - mean_squared_error: 0.5628 - val_loss: 0.6776 - val_mean_absolute_error: 0.4987 - val_mean_squared_error: 0.6776\n",
            "Epoch 804/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.5601 - mean_absolute_error: 0.4552 - mean_squared_error: 0.5601\n",
            "Epoch 804: val_loss improved from 0.67306 to 0.67265, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5617 - mean_absolute_error: 0.4557 - mean_squared_error: 0.5617 - val_loss: 0.6727 - val_mean_absolute_error: 0.4957 - val_mean_squared_error: 0.6727\n",
            "Epoch 805/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 0.5696 - mean_absolute_error: 0.4580 - mean_squared_error: 0.5696\n",
            "Epoch 805: val_loss improved from 0.67265 to 0.67181, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5612 - mean_absolute_error: 0.4550 - mean_squared_error: 0.5612 - val_loss: 0.6718 - val_mean_absolute_error: 0.4949 - val_mean_squared_error: 0.6718\n",
            "Epoch 806/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.5613 - mean_absolute_error: 0.4559 - mean_squared_error: 0.5613\n",
            "Epoch 806: val_loss did not improve from 0.67181\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5601 - mean_absolute_error: 0.4547 - mean_squared_error: 0.5601 - val_loss: 0.6728 - val_mean_absolute_error: 0.4982 - val_mean_squared_error: 0.6728\n",
            "Epoch 807/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.5656 - mean_absolute_error: 0.4585 - mean_squared_error: 0.5656\n",
            "Epoch 807: val_loss improved from 0.67181 to 0.67147, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5602 - mean_absolute_error: 0.4542 - mean_squared_error: 0.5602 - val_loss: 0.6715 - val_mean_absolute_error: 0.4929 - val_mean_squared_error: 0.6715\n",
            "Epoch 808/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.5578 - mean_absolute_error: 0.4532 - mean_squared_error: 0.5578\n",
            "Epoch 808: val_loss improved from 0.67147 to 0.67139, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5599 - mean_absolute_error: 0.4537 - mean_squared_error: 0.5599 - val_loss: 0.6714 - val_mean_absolute_error: 0.4918 - val_mean_squared_error: 0.6714\n",
            "Epoch 809/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.5614 - mean_absolute_error: 0.4539 - mean_squared_error: 0.5614\n",
            "Epoch 809: val_loss improved from 0.67139 to 0.66768, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5586 - mean_absolute_error: 0.4532 - mean_squared_error: 0.5586 - val_loss: 0.6677 - val_mean_absolute_error: 0.4907 - val_mean_squared_error: 0.6677\n",
            "Epoch 810/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.5551 - mean_absolute_error: 0.4503 - mean_squared_error: 0.5551\n",
            "Epoch 810: val_loss did not improve from 0.66768\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5574 - mean_absolute_error: 0.4511 - mean_squared_error: 0.5574 - val_loss: 0.6686 - val_mean_absolute_error: 0.4940 - val_mean_squared_error: 0.6686\n",
            "Epoch 811/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.5596 - mean_absolute_error: 0.4525 - mean_squared_error: 0.5596\n",
            "Epoch 811: val_loss did not improve from 0.66768\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5579 - mean_absolute_error: 0.4522 - mean_squared_error: 0.5579 - val_loss: 0.6699 - val_mean_absolute_error: 0.4953 - val_mean_squared_error: 0.6699\n",
            "Epoch 812/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.5536 - mean_absolute_error: 0.4514 - mean_squared_error: 0.5536\n",
            "Epoch 812: val_loss improved from 0.66768 to 0.66707, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5579 - mean_absolute_error: 0.4522 - mean_squared_error: 0.5579 - val_loss: 0.6671 - val_mean_absolute_error: 0.4900 - val_mean_squared_error: 0.6671\n",
            "Epoch 813/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.5595 - mean_absolute_error: 0.4521 - mean_squared_error: 0.5595\n",
            "Epoch 813: val_loss improved from 0.66707 to 0.66550, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5562 - mean_absolute_error: 0.4507 - mean_squared_error: 0.5562 - val_loss: 0.6655 - val_mean_absolute_error: 0.4902 - val_mean_squared_error: 0.6655\n",
            "Epoch 814/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.5563 - mean_absolute_error: 0.4513 - mean_squared_error: 0.5563\n",
            "Epoch 814: val_loss did not improve from 0.66550\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5553 - mean_absolute_error: 0.4511 - mean_squared_error: 0.5553 - val_loss: 0.6677 - val_mean_absolute_error: 0.4931 - val_mean_squared_error: 0.6677\n",
            "Epoch 815/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.5554 - mean_absolute_error: 0.4505 - mean_squared_error: 0.5554\n",
            "Epoch 815: val_loss did not improve from 0.66550\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5548 - mean_absolute_error: 0.4505 - mean_squared_error: 0.5548 - val_loss: 0.6700 - val_mean_absolute_error: 0.4968 - val_mean_squared_error: 0.6700\n",
            "Epoch 816/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.5533 - mean_absolute_error: 0.4503 - mean_squared_error: 0.5533\n",
            "Epoch 816: val_loss improved from 0.66550 to 0.66429, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5551 - mean_absolute_error: 0.4512 - mean_squared_error: 0.5551 - val_loss: 0.6643 - val_mean_absolute_error: 0.4920 - val_mean_squared_error: 0.6643\n",
            "Epoch 817/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.5541 - mean_absolute_error: 0.4488 - mean_squared_error: 0.5541\n",
            "Epoch 817: val_loss did not improve from 0.66429\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5541 - mean_absolute_error: 0.4495 - mean_squared_error: 0.5541 - val_loss: 0.6672 - val_mean_absolute_error: 0.4915 - val_mean_squared_error: 0.6672\n",
            "Epoch 818/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 0.5565 - mean_absolute_error: 0.4505 - mean_squared_error: 0.5565\n",
            "Epoch 818: val_loss did not improve from 0.66429\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5542 - mean_absolute_error: 0.4498 - mean_squared_error: 0.5542 - val_loss: 0.6680 - val_mean_absolute_error: 0.4914 - val_mean_squared_error: 0.6680\n",
            "Epoch 819/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.5524 - mean_absolute_error: 0.4487 - mean_squared_error: 0.5524\n",
            "Epoch 819: val_loss did not improve from 0.66429\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5537 - mean_absolute_error: 0.4492 - mean_squared_error: 0.5537 - val_loss: 0.6683 - val_mean_absolute_error: 0.4946 - val_mean_squared_error: 0.6683\n",
            "Epoch 820/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.5499 - mean_absolute_error: 0.4483 - mean_squared_error: 0.5499\n",
            "Epoch 820: val_loss did not improve from 0.66429\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5529 - mean_absolute_error: 0.4494 - mean_squared_error: 0.5529 - val_loss: 0.6652 - val_mean_absolute_error: 0.4889 - val_mean_squared_error: 0.6652\n",
            "Epoch 821/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.5551 - mean_absolute_error: 0.4499 - mean_squared_error: 0.5551\n",
            "Epoch 821: val_loss did not improve from 0.66429\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5522 - mean_absolute_error: 0.4488 - mean_squared_error: 0.5522 - val_loss: 0.6653 - val_mean_absolute_error: 0.4903 - val_mean_squared_error: 0.6653\n",
            "Epoch 822/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.5492 - mean_absolute_error: 0.4466 - mean_squared_error: 0.5492\n",
            "Epoch 822: val_loss did not improve from 0.66429\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5525 - mean_absolute_error: 0.4479 - mean_squared_error: 0.5525 - val_loss: 0.6646 - val_mean_absolute_error: 0.4893 - val_mean_squared_error: 0.6646\n",
            "Epoch 823/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.5482 - mean_absolute_error: 0.4455 - mean_squared_error: 0.5482\n",
            "Epoch 823: val_loss improved from 0.66429 to 0.65949, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5518 - mean_absolute_error: 0.4481 - mean_squared_error: 0.5518 - val_loss: 0.6595 - val_mean_absolute_error: 0.4885 - val_mean_squared_error: 0.6595\n",
            "Epoch 824/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.5385 - mean_absolute_error: 0.4438 - mean_squared_error: 0.5385\n",
            "Epoch 824: val_loss did not improve from 0.65949\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5509 - mean_absolute_error: 0.4476 - mean_squared_error: 0.5509 - val_loss: 0.6618 - val_mean_absolute_error: 0.4875 - val_mean_squared_error: 0.6618\n",
            "Epoch 825/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.5510 - mean_absolute_error: 0.4472 - mean_squared_error: 0.5510\n",
            "Epoch 825: val_loss did not improve from 0.65949\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5504 - mean_absolute_error: 0.4470 - mean_squared_error: 0.5504 - val_loss: 0.6641 - val_mean_absolute_error: 0.4917 - val_mean_squared_error: 0.6641\n",
            "Epoch 826/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.5511 - mean_absolute_error: 0.4468 - mean_squared_error: 0.5511\n",
            "Epoch 826: val_loss did not improve from 0.65949\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5498 - mean_absolute_error: 0.4466 - mean_squared_error: 0.5498 - val_loss: 0.6656 - val_mean_absolute_error: 0.4896 - val_mean_squared_error: 0.6656\n",
            "Epoch 827/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.5556 - mean_absolute_error: 0.4501 - mean_squared_error: 0.5556\n",
            "Epoch 827: val_loss improved from 0.65949 to 0.65928, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5509 - mean_absolute_error: 0.4480 - mean_squared_error: 0.5509 - val_loss: 0.6593 - val_mean_absolute_error: 0.4840 - val_mean_squared_error: 0.6593\n",
            "Epoch 828/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.5515 - mean_absolute_error: 0.4466 - mean_squared_error: 0.5515\n",
            "Epoch 828: val_loss did not improve from 0.65928\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5487 - mean_absolute_error: 0.4455 - mean_squared_error: 0.5487 - val_loss: 0.6603 - val_mean_absolute_error: 0.4836 - val_mean_squared_error: 0.6603\n",
            "Epoch 829/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.5490 - mean_absolute_error: 0.4458 - mean_squared_error: 0.5490\n",
            "Epoch 829: val_loss improved from 0.65928 to 0.65864, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5485 - mean_absolute_error: 0.4446 - mean_squared_error: 0.5485 - val_loss: 0.6586 - val_mean_absolute_error: 0.4855 - val_mean_squared_error: 0.6586\n",
            "Epoch 830/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.5544 - mean_absolute_error: 0.4477 - mean_squared_error: 0.5544\n",
            "Epoch 830: val_loss improved from 0.65864 to 0.65759, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5474 - mean_absolute_error: 0.4449 - mean_squared_error: 0.5474 - val_loss: 0.6576 - val_mean_absolute_error: 0.4835 - val_mean_squared_error: 0.6576\n",
            "Epoch 831/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.5435 - mean_absolute_error: 0.4438 - mean_squared_error: 0.5435\n",
            "Epoch 831: val_loss improved from 0.65759 to 0.65478, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5476 - mean_absolute_error: 0.4454 - mean_squared_error: 0.5476 - val_loss: 0.6548 - val_mean_absolute_error: 0.4848 - val_mean_squared_error: 0.6548\n",
            "Epoch 832/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.5462 - mean_absolute_error: 0.4445 - mean_squared_error: 0.5462\n",
            "Epoch 832: val_loss did not improve from 0.65478\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5462 - mean_absolute_error: 0.4440 - mean_squared_error: 0.5462 - val_loss: 0.6599 - val_mean_absolute_error: 0.4859 - val_mean_squared_error: 0.6599\n",
            "Epoch 833/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.5475 - mean_absolute_error: 0.4448 - mean_squared_error: 0.5475\n",
            "Epoch 833: val_loss improved from 0.65478 to 0.65290, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5451 - mean_absolute_error: 0.4436 - mean_squared_error: 0.5451 - val_loss: 0.6529 - val_mean_absolute_error: 0.4817 - val_mean_squared_error: 0.6529\n",
            "Epoch 834/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.5461 - mean_absolute_error: 0.4441 - mean_squared_error: 0.5461\n",
            "Epoch 834: val_loss did not improve from 0.65290\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5452 - mean_absolute_error: 0.4429 - mean_squared_error: 0.5452 - val_loss: 0.6582 - val_mean_absolute_error: 0.4874 - val_mean_squared_error: 0.6582\n",
            "Epoch 835/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.5526 - mean_absolute_error: 0.4453 - mean_squared_error: 0.5526\n",
            "Epoch 835: val_loss did not improve from 0.65290\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5442 - mean_absolute_error: 0.4421 - mean_squared_error: 0.5442 - val_loss: 0.6591 - val_mean_absolute_error: 0.4860 - val_mean_squared_error: 0.6591\n",
            "Epoch 836/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.5488 - mean_absolute_error: 0.4447 - mean_squared_error: 0.5488\n",
            "Epoch 836: val_loss improved from 0.65290 to 0.65240, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5442 - mean_absolute_error: 0.4428 - mean_squared_error: 0.5442 - val_loss: 0.6524 - val_mean_absolute_error: 0.4814 - val_mean_squared_error: 0.6524\n",
            "Epoch 837/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.5440 - mean_absolute_error: 0.4422 - mean_squared_error: 0.5440\n",
            "Epoch 837: val_loss did not improve from 0.65240\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5440 - mean_absolute_error: 0.4422 - mean_squared_error: 0.5440 - val_loss: 0.6547 - val_mean_absolute_error: 0.4817 - val_mean_squared_error: 0.6547\n",
            "Epoch 838/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.5412 - mean_absolute_error: 0.4406 - mean_squared_error: 0.5412\n",
            "Epoch 838: val_loss improved from 0.65240 to 0.65175, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5436 - mean_absolute_error: 0.4418 - mean_squared_error: 0.5436 - val_loss: 0.6517 - val_mean_absolute_error: 0.4811 - val_mean_squared_error: 0.6517\n",
            "Epoch 839/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.5358 - mean_absolute_error: 0.4371 - mean_squared_error: 0.5358\n",
            "Epoch 839: val_loss did not improve from 0.65175\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5426 - mean_absolute_error: 0.4404 - mean_squared_error: 0.5426 - val_loss: 0.6543 - val_mean_absolute_error: 0.4823 - val_mean_squared_error: 0.6543\n",
            "Epoch 840/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.5410 - mean_absolute_error: 0.4415 - mean_squared_error: 0.5410\n",
            "Epoch 840: val_loss did not improve from 0.65175\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5425 - mean_absolute_error: 0.4413 - mean_squared_error: 0.5425 - val_loss: 0.6537 - val_mean_absolute_error: 0.4828 - val_mean_squared_error: 0.6537\n",
            "Epoch 841/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.5424 - mean_absolute_error: 0.4421 - mean_squared_error: 0.5424\n",
            "Epoch 841: val_loss improved from 0.65175 to 0.64917, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5414 - mean_absolute_error: 0.4408 - mean_squared_error: 0.5414 - val_loss: 0.6492 - val_mean_absolute_error: 0.4794 - val_mean_squared_error: 0.6492\n",
            "Epoch 842/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 0.5433 - mean_absolute_error: 0.4397 - mean_squared_error: 0.5433\n",
            "Epoch 842: val_loss did not improve from 0.64917\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5408 - mean_absolute_error: 0.4394 - mean_squared_error: 0.5408 - val_loss: 0.6519 - val_mean_absolute_error: 0.4815 - val_mean_squared_error: 0.6519\n",
            "Epoch 843/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.5381 - mean_absolute_error: 0.4405 - mean_squared_error: 0.5381\n",
            "Epoch 843: val_loss did not improve from 0.64917\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5401 - mean_absolute_error: 0.4406 - mean_squared_error: 0.5401 - val_loss: 0.6555 - val_mean_absolute_error: 0.4815 - val_mean_squared_error: 0.6555\n",
            "Epoch 844/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.5412 - mean_absolute_error: 0.4402 - mean_squared_error: 0.5412\n",
            "Epoch 844: val_loss did not improve from 0.64917\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5399 - mean_absolute_error: 0.4393 - mean_squared_error: 0.5399 - val_loss: 0.6520 - val_mean_absolute_error: 0.4833 - val_mean_squared_error: 0.6520\n",
            "Epoch 845/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.5464 - mean_absolute_error: 0.4396 - mean_squared_error: 0.5464\n",
            "Epoch 845: val_loss improved from 0.64917 to 0.64657, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5391 - mean_absolute_error: 0.4380 - mean_squared_error: 0.5391 - val_loss: 0.6466 - val_mean_absolute_error: 0.4798 - val_mean_squared_error: 0.6466\n",
            "Epoch 846/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.5367 - mean_absolute_error: 0.4376 - mean_squared_error: 0.5367\n",
            "Epoch 846: val_loss did not improve from 0.64657\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5392 - mean_absolute_error: 0.4395 - mean_squared_error: 0.5392 - val_loss: 0.6496 - val_mean_absolute_error: 0.4789 - val_mean_squared_error: 0.6496\n",
            "Epoch 847/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.5295 - mean_absolute_error: 0.4364 - mean_squared_error: 0.5295\n",
            "Epoch 847: val_loss did not improve from 0.64657\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5377 - mean_absolute_error: 0.4376 - mean_squared_error: 0.5377 - val_loss: 0.6468 - val_mean_absolute_error: 0.4774 - val_mean_squared_error: 0.6468\n",
            "Epoch 848/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.5397 - mean_absolute_error: 0.4380 - mean_squared_error: 0.5397\n",
            "Epoch 848: val_loss did not improve from 0.64657\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5381 - mean_absolute_error: 0.4374 - mean_squared_error: 0.5381 - val_loss: 0.6486 - val_mean_absolute_error: 0.4784 - val_mean_squared_error: 0.6486\n",
            "Epoch 849/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.5381 - mean_absolute_error: 0.4373 - mean_squared_error: 0.5381\n",
            "Epoch 849: val_loss did not improve from 0.64657\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5369 - mean_absolute_error: 0.4367 - mean_squared_error: 0.5369 - val_loss: 0.6489 - val_mean_absolute_error: 0.4775 - val_mean_squared_error: 0.6489\n",
            "Epoch 850/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.5366 - mean_absolute_error: 0.4349 - mean_squared_error: 0.5366\n",
            "Epoch 850: val_loss did not improve from 0.64657\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5370 - mean_absolute_error: 0.4367 - mean_squared_error: 0.5370 - val_loss: 0.6486 - val_mean_absolute_error: 0.4777 - val_mean_squared_error: 0.6486\n",
            "Epoch 851/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.5391 - mean_absolute_error: 0.4374 - mean_squared_error: 0.5391\n",
            "Epoch 851: val_loss did not improve from 0.64657\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.5361 - mean_absolute_error: 0.4363 - mean_squared_error: 0.5361 - val_loss: 0.6494 - val_mean_absolute_error: 0.4783 - val_mean_squared_error: 0.6494\n",
            "Epoch 852/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.5342 - mean_absolute_error: 0.4366 - mean_squared_error: 0.5342\n",
            "Epoch 852: val_loss improved from 0.64657 to 0.64467, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5352 - mean_absolute_error: 0.4356 - mean_squared_error: 0.5352 - val_loss: 0.6447 - val_mean_absolute_error: 0.4789 - val_mean_squared_error: 0.6447\n",
            "Epoch 853/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.5351 - mean_absolute_error: 0.4348 - mean_squared_error: 0.5351\n",
            "Epoch 853: val_loss did not improve from 0.64467\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5357 - mean_absolute_error: 0.4352 - mean_squared_error: 0.5357 - val_loss: 0.6452 - val_mean_absolute_error: 0.4771 - val_mean_squared_error: 0.6452\n",
            "Epoch 854/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.5322 - mean_absolute_error: 0.4348 - mean_squared_error: 0.5322\n",
            "Epoch 854: val_loss improved from 0.64467 to 0.64444, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5344 - mean_absolute_error: 0.4353 - mean_squared_error: 0.5344 - val_loss: 0.6444 - val_mean_absolute_error: 0.4753 - val_mean_squared_error: 0.6444\n",
            "Epoch 855/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.5296 - mean_absolute_error: 0.4333 - mean_squared_error: 0.5296\n",
            "Epoch 855: val_loss improved from 0.64444 to 0.64439, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5342 - mean_absolute_error: 0.4354 - mean_squared_error: 0.5342 - val_loss: 0.6444 - val_mean_absolute_error: 0.4749 - val_mean_squared_error: 0.6444\n",
            "Epoch 856/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.5226 - mean_absolute_error: 0.4296 - mean_squared_error: 0.5226\n",
            "Epoch 856: val_loss improved from 0.64439 to 0.64232, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5332 - mean_absolute_error: 0.4333 - mean_squared_error: 0.5332 - val_loss: 0.6423 - val_mean_absolute_error: 0.4740 - val_mean_squared_error: 0.6423\n",
            "Epoch 857/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.5364 - mean_absolute_error: 0.4347 - mean_squared_error: 0.5364\n",
            "Epoch 857: val_loss improved from 0.64232 to 0.64099, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5333 - mean_absolute_error: 0.4340 - mean_squared_error: 0.5333 - val_loss: 0.6410 - val_mean_absolute_error: 0.4748 - val_mean_squared_error: 0.6410\n",
            "Epoch 858/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.5324 - mean_absolute_error: 0.4327 - mean_squared_error: 0.5324\n",
            "Epoch 858: val_loss did not improve from 0.64099\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5324 - mean_absolute_error: 0.4327 - mean_squared_error: 0.5324 - val_loss: 0.6411 - val_mean_absolute_error: 0.4754 - val_mean_squared_error: 0.6411\n",
            "Epoch 859/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 0.5250 - mean_absolute_error: 0.4298 - mean_squared_error: 0.5250\n",
            "Epoch 859: val_loss did not improve from 0.64099\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5308 - mean_absolute_error: 0.4330 - mean_squared_error: 0.5308 - val_loss: 0.6447 - val_mean_absolute_error: 0.4781 - val_mean_squared_error: 0.6447\n",
            "Epoch 860/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 0.5343 - mean_absolute_error: 0.4327 - mean_squared_error: 0.5343\n",
            "Epoch 860: val_loss improved from 0.64099 to 0.63892, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5308 - mean_absolute_error: 0.4316 - mean_squared_error: 0.5308 - val_loss: 0.6389 - val_mean_absolute_error: 0.4739 - val_mean_squared_error: 0.6389\n",
            "Epoch 861/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 0.5258 - mean_absolute_error: 0.4309 - mean_squared_error: 0.5258\n",
            "Epoch 861: val_loss did not improve from 0.63892\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5306 - mean_absolute_error: 0.4318 - mean_squared_error: 0.5306 - val_loss: 0.6411 - val_mean_absolute_error: 0.4743 - val_mean_squared_error: 0.6411\n",
            "Epoch 862/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.5334 - mean_absolute_error: 0.4313 - mean_squared_error: 0.5334\n",
            "Epoch 862: val_loss did not improve from 0.63892\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5296 - mean_absolute_error: 0.4309 - mean_squared_error: 0.5296 - val_loss: 0.6440 - val_mean_absolute_error: 0.4766 - val_mean_squared_error: 0.6440\n",
            "Epoch 863/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.5292 - mean_absolute_error: 0.4308 - mean_squared_error: 0.5292\n",
            "Epoch 863: val_loss improved from 0.63892 to 0.63884, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5294 - mean_absolute_error: 0.4315 - mean_squared_error: 0.5294 - val_loss: 0.6388 - val_mean_absolute_error: 0.4716 - val_mean_squared_error: 0.6388\n",
            "Epoch 864/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.5307 - mean_absolute_error: 0.4315 - mean_squared_error: 0.5307\n",
            "Epoch 864: val_loss did not improve from 0.63884\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5296 - mean_absolute_error: 0.4312 - mean_squared_error: 0.5296 - val_loss: 0.6397 - val_mean_absolute_error: 0.4726 - val_mean_squared_error: 0.6397\n",
            "Epoch 865/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.5209 - mean_absolute_error: 0.4274 - mean_squared_error: 0.5209\n",
            "Epoch 865: val_loss did not improve from 0.63884\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5274 - mean_absolute_error: 0.4296 - mean_squared_error: 0.5274 - val_loss: 0.6390 - val_mean_absolute_error: 0.4746 - val_mean_squared_error: 0.6390\n",
            "Epoch 866/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.5258 - mean_absolute_error: 0.4282 - mean_squared_error: 0.5258\n",
            "Epoch 866: val_loss did not improve from 0.63884\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5277 - mean_absolute_error: 0.4294 - mean_squared_error: 0.5277 - val_loss: 0.6413 - val_mean_absolute_error: 0.4741 - val_mean_squared_error: 0.6413\n",
            "Epoch 867/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.5303 - mean_absolute_error: 0.4317 - mean_squared_error: 0.5303\n",
            "Epoch 867: val_loss improved from 0.63884 to 0.63590, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5271 - mean_absolute_error: 0.4302 - mean_squared_error: 0.5271 - val_loss: 0.6359 - val_mean_absolute_error: 0.4701 - val_mean_squared_error: 0.6359\n",
            "Epoch 868/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.5340 - mean_absolute_error: 0.4315 - mean_squared_error: 0.5340\n",
            "Epoch 868: val_loss did not improve from 0.63590\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5269 - mean_absolute_error: 0.4290 - mean_squared_error: 0.5269 - val_loss: 0.6361 - val_mean_absolute_error: 0.4701 - val_mean_squared_error: 0.6361\n",
            "Epoch 869/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.5204 - mean_absolute_error: 0.4268 - mean_squared_error: 0.5204\n",
            "Epoch 869: val_loss did not improve from 0.63590\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5262 - mean_absolute_error: 0.4290 - mean_squared_error: 0.5262 - val_loss: 0.6367 - val_mean_absolute_error: 0.4731 - val_mean_squared_error: 0.6367\n",
            "Epoch 870/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.5299 - mean_absolute_error: 0.4307 - mean_squared_error: 0.5299\n",
            "Epoch 870: val_loss did not improve from 0.63590\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5273 - mean_absolute_error: 0.4300 - mean_squared_error: 0.5273 - val_loss: 0.6375 - val_mean_absolute_error: 0.4718 - val_mean_squared_error: 0.6375\n",
            "Epoch 871/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.5270 - mean_absolute_error: 0.4291 - mean_squared_error: 0.5270\n",
            "Epoch 871: val_loss improved from 0.63590 to 0.63424, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5255 - mean_absolute_error: 0.4284 - mean_squared_error: 0.5255 - val_loss: 0.6342 - val_mean_absolute_error: 0.4682 - val_mean_squared_error: 0.6342\n",
            "Epoch 872/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.5244 - mean_absolute_error: 0.4276 - mean_squared_error: 0.5244\n",
            "Epoch 872: val_loss did not improve from 0.63424\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5243 - mean_absolute_error: 0.4275 - mean_squared_error: 0.5243 - val_loss: 0.6367 - val_mean_absolute_error: 0.4718 - val_mean_squared_error: 0.6367\n",
            "Epoch 873/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.5221 - mean_absolute_error: 0.4266 - mean_squared_error: 0.5221\n",
            "Epoch 873: val_loss improved from 0.63424 to 0.63403, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5244 - mean_absolute_error: 0.4284 - mean_squared_error: 0.5244 - val_loss: 0.6340 - val_mean_absolute_error: 0.4679 - val_mean_squared_error: 0.6340\n",
            "Epoch 874/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.5323 - mean_absolute_error: 0.4302 - mean_squared_error: 0.5323\n",
            "Epoch 874: val_loss did not improve from 0.63403\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5242 - mean_absolute_error: 0.4267 - mean_squared_error: 0.5242 - val_loss: 0.6342 - val_mean_absolute_error: 0.4694 - val_mean_squared_error: 0.6342\n",
            "Epoch 875/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.5221 - mean_absolute_error: 0.4255 - mean_squared_error: 0.5221\n",
            "Epoch 875: val_loss improved from 0.63403 to 0.63359, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5225 - mean_absolute_error: 0.4260 - mean_squared_error: 0.5225 - val_loss: 0.6336 - val_mean_absolute_error: 0.4656 - val_mean_squared_error: 0.6336\n",
            "Epoch 876/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.5209 - mean_absolute_error: 0.4262 - mean_squared_error: 0.5209\n",
            "Epoch 876: val_loss improved from 0.63359 to 0.63169, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5236 - mean_absolute_error: 0.4272 - mean_squared_error: 0.5236 - val_loss: 0.6317 - val_mean_absolute_error: 0.4664 - val_mean_squared_error: 0.6317\n",
            "Epoch 877/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.5236 - mean_absolute_error: 0.4255 - mean_squared_error: 0.5236\n",
            "Epoch 877: val_loss improved from 0.63169 to 0.62888, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5224 - mean_absolute_error: 0.4252 - mean_squared_error: 0.5224 - val_loss: 0.6289 - val_mean_absolute_error: 0.4640 - val_mean_squared_error: 0.6289\n",
            "Epoch 878/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.5214 - mean_absolute_error: 0.4242 - mean_squared_error: 0.5214\n",
            "Epoch 878: val_loss did not improve from 0.62888\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5214 - mean_absolute_error: 0.4242 - mean_squared_error: 0.5214 - val_loss: 0.6327 - val_mean_absolute_error: 0.4654 - val_mean_squared_error: 0.6327\n",
            "Epoch 879/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 0.5286 - mean_absolute_error: 0.4261 - mean_squared_error: 0.5286\n",
            "Epoch 879: val_loss did not improve from 0.62888\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5206 - mean_absolute_error: 0.4238 - mean_squared_error: 0.5206 - val_loss: 0.6298 - val_mean_absolute_error: 0.4663 - val_mean_squared_error: 0.6298\n",
            "Epoch 880/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.5198 - mean_absolute_error: 0.4246 - mean_squared_error: 0.5198\n",
            "Epoch 880: val_loss improved from 0.62888 to 0.62799, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5202 - mean_absolute_error: 0.4245 - mean_squared_error: 0.5202 - val_loss: 0.6280 - val_mean_absolute_error: 0.4648 - val_mean_squared_error: 0.6280\n",
            "Epoch 881/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.5208 - mean_absolute_error: 0.4244 - mean_squared_error: 0.5208\n",
            "Epoch 881: val_loss did not improve from 0.62799\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5206 - mean_absolute_error: 0.4242 - mean_squared_error: 0.5206 - val_loss: 0.6315 - val_mean_absolute_error: 0.4643 - val_mean_squared_error: 0.6315\n",
            "Epoch 882/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.5257 - mean_absolute_error: 0.4269 - mean_squared_error: 0.5257\n",
            "Epoch 882: val_loss did not improve from 0.62799\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5191 - mean_absolute_error: 0.4233 - mean_squared_error: 0.5191 - val_loss: 0.6306 - val_mean_absolute_error: 0.4662 - val_mean_squared_error: 0.6306\n",
            "Epoch 883/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.5248 - mean_absolute_error: 0.4265 - mean_squared_error: 0.5248\n",
            "Epoch 883: val_loss improved from 0.62799 to 0.62787, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5193 - mean_absolute_error: 0.4239 - mean_squared_error: 0.5193 - val_loss: 0.6279 - val_mean_absolute_error: 0.4625 - val_mean_squared_error: 0.6279\n",
            "Epoch 884/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.5185 - mean_absolute_error: 0.4221 - mean_squared_error: 0.5185\n",
            "Epoch 884: val_loss did not improve from 0.62787\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5182 - mean_absolute_error: 0.4226 - mean_squared_error: 0.5182 - val_loss: 0.6291 - val_mean_absolute_error: 0.4663 - val_mean_squared_error: 0.6291\n",
            "Epoch 885/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.5066 - mean_absolute_error: 0.4182 - mean_squared_error: 0.5066\n",
            "Epoch 885: val_loss did not improve from 0.62787\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5184 - mean_absolute_error: 0.4230 - mean_squared_error: 0.5184 - val_loss: 0.6308 - val_mean_absolute_error: 0.4695 - val_mean_squared_error: 0.6308\n",
            "Epoch 886/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.5242 - mean_absolute_error: 0.4262 - mean_squared_error: 0.5242\n",
            "Epoch 886: val_loss improved from 0.62787 to 0.62544, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5172 - mean_absolute_error: 0.4224 - mean_squared_error: 0.5172 - val_loss: 0.6254 - val_mean_absolute_error: 0.4645 - val_mean_squared_error: 0.6254\n",
            "Epoch 887/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.5063 - mean_absolute_error: 0.4186 - mean_squared_error: 0.5063\n",
            "Epoch 887: val_loss improved from 0.62544 to 0.62420, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5170 - mean_absolute_error: 0.4222 - mean_squared_error: 0.5170 - val_loss: 0.6242 - val_mean_absolute_error: 0.4598 - val_mean_squared_error: 0.6242\n",
            "Epoch 888/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.5152 - mean_absolute_error: 0.4206 - mean_squared_error: 0.5152\n",
            "Epoch 888: val_loss improved from 0.62420 to 0.62390, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5171 - mean_absolute_error: 0.4212 - mean_squared_error: 0.5171 - val_loss: 0.6239 - val_mean_absolute_error: 0.4611 - val_mean_squared_error: 0.6239\n",
            "Epoch 889/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.5139 - mean_absolute_error: 0.4215 - mean_squared_error: 0.5139\n",
            "Epoch 889: val_loss did not improve from 0.62390\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5149 - mean_absolute_error: 0.4210 - mean_squared_error: 0.5149 - val_loss: 0.6297 - val_mean_absolute_error: 0.4657 - val_mean_squared_error: 0.6297\n",
            "Epoch 890/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.5122 - mean_absolute_error: 0.4182 - mean_squared_error: 0.5122\n",
            "Epoch 890: val_loss improved from 0.62390 to 0.62287, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5157 - mean_absolute_error: 0.4195 - mean_squared_error: 0.5157 - val_loss: 0.6229 - val_mean_absolute_error: 0.4614 - val_mean_squared_error: 0.6229\n",
            "Epoch 891/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.5167 - mean_absolute_error: 0.4212 - mean_squared_error: 0.5167\n",
            "Epoch 891: val_loss did not improve from 0.62287\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5150 - mean_absolute_error: 0.4205 - mean_squared_error: 0.5150 - val_loss: 0.6230 - val_mean_absolute_error: 0.4617 - val_mean_squared_error: 0.6230\n",
            "Epoch 892/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.5179 - mean_absolute_error: 0.4216 - mean_squared_error: 0.5179\n",
            "Epoch 892: val_loss improved from 0.62287 to 0.62275, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5152 - mean_absolute_error: 0.4208 - mean_squared_error: 0.5152 - val_loss: 0.6228 - val_mean_absolute_error: 0.4605 - val_mean_squared_error: 0.6228\n",
            "Epoch 893/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.5121 - mean_absolute_error: 0.4197 - mean_squared_error: 0.5121\n",
            "Epoch 893: val_loss did not improve from 0.62275\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5139 - mean_absolute_error: 0.4199 - mean_squared_error: 0.5139 - val_loss: 0.6235 - val_mean_absolute_error: 0.4624 - val_mean_squared_error: 0.6235\n",
            "Epoch 894/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.5163 - mean_absolute_error: 0.4190 - mean_squared_error: 0.5163\n",
            "Epoch 894: val_loss did not improve from 0.62275\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5132 - mean_absolute_error: 0.4178 - mean_squared_error: 0.5132 - val_loss: 0.6242 - val_mean_absolute_error: 0.4626 - val_mean_squared_error: 0.6242\n",
            "Epoch 895/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.5090 - mean_absolute_error: 0.4187 - mean_squared_error: 0.5090\n",
            "Epoch 895: val_loss did not improve from 0.62275\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5134 - mean_absolute_error: 0.4199 - mean_squared_error: 0.5134 - val_loss: 0.6235 - val_mean_absolute_error: 0.4610 - val_mean_squared_error: 0.6235\n",
            "Epoch 896/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.5259 - mean_absolute_error: 0.4227 - mean_squared_error: 0.5259\n",
            "Epoch 896: val_loss improved from 0.62275 to 0.61833, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5120 - mean_absolute_error: 0.4179 - mean_squared_error: 0.5120 - val_loss: 0.6183 - val_mean_absolute_error: 0.4596 - val_mean_squared_error: 0.6183\n",
            "Epoch 897/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.5130 - mean_absolute_error: 0.4179 - mean_squared_error: 0.5130\n",
            "Epoch 897: val_loss did not improve from 0.61833\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5121 - mean_absolute_error: 0.4177 - mean_squared_error: 0.5121 - val_loss: 0.6198 - val_mean_absolute_error: 0.4577 - val_mean_squared_error: 0.6198\n",
            "Epoch 898/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.5068 - mean_absolute_error: 0.4142 - mean_squared_error: 0.5068\n",
            "Epoch 898: val_loss improved from 0.61833 to 0.61738, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5106 - mean_absolute_error: 0.4166 - mean_squared_error: 0.5106 - val_loss: 0.6174 - val_mean_absolute_error: 0.4574 - val_mean_squared_error: 0.6174\n",
            "Epoch 899/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.5139 - mean_absolute_error: 0.4185 - mean_squared_error: 0.5139\n",
            "Epoch 899: val_loss did not improve from 0.61738\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5115 - mean_absolute_error: 0.4180 - mean_squared_error: 0.5115 - val_loss: 0.6180 - val_mean_absolute_error: 0.4560 - val_mean_squared_error: 0.6180\n",
            "Epoch 900/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 0.5055 - mean_absolute_error: 0.4166 - mean_squared_error: 0.5055\n",
            "Epoch 900: val_loss improved from 0.61738 to 0.61729, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5109 - mean_absolute_error: 0.4168 - mean_squared_error: 0.5109 - val_loss: 0.6173 - val_mean_absolute_error: 0.4571 - val_mean_squared_error: 0.6173\n",
            "Epoch 901/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.5085 - mean_absolute_error: 0.4157 - mean_squared_error: 0.5085\n",
            "Epoch 901: val_loss did not improve from 0.61729\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5099 - mean_absolute_error: 0.4163 - mean_squared_error: 0.5099 - val_loss: 0.6212 - val_mean_absolute_error: 0.4617 - val_mean_squared_error: 0.6212\n",
            "Epoch 902/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.5147 - mean_absolute_error: 0.4180 - mean_squared_error: 0.5147\n",
            "Epoch 902: val_loss did not improve from 0.61729\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5095 - mean_absolute_error: 0.4161 - mean_squared_error: 0.5095 - val_loss: 0.6196 - val_mean_absolute_error: 0.4567 - val_mean_squared_error: 0.6196\n",
            "Epoch 903/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.5091 - mean_absolute_error: 0.4153 - mean_squared_error: 0.5091\n",
            "Epoch 903: val_loss did not improve from 0.61729\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5083 - mean_absolute_error: 0.4146 - mean_squared_error: 0.5083 - val_loss: 0.6203 - val_mean_absolute_error: 0.4574 - val_mean_squared_error: 0.6203\n",
            "Epoch 904/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.4947 - mean_absolute_error: 0.4098 - mean_squared_error: 0.4947\n",
            "Epoch 904: val_loss did not improve from 0.61729\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.5080 - mean_absolute_error: 0.4147 - mean_squared_error: 0.5080 - val_loss: 0.6190 - val_mean_absolute_error: 0.4589 - val_mean_squared_error: 0.6190\n",
            "Epoch 905/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.5049 - mean_absolute_error: 0.4131 - mean_squared_error: 0.5049\n",
            "Epoch 905: val_loss did not improve from 0.61729\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5080 - mean_absolute_error: 0.4139 - mean_squared_error: 0.5080 - val_loss: 0.6174 - val_mean_absolute_error: 0.4554 - val_mean_squared_error: 0.6174\n",
            "Epoch 906/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.5105 - mean_absolute_error: 0.4159 - mean_squared_error: 0.5105\n",
            "Epoch 906: val_loss did not improve from 0.61729\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.5074 - mean_absolute_error: 0.4147 - mean_squared_error: 0.5074 - val_loss: 0.6204 - val_mean_absolute_error: 0.4595 - val_mean_squared_error: 0.6204\n",
            "Epoch 907/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.5096 - mean_absolute_error: 0.4148 - mean_squared_error: 0.5096\n",
            "Epoch 907: val_loss did not improve from 0.61729\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5074 - mean_absolute_error: 0.4141 - mean_squared_error: 0.5074 - val_loss: 0.6193 - val_mean_absolute_error: 0.4576 - val_mean_squared_error: 0.6193\n",
            "Epoch 908/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.5078 - mean_absolute_error: 0.4139 - mean_squared_error: 0.5078\n",
            "Epoch 908: val_loss improved from 0.61729 to 0.61412, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5070 - mean_absolute_error: 0.4137 - mean_squared_error: 0.5070 - val_loss: 0.6141 - val_mean_absolute_error: 0.4554 - val_mean_squared_error: 0.6141\n",
            "Epoch 909/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.5124 - mean_absolute_error: 0.4156 - mean_squared_error: 0.5124\n",
            "Epoch 909: val_loss did not improve from 0.61412\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5068 - mean_absolute_error: 0.4137 - mean_squared_error: 0.5068 - val_loss: 0.6151 - val_mean_absolute_error: 0.4546 - val_mean_squared_error: 0.6151\n",
            "Epoch 910/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.5067 - mean_absolute_error: 0.4132 - mean_squared_error: 0.5067\n",
            "Epoch 910: val_loss improved from 0.61412 to 0.61202, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5054 - mean_absolute_error: 0.4125 - mean_squared_error: 0.5054 - val_loss: 0.6120 - val_mean_absolute_error: 0.4527 - val_mean_squared_error: 0.6120\n",
            "Epoch 911/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.5053 - mean_absolute_error: 0.4123 - mean_squared_error: 0.5053\n",
            "Epoch 911: val_loss improved from 0.61202 to 0.61109, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5053 - mean_absolute_error: 0.4123 - mean_squared_error: 0.5053 - val_loss: 0.6111 - val_mean_absolute_error: 0.4516 - val_mean_squared_error: 0.6111\n",
            "Epoch 912/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.5012 - mean_absolute_error: 0.4105 - mean_squared_error: 0.5012\n",
            "Epoch 912: val_loss did not improve from 0.61109\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5047 - mean_absolute_error: 0.4118 - mean_squared_error: 0.5047 - val_loss: 0.6136 - val_mean_absolute_error: 0.4561 - val_mean_squared_error: 0.6136\n",
            "Epoch 913/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.5017 - mean_absolute_error: 0.4124 - mean_squared_error: 0.5017\n",
            "Epoch 913: val_loss improved from 0.61109 to 0.61108, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5054 - mean_absolute_error: 0.4131 - mean_squared_error: 0.5054 - val_loss: 0.6111 - val_mean_absolute_error: 0.4507 - val_mean_squared_error: 0.6111\n",
            "Epoch 914/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 0.5057 - mean_absolute_error: 0.4096 - mean_squared_error: 0.5057\n",
            "Epoch 914: val_loss did not improve from 0.61108\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5033 - mean_absolute_error: 0.4104 - mean_squared_error: 0.5033 - val_loss: 0.6118 - val_mean_absolute_error: 0.4566 - val_mean_squared_error: 0.6118\n",
            "Epoch 915/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.5010 - mean_absolute_error: 0.4100 - mean_squared_error: 0.5010\n",
            "Epoch 915: val_loss improved from 0.61108 to 0.61058, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5033 - mean_absolute_error: 0.4108 - mean_squared_error: 0.5033 - val_loss: 0.6106 - val_mean_absolute_error: 0.4511 - val_mean_squared_error: 0.6106\n",
            "Epoch 916/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.5002 - mean_absolute_error: 0.4082 - mean_squared_error: 0.5002\n",
            "Epoch 916: val_loss did not improve from 0.61058\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5026 - mean_absolute_error: 0.4101 - mean_squared_error: 0.5026 - val_loss: 0.6109 - val_mean_absolute_error: 0.4511 - val_mean_squared_error: 0.6109\n",
            "Epoch 917/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.5024 - mean_absolute_error: 0.4108 - mean_squared_error: 0.5024\n",
            "Epoch 917: val_loss did not improve from 0.61058\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5031 - mean_absolute_error: 0.4113 - mean_squared_error: 0.5031 - val_loss: 0.6111 - val_mean_absolute_error: 0.4539 - val_mean_squared_error: 0.6111\n",
            "Epoch 918/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.5010 - mean_absolute_error: 0.4105 - mean_squared_error: 0.5010\n",
            "Epoch 918: val_loss improved from 0.61058 to 0.60791, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5027 - mean_absolute_error: 0.4106 - mean_squared_error: 0.5027 - val_loss: 0.6079 - val_mean_absolute_error: 0.4495 - val_mean_squared_error: 0.6079\n",
            "Epoch 919/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.5036 - mean_absolute_error: 0.4110 - mean_squared_error: 0.5036\n",
            "Epoch 919: val_loss did not improve from 0.60791\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5014 - mean_absolute_error: 0.4090 - mean_squared_error: 0.5014 - val_loss: 0.6095 - val_mean_absolute_error: 0.4497 - val_mean_squared_error: 0.6095\n",
            "Epoch 920/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.5014 - mean_absolute_error: 0.4088 - mean_squared_error: 0.5014\n",
            "Epoch 920: val_loss improved from 0.60791 to 0.60774, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5006 - mean_absolute_error: 0.4087 - mean_squared_error: 0.5006 - val_loss: 0.6077 - val_mean_absolute_error: 0.4499 - val_mean_squared_error: 0.6077\n",
            "Epoch 921/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.4995 - mean_absolute_error: 0.4089 - mean_squared_error: 0.4995\n",
            "Epoch 921: val_loss improved from 0.60774 to 0.60764, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5008 - mean_absolute_error: 0.4090 - mean_squared_error: 0.5008 - val_loss: 0.6076 - val_mean_absolute_error: 0.4496 - val_mean_squared_error: 0.6076\n",
            "Epoch 922/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.5013 - mean_absolute_error: 0.4085 - mean_squared_error: 0.5013\n",
            "Epoch 922: val_loss improved from 0.60764 to 0.60699, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5001 - mean_absolute_error: 0.4079 - mean_squared_error: 0.5001 - val_loss: 0.6070 - val_mean_absolute_error: 0.4509 - val_mean_squared_error: 0.6070\n",
            "Epoch 923/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.5000 - mean_absolute_error: 0.4083 - mean_squared_error: 0.5000\n",
            "Epoch 923: val_loss did not improve from 0.60699\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4995 - mean_absolute_error: 0.4080 - mean_squared_error: 0.4995 - val_loss: 0.6077 - val_mean_absolute_error: 0.4505 - val_mean_squared_error: 0.6077\n",
            "Epoch 924/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.4990 - mean_absolute_error: 0.4066 - mean_squared_error: 0.4990\n",
            "Epoch 924: val_loss improved from 0.60699 to 0.60474, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4995 - mean_absolute_error: 0.4071 - mean_squared_error: 0.4995 - val_loss: 0.6047 - val_mean_absolute_error: 0.4471 - val_mean_squared_error: 0.6047\n",
            "Epoch 925/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.4998 - mean_absolute_error: 0.4072 - mean_squared_error: 0.4998\n",
            "Epoch 925: val_loss did not improve from 0.60474\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4998 - mean_absolute_error: 0.4072 - mean_squared_error: 0.4998 - val_loss: 0.6060 - val_mean_absolute_error: 0.4497 - val_mean_squared_error: 0.6060\n",
            "Epoch 926/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.4996 - mean_absolute_error: 0.4081 - mean_squared_error: 0.4996\n",
            "Epoch 926: val_loss improved from 0.60474 to 0.60373, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4983 - mean_absolute_error: 0.4072 - mean_squared_error: 0.4983 - val_loss: 0.6037 - val_mean_absolute_error: 0.4472 - val_mean_squared_error: 0.6037\n",
            "Epoch 927/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.4939 - mean_absolute_error: 0.4047 - mean_squared_error: 0.4939\n",
            "Epoch 927: val_loss improved from 0.60373 to 0.60347, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4979 - mean_absolute_error: 0.4064 - mean_squared_error: 0.4979 - val_loss: 0.6035 - val_mean_absolute_error: 0.4494 - val_mean_squared_error: 0.6035\n",
            "Epoch 928/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.5031 - mean_absolute_error: 0.4072 - mean_squared_error: 0.5031\n",
            "Epoch 928: val_loss did not improve from 0.60347\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4969 - mean_absolute_error: 0.4054 - mean_squared_error: 0.4969 - val_loss: 0.6042 - val_mean_absolute_error: 0.4460 - val_mean_squared_error: 0.6042\n",
            "Epoch 929/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.4949 - mean_absolute_error: 0.4046 - mean_squared_error: 0.4949\n",
            "Epoch 929: val_loss did not improve from 0.60347\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4965 - mean_absolute_error: 0.4051 - mean_squared_error: 0.4965 - val_loss: 0.6050 - val_mean_absolute_error: 0.4458 - val_mean_squared_error: 0.6050\n",
            "Epoch 930/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.4957 - mean_absolute_error: 0.4044 - mean_squared_error: 0.4957\n",
            "Epoch 930: val_loss improved from 0.60347 to 0.60145, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4961 - mean_absolute_error: 0.4048 - mean_squared_error: 0.4961 - val_loss: 0.6014 - val_mean_absolute_error: 0.4452 - val_mean_squared_error: 0.6014\n",
            "Epoch 931/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.4939 - mean_absolute_error: 0.4042 - mean_squared_error: 0.4939\n",
            "Epoch 931: val_loss improved from 0.60145 to 0.59922, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4959 - mean_absolute_error: 0.4046 - mean_squared_error: 0.4959 - val_loss: 0.5992 - val_mean_absolute_error: 0.4445 - val_mean_squared_error: 0.5992\n",
            "Epoch 932/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.4916 - mean_absolute_error: 0.4018 - mean_squared_error: 0.4916\n",
            "Epoch 932: val_loss did not improve from 0.59922\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4956 - mean_absolute_error: 0.4038 - mean_squared_error: 0.4956 - val_loss: 0.6052 - val_mean_absolute_error: 0.4469 - val_mean_squared_error: 0.6052\n",
            "Epoch 933/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.4865 - mean_absolute_error: 0.4026 - mean_squared_error: 0.4865\n",
            "Epoch 933: val_loss improved from 0.59922 to 0.59859, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4947 - mean_absolute_error: 0.4044 - mean_squared_error: 0.4947 - val_loss: 0.5986 - val_mean_absolute_error: 0.4429 - val_mean_squared_error: 0.5986\n",
            "Epoch 934/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.4905 - mean_absolute_error: 0.4011 - mean_squared_error: 0.4905\n",
            "Epoch 934: val_loss did not improve from 0.59859\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4950 - mean_absolute_error: 0.4035 - mean_squared_error: 0.4950 - val_loss: 0.6001 - val_mean_absolute_error: 0.4443 - val_mean_squared_error: 0.6001\n",
            "Epoch 935/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.4806 - mean_absolute_error: 0.3962 - mean_squared_error: 0.4806\n",
            "Epoch 935: val_loss did not improve from 0.59859\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4937 - mean_absolute_error: 0.4017 - mean_squared_error: 0.4937 - val_loss: 0.5996 - val_mean_absolute_error: 0.4437 - val_mean_squared_error: 0.5996\n",
            "Epoch 936/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.4966 - mean_absolute_error: 0.4038 - mean_squared_error: 0.4966\n",
            "Epoch 936: val_loss did not improve from 0.59859\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4942 - mean_absolute_error: 0.4033 - mean_squared_error: 0.4942 - val_loss: 0.6002 - val_mean_absolute_error: 0.4449 - val_mean_squared_error: 0.6002\n",
            "Epoch 937/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.4903 - mean_absolute_error: 0.4024 - mean_squared_error: 0.4903\n",
            "Epoch 937: val_loss did not improve from 0.59859\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4938 - mean_absolute_error: 0.4032 - mean_squared_error: 0.4938 - val_loss: 0.5988 - val_mean_absolute_error: 0.4443 - val_mean_squared_error: 0.5988\n",
            "Epoch 938/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.4892 - mean_absolute_error: 0.4009 - mean_squared_error: 0.4892\n",
            "Epoch 938: val_loss did not improve from 0.59859\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4922 - mean_absolute_error: 0.4018 - mean_squared_error: 0.4922 - val_loss: 0.5993 - val_mean_absolute_error: 0.4426 - val_mean_squared_error: 0.5993\n",
            "Epoch 939/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.4965 - mean_absolute_error: 0.4034 - mean_squared_error: 0.4965\n",
            "Epoch 939: val_loss improved from 0.59859 to 0.59793, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4925 - mean_absolute_error: 0.4013 - mean_squared_error: 0.4925 - val_loss: 0.5979 - val_mean_absolute_error: 0.4436 - val_mean_squared_error: 0.5979\n",
            "Epoch 940/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.4928 - mean_absolute_error: 0.4013 - mean_squared_error: 0.4928\n",
            "Epoch 940: val_loss improved from 0.59793 to 0.59684, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4921 - mean_absolute_error: 0.4017 - mean_squared_error: 0.4921 - val_loss: 0.5968 - val_mean_absolute_error: 0.4421 - val_mean_squared_error: 0.5968\n",
            "Epoch 941/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.4944 - mean_absolute_error: 0.4030 - mean_squared_error: 0.4944\n",
            "Epoch 941: val_loss improved from 0.59684 to 0.59265, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4911 - mean_absolute_error: 0.4015 - mean_squared_error: 0.4911 - val_loss: 0.5926 - val_mean_absolute_error: 0.4400 - val_mean_squared_error: 0.5926\n",
            "Epoch 942/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.4821 - mean_absolute_error: 0.3972 - mean_squared_error: 0.4821\n",
            "Epoch 942: val_loss did not improve from 0.59265\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4919 - mean_absolute_error: 0.4003 - mean_squared_error: 0.4919 - val_loss: 0.5965 - val_mean_absolute_error: 0.4396 - val_mean_squared_error: 0.5965\n",
            "Epoch 943/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.4991 - mean_absolute_error: 0.4018 - mean_squared_error: 0.4991\n",
            "Epoch 943: val_loss did not improve from 0.59265\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4906 - mean_absolute_error: 0.3992 - mean_squared_error: 0.4906 - val_loss: 0.5965 - val_mean_absolute_error: 0.4404 - val_mean_squared_error: 0.5965\n",
            "Epoch 944/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.4880 - mean_absolute_error: 0.3983 - mean_squared_error: 0.4880\n",
            "Epoch 944: val_loss did not improve from 0.59265\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4901 - mean_absolute_error: 0.3991 - mean_squared_error: 0.4901 - val_loss: 0.5940 - val_mean_absolute_error: 0.4407 - val_mean_squared_error: 0.5940\n",
            "Epoch 945/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.4837 - mean_absolute_error: 0.3981 - mean_squared_error: 0.4837\n",
            "Epoch 945: val_loss did not improve from 0.59265\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4899 - mean_absolute_error: 0.3996 - mean_squared_error: 0.4899 - val_loss: 0.5944 - val_mean_absolute_error: 0.4406 - val_mean_squared_error: 0.5944\n",
            "Epoch 946/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.4874 - mean_absolute_error: 0.3982 - mean_squared_error: 0.4874\n",
            "Epoch 946: val_loss did not improve from 0.59265\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4890 - mean_absolute_error: 0.3990 - mean_squared_error: 0.4890 - val_loss: 0.5938 - val_mean_absolute_error: 0.4378 - val_mean_squared_error: 0.5938\n",
            "Epoch 947/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.4830 - mean_absolute_error: 0.3968 - mean_squared_error: 0.4830\n",
            "Epoch 947: val_loss improved from 0.59265 to 0.59117, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4884 - mean_absolute_error: 0.3986 - mean_squared_error: 0.4884 - val_loss: 0.5912 - val_mean_absolute_error: 0.4399 - val_mean_squared_error: 0.5912\n",
            "Epoch 948/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.4848 - mean_absolute_error: 0.3957 - mean_squared_error: 0.4848\n",
            "Epoch 948: val_loss did not improve from 0.59117\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4883 - mean_absolute_error: 0.3974 - mean_squared_error: 0.4883 - val_loss: 0.5928 - val_mean_absolute_error: 0.4391 - val_mean_squared_error: 0.5928\n",
            "Epoch 949/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.4849 - mean_absolute_error: 0.3974 - mean_squared_error: 0.4849\n",
            "Epoch 949: val_loss did not improve from 0.59117\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4882 - mean_absolute_error: 0.3983 - mean_squared_error: 0.4882 - val_loss: 0.5939 - val_mean_absolute_error: 0.4392 - val_mean_squared_error: 0.5939\n",
            "Epoch 950/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.4885 - mean_absolute_error: 0.3968 - mean_squared_error: 0.4885\n",
            "Epoch 950: val_loss did not improve from 0.59117\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4871 - mean_absolute_error: 0.3971 - mean_squared_error: 0.4871 - val_loss: 0.5955 - val_mean_absolute_error: 0.4412 - val_mean_squared_error: 0.5955\n",
            "Epoch 951/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.4856 - mean_absolute_error: 0.3960 - mean_squared_error: 0.4856\n",
            "Epoch 951: val_loss did not improve from 0.59117\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4869 - mean_absolute_error: 0.3970 - mean_squared_error: 0.4869 - val_loss: 0.5959 - val_mean_absolute_error: 0.4394 - val_mean_squared_error: 0.5959\n",
            "Epoch 952/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.4965 - mean_absolute_error: 0.4007 - mean_squared_error: 0.4965\n",
            "Epoch 952: val_loss improved from 0.59117 to 0.59086, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4868 - mean_absolute_error: 0.3978 - mean_squared_error: 0.4868 - val_loss: 0.5909 - val_mean_absolute_error: 0.4373 - val_mean_squared_error: 0.5909\n",
            "Epoch 953/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.4787 - mean_absolute_error: 0.3935 - mean_squared_error: 0.4787\n",
            "Epoch 953: val_loss did not improve from 0.59086\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4859 - mean_absolute_error: 0.3963 - mean_squared_error: 0.4859 - val_loss: 0.5923 - val_mean_absolute_error: 0.4383 - val_mean_squared_error: 0.5923\n",
            "Epoch 954/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.4918 - mean_absolute_error: 0.3984 - mean_squared_error: 0.4918\n",
            "Epoch 954: val_loss did not improve from 0.59086\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4853 - mean_absolute_error: 0.3962 - mean_squared_error: 0.4853 - val_loss: 0.5910 - val_mean_absolute_error: 0.4363 - val_mean_squared_error: 0.5910\n",
            "Epoch 955/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.4859 - mean_absolute_error: 0.3960 - mean_squared_error: 0.4859\n",
            "Epoch 955: val_loss improved from 0.59086 to 0.58798, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4851 - mean_absolute_error: 0.3957 - mean_squared_error: 0.4851 - val_loss: 0.5880 - val_mean_absolute_error: 0.4355 - val_mean_squared_error: 0.5880\n",
            "Epoch 956/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.4833 - mean_absolute_error: 0.3944 - mean_squared_error: 0.4833\n",
            "Epoch 956: val_loss did not improve from 0.58798\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4845 - mean_absolute_error: 0.3947 - mean_squared_error: 0.4845 - val_loss: 0.5929 - val_mean_absolute_error: 0.4398 - val_mean_squared_error: 0.5929\n",
            "Epoch 957/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.4840 - mean_absolute_error: 0.3957 - mean_squared_error: 0.4840\n",
            "Epoch 957: val_loss did not improve from 0.58798\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4852 - mean_absolute_error: 0.3959 - mean_squared_error: 0.4852 - val_loss: 0.5924 - val_mean_absolute_error: 0.4378 - val_mean_squared_error: 0.5924\n",
            "Epoch 958/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.4833 - mean_absolute_error: 0.3950 - mean_squared_error: 0.4833\n",
            "Epoch 958: val_loss improved from 0.58798 to 0.58772, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4841 - mean_absolute_error: 0.3949 - mean_squared_error: 0.4841 - val_loss: 0.5877 - val_mean_absolute_error: 0.4370 - val_mean_squared_error: 0.5877\n",
            "Epoch 959/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.4765 - mean_absolute_error: 0.3895 - mean_squared_error: 0.4765\n",
            "Epoch 959: val_loss improved from 0.58772 to 0.58727, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4836 - mean_absolute_error: 0.3932 - mean_squared_error: 0.4836 - val_loss: 0.5873 - val_mean_absolute_error: 0.4334 - val_mean_squared_error: 0.5873\n",
            "Epoch 960/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.4901 - mean_absolute_error: 0.3961 - mean_squared_error: 0.4901\n",
            "Epoch 960: val_loss improved from 0.58727 to 0.58388, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4823 - mean_absolute_error: 0.3938 - mean_squared_error: 0.4823 - val_loss: 0.5839 - val_mean_absolute_error: 0.4330 - val_mean_squared_error: 0.5839\n",
            "Epoch 961/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.4864 - mean_absolute_error: 0.3945 - mean_squared_error: 0.4864\n",
            "Epoch 961: val_loss did not improve from 0.58388\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4825 - mean_absolute_error: 0.3929 - mean_squared_error: 0.4825 - val_loss: 0.5852 - val_mean_absolute_error: 0.4339 - val_mean_squared_error: 0.5852\n",
            "Epoch 962/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.4870 - mean_absolute_error: 0.3952 - mean_squared_error: 0.4870\n",
            "Epoch 962: val_loss did not improve from 0.58388\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4826 - mean_absolute_error: 0.3936 - mean_squared_error: 0.4826 - val_loss: 0.5885 - val_mean_absolute_error: 0.4342 - val_mean_squared_error: 0.5885\n",
            "Epoch 963/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.4781 - mean_absolute_error: 0.3893 - mean_squared_error: 0.4781\n",
            "Epoch 963: val_loss did not improve from 0.58388\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4814 - mean_absolute_error: 0.3921 - mean_squared_error: 0.4814 - val_loss: 0.5841 - val_mean_absolute_error: 0.4325 - val_mean_squared_error: 0.5841\n",
            "Epoch 964/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.4866 - mean_absolute_error: 0.3951 - mean_squared_error: 0.4866\n",
            "Epoch 964: val_loss did not improve from 0.58388\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4810 - mean_absolute_error: 0.3925 - mean_squared_error: 0.4810 - val_loss: 0.5863 - val_mean_absolute_error: 0.4341 - val_mean_squared_error: 0.5863\n",
            "Epoch 965/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.4934 - mean_absolute_error: 0.3962 - mean_squared_error: 0.4934\n",
            "Epoch 965: val_loss did not improve from 0.58388\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4811 - mean_absolute_error: 0.3915 - mean_squared_error: 0.4811 - val_loss: 0.5855 - val_mean_absolute_error: 0.4328 - val_mean_squared_error: 0.5855\n",
            "Epoch 966/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.4782 - mean_absolute_error: 0.3916 - mean_squared_error: 0.4782\n",
            "Epoch 966: val_loss did not improve from 0.58388\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4811 - mean_absolute_error: 0.3922 - mean_squared_error: 0.4811 - val_loss: 0.5839 - val_mean_absolute_error: 0.4321 - val_mean_squared_error: 0.5839\n",
            "Epoch 967/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.4809 - mean_absolute_error: 0.3919 - mean_squared_error: 0.4809\n",
            "Epoch 967: val_loss did not improve from 0.58388\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4802 - mean_absolute_error: 0.3917 - mean_squared_error: 0.4802 - val_loss: 0.5862 - val_mean_absolute_error: 0.4350 - val_mean_squared_error: 0.5862\n",
            "Epoch 968/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.4839 - mean_absolute_error: 0.3920 - mean_squared_error: 0.4839\n",
            "Epoch 968: val_loss improved from 0.58388 to 0.58347, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4797 - mean_absolute_error: 0.3910 - mean_squared_error: 0.4797 - val_loss: 0.5835 - val_mean_absolute_error: 0.4329 - val_mean_squared_error: 0.5835\n",
            "Epoch 969/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.4758 - mean_absolute_error: 0.3908 - mean_squared_error: 0.4758\n",
            "Epoch 969: val_loss did not improve from 0.58347\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4796 - mean_absolute_error: 0.3914 - mean_squared_error: 0.4796 - val_loss: 0.5847 - val_mean_absolute_error: 0.4317 - val_mean_squared_error: 0.5847\n",
            "Epoch 970/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.4772 - mean_absolute_error: 0.3893 - mean_squared_error: 0.4772\n",
            "Epoch 970: val_loss improved from 0.58347 to 0.58183, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.4781 - mean_absolute_error: 0.3900 - mean_squared_error: 0.4781 - val_loss: 0.5818 - val_mean_absolute_error: 0.4323 - val_mean_squared_error: 0.5818\n",
            "Epoch 971/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.4773 - mean_absolute_error: 0.3896 - mean_squared_error: 0.4773\n",
            "Epoch 971: val_loss improved from 0.58183 to 0.58105, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4788 - mean_absolute_error: 0.3896 - mean_squared_error: 0.4788 - val_loss: 0.5811 - val_mean_absolute_error: 0.4305 - val_mean_squared_error: 0.5811\n",
            "Epoch 972/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.4797 - mean_absolute_error: 0.3885 - mean_squared_error: 0.4797\n",
            "Epoch 972: val_loss improved from 0.58105 to 0.58076, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4774 - mean_absolute_error: 0.3883 - mean_squared_error: 0.4774 - val_loss: 0.5808 - val_mean_absolute_error: 0.4293 - val_mean_squared_error: 0.5808\n",
            "Epoch 973/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.4777 - mean_absolute_error: 0.3892 - mean_squared_error: 0.4777\n",
            "Epoch 973: val_loss did not improve from 0.58076\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4777 - mean_absolute_error: 0.3892 - mean_squared_error: 0.4777 - val_loss: 0.5814 - val_mean_absolute_error: 0.4303 - val_mean_squared_error: 0.5814\n",
            "Epoch 974/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 0.4857 - mean_absolute_error: 0.3924 - mean_squared_error: 0.4857\n",
            "Epoch 974: val_loss improved from 0.58076 to 0.57939, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4769 - mean_absolute_error: 0.3888 - mean_squared_error: 0.4769 - val_loss: 0.5794 - val_mean_absolute_error: 0.4276 - val_mean_squared_error: 0.5794\n",
            "Epoch 975/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.4802 - mean_absolute_error: 0.3907 - mean_squared_error: 0.4802\n",
            "Epoch 975: val_loss improved from 0.57939 to 0.57802, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4766 - mean_absolute_error: 0.3889 - mean_squared_error: 0.4766 - val_loss: 0.5780 - val_mean_absolute_error: 0.4265 - val_mean_squared_error: 0.5780\n",
            "Epoch 976/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.4820 - mean_absolute_error: 0.3905 - mean_squared_error: 0.4820\n",
            "Epoch 976: val_loss did not improve from 0.57802\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4765 - mean_absolute_error: 0.3878 - mean_squared_error: 0.4765 - val_loss: 0.5803 - val_mean_absolute_error: 0.4287 - val_mean_squared_error: 0.5803\n",
            "Epoch 977/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.4746 - mean_absolute_error: 0.3886 - mean_squared_error: 0.4746\n",
            "Epoch 977: val_loss did not improve from 0.57802\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4762 - mean_absolute_error: 0.3886 - mean_squared_error: 0.4762 - val_loss: 0.5800 - val_mean_absolute_error: 0.4287 - val_mean_squared_error: 0.5800\n",
            "Epoch 978/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.4727 - mean_absolute_error: 0.3858 - mean_squared_error: 0.4727\n",
            "Epoch 978: val_loss did not improve from 0.57802\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4753 - mean_absolute_error: 0.3869 - mean_squared_error: 0.4753 - val_loss: 0.5814 - val_mean_absolute_error: 0.4287 - val_mean_squared_error: 0.5814\n",
            "Epoch 979/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.4754 - mean_absolute_error: 0.3878 - mean_squared_error: 0.4754\n",
            "Epoch 979: val_loss did not improve from 0.57802\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4746 - mean_absolute_error: 0.3869 - mean_squared_error: 0.4746 - val_loss: 0.5811 - val_mean_absolute_error: 0.4291 - val_mean_squared_error: 0.5811\n",
            "Epoch 980/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.4738 - mean_absolute_error: 0.3857 - mean_squared_error: 0.4738\n",
            "Epoch 980: val_loss improved from 0.57802 to 0.57735, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4747 - mean_absolute_error: 0.3863 - mean_squared_error: 0.4747 - val_loss: 0.5773 - val_mean_absolute_error: 0.4284 - val_mean_squared_error: 0.5773\n",
            "Epoch 981/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.4776 - mean_absolute_error: 0.3868 - mean_squared_error: 0.4776\n",
            "Epoch 981: val_loss did not improve from 0.57735\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4739 - mean_absolute_error: 0.3859 - mean_squared_error: 0.4739 - val_loss: 0.5775 - val_mean_absolute_error: 0.4276 - val_mean_squared_error: 0.5775\n",
            "Epoch 982/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.4753 - mean_absolute_error: 0.3869 - mean_squared_error: 0.4753\n",
            "Epoch 982: val_loss improved from 0.57735 to 0.57602, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4736 - mean_absolute_error: 0.3863 - mean_squared_error: 0.4736 - val_loss: 0.5760 - val_mean_absolute_error: 0.4264 - val_mean_squared_error: 0.5760\n",
            "Epoch 983/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.4651 - mean_absolute_error: 0.3836 - mean_squared_error: 0.4651\n",
            "Epoch 983: val_loss did not improve from 0.57602\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4732 - mean_absolute_error: 0.3859 - mean_squared_error: 0.4732 - val_loss: 0.5812 - val_mean_absolute_error: 0.4292 - val_mean_squared_error: 0.5812\n",
            "Epoch 984/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.4705 - mean_absolute_error: 0.3833 - mean_squared_error: 0.4705\n",
            "Epoch 984: val_loss did not improve from 0.57602\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4732 - mean_absolute_error: 0.3852 - mean_squared_error: 0.4732 - val_loss: 0.5766 - val_mean_absolute_error: 0.4246 - val_mean_squared_error: 0.5766\n",
            "Epoch 985/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.4661 - mean_absolute_error: 0.3821 - mean_squared_error: 0.4661\n",
            "Epoch 985: val_loss did not improve from 0.57602\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4720 - mean_absolute_error: 0.3837 - mean_squared_error: 0.4720 - val_loss: 0.5764 - val_mean_absolute_error: 0.4262 - val_mean_squared_error: 0.5764\n",
            "Epoch 986/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.4731 - mean_absolute_error: 0.3846 - mean_squared_error: 0.4731\n",
            "Epoch 986: val_loss improved from 0.57602 to 0.57464, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4725 - mean_absolute_error: 0.3846 - mean_squared_error: 0.4725 - val_loss: 0.5746 - val_mean_absolute_error: 0.4243 - val_mean_squared_error: 0.5746\n",
            "Epoch 987/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.4681 - mean_absolute_error: 0.3832 - mean_squared_error: 0.4681\n",
            "Epoch 987: val_loss improved from 0.57464 to 0.57286, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4720 - mean_absolute_error: 0.3846 - mean_squared_error: 0.4720 - val_loss: 0.5729 - val_mean_absolute_error: 0.4240 - val_mean_squared_error: 0.5729\n",
            "Epoch 988/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.4661 - mean_absolute_error: 0.3826 - mean_squared_error: 0.4661\n",
            "Epoch 988: val_loss did not improve from 0.57286\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4712 - mean_absolute_error: 0.3842 - mean_squared_error: 0.4712 - val_loss: 0.5784 - val_mean_absolute_error: 0.4269 - val_mean_squared_error: 0.5784\n",
            "Epoch 989/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.4535 - mean_absolute_error: 0.3773 - mean_squared_error: 0.4535\n",
            "Epoch 989: val_loss did not improve from 0.57286\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4702 - mean_absolute_error: 0.3835 - mean_squared_error: 0.4702 - val_loss: 0.5762 - val_mean_absolute_error: 0.4256 - val_mean_squared_error: 0.5762\n",
            "Epoch 990/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.4699 - mean_absolute_error: 0.3826 - mean_squared_error: 0.4699\n",
            "Epoch 990: val_loss did not improve from 0.57286\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4703 - mean_absolute_error: 0.3825 - mean_squared_error: 0.4703 - val_loss: 0.5760 - val_mean_absolute_error: 0.4282 - val_mean_squared_error: 0.5760\n",
            "Epoch 991/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.4716 - mean_absolute_error: 0.3823 - mean_squared_error: 0.4716\n",
            "Epoch 991: val_loss did not improve from 0.57286\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4697 - mean_absolute_error: 0.3817 - mean_squared_error: 0.4697 - val_loss: 0.5755 - val_mean_absolute_error: 0.4257 - val_mean_squared_error: 0.5755\n",
            "Epoch 992/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.4712 - mean_absolute_error: 0.3820 - mean_squared_error: 0.4712\n",
            "Epoch 992: val_loss improved from 0.57286 to 0.57232, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4695 - mean_absolute_error: 0.3813 - mean_squared_error: 0.4695 - val_loss: 0.5723 - val_mean_absolute_error: 0.4244 - val_mean_squared_error: 0.5723\n",
            "Epoch 993/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.4660 - mean_absolute_error: 0.3821 - mean_squared_error: 0.4660\n",
            "Epoch 993: val_loss improved from 0.57232 to 0.56969, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4689 - mean_absolute_error: 0.3825 - mean_squared_error: 0.4689 - val_loss: 0.5697 - val_mean_absolute_error: 0.4219 - val_mean_squared_error: 0.5697\n",
            "Epoch 994/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.4704 - mean_absolute_error: 0.3824 - mean_squared_error: 0.4704\n",
            "Epoch 994: val_loss did not improve from 0.56969\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4693 - mean_absolute_error: 0.3813 - mean_squared_error: 0.4693 - val_loss: 0.5713 - val_mean_absolute_error: 0.4219 - val_mean_squared_error: 0.5713\n",
            "Epoch 995/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.4666 - mean_absolute_error: 0.3809 - mean_squared_error: 0.4666\n",
            "Epoch 995: val_loss improved from 0.56969 to 0.56940, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4688 - mean_absolute_error: 0.3820 - mean_squared_error: 0.4688 - val_loss: 0.5694 - val_mean_absolute_error: 0.4212 - val_mean_squared_error: 0.5694\n",
            "Epoch 996/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.4636 - mean_absolute_error: 0.3783 - mean_squared_error: 0.4636\n",
            "Epoch 996: val_loss improved from 0.56940 to 0.56931, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4681 - mean_absolute_error: 0.3813 - mean_squared_error: 0.4681 - val_loss: 0.5693 - val_mean_absolute_error: 0.4225 - val_mean_squared_error: 0.5693\n",
            "Epoch 997/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.4642 - mean_absolute_error: 0.3790 - mean_squared_error: 0.4642\n",
            "Epoch 997: val_loss did not improve from 0.56931\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4670 - mean_absolute_error: 0.3806 - mean_squared_error: 0.4670 - val_loss: 0.5729 - val_mean_absolute_error: 0.4251 - val_mean_squared_error: 0.5729\n",
            "Epoch 998/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.4666 - mean_absolute_error: 0.3791 - mean_squared_error: 0.4666\n",
            "Epoch 998: val_loss did not improve from 0.56931\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4669 - mean_absolute_error: 0.3794 - mean_squared_error: 0.4669 - val_loss: 0.5700 - val_mean_absolute_error: 0.4208 - val_mean_squared_error: 0.5700\n",
            "Epoch 999/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.4695 - mean_absolute_error: 0.3816 - mean_squared_error: 0.4695\n",
            "Epoch 999: val_loss improved from 0.56931 to 0.56639, saving model to best_model9.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4669 - mean_absolute_error: 0.3805 - mean_squared_error: 0.4669 - val_loss: 0.5664 - val_mean_absolute_error: 0.4206 - val_mean_squared_error: 0.5664\n",
            "Epoch 1000/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.4683 - mean_absolute_error: 0.3810 - mean_squared_error: 0.4683\n",
            "Epoch 1000: val_loss did not improve from 0.56639\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4661 - mean_absolute_error: 0.3803 - mean_squared_error: 0.4661 - val_loss: 0.5698 - val_mean_absolute_error: 0.4196 - val_mean_squared_error: 0.5698\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f848b27bc10>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = load_model('best_model9.h5')\n",
        "\n",
        "z_predict_test9 = model9.predict(Z_test)\n",
        "\n",
        "plt.plot(z_predict_test9,z_test,'.')\n",
        "\n",
        "print('MSE:', mean_squared_error(z_test, z_predict_test9))\n",
        "print('MAE:', mean_absolute_error(z_test, z_predict_test9))\n",
        "print('RMSE:', mean_squared_error(z_test, z_predict_test9)**0.5)\n",
        "print('Spearman R:', spearmanr(z_test, z_predict_test9))\n",
        "print('R2:', r2_score(z_test, z_predict_test9))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "Hk7YspKFqkEL",
        "outputId": "abe56623-c56e-40d8-bd80-18cc1aeb5205"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 0s 1ms/step\n",
            "MSE: 0.5617015866023277\n",
            "MAE: 0.40825337557302555\n",
            "RMSE: 0.7494675353891773\n",
            "Spearman R: SpearmanrResult(correlation=0.926588106954234, pvalue=0.0)\n",
            "R2: 0.8424790799744372\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5 capas escondidas, 5 neuronas:\n",
        "\n",
        "model10 = Sequential()\n",
        "#model.add(Dense(100, input_dim=2, activation='sigmoid'))\n",
        "model10.add(Dense(5, input_dim=2, activation='sigmoid'))\n",
        "model10.add(Dense(5, activation='sigmoid'))\n",
        "model10.add(Dense(5, activation='sigmoid'))\n",
        "model10.add(Dense(5, activation='sigmoid'))\n",
        "model10.add(Dense(5, activation='sigmoid'))\n",
        "model10.add(Dense(1, activation='linear'))\n",
        "\n",
        "model10.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error', 'mean_squared_error'])\n",
        "model10.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "152C9UdfuN7f",
        "outputId": "48456042-20df-4297-a53b-fa12ecaf665e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_22 (Dense)            (None, 5)                 15        \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 141\n",
            "Trainable params: 141\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ajuste:\n",
        "es10 = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "mc10 = ModelCheckpoint('best_model10.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)"
      ],
      "metadata": {
        "id": "CensqBhAuZ7i"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model10.fit(Z_train, z_train, epochs=1000, batch_size=20, validation_split=0.3, shuffle=True, verbose=True, callbacks=[es10,mc10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QwBAIajulCj",
        "outputId": "0fbde423-2bcf-401c-e84f-8c495375b549"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.5251 - mean_absolute_error: 1.1512 - mean_squared_error: 2.5251\n",
            "Epoch 1: val_loss improved from 2.50525 to 2.50320, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5332 - mean_absolute_error: 1.1496 - mean_squared_error: 2.5332 - val_loss: 2.5032 - val_mean_absolute_error: 1.1423 - val_mean_squared_error: 2.5032\n",
            "Epoch 2/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.5379 - mean_absolute_error: 1.1526 - mean_squared_error: 2.5379\n",
            "Epoch 2: val_loss did not improve from 2.50320\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5313 - mean_absolute_error: 1.1519 - mean_squared_error: 2.5313 - val_loss: 2.5033 - val_mean_absolute_error: 1.1418 - val_mean_squared_error: 2.5033\n",
            "Epoch 3/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.5304 - mean_absolute_error: 1.1500 - mean_squared_error: 2.5304\n",
            "Epoch 3: val_loss did not improve from 2.50320\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5311 - mean_absolute_error: 1.1505 - mean_squared_error: 2.5311 - val_loss: 2.5040 - val_mean_absolute_error: 1.1392 - val_mean_squared_error: 2.5040\n",
            "Epoch 4/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.5333 - mean_absolute_error: 1.1522 - mean_squared_error: 2.5333\n",
            "Epoch 4: val_loss did not improve from 2.50320\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5301 - mean_absolute_error: 1.1513 - mean_squared_error: 2.5301 - val_loss: 2.5073 - val_mean_absolute_error: 1.1376 - val_mean_squared_error: 2.5073\n",
            "Epoch 5/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.5203 - mean_absolute_error: 1.1453 - mean_squared_error: 2.5203\n",
            "Epoch 5: val_loss improved from 2.50320 to 2.50314, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5291 - mean_absolute_error: 1.1460 - mean_squared_error: 2.5291 - val_loss: 2.5031 - val_mean_absolute_error: 1.1426 - val_mean_squared_error: 2.5031\n",
            "Epoch 6/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.5315 - mean_absolute_error: 1.1508 - mean_squared_error: 2.5315\n",
            "Epoch 6: val_loss did not improve from 2.50314\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5280 - mean_absolute_error: 1.1525 - mean_squared_error: 2.5280 - val_loss: 2.5041 - val_mean_absolute_error: 1.1392 - val_mean_squared_error: 2.5041\n",
            "Epoch 7/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.5052 - mean_absolute_error: 1.1449 - mean_squared_error: 2.5052\n",
            "Epoch 7: val_loss improved from 2.50314 to 2.50207, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5301 - mean_absolute_error: 1.1476 - mean_squared_error: 2.5301 - val_loss: 2.5021 - val_mean_absolute_error: 1.1417 - val_mean_squared_error: 2.5021\n",
            "Epoch 8/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.5403 - mean_absolute_error: 1.1535 - mean_squared_error: 2.5403\n",
            "Epoch 8: val_loss improved from 2.50207 to 2.50044, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5284 - mean_absolute_error: 1.1518 - mean_squared_error: 2.5284 - val_loss: 2.5004 - val_mean_absolute_error: 1.1427 - val_mean_squared_error: 2.5004\n",
            "Epoch 9/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.5161 - mean_absolute_error: 1.1464 - mean_squared_error: 2.5161\n",
            "Epoch 9: val_loss did not improve from 2.50044\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5283 - mean_absolute_error: 1.1477 - mean_squared_error: 2.5283 - val_loss: 2.5023 - val_mean_absolute_error: 1.1406 - val_mean_squared_error: 2.5023\n",
            "Epoch 10/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.5219 - mean_absolute_error: 1.1558 - mean_squared_error: 2.5219\n",
            "Epoch 10: val_loss did not improve from 2.50044\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5265 - mean_absolute_error: 1.1554 - mean_squared_error: 2.5265 - val_loss: 2.5009 - val_mean_absolute_error: 1.1377 - val_mean_squared_error: 2.5009\n",
            "Epoch 11/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.5071 - mean_absolute_error: 1.1425 - mean_squared_error: 2.5071\n",
            "Epoch 11: val_loss improved from 2.50044 to 2.49790, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5263 - mean_absolute_error: 1.1466 - mean_squared_error: 2.5263 - val_loss: 2.4979 - val_mean_absolute_error: 1.1409 - val_mean_squared_error: 2.4979\n",
            "Epoch 12/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.5249 - mean_absolute_error: 1.1517 - mean_squared_error: 2.5249\n",
            "Epoch 12: val_loss did not improve from 2.49790\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5258 - mean_absolute_error: 1.1522 - mean_squared_error: 2.5258 - val_loss: 2.5022 - val_mean_absolute_error: 1.1371 - val_mean_squared_error: 2.5022\n",
            "Epoch 13/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.5265 - mean_absolute_error: 1.1495 - mean_squared_error: 2.5265\n",
            "Epoch 13: val_loss improved from 2.49790 to 2.49754, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5265 - mean_absolute_error: 1.1495 - mean_squared_error: 2.5265 - val_loss: 2.4975 - val_mean_absolute_error: 1.1392 - val_mean_squared_error: 2.4975\n",
            "Epoch 14/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.5445 - mean_absolute_error: 1.1529 - mean_squared_error: 2.5445\n",
            "Epoch 14: val_loss did not improve from 2.49754\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5264 - mean_absolute_error: 1.1494 - mean_squared_error: 2.5264 - val_loss: 2.4993 - val_mean_absolute_error: 1.1393 - val_mean_squared_error: 2.4993\n",
            "Epoch 15/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.4920 - mean_absolute_error: 1.1399 - mean_squared_error: 2.4920\n",
            "Epoch 15: val_loss improved from 2.49754 to 2.49590, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5235 - mean_absolute_error: 1.1458 - mean_squared_error: 2.5235 - val_loss: 2.4959 - val_mean_absolute_error: 1.1406 - val_mean_squared_error: 2.4959\n",
            "Epoch 16/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.5397 - mean_absolute_error: 1.1496 - mean_squared_error: 2.5397\n",
            "Epoch 16: val_loss did not improve from 2.49590\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5244 - mean_absolute_error: 1.1511 - mean_squared_error: 2.5244 - val_loss: 2.4974 - val_mean_absolute_error: 1.1400 - val_mean_squared_error: 2.4974\n",
            "Epoch 17/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.5305 - mean_absolute_error: 1.1519 - mean_squared_error: 2.5305\n",
            "Epoch 17: val_loss improved from 2.49590 to 2.49569, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5247 - mean_absolute_error: 1.1511 - mean_squared_error: 2.5247 - val_loss: 2.4957 - val_mean_absolute_error: 1.1394 - val_mean_squared_error: 2.4957\n",
            "Epoch 18/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 2.5000 - mean_absolute_error: 1.1455 - mean_squared_error: 2.5000\n",
            "Epoch 18: val_loss did not improve from 2.49569\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5230 - mean_absolute_error: 1.1473 - mean_squared_error: 2.5230 - val_loss: 2.4982 - val_mean_absolute_error: 1.1372 - val_mean_squared_error: 2.4982\n",
            "Epoch 19/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.5172 - mean_absolute_error: 1.1476 - mean_squared_error: 2.5172\n",
            "Epoch 19: val_loss did not improve from 2.49569\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5244 - mean_absolute_error: 1.1496 - mean_squared_error: 2.5244 - val_loss: 2.4974 - val_mean_absolute_error: 1.1395 - val_mean_squared_error: 2.4974\n",
            "Epoch 20/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.5222 - mean_absolute_error: 1.1474 - mean_squared_error: 2.5222\n",
            "Epoch 20: val_loss did not improve from 2.49569\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5222 - mean_absolute_error: 1.1474 - mean_squared_error: 2.5222 - val_loss: 2.4988 - val_mean_absolute_error: 1.1441 - val_mean_squared_error: 2.4988\n",
            "Epoch 21/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.5332 - mean_absolute_error: 1.1471 - mean_squared_error: 2.5332\n",
            "Epoch 21: val_loss did not improve from 2.49569\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5221 - mean_absolute_error: 1.1479 - mean_squared_error: 2.5221 - val_loss: 2.4974 - val_mean_absolute_error: 1.1446 - val_mean_squared_error: 2.4974\n",
            "Epoch 22/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.5404 - mean_absolute_error: 1.1583 - mean_squared_error: 2.5404\n",
            "Epoch 22: val_loss improved from 2.49569 to 2.49556, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5212 - mean_absolute_error: 1.1532 - mean_squared_error: 2.5212 - val_loss: 2.4956 - val_mean_absolute_error: 1.1392 - val_mean_squared_error: 2.4956\n",
            "Epoch 23/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.5164 - mean_absolute_error: 1.1488 - mean_squared_error: 2.5164\n",
            "Epoch 23: val_loss improved from 2.49556 to 2.49448, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5207 - mean_absolute_error: 1.1491 - mean_squared_error: 2.5207 - val_loss: 2.4945 - val_mean_absolute_error: 1.1380 - val_mean_squared_error: 2.4945\n",
            "Epoch 24/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.5376 - mean_absolute_error: 1.1513 - mean_squared_error: 2.5376\n",
            "Epoch 24: val_loss improved from 2.49448 to 2.49391, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5210 - mean_absolute_error: 1.1496 - mean_squared_error: 2.5210 - val_loss: 2.4939 - val_mean_absolute_error: 1.1347 - val_mean_squared_error: 2.4939\n",
            "Epoch 25/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.4986 - mean_absolute_error: 1.1393 - mean_squared_error: 2.4986\n",
            "Epoch 25: val_loss improved from 2.49391 to 2.49303, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5196 - mean_absolute_error: 1.1446 - mean_squared_error: 2.5196 - val_loss: 2.4930 - val_mean_absolute_error: 1.1393 - val_mean_squared_error: 2.4930\n",
            "Epoch 26/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.5083 - mean_absolute_error: 1.1471 - mean_squared_error: 2.5083\n",
            "Epoch 26: val_loss improved from 2.49303 to 2.49275, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5204 - mean_absolute_error: 1.1485 - mean_squared_error: 2.5204 - val_loss: 2.4928 - val_mean_absolute_error: 1.1390 - val_mean_squared_error: 2.4928\n",
            "Epoch 27/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.4915 - mean_absolute_error: 1.1435 - mean_squared_error: 2.4915\n",
            "Epoch 27: val_loss did not improve from 2.49275\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5192 - mean_absolute_error: 1.1474 - mean_squared_error: 2.5192 - val_loss: 2.4938 - val_mean_absolute_error: 1.1384 - val_mean_squared_error: 2.4938\n",
            "Epoch 28/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.5064 - mean_absolute_error: 1.1412 - mean_squared_error: 2.5064\n",
            "Epoch 28: val_loss improved from 2.49275 to 2.48864, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5175 - mean_absolute_error: 1.1471 - mean_squared_error: 2.5175 - val_loss: 2.4886 - val_mean_absolute_error: 1.1389 - val_mean_squared_error: 2.4886\n",
            "Epoch 29/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.5132 - mean_absolute_error: 1.1477 - mean_squared_error: 2.5132\n",
            "Epoch 29: val_loss did not improve from 2.48864\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5174 - mean_absolute_error: 1.1484 - mean_squared_error: 2.5174 - val_loss: 2.4934 - val_mean_absolute_error: 1.1376 - val_mean_squared_error: 2.4934\n",
            "Epoch 30/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.5136 - mean_absolute_error: 1.1467 - mean_squared_error: 2.5136\n",
            "Epoch 30: val_loss did not improve from 2.48864\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5178 - mean_absolute_error: 1.1491 - mean_squared_error: 2.5178 - val_loss: 2.4916 - val_mean_absolute_error: 1.1335 - val_mean_squared_error: 2.4916\n",
            "Epoch 31/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.5218 - mean_absolute_error: 1.1476 - mean_squared_error: 2.5218\n",
            "Epoch 31: val_loss improved from 2.48864 to 2.48780, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5162 - mean_absolute_error: 1.1456 - mean_squared_error: 2.5162 - val_loss: 2.4878 - val_mean_absolute_error: 1.1347 - val_mean_squared_error: 2.4878\n",
            "Epoch 32/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 2.5100 - mean_absolute_error: 1.1458 - mean_squared_error: 2.5100\n",
            "Epoch 32: val_loss improved from 2.48780 to 2.48677, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5146 - mean_absolute_error: 1.1472 - mean_squared_error: 2.5146 - val_loss: 2.4868 - val_mean_absolute_error: 1.1371 - val_mean_squared_error: 2.4868\n",
            "Epoch 33/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.4905 - mean_absolute_error: 1.1414 - mean_squared_error: 2.4905\n",
            "Epoch 33: val_loss improved from 2.48677 to 2.48599, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5142 - mean_absolute_error: 1.1464 - mean_squared_error: 2.5142 - val_loss: 2.4860 - val_mean_absolute_error: 1.1313 - val_mean_squared_error: 2.4860\n",
            "Epoch 34/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.4843 - mean_absolute_error: 1.1354 - mean_squared_error: 2.4843\n",
            "Epoch 34: val_loss improved from 2.48599 to 2.48554, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5118 - mean_absolute_error: 1.1420 - mean_squared_error: 2.5118 - val_loss: 2.4855 - val_mean_absolute_error: 1.1356 - val_mean_squared_error: 2.4855\n",
            "Epoch 35/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.5187 - mean_absolute_error: 1.1473 - mean_squared_error: 2.5187\n",
            "Epoch 35: val_loss improved from 2.48554 to 2.48329, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5116 - mean_absolute_error: 1.1470 - mean_squared_error: 2.5116 - val_loss: 2.4833 - val_mean_absolute_error: 1.1384 - val_mean_squared_error: 2.4833\n",
            "Epoch 36/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.5229 - mean_absolute_error: 1.1454 - mean_squared_error: 2.5229\n",
            "Epoch 36: val_loss improved from 2.48329 to 2.47987, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5093 - mean_absolute_error: 1.1425 - mean_squared_error: 2.5093 - val_loss: 2.4799 - val_mean_absolute_error: 1.1362 - val_mean_squared_error: 2.4799\n",
            "Epoch 37/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.5034 - mean_absolute_error: 1.1485 - mean_squared_error: 2.5034\n",
            "Epoch 37: val_loss improved from 2.47987 to 2.47702, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5080 - mean_absolute_error: 1.1488 - mean_squared_error: 2.5080 - val_loss: 2.4770 - val_mean_absolute_error: 1.1285 - val_mean_squared_error: 2.4770\n",
            "Epoch 38/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.5061 - mean_absolute_error: 1.1431 - mean_squared_error: 2.5061\n",
            "Epoch 38: val_loss improved from 2.47702 to 2.47370, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5064 - mean_absolute_error: 1.1432 - mean_squared_error: 2.5064 - val_loss: 2.4737 - val_mean_absolute_error: 1.1280 - val_mean_squared_error: 2.4737\n",
            "Epoch 39/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.4774 - mean_absolute_error: 1.1365 - mean_squared_error: 2.4774\n",
            "Epoch 39: val_loss improved from 2.47370 to 2.46894, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5038 - mean_absolute_error: 1.1410 - mean_squared_error: 2.5038 - val_loss: 2.4689 - val_mean_absolute_error: 1.1274 - val_mean_squared_error: 2.4689\n",
            "Epoch 40/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.5015 - mean_absolute_error: 1.1387 - mean_squared_error: 2.5015\n",
            "Epoch 40: val_loss improved from 2.46894 to 2.46861, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5015 - mean_absolute_error: 1.1387 - mean_squared_error: 2.5015 - val_loss: 2.4686 - val_mean_absolute_error: 1.1269 - val_mean_squared_error: 2.4686\n",
            "Epoch 41/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.5115 - mean_absolute_error: 1.1450 - mean_squared_error: 2.5115\n",
            "Epoch 41: val_loss improved from 2.46861 to 2.46350, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4960 - mean_absolute_error: 1.1404 - mean_squared_error: 2.4960 - val_loss: 2.4635 - val_mean_absolute_error: 1.1234 - val_mean_squared_error: 2.4635\n",
            "Epoch 42/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.4916 - mean_absolute_error: 1.1345 - mean_squared_error: 2.4916\n",
            "Epoch 42: val_loss improved from 2.46350 to 2.45907, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.4916 - mean_absolute_error: 1.1345 - mean_squared_error: 2.4916 - val_loss: 2.4591 - val_mean_absolute_error: 1.1174 - val_mean_squared_error: 2.4591\n",
            "Epoch 43/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 2.4727 - mean_absolute_error: 1.1276 - mean_squared_error: 2.4727\n",
            "Epoch 43: val_loss improved from 2.45907 to 2.45157, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4867 - mean_absolute_error: 1.1310 - mean_squared_error: 2.4867 - val_loss: 2.4516 - val_mean_absolute_error: 1.1194 - val_mean_squared_error: 2.4516\n",
            "Epoch 44/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.4941 - mean_absolute_error: 1.1316 - mean_squared_error: 2.4941\n",
            "Epoch 44: val_loss improved from 2.45157 to 2.44456, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4799 - mean_absolute_error: 1.1302 - mean_squared_error: 2.4799 - val_loss: 2.4446 - val_mean_absolute_error: 1.1170 - val_mean_squared_error: 2.4446\n",
            "Epoch 45/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.4532 - mean_absolute_error: 1.1243 - mean_squared_error: 2.4532\n",
            "Epoch 45: val_loss improved from 2.44456 to 2.43121, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.4735 - mean_absolute_error: 1.1274 - mean_squared_error: 2.4735 - val_loss: 2.4312 - val_mean_absolute_error: 1.1147 - val_mean_squared_error: 2.4312\n",
            "Epoch 46/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.4346 - mean_absolute_error: 1.1153 - mean_squared_error: 2.4346\n",
            "Epoch 46: val_loss improved from 2.43121 to 2.42562, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4664 - mean_absolute_error: 1.1214 - mean_squared_error: 2.4664 - val_loss: 2.4256 - val_mean_absolute_error: 1.1058 - val_mean_squared_error: 2.4256\n",
            "Epoch 47/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.4564 - mean_absolute_error: 1.1147 - mean_squared_error: 2.4564\n",
            "Epoch 47: val_loss improved from 2.42562 to 2.41362, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4571 - mean_absolute_error: 1.1164 - mean_squared_error: 2.4571 - val_loss: 2.4136 - val_mean_absolute_error: 1.1094 - val_mean_squared_error: 2.4136\n",
            "Epoch 48/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.4433 - mean_absolute_error: 1.1149 - mean_squared_error: 2.4433\n",
            "Epoch 48: val_loss improved from 2.41362 to 2.40886, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4489 - mean_absolute_error: 1.1157 - mean_squared_error: 2.4489 - val_loss: 2.4089 - val_mean_absolute_error: 1.0963 - val_mean_squared_error: 2.4089\n",
            "Epoch 49/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 2.4464 - mean_absolute_error: 1.1094 - mean_squared_error: 2.4464\n",
            "Epoch 49: val_loss improved from 2.40886 to 2.39936, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4419 - mean_absolute_error: 1.1087 - mean_squared_error: 2.4419 - val_loss: 2.3994 - val_mean_absolute_error: 1.0949 - val_mean_squared_error: 2.3994\n",
            "Epoch 50/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 2.4125 - mean_absolute_error: 1.1034 - mean_squared_error: 2.4125\n",
            "Epoch 50: val_loss improved from 2.39936 to 2.39433, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4374 - mean_absolute_error: 1.1069 - mean_squared_error: 2.4374 - val_loss: 2.3943 - val_mean_absolute_error: 1.0893 - val_mean_squared_error: 2.3943\n",
            "Epoch 51/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.4288 - mean_absolute_error: 1.1078 - mean_squared_error: 2.4288\n",
            "Epoch 51: val_loss improved from 2.39433 to 2.39123, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4309 - mean_absolute_error: 1.1057 - mean_squared_error: 2.4309 - val_loss: 2.3912 - val_mean_absolute_error: 1.0871 - val_mean_squared_error: 2.3912\n",
            "Epoch 52/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.4164 - mean_absolute_error: 1.0969 - mean_squared_error: 2.4164\n",
            "Epoch 52: val_loss improved from 2.39123 to 2.37926, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4275 - mean_absolute_error: 1.0997 - mean_squared_error: 2.4275 - val_loss: 2.3793 - val_mean_absolute_error: 1.0923 - val_mean_squared_error: 2.3793\n",
            "Epoch 53/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.4168 - mean_absolute_error: 1.0977 - mean_squared_error: 2.4168\n",
            "Epoch 53: val_loss improved from 2.37926 to 2.37609, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4224 - mean_absolute_error: 1.0988 - mean_squared_error: 2.4224 - val_loss: 2.3761 - val_mean_absolute_error: 1.0880 - val_mean_squared_error: 2.3761\n",
            "Epoch 54/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.4483 - mean_absolute_error: 1.1085 - mean_squared_error: 2.4483\n",
            "Epoch 54: val_loss improved from 2.37609 to 2.37378, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4198 - mean_absolute_error: 1.1009 - mean_squared_error: 2.4198 - val_loss: 2.3738 - val_mean_absolute_error: 1.0807 - val_mean_squared_error: 2.3738\n",
            "Epoch 55/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.4073 - mean_absolute_error: 1.0912 - mean_squared_error: 2.4073\n",
            "Epoch 55: val_loss improved from 2.37378 to 2.36825, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4166 - mean_absolute_error: 1.0940 - mean_squared_error: 2.4166 - val_loss: 2.3683 - val_mean_absolute_error: 1.0837 - val_mean_squared_error: 2.3683\n",
            "Epoch 56/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.4378 - mean_absolute_error: 1.1026 - mean_squared_error: 2.4378\n",
            "Epoch 56: val_loss improved from 2.36825 to 2.36538, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4152 - mean_absolute_error: 1.0978 - mean_squared_error: 2.4152 - val_loss: 2.3654 - val_mean_absolute_error: 1.0857 - val_mean_squared_error: 2.3654\n",
            "Epoch 57/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.3703 - mean_absolute_error: 1.0868 - mean_squared_error: 2.3703\n",
            "Epoch 57: val_loss improved from 2.36538 to 2.36527, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4114 - mean_absolute_error: 1.0952 - mean_squared_error: 2.4114 - val_loss: 2.3653 - val_mean_absolute_error: 1.0816 - val_mean_squared_error: 2.3653\n",
            "Epoch 58/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.4095 - mean_absolute_error: 1.0937 - mean_squared_error: 2.4095\n",
            "Epoch 58: val_loss improved from 2.36527 to 2.36295, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4095 - mean_absolute_error: 1.0937 - mean_squared_error: 2.4095 - val_loss: 2.3629 - val_mean_absolute_error: 1.0830 - val_mean_squared_error: 2.3629\n",
            "Epoch 59/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 2.4085 - mean_absolute_error: 1.0951 - mean_squared_error: 2.4085\n",
            "Epoch 59: val_loss improved from 2.36295 to 2.35973, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4069 - mean_absolute_error: 1.0944 - mean_squared_error: 2.4069 - val_loss: 2.3597 - val_mean_absolute_error: 1.0834 - val_mean_squared_error: 2.3597\n",
            "Epoch 60/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.4003 - mean_absolute_error: 1.0946 - mean_squared_error: 2.4003\n",
            "Epoch 60: val_loss did not improve from 2.35973\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4045 - mean_absolute_error: 1.0948 - mean_squared_error: 2.4045 - val_loss: 2.3630 - val_mean_absolute_error: 1.0843 - val_mean_squared_error: 2.3630\n",
            "Epoch 61/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.4359 - mean_absolute_error: 1.1025 - mean_squared_error: 2.4359\n",
            "Epoch 61: val_loss improved from 2.35973 to 2.35025, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4040 - mean_absolute_error: 1.0952 - mean_squared_error: 2.4040 - val_loss: 2.3503 - val_mean_absolute_error: 1.0845 - val_mean_squared_error: 2.3503\n",
            "Epoch 62/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.4093 - mean_absolute_error: 1.0967 - mean_squared_error: 2.4093\n",
            "Epoch 62: val_loss improved from 2.35025 to 2.34861, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.4005 - mean_absolute_error: 1.0957 - mean_squared_error: 2.4005 - val_loss: 2.3486 - val_mean_absolute_error: 1.0787 - val_mean_squared_error: 2.3486\n",
            "Epoch 63/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.4201 - mean_absolute_error: 1.0939 - mean_squared_error: 2.4201\n",
            "Epoch 63: val_loss did not improve from 2.34861\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3985 - mean_absolute_error: 1.0900 - mean_squared_error: 2.3985 - val_loss: 2.3510 - val_mean_absolute_error: 1.0797 - val_mean_squared_error: 2.3510\n",
            "Epoch 64/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.4124 - mean_absolute_error: 1.0938 - mean_squared_error: 2.4124\n",
            "Epoch 64: val_loss improved from 2.34861 to 2.34252, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3973 - mean_absolute_error: 1.0916 - mean_squared_error: 2.3973 - val_loss: 2.3425 - val_mean_absolute_error: 1.0820 - val_mean_squared_error: 2.3425\n",
            "Epoch 65/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.4000 - mean_absolute_error: 1.0934 - mean_squared_error: 2.4000\n",
            "Epoch 65: val_loss improved from 2.34252 to 2.34097, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3948 - mean_absolute_error: 1.0925 - mean_squared_error: 2.3948 - val_loss: 2.3410 - val_mean_absolute_error: 1.0785 - val_mean_squared_error: 2.3410\n",
            "Epoch 66/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.3725 - mean_absolute_error: 1.0870 - mean_squared_error: 2.3725\n",
            "Epoch 66: val_loss did not improve from 2.34097\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3941 - mean_absolute_error: 1.0892 - mean_squared_error: 2.3941 - val_loss: 2.3429 - val_mean_absolute_error: 1.0775 - val_mean_squared_error: 2.3429\n",
            "Epoch 67/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.3825 - mean_absolute_error: 1.0902 - mean_squared_error: 2.3825\n",
            "Epoch 67: val_loss did not improve from 2.34097\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3936 - mean_absolute_error: 1.0925 - mean_squared_error: 2.3936 - val_loss: 2.3432 - val_mean_absolute_error: 1.0775 - val_mean_squared_error: 2.3432\n",
            "Epoch 68/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.3845 - mean_absolute_error: 1.0902 - mean_squared_error: 2.3845\n",
            "Epoch 68: val_loss improved from 2.34097 to 2.33437, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3912 - mean_absolute_error: 1.0906 - mean_squared_error: 2.3912 - val_loss: 2.3344 - val_mean_absolute_error: 1.0799 - val_mean_squared_error: 2.3344\n",
            "Epoch 69/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.3880 - mean_absolute_error: 1.0892 - mean_squared_error: 2.3880\n",
            "Epoch 69: val_loss improved from 2.33437 to 2.33335, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3895 - mean_absolute_error: 1.0891 - mean_squared_error: 2.3895 - val_loss: 2.3334 - val_mean_absolute_error: 1.0759 - val_mean_squared_error: 2.3334\n",
            "Epoch 70/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.3992 - mean_absolute_error: 1.0930 - mean_squared_error: 2.3992\n",
            "Epoch 70: val_loss improved from 2.33335 to 2.33122, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3879 - mean_absolute_error: 1.0884 - mean_squared_error: 2.3879 - val_loss: 2.3312 - val_mean_absolute_error: 1.0800 - val_mean_squared_error: 2.3312\n",
            "Epoch 71/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.3903 - mean_absolute_error: 1.0895 - mean_squared_error: 2.3903\n",
            "Epoch 71: val_loss improved from 2.33122 to 2.32946, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3869 - mean_absolute_error: 1.0882 - mean_squared_error: 2.3869 - val_loss: 2.3295 - val_mean_absolute_error: 1.0750 - val_mean_squared_error: 2.3295\n",
            "Epoch 72/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.3998 - mean_absolute_error: 1.0938 - mean_squared_error: 2.3998\n",
            "Epoch 72: val_loss improved from 2.32946 to 2.32895, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3856 - mean_absolute_error: 1.0896 - mean_squared_error: 2.3856 - val_loss: 2.3290 - val_mean_absolute_error: 1.0730 - val_mean_squared_error: 2.3290\n",
            "Epoch 73/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.3733 - mean_absolute_error: 1.0841 - mean_squared_error: 2.3733\n",
            "Epoch 73: val_loss improved from 2.32895 to 2.32895, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3828 - mean_absolute_error: 1.0853 - mean_squared_error: 2.3828 - val_loss: 2.3290 - val_mean_absolute_error: 1.0726 - val_mean_squared_error: 2.3290\n",
            "Epoch 74/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.3451 - mean_absolute_error: 1.0774 - mean_squared_error: 2.3451\n",
            "Epoch 74: val_loss did not improve from 2.32895\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3819 - mean_absolute_error: 1.0836 - mean_squared_error: 2.3819 - val_loss: 2.3323 - val_mean_absolute_error: 1.0748 - val_mean_squared_error: 2.3323\n",
            "Epoch 75/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.3879 - mean_absolute_error: 1.0889 - mean_squared_error: 2.3879\n",
            "Epoch 75: val_loss did not improve from 2.32895\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3810 - mean_absolute_error: 1.0871 - mean_squared_error: 2.3810 - val_loss: 2.3310 - val_mean_absolute_error: 1.0745 - val_mean_squared_error: 2.3310\n",
            "Epoch 76/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.3643 - mean_absolute_error: 1.0822 - mean_squared_error: 2.3643\n",
            "Epoch 76: val_loss improved from 2.32895 to 2.32847, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3795 - mean_absolute_error: 1.0852 - mean_squared_error: 2.3795 - val_loss: 2.3285 - val_mean_absolute_error: 1.0731 - val_mean_squared_error: 2.3285\n",
            "Epoch 77/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.3580 - mean_absolute_error: 1.0806 - mean_squared_error: 2.3580\n",
            "Epoch 77: val_loss improved from 2.32847 to 2.32176, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3795 - mean_absolute_error: 1.0855 - mean_squared_error: 2.3795 - val_loss: 2.3218 - val_mean_absolute_error: 1.0726 - val_mean_squared_error: 2.3218\n",
            "Epoch 78/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.3793 - mean_absolute_error: 1.0809 - mean_squared_error: 2.3793\n",
            "Epoch 78: val_loss did not improve from 2.32176\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3773 - mean_absolute_error: 1.0823 - mean_squared_error: 2.3773 - val_loss: 2.3233 - val_mean_absolute_error: 1.0802 - val_mean_squared_error: 2.3233\n",
            "Epoch 79/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.3899 - mean_absolute_error: 1.0864 - mean_squared_error: 2.3899\n",
            "Epoch 79: val_loss did not improve from 2.32176\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3762 - mean_absolute_error: 1.0837 - mean_squared_error: 2.3762 - val_loss: 2.3233 - val_mean_absolute_error: 1.0717 - val_mean_squared_error: 2.3233\n",
            "Epoch 80/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.3591 - mean_absolute_error: 1.0802 - mean_squared_error: 2.3591\n",
            "Epoch 80: val_loss improved from 2.32176 to 2.32005, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3765 - mean_absolute_error: 1.0838 - mean_squared_error: 2.3765 - val_loss: 2.3200 - val_mean_absolute_error: 1.0721 - val_mean_squared_error: 2.3200\n",
            "Epoch 81/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.3749 - mean_absolute_error: 1.0805 - mean_squared_error: 2.3749\n",
            "Epoch 81: val_loss improved from 2.32005 to 2.31933, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3749 - mean_absolute_error: 1.0805 - mean_squared_error: 2.3749 - val_loss: 2.3193 - val_mean_absolute_error: 1.0728 - val_mean_squared_error: 2.3193\n",
            "Epoch 82/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.3729 - mean_absolute_error: 1.0847 - mean_squared_error: 2.3729\n",
            "Epoch 82: val_loss improved from 2.31933 to 2.31446, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3741 - mean_absolute_error: 1.0845 - mean_squared_error: 2.3741 - val_loss: 2.3145 - val_mean_absolute_error: 1.0708 - val_mean_squared_error: 2.3145\n",
            "Epoch 83/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.3491 - mean_absolute_error: 1.0733 - mean_squared_error: 2.3491\n",
            "Epoch 83: val_loss did not improve from 2.31446\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3729 - mean_absolute_error: 1.0805 - mean_squared_error: 2.3729 - val_loss: 2.3154 - val_mean_absolute_error: 1.0677 - val_mean_squared_error: 2.3154\n",
            "Epoch 84/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.3637 - mean_absolute_error: 1.0768 - mean_squared_error: 2.3637\n",
            "Epoch 84: val_loss did not improve from 2.31446\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3725 - mean_absolute_error: 1.0787 - mean_squared_error: 2.3725 - val_loss: 2.3202 - val_mean_absolute_error: 1.0713 - val_mean_squared_error: 2.3202\n",
            "Epoch 85/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.3829 - mean_absolute_error: 1.0827 - mean_squared_error: 2.3829\n",
            "Epoch 85: val_loss did not improve from 2.31446\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3727 - mean_absolute_error: 1.0815 - mean_squared_error: 2.3727 - val_loss: 2.3286 - val_mean_absolute_error: 1.0711 - val_mean_squared_error: 2.3286\n",
            "Epoch 86/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.3875 - mean_absolute_error: 1.0859 - mean_squared_error: 2.3875\n",
            "Epoch 86: val_loss did not improve from 2.31446\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.3710 - mean_absolute_error: 1.0812 - mean_squared_error: 2.3710 - val_loss: 2.3163 - val_mean_absolute_error: 1.0693 - val_mean_squared_error: 2.3163\n",
            "Epoch 87/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.3575 - mean_absolute_error: 1.0800 - mean_squared_error: 2.3575\n",
            "Epoch 87: val_loss improved from 2.31446 to 2.31301, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.3730 - mean_absolute_error: 1.0822 - mean_squared_error: 2.3730 - val_loss: 2.3130 - val_mean_absolute_error: 1.0681 - val_mean_squared_error: 2.3130\n",
            "Epoch 88/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.3918 - mean_absolute_error: 1.0814 - mean_squared_error: 2.3918\n",
            "Epoch 88: val_loss improved from 2.31301 to 2.31153, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3688 - mean_absolute_error: 1.0783 - mean_squared_error: 2.3688 - val_loss: 2.3115 - val_mean_absolute_error: 1.0726 - val_mean_squared_error: 2.3115\n",
            "Epoch 89/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.3679 - mean_absolute_error: 1.0791 - mean_squared_error: 2.3679\n",
            "Epoch 89: val_loss improved from 2.31153 to 2.30955, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3679 - mean_absolute_error: 1.0791 - mean_squared_error: 2.3679 - val_loss: 2.3096 - val_mean_absolute_error: 1.0779 - val_mean_squared_error: 2.3096\n",
            "Epoch 90/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.3792 - mean_absolute_error: 1.0815 - mean_squared_error: 2.3792\n",
            "Epoch 90: val_loss did not improve from 2.30955\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.3677 - mean_absolute_error: 1.0799 - mean_squared_error: 2.3677 - val_loss: 2.3106 - val_mean_absolute_error: 1.0660 - val_mean_squared_error: 2.3106\n",
            "Epoch 91/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.3688 - mean_absolute_error: 1.0801 - mean_squared_error: 2.3688\n",
            "Epoch 91: val_loss improved from 2.30955 to 2.30553, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3681 - mean_absolute_error: 1.0789 - mean_squared_error: 2.3681 - val_loss: 2.3055 - val_mean_absolute_error: 1.0653 - val_mean_squared_error: 2.3055\n",
            "Epoch 92/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.3797 - mean_absolute_error: 1.0806 - mean_squared_error: 2.3797\n",
            "Epoch 92: val_loss did not improve from 2.30553\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3684 - mean_absolute_error: 1.0772 - mean_squared_error: 2.3684 - val_loss: 2.3149 - val_mean_absolute_error: 1.0665 - val_mean_squared_error: 2.3149\n",
            "Epoch 93/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.3617 - mean_absolute_error: 1.0699 - mean_squared_error: 2.3617\n",
            "Epoch 93: val_loss did not improve from 2.30553\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3658 - mean_absolute_error: 1.0740 - mean_squared_error: 2.3658 - val_loss: 2.3070 - val_mean_absolute_error: 1.0704 - val_mean_squared_error: 2.3070\n",
            "Epoch 94/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.3801 - mean_absolute_error: 1.0832 - mean_squared_error: 2.3801\n",
            "Epoch 94: val_loss did not improve from 2.30553\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3667 - mean_absolute_error: 1.0790 - mean_squared_error: 2.3667 - val_loss: 2.3089 - val_mean_absolute_error: 1.0663 - val_mean_squared_error: 2.3089\n",
            "Epoch 95/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.3879 - mean_absolute_error: 1.0829 - mean_squared_error: 2.3879\n",
            "Epoch 95: val_loss did not improve from 2.30553\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3648 - mean_absolute_error: 1.0779 - mean_squared_error: 2.3648 - val_loss: 2.3091 - val_mean_absolute_error: 1.0667 - val_mean_squared_error: 2.3091\n",
            "Epoch 96/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.3811 - mean_absolute_error: 1.0826 - mean_squared_error: 2.3811\n",
            "Epoch 96: val_loss did not improve from 2.30553\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3648 - mean_absolute_error: 1.0787 - mean_squared_error: 2.3648 - val_loss: 2.3062 - val_mean_absolute_error: 1.0685 - val_mean_squared_error: 2.3062\n",
            "Epoch 97/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.3652 - mean_absolute_error: 1.0766 - mean_squared_error: 2.3652\n",
            "Epoch 97: val_loss did not improve from 2.30553\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.3649 - mean_absolute_error: 1.0765 - mean_squared_error: 2.3649 - val_loss: 2.3089 - val_mean_absolute_error: 1.0675 - val_mean_squared_error: 2.3089\n",
            "Epoch 98/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.3829 - mean_absolute_error: 1.0846 - mean_squared_error: 2.3829\n",
            "Epoch 98: val_loss did not improve from 2.30553\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3644 - mean_absolute_error: 1.0783 - mean_squared_error: 2.3644 - val_loss: 2.3086 - val_mean_absolute_error: 1.0639 - val_mean_squared_error: 2.3086\n",
            "Epoch 99/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.3738 - mean_absolute_error: 1.0768 - mean_squared_error: 2.3738\n",
            "Epoch 99: val_loss did not improve from 2.30553\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.3631 - mean_absolute_error: 1.0753 - mean_squared_error: 2.3631 - val_loss: 2.3058 - val_mean_absolute_error: 1.0639 - val_mean_squared_error: 2.3058\n",
            "Epoch 100/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.3795 - mean_absolute_error: 1.0812 - mean_squared_error: 2.3795\n",
            "Epoch 100: val_loss did not improve from 2.30553\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3612 - mean_absolute_error: 1.0759 - mean_squared_error: 2.3612 - val_loss: 2.3094 - val_mean_absolute_error: 1.0648 - val_mean_squared_error: 2.3094\n",
            "Epoch 101/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.3609 - mean_absolute_error: 1.0727 - mean_squared_error: 2.3609\n",
            "Epoch 101: val_loss improved from 2.30553 to 2.30150, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3612 - mean_absolute_error: 1.0736 - mean_squared_error: 2.3612 - val_loss: 2.3015 - val_mean_absolute_error: 1.0672 - val_mean_squared_error: 2.3015\n",
            "Epoch 102/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.3719 - mean_absolute_error: 1.0793 - mean_squared_error: 2.3719\n",
            "Epoch 102: val_loss did not improve from 2.30150\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3621 - mean_absolute_error: 1.0771 - mean_squared_error: 2.3621 - val_loss: 2.3068 - val_mean_absolute_error: 1.0653 - val_mean_squared_error: 2.3068\n",
            "Epoch 103/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.3791 - mean_absolute_error: 1.0773 - mean_squared_error: 2.3791\n",
            "Epoch 103: val_loss did not improve from 2.30150\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3622 - mean_absolute_error: 1.0753 - mean_squared_error: 2.3622 - val_loss: 2.3025 - val_mean_absolute_error: 1.0698 - val_mean_squared_error: 2.3025\n",
            "Epoch 104/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.3424 - mean_absolute_error: 1.0741 - mean_squared_error: 2.3424\n",
            "Epoch 104: val_loss improved from 2.30150 to 2.30090, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3625 - mean_absolute_error: 1.0779 - mean_squared_error: 2.3625 - val_loss: 2.3009 - val_mean_absolute_error: 1.0627 - val_mean_squared_error: 2.3009\n",
            "Epoch 105/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.3587 - mean_absolute_error: 1.0738 - mean_squared_error: 2.3587\n",
            "Epoch 105: val_loss improved from 2.30090 to 2.29657, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.3607 - mean_absolute_error: 1.0741 - mean_squared_error: 2.3607 - val_loss: 2.2966 - val_mean_absolute_error: 1.0636 - val_mean_squared_error: 2.2966\n",
            "Epoch 106/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.3379 - mean_absolute_error: 1.0695 - mean_squared_error: 2.3379\n",
            "Epoch 106: val_loss did not improve from 2.29657\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3609 - mean_absolute_error: 1.0738 - mean_squared_error: 2.3609 - val_loss: 2.3018 - val_mean_absolute_error: 1.0611 - val_mean_squared_error: 2.3018\n",
            "Epoch 107/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.3348 - mean_absolute_error: 1.0713 - mean_squared_error: 2.3348\n",
            "Epoch 107: val_loss did not improve from 2.29657\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.3608 - mean_absolute_error: 1.0756 - mean_squared_error: 2.3608 - val_loss: 2.3026 - val_mean_absolute_error: 1.0662 - val_mean_squared_error: 2.3026\n",
            "Epoch 108/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.3632 - mean_absolute_error: 1.0724 - mean_squared_error: 2.3632\n",
            "Epoch 108: val_loss did not improve from 2.29657\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3587 - mean_absolute_error: 1.0728 - mean_squared_error: 2.3587 - val_loss: 2.2988 - val_mean_absolute_error: 1.0655 - val_mean_squared_error: 2.2988\n",
            "Epoch 109/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.3887 - mean_absolute_error: 1.0789 - mean_squared_error: 2.3887\n",
            "Epoch 109: val_loss improved from 2.29657 to 2.29480, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.3601 - mean_absolute_error: 1.0744 - mean_squared_error: 2.3601 - val_loss: 2.2948 - val_mean_absolute_error: 1.0695 - val_mean_squared_error: 2.2948\n",
            "Epoch 110/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.3456 - mean_absolute_error: 1.0712 - mean_squared_error: 2.3456\n",
            "Epoch 110: val_loss did not improve from 2.29480\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3596 - mean_absolute_error: 1.0747 - mean_squared_error: 2.3596 - val_loss: 2.2949 - val_mean_absolute_error: 1.0651 - val_mean_squared_error: 2.2949\n",
            "Epoch 111/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.3673 - mean_absolute_error: 1.0809 - mean_squared_error: 2.3673\n",
            "Epoch 111: val_loss did not improve from 2.29480\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3600 - mean_absolute_error: 1.0774 - mean_squared_error: 2.3600 - val_loss: 2.3055 - val_mean_absolute_error: 1.0619 - val_mean_squared_error: 2.3055\n",
            "Epoch 112/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.3692 - mean_absolute_error: 1.0746 - mean_squared_error: 2.3692\n",
            "Epoch 112: val_loss improved from 2.29480 to 2.29401, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3599 - mean_absolute_error: 1.0731 - mean_squared_error: 2.3599 - val_loss: 2.2940 - val_mean_absolute_error: 1.0621 - val_mean_squared_error: 2.2940\n",
            "Epoch 113/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.3514 - mean_absolute_error: 1.0691 - mean_squared_error: 2.3514\n",
            "Epoch 113: val_loss improved from 2.29401 to 2.29360, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3575 - mean_absolute_error: 1.0716 - mean_squared_error: 2.3575 - val_loss: 2.2936 - val_mean_absolute_error: 1.0699 - val_mean_squared_error: 2.2936\n",
            "Epoch 114/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.3712 - mean_absolute_error: 1.0800 - mean_squared_error: 2.3712\n",
            "Epoch 114: val_loss did not improve from 2.29360\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3580 - mean_absolute_error: 1.0746 - mean_squared_error: 2.3580 - val_loss: 2.2976 - val_mean_absolute_error: 1.0611 - val_mean_squared_error: 2.2976\n",
            "Epoch 115/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.3335 - mean_absolute_error: 1.0676 - mean_squared_error: 2.3335\n",
            "Epoch 115: val_loss did not improve from 2.29360\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.3579 - mean_absolute_error: 1.0725 - mean_squared_error: 2.3579 - val_loss: 2.2941 - val_mean_absolute_error: 1.0609 - val_mean_squared_error: 2.2941\n",
            "Epoch 116/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.3665 - mean_absolute_error: 1.0792 - mean_squared_error: 2.3665\n",
            "Epoch 116: val_loss did not improve from 2.29360\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3581 - mean_absolute_error: 1.0770 - mean_squared_error: 2.3581 - val_loss: 2.2977 - val_mean_absolute_error: 1.0592 - val_mean_squared_error: 2.2977\n",
            "Epoch 117/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.3471 - mean_absolute_error: 1.0732 - mean_squared_error: 2.3471\n",
            "Epoch 117: val_loss did not improve from 2.29360\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3572 - mean_absolute_error: 1.0749 - mean_squared_error: 2.3572 - val_loss: 2.2940 - val_mean_absolute_error: 1.0586 - val_mean_squared_error: 2.2940\n",
            "Epoch 118/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.3554 - mean_absolute_error: 1.0672 - mean_squared_error: 2.3554\n",
            "Epoch 118: val_loss improved from 2.29360 to 2.29242, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3554 - mean_absolute_error: 1.0687 - mean_squared_error: 2.3554 - val_loss: 2.2924 - val_mean_absolute_error: 1.0614 - val_mean_squared_error: 2.2924\n",
            "Epoch 119/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.3263 - mean_absolute_error: 1.0687 - mean_squared_error: 2.3263\n",
            "Epoch 119: val_loss improved from 2.29242 to 2.29030, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3564 - mean_absolute_error: 1.0737 - mean_squared_error: 2.3564 - val_loss: 2.2903 - val_mean_absolute_error: 1.0689 - val_mean_squared_error: 2.2903\n",
            "Epoch 120/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.3593 - mean_absolute_error: 1.0767 - mean_squared_error: 2.3593\n",
            "Epoch 120: val_loss did not improve from 2.29030\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3553 - mean_absolute_error: 1.0747 - mean_squared_error: 2.3553 - val_loss: 2.2904 - val_mean_absolute_error: 1.0614 - val_mean_squared_error: 2.2904\n",
            "Epoch 121/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.3356 - mean_absolute_error: 1.0679 - mean_squared_error: 2.3356\n",
            "Epoch 121: val_loss did not improve from 2.29030\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.3564 - mean_absolute_error: 1.0721 - mean_squared_error: 2.3564 - val_loss: 2.2943 - val_mean_absolute_error: 1.0621 - val_mean_squared_error: 2.2943\n",
            "Epoch 122/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.3523 - mean_absolute_error: 1.0673 - mean_squared_error: 2.3523\n",
            "Epoch 122: val_loss did not improve from 2.29030\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.3555 - mean_absolute_error: 1.0708 - mean_squared_error: 2.3555 - val_loss: 2.2933 - val_mean_absolute_error: 1.0686 - val_mean_squared_error: 2.2933\n",
            "Epoch 123/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.3704 - mean_absolute_error: 1.0782 - mean_squared_error: 2.3704\n",
            "Epoch 123: val_loss did not improve from 2.29030\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.3555 - mean_absolute_error: 1.0749 - mean_squared_error: 2.3555 - val_loss: 2.2915 - val_mean_absolute_error: 1.0621 - val_mean_squared_error: 2.2915\n",
            "Epoch 124/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.3519 - mean_absolute_error: 1.0714 - mean_squared_error: 2.3519\n",
            "Epoch 124: val_loss improved from 2.29030 to 2.28822, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.3579 - mean_absolute_error: 1.0732 - mean_squared_error: 2.3579 - val_loss: 2.2882 - val_mean_absolute_error: 1.0637 - val_mean_squared_error: 2.2882\n",
            "Epoch 125/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.3363 - mean_absolute_error: 1.0692 - mean_squared_error: 2.3363\n",
            "Epoch 125: val_loss improved from 2.28822 to 2.28754, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3557 - mean_absolute_error: 1.0726 - mean_squared_error: 2.3557 - val_loss: 2.2875 - val_mean_absolute_error: 1.0687 - val_mean_squared_error: 2.2875\n",
            "Epoch 126/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.3969 - mean_absolute_error: 1.0817 - mean_squared_error: 2.3969\n",
            "Epoch 126: val_loss did not improve from 2.28754\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3560 - mean_absolute_error: 1.0754 - mean_squared_error: 2.3560 - val_loss: 2.3009 - val_mean_absolute_error: 1.0621 - val_mean_squared_error: 2.3009\n",
            "Epoch 127/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.3639 - mean_absolute_error: 1.0756 - mean_squared_error: 2.3639\n",
            "Epoch 127: val_loss did not improve from 2.28754\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3544 - mean_absolute_error: 1.0731 - mean_squared_error: 2.3544 - val_loss: 2.2993 - val_mean_absolute_error: 1.0568 - val_mean_squared_error: 2.2993\n",
            "Epoch 128/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.3800 - mean_absolute_error: 1.0744 - mean_squared_error: 2.3800\n",
            "Epoch 128: val_loss improved from 2.28754 to 2.28736, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3531 - mean_absolute_error: 1.0709 - mean_squared_error: 2.3531 - val_loss: 2.2874 - val_mean_absolute_error: 1.0687 - val_mean_squared_error: 2.2874\n",
            "Epoch 129/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.3613 - mean_absolute_error: 1.0730 - mean_squared_error: 2.3613\n",
            "Epoch 129: val_loss did not improve from 2.28736\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3568 - mean_absolute_error: 1.0719 - mean_squared_error: 2.3568 - val_loss: 2.2880 - val_mean_absolute_error: 1.0627 - val_mean_squared_error: 2.2880\n",
            "Epoch 130/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.3613 - mean_absolute_error: 1.0747 - mean_squared_error: 2.3613\n",
            "Epoch 130: val_loss did not improve from 2.28736\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.3519 - mean_absolute_error: 1.0730 - mean_squared_error: 2.3519 - val_loss: 2.2978 - val_mean_absolute_error: 1.0591 - val_mean_squared_error: 2.2978\n",
            "Epoch 131/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.3466 - mean_absolute_error: 1.0728 - mean_squared_error: 2.3466\n",
            "Epoch 131: val_loss did not improve from 2.28736\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.3518 - mean_absolute_error: 1.0733 - mean_squared_error: 2.3518 - val_loss: 2.2878 - val_mean_absolute_error: 1.0669 - val_mean_squared_error: 2.2878\n",
            "Epoch 132/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.3748 - mean_absolute_error: 1.0793 - mean_squared_error: 2.3748\n",
            "Epoch 132: val_loss did not improve from 2.28736\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3563 - mean_absolute_error: 1.0742 - mean_squared_error: 2.3563 - val_loss: 2.3040 - val_mean_absolute_error: 1.0595 - val_mean_squared_error: 2.3040\n",
            "Epoch 133/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.3621 - mean_absolute_error: 1.0705 - mean_squared_error: 2.3621\n",
            "Epoch 133: val_loss did not improve from 2.28736\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3546 - mean_absolute_error: 1.0687 - mean_squared_error: 2.3546 - val_loss: 2.2901 - val_mean_absolute_error: 1.0616 - val_mean_squared_error: 2.2901\n",
            "Epoch 134/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.3546 - mean_absolute_error: 1.0742 - mean_squared_error: 2.3546\n",
            "Epoch 134: val_loss did not improve from 2.28736\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3529 - mean_absolute_error: 1.0738 - mean_squared_error: 2.3529 - val_loss: 2.2899 - val_mean_absolute_error: 1.0596 - val_mean_squared_error: 2.2899\n",
            "Epoch 135/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.3663 - mean_absolute_error: 1.0751 - mean_squared_error: 2.3663\n",
            "Epoch 135: val_loss did not improve from 2.28736\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3540 - mean_absolute_error: 1.0720 - mean_squared_error: 2.3540 - val_loss: 2.2899 - val_mean_absolute_error: 1.0582 - val_mean_squared_error: 2.2899\n",
            "Epoch 136/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.3614 - mean_absolute_error: 1.0728 - mean_squared_error: 2.3614\n",
            "Epoch 136: val_loss did not improve from 2.28736\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.3516 - mean_absolute_error: 1.0702 - mean_squared_error: 2.3516 - val_loss: 2.2954 - val_mean_absolute_error: 1.0642 - val_mean_squared_error: 2.2954\n",
            "Epoch 137/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.3511 - mean_absolute_error: 1.0692 - mean_squared_error: 2.3511\n",
            "Epoch 137: val_loss improved from 2.28736 to 2.28453, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3550 - mean_absolute_error: 1.0709 - mean_squared_error: 2.3550 - val_loss: 2.2845 - val_mean_absolute_error: 1.0611 - val_mean_squared_error: 2.2845\n",
            "Epoch 138/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.3539 - mean_absolute_error: 1.0737 - mean_squared_error: 2.3539\n",
            "Epoch 138: val_loss did not improve from 2.28453\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3499 - mean_absolute_error: 1.0731 - mean_squared_error: 2.3499 - val_loss: 2.3061 - val_mean_absolute_error: 1.0572 - val_mean_squared_error: 2.3061\n",
            "Epoch 139/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.3364 - mean_absolute_error: 1.0645 - mean_squared_error: 2.3364\n",
            "Epoch 139: val_loss did not improve from 2.28453\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3541 - mean_absolute_error: 1.0692 - mean_squared_error: 2.3541 - val_loss: 2.2914 - val_mean_absolute_error: 1.0574 - val_mean_squared_error: 2.2914\n",
            "Epoch 140/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.3626 - mean_absolute_error: 1.0754 - mean_squared_error: 2.3626\n",
            "Epoch 140: val_loss did not improve from 2.28453\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3515 - mean_absolute_error: 1.0727 - mean_squared_error: 2.3515 - val_loss: 2.2907 - val_mean_absolute_error: 1.0569 - val_mean_squared_error: 2.2907\n",
            "Epoch 141/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.3487 - mean_absolute_error: 1.0690 - mean_squared_error: 2.3487\n",
            "Epoch 141: val_loss improved from 2.28453 to 2.28410, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3514 - mean_absolute_error: 1.0692 - mean_squared_error: 2.3514 - val_loss: 2.2841 - val_mean_absolute_error: 1.0608 - val_mean_squared_error: 2.2841\n",
            "Epoch 142/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.3366 - mean_absolute_error: 1.0696 - mean_squared_error: 2.3366\n",
            "Epoch 142: val_loss did not improve from 2.28410\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.3515 - mean_absolute_error: 1.0721 - mean_squared_error: 2.3515 - val_loss: 2.2896 - val_mean_absolute_error: 1.0599 - val_mean_squared_error: 2.2896\n",
            "Epoch 143/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.3510 - mean_absolute_error: 1.0691 - mean_squared_error: 2.3510\n",
            "Epoch 143: val_loss improved from 2.28410 to 2.28333, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3472 - mean_absolute_error: 1.0702 - mean_squared_error: 2.3472 - val_loss: 2.2833 - val_mean_absolute_error: 1.0634 - val_mean_squared_error: 2.2833\n",
            "Epoch 144/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.3493 - mean_absolute_error: 1.0717 - mean_squared_error: 2.3493\n",
            "Epoch 144: val_loss improved from 2.28333 to 2.28146, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3539 - mean_absolute_error: 1.0713 - mean_squared_error: 2.3539 - val_loss: 2.2815 - val_mean_absolute_error: 1.0603 - val_mean_squared_error: 2.2815\n",
            "Epoch 145/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.3489 - mean_absolute_error: 1.0678 - mean_squared_error: 2.3489\n",
            "Epoch 145: val_loss improved from 2.28146 to 2.28064, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3502 - mean_absolute_error: 1.0705 - mean_squared_error: 2.3502 - val_loss: 2.2806 - val_mean_absolute_error: 1.0632 - val_mean_squared_error: 2.2806\n",
            "Epoch 146/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.3302 - mean_absolute_error: 1.0646 - mean_squared_error: 2.3302\n",
            "Epoch 146: val_loss did not improve from 2.28064\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3499 - mean_absolute_error: 1.0706 - mean_squared_error: 2.3499 - val_loss: 2.2911 - val_mean_absolute_error: 1.0549 - val_mean_squared_error: 2.2911\n",
            "Epoch 147/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.3567 - mean_absolute_error: 1.0725 - mean_squared_error: 2.3567\n",
            "Epoch 147: val_loss did not improve from 2.28064\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3499 - mean_absolute_error: 1.0706 - mean_squared_error: 2.3499 - val_loss: 2.2823 - val_mean_absolute_error: 1.0584 - val_mean_squared_error: 2.2823\n",
            "Epoch 148/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.3480 - mean_absolute_error: 1.0725 - mean_squared_error: 2.3480\n",
            "Epoch 148: val_loss did not improve from 2.28064\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3507 - mean_absolute_error: 1.0724 - mean_squared_error: 2.3507 - val_loss: 2.2836 - val_mean_absolute_error: 1.0561 - val_mean_squared_error: 2.2836\n",
            "Epoch 149/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.3628 - mean_absolute_error: 1.0729 - mean_squared_error: 2.3628\n",
            "Epoch 149: val_loss did not improve from 2.28064\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3506 - mean_absolute_error: 1.0694 - mean_squared_error: 2.3506 - val_loss: 2.2863 - val_mean_absolute_error: 1.0558 - val_mean_squared_error: 2.2863\n",
            "Epoch 150/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.3480 - mean_absolute_error: 1.0687 - mean_squared_error: 2.3480\n",
            "Epoch 150: val_loss improved from 2.28064 to 2.28050, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3493 - mean_absolute_error: 1.0698 - mean_squared_error: 2.3493 - val_loss: 2.2805 - val_mean_absolute_error: 1.0609 - val_mean_squared_error: 2.2805\n",
            "Epoch 151/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.3537 - mean_absolute_error: 1.0706 - mean_squared_error: 2.3537\n",
            "Epoch 151: val_loss did not improve from 2.28050\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.3497 - mean_absolute_error: 1.0702 - mean_squared_error: 2.3497 - val_loss: 2.2862 - val_mean_absolute_error: 1.0571 - val_mean_squared_error: 2.2862\n",
            "Epoch 152/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.3196 - mean_absolute_error: 1.0665 - mean_squared_error: 2.3196\n",
            "Epoch 152: val_loss did not improve from 2.28050\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3480 - mean_absolute_error: 1.0708 - mean_squared_error: 2.3480 - val_loss: 2.2858 - val_mean_absolute_error: 1.0562 - val_mean_squared_error: 2.2858\n",
            "Epoch 153/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.3504 - mean_absolute_error: 1.0698 - mean_squared_error: 2.3504\n",
            "Epoch 153: val_loss improved from 2.28050 to 2.28006, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3483 - mean_absolute_error: 1.0699 - mean_squared_error: 2.3483 - val_loss: 2.2801 - val_mean_absolute_error: 1.0595 - val_mean_squared_error: 2.2801\n",
            "Epoch 154/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.3491 - mean_absolute_error: 1.0713 - mean_squared_error: 2.3491\n",
            "Epoch 154: val_loss improved from 2.28006 to 2.27940, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3500 - mean_absolute_error: 1.0714 - mean_squared_error: 2.3500 - val_loss: 2.2794 - val_mean_absolute_error: 1.0584 - val_mean_squared_error: 2.2794\n",
            "Epoch 155/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.3501 - mean_absolute_error: 1.0746 - mean_squared_error: 2.3501\n",
            "Epoch 155: val_loss did not improve from 2.27940\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.3501 - mean_absolute_error: 1.0746 - mean_squared_error: 2.3501 - val_loss: 2.2818 - val_mean_absolute_error: 1.0555 - val_mean_squared_error: 2.2818\n",
            "Epoch 156/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.3638 - mean_absolute_error: 1.0725 - mean_squared_error: 2.3638\n",
            "Epoch 156: val_loss did not improve from 2.27940\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3482 - mean_absolute_error: 1.0698 - mean_squared_error: 2.3482 - val_loss: 2.2797 - val_mean_absolute_error: 1.0559 - val_mean_squared_error: 2.2797\n",
            "Epoch 157/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.3244 - mean_absolute_error: 1.0662 - mean_squared_error: 2.3244\n",
            "Epoch 157: val_loss improved from 2.27940 to 2.27716, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3483 - mean_absolute_error: 1.0698 - mean_squared_error: 2.3483 - val_loss: 2.2772 - val_mean_absolute_error: 1.0568 - val_mean_squared_error: 2.2772\n",
            "Epoch 158/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.3492 - mean_absolute_error: 1.0702 - mean_squared_error: 2.3492\n",
            "Epoch 158: val_loss did not improve from 2.27716\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3481 - mean_absolute_error: 1.0706 - mean_squared_error: 2.3481 - val_loss: 2.2826 - val_mean_absolute_error: 1.0611 - val_mean_squared_error: 2.2826\n",
            "Epoch 159/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.3507 - mean_absolute_error: 1.0682 - mean_squared_error: 2.3507\n",
            "Epoch 159: val_loss improved from 2.27716 to 2.27631, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3487 - mean_absolute_error: 1.0690 - mean_squared_error: 2.3487 - val_loss: 2.2763 - val_mean_absolute_error: 1.0626 - val_mean_squared_error: 2.2763\n",
            "Epoch 160/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.3471 - mean_absolute_error: 1.0692 - mean_squared_error: 2.3471\n",
            "Epoch 160: val_loss did not improve from 2.27631\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3476 - mean_absolute_error: 1.0706 - mean_squared_error: 2.3476 - val_loss: 2.2906 - val_mean_absolute_error: 1.0569 - val_mean_squared_error: 2.2906\n",
            "Epoch 161/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.3670 - mean_absolute_error: 1.0750 - mean_squared_error: 2.3670\n",
            "Epoch 161: val_loss did not improve from 2.27631\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3502 - mean_absolute_error: 1.0714 - mean_squared_error: 2.3502 - val_loss: 2.2766 - val_mean_absolute_error: 1.0581 - val_mean_squared_error: 2.2766\n",
            "Epoch 162/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.3528 - mean_absolute_error: 1.0730 - mean_squared_error: 2.3528\n",
            "Epoch 162: val_loss did not improve from 2.27631\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3486 - mean_absolute_error: 1.0692 - mean_squared_error: 2.3486 - val_loss: 2.2783 - val_mean_absolute_error: 1.0550 - val_mean_squared_error: 2.2783\n",
            "Epoch 163/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 2.3319 - mean_absolute_error: 1.0672 - mean_squared_error: 2.3319\n",
            "Epoch 163: val_loss did not improve from 2.27631\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3447 - mean_absolute_error: 1.0693 - mean_squared_error: 2.3447 - val_loss: 2.2842 - val_mean_absolute_error: 1.0539 - val_mean_squared_error: 2.2842\n",
            "Epoch 164/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.3555 - mean_absolute_error: 1.0712 - mean_squared_error: 2.3555\n",
            "Epoch 164: val_loss did not improve from 2.27631\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.3470 - mean_absolute_error: 1.0698 - mean_squared_error: 2.3470 - val_loss: 2.2801 - val_mean_absolute_error: 1.0562 - val_mean_squared_error: 2.2801\n",
            "Epoch 165/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.3581 - mean_absolute_error: 1.0743 - mean_squared_error: 2.3581\n",
            "Epoch 165: val_loss did not improve from 2.27631\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3448 - mean_absolute_error: 1.0706 - mean_squared_error: 2.3448 - val_loss: 2.2822 - val_mean_absolute_error: 1.0572 - val_mean_squared_error: 2.2822\n",
            "Epoch 166/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.3454 - mean_absolute_error: 1.0751 - mean_squared_error: 2.3454\n",
            "Epoch 166: val_loss did not improve from 2.27631\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3450 - mean_absolute_error: 1.0716 - mean_squared_error: 2.3450 - val_loss: 2.2984 - val_mean_absolute_error: 1.0506 - val_mean_squared_error: 2.2984\n",
            "Epoch 167/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.3257 - mean_absolute_error: 1.0626 - mean_squared_error: 2.3257\n",
            "Epoch 167: val_loss did not improve from 2.27631\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3491 - mean_absolute_error: 1.0676 - mean_squared_error: 2.3491 - val_loss: 2.2856 - val_mean_absolute_error: 1.0526 - val_mean_squared_error: 2.2856\n",
            "Epoch 168/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.3579 - mean_absolute_error: 1.0750 - mean_squared_error: 2.3579\n",
            "Epoch 168: val_loss did not improve from 2.27631\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3483 - mean_absolute_error: 1.0704 - mean_squared_error: 2.3483 - val_loss: 2.2776 - val_mean_absolute_error: 1.0562 - val_mean_squared_error: 2.2776\n",
            "Epoch 169/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.3641 - mean_absolute_error: 1.0751 - mean_squared_error: 2.3641\n",
            "Epoch 169: val_loss improved from 2.27631 to 2.27276, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3444 - mean_absolute_error: 1.0695 - mean_squared_error: 2.3444 - val_loss: 2.2728 - val_mean_absolute_error: 1.0573 - val_mean_squared_error: 2.2728\n",
            "Epoch 170/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.3593 - mean_absolute_error: 1.0726 - mean_squared_error: 2.3593\n",
            "Epoch 170: val_loss did not improve from 2.27276\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3449 - mean_absolute_error: 1.0685 - mean_squared_error: 2.3449 - val_loss: 2.2755 - val_mean_absolute_error: 1.0590 - val_mean_squared_error: 2.2755\n",
            "Epoch 171/1000\n",
            "221/245 [==========================>...] - ETA: 0s - loss: 2.3610 - mean_absolute_error: 1.0767 - mean_squared_error: 2.3610\n",
            "Epoch 171: val_loss did not improve from 2.27276\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3449 - mean_absolute_error: 1.0719 - mean_squared_error: 2.3449 - val_loss: 2.2811 - val_mean_absolute_error: 1.0514 - val_mean_squared_error: 2.2811\n",
            "Epoch 172/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.3546 - mean_absolute_error: 1.0722 - mean_squared_error: 2.3546\n",
            "Epoch 172: val_loss did not improve from 2.27276\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3430 - mean_absolute_error: 1.0686 - mean_squared_error: 2.3430 - val_loss: 2.2746 - val_mean_absolute_error: 1.0560 - val_mean_squared_error: 2.2746\n",
            "Epoch 173/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.3415 - mean_absolute_error: 1.0687 - mean_squared_error: 2.3415\n",
            "Epoch 173: val_loss did not improve from 2.27276\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3436 - mean_absolute_error: 1.0690 - mean_squared_error: 2.3436 - val_loss: 2.2768 - val_mean_absolute_error: 1.0542 - val_mean_squared_error: 2.2768\n",
            "Epoch 174/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.3670 - mean_absolute_error: 1.0714 - mean_squared_error: 2.3670\n",
            "Epoch 174: val_loss did not improve from 2.27276\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3437 - mean_absolute_error: 1.0675 - mean_squared_error: 2.3437 - val_loss: 2.2771 - val_mean_absolute_error: 1.0538 - val_mean_squared_error: 2.2771\n",
            "Epoch 175/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.3780 - mean_absolute_error: 1.0788 - mean_squared_error: 2.3780\n",
            "Epoch 175: val_loss did not improve from 2.27276\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3422 - mean_absolute_error: 1.0694 - mean_squared_error: 2.3422 - val_loss: 2.2800 - val_mean_absolute_error: 1.0526 - val_mean_squared_error: 2.2800\n",
            "Epoch 176/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.3490 - mean_absolute_error: 1.0715 - mean_squared_error: 2.3490\n",
            "Epoch 176: val_loss did not improve from 2.27276\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3450 - mean_absolute_error: 1.0686 - mean_squared_error: 2.3450 - val_loss: 2.2819 - val_mean_absolute_error: 1.0510 - val_mean_squared_error: 2.2819\n",
            "Epoch 177/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.3431 - mean_absolute_error: 1.0704 - mean_squared_error: 2.3431\n",
            "Epoch 177: val_loss improved from 2.27276 to 2.27166, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3431 - mean_absolute_error: 1.0704 - mean_squared_error: 2.3431 - val_loss: 2.2717 - val_mean_absolute_error: 1.0526 - val_mean_squared_error: 2.2717\n",
            "Epoch 178/1000\n",
            "220/245 [=========================>....] - ETA: 0s - loss: 2.3838 - mean_absolute_error: 1.0748 - mean_squared_error: 2.3838\n",
            "Epoch 178: val_loss improved from 2.27166 to 2.27099, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3407 - mean_absolute_error: 1.0683 - mean_squared_error: 2.3407 - val_loss: 2.2710 - val_mean_absolute_error: 1.0552 - val_mean_squared_error: 2.2710\n",
            "Epoch 179/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.3415 - mean_absolute_error: 1.0649 - mean_squared_error: 2.3415\n",
            "Epoch 179: val_loss did not improve from 2.27099\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3430 - mean_absolute_error: 1.0662 - mean_squared_error: 2.3430 - val_loss: 2.2715 - val_mean_absolute_error: 1.0574 - val_mean_squared_error: 2.2715\n",
            "Epoch 180/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.3256 - mean_absolute_error: 1.0663 - mean_squared_error: 2.3256\n",
            "Epoch 180: val_loss did not improve from 2.27099\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3415 - mean_absolute_error: 1.0702 - mean_squared_error: 2.3415 - val_loss: 2.2723 - val_mean_absolute_error: 1.0516 - val_mean_squared_error: 2.2723\n",
            "Epoch 181/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.3219 - mean_absolute_error: 1.0615 - mean_squared_error: 2.3219\n",
            "Epoch 181: val_loss improved from 2.27099 to 2.26817, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3389 - mean_absolute_error: 1.0663 - mean_squared_error: 2.3389 - val_loss: 2.2682 - val_mean_absolute_error: 1.0583 - val_mean_squared_error: 2.2682\n",
            "Epoch 182/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.3448 - mean_absolute_error: 1.0686 - mean_squared_error: 2.3448\n",
            "Epoch 182: val_loss did not improve from 2.26817\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3439 - mean_absolute_error: 1.0691 - mean_squared_error: 2.3439 - val_loss: 2.2735 - val_mean_absolute_error: 1.0552 - val_mean_squared_error: 2.2735\n",
            "Epoch 183/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.3544 - mean_absolute_error: 1.0730 - mean_squared_error: 2.3544\n",
            "Epoch 183: val_loss did not improve from 2.26817\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3421 - mean_absolute_error: 1.0705 - mean_squared_error: 2.3421 - val_loss: 2.2793 - val_mean_absolute_error: 1.0501 - val_mean_squared_error: 2.2793\n",
            "Epoch 184/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.3460 - mean_absolute_error: 1.0682 - mean_squared_error: 2.3460\n",
            "Epoch 184: val_loss did not improve from 2.26817\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3407 - mean_absolute_error: 1.0673 - mean_squared_error: 2.3407 - val_loss: 2.2683 - val_mean_absolute_error: 1.0578 - val_mean_squared_error: 2.2683\n",
            "Epoch 185/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.3401 - mean_absolute_error: 1.0670 - mean_squared_error: 2.3401\n",
            "Epoch 185: val_loss improved from 2.26817 to 2.26692, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3399 - mean_absolute_error: 1.0677 - mean_squared_error: 2.3399 - val_loss: 2.2669 - val_mean_absolute_error: 1.0540 - val_mean_squared_error: 2.2669\n",
            "Epoch 186/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.3436 - mean_absolute_error: 1.0707 - mean_squared_error: 2.3436\n",
            "Epoch 186: val_loss improved from 2.26692 to 2.26639, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3422 - mean_absolute_error: 1.0692 - mean_squared_error: 2.3422 - val_loss: 2.2664 - val_mean_absolute_error: 1.0516 - val_mean_squared_error: 2.2664\n",
            "Epoch 187/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.3488 - mean_absolute_error: 1.0697 - mean_squared_error: 2.3488\n",
            "Epoch 187: val_loss did not improve from 2.26639\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.3360 - mean_absolute_error: 1.0669 - mean_squared_error: 2.3360 - val_loss: 2.2880 - val_mean_absolute_error: 1.0495 - val_mean_squared_error: 2.2880\n",
            "Epoch 188/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.3366 - mean_absolute_error: 1.0612 - mean_squared_error: 2.3366\n",
            "Epoch 188: val_loss improved from 2.26639 to 2.26572, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3404 - mean_absolute_error: 1.0642 - mean_squared_error: 2.3404 - val_loss: 2.2657 - val_mean_absolute_error: 1.0539 - val_mean_squared_error: 2.2657\n",
            "Epoch 189/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.3404 - mean_absolute_error: 1.0676 - mean_squared_error: 2.3404\n",
            "Epoch 189: val_loss did not improve from 2.26572\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3415 - mean_absolute_error: 1.0680 - mean_squared_error: 2.3415 - val_loss: 2.2657 - val_mean_absolute_error: 1.0526 - val_mean_squared_error: 2.2657\n",
            "Epoch 190/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.3361 - mean_absolute_error: 1.0691 - mean_squared_error: 2.3361\n",
            "Epoch 190: val_loss did not improve from 2.26572\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3361 - mean_absolute_error: 1.0691 - mean_squared_error: 2.3361 - val_loss: 2.2685 - val_mean_absolute_error: 1.0480 - val_mean_squared_error: 2.2685\n",
            "Epoch 191/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.3362 - mean_absolute_error: 1.0627 - mean_squared_error: 2.3362\n",
            "Epoch 191: val_loss improved from 2.26572 to 2.26411, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3380 - mean_absolute_error: 1.0652 - mean_squared_error: 2.3380 - val_loss: 2.2641 - val_mean_absolute_error: 1.0556 - val_mean_squared_error: 2.2641\n",
            "Epoch 192/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.3402 - mean_absolute_error: 1.0656 - mean_squared_error: 2.3402\n",
            "Epoch 192: val_loss improved from 2.26411 to 2.26180, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.3364 - mean_absolute_error: 1.0647 - mean_squared_error: 2.3364 - val_loss: 2.2618 - val_mean_absolute_error: 1.0632 - val_mean_squared_error: 2.2618\n",
            "Epoch 193/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.3431 - mean_absolute_error: 1.0665 - mean_squared_error: 2.3431\n",
            "Epoch 193: val_loss did not improve from 2.26180\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3378 - mean_absolute_error: 1.0655 - mean_squared_error: 2.3378 - val_loss: 2.2658 - val_mean_absolute_error: 1.0484 - val_mean_squared_error: 2.2658\n",
            "Epoch 194/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.3297 - mean_absolute_error: 1.0630 - mean_squared_error: 2.3297\n",
            "Epoch 194: val_loss improved from 2.26180 to 2.26131, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.3353 - mean_absolute_error: 1.0651 - mean_squared_error: 2.3353 - val_loss: 2.2613 - val_mean_absolute_error: 1.0571 - val_mean_squared_error: 2.2613\n",
            "Epoch 195/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.3463 - mean_absolute_error: 1.0704 - mean_squared_error: 2.3463\n",
            "Epoch 195: val_loss did not improve from 2.26131\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3368 - mean_absolute_error: 1.0677 - mean_squared_error: 2.3368 - val_loss: 2.2673 - val_mean_absolute_error: 1.0498 - val_mean_squared_error: 2.2673\n",
            "Epoch 196/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.3145 - mean_absolute_error: 1.0601 - mean_squared_error: 2.3145\n",
            "Epoch 196: val_loss did not improve from 2.26131\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3320 - mean_absolute_error: 1.0630 - mean_squared_error: 2.3320 - val_loss: 2.2806 - val_mean_absolute_error: 1.0483 - val_mean_squared_error: 2.2806\n",
            "Epoch 197/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.3293 - mean_absolute_error: 1.0641 - mean_squared_error: 2.3293\n",
            "Epoch 197: val_loss did not improve from 2.26131\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3380 - mean_absolute_error: 1.0646 - mean_squared_error: 2.3380 - val_loss: 2.2653 - val_mean_absolute_error: 1.0498 - val_mean_squared_error: 2.2653\n",
            "Epoch 198/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.3585 - mean_absolute_error: 1.0695 - mean_squared_error: 2.3585\n",
            "Epoch 198: val_loss improved from 2.26131 to 2.25637, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3320 - mean_absolute_error: 1.0649 - mean_squared_error: 2.3320 - val_loss: 2.2564 - val_mean_absolute_error: 1.0531 - val_mean_squared_error: 2.2564\n",
            "Epoch 199/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.3290 - mean_absolute_error: 1.0616 - mean_squared_error: 2.3290\n",
            "Epoch 199: val_loss did not improve from 2.25637\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.3290 - mean_absolute_error: 1.0616 - mean_squared_error: 2.3290 - val_loss: 2.2574 - val_mean_absolute_error: 1.0650 - val_mean_squared_error: 2.2574\n",
            "Epoch 200/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.3311 - mean_absolute_error: 1.0686 - mean_squared_error: 2.3311\n",
            "Epoch 200: val_loss did not improve from 2.25637\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.3309 - mean_absolute_error: 1.0685 - mean_squared_error: 2.3309 - val_loss: 2.2678 - val_mean_absolute_error: 1.0436 - val_mean_squared_error: 2.2678\n",
            "Epoch 201/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.3142 - mean_absolute_error: 1.0592 - mean_squared_error: 2.3142\n",
            "Epoch 201: val_loss improved from 2.25637 to 2.25491, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.3314 - mean_absolute_error: 1.0622 - mean_squared_error: 2.3314 - val_loss: 2.2549 - val_mean_absolute_error: 1.0464 - val_mean_squared_error: 2.2549\n",
            "Epoch 202/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.3282 - mean_absolute_error: 1.0619 - mean_squared_error: 2.3282\n",
            "Epoch 202: val_loss improved from 2.25491 to 2.25362, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.3295 - mean_absolute_error: 1.0620 - mean_squared_error: 2.3295 - val_loss: 2.2536 - val_mean_absolute_error: 1.0477 - val_mean_squared_error: 2.2536\n",
            "Epoch 203/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.3297 - mean_absolute_error: 1.0611 - mean_squared_error: 2.3297\n",
            "Epoch 203: val_loss improved from 2.25362 to 2.25175, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3297 - mean_absolute_error: 1.0611 - mean_squared_error: 2.3297 - val_loss: 2.2518 - val_mean_absolute_error: 1.0505 - val_mean_squared_error: 2.2518\n",
            "Epoch 204/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.3338 - mean_absolute_error: 1.0640 - mean_squared_error: 2.3338\n",
            "Epoch 204: val_loss did not improve from 2.25175\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3281 - mean_absolute_error: 1.0640 - mean_squared_error: 2.3281 - val_loss: 2.2578 - val_mean_absolute_error: 1.0446 - val_mean_squared_error: 2.2578\n",
            "Epoch 205/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.3013 - mean_absolute_error: 1.0576 - mean_squared_error: 2.3013\n",
            "Epoch 205: val_loss did not improve from 2.25175\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3264 - mean_absolute_error: 1.0629 - mean_squared_error: 2.3264 - val_loss: 2.2719 - val_mean_absolute_error: 1.0437 - val_mean_squared_error: 2.2719\n",
            "Epoch 206/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.3297 - mean_absolute_error: 1.0633 - mean_squared_error: 2.3297\n",
            "Epoch 206: val_loss improved from 2.25175 to 2.25038, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.3287 - mean_absolute_error: 1.0606 - mean_squared_error: 2.3287 - val_loss: 2.2504 - val_mean_absolute_error: 1.0462 - val_mean_squared_error: 2.2504\n",
            "Epoch 207/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.3222 - mean_absolute_error: 1.0641 - mean_squared_error: 2.3222\n",
            "Epoch 207: val_loss improved from 2.25038 to 2.24718, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3251 - mean_absolute_error: 1.0614 - mean_squared_error: 2.3251 - val_loss: 2.2472 - val_mean_absolute_error: 1.0503 - val_mean_squared_error: 2.2472\n",
            "Epoch 208/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.3288 - mean_absolute_error: 1.0627 - mean_squared_error: 2.3288\n",
            "Epoch 208: val_loss did not improve from 2.24718\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3238 - mean_absolute_error: 1.0634 - mean_squared_error: 2.3238 - val_loss: 2.2483 - val_mean_absolute_error: 1.0527 - val_mean_squared_error: 2.2483\n",
            "Epoch 209/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.3041 - mean_absolute_error: 1.0587 - mean_squared_error: 2.3041\n",
            "Epoch 209: val_loss did not improve from 2.24718\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3234 - mean_absolute_error: 1.0617 - mean_squared_error: 2.3234 - val_loss: 2.2504 - val_mean_absolute_error: 1.0401 - val_mean_squared_error: 2.2504\n",
            "Epoch 210/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.2656 - mean_absolute_error: 1.0490 - mean_squared_error: 2.2656\n",
            "Epoch 210: val_loss did not improve from 2.24718\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3214 - mean_absolute_error: 1.0586 - mean_squared_error: 2.3214 - val_loss: 2.2547 - val_mean_absolute_error: 1.0403 - val_mean_squared_error: 2.2547\n",
            "Epoch 211/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.3463 - mean_absolute_error: 1.0617 - mean_squared_error: 2.3463\n",
            "Epoch 211: val_loss improved from 2.24718 to 2.24360, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3201 - mean_absolute_error: 1.0590 - mean_squared_error: 2.3201 - val_loss: 2.2436 - val_mean_absolute_error: 1.0495 - val_mean_squared_error: 2.2436\n",
            "Epoch 212/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.3336 - mean_absolute_error: 1.0617 - mean_squared_error: 2.3336\n",
            "Epoch 212: val_loss did not improve from 2.24360\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.3190 - mean_absolute_error: 1.0610 - mean_squared_error: 2.3190 - val_loss: 2.2553 - val_mean_absolute_error: 1.0418 - val_mean_squared_error: 2.2553\n",
            "Epoch 213/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.3128 - mean_absolute_error: 1.0564 - mean_squared_error: 2.3128\n",
            "Epoch 213: val_loss improved from 2.24360 to 2.24117, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.3194 - mean_absolute_error: 1.0575 - mean_squared_error: 2.3194 - val_loss: 2.2412 - val_mean_absolute_error: 1.0414 - val_mean_squared_error: 2.2412\n",
            "Epoch 214/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.3375 - mean_absolute_error: 1.0617 - mean_squared_error: 2.3375\n",
            "Epoch 214: val_loss improved from 2.24117 to 2.23666, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.3192 - mean_absolute_error: 1.0591 - mean_squared_error: 2.3192 - val_loss: 2.2367 - val_mean_absolute_error: 1.0498 - val_mean_squared_error: 2.2367\n",
            "Epoch 215/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.3311 - mean_absolute_error: 1.0607 - mean_squared_error: 2.3311\n",
            "Epoch 215: val_loss improved from 2.23666 to 2.23406, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.3154 - mean_absolute_error: 1.0587 - mean_squared_error: 2.3154 - val_loss: 2.2341 - val_mean_absolute_error: 1.0420 - val_mean_squared_error: 2.2341\n",
            "Epoch 216/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.3163 - mean_absolute_error: 1.0562 - mean_squared_error: 2.3163\n",
            "Epoch 216: val_loss improved from 2.23406 to 2.23334, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.3151 - mean_absolute_error: 1.0564 - mean_squared_error: 2.3151 - val_loss: 2.2333 - val_mean_absolute_error: 1.0527 - val_mean_squared_error: 2.2333\n",
            "Epoch 217/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.3315 - mean_absolute_error: 1.0597 - mean_squared_error: 2.3315\n",
            "Epoch 217: val_loss did not improve from 2.23334\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3147 - mean_absolute_error: 1.0562 - mean_squared_error: 2.3147 - val_loss: 2.2336 - val_mean_absolute_error: 1.0395 - val_mean_squared_error: 2.2336\n",
            "Epoch 218/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.2934 - mean_absolute_error: 1.0508 - mean_squared_error: 2.2934\n",
            "Epoch 218: val_loss improved from 2.23334 to 2.23216, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3091 - mean_absolute_error: 1.0545 - mean_squared_error: 2.3091 - val_loss: 2.2322 - val_mean_absolute_error: 1.0389 - val_mean_squared_error: 2.2322\n",
            "Epoch 219/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.3170 - mean_absolute_error: 1.0592 - mean_squared_error: 2.3170\n",
            "Epoch 219: val_loss did not improve from 2.23216\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3091 - mean_absolute_error: 1.0574 - mean_squared_error: 2.3091 - val_loss: 2.2433 - val_mean_absolute_error: 1.0321 - val_mean_squared_error: 2.2433\n",
            "Epoch 220/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.3297 - mean_absolute_error: 1.0585 - mean_squared_error: 2.3297\n",
            "Epoch 220: val_loss did not improve from 2.23216\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3090 - mean_absolute_error: 1.0564 - mean_squared_error: 2.3090 - val_loss: 2.2370 - val_mean_absolute_error: 1.0381 - val_mean_squared_error: 2.2370\n",
            "Epoch 221/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.3349 - mean_absolute_error: 1.0579 - mean_squared_error: 2.3349\n",
            "Epoch 221: val_loss improved from 2.23216 to 2.22678, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3083 - mean_absolute_error: 1.0541 - mean_squared_error: 2.3083 - val_loss: 2.2268 - val_mean_absolute_error: 1.0401 - val_mean_squared_error: 2.2268\n",
            "Epoch 222/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.3102 - mean_absolute_error: 1.0528 - mean_squared_error: 2.3102\n",
            "Epoch 222: val_loss improved from 2.22678 to 2.22609, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3023 - mean_absolute_error: 1.0517 - mean_squared_error: 2.3023 - val_loss: 2.2261 - val_mean_absolute_error: 1.0346 - val_mean_squared_error: 2.2261\n",
            "Epoch 223/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.2980 - mean_absolute_error: 1.0528 - mean_squared_error: 2.2980\n",
            "Epoch 223: val_loss did not improve from 2.22609\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.3016 - mean_absolute_error: 1.0540 - mean_squared_error: 2.3016 - val_loss: 2.2354 - val_mean_absolute_error: 1.0318 - val_mean_squared_error: 2.2354\n",
            "Epoch 224/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.3076 - mean_absolute_error: 1.0550 - mean_squared_error: 2.3076\n",
            "Epoch 224: val_loss improved from 2.22609 to 2.21737, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.3039 - mean_absolute_error: 1.0547 - mean_squared_error: 2.3039 - val_loss: 2.2174 - val_mean_absolute_error: 1.0356 - val_mean_squared_error: 2.2174\n",
            "Epoch 225/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.3049 - mean_absolute_error: 1.0523 - mean_squared_error: 2.3049\n",
            "Epoch 225: val_loss did not improve from 2.21737\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2980 - mean_absolute_error: 1.0507 - mean_squared_error: 2.2980 - val_loss: 2.2194 - val_mean_absolute_error: 1.0315 - val_mean_squared_error: 2.2194\n",
            "Epoch 226/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.2779 - mean_absolute_error: 1.0468 - mean_squared_error: 2.2779\n",
            "Epoch 226: val_loss improved from 2.21737 to 2.21304, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2980 - mean_absolute_error: 1.0508 - mean_squared_error: 2.2980 - val_loss: 2.2130 - val_mean_absolute_error: 1.0346 - val_mean_squared_error: 2.2130\n",
            "Epoch 227/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.2963 - mean_absolute_error: 1.0490 - mean_squared_error: 2.2963\n",
            "Epoch 227: val_loss improved from 2.21304 to 2.21279, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2944 - mean_absolute_error: 1.0492 - mean_squared_error: 2.2944 - val_loss: 2.2128 - val_mean_absolute_error: 1.0445 - val_mean_squared_error: 2.2128\n",
            "Epoch 228/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.3212 - mean_absolute_error: 1.0593 - mean_squared_error: 2.3212\n",
            "Epoch 228: val_loss did not improve from 2.21279\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2914 - mean_absolute_error: 1.0511 - mean_squared_error: 2.2914 - val_loss: 2.2141 - val_mean_absolute_error: 1.0405 - val_mean_squared_error: 2.2141\n",
            "Epoch 229/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.2887 - mean_absolute_error: 1.0471 - mean_squared_error: 2.2887\n",
            "Epoch 229: val_loss did not improve from 2.21279\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2887 - mean_absolute_error: 1.0471 - mean_squared_error: 2.2887 - val_loss: 2.2129 - val_mean_absolute_error: 1.0302 - val_mean_squared_error: 2.2129\n",
            "Epoch 230/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.2729 - mean_absolute_error: 1.0472 - mean_squared_error: 2.2729\n",
            "Epoch 230: val_loss improved from 2.21279 to 2.20109, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.2844 - mean_absolute_error: 1.0454 - mean_squared_error: 2.2844 - val_loss: 2.2011 - val_mean_absolute_error: 1.0326 - val_mean_squared_error: 2.2011\n",
            "Epoch 231/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.2701 - mean_absolute_error: 1.0406 - mean_squared_error: 2.2701\n",
            "Epoch 231: val_loss did not improve from 2.20109\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2826 - mean_absolute_error: 1.0443 - mean_squared_error: 2.2826 - val_loss: 2.2044 - val_mean_absolute_error: 1.0329 - val_mean_squared_error: 2.2044\n",
            "Epoch 232/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.2810 - mean_absolute_error: 1.0461 - mean_squared_error: 2.2810\n",
            "Epoch 232: val_loss improved from 2.20109 to 2.19659, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2810 - mean_absolute_error: 1.0461 - mean_squared_error: 2.2810 - val_loss: 2.1966 - val_mean_absolute_error: 1.0232 - val_mean_squared_error: 2.1966\n",
            "Epoch 233/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.2803 - mean_absolute_error: 1.0417 - mean_squared_error: 2.2803\n",
            "Epoch 233: val_loss did not improve from 2.19659\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2775 - mean_absolute_error: 1.0414 - mean_squared_error: 2.2775 - val_loss: 2.1992 - val_mean_absolute_error: 1.0261 - val_mean_squared_error: 2.1992\n",
            "Epoch 234/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.2776 - mean_absolute_error: 1.0417 - mean_squared_error: 2.2776\n",
            "Epoch 234: val_loss improved from 2.19659 to 2.18860, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2734 - mean_absolute_error: 1.0419 - mean_squared_error: 2.2734 - val_loss: 2.1886 - val_mean_absolute_error: 1.0318 - val_mean_squared_error: 2.1886\n",
            "Epoch 235/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.2490 - mean_absolute_error: 1.0380 - mean_squared_error: 2.2490\n",
            "Epoch 235: val_loss improved from 2.18860 to 2.18605, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.2679 - mean_absolute_error: 1.0413 - mean_squared_error: 2.2679 - val_loss: 2.1861 - val_mean_absolute_error: 1.0224 - val_mean_squared_error: 2.1861\n",
            "Epoch 236/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.2420 - mean_absolute_error: 1.0351 - mean_squared_error: 2.2420\n",
            "Epoch 236: val_loss did not improve from 2.18605\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2676 - mean_absolute_error: 1.0397 - mean_squared_error: 2.2676 - val_loss: 2.2018 - val_mean_absolute_error: 1.0163 - val_mean_squared_error: 2.2018\n",
            "Epoch 237/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.2792 - mean_absolute_error: 1.0374 - mean_squared_error: 2.2792\n",
            "Epoch 237: val_loss improved from 2.18605 to 2.17849, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2630 - mean_absolute_error: 1.0350 - mean_squared_error: 2.2630 - val_loss: 2.1785 - val_mean_absolute_error: 1.0253 - val_mean_squared_error: 2.1785\n",
            "Epoch 238/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.2580 - mean_absolute_error: 1.0382 - mean_squared_error: 2.2580\n",
            "Epoch 238: val_loss improved from 2.17849 to 2.17653, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2579 - mean_absolute_error: 1.0376 - mean_squared_error: 2.2579 - val_loss: 2.1765 - val_mean_absolute_error: 1.0208 - val_mean_squared_error: 2.1765\n",
            "Epoch 239/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.2611 - mean_absolute_error: 1.0344 - mean_squared_error: 2.2611\n",
            "Epoch 239: val_loss improved from 2.17653 to 2.17141, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.2555 - mean_absolute_error: 1.0341 - mean_squared_error: 2.2555 - val_loss: 2.1714 - val_mean_absolute_error: 1.0175 - val_mean_squared_error: 2.1714\n",
            "Epoch 240/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.2526 - mean_absolute_error: 1.0323 - mean_squared_error: 2.2526\n",
            "Epoch 240: val_loss improved from 2.17141 to 2.16743, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2526 - mean_absolute_error: 1.0323 - mean_squared_error: 2.2526 - val_loss: 2.1674 - val_mean_absolute_error: 1.0138 - val_mean_squared_error: 2.1674\n",
            "Epoch 241/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.2187 - mean_absolute_error: 1.0229 - mean_squared_error: 2.2187\n",
            "Epoch 241: val_loss did not improve from 2.16743\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2484 - mean_absolute_error: 1.0294 - mean_squared_error: 2.2484 - val_loss: 2.1697 - val_mean_absolute_error: 1.0169 - val_mean_squared_error: 2.1697\n",
            "Epoch 242/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.2449 - mean_absolute_error: 1.0297 - mean_squared_error: 2.2449\n",
            "Epoch 242: val_loss improved from 2.16743 to 2.16168, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.2449 - mean_absolute_error: 1.0297 - mean_squared_error: 2.2449 - val_loss: 2.1617 - val_mean_absolute_error: 1.0072 - val_mean_squared_error: 2.1617\n",
            "Epoch 243/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.2409 - mean_absolute_error: 1.0254 - mean_squared_error: 2.2409\n",
            "Epoch 243: val_loss improved from 2.16168 to 2.15693, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.2402 - mean_absolute_error: 1.0264 - mean_squared_error: 2.2402 - val_loss: 2.1569 - val_mean_absolute_error: 1.0107 - val_mean_squared_error: 2.1569\n",
            "Epoch 244/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.2243 - mean_absolute_error: 1.0223 - mean_squared_error: 2.2243\n",
            "Epoch 244: val_loss improved from 2.15693 to 2.15368, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.2386 - mean_absolute_error: 1.0252 - mean_squared_error: 2.2386 - val_loss: 2.1537 - val_mean_absolute_error: 1.0086 - val_mean_squared_error: 2.1537\n",
            "Epoch 245/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.2322 - mean_absolute_error: 1.0240 - mean_squared_error: 2.2322\n",
            "Epoch 245: val_loss did not improve from 2.15368\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.2322 - mean_absolute_error: 1.0240 - mean_squared_error: 2.2322 - val_loss: 2.1587 - val_mean_absolute_error: 1.0039 - val_mean_squared_error: 2.1587\n",
            "Epoch 246/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.2115 - mean_absolute_error: 1.0188 - mean_squared_error: 2.2115\n",
            "Epoch 246: val_loss improved from 2.15368 to 2.14815, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.2287 - mean_absolute_error: 1.0207 - mean_squared_error: 2.2287 - val_loss: 2.1482 - val_mean_absolute_error: 1.0024 - val_mean_squared_error: 2.1482\n",
            "Epoch 247/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.2212 - mean_absolute_error: 1.0190 - mean_squared_error: 2.2212\n",
            "Epoch 247: val_loss improved from 2.14815 to 2.14287, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2265 - mean_absolute_error: 1.0204 - mean_squared_error: 2.2265 - val_loss: 2.1429 - val_mean_absolute_error: 1.0150 - val_mean_squared_error: 2.1429\n",
            "Epoch 248/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.2373 - mean_absolute_error: 1.0201 - mean_squared_error: 2.2373\n",
            "Epoch 248: val_loss improved from 2.14287 to 2.13880, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2224 - mean_absolute_error: 1.0173 - mean_squared_error: 2.2224 - val_loss: 2.1388 - val_mean_absolute_error: 1.0018 - val_mean_squared_error: 2.1388\n",
            "Epoch 249/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.2175 - mean_absolute_error: 1.0173 - mean_squared_error: 2.2175\n",
            "Epoch 249: val_loss improved from 2.13880 to 2.13710, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2198 - mean_absolute_error: 1.0177 - mean_squared_error: 2.2198 - val_loss: 2.1371 - val_mean_absolute_error: 0.9968 - val_mean_squared_error: 2.1371\n",
            "Epoch 250/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.2041 - mean_absolute_error: 1.0137 - mean_squared_error: 2.2041\n",
            "Epoch 250: val_loss improved from 2.13710 to 2.13316, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2162 - mean_absolute_error: 1.0152 - mean_squared_error: 2.2162 - val_loss: 2.1332 - val_mean_absolute_error: 1.0121 - val_mean_squared_error: 2.1332\n",
            "Epoch 251/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.2191 - mean_absolute_error: 1.0153 - mean_squared_error: 2.2191\n",
            "Epoch 251: val_loss improved from 2.13316 to 2.12607, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.2133 - mean_absolute_error: 1.0140 - mean_squared_error: 2.2133 - val_loss: 2.1261 - val_mean_absolute_error: 0.9993 - val_mean_squared_error: 2.1261\n",
            "Epoch 252/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.1737 - mean_absolute_error: 1.0058 - mean_squared_error: 2.1737\n",
            "Epoch 252: val_loss improved from 2.12607 to 2.12603, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.2099 - mean_absolute_error: 1.0136 - mean_squared_error: 2.2099 - val_loss: 2.1260 - val_mean_absolute_error: 0.9914 - val_mean_squared_error: 2.1260\n",
            "Epoch 253/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.2231 - mean_absolute_error: 1.0120 - mean_squared_error: 2.2231\n",
            "Epoch 253: val_loss improved from 2.12603 to 2.12334, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.2057 - mean_absolute_error: 1.0080 - mean_squared_error: 2.2057 - val_loss: 2.1233 - val_mean_absolute_error: 1.0002 - val_mean_squared_error: 2.1233\n",
            "Epoch 254/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.2036 - mean_absolute_error: 1.0080 - mean_squared_error: 2.2036\n",
            "Epoch 254: val_loss improved from 2.12334 to 2.12119, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.2064 - mean_absolute_error: 1.0091 - mean_squared_error: 2.2064 - val_loss: 2.1212 - val_mean_absolute_error: 0.9937 - val_mean_squared_error: 2.1212\n",
            "Epoch 255/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.2126 - mean_absolute_error: 1.0126 - mean_squared_error: 2.2126\n",
            "Epoch 255: val_loss improved from 2.12119 to 2.12072, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.2042 - mean_absolute_error: 1.0081 - mean_squared_error: 2.2042 - val_loss: 2.1207 - val_mean_absolute_error: 0.9944 - val_mean_squared_error: 2.1207\n",
            "Epoch 256/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.1792 - mean_absolute_error: 1.0026 - mean_squared_error: 2.1792\n",
            "Epoch 256: val_loss did not improve from 2.12072\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1985 - mean_absolute_error: 1.0072 - mean_squared_error: 2.1985 - val_loss: 2.1273 - val_mean_absolute_error: 0.9868 - val_mean_squared_error: 2.1273\n",
            "Epoch 257/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.1984 - mean_absolute_error: 1.0072 - mean_squared_error: 2.1984\n",
            "Epoch 257: val_loss improved from 2.12072 to 2.11221, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1959 - mean_absolute_error: 1.0050 - mean_squared_error: 2.1959 - val_loss: 2.1122 - val_mean_absolute_error: 0.9887 - val_mean_squared_error: 2.1122\n",
            "Epoch 258/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.1676 - mean_absolute_error: 0.9962 - mean_squared_error: 2.1676\n",
            "Epoch 258: val_loss improved from 2.11221 to 2.10927, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1926 - mean_absolute_error: 1.0030 - mean_squared_error: 2.1926 - val_loss: 2.1093 - val_mean_absolute_error: 0.9964 - val_mean_squared_error: 2.1093\n",
            "Epoch 259/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.2058 - mean_absolute_error: 1.0106 - mean_squared_error: 2.2058\n",
            "Epoch 259: val_loss did not improve from 2.10927\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1907 - mean_absolute_error: 1.0039 - mean_squared_error: 2.1907 - val_loss: 2.1230 - val_mean_absolute_error: 0.9924 - val_mean_squared_error: 2.1230\n",
            "Epoch 260/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.1700 - mean_absolute_error: 0.9946 - mean_squared_error: 2.1700\n",
            "Epoch 260: val_loss did not improve from 2.10927\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1925 - mean_absolute_error: 1.0010 - mean_squared_error: 2.1925 - val_loss: 2.1133 - val_mean_absolute_error: 0.9915 - val_mean_squared_error: 2.1133\n",
            "Epoch 261/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.1968 - mean_absolute_error: 1.0049 - mean_squared_error: 2.1968\n",
            "Epoch 261: val_loss did not improve from 2.10927\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1895 - mean_absolute_error: 1.0016 - mean_squared_error: 2.1895 - val_loss: 2.1104 - val_mean_absolute_error: 0.9831 - val_mean_squared_error: 2.1104\n",
            "Epoch 262/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.1787 - mean_absolute_error: 1.0018 - mean_squared_error: 2.1787\n",
            "Epoch 262: val_loss improved from 2.10927 to 2.10052, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1861 - mean_absolute_error: 1.0019 - mean_squared_error: 2.1861 - val_loss: 2.1005 - val_mean_absolute_error: 0.9906 - val_mean_squared_error: 2.1005\n",
            "Epoch 263/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.1904 - mean_absolute_error: 0.9989 - mean_squared_error: 2.1904\n",
            "Epoch 263: val_loss did not improve from 2.10052\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1851 - mean_absolute_error: 0.9978 - mean_squared_error: 2.1851 - val_loss: 2.1010 - val_mean_absolute_error: 0.9870 - val_mean_squared_error: 2.1010\n",
            "Epoch 264/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.1620 - mean_absolute_error: 0.9929 - mean_squared_error: 2.1620\n",
            "Epoch 264: val_loss improved from 2.10052 to 2.09961, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1832 - mean_absolute_error: 0.9972 - mean_squared_error: 2.1832 - val_loss: 2.0996 - val_mean_absolute_error: 0.9839 - val_mean_squared_error: 2.0996\n",
            "Epoch 265/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.1860 - mean_absolute_error: 0.9981 - mean_squared_error: 2.1860\n",
            "Epoch 265: val_loss did not improve from 2.09961\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1825 - mean_absolute_error: 0.9978 - mean_squared_error: 2.1825 - val_loss: 2.1016 - val_mean_absolute_error: 0.9805 - val_mean_squared_error: 2.1016\n",
            "Epoch 266/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.1826 - mean_absolute_error: 0.9962 - mean_squared_error: 2.1826\n",
            "Epoch 266: val_loss improved from 2.09961 to 2.09318, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1791 - mean_absolute_error: 0.9946 - mean_squared_error: 2.1791 - val_loss: 2.0932 - val_mean_absolute_error: 0.9795 - val_mean_squared_error: 2.0932\n",
            "Epoch 267/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.1795 - mean_absolute_error: 0.9944 - mean_squared_error: 2.1795\n",
            "Epoch 267: val_loss improved from 2.09318 to 2.09215, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1770 - mean_absolute_error: 0.9942 - mean_squared_error: 2.1770 - val_loss: 2.0922 - val_mean_absolute_error: 0.9849 - val_mean_squared_error: 2.0922\n",
            "Epoch 268/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.1848 - mean_absolute_error: 0.9977 - mean_squared_error: 2.1848\n",
            "Epoch 268: val_loss did not improve from 2.09215\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1772 - mean_absolute_error: 0.9969 - mean_squared_error: 2.1772 - val_loss: 2.0946 - val_mean_absolute_error: 0.9856 - val_mean_squared_error: 2.0946\n",
            "Epoch 269/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.1747 - mean_absolute_error: 0.9932 - mean_squared_error: 2.1747\n",
            "Epoch 269: val_loss improved from 2.09215 to 2.09193, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1782 - mean_absolute_error: 0.9936 - mean_squared_error: 2.1782 - val_loss: 2.0919 - val_mean_absolute_error: 0.9742 - val_mean_squared_error: 2.0919\n",
            "Epoch 270/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.1729 - mean_absolute_error: 0.9928 - mean_squared_error: 2.1729\n",
            "Epoch 270: val_loss did not improve from 2.09193\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.1729 - mean_absolute_error: 0.9928 - mean_squared_error: 2.1729 - val_loss: 2.0982 - val_mean_absolute_error: 0.9814 - val_mean_squared_error: 2.0982\n",
            "Epoch 271/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.1553 - mean_absolute_error: 0.9888 - mean_squared_error: 2.1553\n",
            "Epoch 271: val_loss improved from 2.09193 to 2.08510, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.1717 - mean_absolute_error: 0.9934 - mean_squared_error: 2.1717 - val_loss: 2.0851 - val_mean_absolute_error: 0.9753 - val_mean_squared_error: 2.0851\n",
            "Epoch 272/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.1769 - mean_absolute_error: 0.9926 - mean_squared_error: 2.1769\n",
            "Epoch 272: val_loss improved from 2.08510 to 2.08380, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.1708 - mean_absolute_error: 0.9910 - mean_squared_error: 2.1708 - val_loss: 2.0838 - val_mean_absolute_error: 0.9773 - val_mean_squared_error: 2.0838\n",
            "Epoch 273/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.1588 - mean_absolute_error: 0.9919 - mean_squared_error: 2.1588\n",
            "Epoch 273: val_loss did not improve from 2.08380\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1681 - mean_absolute_error: 0.9935 - mean_squared_error: 2.1681 - val_loss: 2.0947 - val_mean_absolute_error: 0.9776 - val_mean_squared_error: 2.0947\n",
            "Epoch 274/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.1819 - mean_absolute_error: 0.9926 - mean_squared_error: 2.1819\n",
            "Epoch 274: val_loss improved from 2.08380 to 2.07968, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1692 - mean_absolute_error: 0.9901 - mean_squared_error: 2.1692 - val_loss: 2.0797 - val_mean_absolute_error: 0.9742 - val_mean_squared_error: 2.0797\n",
            "Epoch 275/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.1549 - mean_absolute_error: 0.9882 - mean_squared_error: 2.1549\n",
            "Epoch 275: val_loss improved from 2.07968 to 2.07946, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1661 - mean_absolute_error: 0.9887 - mean_squared_error: 2.1661 - val_loss: 2.0795 - val_mean_absolute_error: 0.9759 - val_mean_squared_error: 2.0795\n",
            "Epoch 276/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.1898 - mean_absolute_error: 0.9953 - mean_squared_error: 2.1898\n",
            "Epoch 276: val_loss did not improve from 2.07946\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1654 - mean_absolute_error: 0.9908 - mean_squared_error: 2.1654 - val_loss: 2.0816 - val_mean_absolute_error: 0.9668 - val_mean_squared_error: 2.0816\n",
            "Epoch 277/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.1681 - mean_absolute_error: 0.9882 - mean_squared_error: 2.1681\n",
            "Epoch 277: val_loss did not improve from 2.07946\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1654 - mean_absolute_error: 0.9884 - mean_squared_error: 2.1654 - val_loss: 2.0803 - val_mean_absolute_error: 0.9747 - val_mean_squared_error: 2.0803\n",
            "Epoch 278/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.1646 - mean_absolute_error: 0.9875 - mean_squared_error: 2.1646\n",
            "Epoch 278: val_loss did not improve from 2.07946\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1606 - mean_absolute_error: 0.9862 - mean_squared_error: 2.1606 - val_loss: 2.0893 - val_mean_absolute_error: 0.9733 - val_mean_squared_error: 2.0893\n",
            "Epoch 279/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.1541 - mean_absolute_error: 0.9865 - mean_squared_error: 2.1541\n",
            "Epoch 279: val_loss improved from 2.07946 to 2.07411, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1606 - mean_absolute_error: 0.9861 - mean_squared_error: 2.1606 - val_loss: 2.0741 - val_mean_absolute_error: 0.9684 - val_mean_squared_error: 2.0741\n",
            "Epoch 280/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.1717 - mean_absolute_error: 0.9923 - mean_squared_error: 2.1717\n",
            "Epoch 280: val_loss improved from 2.07411 to 2.07085, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1635 - mean_absolute_error: 0.9898 - mean_squared_error: 2.1635 - val_loss: 2.0708 - val_mean_absolute_error: 0.9674 - val_mean_squared_error: 2.0708\n",
            "Epoch 281/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.1594 - mean_absolute_error: 0.9891 - mean_squared_error: 2.1594\n",
            "Epoch 281: val_loss did not improve from 2.07085\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1596 - mean_absolute_error: 0.9878 - mean_squared_error: 2.1596 - val_loss: 2.0716 - val_mean_absolute_error: 0.9663 - val_mean_squared_error: 2.0716\n",
            "Epoch 282/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.1468 - mean_absolute_error: 0.9825 - mean_squared_error: 2.1468\n",
            "Epoch 282: val_loss did not improve from 2.07085\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1599 - mean_absolute_error: 0.9843 - mean_squared_error: 2.1599 - val_loss: 2.0819 - val_mean_absolute_error: 0.9764 - val_mean_squared_error: 2.0819\n",
            "Epoch 283/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.1757 - mean_absolute_error: 0.9905 - mean_squared_error: 2.1757\n",
            "Epoch 283: val_loss improved from 2.07085 to 2.06943, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1547 - mean_absolute_error: 0.9864 - mean_squared_error: 2.1547 - val_loss: 2.0694 - val_mean_absolute_error: 0.9740 - val_mean_squared_error: 2.0694\n",
            "Epoch 284/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.1578 - mean_absolute_error: 0.9869 - mean_squared_error: 2.1578\n",
            "Epoch 284: val_loss improved from 2.06943 to 2.06643, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1572 - mean_absolute_error: 0.9861 - mean_squared_error: 2.1572 - val_loss: 2.0664 - val_mean_absolute_error: 0.9735 - val_mean_squared_error: 2.0664\n",
            "Epoch 285/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.1320 - mean_absolute_error: 0.9763 - mean_squared_error: 2.1320\n",
            "Epoch 285: val_loss improved from 2.06643 to 2.06430, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1537 - mean_absolute_error: 0.9812 - mean_squared_error: 2.1537 - val_loss: 2.0643 - val_mean_absolute_error: 0.9720 - val_mean_squared_error: 2.0643\n",
            "Epoch 286/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.1580 - mean_absolute_error: 0.9857 - mean_squared_error: 2.1580\n",
            "Epoch 286: val_loss did not improve from 2.06430\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1501 - mean_absolute_error: 0.9844 - mean_squared_error: 2.1501 - val_loss: 2.0672 - val_mean_absolute_error: 0.9816 - val_mean_squared_error: 2.0672\n",
            "Epoch 287/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.1429 - mean_absolute_error: 0.9832 - mean_squared_error: 2.1429\n",
            "Epoch 287: val_loss did not improve from 2.06430\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1503 - mean_absolute_error: 0.9845 - mean_squared_error: 2.1503 - val_loss: 2.0662 - val_mean_absolute_error: 0.9691 - val_mean_squared_error: 2.0662\n",
            "Epoch 288/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.1561 - mean_absolute_error: 0.9848 - mean_squared_error: 2.1561\n",
            "Epoch 288: val_loss did not improve from 2.06430\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1491 - mean_absolute_error: 0.9832 - mean_squared_error: 2.1491 - val_loss: 2.0697 - val_mean_absolute_error: 0.9657 - val_mean_squared_error: 2.0697\n",
            "Epoch 289/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.1509 - mean_absolute_error: 0.9836 - mean_squared_error: 2.1509\n",
            "Epoch 289: val_loss did not improve from 2.06430\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1509 - mean_absolute_error: 0.9836 - mean_squared_error: 2.1509 - val_loss: 2.0710 - val_mean_absolute_error: 0.9830 - val_mean_squared_error: 2.0710\n",
            "Epoch 290/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.1409 - mean_absolute_error: 0.9801 - mean_squared_error: 2.1409\n",
            "Epoch 290: val_loss did not improve from 2.06430\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1466 - mean_absolute_error: 0.9812 - mean_squared_error: 2.1466 - val_loss: 2.0673 - val_mean_absolute_error: 0.9721 - val_mean_squared_error: 2.0673\n",
            "Epoch 291/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.1302 - mean_absolute_error: 0.9774 - mean_squared_error: 2.1302\n",
            "Epoch 291: val_loss improved from 2.06430 to 2.05737, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1467 - mean_absolute_error: 0.9811 - mean_squared_error: 2.1467 - val_loss: 2.0574 - val_mean_absolute_error: 0.9629 - val_mean_squared_error: 2.0574\n",
            "Epoch 292/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.1499 - mean_absolute_error: 0.9812 - mean_squared_error: 2.1499\n",
            "Epoch 292: val_loss improved from 2.05737 to 2.05456, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1456 - mean_absolute_error: 0.9821 - mean_squared_error: 2.1456 - val_loss: 2.0546 - val_mean_absolute_error: 0.9668 - val_mean_squared_error: 2.0546\n",
            "Epoch 293/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.1580 - mean_absolute_error: 0.9861 - mean_squared_error: 2.1580\n",
            "Epoch 293: val_loss did not improve from 2.05456\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1460 - mean_absolute_error: 0.9837 - mean_squared_error: 2.1460 - val_loss: 2.0586 - val_mean_absolute_error: 0.9660 - val_mean_squared_error: 2.0586\n",
            "Epoch 294/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.1461 - mean_absolute_error: 0.9802 - mean_squared_error: 2.1461\n",
            "Epoch 294: val_loss did not improve from 2.05456\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1427 - mean_absolute_error: 0.9811 - mean_squared_error: 2.1427 - val_loss: 2.0574 - val_mean_absolute_error: 0.9653 - val_mean_squared_error: 2.0574\n",
            "Epoch 295/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.1576 - mean_absolute_error: 0.9832 - mean_squared_error: 2.1576\n",
            "Epoch 295: val_loss improved from 2.05456 to 2.05419, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1431 - mean_absolute_error: 0.9803 - mean_squared_error: 2.1431 - val_loss: 2.0542 - val_mean_absolute_error: 0.9616 - val_mean_squared_error: 2.0542\n",
            "Epoch 296/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.1147 - mean_absolute_error: 0.9728 - mean_squared_error: 2.1147\n",
            "Epoch 296: val_loss did not improve from 2.05419\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1412 - mean_absolute_error: 0.9786 - mean_squared_error: 2.1412 - val_loss: 2.0555 - val_mean_absolute_error: 0.9580 - val_mean_squared_error: 2.0555\n",
            "Epoch 297/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.1699 - mean_absolute_error: 0.9906 - mean_squared_error: 2.1699\n",
            "Epoch 297: val_loss improved from 2.05419 to 2.05113, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1412 - mean_absolute_error: 0.9834 - mean_squared_error: 2.1412 - val_loss: 2.0511 - val_mean_absolute_error: 0.9587 - val_mean_squared_error: 2.0511\n",
            "Epoch 298/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.1221 - mean_absolute_error: 0.9769 - mean_squared_error: 2.1221\n",
            "Epoch 298: val_loss did not improve from 2.05113\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1325 - mean_absolute_error: 0.9791 - mean_squared_error: 2.1325 - val_loss: 2.0587 - val_mean_absolute_error: 0.9752 - val_mean_squared_error: 2.0587\n",
            "Epoch 299/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.1721 - mean_absolute_error: 0.9915 - mean_squared_error: 2.1721\n",
            "Epoch 299: val_loss improved from 2.05113 to 2.04363, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1416 - mean_absolute_error: 0.9830 - mean_squared_error: 2.1416 - val_loss: 2.0436 - val_mean_absolute_error: 0.9594 - val_mean_squared_error: 2.0436\n",
            "Epoch 300/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.1381 - mean_absolute_error: 0.9749 - mean_squared_error: 2.1381\n",
            "Epoch 300: val_loss did not improve from 2.04363\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1379 - mean_absolute_error: 0.9756 - mean_squared_error: 2.1379 - val_loss: 2.0544 - val_mean_absolute_error: 0.9751 - val_mean_squared_error: 2.0544\n",
            "Epoch 301/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.1363 - mean_absolute_error: 0.9802 - mean_squared_error: 2.1363\n",
            "Epoch 301: val_loss improved from 2.04363 to 2.04264, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1355 - mean_absolute_error: 0.9787 - mean_squared_error: 2.1355 - val_loss: 2.0426 - val_mean_absolute_error: 0.9621 - val_mean_squared_error: 2.0426\n",
            "Epoch 302/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.0978 - mean_absolute_error: 0.9724 - mean_squared_error: 2.0978\n",
            "Epoch 302: val_loss did not improve from 2.04264\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1325 - mean_absolute_error: 0.9786 - mean_squared_error: 2.1325 - val_loss: 2.0467 - val_mean_absolute_error: 0.9558 - val_mean_squared_error: 2.0467\n",
            "Epoch 303/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.1369 - mean_absolute_error: 0.9761 - mean_squared_error: 2.1369\n",
            "Epoch 303: val_loss did not improve from 2.04264\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1360 - mean_absolute_error: 0.9787 - mean_squared_error: 2.1360 - val_loss: 2.0488 - val_mean_absolute_error: 0.9750 - val_mean_squared_error: 2.0488\n",
            "Epoch 304/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.1331 - mean_absolute_error: 0.9793 - mean_squared_error: 2.1331\n",
            "Epoch 304: val_loss improved from 2.04264 to 2.04130, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1331 - mean_absolute_error: 0.9793 - mean_squared_error: 2.1331 - val_loss: 2.0413 - val_mean_absolute_error: 0.9637 - val_mean_squared_error: 2.0413\n",
            "Epoch 305/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.1593 - mean_absolute_error: 0.9864 - mean_squared_error: 2.1593\n",
            "Epoch 305: val_loss improved from 2.04130 to 2.04124, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1352 - mean_absolute_error: 0.9797 - mean_squared_error: 2.1352 - val_loss: 2.0412 - val_mean_absolute_error: 0.9549 - val_mean_squared_error: 2.0412\n",
            "Epoch 306/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.1356 - mean_absolute_error: 0.9797 - mean_squared_error: 2.1356\n",
            "Epoch 306: val_loss improved from 2.04124 to 2.04033, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1322 - mean_absolute_error: 0.9766 - mean_squared_error: 2.1322 - val_loss: 2.0403 - val_mean_absolute_error: 0.9554 - val_mean_squared_error: 2.0403\n",
            "Epoch 307/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.1307 - mean_absolute_error: 0.9755 - mean_squared_error: 2.1307\n",
            "Epoch 307: val_loss improved from 2.04033 to 2.03384, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1294 - mean_absolute_error: 0.9751 - mean_squared_error: 2.1294 - val_loss: 2.0338 - val_mean_absolute_error: 0.9594 - val_mean_squared_error: 2.0338\n",
            "Epoch 308/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.1273 - mean_absolute_error: 0.9724 - mean_squared_error: 2.1273\n",
            "Epoch 308: val_loss did not improve from 2.03384\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1309 - mean_absolute_error: 0.9743 - mean_squared_error: 2.1309 - val_loss: 2.0353 - val_mean_absolute_error: 0.9554 - val_mean_squared_error: 2.0353\n",
            "Epoch 309/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.1270 - mean_absolute_error: 0.9758 - mean_squared_error: 2.1270\n",
            "Epoch 309: val_loss did not improve from 2.03384\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1267 - mean_absolute_error: 0.9769 - mean_squared_error: 2.1267 - val_loss: 2.0399 - val_mean_absolute_error: 0.9622 - val_mean_squared_error: 2.0399\n",
            "Epoch 310/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.1275 - mean_absolute_error: 0.9750 - mean_squared_error: 2.1275\n",
            "Epoch 310: val_loss improved from 2.03384 to 2.03135, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1275 - mean_absolute_error: 0.9750 - mean_squared_error: 2.1275 - val_loss: 2.0314 - val_mean_absolute_error: 0.9599 - val_mean_squared_error: 2.0314\n",
            "Epoch 311/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.1183 - mean_absolute_error: 0.9741 - mean_squared_error: 2.1183\n",
            "Epoch 311: val_loss did not improve from 2.03135\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1263 - mean_absolute_error: 0.9769 - mean_squared_error: 2.1263 - val_loss: 2.0407 - val_mean_absolute_error: 0.9599 - val_mean_squared_error: 2.0407\n",
            "Epoch 312/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.1525 - mean_absolute_error: 0.9804 - mean_squared_error: 2.1525\n",
            "Epoch 312: val_loss improved from 2.03135 to 2.02823, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1295 - mean_absolute_error: 0.9766 - mean_squared_error: 2.1295 - val_loss: 2.0282 - val_mean_absolute_error: 0.9619 - val_mean_squared_error: 2.0282\n",
            "Epoch 313/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.1318 - mean_absolute_error: 0.9756 - mean_squared_error: 2.1318\n",
            "Epoch 313: val_loss improved from 2.02823 to 2.02741, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1283 - mean_absolute_error: 0.9746 - mean_squared_error: 2.1283 - val_loss: 2.0274 - val_mean_absolute_error: 0.9567 - val_mean_squared_error: 2.0274\n",
            "Epoch 314/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.1475 - mean_absolute_error: 0.9804 - mean_squared_error: 2.1475\n",
            "Epoch 314: val_loss did not improve from 2.02741\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1252 - mean_absolute_error: 0.9751 - mean_squared_error: 2.1252 - val_loss: 2.0304 - val_mean_absolute_error: 0.9619 - val_mean_squared_error: 2.0304\n",
            "Epoch 315/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.1138 - mean_absolute_error: 0.9711 - mean_squared_error: 2.1138\n",
            "Epoch 315: val_loss did not improve from 2.02741\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1230 - mean_absolute_error: 0.9750 - mean_squared_error: 2.1230 - val_loss: 2.0277 - val_mean_absolute_error: 0.9553 - val_mean_squared_error: 2.0277\n",
            "Epoch 316/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.1349 - mean_absolute_error: 0.9784 - mean_squared_error: 2.1349\n",
            "Epoch 316: val_loss did not improve from 2.02741\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1201 - mean_absolute_error: 0.9750 - mean_squared_error: 2.1201 - val_loss: 2.0319 - val_mean_absolute_error: 0.9504 - val_mean_squared_error: 2.0319\n",
            "Epoch 317/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.1012 - mean_absolute_error: 0.9722 - mean_squared_error: 2.1012\n",
            "Epoch 317: val_loss did not improve from 2.02741\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1215 - mean_absolute_error: 0.9761 - mean_squared_error: 2.1215 - val_loss: 2.0429 - val_mean_absolute_error: 0.9539 - val_mean_squared_error: 2.0429\n",
            "Epoch 318/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.1355 - mean_absolute_error: 0.9769 - mean_squared_error: 2.1355\n",
            "Epoch 318: val_loss improved from 2.02741 to 2.02642, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1188 - mean_absolute_error: 0.9738 - mean_squared_error: 2.1188 - val_loss: 2.0264 - val_mean_absolute_error: 0.9578 - val_mean_squared_error: 2.0264\n",
            "Epoch 319/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.1078 - mean_absolute_error: 0.9710 - mean_squared_error: 2.1078\n",
            "Epoch 319: val_loss did not improve from 2.02642\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1185 - mean_absolute_error: 0.9752 - mean_squared_error: 2.1185 - val_loss: 2.0367 - val_mean_absolute_error: 0.9750 - val_mean_squared_error: 2.0367\n",
            "Epoch 320/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.1137 - mean_absolute_error: 0.9751 - mean_squared_error: 2.1137\n",
            "Epoch 320: val_loss improved from 2.02642 to 2.02039, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1170 - mean_absolute_error: 0.9745 - mean_squared_error: 2.1170 - val_loss: 2.0204 - val_mean_absolute_error: 0.9610 - val_mean_squared_error: 2.0204\n",
            "Epoch 321/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.1128 - mean_absolute_error: 0.9736 - mean_squared_error: 2.1128\n",
            "Epoch 321: val_loss improved from 2.02039 to 2.01487, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1176 - mean_absolute_error: 0.9732 - mean_squared_error: 2.1176 - val_loss: 2.0149 - val_mean_absolute_error: 0.9539 - val_mean_squared_error: 2.0149\n",
            "Epoch 322/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.1162 - mean_absolute_error: 0.9734 - mean_squared_error: 2.1162\n",
            "Epoch 322: val_loss did not improve from 2.01487\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1157 - mean_absolute_error: 0.9712 - mean_squared_error: 2.1157 - val_loss: 2.0187 - val_mean_absolute_error: 0.9501 - val_mean_squared_error: 2.0187\n",
            "Epoch 323/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.1162 - mean_absolute_error: 0.9710 - mean_squared_error: 2.1162\n",
            "Epoch 323: val_loss improved from 2.01487 to 2.01279, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1145 - mean_absolute_error: 0.9734 - mean_squared_error: 2.1145 - val_loss: 2.0128 - val_mean_absolute_error: 0.9601 - val_mean_squared_error: 2.0128\n",
            "Epoch 324/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.0923 - mean_absolute_error: 0.9672 - mean_squared_error: 2.0923\n",
            "Epoch 324: val_loss improved from 2.01279 to 2.00990, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1154 - mean_absolute_error: 0.9722 - mean_squared_error: 2.1154 - val_loss: 2.0099 - val_mean_absolute_error: 0.9483 - val_mean_squared_error: 2.0099\n",
            "Epoch 325/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.1345 - mean_absolute_error: 0.9758 - mean_squared_error: 2.1345\n",
            "Epoch 325: val_loss did not improve from 2.00990\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1128 - mean_absolute_error: 0.9706 - mean_squared_error: 2.1128 - val_loss: 2.0100 - val_mean_absolute_error: 0.9555 - val_mean_squared_error: 2.0100\n",
            "Epoch 326/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.1153 - mean_absolute_error: 0.9755 - mean_squared_error: 2.1153\n",
            "Epoch 326: val_loss did not improve from 2.00990\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1127 - mean_absolute_error: 0.9748 - mean_squared_error: 2.1127 - val_loss: 2.0126 - val_mean_absolute_error: 0.9487 - val_mean_squared_error: 2.0126\n",
            "Epoch 327/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.1117 - mean_absolute_error: 0.9696 - mean_squared_error: 2.1117\n",
            "Epoch 327: val_loss improved from 2.00990 to 2.00639, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1106 - mean_absolute_error: 0.9698 - mean_squared_error: 2.1106 - val_loss: 2.0064 - val_mean_absolute_error: 0.9528 - val_mean_squared_error: 2.0064\n",
            "Epoch 328/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.1172 - mean_absolute_error: 0.9768 - mean_squared_error: 2.1172\n",
            "Epoch 328: val_loss improved from 2.00639 to 2.00396, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1082 - mean_absolute_error: 0.9746 - mean_squared_error: 2.1082 - val_loss: 2.0040 - val_mean_absolute_error: 0.9534 - val_mean_squared_error: 2.0040\n",
            "Epoch 329/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.1172 - mean_absolute_error: 0.9739 - mean_squared_error: 2.1172\n",
            "Epoch 329: val_loss did not improve from 2.00396\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1088 - mean_absolute_error: 0.9709 - mean_squared_error: 2.1088 - val_loss: 2.0141 - val_mean_absolute_error: 0.9596 - val_mean_squared_error: 2.0141\n",
            "Epoch 330/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.1203 - mean_absolute_error: 0.9730 - mean_squared_error: 2.1203\n",
            "Epoch 330: val_loss did not improve from 2.00396\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1080 - mean_absolute_error: 0.9704 - mean_squared_error: 2.1080 - val_loss: 2.0062 - val_mean_absolute_error: 0.9482 - val_mean_squared_error: 2.0062\n",
            "Epoch 331/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.1020 - mean_absolute_error: 0.9682 - mean_squared_error: 2.1020\n",
            "Epoch 331: val_loss did not improve from 2.00396\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1078 - mean_absolute_error: 0.9695 - mean_squared_error: 2.1078 - val_loss: 2.0066 - val_mean_absolute_error: 0.9566 - val_mean_squared_error: 2.0066\n",
            "Epoch 332/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.0840 - mean_absolute_error: 0.9666 - mean_squared_error: 2.0840\n",
            "Epoch 332: val_loss improved from 2.00396 to 1.99905, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1055 - mean_absolute_error: 0.9708 - mean_squared_error: 2.1055 - val_loss: 1.9991 - val_mean_absolute_error: 0.9518 - val_mean_squared_error: 1.9991\n",
            "Epoch 333/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.1200 - mean_absolute_error: 0.9745 - mean_squared_error: 2.1200\n",
            "Epoch 333: val_loss improved from 1.99905 to 1.99868, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1021 - mean_absolute_error: 0.9728 - mean_squared_error: 2.1021 - val_loss: 1.9987 - val_mean_absolute_error: 0.9523 - val_mean_squared_error: 1.9987\n",
            "Epoch 334/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.1166 - mean_absolute_error: 0.9720 - mean_squared_error: 2.1166\n",
            "Epoch 334: val_loss did not improve from 1.99868\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1033 - mean_absolute_error: 0.9712 - mean_squared_error: 2.1033 - val_loss: 2.0007 - val_mean_absolute_error: 0.9615 - val_mean_squared_error: 2.0007\n",
            "Epoch 335/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.1059 - mean_absolute_error: 0.9700 - mean_squared_error: 2.1059\n",
            "Epoch 335: val_loss did not improve from 1.99868\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.1023 - mean_absolute_error: 0.9696 - mean_squared_error: 2.1023 - val_loss: 2.0068 - val_mean_absolute_error: 0.9465 - val_mean_squared_error: 2.0068\n",
            "Epoch 336/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.1139 - mean_absolute_error: 0.9713 - mean_squared_error: 2.1139\n",
            "Epoch 336: val_loss improved from 1.99868 to 1.99459, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.1030 - mean_absolute_error: 0.9688 - mean_squared_error: 2.1030 - val_loss: 1.9946 - val_mean_absolute_error: 0.9530 - val_mean_squared_error: 1.9946\n",
            "Epoch 337/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.0874 - mean_absolute_error: 0.9690 - mean_squared_error: 2.0874\n",
            "Epoch 337: val_loss improved from 1.99459 to 1.99234, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0997 - mean_absolute_error: 0.9694 - mean_squared_error: 2.0997 - val_loss: 1.9923 - val_mean_absolute_error: 0.9488 - val_mean_squared_error: 1.9923\n",
            "Epoch 338/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.1052 - mean_absolute_error: 0.9720 - mean_squared_error: 2.1052\n",
            "Epoch 338: val_loss did not improve from 1.99234\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0998 - mean_absolute_error: 0.9723 - mean_squared_error: 2.0998 - val_loss: 1.9977 - val_mean_absolute_error: 0.9536 - val_mean_squared_error: 1.9977\n",
            "Epoch 339/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.0859 - mean_absolute_error: 0.9669 - mean_squared_error: 2.0859\n",
            "Epoch 339: val_loss did not improve from 1.99234\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0940 - mean_absolute_error: 0.9692 - mean_squared_error: 2.0940 - val_loss: 2.0039 - val_mean_absolute_error: 0.9454 - val_mean_squared_error: 2.0039\n",
            "Epoch 340/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.1061 - mean_absolute_error: 0.9722 - mean_squared_error: 2.1061\n",
            "Epoch 340: val_loss improved from 1.99234 to 1.98784, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0984 - mean_absolute_error: 0.9705 - mean_squared_error: 2.0984 - val_loss: 1.9878 - val_mean_absolute_error: 0.9434 - val_mean_squared_error: 1.9878\n",
            "Epoch 341/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.1020 - mean_absolute_error: 0.9639 - mean_squared_error: 2.1020\n",
            "Epoch 341: val_loss did not improve from 1.98784\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0926 - mean_absolute_error: 0.9632 - mean_squared_error: 2.0926 - val_loss: 1.9905 - val_mean_absolute_error: 0.9518 - val_mean_squared_error: 1.9905\n",
            "Epoch 342/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.0981 - mean_absolute_error: 0.9714 - mean_squared_error: 2.0981\n",
            "Epoch 342: val_loss did not improve from 1.98784\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.0929 - mean_absolute_error: 0.9701 - mean_squared_error: 2.0929 - val_loss: 1.9903 - val_mean_absolute_error: 0.9502 - val_mean_squared_error: 1.9903\n",
            "Epoch 343/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.1144 - mean_absolute_error: 0.9780 - mean_squared_error: 2.1144\n",
            "Epoch 343: val_loss improved from 1.98784 to 1.98107, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.0959 - mean_absolute_error: 0.9728 - mean_squared_error: 2.0959 - val_loss: 1.9811 - val_mean_absolute_error: 0.9457 - val_mean_squared_error: 1.9811\n",
            "Epoch 344/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.0932 - mean_absolute_error: 0.9661 - mean_squared_error: 2.0932\n",
            "Epoch 344: val_loss improved from 1.98107 to 1.98001, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.0879 - mean_absolute_error: 0.9666 - mean_squared_error: 2.0879 - val_loss: 1.9800 - val_mean_absolute_error: 0.9521 - val_mean_squared_error: 1.9800\n",
            "Epoch 345/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.1031 - mean_absolute_error: 0.9710 - mean_squared_error: 2.1031\n",
            "Epoch 345: val_loss improved from 1.98001 to 1.97693, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0885 - mean_absolute_error: 0.9670 - mean_squared_error: 2.0885 - val_loss: 1.9769 - val_mean_absolute_error: 0.9446 - val_mean_squared_error: 1.9769\n",
            "Epoch 346/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.0822 - mean_absolute_error: 0.9661 - mean_squared_error: 2.0822\n",
            "Epoch 346: val_loss did not improve from 1.97693\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0887 - mean_absolute_error: 0.9665 - mean_squared_error: 2.0887 - val_loss: 1.9804 - val_mean_absolute_error: 0.9527 - val_mean_squared_error: 1.9804\n",
            "Epoch 347/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.0883 - mean_absolute_error: 0.9697 - mean_squared_error: 2.0883\n",
            "Epoch 347: val_loss improved from 1.97693 to 1.97349, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0916 - mean_absolute_error: 0.9696 - mean_squared_error: 2.0916 - val_loss: 1.9735 - val_mean_absolute_error: 0.9533 - val_mean_squared_error: 1.9735\n",
            "Epoch 348/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.0833 - mean_absolute_error: 0.9682 - mean_squared_error: 2.0833\n",
            "Epoch 348: val_loss did not improve from 1.97349\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0846 - mean_absolute_error: 0.9681 - mean_squared_error: 2.0846 - val_loss: 1.9808 - val_mean_absolute_error: 0.9449 - val_mean_squared_error: 1.9808\n",
            "Epoch 349/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.0925 - mean_absolute_error: 0.9729 - mean_squared_error: 2.0925\n",
            "Epoch 349: val_loss did not improve from 1.97349\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0840 - mean_absolute_error: 0.9680 - mean_squared_error: 2.0840 - val_loss: 1.9764 - val_mean_absolute_error: 0.9397 - val_mean_squared_error: 1.9764\n",
            "Epoch 350/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.0791 - mean_absolute_error: 0.9675 - mean_squared_error: 2.0791\n",
            "Epoch 350: val_loss improved from 1.97349 to 1.96994, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0859 - mean_absolute_error: 0.9688 - mean_squared_error: 2.0859 - val_loss: 1.9699 - val_mean_absolute_error: 0.9441 - val_mean_squared_error: 1.9699\n",
            "Epoch 351/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.0884 - mean_absolute_error: 0.9682 - mean_squared_error: 2.0884\n",
            "Epoch 351: val_loss improved from 1.96994 to 1.96453, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0823 - mean_absolute_error: 0.9659 - mean_squared_error: 2.0823 - val_loss: 1.9645 - val_mean_absolute_error: 0.9407 - val_mean_squared_error: 1.9645\n",
            "Epoch 352/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.0904 - mean_absolute_error: 0.9702 - mean_squared_error: 2.0904\n",
            "Epoch 352: val_loss did not improve from 1.96453\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0797 - mean_absolute_error: 0.9672 - mean_squared_error: 2.0797 - val_loss: 1.9737 - val_mean_absolute_error: 0.9423 - val_mean_squared_error: 1.9737\n",
            "Epoch 353/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.0949 - mean_absolute_error: 0.9691 - mean_squared_error: 2.0949\n",
            "Epoch 353: val_loss did not improve from 1.96453\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0819 - mean_absolute_error: 0.9660 - mean_squared_error: 2.0819 - val_loss: 1.9675 - val_mean_absolute_error: 0.9497 - val_mean_squared_error: 1.9675\n",
            "Epoch 354/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.0766 - mean_absolute_error: 0.9630 - mean_squared_error: 2.0766\n",
            "Epoch 354: val_loss improved from 1.96453 to 1.96335, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0855 - mean_absolute_error: 0.9637 - mean_squared_error: 2.0855 - val_loss: 1.9633 - val_mean_absolute_error: 0.9452 - val_mean_squared_error: 1.9633\n",
            "Epoch 355/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.0716 - mean_absolute_error: 0.9671 - mean_squared_error: 2.0716\n",
            "Epoch 355: val_loss improved from 1.96335 to 1.96007, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0782 - mean_absolute_error: 0.9665 - mean_squared_error: 2.0782 - val_loss: 1.9601 - val_mean_absolute_error: 0.9419 - val_mean_squared_error: 1.9601\n",
            "Epoch 356/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.0660 - mean_absolute_error: 0.9655 - mean_squared_error: 2.0660\n",
            "Epoch 356: val_loss did not improve from 1.96007\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0745 - mean_absolute_error: 0.9660 - mean_squared_error: 2.0745 - val_loss: 1.9676 - val_mean_absolute_error: 0.9466 - val_mean_squared_error: 1.9676\n",
            "Epoch 357/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.0840 - mean_absolute_error: 0.9667 - mean_squared_error: 2.0840\n",
            "Epoch 357: val_loss did not improve from 1.96007\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0738 - mean_absolute_error: 0.9647 - mean_squared_error: 2.0738 - val_loss: 1.9602 - val_mean_absolute_error: 0.9439 - val_mean_squared_error: 1.9602\n",
            "Epoch 358/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.0504 - mean_absolute_error: 0.9590 - mean_squared_error: 2.0504\n",
            "Epoch 358: val_loss improved from 1.96007 to 1.95768, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0730 - mean_absolute_error: 0.9630 - mean_squared_error: 2.0730 - val_loss: 1.9577 - val_mean_absolute_error: 0.9403 - val_mean_squared_error: 1.9577\n",
            "Epoch 359/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.0723 - mean_absolute_error: 0.9656 - mean_squared_error: 2.0723\n",
            "Epoch 359: val_loss improved from 1.95768 to 1.95234, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0714 - mean_absolute_error: 0.9659 - mean_squared_error: 2.0714 - val_loss: 1.9523 - val_mean_absolute_error: 0.9435 - val_mean_squared_error: 1.9523\n",
            "Epoch 360/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.0499 - mean_absolute_error: 0.9616 - mean_squared_error: 2.0499\n",
            "Epoch 360: val_loss improved from 1.95234 to 1.94784, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0675 - mean_absolute_error: 0.9641 - mean_squared_error: 2.0675 - val_loss: 1.9478 - val_mean_absolute_error: 0.9400 - val_mean_squared_error: 1.9478\n",
            "Epoch 361/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.0607 - mean_absolute_error: 0.9622 - mean_squared_error: 2.0607\n",
            "Epoch 361: val_loss improved from 1.94784 to 1.94746, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0687 - mean_absolute_error: 0.9643 - mean_squared_error: 2.0687 - val_loss: 1.9475 - val_mean_absolute_error: 0.9329 - val_mean_squared_error: 1.9475\n",
            "Epoch 362/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.0717 - mean_absolute_error: 0.9653 - mean_squared_error: 2.0717\n",
            "Epoch 362: val_loss improved from 1.94746 to 1.94428, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0679 - mean_absolute_error: 0.9654 - mean_squared_error: 2.0679 - val_loss: 1.9443 - val_mean_absolute_error: 0.9405 - val_mean_squared_error: 1.9443\n",
            "Epoch 363/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.0680 - mean_absolute_error: 0.9631 - mean_squared_error: 2.0680\n",
            "Epoch 363: val_loss improved from 1.94428 to 1.94270, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0651 - mean_absolute_error: 0.9629 - mean_squared_error: 2.0651 - val_loss: 1.9427 - val_mean_absolute_error: 0.9319 - val_mean_squared_error: 1.9427\n",
            "Epoch 364/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.0615 - mean_absolute_error: 0.9617 - mean_squared_error: 2.0615\n",
            "Epoch 364: val_loss did not improve from 1.94270\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0606 - mean_absolute_error: 0.9617 - mean_squared_error: 2.0606 - val_loss: 1.9458 - val_mean_absolute_error: 0.9456 - val_mean_squared_error: 1.9458\n",
            "Epoch 365/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.0694 - mean_absolute_error: 0.9636 - mean_squared_error: 2.0694\n",
            "Epoch 365: val_loss improved from 1.94270 to 1.93711, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0615 - mean_absolute_error: 0.9630 - mean_squared_error: 2.0615 - val_loss: 1.9371 - val_mean_absolute_error: 0.9420 - val_mean_squared_error: 1.9371\n",
            "Epoch 366/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.0658 - mean_absolute_error: 0.9621 - mean_squared_error: 2.0658\n",
            "Epoch 366: val_loss improved from 1.93711 to 1.93244, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0658 - mean_absolute_error: 0.9630 - mean_squared_error: 2.0658 - val_loss: 1.9324 - val_mean_absolute_error: 0.9397 - val_mean_squared_error: 1.9324\n",
            "Epoch 367/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.0617 - mean_absolute_error: 0.9629 - mean_squared_error: 2.0617\n",
            "Epoch 367: val_loss did not improve from 1.93244\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0609 - mean_absolute_error: 0.9614 - mean_squared_error: 2.0609 - val_loss: 1.9373 - val_mean_absolute_error: 0.9369 - val_mean_squared_error: 1.9373\n",
            "Epoch 368/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.0627 - mean_absolute_error: 0.9631 - mean_squared_error: 2.0627\n",
            "Epoch 368: val_loss did not improve from 1.93244\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0576 - mean_absolute_error: 0.9615 - mean_squared_error: 2.0576 - val_loss: 1.9326 - val_mean_absolute_error: 0.9350 - val_mean_squared_error: 1.9326\n",
            "Epoch 369/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.0718 - mean_absolute_error: 0.9665 - mean_squared_error: 2.0718\n",
            "Epoch 369: val_loss improved from 1.93244 to 1.92740, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0606 - mean_absolute_error: 0.9645 - mean_squared_error: 2.0606 - val_loss: 1.9274 - val_mean_absolute_error: 0.9335 - val_mean_squared_error: 1.9274\n",
            "Epoch 370/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.0534 - mean_absolute_error: 0.9636 - mean_squared_error: 2.0534\n",
            "Epoch 370: val_loss did not improve from 1.92740\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0523 - mean_absolute_error: 0.9628 - mean_squared_error: 2.0523 - val_loss: 1.9400 - val_mean_absolute_error: 0.9374 - val_mean_squared_error: 1.9400\n",
            "Epoch 371/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.0936 - mean_absolute_error: 0.9683 - mean_squared_error: 2.0936\n",
            "Epoch 371: val_loss did not improve from 1.92740\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0529 - mean_absolute_error: 0.9597 - mean_squared_error: 2.0529 - val_loss: 1.9404 - val_mean_absolute_error: 0.9371 - val_mean_squared_error: 1.9404\n",
            "Epoch 372/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.0610 - mean_absolute_error: 0.9624 - mean_squared_error: 2.0610\n",
            "Epoch 372: val_loss improved from 1.92740 to 1.91958, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0535 - mean_absolute_error: 0.9614 - mean_squared_error: 2.0535 - val_loss: 1.9196 - val_mean_absolute_error: 0.9305 - val_mean_squared_error: 1.9196\n",
            "Epoch 373/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.0241 - mean_absolute_error: 0.9512 - mean_squared_error: 2.0241\n",
            "Epoch 373: val_loss did not improve from 1.91958\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0499 - mean_absolute_error: 0.9580 - mean_squared_error: 2.0499 - val_loss: 1.9283 - val_mean_absolute_error: 0.9324 - val_mean_squared_error: 1.9283\n",
            "Epoch 374/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.0563 - mean_absolute_error: 0.9585 - mean_squared_error: 2.0563\n",
            "Epoch 374: val_loss improved from 1.91958 to 1.91533, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0472 - mean_absolute_error: 0.9577 - mean_squared_error: 2.0472 - val_loss: 1.9153 - val_mean_absolute_error: 0.9379 - val_mean_squared_error: 1.9153\n",
            "Epoch 375/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.0568 - mean_absolute_error: 0.9621 - mean_squared_error: 2.0568\n",
            "Epoch 375: val_loss improved from 1.91533 to 1.91390, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0463 - mean_absolute_error: 0.9608 - mean_squared_error: 2.0463 - val_loss: 1.9139 - val_mean_absolute_error: 0.9329 - val_mean_squared_error: 1.9139\n",
            "Epoch 376/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.0432 - mean_absolute_error: 0.9595 - mean_squared_error: 2.0432\n",
            "Epoch 376: val_loss did not improve from 1.91390\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0456 - mean_absolute_error: 0.9588 - mean_squared_error: 2.0456 - val_loss: 1.9204 - val_mean_absolute_error: 0.9429 - val_mean_squared_error: 1.9204\n",
            "Epoch 377/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.0267 - mean_absolute_error: 0.9522 - mean_squared_error: 2.0267\n",
            "Epoch 377: val_loss improved from 1.91390 to 1.91043, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0393 - mean_absolute_error: 0.9572 - mean_squared_error: 2.0393 - val_loss: 1.9104 - val_mean_absolute_error: 0.9302 - val_mean_squared_error: 1.9104\n",
            "Epoch 378/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.0372 - mean_absolute_error: 0.9582 - mean_squared_error: 2.0372\n",
            "Epoch 378: val_loss improved from 1.91043 to 1.90864, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0372 - mean_absolute_error: 0.9582 - mean_squared_error: 2.0372 - val_loss: 1.9086 - val_mean_absolute_error: 0.9325 - val_mean_squared_error: 1.9086\n",
            "Epoch 379/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.0526 - mean_absolute_error: 0.9608 - mean_squared_error: 2.0526\n",
            "Epoch 379: val_loss improved from 1.90864 to 1.90397, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0388 - mean_absolute_error: 0.9576 - mean_squared_error: 2.0388 - val_loss: 1.9040 - val_mean_absolute_error: 0.9255 - val_mean_squared_error: 1.9040\n",
            "Epoch 380/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.0507 - mean_absolute_error: 0.9639 - mean_squared_error: 2.0507\n",
            "Epoch 380: val_loss did not improve from 1.90397\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0348 - mean_absolute_error: 0.9587 - mean_squared_error: 2.0348 - val_loss: 1.9053 - val_mean_absolute_error: 0.9263 - val_mean_squared_error: 1.9053\n",
            "Epoch 381/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.0322 - mean_absolute_error: 0.9558 - mean_squared_error: 2.0322\n",
            "Epoch 381: val_loss improved from 1.90397 to 1.89704, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0319 - mean_absolute_error: 0.9556 - mean_squared_error: 2.0319 - val_loss: 1.8970 - val_mean_absolute_error: 0.9247 - val_mean_squared_error: 1.8970\n",
            "Epoch 382/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.0434 - mean_absolute_error: 0.9585 - mean_squared_error: 2.0434\n",
            "Epoch 382: val_loss improved from 1.89704 to 1.89484, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0332 - mean_absolute_error: 0.9565 - mean_squared_error: 2.0332 - val_loss: 1.8948 - val_mean_absolute_error: 0.9264 - val_mean_squared_error: 1.8948\n",
            "Epoch 383/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.0181 - mean_absolute_error: 0.9548 - mean_squared_error: 2.0181\n",
            "Epoch 383: val_loss improved from 1.89484 to 1.89388, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.0249 - mean_absolute_error: 0.9556 - mean_squared_error: 2.0249 - val_loss: 1.8939 - val_mean_absolute_error: 0.9299 - val_mean_squared_error: 1.8939\n",
            "Epoch 384/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.0229 - mean_absolute_error: 0.9580 - mean_squared_error: 2.0229\n",
            "Epoch 384: val_loss improved from 1.89388 to 1.89177, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0274 - mean_absolute_error: 0.9582 - mean_squared_error: 2.0274 - val_loss: 1.8918 - val_mean_absolute_error: 0.9247 - val_mean_squared_error: 1.8918\n",
            "Epoch 385/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.0331 - mean_absolute_error: 0.9550 - mean_squared_error: 2.0331\n",
            "Epoch 385: val_loss improved from 1.89177 to 1.88885, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0251 - mean_absolute_error: 0.9522 - mean_squared_error: 2.0251 - val_loss: 1.8889 - val_mean_absolute_error: 0.9278 - val_mean_squared_error: 1.8889\n",
            "Epoch 386/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.0052 - mean_absolute_error: 0.9474 - mean_squared_error: 2.0052\n",
            "Epoch 386: val_loss improved from 1.88885 to 1.88752, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0235 - mean_absolute_error: 0.9534 - mean_squared_error: 2.0235 - val_loss: 1.8875 - val_mean_absolute_error: 0.9224 - val_mean_squared_error: 1.8875\n",
            "Epoch 387/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.0052 - mean_absolute_error: 0.9522 - mean_squared_error: 2.0052\n",
            "Epoch 387: val_loss did not improve from 1.88752\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0188 - mean_absolute_error: 0.9548 - mean_squared_error: 2.0188 - val_loss: 1.9073 - val_mean_absolute_error: 0.9281 - val_mean_squared_error: 1.9073\n",
            "Epoch 388/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.0255 - mean_absolute_error: 0.9594 - mean_squared_error: 2.0255\n",
            "Epoch 388: val_loss improved from 1.88752 to 1.88622, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0201 - mean_absolute_error: 0.9574 - mean_squared_error: 2.0201 - val_loss: 1.8862 - val_mean_absolute_error: 0.9329 - val_mean_squared_error: 1.8862\n",
            "Epoch 389/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.0142 - mean_absolute_error: 0.9484 - mean_squared_error: 2.0142\n",
            "Epoch 389: val_loss improved from 1.88622 to 1.87632, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0162 - mean_absolute_error: 0.9504 - mean_squared_error: 2.0162 - val_loss: 1.8763 - val_mean_absolute_error: 0.9215 - val_mean_squared_error: 1.8763\n",
            "Epoch 390/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.9938 - mean_absolute_error: 0.9471 - mean_squared_error: 1.9938\n",
            "Epoch 390: val_loss did not improve from 1.87632\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0104 - mean_absolute_error: 0.9517 - mean_squared_error: 2.0104 - val_loss: 1.8810 - val_mean_absolute_error: 0.9284 - val_mean_squared_error: 1.8810\n",
            "Epoch 391/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.0077 - mean_absolute_error: 0.9533 - mean_squared_error: 2.0077\n",
            "Epoch 391: val_loss improved from 1.87632 to 1.87005, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0114 - mean_absolute_error: 0.9546 - mean_squared_error: 2.0114 - val_loss: 1.8700 - val_mean_absolute_error: 0.9241 - val_mean_squared_error: 1.8700\n",
            "Epoch 392/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.0140 - mean_absolute_error: 0.9515 - mean_squared_error: 2.0140\n",
            "Epoch 392: val_loss improved from 1.87005 to 1.86290, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0073 - mean_absolute_error: 0.9499 - mean_squared_error: 2.0073 - val_loss: 1.8629 - val_mean_absolute_error: 0.9245 - val_mean_squared_error: 1.8629\n",
            "Epoch 393/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.0217 - mean_absolute_error: 0.9562 - mean_squared_error: 2.0217\n",
            "Epoch 393: val_loss improved from 1.86290 to 1.85949, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.0042 - mean_absolute_error: 0.9518 - mean_squared_error: 2.0042 - val_loss: 1.8595 - val_mean_absolute_error: 0.9179 - val_mean_squared_error: 1.8595\n",
            "Epoch 394/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.0067 - mean_absolute_error: 0.9518 - mean_squared_error: 2.0067\n",
            "Epoch 394: val_loss did not improve from 1.85949\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.0002 - mean_absolute_error: 0.9499 - mean_squared_error: 2.0002 - val_loss: 1.8662 - val_mean_absolute_error: 0.9306 - val_mean_squared_error: 1.8662\n",
            "Epoch 395/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.9775 - mean_absolute_error: 0.9452 - mean_squared_error: 1.9775\n",
            "Epoch 395: val_loss did not improve from 1.85949\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.9947 - mean_absolute_error: 0.9471 - mean_squared_error: 1.9947 - val_loss: 1.8597 - val_mean_absolute_error: 0.9188 - val_mean_squared_error: 1.8597\n",
            "Epoch 396/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.9991 - mean_absolute_error: 0.9495 - mean_squared_error: 1.9991\n",
            "Epoch 396: val_loss improved from 1.85949 to 1.85517, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.9970 - mean_absolute_error: 0.9487 - mean_squared_error: 1.9970 - val_loss: 1.8552 - val_mean_absolute_error: 0.9289 - val_mean_squared_error: 1.8552\n",
            "Epoch 397/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.9990 - mean_absolute_error: 0.9485 - mean_squared_error: 1.9990\n",
            "Epoch 397: val_loss improved from 1.85517 to 1.85142, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.9897 - mean_absolute_error: 0.9464 - mean_squared_error: 1.9897 - val_loss: 1.8514 - val_mean_absolute_error: 0.9177 - val_mean_squared_error: 1.8514\n",
            "Epoch 398/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.9876 - mean_absolute_error: 0.9445 - mean_squared_error: 1.9876\n",
            "Epoch 398: val_loss improved from 1.85142 to 1.83997, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9863 - mean_absolute_error: 0.9440 - mean_squared_error: 1.9863 - val_loss: 1.8400 - val_mean_absolute_error: 0.9200 - val_mean_squared_error: 1.8400\n",
            "Epoch 399/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.9565 - mean_absolute_error: 0.9411 - mean_squared_error: 1.9565\n",
            "Epoch 399: val_loss improved from 1.83997 to 1.83487, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.9822 - mean_absolute_error: 0.9471 - mean_squared_error: 1.9822 - val_loss: 1.8349 - val_mean_absolute_error: 0.9101 - val_mean_squared_error: 1.8349\n",
            "Epoch 400/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.9898 - mean_absolute_error: 0.9451 - mean_squared_error: 1.9898\n",
            "Epoch 400: val_loss did not improve from 1.83487\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.9746 - mean_absolute_error: 0.9423 - mean_squared_error: 1.9746 - val_loss: 1.8426 - val_mean_absolute_error: 0.9289 - val_mean_squared_error: 1.8426\n",
            "Epoch 401/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.9585 - mean_absolute_error: 0.9390 - mean_squared_error: 1.9585\n",
            "Epoch 401: val_loss improved from 1.83487 to 1.82128, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.9724 - mean_absolute_error: 0.9419 - mean_squared_error: 1.9724 - val_loss: 1.8213 - val_mean_absolute_error: 0.9113 - val_mean_squared_error: 1.8213\n",
            "Epoch 402/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.9567 - mean_absolute_error: 0.9394 - mean_squared_error: 1.9567\n",
            "Epoch 402: val_loss did not improve from 1.82128\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9598 - mean_absolute_error: 0.9388 - mean_squared_error: 1.9598 - val_loss: 1.8351 - val_mean_absolute_error: 0.9240 - val_mean_squared_error: 1.8351\n",
            "Epoch 403/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.9193 - mean_absolute_error: 0.9336 - mean_squared_error: 1.9193\n",
            "Epoch 403: val_loss improved from 1.82128 to 1.80310, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.9564 - mean_absolute_error: 0.9409 - mean_squared_error: 1.9564 - val_loss: 1.8031 - val_mean_absolute_error: 0.9039 - val_mean_squared_error: 1.8031\n",
            "Epoch 404/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.9635 - mean_absolute_error: 0.9387 - mean_squared_error: 1.9635\n",
            "Epoch 404: val_loss improved from 1.80310 to 1.78923, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.9460 - mean_absolute_error: 0.9350 - mean_squared_error: 1.9460 - val_loss: 1.7892 - val_mean_absolute_error: 0.9031 - val_mean_squared_error: 1.7892\n",
            "Epoch 405/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.9297 - mean_absolute_error: 0.9323 - mean_squared_error: 1.9297\n",
            "Epoch 405: val_loss improved from 1.78923 to 1.78433, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.9322 - mean_absolute_error: 0.9333 - mean_squared_error: 1.9322 - val_loss: 1.7843 - val_mean_absolute_error: 0.8993 - val_mean_squared_error: 1.7843\n",
            "Epoch 406/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.9203 - mean_absolute_error: 0.9322 - mean_squared_error: 1.9203\n",
            "Epoch 406: val_loss improved from 1.78433 to 1.76880, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.9203 - mean_absolute_error: 0.9322 - mean_squared_error: 1.9203 - val_loss: 1.7688 - val_mean_absolute_error: 0.8984 - val_mean_squared_error: 1.7688\n",
            "Epoch 407/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.9164 - mean_absolute_error: 0.9305 - mean_squared_error: 1.9164\n",
            "Epoch 407: val_loss improved from 1.76880 to 1.75355, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.9008 - mean_absolute_error: 0.9250 - mean_squared_error: 1.9008 - val_loss: 1.7536 - val_mean_absolute_error: 0.8940 - val_mean_squared_error: 1.7536\n",
            "Epoch 408/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.8930 - mean_absolute_error: 0.9249 - mean_squared_error: 1.8930\n",
            "Epoch 408: val_loss improved from 1.75355 to 1.73655, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.8900 - mean_absolute_error: 0.9243 - mean_squared_error: 1.8900 - val_loss: 1.7366 - val_mean_absolute_error: 0.8924 - val_mean_squared_error: 1.7366\n",
            "Epoch 409/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.8620 - mean_absolute_error: 0.9212 - mean_squared_error: 1.8620\n",
            "Epoch 409: val_loss improved from 1.73655 to 1.71937, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.8725 - mean_absolute_error: 0.9234 - mean_squared_error: 1.8725 - val_loss: 1.7194 - val_mean_absolute_error: 0.8851 - val_mean_squared_error: 1.7194\n",
            "Epoch 410/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.8644 - mean_absolute_error: 0.9211 - mean_squared_error: 1.8644\n",
            "Epoch 410: val_loss improved from 1.71937 to 1.71736, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.8590 - mean_absolute_error: 0.9204 - mean_squared_error: 1.8590 - val_loss: 1.7174 - val_mean_absolute_error: 0.8871 - val_mean_squared_error: 1.7174\n",
            "Epoch 411/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.8315 - mean_absolute_error: 0.9151 - mean_squared_error: 1.8315\n",
            "Epoch 411: val_loss improved from 1.71736 to 1.69374, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.8463 - mean_absolute_error: 0.9171 - mean_squared_error: 1.8463 - val_loss: 1.6937 - val_mean_absolute_error: 0.8877 - val_mean_squared_error: 1.6937\n",
            "Epoch 412/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.8214 - mean_absolute_error: 0.9194 - mean_squared_error: 1.8214\n",
            "Epoch 412: val_loss improved from 1.69374 to 1.68528, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.8352 - mean_absolute_error: 0.9206 - mean_squared_error: 1.8352 - val_loss: 1.6853 - val_mean_absolute_error: 0.8851 - val_mean_squared_error: 1.6853\n",
            "Epoch 413/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.8093 - mean_absolute_error: 0.9123 - mean_squared_error: 1.8093\n",
            "Epoch 413: val_loss improved from 1.68528 to 1.66883, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.8173 - mean_absolute_error: 0.9149 - mean_squared_error: 1.8173 - val_loss: 1.6688 - val_mean_absolute_error: 0.8774 - val_mean_squared_error: 1.6688\n",
            "Epoch 414/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.8085 - mean_absolute_error: 0.9113 - mean_squared_error: 1.8085\n",
            "Epoch 414: val_loss did not improve from 1.66883\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.8069 - mean_absolute_error: 0.9110 - mean_squared_error: 1.8069 - val_loss: 1.6693 - val_mean_absolute_error: 0.8800 - val_mean_squared_error: 1.6693\n",
            "Epoch 415/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.7982 - mean_absolute_error: 0.9121 - mean_squared_error: 1.7982\n",
            "Epoch 415: val_loss improved from 1.66883 to 1.64462, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7943 - mean_absolute_error: 0.9111 - mean_squared_error: 1.7943 - val_loss: 1.6446 - val_mean_absolute_error: 0.8763 - val_mean_squared_error: 1.6446\n",
            "Epoch 416/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.7722 - mean_absolute_error: 0.9060 - mean_squared_error: 1.7722\n",
            "Epoch 416: val_loss did not improve from 1.64462\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7792 - mean_absolute_error: 0.9056 - mean_squared_error: 1.7792 - val_loss: 1.6561 - val_mean_absolute_error: 0.8796 - val_mean_squared_error: 1.6561\n",
            "Epoch 417/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.7874 - mean_absolute_error: 0.9116 - mean_squared_error: 1.7874\n",
            "Epoch 417: val_loss improved from 1.64462 to 1.62346, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7713 - mean_absolute_error: 0.9077 - mean_squared_error: 1.7713 - val_loss: 1.6235 - val_mean_absolute_error: 0.8750 - val_mean_squared_error: 1.6235\n",
            "Epoch 418/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.7524 - mean_absolute_error: 0.9022 - mean_squared_error: 1.7524\n",
            "Epoch 418: val_loss improved from 1.62346 to 1.61610, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7566 - mean_absolute_error: 0.9025 - mean_squared_error: 1.7566 - val_loss: 1.6161 - val_mean_absolute_error: 0.8650 - val_mean_squared_error: 1.6161\n",
            "Epoch 419/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.7530 - mean_absolute_error: 0.9010 - mean_squared_error: 1.7530\n",
            "Epoch 419: val_loss improved from 1.61610 to 1.60228, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7505 - mean_absolute_error: 0.9012 - mean_squared_error: 1.7505 - val_loss: 1.6023 - val_mean_absolute_error: 0.8678 - val_mean_squared_error: 1.6023\n",
            "Epoch 420/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.7278 - mean_absolute_error: 0.8970 - mean_squared_error: 1.7278\n",
            "Epoch 420: val_loss did not improve from 1.60228\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7322 - mean_absolute_error: 0.8974 - mean_squared_error: 1.7322 - val_loss: 1.6063 - val_mean_absolute_error: 0.8632 - val_mean_squared_error: 1.6063\n",
            "Epoch 421/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.7305 - mean_absolute_error: 0.8983 - mean_squared_error: 1.7305\n",
            "Epoch 421: val_loss improved from 1.60228 to 1.59141, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7249 - mean_absolute_error: 0.8967 - mean_squared_error: 1.7249 - val_loss: 1.5914 - val_mean_absolute_error: 0.8661 - val_mean_squared_error: 1.5914\n",
            "Epoch 422/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.7158 - mean_absolute_error: 0.8919 - mean_squared_error: 1.7158\n",
            "Epoch 422: val_loss improved from 1.59141 to 1.57873, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7168 - mean_absolute_error: 0.8924 - mean_squared_error: 1.7168 - val_loss: 1.5787 - val_mean_absolute_error: 0.8758 - val_mean_squared_error: 1.5787\n",
            "Epoch 423/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.7109 - mean_absolute_error: 0.8933 - mean_squared_error: 1.7109\n",
            "Epoch 423: val_loss improved from 1.57873 to 1.57371, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.7104 - mean_absolute_error: 0.8934 - mean_squared_error: 1.7104 - val_loss: 1.5737 - val_mean_absolute_error: 0.8657 - val_mean_squared_error: 1.5737\n",
            "Epoch 424/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.6988 - mean_absolute_error: 0.8915 - mean_squared_error: 1.6988\n",
            "Epoch 424: val_loss improved from 1.57371 to 1.56231, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6975 - mean_absolute_error: 0.8920 - mean_squared_error: 1.6975 - val_loss: 1.5623 - val_mean_absolute_error: 0.8590 - val_mean_squared_error: 1.5623\n",
            "Epoch 425/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.6919 - mean_absolute_error: 0.8872 - mean_squared_error: 1.6919\n",
            "Epoch 425: val_loss improved from 1.56231 to 1.55169, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6945 - mean_absolute_error: 0.8883 - mean_squared_error: 1.6945 - val_loss: 1.5517 - val_mean_absolute_error: 0.8530 - val_mean_squared_error: 1.5517\n",
            "Epoch 426/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.6684 - mean_absolute_error: 0.8844 - mean_squared_error: 1.6684\n",
            "Epoch 426: val_loss improved from 1.55169 to 1.55017, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6826 - mean_absolute_error: 0.8884 - mean_squared_error: 1.6826 - val_loss: 1.5502 - val_mean_absolute_error: 0.8585 - val_mean_squared_error: 1.5502\n",
            "Epoch 427/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.6686 - mean_absolute_error: 0.8848 - mean_squared_error: 1.6686\n",
            "Epoch 427: val_loss improved from 1.55017 to 1.53729, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6730 - mean_absolute_error: 0.8847 - mean_squared_error: 1.6730 - val_loss: 1.5373 - val_mean_absolute_error: 0.8538 - val_mean_squared_error: 1.5373\n",
            "Epoch 428/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.6646 - mean_absolute_error: 0.8836 - mean_squared_error: 1.6646\n",
            "Epoch 428: val_loss improved from 1.53729 to 1.52731, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6663 - mean_absolute_error: 0.8846 - mean_squared_error: 1.6663 - val_loss: 1.5273 - val_mean_absolute_error: 0.8536 - val_mean_squared_error: 1.5273\n",
            "Epoch 429/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.6531 - mean_absolute_error: 0.8827 - mean_squared_error: 1.6531\n",
            "Epoch 429: val_loss did not improve from 1.52731\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6611 - mean_absolute_error: 0.8819 - mean_squared_error: 1.6611 - val_loss: 1.5287 - val_mean_absolute_error: 0.8475 - val_mean_squared_error: 1.5287\n",
            "Epoch 430/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.6579 - mean_absolute_error: 0.8814 - mean_squared_error: 1.6579\n",
            "Epoch 430: val_loss improved from 1.52731 to 1.51365, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6504 - mean_absolute_error: 0.8797 - mean_squared_error: 1.6504 - val_loss: 1.5136 - val_mean_absolute_error: 0.8511 - val_mean_squared_error: 1.5136\n",
            "Epoch 431/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.6621 - mean_absolute_error: 0.8805 - mean_squared_error: 1.6621\n",
            "Epoch 431: val_loss improved from 1.51365 to 1.50453, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6462 - mean_absolute_error: 0.8792 - mean_squared_error: 1.6462 - val_loss: 1.5045 - val_mean_absolute_error: 0.8427 - val_mean_squared_error: 1.5045\n",
            "Epoch 432/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.6403 - mean_absolute_error: 0.8776 - mean_squared_error: 1.6403\n",
            "Epoch 432: val_loss did not improve from 1.50453\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6476 - mean_absolute_error: 0.8788 - mean_squared_error: 1.6476 - val_loss: 1.5299 - val_mean_absolute_error: 0.8510 - val_mean_squared_error: 1.5299\n",
            "Epoch 433/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.6378 - mean_absolute_error: 0.8777 - mean_squared_error: 1.6378\n",
            "Epoch 433: val_loss improved from 1.50453 to 1.49368, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6312 - mean_absolute_error: 0.8768 - mean_squared_error: 1.6312 - val_loss: 1.4937 - val_mean_absolute_error: 0.8471 - val_mean_squared_error: 1.4937\n",
            "Epoch 434/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.6293 - mean_absolute_error: 0.8755 - mean_squared_error: 1.6293\n",
            "Epoch 434: val_loss improved from 1.49368 to 1.48649, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6287 - mean_absolute_error: 0.8754 - mean_squared_error: 1.6287 - val_loss: 1.4865 - val_mean_absolute_error: 0.8414 - val_mean_squared_error: 1.4865\n",
            "Epoch 435/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.6424 - mean_absolute_error: 0.8792 - mean_squared_error: 1.6424\n",
            "Epoch 435: val_loss did not improve from 1.48649\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6255 - mean_absolute_error: 0.8747 - mean_squared_error: 1.6255 - val_loss: 1.4880 - val_mean_absolute_error: 0.8478 - val_mean_squared_error: 1.4880\n",
            "Epoch 436/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.6026 - mean_absolute_error: 0.8703 - mean_squared_error: 1.6026\n",
            "Epoch 436: val_loss improved from 1.48649 to 1.48459, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.6114 - mean_absolute_error: 0.8722 - mean_squared_error: 1.6114 - val_loss: 1.4846 - val_mean_absolute_error: 0.8454 - val_mean_squared_error: 1.4846\n",
            "Epoch 437/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.5984 - mean_absolute_error: 0.8725 - mean_squared_error: 1.5984\n",
            "Epoch 437: val_loss improved from 1.48459 to 1.47061, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6077 - mean_absolute_error: 0.8734 - mean_squared_error: 1.6077 - val_loss: 1.4706 - val_mean_absolute_error: 0.8323 - val_mean_squared_error: 1.4706\n",
            "Epoch 438/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.5959 - mean_absolute_error: 0.8676 - mean_squared_error: 1.5959\n",
            "Epoch 438: val_loss improved from 1.47061 to 1.46832, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6008 - mean_absolute_error: 0.8697 - mean_squared_error: 1.6008 - val_loss: 1.4683 - val_mean_absolute_error: 0.8328 - val_mean_squared_error: 1.4683\n",
            "Epoch 439/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.6085 - mean_absolute_error: 0.8714 - mean_squared_error: 1.6085\n",
            "Epoch 439: val_loss improved from 1.46832 to 1.45943, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.6001 - mean_absolute_error: 0.8693 - mean_squared_error: 1.6001 - val_loss: 1.4594 - val_mean_absolute_error: 0.8407 - val_mean_squared_error: 1.4594\n",
            "Epoch 440/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.5741 - mean_absolute_error: 0.8629 - mean_squared_error: 1.5741\n",
            "Epoch 440: val_loss did not improve from 1.45943\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5926 - mean_absolute_error: 0.8674 - mean_squared_error: 1.5926 - val_loss: 1.4928 - val_mean_absolute_error: 0.8428 - val_mean_squared_error: 1.4928\n",
            "Epoch 441/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.5976 - mean_absolute_error: 0.8676 - mean_squared_error: 1.5976\n",
            "Epoch 441: val_loss improved from 1.45943 to 1.44869, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5904 - mean_absolute_error: 0.8645 - mean_squared_error: 1.5904 - val_loss: 1.4487 - val_mean_absolute_error: 0.8371 - val_mean_squared_error: 1.4487\n",
            "Epoch 442/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.5896 - mean_absolute_error: 0.8687 - mean_squared_error: 1.5896\n",
            "Epoch 442: val_loss did not improve from 1.44869\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5867 - mean_absolute_error: 0.8672 - mean_squared_error: 1.5867 - val_loss: 1.4513 - val_mean_absolute_error: 0.8277 - val_mean_squared_error: 1.4513\n",
            "Epoch 443/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.5743 - mean_absolute_error: 0.8620 - mean_squared_error: 1.5743\n",
            "Epoch 443: val_loss improved from 1.44869 to 1.44686, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5776 - mean_absolute_error: 0.8627 - mean_squared_error: 1.5776 - val_loss: 1.4469 - val_mean_absolute_error: 0.8337 - val_mean_squared_error: 1.4469\n",
            "Epoch 444/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.5522 - mean_absolute_error: 0.8576 - mean_squared_error: 1.5522\n",
            "Epoch 444: val_loss improved from 1.44686 to 1.44101, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5702 - mean_absolute_error: 0.8625 - mean_squared_error: 1.5702 - val_loss: 1.4410 - val_mean_absolute_error: 0.8259 - val_mean_squared_error: 1.4410\n",
            "Epoch 445/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.5616 - mean_absolute_error: 0.8574 - mean_squared_error: 1.5616\n",
            "Epoch 445: val_loss improved from 1.44101 to 1.43916, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5601 - mean_absolute_error: 0.8570 - mean_squared_error: 1.5601 - val_loss: 1.4392 - val_mean_absolute_error: 0.8232 - val_mean_squared_error: 1.4392\n",
            "Epoch 446/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.5608 - mean_absolute_error: 0.8593 - mean_squared_error: 1.5608\n",
            "Epoch 446: val_loss did not improve from 1.43916\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5610 - mean_absolute_error: 0.8593 - mean_squared_error: 1.5610 - val_loss: 1.4515 - val_mean_absolute_error: 0.8335 - val_mean_squared_error: 1.4515\n",
            "Epoch 447/1000\n",
            "223/245 [==========================>...] - ETA: 0s - loss: 1.5601 - mean_absolute_error: 0.8614 - mean_squared_error: 1.5601\n",
            "Epoch 447: val_loss did not improve from 1.43916\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5543 - mean_absolute_error: 0.8592 - mean_squared_error: 1.5543 - val_loss: 1.4559 - val_mean_absolute_error: 0.8434 - val_mean_squared_error: 1.4559\n",
            "Epoch 448/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.5457 - mean_absolute_error: 0.8551 - mean_squared_error: 1.5457\n",
            "Epoch 448: val_loss improved from 1.43916 to 1.41367, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5500 - mean_absolute_error: 0.8556 - mean_squared_error: 1.5500 - val_loss: 1.4137 - val_mean_absolute_error: 0.8232 - val_mean_squared_error: 1.4137\n",
            "Epoch 449/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.5399 - mean_absolute_error: 0.8539 - mean_squared_error: 1.5399\n",
            "Epoch 449: val_loss did not improve from 1.41367\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5431 - mean_absolute_error: 0.8557 - mean_squared_error: 1.5431 - val_loss: 1.4182 - val_mean_absolute_error: 0.8209 - val_mean_squared_error: 1.4182\n",
            "Epoch 450/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.5326 - mean_absolute_error: 0.8529 - mean_squared_error: 1.5326\n",
            "Epoch 450: val_loss improved from 1.41367 to 1.40170, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5352 - mean_absolute_error: 0.8531 - mean_squared_error: 1.5352 - val_loss: 1.4017 - val_mean_absolute_error: 0.8221 - val_mean_squared_error: 1.4017\n",
            "Epoch 451/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.5375 - mean_absolute_error: 0.8561 - mean_squared_error: 1.5375\n",
            "Epoch 451: val_loss did not improve from 1.40170\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5332 - mean_absolute_error: 0.8534 - mean_squared_error: 1.5332 - val_loss: 1.4076 - val_mean_absolute_error: 0.8292 - val_mean_squared_error: 1.4076\n",
            "Epoch 452/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.5278 - mean_absolute_error: 0.8536 - mean_squared_error: 1.5278\n",
            "Epoch 452: val_loss improved from 1.40170 to 1.40033, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5289 - mean_absolute_error: 0.8533 - mean_squared_error: 1.5289 - val_loss: 1.4003 - val_mean_absolute_error: 0.8197 - val_mean_squared_error: 1.4003\n",
            "Epoch 453/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.5243 - mean_absolute_error: 0.8512 - mean_squared_error: 1.5243\n",
            "Epoch 453: val_loss improved from 1.40033 to 1.39114, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5243 - mean_absolute_error: 0.8512 - mean_squared_error: 1.5243 - val_loss: 1.3911 - val_mean_absolute_error: 0.8228 - val_mean_squared_error: 1.3911\n",
            "Epoch 454/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.5071 - mean_absolute_error: 0.8465 - mean_squared_error: 1.5071\n",
            "Epoch 454: val_loss improved from 1.39114 to 1.38616, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5201 - mean_absolute_error: 0.8498 - mean_squared_error: 1.5201 - val_loss: 1.3862 - val_mean_absolute_error: 0.8229 - val_mean_squared_error: 1.3862\n",
            "Epoch 455/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.5295 - mean_absolute_error: 0.8535 - mean_squared_error: 1.5295\n",
            "Epoch 455: val_loss did not improve from 1.38616\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.5115 - mean_absolute_error: 0.8469 - mean_squared_error: 1.5115 - val_loss: 1.4317 - val_mean_absolute_error: 0.8351 - val_mean_squared_error: 1.4317\n",
            "Epoch 456/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.5146 - mean_absolute_error: 0.8529 - mean_squared_error: 1.5146\n",
            "Epoch 456: val_loss did not improve from 1.38616\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5086 - mean_absolute_error: 0.8479 - mean_squared_error: 1.5086 - val_loss: 1.3873 - val_mean_absolute_error: 0.8121 - val_mean_squared_error: 1.3873\n",
            "Epoch 457/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.5040 - mean_absolute_error: 0.8474 - mean_squared_error: 1.5040\n",
            "Epoch 457: val_loss improved from 1.38616 to 1.37029, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5029 - mean_absolute_error: 0.8454 - mean_squared_error: 1.5029 - val_loss: 1.3703 - val_mean_absolute_error: 0.8115 - val_mean_squared_error: 1.3703\n",
            "Epoch 458/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.5093 - mean_absolute_error: 0.8486 - mean_squared_error: 1.5093\n",
            "Epoch 458: val_loss did not improve from 1.37029\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.5014 - mean_absolute_error: 0.8454 - mean_squared_error: 1.5014 - val_loss: 1.3740 - val_mean_absolute_error: 0.8207 - val_mean_squared_error: 1.3740\n",
            "Epoch 459/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.4910 - mean_absolute_error: 0.8448 - mean_squared_error: 1.4910\n",
            "Epoch 459: val_loss improved from 1.37029 to 1.36373, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4934 - mean_absolute_error: 0.8445 - mean_squared_error: 1.4934 - val_loss: 1.3637 - val_mean_absolute_error: 0.8111 - val_mean_squared_error: 1.3637\n",
            "Epoch 460/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.4867 - mean_absolute_error: 0.8428 - mean_squared_error: 1.4867\n",
            "Epoch 460: val_loss did not improve from 1.36373\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4904 - mean_absolute_error: 0.8441 - mean_squared_error: 1.4904 - val_loss: 1.4102 - val_mean_absolute_error: 0.8263 - val_mean_squared_error: 1.4102\n",
            "Epoch 461/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.4911 - mean_absolute_error: 0.8439 - mean_squared_error: 1.4911\n",
            "Epoch 461: val_loss improved from 1.36373 to 1.34882, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4870 - mean_absolute_error: 0.8435 - mean_squared_error: 1.4870 - val_loss: 1.3488 - val_mean_absolute_error: 0.8073 - val_mean_squared_error: 1.3488\n",
            "Epoch 462/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.4841 - mean_absolute_error: 0.8394 - mean_squared_error: 1.4841\n",
            "Epoch 462: val_loss improved from 1.34882 to 1.34581, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4815 - mean_absolute_error: 0.8386 - mean_squared_error: 1.4815 - val_loss: 1.3458 - val_mean_absolute_error: 0.8084 - val_mean_squared_error: 1.3458\n",
            "Epoch 463/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.4912 - mean_absolute_error: 0.8439 - mean_squared_error: 1.4912\n",
            "Epoch 463: val_loss improved from 1.34581 to 1.34438, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4773 - mean_absolute_error: 0.8404 - mean_squared_error: 1.4773 - val_loss: 1.3444 - val_mean_absolute_error: 0.8036 - val_mean_squared_error: 1.3444\n",
            "Epoch 464/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.4551 - mean_absolute_error: 0.8327 - mean_squared_error: 1.4551\n",
            "Epoch 464: val_loss improved from 1.34438 to 1.33865, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4631 - mean_absolute_error: 0.8350 - mean_squared_error: 1.4631 - val_loss: 1.3387 - val_mean_absolute_error: 0.8075 - val_mean_squared_error: 1.3387\n",
            "Epoch 465/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.4616 - mean_absolute_error: 0.8372 - mean_squared_error: 1.4616\n",
            "Epoch 465: val_loss improved from 1.33865 to 1.33129, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4666 - mean_absolute_error: 0.8396 - mean_squared_error: 1.4666 - val_loss: 1.3313 - val_mean_absolute_error: 0.8083 - val_mean_squared_error: 1.3313\n",
            "Epoch 466/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.4700 - mean_absolute_error: 0.8368 - mean_squared_error: 1.4700\n",
            "Epoch 466: val_loss improved from 1.33129 to 1.32943, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4631 - mean_absolute_error: 0.8362 - mean_squared_error: 1.4631 - val_loss: 1.3294 - val_mean_absolute_error: 0.8005 - val_mean_squared_error: 1.3294\n",
            "Epoch 467/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.4556 - mean_absolute_error: 0.8328 - mean_squared_error: 1.4556\n",
            "Epoch 467: val_loss improved from 1.32943 to 1.32253, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4533 - mean_absolute_error: 0.8322 - mean_squared_error: 1.4533 - val_loss: 1.3225 - val_mean_absolute_error: 0.8037 - val_mean_squared_error: 1.3225\n",
            "Epoch 468/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.4531 - mean_absolute_error: 0.8315 - mean_squared_error: 1.4531\n",
            "Epoch 468: val_loss improved from 1.32253 to 1.31928, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4500 - mean_absolute_error: 0.8310 - mean_squared_error: 1.4500 - val_loss: 1.3193 - val_mean_absolute_error: 0.7996 - val_mean_squared_error: 1.3193\n",
            "Epoch 469/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.4572 - mean_absolute_error: 0.8364 - mean_squared_error: 1.4572\n",
            "Epoch 469: val_loss improved from 1.31928 to 1.31504, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4425 - mean_absolute_error: 0.8320 - mean_squared_error: 1.4425 - val_loss: 1.3150 - val_mean_absolute_error: 0.8031 - val_mean_squared_error: 1.3150\n",
            "Epoch 470/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.4384 - mean_absolute_error: 0.8282 - mean_squared_error: 1.4384\n",
            "Epoch 470: val_loss improved from 1.31504 to 1.31220, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4346 - mean_absolute_error: 0.8273 - mean_squared_error: 1.4346 - val_loss: 1.3122 - val_mean_absolute_error: 0.7988 - val_mean_squared_error: 1.3122\n",
            "Epoch 471/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.4247 - mean_absolute_error: 0.8256 - mean_squared_error: 1.4247\n",
            "Epoch 471: val_loss did not improve from 1.31220\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4348 - mean_absolute_error: 0.8294 - mean_squared_error: 1.4348 - val_loss: 1.3346 - val_mean_absolute_error: 0.7931 - val_mean_squared_error: 1.3346\n",
            "Epoch 472/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.4345 - mean_absolute_error: 0.8297 - mean_squared_error: 1.4345\n",
            "Epoch 472: val_loss improved from 1.31220 to 1.30657, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4329 - mean_absolute_error: 0.8290 - mean_squared_error: 1.4329 - val_loss: 1.3066 - val_mean_absolute_error: 0.7977 - val_mean_squared_error: 1.3066\n",
            "Epoch 473/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.4287 - mean_absolute_error: 0.8283 - mean_squared_error: 1.4287\n",
            "Epoch 473: val_loss improved from 1.30657 to 1.29907, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4283 - mean_absolute_error: 0.8282 - mean_squared_error: 1.4283 - val_loss: 1.2991 - val_mean_absolute_error: 0.7946 - val_mean_squared_error: 1.2991\n",
            "Epoch 474/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.4150 - mean_absolute_error: 0.8220 - mean_squared_error: 1.4150\n",
            "Epoch 474: val_loss improved from 1.29907 to 1.28768, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4173 - mean_absolute_error: 0.8237 - mean_squared_error: 1.4173 - val_loss: 1.2877 - val_mean_absolute_error: 0.7918 - val_mean_squared_error: 1.2877\n",
            "Epoch 475/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.4149 - mean_absolute_error: 0.8240 - mean_squared_error: 1.4149\n",
            "Epoch 475: val_loss improved from 1.28768 to 1.28568, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4125 - mean_absolute_error: 0.8228 - mean_squared_error: 1.4125 - val_loss: 1.2857 - val_mean_absolute_error: 0.7934 - val_mean_squared_error: 1.2857\n",
            "Epoch 476/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.4150 - mean_absolute_error: 0.8229 - mean_squared_error: 1.4150\n",
            "Epoch 476: val_loss improved from 1.28568 to 1.28042, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4127 - mean_absolute_error: 0.8230 - mean_squared_error: 1.4127 - val_loss: 1.2804 - val_mean_absolute_error: 0.7894 - val_mean_squared_error: 1.2804\n",
            "Epoch 477/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.4054 - mean_absolute_error: 0.8225 - mean_squared_error: 1.4054\n",
            "Epoch 477: val_loss did not improve from 1.28042\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4043 - mean_absolute_error: 0.8214 - mean_squared_error: 1.4043 - val_loss: 1.2913 - val_mean_absolute_error: 0.7969 - val_mean_squared_error: 1.2913\n",
            "Epoch 478/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.4013 - mean_absolute_error: 0.8190 - mean_squared_error: 1.4013\n",
            "Epoch 478: val_loss improved from 1.28042 to 1.27526, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.4007 - mean_absolute_error: 0.8189 - mean_squared_error: 1.4007 - val_loss: 1.2753 - val_mean_absolute_error: 0.7899 - val_mean_squared_error: 1.2753\n",
            "Epoch 479/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.3861 - mean_absolute_error: 0.8167 - mean_squared_error: 1.3861\n",
            "Epoch 479: val_loss improved from 1.27526 to 1.26532, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3927 - mean_absolute_error: 0.8189 - mean_squared_error: 1.3927 - val_loss: 1.2653 - val_mean_absolute_error: 0.7839 - val_mean_squared_error: 1.2653\n",
            "Epoch 480/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.3878 - mean_absolute_error: 0.8169 - mean_squared_error: 1.3878\n",
            "Epoch 480: val_loss improved from 1.26532 to 1.26162, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3864 - mean_absolute_error: 0.8168 - mean_squared_error: 1.3864 - val_loss: 1.2616 - val_mean_absolute_error: 0.7856 - val_mean_squared_error: 1.2616\n",
            "Epoch 481/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.3914 - mean_absolute_error: 0.8185 - mean_squared_error: 1.3914\n",
            "Epoch 481: val_loss improved from 1.26162 to 1.25516, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3927 - mean_absolute_error: 0.8194 - mean_squared_error: 1.3927 - val_loss: 1.2552 - val_mean_absolute_error: 0.7828 - val_mean_squared_error: 1.2552\n",
            "Epoch 482/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.3840 - mean_absolute_error: 0.8171 - mean_squared_error: 1.3840\n",
            "Epoch 482: val_loss improved from 1.25516 to 1.25134, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.3763 - mean_absolute_error: 0.8146 - mean_squared_error: 1.3763 - val_loss: 1.2513 - val_mean_absolute_error: 0.7833 - val_mean_squared_error: 1.2513\n",
            "Epoch 483/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.3705 - mean_absolute_error: 0.8108 - mean_squared_error: 1.3705\n",
            "Epoch 483: val_loss did not improve from 1.25134\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3731 - mean_absolute_error: 0.8117 - mean_squared_error: 1.3731 - val_loss: 1.2622 - val_mean_absolute_error: 0.7872 - val_mean_squared_error: 1.2622\n",
            "Epoch 484/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.3755 - mean_absolute_error: 0.8161 - mean_squared_error: 1.3755\n",
            "Epoch 484: val_loss did not improve from 1.25134\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3699 - mean_absolute_error: 0.8129 - mean_squared_error: 1.3699 - val_loss: 1.2592 - val_mean_absolute_error: 0.7905 - val_mean_squared_error: 1.2592\n",
            "Epoch 485/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 1.3578 - mean_absolute_error: 0.8083 - mean_squared_error: 1.3578\n",
            "Epoch 485: val_loss improved from 1.25134 to 1.23518, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3653 - mean_absolute_error: 0.8110 - mean_squared_error: 1.3653 - val_loss: 1.2352 - val_mean_absolute_error: 0.7774 - val_mean_squared_error: 1.2352\n",
            "Epoch 486/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.3567 - mean_absolute_error: 0.8111 - mean_squared_error: 1.3567\n",
            "Epoch 486: val_loss improved from 1.23518 to 1.23075, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3557 - mean_absolute_error: 0.8091 - mean_squared_error: 1.3557 - val_loss: 1.2307 - val_mean_absolute_error: 0.7750 - val_mean_squared_error: 1.2307\n",
            "Epoch 487/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.3473 - mean_absolute_error: 0.8048 - mean_squared_error: 1.3473\n",
            "Epoch 487: val_loss improved from 1.23075 to 1.22491, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3561 - mean_absolute_error: 0.8087 - mean_squared_error: 1.3561 - val_loss: 1.2249 - val_mean_absolute_error: 0.7738 - val_mean_squared_error: 1.2249\n",
            "Epoch 488/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.3545 - mean_absolute_error: 0.8078 - mean_squared_error: 1.3545\n",
            "Epoch 488: val_loss did not improve from 1.22491\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3530 - mean_absolute_error: 0.8074 - mean_squared_error: 1.3530 - val_loss: 1.2432 - val_mean_absolute_error: 0.7861 - val_mean_squared_error: 1.2432\n",
            "Epoch 489/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.3493 - mean_absolute_error: 0.8058 - mean_squared_error: 1.3493\n",
            "Epoch 489: val_loss did not improve from 1.22491\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3423 - mean_absolute_error: 0.8041 - mean_squared_error: 1.3423 - val_loss: 1.2399 - val_mean_absolute_error: 0.7813 - val_mean_squared_error: 1.2399\n",
            "Epoch 490/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.3382 - mean_absolute_error: 0.8017 - mean_squared_error: 1.3382\n",
            "Epoch 490: val_loss improved from 1.22491 to 1.21364, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3395 - mean_absolute_error: 0.8028 - mean_squared_error: 1.3395 - val_loss: 1.2136 - val_mean_absolute_error: 0.7700 - val_mean_squared_error: 1.2136\n",
            "Epoch 491/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.3329 - mean_absolute_error: 0.8025 - mean_squared_error: 1.3329\n",
            "Epoch 491: val_loss improved from 1.21364 to 1.21194, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.3329 - mean_absolute_error: 0.8025 - mean_squared_error: 1.3329 - val_loss: 1.2119 - val_mean_absolute_error: 0.7711 - val_mean_squared_error: 1.2119\n",
            "Epoch 492/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.3266 - mean_absolute_error: 0.8011 - mean_squared_error: 1.3266\n",
            "Epoch 492: val_loss did not improve from 1.21194\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3280 - mean_absolute_error: 0.8012 - mean_squared_error: 1.3280 - val_loss: 1.2230 - val_mean_absolute_error: 0.7746 - val_mean_squared_error: 1.2230\n",
            "Epoch 493/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.3237 - mean_absolute_error: 0.7991 - mean_squared_error: 1.3237\n",
            "Epoch 493: val_loss improved from 1.21194 to 1.19856, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3237 - mean_absolute_error: 0.7991 - mean_squared_error: 1.3237 - val_loss: 1.1986 - val_mean_absolute_error: 0.7671 - val_mean_squared_error: 1.1986\n",
            "Epoch 494/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.3118 - mean_absolute_error: 0.7964 - mean_squared_error: 1.3118\n",
            "Epoch 494: val_loss did not improve from 1.19856\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3121 - mean_absolute_error: 0.7971 - mean_squared_error: 1.3121 - val_loss: 1.2110 - val_mean_absolute_error: 0.7721 - val_mean_squared_error: 1.2110\n",
            "Epoch 495/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.3153 - mean_absolute_error: 0.7969 - mean_squared_error: 1.3153\n",
            "Epoch 495: val_loss improved from 1.19856 to 1.18920, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3089 - mean_absolute_error: 0.7945 - mean_squared_error: 1.3089 - val_loss: 1.1892 - val_mean_absolute_error: 0.7684 - val_mean_squared_error: 1.1892\n",
            "Epoch 496/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.3148 - mean_absolute_error: 0.7993 - mean_squared_error: 1.3148\n",
            "Epoch 496: val_loss improved from 1.18920 to 1.18682, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.3009 - mean_absolute_error: 0.7945 - mean_squared_error: 1.3009 - val_loss: 1.1868 - val_mean_absolute_error: 0.7643 - val_mean_squared_error: 1.1868\n",
            "Epoch 497/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.2974 - mean_absolute_error: 0.7937 - mean_squared_error: 1.2974\n",
            "Epoch 497: val_loss did not improve from 1.18682\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2950 - mean_absolute_error: 0.7927 - mean_squared_error: 1.2950 - val_loss: 1.2021 - val_mean_absolute_error: 0.7703 - val_mean_squared_error: 1.2021\n",
            "Epoch 498/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.2975 - mean_absolute_error: 0.7938 - mean_squared_error: 1.2975\n",
            "Epoch 498: val_loss improved from 1.18682 to 1.17811, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2854 - mean_absolute_error: 0.7900 - mean_squared_error: 1.2854 - val_loss: 1.1781 - val_mean_absolute_error: 0.7584 - val_mean_squared_error: 1.1781\n",
            "Epoch 499/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.2776 - mean_absolute_error: 0.7867 - mean_squared_error: 1.2776\n",
            "Epoch 499: val_loss did not improve from 1.17811\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2823 - mean_absolute_error: 0.7891 - mean_squared_error: 1.2823 - val_loss: 1.1811 - val_mean_absolute_error: 0.7632 - val_mean_squared_error: 1.1811\n",
            "Epoch 500/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.2758 - mean_absolute_error: 0.7887 - mean_squared_error: 1.2758\n",
            "Epoch 500: val_loss improved from 1.17811 to 1.16276, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2758 - mean_absolute_error: 0.7886 - mean_squared_error: 1.2758 - val_loss: 1.1628 - val_mean_absolute_error: 0.7549 - val_mean_squared_error: 1.1628\n",
            "Epoch 501/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.2732 - mean_absolute_error: 0.7874 - mean_squared_error: 1.2732\n",
            "Epoch 501: val_loss did not improve from 1.16276\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2727 - mean_absolute_error: 0.7868 - mean_squared_error: 1.2727 - val_loss: 1.1657 - val_mean_absolute_error: 0.7567 - val_mean_squared_error: 1.1657\n",
            "Epoch 502/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.2703 - mean_absolute_error: 0.7862 - mean_squared_error: 1.2703\n",
            "Epoch 502: val_loss did not improve from 1.16276\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2724 - mean_absolute_error: 0.7864 - mean_squared_error: 1.2724 - val_loss: 1.1806 - val_mean_absolute_error: 0.7572 - val_mean_squared_error: 1.1806\n",
            "Epoch 503/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.2522 - mean_absolute_error: 0.7776 - mean_squared_error: 1.2522\n",
            "Epoch 503: val_loss did not improve from 1.16276\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2675 - mean_absolute_error: 0.7836 - mean_squared_error: 1.2675 - val_loss: 1.1647 - val_mean_absolute_error: 0.7544 - val_mean_squared_error: 1.1647\n",
            "Epoch 504/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.2580 - mean_absolute_error: 0.7815 - mean_squared_error: 1.2580\n",
            "Epoch 504: val_loss improved from 1.16276 to 1.14698, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2576 - mean_absolute_error: 0.7818 - mean_squared_error: 1.2576 - val_loss: 1.1470 - val_mean_absolute_error: 0.7527 - val_mean_squared_error: 1.1470\n",
            "Epoch 505/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 1.2467 - mean_absolute_error: 0.7790 - mean_squared_error: 1.2467\n",
            "Epoch 505: val_loss improved from 1.14698 to 1.14594, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2478 - mean_absolute_error: 0.7793 - mean_squared_error: 1.2478 - val_loss: 1.1459 - val_mean_absolute_error: 0.7479 - val_mean_squared_error: 1.1459\n",
            "Epoch 506/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.2387 - mean_absolute_error: 0.7768 - mean_squared_error: 1.2387\n",
            "Epoch 506: val_loss improved from 1.14594 to 1.14123, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2381 - mean_absolute_error: 0.7765 - mean_squared_error: 1.2381 - val_loss: 1.1412 - val_mean_absolute_error: 0.7515 - val_mean_squared_error: 1.1412\n",
            "Epoch 507/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.2396 - mean_absolute_error: 0.7763 - mean_squared_error: 1.2396\n",
            "Epoch 507: val_loss improved from 1.14123 to 1.13132, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2418 - mean_absolute_error: 0.7776 - mean_squared_error: 1.2418 - val_loss: 1.1313 - val_mean_absolute_error: 0.7461 - val_mean_squared_error: 1.1313\n",
            "Epoch 508/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 1.2277 - mean_absolute_error: 0.7748 - mean_squared_error: 1.2277\n",
            "Epoch 508: val_loss improved from 1.13132 to 1.12811, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2277 - mean_absolute_error: 0.7748 - mean_squared_error: 1.2277 - val_loss: 1.1281 - val_mean_absolute_error: 0.7438 - val_mean_squared_error: 1.1281\n",
            "Epoch 509/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.2276 - mean_absolute_error: 0.7737 - mean_squared_error: 1.2276\n",
            "Epoch 509: val_loss improved from 1.12811 to 1.12598, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 1.2290 - mean_absolute_error: 0.7742 - mean_squared_error: 1.2290 - val_loss: 1.1260 - val_mean_absolute_error: 0.7491 - val_mean_squared_error: 1.1260\n",
            "Epoch 510/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.2237 - mean_absolute_error: 0.7744 - mean_squared_error: 1.2237\n",
            "Epoch 510: val_loss improved from 1.12598 to 1.12104, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2214 - mean_absolute_error: 0.7743 - mean_squared_error: 1.2214 - val_loss: 1.1210 - val_mean_absolute_error: 0.7469 - val_mean_squared_error: 1.1210\n",
            "Epoch 511/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 1.2336 - mean_absolute_error: 0.7780 - mean_squared_error: 1.2336\n",
            "Epoch 511: val_loss did not improve from 1.12104\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2141 - mean_absolute_error: 0.7698 - mean_squared_error: 1.2141 - val_loss: 1.1235 - val_mean_absolute_error: 0.7464 - val_mean_squared_error: 1.1235\n",
            "Epoch 512/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.1960 - mean_absolute_error: 0.7641 - mean_squared_error: 1.1960\n",
            "Epoch 512: val_loss did not improve from 1.12104\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2047 - mean_absolute_error: 0.7667 - mean_squared_error: 1.2047 - val_loss: 1.1529 - val_mean_absolute_error: 0.7525 - val_mean_squared_error: 1.1529\n",
            "Epoch 513/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.2151 - mean_absolute_error: 0.7723 - mean_squared_error: 1.2151\n",
            "Epoch 513: val_loss improved from 1.12104 to 1.11539, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.2070 - mean_absolute_error: 0.7679 - mean_squared_error: 1.2070 - val_loss: 1.1154 - val_mean_absolute_error: 0.7437 - val_mean_squared_error: 1.1154\n",
            "Epoch 514/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.1956 - mean_absolute_error: 0.7658 - mean_squared_error: 1.1956\n",
            "Epoch 514: val_loss improved from 1.11539 to 1.09773, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1894 - mean_absolute_error: 0.7635 - mean_squared_error: 1.1894 - val_loss: 1.0977 - val_mean_absolute_error: 0.7386 - val_mean_squared_error: 1.0977\n",
            "Epoch 515/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.1957 - mean_absolute_error: 0.7663 - mean_squared_error: 1.1957\n",
            "Epoch 515: val_loss improved from 1.09773 to 1.09080, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1914 - mean_absolute_error: 0.7648 - mean_squared_error: 1.1914 - val_loss: 1.0908 - val_mean_absolute_error: 0.7348 - val_mean_squared_error: 1.0908\n",
            "Epoch 516/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.1821 - mean_absolute_error: 0.7612 - mean_squared_error: 1.1821\n",
            "Epoch 516: val_loss did not improve from 1.09080\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1775 - mean_absolute_error: 0.7592 - mean_squared_error: 1.1775 - val_loss: 1.1255 - val_mean_absolute_error: 0.7442 - val_mean_squared_error: 1.1255\n",
            "Epoch 517/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 1.1726 - mean_absolute_error: 0.7565 - mean_squared_error: 1.1726\n",
            "Epoch 517: val_loss improved from 1.09080 to 1.08560, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1784 - mean_absolute_error: 0.7579 - mean_squared_error: 1.1784 - val_loss: 1.0856 - val_mean_absolute_error: 0.7337 - val_mean_squared_error: 1.0856\n",
            "Epoch 518/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 1.1851 - mean_absolute_error: 0.7618 - mean_squared_error: 1.1851\n",
            "Epoch 518: val_loss did not improve from 1.08560\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1745 - mean_absolute_error: 0.7581 - mean_squared_error: 1.1745 - val_loss: 1.0909 - val_mean_absolute_error: 0.7333 - val_mean_squared_error: 1.0909\n",
            "Epoch 519/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.1627 - mean_absolute_error: 0.7565 - mean_squared_error: 1.1627\n",
            "Epoch 519: val_loss did not improve from 1.08560\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1622 - mean_absolute_error: 0.7556 - mean_squared_error: 1.1622 - val_loss: 1.1009 - val_mean_absolute_error: 0.7380 - val_mean_squared_error: 1.1009\n",
            "Epoch 520/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.1615 - mean_absolute_error: 0.7563 - mean_squared_error: 1.1615\n",
            "Epoch 520: val_loss improved from 1.08560 to 1.06847, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1581 - mean_absolute_error: 0.7546 - mean_squared_error: 1.1581 - val_loss: 1.0685 - val_mean_absolute_error: 0.7299 - val_mean_squared_error: 1.0685\n",
            "Epoch 521/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.1517 - mean_absolute_error: 0.7506 - mean_squared_error: 1.1517\n",
            "Epoch 521: val_loss improved from 1.06847 to 1.06335, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1538 - mean_absolute_error: 0.7517 - mean_squared_error: 1.1538 - val_loss: 1.0633 - val_mean_absolute_error: 0.7262 - val_mean_squared_error: 1.0633\n",
            "Epoch 522/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.1395 - mean_absolute_error: 0.7464 - mean_squared_error: 1.1395\n",
            "Epoch 522: val_loss did not improve from 1.06335\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1481 - mean_absolute_error: 0.7500 - mean_squared_error: 1.1481 - val_loss: 1.0693 - val_mean_absolute_error: 0.7305 - val_mean_squared_error: 1.0693\n",
            "Epoch 523/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.1447 - mean_absolute_error: 0.7504 - mean_squared_error: 1.1447\n",
            "Epoch 523: val_loss improved from 1.06335 to 1.06016, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1428 - mean_absolute_error: 0.7491 - mean_squared_error: 1.1428 - val_loss: 1.0602 - val_mean_absolute_error: 0.7270 - val_mean_squared_error: 1.0602\n",
            "Epoch 524/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.1220 - mean_absolute_error: 0.7430 - mean_squared_error: 1.1220\n",
            "Epoch 524: val_loss did not improve from 1.06016\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1328 - mean_absolute_error: 0.7467 - mean_squared_error: 1.1328 - val_loss: 1.0790 - val_mean_absolute_error: 0.7324 - val_mean_squared_error: 1.0790\n",
            "Epoch 525/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 1.1211 - mean_absolute_error: 0.7446 - mean_squared_error: 1.1211\n",
            "Epoch 525: val_loss did not improve from 1.06016\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1284 - mean_absolute_error: 0.7461 - mean_squared_error: 1.1284 - val_loss: 1.0840 - val_mean_absolute_error: 0.7340 - val_mean_squared_error: 1.0840\n",
            "Epoch 526/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.1214 - mean_absolute_error: 0.7461 - mean_squared_error: 1.1214\n",
            "Epoch 526: val_loss improved from 1.06016 to 1.04368, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.1232 - mean_absolute_error: 0.7448 - mean_squared_error: 1.1232 - val_loss: 1.0437 - val_mean_absolute_error: 0.7223 - val_mean_squared_error: 1.0437\n",
            "Epoch 527/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.1205 - mean_absolute_error: 0.7456 - mean_squared_error: 1.1205\n",
            "Epoch 527: val_loss did not improve from 1.04368\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1207 - mean_absolute_error: 0.7454 - mean_squared_error: 1.1207 - val_loss: 1.0543 - val_mean_absolute_error: 0.7261 - val_mean_squared_error: 1.0543\n",
            "Epoch 528/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.1125 - mean_absolute_error: 0.7408 - mean_squared_error: 1.1125\n",
            "Epoch 528: val_loss improved from 1.04368 to 1.03583, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1130 - mean_absolute_error: 0.7408 - mean_squared_error: 1.1130 - val_loss: 1.0358 - val_mean_absolute_error: 0.7192 - val_mean_squared_error: 1.0358\n",
            "Epoch 529/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.1088 - mean_absolute_error: 0.7390 - mean_squared_error: 1.1088\n",
            "Epoch 529: val_loss improved from 1.03583 to 1.02887, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1096 - mean_absolute_error: 0.7394 - mean_squared_error: 1.1096 - val_loss: 1.0289 - val_mean_absolute_error: 0.7177 - val_mean_squared_error: 1.0289\n",
            "Epoch 530/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 1.0928 - mean_absolute_error: 0.7336 - mean_squared_error: 1.0928\n",
            "Epoch 530: val_loss did not improve from 1.02887\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0975 - mean_absolute_error: 0.7350 - mean_squared_error: 1.0975 - val_loss: 1.0296 - val_mean_absolute_error: 0.7155 - val_mean_squared_error: 1.0296\n",
            "Epoch 531/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.0815 - mean_absolute_error: 0.7295 - mean_squared_error: 1.0815\n",
            "Epoch 531: val_loss did not improve from 1.02887\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0911 - mean_absolute_error: 0.7332 - mean_squared_error: 1.0911 - val_loss: 1.0465 - val_mean_absolute_error: 0.7251 - val_mean_squared_error: 1.0465\n",
            "Epoch 532/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 1.1125 - mean_absolute_error: 0.7402 - mean_squared_error: 1.1125\n",
            "Epoch 532: val_loss did not improve from 1.02887\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1012 - mean_absolute_error: 0.7359 - mean_squared_error: 1.1012 - val_loss: 1.0336 - val_mean_absolute_error: 0.7151 - val_mean_squared_error: 1.0336\n",
            "Epoch 533/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 1.0783 - mean_absolute_error: 0.7314 - mean_squared_error: 1.0783\n",
            "Epoch 533: val_loss improved from 1.02887 to 1.02286, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0833 - mean_absolute_error: 0.7330 - mean_squared_error: 1.0833 - val_loss: 1.0229 - val_mean_absolute_error: 0.7168 - val_mean_squared_error: 1.0229\n",
            "Epoch 534/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 1.0727 - mean_absolute_error: 0.7307 - mean_squared_error: 1.0727\n",
            "Epoch 534: val_loss improved from 1.02286 to 1.01917, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0774 - mean_absolute_error: 0.7322 - mean_squared_error: 1.0774 - val_loss: 1.0192 - val_mean_absolute_error: 0.7139 - val_mean_squared_error: 1.0192\n",
            "Epoch 535/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.0710 - mean_absolute_error: 0.7283 - mean_squared_error: 1.0710\n",
            "Epoch 535: val_loss improved from 1.01917 to 1.00134, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0709 - mean_absolute_error: 0.7278 - mean_squared_error: 1.0709 - val_loss: 1.0013 - val_mean_absolute_error: 0.7095 - val_mean_squared_error: 1.0013\n",
            "Epoch 536/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 1.0473 - mean_absolute_error: 0.7193 - mean_squared_error: 1.0473\n",
            "Epoch 536: val_loss did not improve from 1.00134\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0627 - mean_absolute_error: 0.7256 - mean_squared_error: 1.0627 - val_loss: 1.0035 - val_mean_absolute_error: 0.7097 - val_mean_squared_error: 1.0035\n",
            "Epoch 537/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 1.0554 - mean_absolute_error: 0.7238 - mean_squared_error: 1.0554\n",
            "Epoch 537: val_loss did not improve from 1.00134\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0595 - mean_absolute_error: 0.7237 - mean_squared_error: 1.0595 - val_loss: 1.0470 - val_mean_absolute_error: 0.7216 - val_mean_squared_error: 1.0470\n",
            "Epoch 538/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.0583 - mean_absolute_error: 0.7251 - mean_squared_error: 1.0583\n",
            "Epoch 538: val_loss improved from 1.00134 to 0.99010, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0589 - mean_absolute_error: 0.7250 - mean_squared_error: 1.0589 - val_loss: 0.9901 - val_mean_absolute_error: 0.7041 - val_mean_squared_error: 0.9901\n",
            "Epoch 539/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 1.0525 - mean_absolute_error: 0.7227 - mean_squared_error: 1.0525\n",
            "Epoch 539: val_loss did not improve from 0.99010\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0506 - mean_absolute_error: 0.7222 - mean_squared_error: 1.0506 - val_loss: 1.0055 - val_mean_absolute_error: 0.7105 - val_mean_squared_error: 1.0055\n",
            "Epoch 540/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 1.0517 - mean_absolute_error: 0.7231 - mean_squared_error: 1.0517\n",
            "Epoch 540: val_loss did not improve from 0.99010\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0475 - mean_absolute_error: 0.7216 - mean_squared_error: 1.0475 - val_loss: 1.0096 - val_mean_absolute_error: 0.7100 - val_mean_squared_error: 1.0096\n",
            "Epoch 541/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.0371 - mean_absolute_error: 0.7156 - mean_squared_error: 1.0371\n",
            "Epoch 541: val_loss improved from 0.99010 to 0.97673, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0364 - mean_absolute_error: 0.7163 - mean_squared_error: 1.0364 - val_loss: 0.9767 - val_mean_absolute_error: 0.7008 - val_mean_squared_error: 0.9767\n",
            "Epoch 542/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.0322 - mean_absolute_error: 0.7147 - mean_squared_error: 1.0322\n",
            "Epoch 542: val_loss improved from 0.97673 to 0.97615, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0328 - mean_absolute_error: 0.7147 - mean_squared_error: 1.0328 - val_loss: 0.9761 - val_mean_absolute_error: 0.7011 - val_mean_squared_error: 0.9761\n",
            "Epoch 543/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 1.0187 - mean_absolute_error: 0.7099 - mean_squared_error: 1.0187\n",
            "Epoch 543: val_loss improved from 0.97615 to 0.96986, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0225 - mean_absolute_error: 0.7110 - mean_squared_error: 1.0225 - val_loss: 0.9699 - val_mean_absolute_error: 0.6995 - val_mean_squared_error: 0.9699\n",
            "Epoch 544/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 1.0245 - mean_absolute_error: 0.7126 - mean_squared_error: 1.0245\n",
            "Epoch 544: val_loss did not improve from 0.96986\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0234 - mean_absolute_error: 0.7121 - mean_squared_error: 1.0234 - val_loss: 0.9739 - val_mean_absolute_error: 0.6998 - val_mean_squared_error: 0.9739\n",
            "Epoch 545/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 1.0171 - mean_absolute_error: 0.7080 - mean_squared_error: 1.0171\n",
            "Epoch 545: val_loss improved from 0.96986 to 0.95886, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0183 - mean_absolute_error: 0.7099 - mean_squared_error: 1.0183 - val_loss: 0.9589 - val_mean_absolute_error: 0.6961 - val_mean_squared_error: 0.9589\n",
            "Epoch 546/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 1.0112 - mean_absolute_error: 0.7072 - mean_squared_error: 1.0112\n",
            "Epoch 546: val_loss did not improve from 0.95886\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0087 - mean_absolute_error: 0.7067 - mean_squared_error: 1.0087 - val_loss: 0.9719 - val_mean_absolute_error: 0.6993 - val_mean_squared_error: 0.9719\n",
            "Epoch 547/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 1.0049 - mean_absolute_error: 0.7056 - mean_squared_error: 1.0049\n",
            "Epoch 547: val_loss improved from 0.95886 to 0.95191, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0060 - mean_absolute_error: 0.7066 - mean_squared_error: 1.0060 - val_loss: 0.9519 - val_mean_absolute_error: 0.6921 - val_mean_squared_error: 0.9519\n",
            "Epoch 548/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 1.0081 - mean_absolute_error: 0.7082 - mean_squared_error: 1.0081\n",
            "Epoch 548: val_loss improved from 0.95191 to 0.94734, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 1.0009 - mean_absolute_error: 0.7045 - mean_squared_error: 1.0009 - val_loss: 0.9473 - val_mean_absolute_error: 0.6917 - val_mean_squared_error: 0.9473\n",
            "Epoch 549/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.9950 - mean_absolute_error: 0.7027 - mean_squared_error: 0.9950\n",
            "Epoch 549: val_loss did not improve from 0.94734\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9968 - mean_absolute_error: 0.7033 - mean_squared_error: 0.9968 - val_loss: 0.9503 - val_mean_absolute_error: 0.6922 - val_mean_squared_error: 0.9503\n",
            "Epoch 550/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.9883 - mean_absolute_error: 0.7025 - mean_squared_error: 0.9883\n",
            "Epoch 550: val_loss improved from 0.94734 to 0.94068, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.9903 - mean_absolute_error: 0.7030 - mean_squared_error: 0.9903 - val_loss: 0.9407 - val_mean_absolute_error: 0.6910 - val_mean_squared_error: 0.9407\n",
            "Epoch 551/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.9740 - mean_absolute_error: 0.6950 - mean_squared_error: 0.9740\n",
            "Epoch 551: val_loss did not improve from 0.94068\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.9779 - mean_absolute_error: 0.6973 - mean_squared_error: 0.9779 - val_loss: 0.9639 - val_mean_absolute_error: 0.6909 - val_mean_squared_error: 0.9639\n",
            "Epoch 552/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.9881 - mean_absolute_error: 0.6996 - mean_squared_error: 0.9881\n",
            "Epoch 552: val_loss did not improve from 0.94068\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9784 - mean_absolute_error: 0.6967 - mean_squared_error: 0.9784 - val_loss: 0.9617 - val_mean_absolute_error: 0.6942 - val_mean_squared_error: 0.9617\n",
            "Epoch 553/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.9728 - mean_absolute_error: 0.6960 - mean_squared_error: 0.9728\n",
            "Epoch 553: val_loss did not improve from 0.94068\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9751 - mean_absolute_error: 0.6972 - mean_squared_error: 0.9751 - val_loss: 0.9424 - val_mean_absolute_error: 0.6885 - val_mean_squared_error: 0.9424\n",
            "Epoch 554/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.9618 - mean_absolute_error: 0.6916 - mean_squared_error: 0.9618\n",
            "Epoch 554: val_loss improved from 0.94068 to 0.92585, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9643 - mean_absolute_error: 0.6922 - mean_squared_error: 0.9643 - val_loss: 0.9258 - val_mean_absolute_error: 0.6815 - val_mean_squared_error: 0.9258\n",
            "Epoch 555/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.9735 - mean_absolute_error: 0.6944 - mean_squared_error: 0.9735\n",
            "Epoch 555: val_loss did not improve from 0.92585\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9662 - mean_absolute_error: 0.6918 - mean_squared_error: 0.9662 - val_loss: 0.9797 - val_mean_absolute_error: 0.6957 - val_mean_squared_error: 0.9797\n",
            "Epoch 556/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.9663 - mean_absolute_error: 0.6914 - mean_squared_error: 0.9663\n",
            "Epoch 556: val_loss did not improve from 0.92585\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9619 - mean_absolute_error: 0.6896 - mean_squared_error: 0.9619 - val_loss: 0.9657 - val_mean_absolute_error: 0.7035 - val_mean_squared_error: 0.9657\n",
            "Epoch 557/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.9613 - mean_absolute_error: 0.6923 - mean_squared_error: 0.9613\n",
            "Epoch 557: val_loss improved from 0.92585 to 0.92345, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9576 - mean_absolute_error: 0.6908 - mean_squared_error: 0.9576 - val_loss: 0.9235 - val_mean_absolute_error: 0.6795 - val_mean_squared_error: 0.9235\n",
            "Epoch 558/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.9514 - mean_absolute_error: 0.6880 - mean_squared_error: 0.9514\n",
            "Epoch 558: val_loss improved from 0.92345 to 0.90242, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9510 - mean_absolute_error: 0.6879 - mean_squared_error: 0.9510 - val_loss: 0.9024 - val_mean_absolute_error: 0.6771 - val_mean_squared_error: 0.9024\n",
            "Epoch 559/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.9477 - mean_absolute_error: 0.6854 - mean_squared_error: 0.9477\n",
            "Epoch 559: val_loss did not improve from 0.90242\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9457 - mean_absolute_error: 0.6847 - mean_squared_error: 0.9457 - val_loss: 0.9061 - val_mean_absolute_error: 0.6763 - val_mean_squared_error: 0.9061\n",
            "Epoch 560/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.9369 - mean_absolute_error: 0.6820 - mean_squared_error: 0.9369\n",
            "Epoch 560: val_loss improved from 0.90242 to 0.89892, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9409 - mean_absolute_error: 0.6837 - mean_squared_error: 0.9409 - val_loss: 0.8989 - val_mean_absolute_error: 0.6752 - val_mean_squared_error: 0.8989\n",
            "Epoch 561/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.9310 - mean_absolute_error: 0.6805 - mean_squared_error: 0.9310\n",
            "Epoch 561: val_loss did not improve from 0.89892\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9289 - mean_absolute_error: 0.6796 - mean_squared_error: 0.9289 - val_loss: 0.9295 - val_mean_absolute_error: 0.6909 - val_mean_squared_error: 0.9295\n",
            "Epoch 562/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.9351 - mean_absolute_error: 0.6830 - mean_squared_error: 0.9351\n",
            "Epoch 562: val_loss improved from 0.89892 to 0.89561, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9283 - mean_absolute_error: 0.6812 - mean_squared_error: 0.9283 - val_loss: 0.8956 - val_mean_absolute_error: 0.6763 - val_mean_squared_error: 0.8956\n",
            "Epoch 563/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.9209 - mean_absolute_error: 0.6767 - mean_squared_error: 0.9209\n",
            "Epoch 563: val_loss did not improve from 0.89561\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9253 - mean_absolute_error: 0.6792 - mean_squared_error: 0.9253 - val_loss: 0.9680 - val_mean_absolute_error: 0.6869 - val_mean_squared_error: 0.9680\n",
            "Epoch 564/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.9207 - mean_absolute_error: 0.6789 - mean_squared_error: 0.9207\n",
            "Epoch 564: val_loss improved from 0.89561 to 0.87986, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9207 - mean_absolute_error: 0.6785 - mean_squared_error: 0.9207 - val_loss: 0.8799 - val_mean_absolute_error: 0.6705 - val_mean_squared_error: 0.8799\n",
            "Epoch 565/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.9110 - mean_absolute_error: 0.6751 - mean_squared_error: 0.9110\n",
            "Epoch 565: val_loss improved from 0.87986 to 0.87498, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9109 - mean_absolute_error: 0.6749 - mean_squared_error: 0.9109 - val_loss: 0.8750 - val_mean_absolute_error: 0.6683 - val_mean_squared_error: 0.8750\n",
            "Epoch 566/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.9046 - mean_absolute_error: 0.6738 - mean_squared_error: 0.9046\n",
            "Epoch 566: val_loss improved from 0.87498 to 0.86858, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.9037 - mean_absolute_error: 0.6734 - mean_squared_error: 0.9037 - val_loss: 0.8686 - val_mean_absolute_error: 0.6670 - val_mean_squared_error: 0.8686\n",
            "Epoch 567/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.9052 - mean_absolute_error: 0.6744 - mean_squared_error: 0.9052\n",
            "Epoch 567: val_loss did not improve from 0.86858\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.9002 - mean_absolute_error: 0.6726 - mean_squared_error: 0.9002 - val_loss: 0.8693 - val_mean_absolute_error: 0.6697 - val_mean_squared_error: 0.8693\n",
            "Epoch 568/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.8978 - mean_absolute_error: 0.6726 - mean_squared_error: 0.8978\n",
            "Epoch 568: val_loss did not improve from 0.86858\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8980 - mean_absolute_error: 0.6731 - mean_squared_error: 0.8980 - val_loss: 0.8898 - val_mean_absolute_error: 0.6686 - val_mean_squared_error: 0.8898\n",
            "Epoch 569/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.8933 - mean_absolute_error: 0.6730 - mean_squared_error: 0.8933\n",
            "Epoch 569: val_loss did not improve from 0.86858\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.8917 - mean_absolute_error: 0.6722 - mean_squared_error: 0.8917 - val_loss: 0.8862 - val_mean_absolute_error: 0.6675 - val_mean_squared_error: 0.8862\n",
            "Epoch 570/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.8751 - mean_absolute_error: 0.6644 - mean_squared_error: 0.8751\n",
            "Epoch 570: val_loss improved from 0.86858 to 0.85440, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.8835 - mean_absolute_error: 0.6679 - mean_squared_error: 0.8835 - val_loss: 0.8544 - val_mean_absolute_error: 0.6614 - val_mean_squared_error: 0.8544\n",
            "Epoch 571/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.8764 - mean_absolute_error: 0.6650 - mean_squared_error: 0.8764\n",
            "Epoch 571: val_loss did not improve from 0.85440\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8779 - mean_absolute_error: 0.6653 - mean_squared_error: 0.8779 - val_loss: 0.8742 - val_mean_absolute_error: 0.6638 - val_mean_squared_error: 0.8742\n",
            "Epoch 572/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.8786 - mean_absolute_error: 0.6673 - mean_squared_error: 0.8786\n",
            "Epoch 572: val_loss improved from 0.85440 to 0.84163, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8721 - mean_absolute_error: 0.6639 - mean_squared_error: 0.8721 - val_loss: 0.8416 - val_mean_absolute_error: 0.6595 - val_mean_squared_error: 0.8416\n",
            "Epoch 573/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.8787 - mean_absolute_error: 0.6676 - mean_squared_error: 0.8787\n",
            "Epoch 573: val_loss did not improve from 0.84163\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8678 - mean_absolute_error: 0.6634 - mean_squared_error: 0.8678 - val_loss: 0.8789 - val_mean_absolute_error: 0.6636 - val_mean_squared_error: 0.8789\n",
            "Epoch 574/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.8714 - mean_absolute_error: 0.6650 - mean_squared_error: 0.8714\n",
            "Epoch 574: val_loss improved from 0.84163 to 0.83638, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8709 - mean_absolute_error: 0.6644 - mean_squared_error: 0.8709 - val_loss: 0.8364 - val_mean_absolute_error: 0.6594 - val_mean_squared_error: 0.8364\n",
            "Epoch 575/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.8653 - mean_absolute_error: 0.6644 - mean_squared_error: 0.8653\n",
            "Epoch 575: val_loss improved from 0.83638 to 0.83290, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.8637 - mean_absolute_error: 0.6622 - mean_squared_error: 0.8637 - val_loss: 0.8329 - val_mean_absolute_error: 0.6547 - val_mean_squared_error: 0.8329\n",
            "Epoch 576/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.8625 - mean_absolute_error: 0.6643 - mean_squared_error: 0.8625\n",
            "Epoch 576: val_loss did not improve from 0.83290\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8558 - mean_absolute_error: 0.6604 - mean_squared_error: 0.8558 - val_loss: 0.8433 - val_mean_absolute_error: 0.6596 - val_mean_squared_error: 0.8433\n",
            "Epoch 577/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.8540 - mean_absolute_error: 0.6612 - mean_squared_error: 0.8540\n",
            "Epoch 577: val_loss improved from 0.83290 to 0.81618, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8489 - mean_absolute_error: 0.6574 - mean_squared_error: 0.8489 - val_loss: 0.8162 - val_mean_absolute_error: 0.6523 - val_mean_squared_error: 0.8162\n",
            "Epoch 578/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.8432 - mean_absolute_error: 0.6572 - mean_squared_error: 0.8432\n",
            "Epoch 578: val_loss did not improve from 0.81618\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.8389 - mean_absolute_error: 0.6562 - mean_squared_error: 0.8389 - val_loss: 0.8193 - val_mean_absolute_error: 0.6514 - val_mean_squared_error: 0.8193\n",
            "Epoch 579/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.8452 - mean_absolute_error: 0.6568 - mean_squared_error: 0.8452\n",
            "Epoch 579: val_loss improved from 0.81618 to 0.81492, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.8452 - mean_absolute_error: 0.6568 - mean_squared_error: 0.8452 - val_loss: 0.8149 - val_mean_absolute_error: 0.6506 - val_mean_squared_error: 0.8149\n",
            "Epoch 580/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.8272 - mean_absolute_error: 0.6517 - mean_squared_error: 0.8272\n",
            "Epoch 580: val_loss improved from 0.81492 to 0.80548, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8287 - mean_absolute_error: 0.6524 - mean_squared_error: 0.8287 - val_loss: 0.8055 - val_mean_absolute_error: 0.6483 - val_mean_squared_error: 0.8055\n",
            "Epoch 581/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.8299 - mean_absolute_error: 0.6565 - mean_squared_error: 0.8299\n",
            "Epoch 581: val_loss improved from 0.80548 to 0.79337, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8265 - mean_absolute_error: 0.6548 - mean_squared_error: 0.8265 - val_loss: 0.7934 - val_mean_absolute_error: 0.6428 - val_mean_squared_error: 0.7934\n",
            "Epoch 582/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.8162 - mean_absolute_error: 0.6492 - mean_squared_error: 0.8162\n",
            "Epoch 582: val_loss improved from 0.79337 to 0.78910, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8162 - mean_absolute_error: 0.6492 - mean_squared_error: 0.8162 - val_loss: 0.7891 - val_mean_absolute_error: 0.6406 - val_mean_squared_error: 0.7891\n",
            "Epoch 583/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.8207 - mean_absolute_error: 0.6508 - mean_squared_error: 0.8207\n",
            "Epoch 583: val_loss improved from 0.78910 to 0.78703, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8176 - mean_absolute_error: 0.6485 - mean_squared_error: 0.8176 - val_loss: 0.7870 - val_mean_absolute_error: 0.6386 - val_mean_squared_error: 0.7870\n",
            "Epoch 584/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.8082 - mean_absolute_error: 0.6458 - mean_squared_error: 0.8082\n",
            "Epoch 584: val_loss improved from 0.78703 to 0.78041, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.8080 - mean_absolute_error: 0.6458 - mean_squared_error: 0.8080 - val_loss: 0.7804 - val_mean_absolute_error: 0.6414 - val_mean_squared_error: 0.7804\n",
            "Epoch 585/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.8130 - mean_absolute_error: 0.6461 - mean_squared_error: 0.8130\n",
            "Epoch 585: val_loss improved from 0.78041 to 0.77778, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.8116 - mean_absolute_error: 0.6455 - mean_squared_error: 0.8116 - val_loss: 0.7778 - val_mean_absolute_error: 0.6387 - val_mean_squared_error: 0.7778\n",
            "Epoch 586/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.7971 - mean_absolute_error: 0.6436 - mean_squared_error: 0.7971\n",
            "Epoch 586: val_loss improved from 0.77778 to 0.77426, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7969 - mean_absolute_error: 0.6432 - mean_squared_error: 0.7969 - val_loss: 0.7743 - val_mean_absolute_error: 0.6410 - val_mean_squared_error: 0.7743\n",
            "Epoch 587/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.7909 - mean_absolute_error: 0.6429 - mean_squared_error: 0.7909\n",
            "Epoch 587: val_loss improved from 0.77426 to 0.77030, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7899 - mean_absolute_error: 0.6421 - mean_squared_error: 0.7899 - val_loss: 0.7703 - val_mean_absolute_error: 0.6345 - val_mean_squared_error: 0.7703\n",
            "Epoch 588/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.7890 - mean_absolute_error: 0.6419 - mean_squared_error: 0.7890\n",
            "Epoch 588: val_loss improved from 0.77030 to 0.76320, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7887 - mean_absolute_error: 0.6417 - mean_squared_error: 0.7887 - val_loss: 0.7632 - val_mean_absolute_error: 0.6306 - val_mean_squared_error: 0.7632\n",
            "Epoch 589/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.7785 - mean_absolute_error: 0.6363 - mean_squared_error: 0.7785\n",
            "Epoch 589: val_loss improved from 0.76320 to 0.76171, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.7794 - mean_absolute_error: 0.6371 - mean_squared_error: 0.7794 - val_loss: 0.7617 - val_mean_absolute_error: 0.6331 - val_mean_squared_error: 0.7617\n",
            "Epoch 590/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.7731 - mean_absolute_error: 0.6360 - mean_squared_error: 0.7731\n",
            "Epoch 590: val_loss improved from 0.76171 to 0.76111, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7755 - mean_absolute_error: 0.6375 - mean_squared_error: 0.7755 - val_loss: 0.7611 - val_mean_absolute_error: 0.6303 - val_mean_squared_error: 0.7611\n",
            "Epoch 591/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.7665 - mean_absolute_error: 0.6314 - mean_squared_error: 0.7665\n",
            "Epoch 591: val_loss did not improve from 0.76111\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7697 - mean_absolute_error: 0.6336 - mean_squared_error: 0.7697 - val_loss: 0.7840 - val_mean_absolute_error: 0.6383 - val_mean_squared_error: 0.7840\n",
            "Epoch 592/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.7649 - mean_absolute_error: 0.6342 - mean_squared_error: 0.7649\n",
            "Epoch 592: val_loss improved from 0.76111 to 0.75093, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7644 - mean_absolute_error: 0.6337 - mean_squared_error: 0.7644 - val_loss: 0.7509 - val_mean_absolute_error: 0.6293 - val_mean_squared_error: 0.7509\n",
            "Epoch 593/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.7538 - mean_absolute_error: 0.6314 - mean_squared_error: 0.7538\n",
            "Epoch 593: val_loss improved from 0.75093 to 0.74501, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.7604 - mean_absolute_error: 0.6338 - mean_squared_error: 0.7604 - val_loss: 0.7450 - val_mean_absolute_error: 0.6271 - val_mean_squared_error: 0.7450\n",
            "Epoch 594/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.7516 - mean_absolute_error: 0.6271 - mean_squared_error: 0.7516\n",
            "Epoch 594: val_loss improved from 0.74501 to 0.73581, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.7516 - mean_absolute_error: 0.6271 - mean_squared_error: 0.7516 - val_loss: 0.7358 - val_mean_absolute_error: 0.6245 - val_mean_squared_error: 0.7358\n",
            "Epoch 595/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.7528 - mean_absolute_error: 0.6301 - mean_squared_error: 0.7528\n",
            "Epoch 595: val_loss improved from 0.73581 to 0.73522, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7501 - mean_absolute_error: 0.6291 - mean_squared_error: 0.7501 - val_loss: 0.7352 - val_mean_absolute_error: 0.6241 - val_mean_squared_error: 0.7352\n",
            "Epoch 596/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.7413 - mean_absolute_error: 0.6256 - mean_squared_error: 0.7413\n",
            "Epoch 596: val_loss improved from 0.73522 to 0.71861, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7448 - mean_absolute_error: 0.6271 - mean_squared_error: 0.7448 - val_loss: 0.7186 - val_mean_absolute_error: 0.6172 - val_mean_squared_error: 0.7186\n",
            "Epoch 597/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.7324 - mean_absolute_error: 0.6222 - mean_squared_error: 0.7324\n",
            "Epoch 597: val_loss did not improve from 0.71861\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7343 - mean_absolute_error: 0.6233 - mean_squared_error: 0.7343 - val_loss: 0.7302 - val_mean_absolute_error: 0.6156 - val_mean_squared_error: 0.7302\n",
            "Epoch 598/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.7316 - mean_absolute_error: 0.6204 - mean_squared_error: 0.7316\n",
            "Epoch 598: val_loss did not improve from 0.71861\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.7313 - mean_absolute_error: 0.6206 - mean_squared_error: 0.7313 - val_loss: 0.7244 - val_mean_absolute_error: 0.6178 - val_mean_squared_error: 0.7244\n",
            "Epoch 599/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.7293 - mean_absolute_error: 0.6222 - mean_squared_error: 0.7293\n",
            "Epoch 599: val_loss improved from 0.71861 to 0.71281, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7247 - mean_absolute_error: 0.6191 - mean_squared_error: 0.7247 - val_loss: 0.7128 - val_mean_absolute_error: 0.6149 - val_mean_squared_error: 0.7128\n",
            "Epoch 600/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.7204 - mean_absolute_error: 0.6179 - mean_squared_error: 0.7204\n",
            "Epoch 600: val_loss improved from 0.71281 to 0.69710, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7230 - mean_absolute_error: 0.6181 - mean_squared_error: 0.7230 - val_loss: 0.6971 - val_mean_absolute_error: 0.6092 - val_mean_squared_error: 0.6971\n",
            "Epoch 601/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.7115 - mean_absolute_error: 0.6148 - mean_squared_error: 0.7115\n",
            "Epoch 601: val_loss did not improve from 0.69710\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.7145 - mean_absolute_error: 0.6156 - mean_squared_error: 0.7145 - val_loss: 0.7308 - val_mean_absolute_error: 0.6229 - val_mean_squared_error: 0.7308\n",
            "Epoch 602/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.7068 - mean_absolute_error: 0.6135 - mean_squared_error: 0.7068\n",
            "Epoch 602: val_loss improved from 0.69710 to 0.68849, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.7086 - mean_absolute_error: 0.6137 - mean_squared_error: 0.7086 - val_loss: 0.6885 - val_mean_absolute_error: 0.6070 - val_mean_squared_error: 0.6885\n",
            "Epoch 603/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.7032 - mean_absolute_error: 0.6126 - mean_squared_error: 0.7032\n",
            "Epoch 603: val_loss improved from 0.68849 to 0.68308, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.7023 - mean_absolute_error: 0.6126 - mean_squared_error: 0.7023 - val_loss: 0.6831 - val_mean_absolute_error: 0.6029 - val_mean_squared_error: 0.6831\n",
            "Epoch 604/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.6996 - mean_absolute_error: 0.6107 - mean_squared_error: 0.6996\n",
            "Epoch 604: val_loss did not improve from 0.68308\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6931 - mean_absolute_error: 0.6070 - mean_squared_error: 0.6931 - val_loss: 0.6893 - val_mean_absolute_error: 0.6062 - val_mean_squared_error: 0.6893\n",
            "Epoch 605/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.6948 - mean_absolute_error: 0.6089 - mean_squared_error: 0.6948\n",
            "Epoch 605: val_loss improved from 0.68308 to 0.68019, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.6938 - mean_absolute_error: 0.6085 - mean_squared_error: 0.6938 - val_loss: 0.6802 - val_mean_absolute_error: 0.6019 - val_mean_squared_error: 0.6802\n",
            "Epoch 606/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.6803 - mean_absolute_error: 0.6035 - mean_squared_error: 0.6803\n",
            "Epoch 606: val_loss did not improve from 0.68019\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6809 - mean_absolute_error: 0.6038 - mean_squared_error: 0.6809 - val_loss: 0.6821 - val_mean_absolute_error: 0.6047 - val_mean_squared_error: 0.6821\n",
            "Epoch 607/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.6767 - mean_absolute_error: 0.6009 - mean_squared_error: 0.6767\n",
            "Epoch 607: val_loss improved from 0.68019 to 0.66545, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6766 - mean_absolute_error: 0.6022 - mean_squared_error: 0.6766 - val_loss: 0.6654 - val_mean_absolute_error: 0.5962 - val_mean_squared_error: 0.6654\n",
            "Epoch 608/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.6648 - mean_absolute_error: 0.5961 - mean_squared_error: 0.6648\n",
            "Epoch 608: val_loss improved from 0.66545 to 0.65681, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6673 - mean_absolute_error: 0.5975 - mean_squared_error: 0.6673 - val_loss: 0.6568 - val_mean_absolute_error: 0.5918 - val_mean_squared_error: 0.6568\n",
            "Epoch 609/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.6652 - mean_absolute_error: 0.5964 - mean_squared_error: 0.6652\n",
            "Epoch 609: val_loss improved from 0.65681 to 0.65425, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6631 - mean_absolute_error: 0.5954 - mean_squared_error: 0.6631 - val_loss: 0.6543 - val_mean_absolute_error: 0.5926 - val_mean_squared_error: 0.6543\n",
            "Epoch 610/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.6551 - mean_absolute_error: 0.5939 - mean_squared_error: 0.6551\n",
            "Epoch 610: val_loss did not improve from 0.65425\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6551 - mean_absolute_error: 0.5939 - mean_squared_error: 0.6551 - val_loss: 0.7017 - val_mean_absolute_error: 0.6129 - val_mean_squared_error: 0.7017\n",
            "Epoch 611/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.6448 - mean_absolute_error: 0.5897 - mean_squared_error: 0.6448\n",
            "Epoch 611: val_loss did not improve from 0.65425\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6465 - mean_absolute_error: 0.5909 - mean_squared_error: 0.6465 - val_loss: 0.6778 - val_mean_absolute_error: 0.6049 - val_mean_squared_error: 0.6778\n",
            "Epoch 612/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.6420 - mean_absolute_error: 0.5888 - mean_squared_error: 0.6420\n",
            "Epoch 612: val_loss improved from 0.65425 to 0.62849, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.6448 - mean_absolute_error: 0.5893 - mean_squared_error: 0.6448 - val_loss: 0.6285 - val_mean_absolute_error: 0.5808 - val_mean_squared_error: 0.6285\n",
            "Epoch 613/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.6422 - mean_absolute_error: 0.5892 - mean_squared_error: 0.6422\n",
            "Epoch 613: val_loss improved from 0.62849 to 0.62026, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.6425 - mean_absolute_error: 0.5894 - mean_squared_error: 0.6425 - val_loss: 0.6203 - val_mean_absolute_error: 0.5759 - val_mean_squared_error: 0.6203\n",
            "Epoch 614/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.6364 - mean_absolute_error: 0.5859 - mean_squared_error: 0.6364\n",
            "Epoch 614: val_loss did not improve from 0.62026\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.6352 - mean_absolute_error: 0.5855 - mean_squared_error: 0.6352 - val_loss: 0.6492 - val_mean_absolute_error: 0.5907 - val_mean_squared_error: 0.6492\n",
            "Epoch 615/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.6254 - mean_absolute_error: 0.5805 - mean_squared_error: 0.6254\n",
            "Epoch 615: val_loss improved from 0.62026 to 0.61218, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.6262 - mean_absolute_error: 0.5813 - mean_squared_error: 0.6262 - val_loss: 0.6122 - val_mean_absolute_error: 0.5736 - val_mean_squared_error: 0.6122\n",
            "Epoch 616/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.6166 - mean_absolute_error: 0.5775 - mean_squared_error: 0.6166\n",
            "Epoch 616: val_loss improved from 0.61218 to 0.60645, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6132 - mean_absolute_error: 0.5760 - mean_squared_error: 0.6132 - val_loss: 0.6065 - val_mean_absolute_error: 0.5719 - val_mean_squared_error: 0.6065\n",
            "Epoch 617/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.6110 - mean_absolute_error: 0.5769 - mean_squared_error: 0.6110\n",
            "Epoch 617: val_loss did not improve from 0.60645\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6091 - mean_absolute_error: 0.5760 - mean_squared_error: 0.6091 - val_loss: 0.6139 - val_mean_absolute_error: 0.5727 - val_mean_squared_error: 0.6139\n",
            "Epoch 618/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.6102 - mean_absolute_error: 0.5766 - mean_squared_error: 0.6102\n",
            "Epoch 618: val_loss improved from 0.60645 to 0.60001, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.6078 - mean_absolute_error: 0.5749 - mean_squared_error: 0.6078 - val_loss: 0.6000 - val_mean_absolute_error: 0.5683 - val_mean_squared_error: 0.6000\n",
            "Epoch 619/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.6012 - mean_absolute_error: 0.5718 - mean_squared_error: 0.6012\n",
            "Epoch 619: val_loss improved from 0.60001 to 0.59008, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5993 - mean_absolute_error: 0.5709 - mean_squared_error: 0.5993 - val_loss: 0.5901 - val_mean_absolute_error: 0.5640 - val_mean_squared_error: 0.5901\n",
            "Epoch 620/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.5923 - mean_absolute_error: 0.5679 - mean_squared_error: 0.5923\n",
            "Epoch 620: val_loss did not improve from 0.59008\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5954 - mean_absolute_error: 0.5689 - mean_squared_error: 0.5954 - val_loss: 0.6087 - val_mean_absolute_error: 0.5667 - val_mean_squared_error: 0.6087\n",
            "Epoch 621/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.5806 - mean_absolute_error: 0.5612 - mean_squared_error: 0.5806\n",
            "Epoch 621: val_loss improved from 0.59008 to 0.58209, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5831 - mean_absolute_error: 0.5616 - mean_squared_error: 0.5831 - val_loss: 0.5821 - val_mean_absolute_error: 0.5608 - val_mean_squared_error: 0.5821\n",
            "Epoch 622/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.5948 - mean_absolute_error: 0.5675 - mean_squared_error: 0.5948\n",
            "Epoch 622: val_loss did not improve from 0.58209\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.5931 - mean_absolute_error: 0.5665 - mean_squared_error: 0.5931 - val_loss: 0.5937 - val_mean_absolute_error: 0.5693 - val_mean_squared_error: 0.5937\n",
            "Epoch 623/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.5687 - mean_absolute_error: 0.5585 - mean_squared_error: 0.5687\n",
            "Epoch 623: val_loss did not improve from 0.58209\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5714 - mean_absolute_error: 0.5599 - mean_squared_error: 0.5714 - val_loss: 0.5953 - val_mean_absolute_error: 0.5591 - val_mean_squared_error: 0.5953\n",
            "Epoch 624/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.5676 - mean_absolute_error: 0.5559 - mean_squared_error: 0.5676\n",
            "Epoch 624: val_loss did not improve from 0.58209\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5678 - mean_absolute_error: 0.5558 - mean_squared_error: 0.5678 - val_loss: 0.5884 - val_mean_absolute_error: 0.5612 - val_mean_squared_error: 0.5884\n",
            "Epoch 625/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.5587 - mean_absolute_error: 0.5513 - mean_squared_error: 0.5587\n",
            "Epoch 625: val_loss improved from 0.58209 to 0.56197, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5595 - mean_absolute_error: 0.5517 - mean_squared_error: 0.5595 - val_loss: 0.5620 - val_mean_absolute_error: 0.5500 - val_mean_squared_error: 0.5620\n",
            "Epoch 626/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.5564 - mean_absolute_error: 0.5520 - mean_squared_error: 0.5564\n",
            "Epoch 626: val_loss improved from 0.56197 to 0.54738, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5581 - mean_absolute_error: 0.5528 - mean_squared_error: 0.5581 - val_loss: 0.5474 - val_mean_absolute_error: 0.5436 - val_mean_squared_error: 0.5474\n",
            "Epoch 627/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.5511 - mean_absolute_error: 0.5481 - mean_squared_error: 0.5511\n",
            "Epoch 627: val_loss did not improve from 0.54738\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5509 - mean_absolute_error: 0.5494 - mean_squared_error: 0.5509 - val_loss: 0.5508 - val_mean_absolute_error: 0.5469 - val_mean_squared_error: 0.5508\n",
            "Epoch 628/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.5418 - mean_absolute_error: 0.5452 - mean_squared_error: 0.5418\n",
            "Epoch 628: val_loss did not improve from 0.54738\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5414 - mean_absolute_error: 0.5449 - mean_squared_error: 0.5414 - val_loss: 0.5587 - val_mean_absolute_error: 0.5483 - val_mean_squared_error: 0.5587\n",
            "Epoch 629/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.5409 - mean_absolute_error: 0.5440 - mean_squared_error: 0.5409\n",
            "Epoch 629: val_loss improved from 0.54738 to 0.53203, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5400 - mean_absolute_error: 0.5433 - mean_squared_error: 0.5400 - val_loss: 0.5320 - val_mean_absolute_error: 0.5349 - val_mean_squared_error: 0.5320\n",
            "Epoch 630/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.5401 - mean_absolute_error: 0.5422 - mean_squared_error: 0.5401\n",
            "Epoch 630: val_loss did not improve from 0.53203\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5394 - mean_absolute_error: 0.5419 - mean_squared_error: 0.5394 - val_loss: 0.5520 - val_mean_absolute_error: 0.5457 - val_mean_squared_error: 0.5520\n",
            "Epoch 631/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.5251 - mean_absolute_error: 0.5361 - mean_squared_error: 0.5251\n",
            "Epoch 631: val_loss did not improve from 0.53203\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5264 - mean_absolute_error: 0.5370 - mean_squared_error: 0.5264 - val_loss: 0.5356 - val_mean_absolute_error: 0.5383 - val_mean_squared_error: 0.5356\n",
            "Epoch 632/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.5233 - mean_absolute_error: 0.5333 - mean_squared_error: 0.5233\n",
            "Epoch 632: val_loss did not improve from 0.53203\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5263 - mean_absolute_error: 0.5349 - mean_squared_error: 0.5263 - val_loss: 0.5456 - val_mean_absolute_error: 0.5409 - val_mean_squared_error: 0.5456\n",
            "Epoch 633/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.5080 - mean_absolute_error: 0.5279 - mean_squared_error: 0.5080\n",
            "Epoch 633: val_loss improved from 0.53203 to 0.52065, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5124 - mean_absolute_error: 0.5307 - mean_squared_error: 0.5124 - val_loss: 0.5206 - val_mean_absolute_error: 0.5308 - val_mean_squared_error: 0.5206\n",
            "Epoch 634/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.5158 - mean_absolute_error: 0.5315 - mean_squared_error: 0.5158\n",
            "Epoch 634: val_loss improved from 0.52065 to 0.50755, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.5148 - mean_absolute_error: 0.5307 - mean_squared_error: 0.5148 - val_loss: 0.5076 - val_mean_absolute_error: 0.5240 - val_mean_squared_error: 0.5076\n",
            "Epoch 635/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.5041 - mean_absolute_error: 0.5259 - mean_squared_error: 0.5041\n",
            "Epoch 635: val_loss did not improve from 0.50755\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5041 - mean_absolute_error: 0.5263 - mean_squared_error: 0.5041 - val_loss: 0.5116 - val_mean_absolute_error: 0.5242 - val_mean_squared_error: 0.5116\n",
            "Epoch 636/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.5097 - mean_absolute_error: 0.5289 - mean_squared_error: 0.5097\n",
            "Epoch 636: val_loss improved from 0.50755 to 0.50630, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5069 - mean_absolute_error: 0.5263 - mean_squared_error: 0.5069 - val_loss: 0.5063 - val_mean_absolute_error: 0.5227 - val_mean_squared_error: 0.5063\n",
            "Epoch 637/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.4876 - mean_absolute_error: 0.5167 - mean_squared_error: 0.4876\n",
            "Epoch 637: val_loss improved from 0.50630 to 0.50432, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4936 - mean_absolute_error: 0.5208 - mean_squared_error: 0.4936 - val_loss: 0.5043 - val_mean_absolute_error: 0.5205 - val_mean_squared_error: 0.5043\n",
            "Epoch 638/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.4887 - mean_absolute_error: 0.5155 - mean_squared_error: 0.4887\n",
            "Epoch 638: val_loss did not improve from 0.50432\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4900 - mean_absolute_error: 0.5167 - mean_squared_error: 0.4900 - val_loss: 0.5189 - val_mean_absolute_error: 0.5286 - val_mean_squared_error: 0.5189\n",
            "Epoch 639/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.4925 - mean_absolute_error: 0.5194 - mean_squared_error: 0.4925\n",
            "Epoch 639: val_loss improved from 0.50432 to 0.49733, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4905 - mean_absolute_error: 0.5183 - mean_squared_error: 0.4905 - val_loss: 0.4973 - val_mean_absolute_error: 0.5190 - val_mean_squared_error: 0.4973\n",
            "Epoch 640/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.4768 - mean_absolute_error: 0.5104 - mean_squared_error: 0.4768\n",
            "Epoch 640: val_loss improved from 0.49733 to 0.48764, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4775 - mean_absolute_error: 0.5111 - mean_squared_error: 0.4775 - val_loss: 0.4876 - val_mean_absolute_error: 0.5117 - val_mean_squared_error: 0.4876\n",
            "Epoch 641/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.4816 - mean_absolute_error: 0.5134 - mean_squared_error: 0.4816\n",
            "Epoch 641: val_loss improved from 0.48764 to 0.47581, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.4806 - mean_absolute_error: 0.5126 - mean_squared_error: 0.4806 - val_loss: 0.4758 - val_mean_absolute_error: 0.5072 - val_mean_squared_error: 0.4758\n",
            "Epoch 642/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.4698 - mean_absolute_error: 0.5083 - mean_squared_error: 0.4698\n",
            "Epoch 642: val_loss did not improve from 0.47581\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4706 - mean_absolute_error: 0.5086 - mean_squared_error: 0.4706 - val_loss: 0.4976 - val_mean_absolute_error: 0.5205 - val_mean_squared_error: 0.4976\n",
            "Epoch 643/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.4695 - mean_absolute_error: 0.5065 - mean_squared_error: 0.4695\n",
            "Epoch 643: val_loss did not improve from 0.47581\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4699 - mean_absolute_error: 0.5065 - mean_squared_error: 0.4699 - val_loss: 0.4877 - val_mean_absolute_error: 0.5116 - val_mean_squared_error: 0.4877\n",
            "Epoch 644/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.4596 - mean_absolute_error: 0.5012 - mean_squared_error: 0.4596\n",
            "Epoch 644: val_loss improved from 0.47581 to 0.47322, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4610 - mean_absolute_error: 0.5019 - mean_squared_error: 0.4610 - val_loss: 0.4732 - val_mean_absolute_error: 0.5085 - val_mean_squared_error: 0.4732\n",
            "Epoch 645/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.4589 - mean_absolute_error: 0.5011 - mean_squared_error: 0.4589\n",
            "Epoch 645: val_loss improved from 0.47322 to 0.45651, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.4583 - mean_absolute_error: 0.5005 - mean_squared_error: 0.4583 - val_loss: 0.4565 - val_mean_absolute_error: 0.4955 - val_mean_squared_error: 0.4565\n",
            "Epoch 646/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.4545 - mean_absolute_error: 0.4988 - mean_squared_error: 0.4545\n",
            "Epoch 646: val_loss improved from 0.45651 to 0.45512, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4544 - mean_absolute_error: 0.4988 - mean_squared_error: 0.4544 - val_loss: 0.4551 - val_mean_absolute_error: 0.4934 - val_mean_squared_error: 0.4551\n",
            "Epoch 647/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.4501 - mean_absolute_error: 0.4964 - mean_squared_error: 0.4501\n",
            "Epoch 647: val_loss improved from 0.45512 to 0.44918, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4461 - mean_absolute_error: 0.4941 - mean_squared_error: 0.4461 - val_loss: 0.4492 - val_mean_absolute_error: 0.4886 - val_mean_squared_error: 0.4492\n",
            "Epoch 648/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.4498 - mean_absolute_error: 0.4961 - mean_squared_error: 0.4498\n",
            "Epoch 648: val_loss did not improve from 0.44918\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4485 - mean_absolute_error: 0.4945 - mean_squared_error: 0.4485 - val_loss: 0.4492 - val_mean_absolute_error: 0.4894 - val_mean_squared_error: 0.4492\n",
            "Epoch 649/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.4393 - mean_absolute_error: 0.4899 - mean_squared_error: 0.4393\n",
            "Epoch 649: val_loss did not improve from 0.44918\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4373 - mean_absolute_error: 0.4892 - mean_squared_error: 0.4373 - val_loss: 0.5068 - val_mean_absolute_error: 0.5228 - val_mean_squared_error: 0.5068\n",
            "Epoch 650/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.4335 - mean_absolute_error: 0.4856 - mean_squared_error: 0.4335\n",
            "Epoch 650: val_loss improved from 0.44918 to 0.43794, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4329 - mean_absolute_error: 0.4847 - mean_squared_error: 0.4329 - val_loss: 0.4379 - val_mean_absolute_error: 0.4835 - val_mean_squared_error: 0.4379\n",
            "Epoch 651/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.4293 - mean_absolute_error: 0.4823 - mean_squared_error: 0.4293\n",
            "Epoch 651: val_loss did not improve from 0.43794\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4293 - mean_absolute_error: 0.4823 - mean_squared_error: 0.4293 - val_loss: 0.4415 - val_mean_absolute_error: 0.4863 - val_mean_squared_error: 0.4415\n",
            "Epoch 652/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.4234 - mean_absolute_error: 0.4816 - mean_squared_error: 0.4234\n",
            "Epoch 652: val_loss did not improve from 0.43794\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4247 - mean_absolute_error: 0.4820 - mean_squared_error: 0.4247 - val_loss: 0.4476 - val_mean_absolute_error: 0.4884 - val_mean_squared_error: 0.4476\n",
            "Epoch 653/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.4170 - mean_absolute_error: 0.4751 - mean_squared_error: 0.4170\n",
            "Epoch 653: val_loss improved from 0.43794 to 0.42831, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4181 - mean_absolute_error: 0.4762 - mean_squared_error: 0.4181 - val_loss: 0.4283 - val_mean_absolute_error: 0.4790 - val_mean_squared_error: 0.4283\n",
            "Epoch 654/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.4173 - mean_absolute_error: 0.4770 - mean_squared_error: 0.4173\n",
            "Epoch 654: val_loss did not improve from 0.42831\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4175 - mean_absolute_error: 0.4772 - mean_squared_error: 0.4175 - val_loss: 0.4301 - val_mean_absolute_error: 0.4806 - val_mean_squared_error: 0.4301\n",
            "Epoch 655/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.4049 - mean_absolute_error: 0.4732 - mean_squared_error: 0.4049\n",
            "Epoch 655: val_loss did not improve from 0.42831\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4098 - mean_absolute_error: 0.4758 - mean_squared_error: 0.4098 - val_loss: 0.4660 - val_mean_absolute_error: 0.4925 - val_mean_squared_error: 0.4660\n",
            "Epoch 656/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.4120 - mean_absolute_error: 0.4724 - mean_squared_error: 0.4120\n",
            "Epoch 656: val_loss improved from 0.42831 to 0.40949, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4112 - mean_absolute_error: 0.4720 - mean_squared_error: 0.4112 - val_loss: 0.4095 - val_mean_absolute_error: 0.4673 - val_mean_squared_error: 0.4095\n",
            "Epoch 657/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.4015 - mean_absolute_error: 0.4684 - mean_squared_error: 0.4015\n",
            "Epoch 657: val_loss improved from 0.40949 to 0.40905, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4030 - mean_absolute_error: 0.4699 - mean_squared_error: 0.4030 - val_loss: 0.4091 - val_mean_absolute_error: 0.4682 - val_mean_squared_error: 0.4091\n",
            "Epoch 658/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.4008 - mean_absolute_error: 0.4661 - mean_squared_error: 0.4008\n",
            "Epoch 658: val_loss improved from 0.40905 to 0.40652, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4006 - mean_absolute_error: 0.4661 - mean_squared_error: 0.4006 - val_loss: 0.4065 - val_mean_absolute_error: 0.4678 - val_mean_squared_error: 0.4065\n",
            "Epoch 659/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.3936 - mean_absolute_error: 0.4614 - mean_squared_error: 0.3936\n",
            "Epoch 659: val_loss did not improve from 0.40652\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3930 - mean_absolute_error: 0.4616 - mean_squared_error: 0.3930 - val_loss: 0.4078 - val_mean_absolute_error: 0.4656 - val_mean_squared_error: 0.4078\n",
            "Epoch 660/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.3866 - mean_absolute_error: 0.4591 - mean_squared_error: 0.3866\n",
            "Epoch 660: val_loss improved from 0.40652 to 0.39802, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3860 - mean_absolute_error: 0.4584 - mean_squared_error: 0.3860 - val_loss: 0.3980 - val_mean_absolute_error: 0.4594 - val_mean_squared_error: 0.3980\n",
            "Epoch 661/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.3875 - mean_absolute_error: 0.4601 - mean_squared_error: 0.3875\n",
            "Epoch 661: val_loss improved from 0.39802 to 0.39483, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.3860 - mean_absolute_error: 0.4590 - mean_squared_error: 0.3860 - val_loss: 0.3948 - val_mean_absolute_error: 0.4578 - val_mean_squared_error: 0.3948\n",
            "Epoch 662/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.3876 - mean_absolute_error: 0.4569 - mean_squared_error: 0.3876\n",
            "Epoch 662: val_loss improved from 0.39483 to 0.38968, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3866 - mean_absolute_error: 0.4568 - mean_squared_error: 0.3866 - val_loss: 0.3897 - val_mean_absolute_error: 0.4571 - val_mean_squared_error: 0.3897\n",
            "Epoch 663/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.3760 - mean_absolute_error: 0.4535 - mean_squared_error: 0.3760\n",
            "Epoch 663: val_loss did not improve from 0.38968\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.3786 - mean_absolute_error: 0.4545 - mean_squared_error: 0.3786 - val_loss: 0.3995 - val_mean_absolute_error: 0.4618 - val_mean_squared_error: 0.3995\n",
            "Epoch 664/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.3658 - mean_absolute_error: 0.4478 - mean_squared_error: 0.3658\n",
            "Epoch 664: val_loss improved from 0.38968 to 0.38391, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3647 - mean_absolute_error: 0.4466 - mean_squared_error: 0.3647 - val_loss: 0.3839 - val_mean_absolute_error: 0.4505 - val_mean_squared_error: 0.3839\n",
            "Epoch 665/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.3621 - mean_absolute_error: 0.4432 - mean_squared_error: 0.3621\n",
            "Epoch 665: val_loss improved from 0.38391 to 0.37255, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3621 - mean_absolute_error: 0.4432 - mean_squared_error: 0.3621 - val_loss: 0.3725 - val_mean_absolute_error: 0.4449 - val_mean_squared_error: 0.3725\n",
            "Epoch 666/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.3578 - mean_absolute_error: 0.4415 - mean_squared_error: 0.3578\n",
            "Epoch 666: val_loss did not improve from 0.37255\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3588 - mean_absolute_error: 0.4421 - mean_squared_error: 0.3588 - val_loss: 0.3829 - val_mean_absolute_error: 0.4518 - val_mean_squared_error: 0.3829\n",
            "Epoch 667/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.3662 - mean_absolute_error: 0.4458 - mean_squared_error: 0.3662\n",
            "Epoch 667: val_loss improved from 0.37255 to 0.36713, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3641 - mean_absolute_error: 0.4445 - mean_squared_error: 0.3641 - val_loss: 0.3671 - val_mean_absolute_error: 0.4414 - val_mean_squared_error: 0.3671\n",
            "Epoch 668/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.3481 - mean_absolute_error: 0.4349 - mean_squared_error: 0.3481\n",
            "Epoch 668: val_loss did not improve from 0.36713\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3445 - mean_absolute_error: 0.4330 - mean_squared_error: 0.3445 - val_loss: 0.3826 - val_mean_absolute_error: 0.4513 - val_mean_squared_error: 0.3826\n",
            "Epoch 669/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.3400 - mean_absolute_error: 0.4293 - mean_squared_error: 0.3400\n",
            "Epoch 669: val_loss did not improve from 0.36713\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3422 - mean_absolute_error: 0.4303 - mean_squared_error: 0.3422 - val_loss: 0.3966 - val_mean_absolute_error: 0.4538 - val_mean_squared_error: 0.3966\n",
            "Epoch 670/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.3364 - mean_absolute_error: 0.4262 - mean_squared_error: 0.3364\n",
            "Epoch 670: val_loss improved from 0.36713 to 0.34714, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.3357 - mean_absolute_error: 0.4260 - mean_squared_error: 0.3357 - val_loss: 0.3471 - val_mean_absolute_error: 0.4309 - val_mean_squared_error: 0.3471\n",
            "Epoch 671/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.3290 - mean_absolute_error: 0.4226 - mean_squared_error: 0.3290\n",
            "Epoch 671: val_loss improved from 0.34714 to 0.34528, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3286 - mean_absolute_error: 0.4225 - mean_squared_error: 0.3286 - val_loss: 0.3453 - val_mean_absolute_error: 0.4285 - val_mean_squared_error: 0.3453\n",
            "Epoch 672/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.3280 - mean_absolute_error: 0.4218 - mean_squared_error: 0.3280\n",
            "Epoch 672: val_loss did not improve from 0.34528\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.3277 - mean_absolute_error: 0.4215 - mean_squared_error: 0.3277 - val_loss: 0.3538 - val_mean_absolute_error: 0.4328 - val_mean_squared_error: 0.3538\n",
            "Epoch 673/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.3179 - mean_absolute_error: 0.4145 - mean_squared_error: 0.3179\n",
            "Epoch 673: val_loss did not improve from 0.34528\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3202 - mean_absolute_error: 0.4166 - mean_squared_error: 0.3202 - val_loss: 0.3498 - val_mean_absolute_error: 0.4305 - val_mean_squared_error: 0.3498\n",
            "Epoch 674/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.3228 - mean_absolute_error: 0.4166 - mean_squared_error: 0.3228\n",
            "Epoch 674: val_loss improved from 0.34528 to 0.34028, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3247 - mean_absolute_error: 0.4177 - mean_squared_error: 0.3247 - val_loss: 0.3403 - val_mean_absolute_error: 0.4232 - val_mean_squared_error: 0.3403\n",
            "Epoch 675/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.3091 - mean_absolute_error: 0.4091 - mean_squared_error: 0.3091\n",
            "Epoch 675: val_loss did not improve from 0.34028\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3092 - mean_absolute_error: 0.4093 - mean_squared_error: 0.3092 - val_loss: 0.3462 - val_mean_absolute_error: 0.4235 - val_mean_squared_error: 0.3462\n",
            "Epoch 676/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.3049 - mean_absolute_error: 0.4046 - mean_squared_error: 0.3049\n",
            "Epoch 676: val_loss improved from 0.34028 to 0.31784, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3062 - mean_absolute_error: 0.4059 - mean_squared_error: 0.3062 - val_loss: 0.3178 - val_mean_absolute_error: 0.4070 - val_mean_squared_error: 0.3178\n",
            "Epoch 677/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.2982 - mean_absolute_error: 0.4006 - mean_squared_error: 0.2982\n",
            "Epoch 677: val_loss did not improve from 0.31784\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.2981 - mean_absolute_error: 0.4005 - mean_squared_error: 0.2981 - val_loss: 0.3709 - val_mean_absolute_error: 0.4389 - val_mean_squared_error: 0.3709\n",
            "Epoch 678/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.2927 - mean_absolute_error: 0.3968 - mean_squared_error: 0.2927\n",
            "Epoch 678: val_loss did not improve from 0.31784\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.2934 - mean_absolute_error: 0.3973 - mean_squared_error: 0.2934 - val_loss: 0.3243 - val_mean_absolute_error: 0.4143 - val_mean_squared_error: 0.3243\n",
            "Epoch 679/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.2887 - mean_absolute_error: 0.3941 - mean_squared_error: 0.2887\n",
            "Epoch 679: val_loss did not improve from 0.31784\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.2884 - mean_absolute_error: 0.3939 - mean_squared_error: 0.2884 - val_loss: 0.3530 - val_mean_absolute_error: 0.4306 - val_mean_squared_error: 0.3530\n",
            "Epoch 680/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.2831 - mean_absolute_error: 0.3913 - mean_squared_error: 0.2831\n",
            "Epoch 680: val_loss improved from 0.31784 to 0.30255, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2847 - mean_absolute_error: 0.3926 - mean_squared_error: 0.2847 - val_loss: 0.3026 - val_mean_absolute_error: 0.3999 - val_mean_squared_error: 0.3026\n",
            "Epoch 681/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.2800 - mean_absolute_error: 0.3874 - mean_squared_error: 0.2800\n",
            "Epoch 681: val_loss improved from 0.30255 to 0.29547, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2785 - mean_absolute_error: 0.3868 - mean_squared_error: 0.2785 - val_loss: 0.2955 - val_mean_absolute_error: 0.3944 - val_mean_squared_error: 0.2955\n",
            "Epoch 682/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.2748 - mean_absolute_error: 0.3839 - mean_squared_error: 0.2748\n",
            "Epoch 682: val_loss did not improve from 0.29547\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.2750 - mean_absolute_error: 0.3843 - mean_squared_error: 0.2750 - val_loss: 0.2978 - val_mean_absolute_error: 0.3944 - val_mean_squared_error: 0.2978\n",
            "Epoch 683/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.2676 - mean_absolute_error: 0.3791 - mean_squared_error: 0.2676\n",
            "Epoch 683: val_loss improved from 0.29547 to 0.28422, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2676 - mean_absolute_error: 0.3790 - mean_squared_error: 0.2676 - val_loss: 0.2842 - val_mean_absolute_error: 0.3859 - val_mean_squared_error: 0.2842\n",
            "Epoch 684/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.2668 - mean_absolute_error: 0.3779 - mean_squared_error: 0.2668\n",
            "Epoch 684: val_loss did not improve from 0.28422\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2668 - mean_absolute_error: 0.3785 - mean_squared_error: 0.2668 - val_loss: 0.2848 - val_mean_absolute_error: 0.3870 - val_mean_squared_error: 0.2848\n",
            "Epoch 685/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.2660 - mean_absolute_error: 0.3762 - mean_squared_error: 0.2660\n",
            "Epoch 685: val_loss improved from 0.28422 to 0.27559, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2656 - mean_absolute_error: 0.3761 - mean_squared_error: 0.2656 - val_loss: 0.2756 - val_mean_absolute_error: 0.3797 - val_mean_squared_error: 0.2756\n",
            "Epoch 686/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.2582 - mean_absolute_error: 0.3710 - mean_squared_error: 0.2582\n",
            "Epoch 686: val_loss improved from 0.27559 to 0.26899, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2580 - mean_absolute_error: 0.3711 - mean_squared_error: 0.2580 - val_loss: 0.2690 - val_mean_absolute_error: 0.3785 - val_mean_squared_error: 0.2690\n",
            "Epoch 687/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.2533 - mean_absolute_error: 0.3683 - mean_squared_error: 0.2533\n",
            "Epoch 687: val_loss improved from 0.26899 to 0.26583, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.2512 - mean_absolute_error: 0.3666 - mean_squared_error: 0.2512 - val_loss: 0.2658 - val_mean_absolute_error: 0.3705 - val_mean_squared_error: 0.2658\n",
            "Epoch 688/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.2492 - mean_absolute_error: 0.3635 - mean_squared_error: 0.2492\n",
            "Epoch 688: val_loss improved from 0.26583 to 0.26053, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2499 - mean_absolute_error: 0.3638 - mean_squared_error: 0.2499 - val_loss: 0.2605 - val_mean_absolute_error: 0.3672 - val_mean_squared_error: 0.2605\n",
            "Epoch 689/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.2437 - mean_absolute_error: 0.3605 - mean_squared_error: 0.2437\n",
            "Epoch 689: val_loss improved from 0.26053 to 0.25625, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2447 - mean_absolute_error: 0.3616 - mean_squared_error: 0.2447 - val_loss: 0.2562 - val_mean_absolute_error: 0.3662 - val_mean_squared_error: 0.2562\n",
            "Epoch 690/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.2399 - mean_absolute_error: 0.3562 - mean_squared_error: 0.2399\n",
            "Epoch 690: val_loss improved from 0.25625 to 0.25461, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2414 - mean_absolute_error: 0.3575 - mean_squared_error: 0.2414 - val_loss: 0.2546 - val_mean_absolute_error: 0.3662 - val_mean_squared_error: 0.2546\n",
            "Epoch 691/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.2377 - mean_absolute_error: 0.3556 - mean_squared_error: 0.2377\n",
            "Epoch 691: val_loss improved from 0.25461 to 0.24903, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2377 - mean_absolute_error: 0.3556 - mean_squared_error: 0.2377 - val_loss: 0.2490 - val_mean_absolute_error: 0.3612 - val_mean_squared_error: 0.2490\n",
            "Epoch 692/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.2320 - mean_absolute_error: 0.3509 - mean_squared_error: 0.2320\n",
            "Epoch 692: val_loss improved from 0.24903 to 0.24378, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.2311 - mean_absolute_error: 0.3506 - mean_squared_error: 0.2311 - val_loss: 0.2438 - val_mean_absolute_error: 0.3571 - val_mean_squared_error: 0.2438\n",
            "Epoch 693/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.2280 - mean_absolute_error: 0.3456 - mean_squared_error: 0.2280\n",
            "Epoch 693: val_loss did not improve from 0.24378\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2283 - mean_absolute_error: 0.3459 - mean_squared_error: 0.2283 - val_loss: 0.2591 - val_mean_absolute_error: 0.3697 - val_mean_squared_error: 0.2591\n",
            "Epoch 694/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.2252 - mean_absolute_error: 0.3457 - mean_squared_error: 0.2252\n",
            "Epoch 694: val_loss improved from 0.24378 to 0.23869, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2248 - mean_absolute_error: 0.3447 - mean_squared_error: 0.2248 - val_loss: 0.2387 - val_mean_absolute_error: 0.3549 - val_mean_squared_error: 0.2387\n",
            "Epoch 695/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.2239 - mean_absolute_error: 0.3450 - mean_squared_error: 0.2239\n",
            "Epoch 695: val_loss improved from 0.23869 to 0.23729, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2223 - mean_absolute_error: 0.3435 - mean_squared_error: 0.2223 - val_loss: 0.2373 - val_mean_absolute_error: 0.3491 - val_mean_squared_error: 0.2373\n",
            "Epoch 696/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.2182 - mean_absolute_error: 0.3398 - mean_squared_error: 0.2182\n",
            "Epoch 696: val_loss improved from 0.23729 to 0.23713, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2188 - mean_absolute_error: 0.3403 - mean_squared_error: 0.2188 - val_loss: 0.2371 - val_mean_absolute_error: 0.3532 - val_mean_squared_error: 0.2371\n",
            "Epoch 697/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.2166 - mean_absolute_error: 0.3380 - mean_squared_error: 0.2166\n",
            "Epoch 697: val_loss improved from 0.23713 to 0.23371, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2164 - mean_absolute_error: 0.3375 - mean_squared_error: 0.2164 - val_loss: 0.2337 - val_mean_absolute_error: 0.3513 - val_mean_squared_error: 0.2337\n",
            "Epoch 698/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.2108 - mean_absolute_error: 0.3330 - mean_squared_error: 0.2108\n",
            "Epoch 698: val_loss improved from 0.23371 to 0.22814, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2108 - mean_absolute_error: 0.3330 - mean_squared_error: 0.2108 - val_loss: 0.2281 - val_mean_absolute_error: 0.3452 - val_mean_squared_error: 0.2281\n",
            "Epoch 699/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.2129 - mean_absolute_error: 0.3329 - mean_squared_error: 0.2129\n",
            "Epoch 699: val_loss did not improve from 0.22814\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2129 - mean_absolute_error: 0.3333 - mean_squared_error: 0.2129 - val_loss: 0.2316 - val_mean_absolute_error: 0.3448 - val_mean_squared_error: 0.2316\n",
            "Epoch 700/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.2063 - mean_absolute_error: 0.3287 - mean_squared_error: 0.2063\n",
            "Epoch 700: val_loss improved from 0.22814 to 0.22181, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2056 - mean_absolute_error: 0.3278 - mean_squared_error: 0.2056 - val_loss: 0.2218 - val_mean_absolute_error: 0.3368 - val_mean_squared_error: 0.2218\n",
            "Epoch 701/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.2044 - mean_absolute_error: 0.3280 - mean_squared_error: 0.2044\n",
            "Epoch 701: val_loss improved from 0.22181 to 0.21735, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2013 - mean_absolute_error: 0.3254 - mean_squared_error: 0.2013 - val_loss: 0.2174 - val_mean_absolute_error: 0.3336 - val_mean_squared_error: 0.2174\n",
            "Epoch 702/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.2021 - mean_absolute_error: 0.3251 - mean_squared_error: 0.2021\n",
            "Epoch 702: val_loss improved from 0.21735 to 0.21231, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2024 - mean_absolute_error: 0.3255 - mean_squared_error: 0.2024 - val_loss: 0.2123 - val_mean_absolute_error: 0.3288 - val_mean_squared_error: 0.2123\n",
            "Epoch 703/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.1989 - mean_absolute_error: 0.3213 - mean_squared_error: 0.1989\n",
            "Epoch 703: val_loss improved from 0.21231 to 0.21213, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1981 - mean_absolute_error: 0.3212 - mean_squared_error: 0.1981 - val_loss: 0.2121 - val_mean_absolute_error: 0.3299 - val_mean_squared_error: 0.2121\n",
            "Epoch 704/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.1919 - mean_absolute_error: 0.3165 - mean_squared_error: 0.1919\n",
            "Epoch 704: val_loss did not improve from 0.21213\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1941 - mean_absolute_error: 0.3181 - mean_squared_error: 0.1941 - val_loss: 0.2166 - val_mean_absolute_error: 0.3347 - val_mean_squared_error: 0.2166\n",
            "Epoch 705/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.1935 - mean_absolute_error: 0.3173 - mean_squared_error: 0.1935\n",
            "Epoch 705: val_loss improved from 0.21213 to 0.20976, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1944 - mean_absolute_error: 0.3183 - mean_squared_error: 0.1944 - val_loss: 0.2098 - val_mean_absolute_error: 0.3283 - val_mean_squared_error: 0.2098\n",
            "Epoch 706/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.1924 - mean_absolute_error: 0.3152 - mean_squared_error: 0.1924\n",
            "Epoch 706: val_loss improved from 0.20976 to 0.20795, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1924 - mean_absolute_error: 0.3152 - mean_squared_error: 0.1924 - val_loss: 0.2079 - val_mean_absolute_error: 0.3270 - val_mean_squared_error: 0.2079\n",
            "Epoch 707/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.1915 - mean_absolute_error: 0.3142 - mean_squared_error: 0.1915\n",
            "Epoch 707: val_loss did not improve from 0.20795\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1906 - mean_absolute_error: 0.3136 - mean_squared_error: 0.1906 - val_loss: 0.2103 - val_mean_absolute_error: 0.3291 - val_mean_squared_error: 0.2103\n",
            "Epoch 708/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.1885 - mean_absolute_error: 0.3122 - mean_squared_error: 0.1885\n",
            "Epoch 708: val_loss improved from 0.20795 to 0.20617, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1880 - mean_absolute_error: 0.3120 - mean_squared_error: 0.1880 - val_loss: 0.2062 - val_mean_absolute_error: 0.3196 - val_mean_squared_error: 0.2062\n",
            "Epoch 709/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.1848 - mean_absolute_error: 0.3084 - mean_squared_error: 0.1848\n",
            "Epoch 709: val_loss improved from 0.20617 to 0.19922, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.1861 - mean_absolute_error: 0.3096 - mean_squared_error: 0.1861 - val_loss: 0.1992 - val_mean_absolute_error: 0.3189 - val_mean_squared_error: 0.1992\n",
            "Epoch 710/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.1808 - mean_absolute_error: 0.3059 - mean_squared_error: 0.1808\n",
            "Epoch 710: val_loss improved from 0.19922 to 0.19585, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1804 - mean_absolute_error: 0.3055 - mean_squared_error: 0.1804 - val_loss: 0.1959 - val_mean_absolute_error: 0.3147 - val_mean_squared_error: 0.1959\n",
            "Epoch 711/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.1764 - mean_absolute_error: 0.3024 - mean_squared_error: 0.1764\n",
            "Epoch 711: val_loss improved from 0.19585 to 0.19278, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1763 - mean_absolute_error: 0.3024 - mean_squared_error: 0.1763 - val_loss: 0.1928 - val_mean_absolute_error: 0.3128 - val_mean_squared_error: 0.1928\n",
            "Epoch 712/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.1768 - mean_absolute_error: 0.3008 - mean_squared_error: 0.1768\n",
            "Epoch 712: val_loss did not improve from 0.19278\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1766 - mean_absolute_error: 0.3013 - mean_squared_error: 0.1766 - val_loss: 0.1952 - val_mean_absolute_error: 0.3171 - val_mean_squared_error: 0.1952\n",
            "Epoch 713/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.1809 - mean_absolute_error: 0.3047 - mean_squared_error: 0.1809\n",
            "Epoch 713: val_loss improved from 0.19278 to 0.19133, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1797 - mean_absolute_error: 0.3036 - mean_squared_error: 0.1797 - val_loss: 0.1913 - val_mean_absolute_error: 0.3124 - val_mean_squared_error: 0.1913\n",
            "Epoch 714/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.1724 - mean_absolute_error: 0.2969 - mean_squared_error: 0.1724\n",
            "Epoch 714: val_loss improved from 0.19133 to 0.18570, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1729 - mean_absolute_error: 0.2973 - mean_squared_error: 0.1729 - val_loss: 0.1857 - val_mean_absolute_error: 0.3058 - val_mean_squared_error: 0.1857\n",
            "Epoch 715/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.1696 - mean_absolute_error: 0.2940 - mean_squared_error: 0.1696\n",
            "Epoch 715: val_loss did not improve from 0.18570\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1701 - mean_absolute_error: 0.2944 - mean_squared_error: 0.1701 - val_loss: 0.1936 - val_mean_absolute_error: 0.3134 - val_mean_squared_error: 0.1936\n",
            "Epoch 716/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.1715 - mean_absolute_error: 0.2956 - mean_squared_error: 0.1715\n",
            "Epoch 716: val_loss did not improve from 0.18570\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1709 - mean_absolute_error: 0.2950 - mean_squared_error: 0.1709 - val_loss: 0.1866 - val_mean_absolute_error: 0.3086 - val_mean_squared_error: 0.1866\n",
            "Epoch 717/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.1707 - mean_absolute_error: 0.2945 - mean_squared_error: 0.1707\n",
            "Epoch 717: val_loss improved from 0.18570 to 0.17764, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1688 - mean_absolute_error: 0.2929 - mean_squared_error: 0.1688 - val_loss: 0.1776 - val_mean_absolute_error: 0.2988 - val_mean_squared_error: 0.1776\n",
            "Epoch 718/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.1656 - mean_absolute_error: 0.2899 - mean_squared_error: 0.1656\n",
            "Epoch 718: val_loss did not improve from 0.17764\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1660 - mean_absolute_error: 0.2905 - mean_squared_error: 0.1660 - val_loss: 0.1789 - val_mean_absolute_error: 0.3019 - val_mean_squared_error: 0.1789\n",
            "Epoch 719/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.1651 - mean_absolute_error: 0.2914 - mean_squared_error: 0.1651\n",
            "Epoch 719: val_loss improved from 0.17764 to 0.17545, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1636 - mean_absolute_error: 0.2897 - mean_squared_error: 0.1636 - val_loss: 0.1755 - val_mean_absolute_error: 0.2971 - val_mean_squared_error: 0.1755\n",
            "Epoch 720/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.1619 - mean_absolute_error: 0.2866 - mean_squared_error: 0.1619\n",
            "Epoch 720: val_loss improved from 0.17545 to 0.17345, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1613 - mean_absolute_error: 0.2863 - mean_squared_error: 0.1613 - val_loss: 0.1734 - val_mean_absolute_error: 0.2951 - val_mean_squared_error: 0.1734\n",
            "Epoch 721/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.1565 - mean_absolute_error: 0.2819 - mean_squared_error: 0.1565\n",
            "Epoch 721: val_loss did not improve from 0.17345\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1582 - mean_absolute_error: 0.2835 - mean_squared_error: 0.1582 - val_loss: 0.1768 - val_mean_absolute_error: 0.2975 - val_mean_squared_error: 0.1768\n",
            "Epoch 722/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.1609 - mean_absolute_error: 0.2857 - mean_squared_error: 0.1609\n",
            "Epoch 722: val_loss did not improve from 0.17345\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1601 - mean_absolute_error: 0.2844 - mean_squared_error: 0.1601 - val_loss: 0.1869 - val_mean_absolute_error: 0.3054 - val_mean_squared_error: 0.1869\n",
            "Epoch 723/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.1553 - mean_absolute_error: 0.2810 - mean_squared_error: 0.1553\n",
            "Epoch 723: val_loss did not improve from 0.17345\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1550 - mean_absolute_error: 0.2808 - mean_squared_error: 0.1550 - val_loss: 0.1804 - val_mean_absolute_error: 0.2978 - val_mean_squared_error: 0.1804\n",
            "Epoch 724/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.1539 - mean_absolute_error: 0.2781 - mean_squared_error: 0.1539\n",
            "Epoch 724: val_loss did not improve from 0.17345\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1544 - mean_absolute_error: 0.2782 - mean_squared_error: 0.1544 - val_loss: 0.1764 - val_mean_absolute_error: 0.2967 - val_mean_squared_error: 0.1764\n",
            "Epoch 725/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.1555 - mean_absolute_error: 0.2806 - mean_squared_error: 0.1555\n",
            "Epoch 725: val_loss improved from 0.17345 to 0.16192, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1548 - mean_absolute_error: 0.2801 - mean_squared_error: 0.1548 - val_loss: 0.1619 - val_mean_absolute_error: 0.2842 - val_mean_squared_error: 0.1619\n",
            "Epoch 726/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.1555 - mean_absolute_error: 0.2801 - mean_squared_error: 0.1555\n",
            "Epoch 726: val_loss did not improve from 0.16192\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1550 - mean_absolute_error: 0.2797 - mean_squared_error: 0.1550 - val_loss: 0.1785 - val_mean_absolute_error: 0.3020 - val_mean_squared_error: 0.1785\n",
            "Epoch 727/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.1499 - mean_absolute_error: 0.2757 - mean_squared_error: 0.1499\n",
            "Epoch 727: val_loss did not improve from 0.16192\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1503 - mean_absolute_error: 0.2761 - mean_squared_error: 0.1503 - val_loss: 0.1625 - val_mean_absolute_error: 0.2855 - val_mean_squared_error: 0.1625\n",
            "Epoch 728/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.1495 - mean_absolute_error: 0.2745 - mean_squared_error: 0.1495\n",
            "Epoch 728: val_loss did not improve from 0.16192\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1483 - mean_absolute_error: 0.2731 - mean_squared_error: 0.1483 - val_loss: 0.1631 - val_mean_absolute_error: 0.2844 - val_mean_squared_error: 0.1631\n",
            "Epoch 729/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.1453 - mean_absolute_error: 0.2703 - mean_squared_error: 0.1453\n",
            "Epoch 729: val_loss did not improve from 0.16192\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1453 - mean_absolute_error: 0.2704 - mean_squared_error: 0.1453 - val_loss: 0.1668 - val_mean_absolute_error: 0.2892 - val_mean_squared_error: 0.1668\n",
            "Epoch 730/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.1435 - mean_absolute_error: 0.2678 - mean_squared_error: 0.1435\n",
            "Epoch 730: val_loss improved from 0.16192 to 0.15685, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.1437 - mean_absolute_error: 0.2678 - mean_squared_error: 0.1437 - val_loss: 0.1569 - val_mean_absolute_error: 0.2785 - val_mean_squared_error: 0.1569\n",
            "Epoch 731/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.1432 - mean_absolute_error: 0.2682 - mean_squared_error: 0.1432\n",
            "Epoch 731: val_loss did not improve from 0.15685\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1433 - mean_absolute_error: 0.2686 - mean_squared_error: 0.1433 - val_loss: 0.1626 - val_mean_absolute_error: 0.2821 - val_mean_squared_error: 0.1626\n",
            "Epoch 732/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.1444 - mean_absolute_error: 0.2699 - mean_squared_error: 0.1444\n",
            "Epoch 732: val_loss improved from 0.15685 to 0.15117, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1440 - mean_absolute_error: 0.2693 - mean_squared_error: 0.1440 - val_loss: 0.1512 - val_mean_absolute_error: 0.2714 - val_mean_squared_error: 0.1512\n",
            "Epoch 733/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.1417 - mean_absolute_error: 0.2661 - mean_squared_error: 0.1417\n",
            "Epoch 733: val_loss did not improve from 0.15117\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1408 - mean_absolute_error: 0.2654 - mean_squared_error: 0.1408 - val_loss: 0.1540 - val_mean_absolute_error: 0.2761 - val_mean_squared_error: 0.1540\n",
            "Epoch 734/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.1425 - mean_absolute_error: 0.2664 - mean_squared_error: 0.1425\n",
            "Epoch 734: val_loss did not improve from 0.15117\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1419 - mean_absolute_error: 0.2660 - mean_squared_error: 0.1419 - val_loss: 0.1535 - val_mean_absolute_error: 0.2759 - val_mean_squared_error: 0.1535\n",
            "Epoch 735/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.1370 - mean_absolute_error: 0.2613 - mean_squared_error: 0.1370\n",
            "Epoch 735: val_loss did not improve from 0.15117\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.1374 - mean_absolute_error: 0.2616 - mean_squared_error: 0.1374 - val_loss: 0.1574 - val_mean_absolute_error: 0.2790 - val_mean_squared_error: 0.1574\n",
            "Epoch 736/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.1326 - mean_absolute_error: 0.2563 - mean_squared_error: 0.1326\n",
            "Epoch 736: val_loss did not improve from 0.15117\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1332 - mean_absolute_error: 0.2572 - mean_squared_error: 0.1332 - val_loss: 0.1569 - val_mean_absolute_error: 0.2809 - val_mean_squared_error: 0.1569\n",
            "Epoch 737/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.1360 - mean_absolute_error: 0.2615 - mean_squared_error: 0.1360\n",
            "Epoch 737: val_loss improved from 0.15117 to 0.14360, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1372 - mean_absolute_error: 0.2625 - mean_squared_error: 0.1372 - val_loss: 0.1436 - val_mean_absolute_error: 0.2669 - val_mean_squared_error: 0.1436\n",
            "Epoch 738/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.1338 - mean_absolute_error: 0.2588 - mean_squared_error: 0.1338\n",
            "Epoch 738: val_loss did not improve from 0.14360\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1335 - mean_absolute_error: 0.2586 - mean_squared_error: 0.1335 - val_loss: 0.1490 - val_mean_absolute_error: 0.2713 - val_mean_squared_error: 0.1490\n",
            "Epoch 739/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.1321 - mean_absolute_error: 0.2569 - mean_squared_error: 0.1321\n",
            "Epoch 739: val_loss improved from 0.14360 to 0.14113, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.1318 - mean_absolute_error: 0.2565 - mean_squared_error: 0.1318 - val_loss: 0.1411 - val_mean_absolute_error: 0.2640 - val_mean_squared_error: 0.1411\n",
            "Epoch 740/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.1305 - mean_absolute_error: 0.2546 - mean_squared_error: 0.1305\n",
            "Epoch 740: val_loss improved from 0.14113 to 0.13721, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.1306 - mean_absolute_error: 0.2549 - mean_squared_error: 0.1306 - val_loss: 0.1372 - val_mean_absolute_error: 0.2596 - val_mean_squared_error: 0.1372\n",
            "Epoch 741/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.1322 - mean_absolute_error: 0.2552 - mean_squared_error: 0.1322\n",
            "Epoch 741: val_loss improved from 0.13721 to 0.13421, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.1323 - mean_absolute_error: 0.2553 - mean_squared_error: 0.1323 - val_loss: 0.1342 - val_mean_absolute_error: 0.2556 - val_mean_squared_error: 0.1342\n",
            "Epoch 742/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.1276 - mean_absolute_error: 0.2512 - mean_squared_error: 0.1276\n",
            "Epoch 742: val_loss improved from 0.13421 to 0.13222, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.1272 - mean_absolute_error: 0.2509 - mean_squared_error: 0.1272 - val_loss: 0.1322 - val_mean_absolute_error: 0.2533 - val_mean_squared_error: 0.1322\n",
            "Epoch 743/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.1287 - mean_absolute_error: 0.2529 - mean_squared_error: 0.1287\n",
            "Epoch 743: val_loss did not improve from 0.13222\n",
            "245/245 [==============================] - 2s 8ms/step - loss: 0.1291 - mean_absolute_error: 0.2529 - mean_squared_error: 0.1291 - val_loss: 0.1328 - val_mean_absolute_error: 0.2541 - val_mean_squared_error: 0.1328\n",
            "Epoch 744/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.1261 - mean_absolute_error: 0.2496 - mean_squared_error: 0.1261\n",
            "Epoch 744: val_loss improved from 0.13222 to 0.12946, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1255 - mean_absolute_error: 0.2490 - mean_squared_error: 0.1255 - val_loss: 0.1295 - val_mean_absolute_error: 0.2491 - val_mean_squared_error: 0.1295\n",
            "Epoch 745/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.1243 - mean_absolute_error: 0.2478 - mean_squared_error: 0.1243\n",
            "Epoch 745: val_loss did not improve from 0.12946\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.1237 - mean_absolute_error: 0.2472 - mean_squared_error: 0.1237 - val_loss: 0.1295 - val_mean_absolute_error: 0.2505 - val_mean_squared_error: 0.1295\n",
            "Epoch 746/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.1216 - mean_absolute_error: 0.2454 - mean_squared_error: 0.1216\n",
            "Epoch 746: val_loss improved from 0.12946 to 0.12727, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.1212 - mean_absolute_error: 0.2450 - mean_squared_error: 0.1212 - val_loss: 0.1273 - val_mean_absolute_error: 0.2490 - val_mean_squared_error: 0.1273\n",
            "Epoch 747/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.1180 - mean_absolute_error: 0.2421 - mean_squared_error: 0.1180\n",
            "Epoch 747: val_loss did not improve from 0.12727\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1195 - mean_absolute_error: 0.2432 - mean_squared_error: 0.1195 - val_loss: 0.1309 - val_mean_absolute_error: 0.2517 - val_mean_squared_error: 0.1309\n",
            "Epoch 748/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.1182 - mean_absolute_error: 0.2405 - mean_squared_error: 0.1182\n",
            "Epoch 748: val_loss did not improve from 0.12727\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1190 - mean_absolute_error: 0.2411 - mean_squared_error: 0.1190 - val_loss: 0.1315 - val_mean_absolute_error: 0.2506 - val_mean_squared_error: 0.1315\n",
            "Epoch 749/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.1202 - mean_absolute_error: 0.2424 - mean_squared_error: 0.1202\n",
            "Epoch 749: val_loss did not improve from 0.12727\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1200 - mean_absolute_error: 0.2423 - mean_squared_error: 0.1200 - val_loss: 0.1396 - val_mean_absolute_error: 0.2633 - val_mean_squared_error: 0.1396\n",
            "Epoch 750/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.1161 - mean_absolute_error: 0.2389 - mean_squared_error: 0.1161\n",
            "Epoch 750: val_loss improved from 0.12727 to 0.12658, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1175 - mean_absolute_error: 0.2404 - mean_squared_error: 0.1175 - val_loss: 0.1266 - val_mean_absolute_error: 0.2478 - val_mean_squared_error: 0.1266\n",
            "Epoch 751/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.1165 - mean_absolute_error: 0.2392 - mean_squared_error: 0.1165\n",
            "Epoch 751: val_loss improved from 0.12658 to 0.12071, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1157 - mean_absolute_error: 0.2383 - mean_squared_error: 0.1157 - val_loss: 0.1207 - val_mean_absolute_error: 0.2419 - val_mean_squared_error: 0.1207\n",
            "Epoch 752/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.1135 - mean_absolute_error: 0.2365 - mean_squared_error: 0.1135\n",
            "Epoch 752: val_loss improved from 0.12071 to 0.12035, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1129 - mean_absolute_error: 0.2359 - mean_squared_error: 0.1129 - val_loss: 0.1203 - val_mean_absolute_error: 0.2386 - val_mean_squared_error: 0.1203\n",
            "Epoch 753/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.1128 - mean_absolute_error: 0.2349 - mean_squared_error: 0.1128\n",
            "Epoch 753: val_loss did not improve from 0.12035\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1133 - mean_absolute_error: 0.2351 - mean_squared_error: 0.1133 - val_loss: 0.1213 - val_mean_absolute_error: 0.2410 - val_mean_squared_error: 0.1213\n",
            "Epoch 754/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.1164 - mean_absolute_error: 0.2381 - mean_squared_error: 0.1164\n",
            "Epoch 754: val_loss improved from 0.12035 to 0.11699, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.1152 - mean_absolute_error: 0.2371 - mean_squared_error: 0.1152 - val_loss: 0.1170 - val_mean_absolute_error: 0.2377 - val_mean_squared_error: 0.1170\n",
            "Epoch 755/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.1096 - mean_absolute_error: 0.2315 - mean_squared_error: 0.1096\n",
            "Epoch 755: val_loss did not improve from 0.11699\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1094 - mean_absolute_error: 0.2316 - mean_squared_error: 0.1094 - val_loss: 0.1227 - val_mean_absolute_error: 0.2456 - val_mean_squared_error: 0.1227\n",
            "Epoch 756/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.1084 - mean_absolute_error: 0.2306 - mean_squared_error: 0.1084\n",
            "Epoch 756: val_loss improved from 0.11699 to 0.11572, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1100 - mean_absolute_error: 0.2320 - mean_squared_error: 0.1100 - val_loss: 0.1157 - val_mean_absolute_error: 0.2359 - val_mean_squared_error: 0.1157\n",
            "Epoch 757/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.1084 - mean_absolute_error: 0.2308 - mean_squared_error: 0.1084\n",
            "Epoch 757: val_loss did not improve from 0.11572\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1075 - mean_absolute_error: 0.2300 - mean_squared_error: 0.1075 - val_loss: 0.1206 - val_mean_absolute_error: 0.2405 - val_mean_squared_error: 0.1206\n",
            "Epoch 758/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.1088 - mean_absolute_error: 0.2322 - mean_squared_error: 0.1088\n",
            "Epoch 758: val_loss improved from 0.11572 to 0.11568, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1089 - mean_absolute_error: 0.2321 - mean_squared_error: 0.1089 - val_loss: 0.1157 - val_mean_absolute_error: 0.2372 - val_mean_squared_error: 0.1157\n",
            "Epoch 759/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.1068 - mean_absolute_error: 0.2279 - mean_squared_error: 0.1068\n",
            "Epoch 759: val_loss did not improve from 0.11568\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1069 - mean_absolute_error: 0.2279 - mean_squared_error: 0.1069 - val_loss: 0.1164 - val_mean_absolute_error: 0.2370 - val_mean_squared_error: 0.1164\n",
            "Epoch 760/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.1050 - mean_absolute_error: 0.2267 - mean_squared_error: 0.1050\n",
            "Epoch 760: val_loss did not improve from 0.11568\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.1050 - mean_absolute_error: 0.2267 - mean_squared_error: 0.1050 - val_loss: 0.1231 - val_mean_absolute_error: 0.2463 - val_mean_squared_error: 0.1231\n",
            "Epoch 761/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.1035 - mean_absolute_error: 0.2245 - mean_squared_error: 0.1035\n",
            "Epoch 761: val_loss improved from 0.11568 to 0.11367, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1041 - mean_absolute_error: 0.2251 - mean_squared_error: 0.1041 - val_loss: 0.1137 - val_mean_absolute_error: 0.2368 - val_mean_squared_error: 0.1137\n",
            "Epoch 762/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.1018 - mean_absolute_error: 0.2242 - mean_squared_error: 0.1018\n",
            "Epoch 762: val_loss improved from 0.11367 to 0.10830, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1022 - mean_absolute_error: 0.2244 - mean_squared_error: 0.1022 - val_loss: 0.1083 - val_mean_absolute_error: 0.2299 - val_mean_squared_error: 0.1083\n",
            "Epoch 763/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.1006 - mean_absolute_error: 0.2221 - mean_squared_error: 0.1006\n",
            "Epoch 763: val_loss improved from 0.10830 to 0.10496, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.1018 - mean_absolute_error: 0.2229 - mean_squared_error: 0.1018 - val_loss: 0.1050 - val_mean_absolute_error: 0.2255 - val_mean_squared_error: 0.1050\n",
            "Epoch 764/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.1025 - mean_absolute_error: 0.2246 - mean_squared_error: 0.1025\n",
            "Epoch 764: val_loss improved from 0.10496 to 0.10416, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1012 - mean_absolute_error: 0.2227 - mean_squared_error: 0.1012 - val_loss: 0.1042 - val_mean_absolute_error: 0.2223 - val_mean_squared_error: 0.1042\n",
            "Epoch 765/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0997 - mean_absolute_error: 0.2190 - mean_squared_error: 0.0997\n",
            "Epoch 765: val_loss did not improve from 0.10416\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0996 - mean_absolute_error: 0.2190 - mean_squared_error: 0.0996 - val_loss: 0.1048 - val_mean_absolute_error: 0.2246 - val_mean_squared_error: 0.1048\n",
            "Epoch 766/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0986 - mean_absolute_error: 0.2197 - mean_squared_error: 0.0986\n",
            "Epoch 766: val_loss did not improve from 0.10416\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0985 - mean_absolute_error: 0.2196 - mean_squared_error: 0.0985 - val_loss: 0.1100 - val_mean_absolute_error: 0.2302 - val_mean_squared_error: 0.1100\n",
            "Epoch 767/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.0967 - mean_absolute_error: 0.2170 - mean_squared_error: 0.0967\n",
            "Epoch 767: val_loss improved from 0.10416 to 0.10297, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0968 - mean_absolute_error: 0.2172 - mean_squared_error: 0.0968 - val_loss: 0.1030 - val_mean_absolute_error: 0.2209 - val_mean_squared_error: 0.1030\n",
            "Epoch 768/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0962 - mean_absolute_error: 0.2166 - mean_squared_error: 0.0962\n",
            "Epoch 768: val_loss improved from 0.10297 to 0.09721, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0961 - mean_absolute_error: 0.2166 - mean_squared_error: 0.0961 - val_loss: 0.0972 - val_mean_absolute_error: 0.2162 - val_mean_squared_error: 0.0972\n",
            "Epoch 769/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0954 - mean_absolute_error: 0.2158 - mean_squared_error: 0.0954\n",
            "Epoch 769: val_loss did not improve from 0.09721\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0956 - mean_absolute_error: 0.2161 - mean_squared_error: 0.0956 - val_loss: 0.0983 - val_mean_absolute_error: 0.2174 - val_mean_squared_error: 0.0983\n",
            "Epoch 770/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0941 - mean_absolute_error: 0.2156 - mean_squared_error: 0.0941\n",
            "Epoch 770: val_loss did not improve from 0.09721\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0939 - mean_absolute_error: 0.2153 - mean_squared_error: 0.0939 - val_loss: 0.0974 - val_mean_absolute_error: 0.2165 - val_mean_squared_error: 0.0974\n",
            "Epoch 771/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.0940 - mean_absolute_error: 0.2143 - mean_squared_error: 0.0940\n",
            "Epoch 771: val_loss improved from 0.09721 to 0.09507, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0932 - mean_absolute_error: 0.2131 - mean_squared_error: 0.0932 - val_loss: 0.0951 - val_mean_absolute_error: 0.2125 - val_mean_squared_error: 0.0951\n",
            "Epoch 772/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0904 - mean_absolute_error: 0.2103 - mean_squared_error: 0.0904\n",
            "Epoch 772: val_loss improved from 0.09507 to 0.09315, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0906 - mean_absolute_error: 0.2104 - mean_squared_error: 0.0906 - val_loss: 0.0931 - val_mean_absolute_error: 0.2107 - val_mean_squared_error: 0.0931\n",
            "Epoch 773/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0909 - mean_absolute_error: 0.2116 - mean_squared_error: 0.0909\n",
            "Epoch 773: val_loss did not improve from 0.09315\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0905 - mean_absolute_error: 0.2107 - mean_squared_error: 0.0905 - val_loss: 0.0968 - val_mean_absolute_error: 0.2136 - val_mean_squared_error: 0.0968\n",
            "Epoch 774/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0892 - mean_absolute_error: 0.2088 - mean_squared_error: 0.0892\n",
            "Epoch 774: val_loss improved from 0.09315 to 0.09163, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0893 - mean_absolute_error: 0.2088 - mean_squared_error: 0.0893 - val_loss: 0.0916 - val_mean_absolute_error: 0.2103 - val_mean_squared_error: 0.0916\n",
            "Epoch 775/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0898 - mean_absolute_error: 0.2089 - mean_squared_error: 0.0898\n",
            "Epoch 775: val_loss did not improve from 0.09163\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0893 - mean_absolute_error: 0.2086 - mean_squared_error: 0.0893 - val_loss: 0.0937 - val_mean_absolute_error: 0.2108 - val_mean_squared_error: 0.0937\n",
            "Epoch 776/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0869 - mean_absolute_error: 0.2051 - mean_squared_error: 0.0869\n",
            "Epoch 776: val_loss improved from 0.09163 to 0.08991, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0868 - mean_absolute_error: 0.2051 - mean_squared_error: 0.0868 - val_loss: 0.0899 - val_mean_absolute_error: 0.2064 - val_mean_squared_error: 0.0899\n",
            "Epoch 777/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0855 - mean_absolute_error: 0.2041 - mean_squared_error: 0.0855\n",
            "Epoch 777: val_loss improved from 0.08991 to 0.08911, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0862 - mean_absolute_error: 0.2048 - mean_squared_error: 0.0862 - val_loss: 0.0891 - val_mean_absolute_error: 0.2079 - val_mean_squared_error: 0.0891\n",
            "Epoch 778/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.0866 - mean_absolute_error: 0.2057 - mean_squared_error: 0.0866\n",
            "Epoch 778: val_loss did not improve from 0.08911\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0862 - mean_absolute_error: 0.2053 - mean_squared_error: 0.0862 - val_loss: 0.0940 - val_mean_absolute_error: 0.2115 - val_mean_squared_error: 0.0940\n",
            "Epoch 779/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0859 - mean_absolute_error: 0.2045 - mean_squared_error: 0.0859\n",
            "Epoch 779: val_loss improved from 0.08911 to 0.08675, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0856 - mean_absolute_error: 0.2043 - mean_squared_error: 0.0856 - val_loss: 0.0867 - val_mean_absolute_error: 0.2021 - val_mean_squared_error: 0.0867\n",
            "Epoch 780/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0833 - mean_absolute_error: 0.2009 - mean_squared_error: 0.0833\n",
            "Epoch 780: val_loss did not improve from 0.08675\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0832 - mean_absolute_error: 0.2009 - mean_squared_error: 0.0832 - val_loss: 0.0875 - val_mean_absolute_error: 0.2085 - val_mean_squared_error: 0.0875\n",
            "Epoch 781/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.0856 - mean_absolute_error: 0.2045 - mean_squared_error: 0.0856\n",
            "Epoch 781: val_loss did not improve from 0.08675\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0852 - mean_absolute_error: 0.2042 - mean_squared_error: 0.0852 - val_loss: 0.0881 - val_mean_absolute_error: 0.2058 - val_mean_squared_error: 0.0881\n",
            "Epoch 782/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0816 - mean_absolute_error: 0.1990 - mean_squared_error: 0.0816\n",
            "Epoch 782: val_loss improved from 0.08675 to 0.08493, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0813 - mean_absolute_error: 0.1985 - mean_squared_error: 0.0813 - val_loss: 0.0849 - val_mean_absolute_error: 0.2010 - val_mean_squared_error: 0.0849\n",
            "Epoch 783/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0806 - mean_absolute_error: 0.1983 - mean_squared_error: 0.0806\n",
            "Epoch 783: val_loss did not improve from 0.08493\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0806 - mean_absolute_error: 0.1983 - mean_squared_error: 0.0806 - val_loss: 0.0850 - val_mean_absolute_error: 0.2018 - val_mean_squared_error: 0.0850\n",
            "Epoch 784/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0795 - mean_absolute_error: 0.1972 - mean_squared_error: 0.0795\n",
            "Epoch 784: val_loss improved from 0.08493 to 0.08121, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0800 - mean_absolute_error: 0.1976 - mean_squared_error: 0.0800 - val_loss: 0.0812 - val_mean_absolute_error: 0.1981 - val_mean_squared_error: 0.0812\n",
            "Epoch 785/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0782 - mean_absolute_error: 0.1944 - mean_squared_error: 0.0782\n",
            "Epoch 785: val_loss did not improve from 0.08121\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0781 - mean_absolute_error: 0.1944 - mean_squared_error: 0.0781 - val_loss: 0.0821 - val_mean_absolute_error: 0.1967 - val_mean_squared_error: 0.0821\n",
            "Epoch 786/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0769 - mean_absolute_error: 0.1924 - mean_squared_error: 0.0769\n",
            "Epoch 786: val_loss did not improve from 0.08121\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0767 - mean_absolute_error: 0.1923 - mean_squared_error: 0.0767 - val_loss: 0.0812 - val_mean_absolute_error: 0.1992 - val_mean_squared_error: 0.0812\n",
            "Epoch 787/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0760 - mean_absolute_error: 0.1924 - mean_squared_error: 0.0760\n",
            "Epoch 787: val_loss improved from 0.08121 to 0.07952, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0770 - mean_absolute_error: 0.1929 - mean_squared_error: 0.0770 - val_loss: 0.0795 - val_mean_absolute_error: 0.1966 - val_mean_squared_error: 0.0795\n",
            "Epoch 788/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.0760 - mean_absolute_error: 0.1921 - mean_squared_error: 0.0760\n",
            "Epoch 788: val_loss improved from 0.07952 to 0.07839, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0752 - mean_absolute_error: 0.1908 - mean_squared_error: 0.0752 - val_loss: 0.0784 - val_mean_absolute_error: 0.1972 - val_mean_squared_error: 0.0784\n",
            "Epoch 789/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0772 - mean_absolute_error: 0.1932 - mean_squared_error: 0.0772\n",
            "Epoch 789: val_loss improved from 0.07839 to 0.07630, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0772 - mean_absolute_error: 0.1932 - mean_squared_error: 0.0772 - val_loss: 0.0763 - val_mean_absolute_error: 0.1894 - val_mean_squared_error: 0.0763\n",
            "Epoch 790/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0743 - mean_absolute_error: 0.1888 - mean_squared_error: 0.0743\n",
            "Epoch 790: val_loss improved from 0.07630 to 0.07611, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0740 - mean_absolute_error: 0.1884 - mean_squared_error: 0.0740 - val_loss: 0.0761 - val_mean_absolute_error: 0.1909 - val_mean_squared_error: 0.0761\n",
            "Epoch 791/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0728 - mean_absolute_error: 0.1878 - mean_squared_error: 0.0728\n",
            "Epoch 791: val_loss did not improve from 0.07611\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0732 - mean_absolute_error: 0.1884 - mean_squared_error: 0.0732 - val_loss: 0.0773 - val_mean_absolute_error: 0.1920 - val_mean_squared_error: 0.0773\n",
            "Epoch 792/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0749 - mean_absolute_error: 0.1899 - mean_squared_error: 0.0749\n",
            "Epoch 792: val_loss improved from 0.07611 to 0.07416, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0748 - mean_absolute_error: 0.1898 - mean_squared_error: 0.0748 - val_loss: 0.0742 - val_mean_absolute_error: 0.1894 - val_mean_squared_error: 0.0742\n",
            "Epoch 793/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0734 - mean_absolute_error: 0.1882 - mean_squared_error: 0.0734\n",
            "Epoch 793: val_loss did not improve from 0.07416\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0736 - mean_absolute_error: 0.1882 - mean_squared_error: 0.0736 - val_loss: 0.0781 - val_mean_absolute_error: 0.1931 - val_mean_squared_error: 0.0781\n",
            "Epoch 794/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0741 - mean_absolute_error: 0.1885 - mean_squared_error: 0.0741\n",
            "Epoch 794: val_loss did not improve from 0.07416\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0741 - mean_absolute_error: 0.1885 - mean_squared_error: 0.0741 - val_loss: 0.0768 - val_mean_absolute_error: 0.1902 - val_mean_squared_error: 0.0768\n",
            "Epoch 795/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0715 - mean_absolute_error: 0.1860 - mean_squared_error: 0.0715\n",
            "Epoch 795: val_loss improved from 0.07416 to 0.07415, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0718 - mean_absolute_error: 0.1862 - mean_squared_error: 0.0718 - val_loss: 0.0742 - val_mean_absolute_error: 0.1912 - val_mean_squared_error: 0.0742\n",
            "Epoch 796/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 0.0725 - mean_absolute_error: 0.1873 - mean_squared_error: 0.0725\n",
            "Epoch 796: val_loss did not improve from 0.07415\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0721 - mean_absolute_error: 0.1867 - mean_squared_error: 0.0721 - val_loss: 0.0812 - val_mean_absolute_error: 0.1993 - val_mean_squared_error: 0.0812\n",
            "Epoch 797/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0715 - mean_absolute_error: 0.1865 - mean_squared_error: 0.0715\n",
            "Epoch 797: val_loss did not improve from 0.07415\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0715 - mean_absolute_error: 0.1863 - mean_squared_error: 0.0715 - val_loss: 0.0755 - val_mean_absolute_error: 0.1872 - val_mean_squared_error: 0.0755\n",
            "Epoch 798/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0685 - mean_absolute_error: 0.1807 - mean_squared_error: 0.0685\n",
            "Epoch 798: val_loss improved from 0.07415 to 0.06932, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0685 - mean_absolute_error: 0.1809 - mean_squared_error: 0.0685 - val_loss: 0.0693 - val_mean_absolute_error: 0.1827 - val_mean_squared_error: 0.0693\n",
            "Epoch 799/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0678 - mean_absolute_error: 0.1814 - mean_squared_error: 0.0678\n",
            "Epoch 799: val_loss did not improve from 0.06932\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0689 - mean_absolute_error: 0.1830 - mean_squared_error: 0.0689 - val_loss: 0.0734 - val_mean_absolute_error: 0.1890 - val_mean_squared_error: 0.0734\n",
            "Epoch 800/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.1799 - mean_squared_error: 0.0671\n",
            "Epoch 800: val_loss did not improve from 0.06932\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0670 - mean_absolute_error: 0.1796 - mean_squared_error: 0.0670 - val_loss: 0.0701 - val_mean_absolute_error: 0.1821 - val_mean_squared_error: 0.0701\n",
            "Epoch 801/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0677 - mean_absolute_error: 0.1805 - mean_squared_error: 0.0677\n",
            "Epoch 801: val_loss did not improve from 0.06932\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0673 - mean_absolute_error: 0.1803 - mean_squared_error: 0.0673 - val_loss: 0.0704 - val_mean_absolute_error: 0.1868 - val_mean_squared_error: 0.0704\n",
            "Epoch 802/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0659 - mean_absolute_error: 0.1776 - mean_squared_error: 0.0659\n",
            "Epoch 802: val_loss improved from 0.06932 to 0.06555, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0653 - mean_absolute_error: 0.1767 - mean_squared_error: 0.0653 - val_loss: 0.0656 - val_mean_absolute_error: 0.1768 - val_mean_squared_error: 0.0656\n",
            "Epoch 803/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0666 - mean_absolute_error: 0.1797 - mean_squared_error: 0.0666\n",
            "Epoch 803: val_loss did not improve from 0.06555\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0665 - mean_absolute_error: 0.1795 - mean_squared_error: 0.0665 - val_loss: 0.0689 - val_mean_absolute_error: 0.1834 - val_mean_squared_error: 0.0689\n",
            "Epoch 804/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0657 - mean_absolute_error: 0.1774 - mean_squared_error: 0.0657\n",
            "Epoch 804: val_loss did not improve from 0.06555\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0657 - mean_absolute_error: 0.1774 - mean_squared_error: 0.0657 - val_loss: 0.0675 - val_mean_absolute_error: 0.1806 - val_mean_squared_error: 0.0675\n",
            "Epoch 805/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0655 - mean_absolute_error: 0.1779 - mean_squared_error: 0.0655\n",
            "Epoch 805: val_loss improved from 0.06555 to 0.06436, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0655 - mean_absolute_error: 0.1778 - mean_squared_error: 0.0655 - val_loss: 0.0644 - val_mean_absolute_error: 0.1740 - val_mean_squared_error: 0.0644\n",
            "Epoch 806/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0640 - mean_absolute_error: 0.1755 - mean_squared_error: 0.0640\n",
            "Epoch 806: val_loss did not improve from 0.06436\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0637 - mean_absolute_error: 0.1751 - mean_squared_error: 0.0637 - val_loss: 0.0690 - val_mean_absolute_error: 0.1799 - val_mean_squared_error: 0.0690\n",
            "Epoch 807/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0628 - mean_absolute_error: 0.1736 - mean_squared_error: 0.0628\n",
            "Epoch 807: val_loss did not improve from 0.06436\n",
            "245/245 [==============================] - 2s 7ms/step - loss: 0.0628 - mean_absolute_error: 0.1736 - mean_squared_error: 0.0628 - val_loss: 0.0650 - val_mean_absolute_error: 0.1769 - val_mean_squared_error: 0.0650\n",
            "Epoch 808/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.0637 - mean_absolute_error: 0.1757 - mean_squared_error: 0.0637\n",
            "Epoch 808: val_loss did not improve from 0.06436\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0634 - mean_absolute_error: 0.1755 - mean_squared_error: 0.0634 - val_loss: 0.0669 - val_mean_absolute_error: 0.1798 - val_mean_squared_error: 0.0669\n",
            "Epoch 809/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0618 - mean_absolute_error: 0.1726 - mean_squared_error: 0.0618\n",
            "Epoch 809: val_loss did not improve from 0.06436\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0612 - mean_absolute_error: 0.1712 - mean_squared_error: 0.0612 - val_loss: 0.0705 - val_mean_absolute_error: 0.1860 - val_mean_squared_error: 0.0705\n",
            "Epoch 810/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0643 - mean_absolute_error: 0.1760 - mean_squared_error: 0.0643\n",
            "Epoch 810: val_loss did not improve from 0.06436\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0643 - mean_absolute_error: 0.1761 - mean_squared_error: 0.0643 - val_loss: 0.0678 - val_mean_absolute_error: 0.1815 - val_mean_squared_error: 0.0678\n",
            "Epoch 811/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0618 - mean_absolute_error: 0.1722 - mean_squared_error: 0.0618\n",
            "Epoch 811: val_loss improved from 0.06436 to 0.06046, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0616 - mean_absolute_error: 0.1720 - mean_squared_error: 0.0616 - val_loss: 0.0605 - val_mean_absolute_error: 0.1705 - val_mean_squared_error: 0.0605\n",
            "Epoch 812/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0607 - mean_absolute_error: 0.1712 - mean_squared_error: 0.0607\n",
            "Epoch 812: val_loss did not improve from 0.06046\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0611 - mean_absolute_error: 0.1714 - mean_squared_error: 0.0611 - val_loss: 0.0620 - val_mean_absolute_error: 0.1747 - val_mean_squared_error: 0.0620\n",
            "Epoch 813/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0608 - mean_absolute_error: 0.1707 - mean_squared_error: 0.0608\n",
            "Epoch 813: val_loss did not improve from 0.06046\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0608 - mean_absolute_error: 0.1707 - mean_squared_error: 0.0608 - val_loss: 0.0680 - val_mean_absolute_error: 0.1826 - val_mean_squared_error: 0.0680\n",
            "Epoch 814/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0602 - mean_absolute_error: 0.1706 - mean_squared_error: 0.0602\n",
            "Epoch 814: val_loss improved from 0.06046 to 0.05842, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0598 - mean_absolute_error: 0.1699 - mean_squared_error: 0.0598 - val_loss: 0.0584 - val_mean_absolute_error: 0.1670 - val_mean_squared_error: 0.0584\n",
            "Epoch 815/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0575 - mean_absolute_error: 0.1664 - mean_squared_error: 0.0575\n",
            "Epoch 815: val_loss improved from 0.05842 to 0.05722, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0579 - mean_absolute_error: 0.1673 - mean_squared_error: 0.0579 - val_loss: 0.0572 - val_mean_absolute_error: 0.1671 - val_mean_squared_error: 0.0572\n",
            "Epoch 816/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0575 - mean_absolute_error: 0.1658 - mean_squared_error: 0.0575\n",
            "Epoch 816: val_loss did not improve from 0.05722\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0573 - mean_absolute_error: 0.1658 - mean_squared_error: 0.0573 - val_loss: 0.0603 - val_mean_absolute_error: 0.1699 - val_mean_squared_error: 0.0603\n",
            "Epoch 817/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.0597 - mean_absolute_error: 0.1695 - mean_squared_error: 0.0597\n",
            "Epoch 817: val_loss did not improve from 0.05722\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0592 - mean_absolute_error: 0.1689 - mean_squared_error: 0.0592 - val_loss: 0.0653 - val_mean_absolute_error: 0.1797 - val_mean_squared_error: 0.0653\n",
            "Epoch 818/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0569 - mean_absolute_error: 0.1659 - mean_squared_error: 0.0569\n",
            "Epoch 818: val_loss did not improve from 0.05722\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0567 - mean_absolute_error: 0.1659 - mean_squared_error: 0.0567 - val_loss: 0.0593 - val_mean_absolute_error: 0.1725 - val_mean_squared_error: 0.0593\n",
            "Epoch 819/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 0.0564 - mean_absolute_error: 0.1647 - mean_squared_error: 0.0564\n",
            "Epoch 819: val_loss did not improve from 0.05722\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0562 - mean_absolute_error: 0.1648 - mean_squared_error: 0.0562 - val_loss: 0.0726 - val_mean_absolute_error: 0.1879 - val_mean_squared_error: 0.0726\n",
            "Epoch 820/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 0.0579 - mean_absolute_error: 0.1675 - mean_squared_error: 0.0579\n",
            "Epoch 820: val_loss did not improve from 0.05722\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0590 - mean_absolute_error: 0.1689 - mean_squared_error: 0.0590 - val_loss: 0.0671 - val_mean_absolute_error: 0.1822 - val_mean_squared_error: 0.0671\n",
            "Epoch 821/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0552 - mean_absolute_error: 0.1632 - mean_squared_error: 0.0552\n",
            "Epoch 821: val_loss did not improve from 0.05722\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0555 - mean_absolute_error: 0.1634 - mean_squared_error: 0.0555 - val_loss: 0.0621 - val_mean_absolute_error: 0.1750 - val_mean_squared_error: 0.0621\n",
            "Epoch 822/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0560 - mean_absolute_error: 0.1648 - mean_squared_error: 0.0560\n",
            "Epoch 822: val_loss did not improve from 0.05722\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0563 - mean_absolute_error: 0.1652 - mean_squared_error: 0.0563 - val_loss: 0.0575 - val_mean_absolute_error: 0.1689 - val_mean_squared_error: 0.0575\n",
            "Epoch 823/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0540 - mean_absolute_error: 0.1618 - mean_squared_error: 0.0540\n",
            "Epoch 823: val_loss improved from 0.05722 to 0.05513, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0537 - mean_absolute_error: 0.1613 - mean_squared_error: 0.0537 - val_loss: 0.0551 - val_mean_absolute_error: 0.1643 - val_mean_squared_error: 0.0551\n",
            "Epoch 824/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0542 - mean_absolute_error: 0.1625 - mean_squared_error: 0.0542\n",
            "Epoch 824: val_loss did not improve from 0.05513\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0542 - mean_absolute_error: 0.1627 - mean_squared_error: 0.0542 - val_loss: 0.0570 - val_mean_absolute_error: 0.1684 - val_mean_squared_error: 0.0570\n",
            "Epoch 825/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0530 - mean_absolute_error: 0.1608 - mean_squared_error: 0.0530\n",
            "Epoch 825: val_loss did not improve from 0.05513\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0530 - mean_absolute_error: 0.1608 - mean_squared_error: 0.0530 - val_loss: 0.0574 - val_mean_absolute_error: 0.1669 - val_mean_squared_error: 0.0574\n",
            "Epoch 826/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 0.0543 - mean_absolute_error: 0.1624 - mean_squared_error: 0.0543\n",
            "Epoch 826: val_loss did not improve from 0.05513\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0539 - mean_absolute_error: 0.1619 - mean_squared_error: 0.0539 - val_loss: 0.0623 - val_mean_absolute_error: 0.1765 - val_mean_squared_error: 0.0623\n",
            "Epoch 827/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0537 - mean_absolute_error: 0.1619 - mean_squared_error: 0.0537\n",
            "Epoch 827: val_loss improved from 0.05513 to 0.05071, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0539 - mean_absolute_error: 0.1622 - mean_squared_error: 0.0539 - val_loss: 0.0507 - val_mean_absolute_error: 0.1591 - val_mean_squared_error: 0.0507\n",
            "Epoch 828/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0521 - mean_absolute_error: 0.1597 - mean_squared_error: 0.0521\n",
            "Epoch 828: val_loss did not improve from 0.05071\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0533 - mean_absolute_error: 0.1614 - mean_squared_error: 0.0533 - val_loss: 0.0915 - val_mean_absolute_error: 0.2092 - val_mean_squared_error: 0.0915\n",
            "Epoch 829/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0544 - mean_absolute_error: 0.1629 - mean_squared_error: 0.0544\n",
            "Epoch 829: val_loss did not improve from 0.05071\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0541 - mean_absolute_error: 0.1622 - mean_squared_error: 0.0541 - val_loss: 0.0548 - val_mean_absolute_error: 0.1665 - val_mean_squared_error: 0.0548\n",
            "Epoch 830/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0518 - mean_absolute_error: 0.1593 - mean_squared_error: 0.0518\n",
            "Epoch 830: val_loss did not improve from 0.05071\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0517 - mean_absolute_error: 0.1591 - mean_squared_error: 0.0517 - val_loss: 0.0511 - val_mean_absolute_error: 0.1597 - val_mean_squared_error: 0.0511\n",
            "Epoch 831/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0529 - mean_absolute_error: 0.1613 - mean_squared_error: 0.0529\n",
            "Epoch 831: val_loss did not improve from 0.05071\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0527 - mean_absolute_error: 0.1610 - mean_squared_error: 0.0527 - val_loss: 0.0512 - val_mean_absolute_error: 0.1576 - val_mean_squared_error: 0.0512\n",
            "Epoch 832/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0501 - mean_absolute_error: 0.1573 - mean_squared_error: 0.0501\n",
            "Epoch 832: val_loss improved from 0.05071 to 0.05038, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0496 - mean_absolute_error: 0.1568 - mean_squared_error: 0.0496 - val_loss: 0.0504 - val_mean_absolute_error: 0.1580 - val_mean_squared_error: 0.0504\n",
            "Epoch 833/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.0513 - mean_absolute_error: 0.1589 - mean_squared_error: 0.0513\n",
            "Epoch 833: val_loss improved from 0.05038 to 0.04999, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0517 - mean_absolute_error: 0.1591 - mean_squared_error: 0.0517 - val_loss: 0.0500 - val_mean_absolute_error: 0.1580 - val_mean_squared_error: 0.0500\n",
            "Epoch 834/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0492 - mean_absolute_error: 0.1557 - mean_squared_error: 0.0492\n",
            "Epoch 834: val_loss improved from 0.04999 to 0.04969, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0494 - mean_absolute_error: 0.1561 - mean_squared_error: 0.0494 - val_loss: 0.0497 - val_mean_absolute_error: 0.1560 - val_mean_squared_error: 0.0497\n",
            "Epoch 835/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0498 - mean_absolute_error: 0.1565 - mean_squared_error: 0.0498\n",
            "Epoch 835: val_loss improved from 0.04969 to 0.04933, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0498 - mean_absolute_error: 0.1566 - mean_squared_error: 0.0498 - val_loss: 0.0493 - val_mean_absolute_error: 0.1546 - val_mean_squared_error: 0.0493\n",
            "Epoch 836/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0492 - mean_absolute_error: 0.1550 - mean_squared_error: 0.0492\n",
            "Epoch 836: val_loss did not improve from 0.04933\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0489 - mean_absolute_error: 0.1548 - mean_squared_error: 0.0489 - val_loss: 0.0498 - val_mean_absolute_error: 0.1580 - val_mean_squared_error: 0.0498\n",
            "Epoch 837/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0520 - mean_absolute_error: 0.1601 - mean_squared_error: 0.0520\n",
            "Epoch 837: val_loss did not improve from 0.04933\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0514 - mean_absolute_error: 0.1590 - mean_squared_error: 0.0514 - val_loss: 0.0516 - val_mean_absolute_error: 0.1586 - val_mean_squared_error: 0.0516\n",
            "Epoch 838/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0486 - mean_absolute_error: 0.1554 - mean_squared_error: 0.0486\n",
            "Epoch 838: val_loss improved from 0.04933 to 0.04733, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0482 - mean_absolute_error: 0.1546 - mean_squared_error: 0.0482 - val_loss: 0.0473 - val_mean_absolute_error: 0.1537 - val_mean_squared_error: 0.0473\n",
            "Epoch 839/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0500 - mean_absolute_error: 0.1579 - mean_squared_error: 0.0500\n",
            "Epoch 839: val_loss improved from 0.04733 to 0.04651, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0506 - mean_absolute_error: 0.1585 - mean_squared_error: 0.0506 - val_loss: 0.0465 - val_mean_absolute_error: 0.1525 - val_mean_squared_error: 0.0465\n",
            "Epoch 840/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0494 - mean_absolute_error: 0.1579 - mean_squared_error: 0.0494\n",
            "Epoch 840: val_loss did not improve from 0.04651\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0493 - mean_absolute_error: 0.1578 - mean_squared_error: 0.0493 - val_loss: 0.0625 - val_mean_absolute_error: 0.1774 - val_mean_squared_error: 0.0625\n",
            "Epoch 841/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0476 - mean_absolute_error: 0.1540 - mean_squared_error: 0.0476\n",
            "Epoch 841: val_loss did not improve from 0.04651\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0476 - mean_absolute_error: 0.1540 - mean_squared_error: 0.0476 - val_loss: 0.0477 - val_mean_absolute_error: 0.1571 - val_mean_squared_error: 0.0477\n",
            "Epoch 842/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0481 - mean_absolute_error: 0.1550 - mean_squared_error: 0.0481\n",
            "Epoch 842: val_loss did not improve from 0.04651\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0477 - mean_absolute_error: 0.1543 - mean_squared_error: 0.0477 - val_loss: 0.0512 - val_mean_absolute_error: 0.1626 - val_mean_squared_error: 0.0512\n",
            "Epoch 843/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 0.0479 - mean_absolute_error: 0.1550 - mean_squared_error: 0.0479\n",
            "Epoch 843: val_loss improved from 0.04651 to 0.04506, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0484 - mean_absolute_error: 0.1554 - mean_squared_error: 0.0484 - val_loss: 0.0451 - val_mean_absolute_error: 0.1511 - val_mean_squared_error: 0.0451\n",
            "Epoch 844/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0467 - mean_absolute_error: 0.1532 - mean_squared_error: 0.0467\n",
            "Epoch 844: val_loss did not improve from 0.04506\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0467 - mean_absolute_error: 0.1531 - mean_squared_error: 0.0467 - val_loss: 0.0490 - val_mean_absolute_error: 0.1550 - val_mean_squared_error: 0.0490\n",
            "Epoch 845/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0475 - mean_absolute_error: 0.1539 - mean_squared_error: 0.0475\n",
            "Epoch 845: val_loss did not improve from 0.04506\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0474 - mean_absolute_error: 0.1539 - mean_squared_error: 0.0474 - val_loss: 0.0474 - val_mean_absolute_error: 0.1540 - val_mean_squared_error: 0.0474\n",
            "Epoch 846/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0458 - mean_absolute_error: 0.1522 - mean_squared_error: 0.0458\n",
            "Epoch 846: val_loss did not improve from 0.04506\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0455 - mean_absolute_error: 0.1516 - mean_squared_error: 0.0455 - val_loss: 0.0509 - val_mean_absolute_error: 0.1606 - val_mean_squared_error: 0.0509\n",
            "Epoch 847/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0450 - mean_absolute_error: 0.1505 - mean_squared_error: 0.0450\n",
            "Epoch 847: val_loss did not improve from 0.04506\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0451 - mean_absolute_error: 0.1506 - mean_squared_error: 0.0451 - val_loss: 0.0497 - val_mean_absolute_error: 0.1551 - val_mean_squared_error: 0.0497\n",
            "Epoch 848/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0478 - mean_absolute_error: 0.1540 - mean_squared_error: 0.0478\n",
            "Epoch 848: val_loss improved from 0.04506 to 0.04452, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0477 - mean_absolute_error: 0.1539 - mean_squared_error: 0.0477 - val_loss: 0.0445 - val_mean_absolute_error: 0.1530 - val_mean_squared_error: 0.0445\n",
            "Epoch 849/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0449 - mean_absolute_error: 0.1507 - mean_squared_error: 0.0449\n",
            "Epoch 849: val_loss did not improve from 0.04452\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0449 - mean_absolute_error: 0.1504 - mean_squared_error: 0.0449 - val_loss: 0.0477 - val_mean_absolute_error: 0.1526 - val_mean_squared_error: 0.0477\n",
            "Epoch 850/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0452 - mean_absolute_error: 0.1515 - mean_squared_error: 0.0452\n",
            "Epoch 850: val_loss did not improve from 0.04452\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0452 - mean_absolute_error: 0.1518 - mean_squared_error: 0.0452 - val_loss: 0.0454 - val_mean_absolute_error: 0.1549 - val_mean_squared_error: 0.0454\n",
            "Epoch 851/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 0.0442 - mean_absolute_error: 0.1495 - mean_squared_error: 0.0442\n",
            "Epoch 851: val_loss did not improve from 0.04452\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0442 - mean_absolute_error: 0.1495 - mean_squared_error: 0.0442 - val_loss: 0.0531 - val_mean_absolute_error: 0.1639 - val_mean_squared_error: 0.0531\n",
            "Epoch 852/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 0.0465 - mean_absolute_error: 0.1538 - mean_squared_error: 0.0465\n",
            "Epoch 852: val_loss did not improve from 0.04452\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0470 - mean_absolute_error: 0.1543 - mean_squared_error: 0.0470 - val_loss: 0.0603 - val_mean_absolute_error: 0.1765 - val_mean_squared_error: 0.0603\n",
            "Epoch 853/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0442 - mean_absolute_error: 0.1493 - mean_squared_error: 0.0442\n",
            "Epoch 853: val_loss improved from 0.04452 to 0.04359, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0439 - mean_absolute_error: 0.1489 - mean_squared_error: 0.0439 - val_loss: 0.0436 - val_mean_absolute_error: 0.1490 - val_mean_squared_error: 0.0436\n",
            "Epoch 854/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 0.0430 - mean_absolute_error: 0.1469 - mean_squared_error: 0.0430\n",
            "Epoch 854: val_loss did not improve from 0.04359\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0430 - mean_absolute_error: 0.1470 - mean_squared_error: 0.0430 - val_loss: 0.0561 - val_mean_absolute_error: 0.1702 - val_mean_squared_error: 0.0561\n",
            "Epoch 855/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0453 - mean_absolute_error: 0.1507 - mean_squared_error: 0.0453\n",
            "Epoch 855: val_loss improved from 0.04359 to 0.04086, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0452 - mean_absolute_error: 0.1505 - mean_squared_error: 0.0452 - val_loss: 0.0409 - val_mean_absolute_error: 0.1450 - val_mean_squared_error: 0.0409\n",
            "Epoch 856/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 0.0454 - mean_absolute_error: 0.1521 - mean_squared_error: 0.0454\n",
            "Epoch 856: val_loss did not improve from 0.04086\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0454 - mean_absolute_error: 0.1518 - mean_squared_error: 0.0454 - val_loss: 0.0435 - val_mean_absolute_error: 0.1488 - val_mean_squared_error: 0.0435\n",
            "Epoch 857/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 0.0452 - mean_absolute_error: 0.1512 - mean_squared_error: 0.0452\n",
            "Epoch 857: val_loss did not improve from 0.04086\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0455 - mean_absolute_error: 0.1518 - mean_squared_error: 0.0455 - val_loss: 0.0451 - val_mean_absolute_error: 0.1504 - val_mean_squared_error: 0.0451\n",
            "Epoch 858/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0450 - mean_absolute_error: 0.1508 - mean_squared_error: 0.0450\n",
            "Epoch 858: val_loss did not improve from 0.04086\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0452 - mean_absolute_error: 0.1510 - mean_squared_error: 0.0452 - val_loss: 0.0496 - val_mean_absolute_error: 0.1620 - val_mean_squared_error: 0.0496\n",
            "Epoch 859/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0433 - mean_absolute_error: 0.1487 - mean_squared_error: 0.0433\n",
            "Epoch 859: val_loss improved from 0.04086 to 0.04085, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0431 - mean_absolute_error: 0.1486 - mean_squared_error: 0.0431 - val_loss: 0.0408 - val_mean_absolute_error: 0.1459 - val_mean_squared_error: 0.0408\n",
            "Epoch 860/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0428 - mean_absolute_error: 0.1481 - mean_squared_error: 0.0428\n",
            "Epoch 860: val_loss did not improve from 0.04085\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0426 - mean_absolute_error: 0.1478 - mean_squared_error: 0.0426 - val_loss: 0.0449 - val_mean_absolute_error: 0.1557 - val_mean_squared_error: 0.0449\n",
            "Epoch 861/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0416 - mean_absolute_error: 0.1460 - mean_squared_error: 0.0416\n",
            "Epoch 861: val_loss did not improve from 0.04085\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0417 - mean_absolute_error: 0.1461 - mean_squared_error: 0.0417 - val_loss: 0.0420 - val_mean_absolute_error: 0.1484 - val_mean_squared_error: 0.0420\n",
            "Epoch 862/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0421 - mean_absolute_error: 0.1473 - mean_squared_error: 0.0421\n",
            "Epoch 862: val_loss did not improve from 0.04085\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0422 - mean_absolute_error: 0.1474 - mean_squared_error: 0.0422 - val_loss: 0.0435 - val_mean_absolute_error: 0.1488 - val_mean_squared_error: 0.0435\n",
            "Epoch 863/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 0.0435 - mean_absolute_error: 0.1489 - mean_squared_error: 0.0435\n",
            "Epoch 863: val_loss did not improve from 0.04085\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0430 - mean_absolute_error: 0.1485 - mean_squared_error: 0.0430 - val_loss: 0.0556 - val_mean_absolute_error: 0.1650 - val_mean_squared_error: 0.0556\n",
            "Epoch 864/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 0.0406 - mean_absolute_error: 0.1439 - mean_squared_error: 0.0406\n",
            "Epoch 864: val_loss did not improve from 0.04085\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0406 - mean_absolute_error: 0.1439 - mean_squared_error: 0.0406 - val_loss: 0.0446 - val_mean_absolute_error: 0.1549 - val_mean_squared_error: 0.0446\n",
            "Epoch 865/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0420 - mean_absolute_error: 0.1469 - mean_squared_error: 0.0420\n",
            "Epoch 865: val_loss did not improve from 0.04085\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0420 - mean_absolute_error: 0.1472 - mean_squared_error: 0.0420 - val_loss: 0.0473 - val_mean_absolute_error: 0.1601 - val_mean_squared_error: 0.0473\n",
            "Epoch 866/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 0.0421 - mean_absolute_error: 0.1475 - mean_squared_error: 0.0421\n",
            "Epoch 866: val_loss improved from 0.04085 to 0.03891, saving model to best_model10.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0418 - mean_absolute_error: 0.1469 - mean_squared_error: 0.0418 - val_loss: 0.0389 - val_mean_absolute_error: 0.1434 - val_mean_squared_error: 0.0389\n",
            "Epoch 867/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0397 - mean_absolute_error: 0.1435 - mean_squared_error: 0.0397\n",
            "Epoch 867: val_loss did not improve from 0.03891\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0402 - mean_absolute_error: 0.1441 - mean_squared_error: 0.0402 - val_loss: 0.0418 - val_mean_absolute_error: 0.1482 - val_mean_squared_error: 0.0418\n",
            "Epoch 868/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 0.0425 - mean_absolute_error: 0.1467 - mean_squared_error: 0.0425\n",
            "Epoch 868: val_loss did not improve from 0.03891\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0426 - mean_absolute_error: 0.1467 - mean_squared_error: 0.0426 - val_loss: 0.0568 - val_mean_absolute_error: 0.1706 - val_mean_squared_error: 0.0568\n",
            "Epoch 869/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 0.0412 - mean_absolute_error: 0.1456 - mean_squared_error: 0.0412\n",
            "Epoch 869: val_loss did not improve from 0.03891\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0407 - mean_absolute_error: 0.1446 - mean_squared_error: 0.0407 - val_loss: 0.0390 - val_mean_absolute_error: 0.1444 - val_mean_squared_error: 0.0390\n",
            "Epoch 870/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 0.0398 - mean_absolute_error: 0.1440 - mean_squared_error: 0.0398\n",
            "Epoch 870: val_loss did not improve from 0.03891\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0401 - mean_absolute_error: 0.1446 - mean_squared_error: 0.0401 - val_loss: 0.0397 - val_mean_absolute_error: 0.1451 - val_mean_squared_error: 0.0397\n",
            "Epoch 871/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 0.0404 - mean_absolute_error: 0.1445 - mean_squared_error: 0.0404\n",
            "Epoch 871: val_loss did not improve from 0.03891\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0403 - mean_absolute_error: 0.1443 - mean_squared_error: 0.0403 - val_loss: 0.0425 - val_mean_absolute_error: 0.1495 - val_mean_squared_error: 0.0425\n",
            "Epoch 872/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 0.0397 - mean_absolute_error: 0.1437 - mean_squared_error: 0.0397\n",
            "Epoch 872: val_loss did not improve from 0.03891\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0396 - mean_absolute_error: 0.1436 - mean_squared_error: 0.0396 - val_loss: 0.0425 - val_mean_absolute_error: 0.1453 - val_mean_squared_error: 0.0425\n",
            "Epoch 873/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 0.0396 - mean_absolute_error: 0.1428 - mean_squared_error: 0.0396\n",
            "Epoch 873: val_loss did not improve from 0.03891\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0394 - mean_absolute_error: 0.1426 - mean_squared_error: 0.0394 - val_loss: 0.0396 - val_mean_absolute_error: 0.1444 - val_mean_squared_error: 0.0396\n",
            "Epoch 874/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 0.0394 - mean_absolute_error: 0.1424 - mean_squared_error: 0.0394\n",
            "Epoch 874: val_loss did not improve from 0.03891\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0394 - mean_absolute_error: 0.1424 - mean_squared_error: 0.0394 - val_loss: 0.0436 - val_mean_absolute_error: 0.1499 - val_mean_squared_error: 0.0436\n",
            "Epoch 875/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 0.0392 - mean_absolute_error: 0.1423 - mean_squared_error: 0.0392\n",
            "Epoch 875: val_loss did not improve from 0.03891\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 0.0395 - mean_absolute_error: 0.1431 - mean_squared_error: 0.0395 - val_loss: 0.0427 - val_mean_absolute_error: 0.1497 - val_mean_squared_error: 0.0427\n",
            "Epoch 876/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 0.0400 - mean_absolute_error: 0.1439 - mean_squared_error: 0.0400\n",
            "Epoch 876: val_loss did not improve from 0.03891\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0400 - mean_absolute_error: 0.1440 - mean_squared_error: 0.0400 - val_loss: 0.0423 - val_mean_absolute_error: 0.1497 - val_mean_squared_error: 0.0423\n",
            "Epoch 876: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f847b947110>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = load_model('best_model10.h5')\n",
        "\n",
        "z_predict_test10 = model10.predict(Z_test)\n",
        "\n",
        "plt.plot(z_predict_test10,z_test,'.')\n",
        "\n",
        "print('MSE:', mean_squared_error(z_test, z_predict_test10))\n",
        "print('MAE:', mean_absolute_error(z_test, z_predict_test10))\n",
        "print('RMSE:', mean_squared_error(z_test, z_predict_test10)**0.5)\n",
        "print('Spearman R:', spearmanr(z_test, z_predict_test10))\n",
        "print('R2:', r2_score(z_test, z_predict_test10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "u079TgAaurWz",
        "outputId": "2ad75d41-3e7b-4ca8-bfc6-ec8107213fac"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 0s 1ms/step\n",
            "MSE: 0.04129079637926566\n",
            "MAE: 0.14856958052464816\n",
            "RMSE: 0.20320136903885677\n",
            "Spearman R: SpearmanrResult(correlation=0.9669060576562285, pvalue=0.0)\n",
            "R2: 0.9884206055503723\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#10 capas escondidas, 5 neuronas:\n",
        "\n",
        "model11 = Sequential()\n",
        "#model.add(Dense(100, input_dim=2, activation='sigmoid'))\n",
        "model11.add(Dense(5, input_dim=2, activation='sigmoid'))\n",
        "model11.add(Dense(5, activation='sigmoid'))\n",
        "model11.add(Dense(5, activation='sigmoid'))\n",
        "model11.add(Dense(5, activation='sigmoid'))\n",
        "model11.add(Dense(5, activation='sigmoid'))\n",
        "model11.add(Dense(5, activation='sigmoid'))\n",
        "model11.add(Dense(5, activation='sigmoid'))\n",
        "model11.add(Dense(5, activation='sigmoid'))\n",
        "model11.add(Dense(5, activation='sigmoid'))\n",
        "model11.add(Dense(5, activation='sigmoid'))\n",
        "model11.add(Dense(1, activation='linear'))\n",
        "\n",
        "model11.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error', 'mean_squared_error'])\n",
        "model11.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeOM1dBh2DZK",
        "outputId": "07076705-44e4-4690-9692-ee38150bc9f8"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_28 (Dense)            (None, 5)                 15        \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 291\n",
            "Trainable params: 291\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ajuste:\n",
        "es11 = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "mc11 = ModelCheckpoint('best_model11.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)"
      ],
      "metadata": {
        "id": "eMH8BFdW2Q4Q"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model11.fit(Z_train, z_train, epochs=1000, batch_size=20, validation_split=0.3, shuffle=True, verbose=True, callbacks=[es11,mc11])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWtH6-qs2af4",
        "outputId": "5515608f-c5bb-4225-c7f4-b26290a42ec0"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 3.7709 - mean_absolute_error: 1.2562 - mean_squared_error: 3.7709\n",
            "Epoch 1: val_loss did not improve from 3.62919\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.7480 - mean_absolute_error: 1.2501 - mean_squared_error: 3.7480 - val_loss: 3.6357 - val_mean_absolute_error: 1.2511 - val_mean_squared_error: 3.6357\n",
            "Epoch 2/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 3.7733 - mean_absolute_error: 1.2615 - mean_squared_error: 3.7733\n",
            "Epoch 2: val_loss improved from 3.62919 to 3.62780, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.7478 - mean_absolute_error: 1.2560 - mean_squared_error: 3.7478 - val_loss: 3.6278 - val_mean_absolute_error: 1.2310 - val_mean_squared_error: 3.6278\n",
            "Epoch 3/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 3.7483 - mean_absolute_error: 1.2512 - mean_squared_error: 3.7483\n",
            "Epoch 3: val_loss did not improve from 3.62780\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.7483 - mean_absolute_error: 1.2512 - mean_squared_error: 3.7483 - val_loss: 3.6287 - val_mean_absolute_error: 1.2346 - val_mean_squared_error: 3.6287\n",
            "Epoch 4/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 3.7298 - mean_absolute_error: 1.2418 - mean_squared_error: 3.7298\n",
            "Epoch 4: val_loss did not improve from 3.62780\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.7479 - mean_absolute_error: 1.2456 - mean_squared_error: 3.7479 - val_loss: 3.6335 - val_mean_absolute_error: 1.2470 - val_mean_squared_error: 3.6335\n",
            "Epoch 5/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 3.7539 - mean_absolute_error: 1.2527 - mean_squared_error: 3.7539\n",
            "Epoch 5: val_loss did not improve from 3.62780\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.7495 - mean_absolute_error: 1.2531 - mean_squared_error: 3.7495 - val_loss: 3.6310 - val_mean_absolute_error: 1.2416 - val_mean_squared_error: 3.6310\n",
            "Epoch 6/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 3.7134 - mean_absolute_error: 1.2469 - mean_squared_error: 3.7134\n",
            "Epoch 6: val_loss did not improve from 3.62780\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.7483 - mean_absolute_error: 1.2507 - mean_squared_error: 3.7483 - val_loss: 3.6314 - val_mean_absolute_error: 1.2439 - val_mean_squared_error: 3.6314\n",
            "Epoch 7/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 3.7480 - mean_absolute_error: 1.2521 - mean_squared_error: 3.7480\n",
            "Epoch 7: val_loss improved from 3.62780 to 3.62212, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.7450 - mean_absolute_error: 1.2524 - mean_squared_error: 3.7450 - val_loss: 3.6221 - val_mean_absolute_error: 1.2360 - val_mean_squared_error: 3.6221\n",
            "Epoch 8/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 3.7393 - mean_absolute_error: 1.2449 - mean_squared_error: 3.7393\n",
            "Epoch 8: val_loss improved from 3.62212 to 3.59733, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.7291 - mean_absolute_error: 1.2415 - mean_squared_error: 3.7291 - val_loss: 3.5973 - val_mean_absolute_error: 1.2396 - val_mean_squared_error: 3.5973\n",
            "Epoch 9/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 3.7133 - mean_absolute_error: 1.2482 - mean_squared_error: 3.7133\n",
            "Epoch 9: val_loss improved from 3.59733 to 3.48138, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 3.6686 - mean_absolute_error: 1.2398 - mean_squared_error: 3.6686 - val_loss: 3.4814 - val_mean_absolute_error: 1.1909 - val_mean_squared_error: 3.4814\n",
            "Epoch 10/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 3.4490 - mean_absolute_error: 1.1695 - mean_squared_error: 3.4490\n",
            "Epoch 10: val_loss improved from 3.48138 to 3.15617, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 3.4560 - mean_absolute_error: 1.1726 - mean_squared_error: 3.4560 - val_loss: 3.1562 - val_mean_absolute_error: 1.1017 - val_mean_squared_error: 3.1562\n",
            "Epoch 11/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 3.1327 - mean_absolute_error: 1.1150 - mean_squared_error: 3.1327\n",
            "Epoch 11: val_loss improved from 3.15617 to 2.83177, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 3.0729 - mean_absolute_error: 1.1058 - mean_squared_error: 3.0729 - val_loss: 2.8318 - val_mean_absolute_error: 1.0953 - val_mean_squared_error: 2.8318\n",
            "Epoch 12/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 2.8251 - mean_absolute_error: 1.1332 - mean_squared_error: 2.8251\n",
            "Epoch 12: val_loss improved from 2.83177 to 2.71455, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.8332 - mean_absolute_error: 1.1346 - mean_squared_error: 2.8332 - val_loss: 2.7146 - val_mean_absolute_error: 1.1458 - val_mean_squared_error: 2.7146\n",
            "Epoch 13/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.7351 - mean_absolute_error: 1.1656 - mean_squared_error: 2.7351\n",
            "Epoch 13: val_loss improved from 2.71455 to 2.68491, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7507 - mean_absolute_error: 1.1676 - mean_squared_error: 2.7507 - val_loss: 2.6849 - val_mean_absolute_error: 1.1673 - val_mean_squared_error: 2.6849\n",
            "Epoch 14/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.7352 - mean_absolute_error: 1.1820 - mean_squared_error: 2.7352\n",
            "Epoch 14: val_loss did not improve from 2.68491\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7261 - mean_absolute_error: 1.1800 - mean_squared_error: 2.7261 - val_loss: 2.6874 - val_mean_absolute_error: 1.1762 - val_mean_squared_error: 2.6874\n",
            "Epoch 15/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.7084 - mean_absolute_error: 1.1795 - mean_squared_error: 2.7084\n",
            "Epoch 15: val_loss improved from 2.68491 to 2.67491, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7123 - mean_absolute_error: 1.1828 - mean_squared_error: 2.7123 - val_loss: 2.6749 - val_mean_absolute_error: 1.1796 - val_mean_squared_error: 2.6749\n",
            "Epoch 16/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.7156 - mean_absolute_error: 1.1881 - mean_squared_error: 2.7156\n",
            "Epoch 16: val_loss did not improve from 2.67491\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.7050 - mean_absolute_error: 1.1866 - mean_squared_error: 2.7050 - val_loss: 2.6768 - val_mean_absolute_error: 1.1798 - val_mean_squared_error: 2.6768\n",
            "Epoch 17/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.7255 - mean_absolute_error: 1.1916 - mean_squared_error: 2.7255\n",
            "Epoch 17: val_loss improved from 2.67491 to 2.66905, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7052 - mean_absolute_error: 1.1879 - mean_squared_error: 2.7052 - val_loss: 2.6691 - val_mean_absolute_error: 1.1808 - val_mean_squared_error: 2.6691\n",
            "Epoch 18/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.7250 - mean_absolute_error: 1.1923 - mean_squared_error: 2.7250\n",
            "Epoch 18: val_loss improved from 2.66905 to 2.66569, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.7017 - mean_absolute_error: 1.1885 - mean_squared_error: 2.7017 - val_loss: 2.6657 - val_mean_absolute_error: 1.1778 - val_mean_squared_error: 2.6657\n",
            "Epoch 19/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.7196 - mean_absolute_error: 1.1905 - mean_squared_error: 2.7196\n",
            "Epoch 19: val_loss improved from 2.66569 to 2.66084, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6993 - mean_absolute_error: 1.1884 - mean_squared_error: 2.6993 - val_loss: 2.6608 - val_mean_absolute_error: 1.1794 - val_mean_squared_error: 2.6608\n",
            "Epoch 20/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.6959 - mean_absolute_error: 1.1871 - mean_squared_error: 2.6959\n",
            "Epoch 20: val_loss improved from 2.66084 to 2.66036, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6962 - mean_absolute_error: 1.1875 - mean_squared_error: 2.6962 - val_loss: 2.6604 - val_mean_absolute_error: 1.1792 - val_mean_squared_error: 2.6604\n",
            "Epoch 21/1000\n",
            "224/245 [==========================>...] - ETA: 0s - loss: 2.7165 - mean_absolute_error: 1.1895 - mean_squared_error: 2.7165\n",
            "Epoch 21: val_loss improved from 2.66036 to 2.65479, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6938 - mean_absolute_error: 1.1895 - mean_squared_error: 2.6938 - val_loss: 2.6548 - val_mean_absolute_error: 1.1713 - val_mean_squared_error: 2.6548\n",
            "Epoch 22/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.6155 - mean_absolute_error: 1.1728 - mean_squared_error: 2.6155\n",
            "Epoch 22: val_loss improved from 2.65479 to 2.65413, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6900 - mean_absolute_error: 1.1839 - mean_squared_error: 2.6900 - val_loss: 2.6541 - val_mean_absolute_error: 1.1747 - val_mean_squared_error: 2.6541\n",
            "Epoch 23/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.6986 - mean_absolute_error: 1.1828 - mean_squared_error: 2.6986\n",
            "Epoch 23: val_loss improved from 2.65413 to 2.65241, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6867 - mean_absolute_error: 1.1811 - mean_squared_error: 2.6867 - val_loss: 2.6524 - val_mean_absolute_error: 1.1851 - val_mean_squared_error: 2.6524\n",
            "Epoch 24/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.6819 - mean_absolute_error: 1.1835 - mean_squared_error: 2.6819\n",
            "Epoch 24: val_loss did not improve from 2.65241\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6809 - mean_absolute_error: 1.1842 - mean_squared_error: 2.6809 - val_loss: 2.6553 - val_mean_absolute_error: 1.1679 - val_mean_squared_error: 2.6553\n",
            "Epoch 25/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.6969 - mean_absolute_error: 1.1859 - mean_squared_error: 2.6969\n",
            "Epoch 25: val_loss improved from 2.65241 to 2.64219, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6817 - mean_absolute_error: 1.1839 - mean_squared_error: 2.6817 - val_loss: 2.6422 - val_mean_absolute_error: 1.1713 - val_mean_squared_error: 2.6422\n",
            "Epoch 26/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.6719 - mean_absolute_error: 1.1798 - mean_squared_error: 2.6719\n",
            "Epoch 26: val_loss improved from 2.64219 to 2.64176, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6771 - mean_absolute_error: 1.1804 - mean_squared_error: 2.6771 - val_loss: 2.6418 - val_mean_absolute_error: 1.1714 - val_mean_squared_error: 2.6418\n",
            "Epoch 27/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.6732 - mean_absolute_error: 1.1800 - mean_squared_error: 2.6732\n",
            "Epoch 27: val_loss improved from 2.64176 to 2.63691, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6732 - mean_absolute_error: 1.1800 - mean_squared_error: 2.6732 - val_loss: 2.6369 - val_mean_absolute_error: 1.1719 - val_mean_squared_error: 2.6369\n",
            "Epoch 28/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.6548 - mean_absolute_error: 1.1754 - mean_squared_error: 2.6548\n",
            "Epoch 28: val_loss improved from 2.63691 to 2.63392, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.6716 - mean_absolute_error: 1.1795 - mean_squared_error: 2.6716 - val_loss: 2.6339 - val_mean_absolute_error: 1.1753 - val_mean_squared_error: 2.6339\n",
            "Epoch 29/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.6519 - mean_absolute_error: 1.1799 - mean_squared_error: 2.6519\n",
            "Epoch 29: val_loss did not improve from 2.63392\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6700 - mean_absolute_error: 1.1835 - mean_squared_error: 2.6700 - val_loss: 2.6352 - val_mean_absolute_error: 1.1714 - val_mean_squared_error: 2.6352\n",
            "Epoch 30/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.6306 - mean_absolute_error: 1.1751 - mean_squared_error: 2.6306\n",
            "Epoch 30: val_loss improved from 2.63392 to 2.63284, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6690 - mean_absolute_error: 1.1792 - mean_squared_error: 2.6690 - val_loss: 2.6328 - val_mean_absolute_error: 1.1728 - val_mean_squared_error: 2.6328\n",
            "Epoch 31/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.6846 - mean_absolute_error: 1.1901 - mean_squared_error: 2.6845\n",
            "Epoch 31: val_loss improved from 2.63284 to 2.63277, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6678 - mean_absolute_error: 1.1867 - mean_squared_error: 2.6678 - val_loss: 2.6328 - val_mean_absolute_error: 1.1688 - val_mean_squared_error: 2.6328\n",
            "Epoch 32/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.6681 - mean_absolute_error: 1.1837 - mean_squared_error: 2.6681\n",
            "Epoch 32: val_loss improved from 2.63277 to 2.63142, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6662 - mean_absolute_error: 1.1817 - mean_squared_error: 2.6662 - val_loss: 2.6314 - val_mean_absolute_error: 1.1720 - val_mean_squared_error: 2.6314\n",
            "Epoch 33/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.6435 - mean_absolute_error: 1.1810 - mean_squared_error: 2.6435\n",
            "Epoch 33: val_loss did not improve from 2.63142\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6666 - mean_absolute_error: 1.1843 - mean_squared_error: 2.6666 - val_loss: 2.6328 - val_mean_absolute_error: 1.1693 - val_mean_squared_error: 2.6328\n",
            "Epoch 34/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.6444 - mean_absolute_error: 1.1766 - mean_squared_error: 2.6444\n",
            "Epoch 34: val_loss did not improve from 2.63142\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6644 - mean_absolute_error: 1.1803 - mean_squared_error: 2.6644 - val_loss: 2.6316 - val_mean_absolute_error: 1.1776 - val_mean_squared_error: 2.6316\n",
            "Epoch 35/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.6691 - mean_absolute_error: 1.1877 - mean_squared_error: 2.6691\n",
            "Epoch 35: val_loss did not improve from 2.63142\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6633 - mean_absolute_error: 1.1864 - mean_squared_error: 2.6633 - val_loss: 2.6320 - val_mean_absolute_error: 1.1721 - val_mean_squared_error: 2.6320\n",
            "Epoch 36/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.6710 - mean_absolute_error: 1.1834 - mean_squared_error: 2.6710\n",
            "Epoch 36: val_loss improved from 2.63142 to 2.63025, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6630 - mean_absolute_error: 1.1866 - mean_squared_error: 2.6630 - val_loss: 2.6303 - val_mean_absolute_error: 1.1724 - val_mean_squared_error: 2.6303\n",
            "Epoch 37/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.6729 - mean_absolute_error: 1.1825 - mean_squared_error: 2.6729\n",
            "Epoch 37: val_loss improved from 2.63025 to 2.62737, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.6623 - mean_absolute_error: 1.1812 - mean_squared_error: 2.6623 - val_loss: 2.6274 - val_mean_absolute_error: 1.1803 - val_mean_squared_error: 2.6274\n",
            "Epoch 38/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.6241 - mean_absolute_error: 1.1757 - mean_squared_error: 2.6241\n",
            "Epoch 38: val_loss did not improve from 2.62737\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.6625 - mean_absolute_error: 1.1838 - mean_squared_error: 2.6625 - val_loss: 2.6310 - val_mean_absolute_error: 1.1809 - val_mean_squared_error: 2.6310\n",
            "Epoch 39/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.6520 - mean_absolute_error: 1.1839 - mean_squared_error: 2.6520\n",
            "Epoch 39: val_loss did not improve from 2.62737\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.6626 - mean_absolute_error: 1.1846 - mean_squared_error: 2.6626 - val_loss: 2.6332 - val_mean_absolute_error: 1.1751 - val_mean_squared_error: 2.6332\n",
            "Epoch 40/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.6658 - mean_absolute_error: 1.1859 - mean_squared_error: 2.6658\n",
            "Epoch 40: val_loss did not improve from 2.62737\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.6621 - mean_absolute_error: 1.1845 - mean_squared_error: 2.6621 - val_loss: 2.6284 - val_mean_absolute_error: 1.1843 - val_mean_squared_error: 2.6284\n",
            "Epoch 41/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.6653 - mean_absolute_error: 1.1875 - mean_squared_error: 2.6653\n",
            "Epoch 41: val_loss did not improve from 2.62737\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6600 - mean_absolute_error: 1.1862 - mean_squared_error: 2.6600 - val_loss: 2.6290 - val_mean_absolute_error: 1.1763 - val_mean_squared_error: 2.6290\n",
            "Epoch 42/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.6492 - mean_absolute_error: 1.1812 - mean_squared_error: 2.6492\n",
            "Epoch 42: val_loss improved from 2.62737 to 2.62632, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6586 - mean_absolute_error: 1.1830 - mean_squared_error: 2.6586 - val_loss: 2.6263 - val_mean_absolute_error: 1.1837 - val_mean_squared_error: 2.6263\n",
            "Epoch 43/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.6229 - mean_absolute_error: 1.1811 - mean_squared_error: 2.6229\n",
            "Epoch 43: val_loss did not improve from 2.62632\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.6594 - mean_absolute_error: 1.1869 - mean_squared_error: 2.6594 - val_loss: 2.6309 - val_mean_absolute_error: 1.1694 - val_mean_squared_error: 2.6309\n",
            "Epoch 44/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.6388 - mean_absolute_error: 1.1769 - mean_squared_error: 2.6388\n",
            "Epoch 44: val_loss did not improve from 2.62632\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6587 - mean_absolute_error: 1.1814 - mean_squared_error: 2.6587 - val_loss: 2.6266 - val_mean_absolute_error: 1.1844 - val_mean_squared_error: 2.6266\n",
            "Epoch 45/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.6645 - mean_absolute_error: 1.1898 - mean_squared_error: 2.6645\n",
            "Epoch 45: val_loss improved from 2.62632 to 2.62368, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6594 - mean_absolute_error: 1.1874 - mean_squared_error: 2.6594 - val_loss: 2.6237 - val_mean_absolute_error: 1.1784 - val_mean_squared_error: 2.6237\n",
            "Epoch 46/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.6659 - mean_absolute_error: 1.1889 - mean_squared_error: 2.6659\n",
            "Epoch 46: val_loss did not improve from 2.62368\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6585 - mean_absolute_error: 1.1882 - mean_squared_error: 2.6585 - val_loss: 2.6252 - val_mean_absolute_error: 1.1753 - val_mean_squared_error: 2.6252\n",
            "Epoch 47/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.6593 - mean_absolute_error: 1.1818 - mean_squared_error: 2.6593\n",
            "Epoch 47: val_loss did not improve from 2.62368\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6576 - mean_absolute_error: 1.1814 - mean_squared_error: 2.6576 - val_loss: 2.6265 - val_mean_absolute_error: 1.1783 - val_mean_squared_error: 2.6265\n",
            "Epoch 48/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.6816 - mean_absolute_error: 1.1928 - mean_squared_error: 2.6816\n",
            "Epoch 48: val_loss did not improve from 2.62368\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6570 - mean_absolute_error: 1.1879 - mean_squared_error: 2.6570 - val_loss: 2.6304 - val_mean_absolute_error: 1.1754 - val_mean_squared_error: 2.6304\n",
            "Epoch 49/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.6052 - mean_absolute_error: 1.1694 - mean_squared_error: 2.6052\n",
            "Epoch 49: val_loss improved from 2.62368 to 2.62308, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.6586 - mean_absolute_error: 1.1794 - mean_squared_error: 2.6586 - val_loss: 2.6231 - val_mean_absolute_error: 1.1796 - val_mean_squared_error: 2.6231\n",
            "Epoch 50/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.6498 - mean_absolute_error: 1.1868 - mean_squared_error: 2.6498\n",
            "Epoch 50: val_loss did not improve from 2.62308\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6564 - mean_absolute_error: 1.1877 - mean_squared_error: 2.6564 - val_loss: 2.6246 - val_mean_absolute_error: 1.1790 - val_mean_squared_error: 2.6246\n",
            "Epoch 51/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.6576 - mean_absolute_error: 1.1846 - mean_squared_error: 2.6576\n",
            "Epoch 51: val_loss did not improve from 2.62308\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6576 - mean_absolute_error: 1.1846 - mean_squared_error: 2.6576 - val_loss: 2.6237 - val_mean_absolute_error: 1.1757 - val_mean_squared_error: 2.6237\n",
            "Epoch 52/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.6715 - mean_absolute_error: 1.1857 - mean_squared_error: 2.6715\n",
            "Epoch 52: val_loss did not improve from 2.62308\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6562 - mean_absolute_error: 1.1845 - mean_squared_error: 2.6562 - val_loss: 2.6239 - val_mean_absolute_error: 1.1795 - val_mean_squared_error: 2.6239\n",
            "Epoch 53/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.6513 - mean_absolute_error: 1.1875 - mean_squared_error: 2.6513\n",
            "Epoch 53: val_loss improved from 2.62308 to 2.62276, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.6551 - mean_absolute_error: 1.1868 - mean_squared_error: 2.6551 - val_loss: 2.6228 - val_mean_absolute_error: 1.1767 - val_mean_squared_error: 2.6228\n",
            "Epoch 54/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.6545 - mean_absolute_error: 1.1849 - mean_squared_error: 2.6545\n",
            "Epoch 54: val_loss did not improve from 2.62276\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6536 - mean_absolute_error: 1.1845 - mean_squared_error: 2.6536 - val_loss: 2.6327 - val_mean_absolute_error: 1.1738 - val_mean_squared_error: 2.6327\n",
            "Epoch 55/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.6406 - mean_absolute_error: 1.1833 - mean_squared_error: 2.6406\n",
            "Epoch 55: val_loss improved from 2.62276 to 2.62073, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6551 - mean_absolute_error: 1.1862 - mean_squared_error: 2.6551 - val_loss: 2.6207 - val_mean_absolute_error: 1.1721 - val_mean_squared_error: 2.6207\n",
            "Epoch 56/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.6491 - mean_absolute_error: 1.1874 - mean_squared_error: 2.6491\n",
            "Epoch 56: val_loss did not improve from 2.62073\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6556 - mean_absolute_error: 1.1859 - mean_squared_error: 2.6556 - val_loss: 2.6218 - val_mean_absolute_error: 1.1686 - val_mean_squared_error: 2.6218\n",
            "Epoch 57/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.6532 - mean_absolute_error: 1.1854 - mean_squared_error: 2.6532\n",
            "Epoch 57: val_loss did not improve from 2.62073\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6519 - mean_absolute_error: 1.1844 - mean_squared_error: 2.6519 - val_loss: 2.6298 - val_mean_absolute_error: 1.1721 - val_mean_squared_error: 2.6298\n",
            "Epoch 58/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.6516 - mean_absolute_error: 1.1819 - mean_squared_error: 2.6516\n",
            "Epoch 58: val_loss did not improve from 2.62073\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6551 - mean_absolute_error: 1.1821 - mean_squared_error: 2.6551 - val_loss: 2.6232 - val_mean_absolute_error: 1.1686 - val_mean_squared_error: 2.6232\n",
            "Epoch 59/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.6527 - mean_absolute_error: 1.1802 - mean_squared_error: 2.6527\n",
            "Epoch 59: val_loss did not improve from 2.62073\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.6521 - mean_absolute_error: 1.1829 - mean_squared_error: 2.6521 - val_loss: 2.6317 - val_mean_absolute_error: 1.1803 - val_mean_squared_error: 2.6317\n",
            "Epoch 60/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.6373 - mean_absolute_error: 1.1838 - mean_squared_error: 2.6373\n",
            "Epoch 60: val_loss improved from 2.62073 to 2.61977, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6530 - mean_absolute_error: 1.1855 - mean_squared_error: 2.6530 - val_loss: 2.6198 - val_mean_absolute_error: 1.1709 - val_mean_squared_error: 2.6198\n",
            "Epoch 61/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.6399 - mean_absolute_error: 1.1806 - mean_squared_error: 2.6399\n",
            "Epoch 61: val_loss did not improve from 2.61977\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6507 - mean_absolute_error: 1.1818 - mean_squared_error: 2.6507 - val_loss: 2.6227 - val_mean_absolute_error: 1.1693 - val_mean_squared_error: 2.6227\n",
            "Epoch 62/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.6255 - mean_absolute_error: 1.1776 - mean_squared_error: 2.6255\n",
            "Epoch 62: val_loss improved from 2.61977 to 2.61750, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6506 - mean_absolute_error: 1.1819 - mean_squared_error: 2.6506 - val_loss: 2.6175 - val_mean_absolute_error: 1.1759 - val_mean_squared_error: 2.6175\n",
            "Epoch 63/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.6265 - mean_absolute_error: 1.1804 - mean_squared_error: 2.6265\n",
            "Epoch 63: val_loss did not improve from 2.61750\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.6491 - mean_absolute_error: 1.1851 - mean_squared_error: 2.6491 - val_loss: 2.6200 - val_mean_absolute_error: 1.1706 - val_mean_squared_error: 2.6200\n",
            "Epoch 64/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.6449 - mean_absolute_error: 1.1833 - mean_squared_error: 2.6449\n",
            "Epoch 64: val_loss did not improve from 2.61750\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.6484 - mean_absolute_error: 1.1847 - mean_squared_error: 2.6484 - val_loss: 2.6223 - val_mean_absolute_error: 1.1715 - val_mean_squared_error: 2.6223\n",
            "Epoch 65/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.6367 - mean_absolute_error: 1.1809 - mean_squared_error: 2.6367\n",
            "Epoch 65: val_loss did not improve from 2.61750\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6486 - mean_absolute_error: 1.1829 - mean_squared_error: 2.6486 - val_loss: 2.6191 - val_mean_absolute_error: 1.1704 - val_mean_squared_error: 2.6191\n",
            "Epoch 66/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.5760 - mean_absolute_error: 1.1683 - mean_squared_error: 2.5760\n",
            "Epoch 66: val_loss improved from 2.61750 to 2.61663, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6481 - mean_absolute_error: 1.1799 - mean_squared_error: 2.6481 - val_loss: 2.6166 - val_mean_absolute_error: 1.1743 - val_mean_squared_error: 2.6166\n",
            "Epoch 67/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.6674 - mean_absolute_error: 1.1861 - mean_squared_error: 2.6674\n",
            "Epoch 67: val_loss improved from 2.61663 to 2.61462, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6512 - mean_absolute_error: 1.1864 - mean_squared_error: 2.6512 - val_loss: 2.6146 - val_mean_absolute_error: 1.1781 - val_mean_squared_error: 2.6146\n",
            "Epoch 68/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.6451 - mean_absolute_error: 1.1828 - mean_squared_error: 2.6451\n",
            "Epoch 68: val_loss did not improve from 2.61462\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6450 - mean_absolute_error: 1.1827 - mean_squared_error: 2.6450 - val_loss: 2.6163 - val_mean_absolute_error: 1.1692 - val_mean_squared_error: 2.6163\n",
            "Epoch 69/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.6432 - mean_absolute_error: 1.1802 - mean_squared_error: 2.6432\n",
            "Epoch 69: val_loss did not improve from 2.61462\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.6460 - mean_absolute_error: 1.1804 - mean_squared_error: 2.6460 - val_loss: 2.6167 - val_mean_absolute_error: 1.1714 - val_mean_squared_error: 2.6167\n",
            "Epoch 70/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.6463 - mean_absolute_error: 1.1837 - mean_squared_error: 2.6463\n",
            "Epoch 70: val_loss improved from 2.61462 to 2.61320, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6461 - mean_absolute_error: 1.1833 - mean_squared_error: 2.6461 - val_loss: 2.6132 - val_mean_absolute_error: 1.1751 - val_mean_squared_error: 2.6132\n",
            "Epoch 71/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.6447 - mean_absolute_error: 1.1822 - mean_squared_error: 2.6447\n",
            "Epoch 71: val_loss did not improve from 2.61320\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.6435 - mean_absolute_error: 1.1813 - mean_squared_error: 2.6435 - val_loss: 2.6142 - val_mean_absolute_error: 1.1733 - val_mean_squared_error: 2.6142\n",
            "Epoch 72/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.6443 - mean_absolute_error: 1.1801 - mean_squared_error: 2.6443\n",
            "Epoch 72: val_loss did not improve from 2.61320\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6442 - mean_absolute_error: 1.1798 - mean_squared_error: 2.6442 - val_loss: 2.6160 - val_mean_absolute_error: 1.1805 - val_mean_squared_error: 2.6160\n",
            "Epoch 73/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.6253 - mean_absolute_error: 1.1769 - mean_squared_error: 2.6253\n",
            "Epoch 73: val_loss did not improve from 2.61320\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6431 - mean_absolute_error: 1.1816 - mean_squared_error: 2.6431 - val_loss: 2.6138 - val_mean_absolute_error: 1.1743 - val_mean_squared_error: 2.6138\n",
            "Epoch 74/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.6439 - mean_absolute_error: 1.1827 - mean_squared_error: 2.6439\n",
            "Epoch 74: val_loss improved from 2.61320 to 2.61113, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.6425 - mean_absolute_error: 1.1826 - mean_squared_error: 2.6425 - val_loss: 2.6111 - val_mean_absolute_error: 1.1781 - val_mean_squared_error: 2.6111\n",
            "Epoch 75/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.6396 - mean_absolute_error: 1.1806 - mean_squared_error: 2.6396\n",
            "Epoch 75: val_loss improved from 2.61113 to 2.61026, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6409 - mean_absolute_error: 1.1807 - mean_squared_error: 2.6409 - val_loss: 2.6103 - val_mean_absolute_error: 1.1807 - val_mean_squared_error: 2.6103\n",
            "Epoch 76/1000\n",
            "222/245 [==========================>...] - ETA: 0s - loss: 2.6779 - mean_absolute_error: 1.1895 - mean_squared_error: 2.6779\n",
            "Epoch 76: val_loss improved from 2.61026 to 2.60886, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6406 - mean_absolute_error: 1.1837 - mean_squared_error: 2.6406 - val_loss: 2.6089 - val_mean_absolute_error: 1.1771 - val_mean_squared_error: 2.6089\n",
            "Epoch 77/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.6489 - mean_absolute_error: 1.1797 - mean_squared_error: 2.6489\n",
            "Epoch 77: val_loss did not improve from 2.60886\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6381 - mean_absolute_error: 1.1802 - mean_squared_error: 2.6381 - val_loss: 2.6102 - val_mean_absolute_error: 1.1709 - val_mean_squared_error: 2.6102\n",
            "Epoch 78/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.6556 - mean_absolute_error: 1.1846 - mean_squared_error: 2.6556\n",
            "Epoch 78: val_loss did not improve from 2.60886\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6392 - mean_absolute_error: 1.1805 - mean_squared_error: 2.6392 - val_loss: 2.6108 - val_mean_absolute_error: 1.1709 - val_mean_squared_error: 2.6108\n",
            "Epoch 79/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.6355 - mean_absolute_error: 1.1810 - mean_squared_error: 2.6355\n",
            "Epoch 79: val_loss improved from 2.60886 to 2.60805, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6373 - mean_absolute_error: 1.1812 - mean_squared_error: 2.6373 - val_loss: 2.6080 - val_mean_absolute_error: 1.1662 - val_mean_squared_error: 2.6080\n",
            "Epoch 80/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.6573 - mean_absolute_error: 1.1826 - mean_squared_error: 2.6573\n",
            "Epoch 80: val_loss did not improve from 2.60805\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6378 - mean_absolute_error: 1.1791 - mean_squared_error: 2.6378 - val_loss: 2.6102 - val_mean_absolute_error: 1.1711 - val_mean_squared_error: 2.6102\n",
            "Epoch 81/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.6643 - mean_absolute_error: 1.1826 - mean_squared_error: 2.6643\n",
            "Epoch 81: val_loss improved from 2.60805 to 2.60309, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6354 - mean_absolute_error: 1.1791 - mean_squared_error: 2.6354 - val_loss: 2.6031 - val_mean_absolute_error: 1.1741 - val_mean_squared_error: 2.6031\n",
            "Epoch 82/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.6123 - mean_absolute_error: 1.1743 - mean_squared_error: 2.6123\n",
            "Epoch 82: val_loss did not improve from 2.60309\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.6320 - mean_absolute_error: 1.1782 - mean_squared_error: 2.6320 - val_loss: 2.6107 - val_mean_absolute_error: 1.1724 - val_mean_squared_error: 2.6107\n",
            "Epoch 83/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.6361 - mean_absolute_error: 1.1760 - mean_squared_error: 2.6361\n",
            "Epoch 83: val_loss did not improve from 2.60309\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6350 - mean_absolute_error: 1.1765 - mean_squared_error: 2.6350 - val_loss: 2.6102 - val_mean_absolute_error: 1.1860 - val_mean_squared_error: 2.6102\n",
            "Epoch 84/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.6367 - mean_absolute_error: 1.1818 - mean_squared_error: 2.6367\n",
            "Epoch 84: val_loss did not improve from 2.60309\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6336 - mean_absolute_error: 1.1798 - mean_squared_error: 2.6336 - val_loss: 2.6034 - val_mean_absolute_error: 1.1732 - val_mean_squared_error: 2.6034\n",
            "Epoch 85/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.6507 - mean_absolute_error: 1.1837 - mean_squared_error: 2.6507\n",
            "Epoch 85: val_loss improved from 2.60309 to 2.60282, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6313 - mean_absolute_error: 1.1789 - mean_squared_error: 2.6313 - val_loss: 2.6028 - val_mean_absolute_error: 1.1746 - val_mean_squared_error: 2.6028\n",
            "Epoch 86/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.6506 - mean_absolute_error: 1.1850 - mean_squared_error: 2.6506\n",
            "Epoch 86: val_loss improved from 2.60282 to 2.59988, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6327 - mean_absolute_error: 1.1818 - mean_squared_error: 2.6327 - val_loss: 2.5999 - val_mean_absolute_error: 1.1679 - val_mean_squared_error: 2.5999\n",
            "Epoch 87/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.6254 - mean_absolute_error: 1.1756 - mean_squared_error: 2.6254\n",
            "Epoch 87: val_loss improved from 2.59988 to 2.59975, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6317 - mean_absolute_error: 1.1754 - mean_squared_error: 2.6317 - val_loss: 2.5997 - val_mean_absolute_error: 1.1658 - val_mean_squared_error: 2.5997\n",
            "Epoch 88/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.6215 - mean_absolute_error: 1.1704 - mean_squared_error: 2.6215\n",
            "Epoch 88: val_loss improved from 2.59975 to 2.59641, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6294 - mean_absolute_error: 1.1772 - mean_squared_error: 2.6294 - val_loss: 2.5964 - val_mean_absolute_error: 1.1725 - val_mean_squared_error: 2.5964\n",
            "Epoch 89/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.6271 - mean_absolute_error: 1.1759 - mean_squared_error: 2.6271\n",
            "Epoch 89: val_loss did not improve from 2.59641\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6271 - mean_absolute_error: 1.1759 - mean_squared_error: 2.6271 - val_loss: 2.5971 - val_mean_absolute_error: 1.1722 - val_mean_squared_error: 2.5971\n",
            "Epoch 90/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.6328 - mean_absolute_error: 1.1846 - mean_squared_error: 2.6328\n",
            "Epoch 90: val_loss did not improve from 2.59641\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6270 - mean_absolute_error: 1.1829 - mean_squared_error: 2.6270 - val_loss: 2.5990 - val_mean_absolute_error: 1.1585 - val_mean_squared_error: 2.5990\n",
            "Epoch 91/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.6393 - mean_absolute_error: 1.1732 - mean_squared_error: 2.6393\n",
            "Epoch 91: val_loss improved from 2.59641 to 2.59277, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.6262 - mean_absolute_error: 1.1724 - mean_squared_error: 2.6262 - val_loss: 2.5928 - val_mean_absolute_error: 1.1709 - val_mean_squared_error: 2.5928\n",
            "Epoch 92/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.6283 - mean_absolute_error: 1.1695 - mean_squared_error: 2.6283\n",
            "Epoch 92: val_loss did not improve from 2.59277\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6250 - mean_absolute_error: 1.1727 - mean_squared_error: 2.6250 - val_loss: 2.5937 - val_mean_absolute_error: 1.1725 - val_mean_squared_error: 2.5937\n",
            "Epoch 93/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.5737 - mean_absolute_error: 1.1683 - mean_squared_error: 2.5737\n",
            "Epoch 93: val_loss did not improve from 2.59277\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6249 - mean_absolute_error: 1.1767 - mean_squared_error: 2.6249 - val_loss: 2.5951 - val_mean_absolute_error: 1.1722 - val_mean_squared_error: 2.5951\n",
            "Epoch 94/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.6393 - mean_absolute_error: 1.1804 - mean_squared_error: 2.6393\n",
            "Epoch 94: val_loss improved from 2.59277 to 2.58914, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6213 - mean_absolute_error: 1.1756 - mean_squared_error: 2.6213 - val_loss: 2.5891 - val_mean_absolute_error: 1.1696 - val_mean_squared_error: 2.5891\n",
            "Epoch 95/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.6171 - mean_absolute_error: 1.1764 - mean_squared_error: 2.6171\n",
            "Epoch 95: val_loss did not improve from 2.58914\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6210 - mean_absolute_error: 1.1755 - mean_squared_error: 2.6210 - val_loss: 2.5913 - val_mean_absolute_error: 1.1625 - val_mean_squared_error: 2.5913\n",
            "Epoch 96/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.6094 - mean_absolute_error: 1.1701 - mean_squared_error: 2.6094\n",
            "Epoch 96: val_loss did not improve from 2.58914\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6175 - mean_absolute_error: 1.1718 - mean_squared_error: 2.6175 - val_loss: 2.5961 - val_mean_absolute_error: 1.1783 - val_mean_squared_error: 2.5961\n",
            "Epoch 97/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.6244 - mean_absolute_error: 1.1734 - mean_squared_error: 2.6244\n",
            "Epoch 97: val_loss improved from 2.58914 to 2.58639, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6175 - mean_absolute_error: 1.1722 - mean_squared_error: 2.6175 - val_loss: 2.5864 - val_mean_absolute_error: 1.1696 - val_mean_squared_error: 2.5864\n",
            "Epoch 98/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.6187 - mean_absolute_error: 1.1727 - mean_squared_error: 2.6187\n",
            "Epoch 98: val_loss improved from 2.58639 to 2.58628, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6184 - mean_absolute_error: 1.1727 - mean_squared_error: 2.6184 - val_loss: 2.5863 - val_mean_absolute_error: 1.1682 - val_mean_squared_error: 2.5863\n",
            "Epoch 99/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.6402 - mean_absolute_error: 1.1763 - mean_squared_error: 2.6402\n",
            "Epoch 99: val_loss did not improve from 2.58628\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6156 - mean_absolute_error: 1.1717 - mean_squared_error: 2.6156 - val_loss: 2.5885 - val_mean_absolute_error: 1.1692 - val_mean_squared_error: 2.5885\n",
            "Epoch 100/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.6266 - mean_absolute_error: 1.1785 - mean_squared_error: 2.6266\n",
            "Epoch 100: val_loss did not improve from 2.58628\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.6148 - mean_absolute_error: 1.1764 - mean_squared_error: 2.6148 - val_loss: 2.5872 - val_mean_absolute_error: 1.1616 - val_mean_squared_error: 2.5872\n",
            "Epoch 101/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.6242 - mean_absolute_error: 1.1739 - mean_squared_error: 2.6242\n",
            "Epoch 101: val_loss did not improve from 2.58628\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6144 - mean_absolute_error: 1.1721 - mean_squared_error: 2.6144 - val_loss: 2.5869 - val_mean_absolute_error: 1.1600 - val_mean_squared_error: 2.5869\n",
            "Epoch 102/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.6130 - mean_absolute_error: 1.1733 - mean_squared_error: 2.6130\n",
            "Epoch 102: val_loss did not improve from 2.58628\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.6130 - mean_absolute_error: 1.1741 - mean_squared_error: 2.6130 - val_loss: 2.5909 - val_mean_absolute_error: 1.1610 - val_mean_squared_error: 2.5909\n",
            "Epoch 103/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.6117 - mean_absolute_error: 1.1685 - mean_squared_error: 2.6117\n",
            "Epoch 103: val_loss improved from 2.58628 to 2.58119, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.6117 - mean_absolute_error: 1.1685 - mean_squared_error: 2.6117 - val_loss: 2.5812 - val_mean_absolute_error: 1.1698 - val_mean_squared_error: 2.5812\n",
            "Epoch 104/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.6081 - mean_absolute_error: 1.1697 - mean_squared_error: 2.6081\n",
            "Epoch 104: val_loss did not improve from 2.58119\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6096 - mean_absolute_error: 1.1691 - mean_squared_error: 2.6096 - val_loss: 2.5860 - val_mean_absolute_error: 1.1715 - val_mean_squared_error: 2.5860\n",
            "Epoch 105/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.6179 - mean_absolute_error: 1.1751 - mean_squared_error: 2.6179\n",
            "Epoch 105: val_loss improved from 2.58119 to 2.58046, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6096 - mean_absolute_error: 1.1725 - mean_squared_error: 2.6096 - val_loss: 2.5805 - val_mean_absolute_error: 1.1692 - val_mean_squared_error: 2.5805\n",
            "Epoch 106/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.6341 - mean_absolute_error: 1.1762 - mean_squared_error: 2.6341\n",
            "Epoch 106: val_loss did not improve from 2.58046\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6063 - mean_absolute_error: 1.1716 - mean_squared_error: 2.6063 - val_loss: 2.5821 - val_mean_absolute_error: 1.1691 - val_mean_squared_error: 2.5821\n",
            "Epoch 107/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.6367 - mean_absolute_error: 1.1768 - mean_squared_error: 2.6367\n",
            "Epoch 107: val_loss did not improve from 2.58046\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6048 - mean_absolute_error: 1.1714 - mean_squared_error: 2.6048 - val_loss: 2.5860 - val_mean_absolute_error: 1.1640 - val_mean_squared_error: 2.5860\n",
            "Epoch 108/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.5691 - mean_absolute_error: 1.1624 - mean_squared_error: 2.5691\n",
            "Epoch 108: val_loss did not improve from 2.58046\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6044 - mean_absolute_error: 1.1682 - mean_squared_error: 2.6044 - val_loss: 2.5835 - val_mean_absolute_error: 1.1576 - val_mean_squared_error: 2.5835\n",
            "Epoch 109/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.5983 - mean_absolute_error: 1.1711 - mean_squared_error: 2.5983\n",
            "Epoch 109: val_loss did not improve from 2.58046\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6046 - mean_absolute_error: 1.1709 - mean_squared_error: 2.6046 - val_loss: 2.5809 - val_mean_absolute_error: 1.1600 - val_mean_squared_error: 2.5809\n",
            "Epoch 110/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.6018 - mean_absolute_error: 1.1673 - mean_squared_error: 2.6018\n",
            "Epoch 110: val_loss improved from 2.58046 to 2.57530, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6018 - mean_absolute_error: 1.1673 - mean_squared_error: 2.6018 - val_loss: 2.5753 - val_mean_absolute_error: 1.1657 - val_mean_squared_error: 2.5753\n",
            "Epoch 111/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.5894 - mean_absolute_error: 1.1670 - mean_squared_error: 2.5894\n",
            "Epoch 111: val_loss did not improve from 2.57530\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6008 - mean_absolute_error: 1.1706 - mean_squared_error: 2.6008 - val_loss: 2.5759 - val_mean_absolute_error: 1.1678 - val_mean_squared_error: 2.5759\n",
            "Epoch 112/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.6011 - mean_absolute_error: 1.1672 - mean_squared_error: 2.6011\n",
            "Epoch 112: val_loss did not improve from 2.57530\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.6007 - mean_absolute_error: 1.1696 - mean_squared_error: 2.6007 - val_loss: 2.5772 - val_mean_absolute_error: 1.1687 - val_mean_squared_error: 2.5772\n",
            "Epoch 113/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.6043 - mean_absolute_error: 1.1712 - mean_squared_error: 2.6043\n",
            "Epoch 113: val_loss improved from 2.57530 to 2.57428, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5967 - mean_absolute_error: 1.1682 - mean_squared_error: 2.5967 - val_loss: 2.5743 - val_mean_absolute_error: 1.1560 - val_mean_squared_error: 2.5743\n",
            "Epoch 114/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.5945 - mean_absolute_error: 1.1662 - mean_squared_error: 2.5945\n",
            "Epoch 114: val_loss improved from 2.57428 to 2.57395, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5984 - mean_absolute_error: 1.1675 - mean_squared_error: 2.5984 - val_loss: 2.5740 - val_mean_absolute_error: 1.1589 - val_mean_squared_error: 2.5740\n",
            "Epoch 115/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.5627 - mean_absolute_error: 1.1600 - mean_squared_error: 2.5627\n",
            "Epoch 115: val_loss improved from 2.57395 to 2.56966, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5946 - mean_absolute_error: 1.1637 - mean_squared_error: 2.5946 - val_loss: 2.5697 - val_mean_absolute_error: 1.1639 - val_mean_squared_error: 2.5697\n",
            "Epoch 116/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.5770 - mean_absolute_error: 1.1662 - mean_squared_error: 2.5770\n",
            "Epoch 116: val_loss improved from 2.56966 to 2.56841, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5932 - mean_absolute_error: 1.1684 - mean_squared_error: 2.5932 - val_loss: 2.5684 - val_mean_absolute_error: 1.1607 - val_mean_squared_error: 2.5684\n",
            "Epoch 117/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.5854 - mean_absolute_error: 1.1666 - mean_squared_error: 2.5854\n",
            "Epoch 117: val_loss improved from 2.56841 to 2.56615, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.5944 - mean_absolute_error: 1.1685 - mean_squared_error: 2.5944 - val_loss: 2.5662 - val_mean_absolute_error: 1.1579 - val_mean_squared_error: 2.5662\n",
            "Epoch 118/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.5936 - mean_absolute_error: 1.1615 - mean_squared_error: 2.5936\n",
            "Epoch 118: val_loss did not improve from 2.56615\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5894 - mean_absolute_error: 1.1610 - mean_squared_error: 2.5894 - val_loss: 2.5674 - val_mean_absolute_error: 1.1723 - val_mean_squared_error: 2.5674\n",
            "Epoch 119/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.5814 - mean_absolute_error: 1.1687 - mean_squared_error: 2.5814\n",
            "Epoch 119: val_loss did not improve from 2.56615\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.5890 - mean_absolute_error: 1.1699 - mean_squared_error: 2.5890 - val_loss: 2.5665 - val_mean_absolute_error: 1.1535 - val_mean_squared_error: 2.5665\n",
            "Epoch 120/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.6234 - mean_absolute_error: 1.1687 - mean_squared_error: 2.6234\n",
            "Epoch 120: val_loss improved from 2.56615 to 2.56506, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5895 - mean_absolute_error: 1.1651 - mean_squared_error: 2.5895 - val_loss: 2.5651 - val_mean_absolute_error: 1.1597 - val_mean_squared_error: 2.5651\n",
            "Epoch 121/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.5605 - mean_absolute_error: 1.1545 - mean_squared_error: 2.5605\n",
            "Epoch 121: val_loss improved from 2.56506 to 2.56147, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5856 - mean_absolute_error: 1.1590 - mean_squared_error: 2.5856 - val_loss: 2.5615 - val_mean_absolute_error: 1.1653 - val_mean_squared_error: 2.5615\n",
            "Epoch 122/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.5870 - mean_absolute_error: 1.1654 - mean_squared_error: 2.5870\n",
            "Epoch 122: val_loss did not improve from 2.56147\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5866 - mean_absolute_error: 1.1662 - mean_squared_error: 2.5866 - val_loss: 2.5620 - val_mean_absolute_error: 1.1582 - val_mean_squared_error: 2.5620\n",
            "Epoch 123/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.5920 - mean_absolute_error: 1.1675 - mean_squared_error: 2.5920\n",
            "Epoch 123: val_loss improved from 2.56147 to 2.55804, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5831 - mean_absolute_error: 1.1658 - mean_squared_error: 2.5831 - val_loss: 2.5580 - val_mean_absolute_error: 1.1577 - val_mean_squared_error: 2.5580\n",
            "Epoch 124/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.6003 - mean_absolute_error: 1.1674 - mean_squared_error: 2.6003\n",
            "Epoch 124: val_loss improved from 2.55804 to 2.55790, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5825 - mean_absolute_error: 1.1632 - mean_squared_error: 2.5825 - val_loss: 2.5579 - val_mean_absolute_error: 1.1552 - val_mean_squared_error: 2.5579\n",
            "Epoch 125/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.6138 - mean_absolute_error: 1.1661 - mean_squared_error: 2.6138\n",
            "Epoch 125: val_loss improved from 2.55790 to 2.55525, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5827 - mean_absolute_error: 1.1628 - mean_squared_error: 2.5827 - val_loss: 2.5552 - val_mean_absolute_error: 1.1553 - val_mean_squared_error: 2.5552\n",
            "Epoch 126/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.5857 - mean_absolute_error: 1.1636 - mean_squared_error: 2.5857\n",
            "Epoch 126: val_loss did not improve from 2.55525\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5799 - mean_absolute_error: 1.1621 - mean_squared_error: 2.5799 - val_loss: 2.5644 - val_mean_absolute_error: 1.1549 - val_mean_squared_error: 2.5644\n",
            "Epoch 127/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.5917 - mean_absolute_error: 1.1654 - mean_squared_error: 2.5917\n",
            "Epoch 127: val_loss improved from 2.55525 to 2.55493, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5794 - mean_absolute_error: 1.1631 - mean_squared_error: 2.5794 - val_loss: 2.5549 - val_mean_absolute_error: 1.1540 - val_mean_squared_error: 2.5549\n",
            "Epoch 128/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.5730 - mean_absolute_error: 1.1598 - mean_squared_error: 2.5730\n",
            "Epoch 128: val_loss improved from 2.55493 to 2.55205, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5783 - mean_absolute_error: 1.1601 - mean_squared_error: 2.5783 - val_loss: 2.5521 - val_mean_absolute_error: 1.1566 - val_mean_squared_error: 2.5521\n",
            "Epoch 129/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.5793 - mean_absolute_error: 1.1616 - mean_squared_error: 2.5793\n",
            "Epoch 129: val_loss did not improve from 2.55205\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5783 - mean_absolute_error: 1.1602 - mean_squared_error: 2.5783 - val_loss: 2.5530 - val_mean_absolute_error: 1.1573 - val_mean_squared_error: 2.5530\n",
            "Epoch 130/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.5824 - mean_absolute_error: 1.1645 - mean_squared_error: 2.5824\n",
            "Epoch 130: val_loss improved from 2.55205 to 2.54777, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5746 - mean_absolute_error: 1.1614 - mean_squared_error: 2.5746 - val_loss: 2.5478 - val_mean_absolute_error: 1.1619 - val_mean_squared_error: 2.5478\n",
            "Epoch 131/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.5603 - mean_absolute_error: 1.1599 - mean_squared_error: 2.5603\n",
            "Epoch 131: val_loss improved from 2.54777 to 2.54697, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5734 - mean_absolute_error: 1.1619 - mean_squared_error: 2.5734 - val_loss: 2.5470 - val_mean_absolute_error: 1.1596 - val_mean_squared_error: 2.5470\n",
            "Epoch 132/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.5843 - mean_absolute_error: 1.1639 - mean_squared_error: 2.5843\n",
            "Epoch 132: val_loss did not improve from 2.54697\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5748 - mean_absolute_error: 1.1619 - mean_squared_error: 2.5748 - val_loss: 2.5478 - val_mean_absolute_error: 1.1563 - val_mean_squared_error: 2.5478\n",
            "Epoch 133/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.5764 - mean_absolute_error: 1.1600 - mean_squared_error: 2.5764\n",
            "Epoch 133: val_loss improved from 2.54697 to 2.54618, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5714 - mean_absolute_error: 1.1590 - mean_squared_error: 2.5714 - val_loss: 2.5462 - val_mean_absolute_error: 1.1592 - val_mean_squared_error: 2.5462\n",
            "Epoch 134/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.5730 - mean_absolute_error: 1.1644 - mean_squared_error: 2.5730\n",
            "Epoch 134: val_loss improved from 2.54618 to 2.54423, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.5730 - mean_absolute_error: 1.1644 - mean_squared_error: 2.5730 - val_loss: 2.5442 - val_mean_absolute_error: 1.1521 - val_mean_squared_error: 2.5442\n",
            "Epoch 135/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.5860 - mean_absolute_error: 1.1587 - mean_squared_error: 2.5860\n",
            "Epoch 135: val_loss did not improve from 2.54423\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.5691 - mean_absolute_error: 1.1552 - mean_squared_error: 2.5691 - val_loss: 2.5445 - val_mean_absolute_error: 1.1614 - val_mean_squared_error: 2.5445\n",
            "Epoch 136/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.5684 - mean_absolute_error: 1.1600 - mean_squared_error: 2.5684\n",
            "Epoch 136: val_loss improved from 2.54423 to 2.54265, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 6ms/step - loss: 2.5704 - mean_absolute_error: 1.1613 - mean_squared_error: 2.5704 - val_loss: 2.5426 - val_mean_absolute_error: 1.1566 - val_mean_squared_error: 2.5426\n",
            "Epoch 137/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.5268 - mean_absolute_error: 1.1491 - mean_squared_error: 2.5268\n",
            "Epoch 137: val_loss improved from 2.54265 to 2.54113, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5672 - mean_absolute_error: 1.1566 - mean_squared_error: 2.5672 - val_loss: 2.5411 - val_mean_absolute_error: 1.1557 - val_mean_squared_error: 2.5411\n",
            "Epoch 138/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.5657 - mean_absolute_error: 1.1567 - mean_squared_error: 2.5657\n",
            "Epoch 138: val_loss did not improve from 2.54113\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5679 - mean_absolute_error: 1.1586 - mean_squared_error: 2.5679 - val_loss: 2.5434 - val_mean_absolute_error: 1.1543 - val_mean_squared_error: 2.5434\n",
            "Epoch 139/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.5411 - mean_absolute_error: 1.1532 - mean_squared_error: 2.5411\n",
            "Epoch 139: val_loss did not improve from 2.54113\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5670 - mean_absolute_error: 1.1573 - mean_squared_error: 2.5670 - val_loss: 2.5414 - val_mean_absolute_error: 1.1533 - val_mean_squared_error: 2.5414\n",
            "Epoch 140/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.5466 - mean_absolute_error: 1.1547 - mean_squared_error: 2.5466\n",
            "Epoch 140: val_loss improved from 2.54113 to 2.53734, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5649 - mean_absolute_error: 1.1584 - mean_squared_error: 2.5649 - val_loss: 2.5373 - val_mean_absolute_error: 1.1559 - val_mean_squared_error: 2.5373\n",
            "Epoch 141/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.5704 - mean_absolute_error: 1.1603 - mean_squared_error: 2.5704\n",
            "Epoch 141: val_loss did not improve from 2.53734\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5634 - mean_absolute_error: 1.1588 - mean_squared_error: 2.5634 - val_loss: 2.5409 - val_mean_absolute_error: 1.1546 - val_mean_squared_error: 2.5409\n",
            "Epoch 142/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.5636 - mean_absolute_error: 1.1560 - mean_squared_error: 2.5636\n",
            "Epoch 142: val_loss improved from 2.53734 to 2.53413, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5643 - mean_absolute_error: 1.1572 - mean_squared_error: 2.5643 - val_loss: 2.5341 - val_mean_absolute_error: 1.1531 - val_mean_squared_error: 2.5341\n",
            "Epoch 143/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.5570 - mean_absolute_error: 1.1545 - mean_squared_error: 2.5570\n",
            "Epoch 143: val_loss improved from 2.53413 to 2.53400, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5636 - mean_absolute_error: 1.1578 - mean_squared_error: 2.5636 - val_loss: 2.5340 - val_mean_absolute_error: 1.1543 - val_mean_squared_error: 2.5340\n",
            "Epoch 144/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.5607 - mean_absolute_error: 1.1589 - mean_squared_error: 2.5607\n",
            "Epoch 144: val_loss did not improve from 2.53400\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5614 - mean_absolute_error: 1.1591 - mean_squared_error: 2.5614 - val_loss: 2.5418 - val_mean_absolute_error: 1.1527 - val_mean_squared_error: 2.5418\n",
            "Epoch 145/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.5388 - mean_absolute_error: 1.1496 - mean_squared_error: 2.5388\n",
            "Epoch 145: val_loss did not improve from 2.53400\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5611 - mean_absolute_error: 1.1553 - mean_squared_error: 2.5611 - val_loss: 2.5341 - val_mean_absolute_error: 1.1516 - val_mean_squared_error: 2.5341\n",
            "Epoch 146/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.5607 - mean_absolute_error: 1.1586 - mean_squared_error: 2.5607\n",
            "Epoch 146: val_loss improved from 2.53400 to 2.53134, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5607 - mean_absolute_error: 1.1586 - mean_squared_error: 2.5607 - val_loss: 2.5313 - val_mean_absolute_error: 1.1468 - val_mean_squared_error: 2.5313\n",
            "Epoch 147/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.5568 - mean_absolute_error: 1.1573 - mean_squared_error: 2.5568\n",
            "Epoch 147: val_loss did not improve from 2.53134\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5594 - mean_absolute_error: 1.1575 - mean_squared_error: 2.5594 - val_loss: 2.5325 - val_mean_absolute_error: 1.1498 - val_mean_squared_error: 2.5325\n",
            "Epoch 148/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.5726 - mean_absolute_error: 1.1613 - mean_squared_error: 2.5726\n",
            "Epoch 148: val_loss did not improve from 2.53134\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5586 - mean_absolute_error: 1.1559 - mean_squared_error: 2.5586 - val_loss: 2.5345 - val_mean_absolute_error: 1.1474 - val_mean_squared_error: 2.5345\n",
            "Epoch 149/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.5510 - mean_absolute_error: 1.1537 - mean_squared_error: 2.5510\n",
            "Epoch 149: val_loss did not improve from 2.53134\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5581 - mean_absolute_error: 1.1552 - mean_squared_error: 2.5581 - val_loss: 2.5320 - val_mean_absolute_error: 1.1482 - val_mean_squared_error: 2.5320\n",
            "Epoch 150/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.5398 - mean_absolute_error: 1.1507 - mean_squared_error: 2.5398\n",
            "Epoch 150: val_loss improved from 2.53134 to 2.53044, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5566 - mean_absolute_error: 1.1532 - mean_squared_error: 2.5566 - val_loss: 2.5304 - val_mean_absolute_error: 1.1537 - val_mean_squared_error: 2.5304\n",
            "Epoch 151/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.5520 - mean_absolute_error: 1.1587 - mean_squared_error: 2.5520\n",
            "Epoch 151: val_loss did not improve from 2.53044\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5574 - mean_absolute_error: 1.1580 - mean_squared_error: 2.5574 - val_loss: 2.5345 - val_mean_absolute_error: 1.1554 - val_mean_squared_error: 2.5345\n",
            "Epoch 152/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.5661 - mean_absolute_error: 1.1573 - mean_squared_error: 2.5661\n",
            "Epoch 152: val_loss did not improve from 2.53044\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5576 - mean_absolute_error: 1.1559 - mean_squared_error: 2.5576 - val_loss: 2.5309 - val_mean_absolute_error: 1.1550 - val_mean_squared_error: 2.5309\n",
            "Epoch 153/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.5551 - mean_absolute_error: 1.1557 - mean_squared_error: 2.5551\n",
            "Epoch 153: val_loss improved from 2.53044 to 2.52692, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5551 - mean_absolute_error: 1.1557 - mean_squared_error: 2.5551 - val_loss: 2.5269 - val_mean_absolute_error: 1.1492 - val_mean_squared_error: 2.5269\n",
            "Epoch 154/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.5431 - mean_absolute_error: 1.1572 - mean_squared_error: 2.5431\n",
            "Epoch 154: val_loss improved from 2.52692 to 2.52405, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5548 - mean_absolute_error: 1.1585 - mean_squared_error: 2.5548 - val_loss: 2.5240 - val_mean_absolute_error: 1.1456 - val_mean_squared_error: 2.5240\n",
            "Epoch 155/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.5232 - mean_absolute_error: 1.1525 - mean_squared_error: 2.5232\n",
            "Epoch 155: val_loss did not improve from 2.52405\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5518 - mean_absolute_error: 1.1570 - mean_squared_error: 2.5518 - val_loss: 2.5245 - val_mean_absolute_error: 1.1405 - val_mean_squared_error: 2.5245\n",
            "Epoch 156/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.5692 - mean_absolute_error: 1.1602 - mean_squared_error: 2.5692\n",
            "Epoch 156: val_loss did not improve from 2.52405\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5553 - mean_absolute_error: 1.1560 - mean_squared_error: 2.5553 - val_loss: 2.5389 - val_mean_absolute_error: 1.1477 - val_mean_squared_error: 2.5389\n",
            "Epoch 157/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.5467 - mean_absolute_error: 1.1488 - mean_squared_error: 2.5467\n",
            "Epoch 157: val_loss improved from 2.52405 to 2.52356, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5520 - mean_absolute_error: 1.1510 - mean_squared_error: 2.5520 - val_loss: 2.5236 - val_mean_absolute_error: 1.1497 - val_mean_squared_error: 2.5236\n",
            "Epoch 158/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.5671 - mean_absolute_error: 1.1572 - mean_squared_error: 2.5671\n",
            "Epoch 158: val_loss improved from 2.52356 to 2.52259, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5521 - mean_absolute_error: 1.1550 - mean_squared_error: 2.5521 - val_loss: 2.5226 - val_mean_absolute_error: 1.1544 - val_mean_squared_error: 2.5226\n",
            "Epoch 159/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.5547 - mean_absolute_error: 1.1587 - mean_squared_error: 2.5547\n",
            "Epoch 159: val_loss improved from 2.52259 to 2.52055, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5506 - mean_absolute_error: 1.1578 - mean_squared_error: 2.5506 - val_loss: 2.5205 - val_mean_absolute_error: 1.1430 - val_mean_squared_error: 2.5205\n",
            "Epoch 160/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.5592 - mean_absolute_error: 1.1553 - mean_squared_error: 2.5592\n",
            "Epoch 160: val_loss did not improve from 2.52055\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5501 - mean_absolute_error: 1.1542 - mean_squared_error: 2.5501 - val_loss: 2.5220 - val_mean_absolute_error: 1.1415 - val_mean_squared_error: 2.5220\n",
            "Epoch 161/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.5247 - mean_absolute_error: 1.1482 - mean_squared_error: 2.5247\n",
            "Epoch 161: val_loss improved from 2.52055 to 2.51992, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5502 - mean_absolute_error: 1.1528 - mean_squared_error: 2.5502 - val_loss: 2.5199 - val_mean_absolute_error: 1.1444 - val_mean_squared_error: 2.5199\n",
            "Epoch 162/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.5697 - mean_absolute_error: 1.1575 - mean_squared_error: 2.5697\n",
            "Epoch 162: val_loss did not improve from 2.51992\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5496 - mean_absolute_error: 1.1532 - mean_squared_error: 2.5496 - val_loss: 2.5261 - val_mean_absolute_error: 1.1507 - val_mean_squared_error: 2.5261\n",
            "Epoch 163/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.5337 - mean_absolute_error: 1.1578 - mean_squared_error: 2.5337\n",
            "Epoch 163: val_loss did not improve from 2.51992\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5478 - mean_absolute_error: 1.1573 - mean_squared_error: 2.5478 - val_loss: 2.5209 - val_mean_absolute_error: 1.1394 - val_mean_squared_error: 2.5209\n",
            "Epoch 164/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.5344 - mean_absolute_error: 1.1466 - mean_squared_error: 2.5344\n",
            "Epoch 164: val_loss did not improve from 2.51992\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5471 - mean_absolute_error: 1.1503 - mean_squared_error: 2.5471 - val_loss: 2.5247 - val_mean_absolute_error: 1.1518 - val_mean_squared_error: 2.5247\n",
            "Epoch 165/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.5503 - mean_absolute_error: 1.1593 - mean_squared_error: 2.5503\n",
            "Epoch 165: val_loss improved from 2.51992 to 2.51827, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5488 - mean_absolute_error: 1.1574 - mean_squared_error: 2.5488 - val_loss: 2.5183 - val_mean_absolute_error: 1.1424 - val_mean_squared_error: 2.5183\n",
            "Epoch 166/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.5364 - mean_absolute_error: 1.1490 - mean_squared_error: 2.5364\n",
            "Epoch 166: val_loss did not improve from 2.51827\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5470 - mean_absolute_error: 1.1513 - mean_squared_error: 2.5470 - val_loss: 2.5199 - val_mean_absolute_error: 1.1425 - val_mean_squared_error: 2.5199\n",
            "Epoch 167/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.5360 - mean_absolute_error: 1.1540 - mean_squared_error: 2.5360\n",
            "Epoch 167: val_loss improved from 2.51827 to 2.51339, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.5473 - mean_absolute_error: 1.1563 - mean_squared_error: 2.5473 - val_loss: 2.5134 - val_mean_absolute_error: 1.1443 - val_mean_squared_error: 2.5134\n",
            "Epoch 168/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.5666 - mean_absolute_error: 1.1568 - mean_squared_error: 2.5666\n",
            "Epoch 168: val_loss did not improve from 2.51339\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5457 - mean_absolute_error: 1.1534 - mean_squared_error: 2.5457 - val_loss: 2.5190 - val_mean_absolute_error: 1.1418 - val_mean_squared_error: 2.5190\n",
            "Epoch 169/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.5318 - mean_absolute_error: 1.1498 - mean_squared_error: 2.5318\n",
            "Epoch 169: val_loss did not improve from 2.51339\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5473 - mean_absolute_error: 1.1529 - mean_squared_error: 2.5473 - val_loss: 2.5201 - val_mean_absolute_error: 1.1410 - val_mean_squared_error: 2.5201\n",
            "Epoch 170/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.5527 - mean_absolute_error: 1.1554 - mean_squared_error: 2.5527\n",
            "Epoch 170: val_loss did not improve from 2.51339\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5454 - mean_absolute_error: 1.1540 - mean_squared_error: 2.5454 - val_loss: 2.5173 - val_mean_absolute_error: 1.1431 - val_mean_squared_error: 2.5173\n",
            "Epoch 171/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.5318 - mean_absolute_error: 1.1515 - mean_squared_error: 2.5318\n",
            "Epoch 171: val_loss did not improve from 2.51339\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5446 - mean_absolute_error: 1.1525 - mean_squared_error: 2.5446 - val_loss: 2.5175 - val_mean_absolute_error: 1.1421 - val_mean_squared_error: 2.5175\n",
            "Epoch 172/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.5445 - mean_absolute_error: 1.1529 - mean_squared_error: 2.5445\n",
            "Epoch 172: val_loss did not improve from 2.51339\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5445 - mean_absolute_error: 1.1529 - mean_squared_error: 2.5445 - val_loss: 2.5152 - val_mean_absolute_error: 1.1466 - val_mean_squared_error: 2.5152\n",
            "Epoch 173/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.5631 - mean_absolute_error: 1.1547 - mean_squared_error: 2.5631\n",
            "Epoch 173: val_loss improved from 2.51339 to 2.50986, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5430 - mean_absolute_error: 1.1530 - mean_squared_error: 2.5430 - val_loss: 2.5099 - val_mean_absolute_error: 1.1453 - val_mean_squared_error: 2.5099\n",
            "Epoch 174/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.5614 - mean_absolute_error: 1.1624 - mean_squared_error: 2.5614\n",
            "Epoch 174: val_loss did not improve from 2.50986\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5413 - mean_absolute_error: 1.1577 - mean_squared_error: 2.5413 - val_loss: 2.5132 - val_mean_absolute_error: 1.1361 - val_mean_squared_error: 2.5132\n",
            "Epoch 175/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.5229 - mean_absolute_error: 1.1420 - mean_squared_error: 2.5229\n",
            "Epoch 175: val_loss improved from 2.50986 to 2.50869, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5426 - mean_absolute_error: 1.1476 - mean_squared_error: 2.5426 - val_loss: 2.5087 - val_mean_absolute_error: 1.1469 - val_mean_squared_error: 2.5087\n",
            "Epoch 176/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.5293 - mean_absolute_error: 1.1517 - mean_squared_error: 2.5293\n",
            "Epoch 176: val_loss did not improve from 2.50869\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5399 - mean_absolute_error: 1.1529 - mean_squared_error: 2.5399 - val_loss: 2.5145 - val_mean_absolute_error: 1.1386 - val_mean_squared_error: 2.5145\n",
            "Epoch 177/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.5286 - mean_absolute_error: 1.1517 - mean_squared_error: 2.5286\n",
            "Epoch 177: val_loss did not improve from 2.50869\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5423 - mean_absolute_error: 1.1529 - mean_squared_error: 2.5423 - val_loss: 2.5089 - val_mean_absolute_error: 1.1441 - val_mean_squared_error: 2.5089\n",
            "Epoch 178/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.5199 - mean_absolute_error: 1.1464 - mean_squared_error: 2.5199\n",
            "Epoch 178: val_loss did not improve from 2.50869\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5388 - mean_absolute_error: 1.1511 - mean_squared_error: 2.5388 - val_loss: 2.5142 - val_mean_absolute_error: 1.1427 - val_mean_squared_error: 2.5142\n",
            "Epoch 179/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.5007 - mean_absolute_error: 1.1519 - mean_squared_error: 2.5007\n",
            "Epoch 179: val_loss improved from 2.50869 to 2.50744, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5403 - mean_absolute_error: 1.1564 - mean_squared_error: 2.5403 - val_loss: 2.5074 - val_mean_absolute_error: 1.1385 - val_mean_squared_error: 2.5074\n",
            "Epoch 180/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.5428 - mean_absolute_error: 1.1490 - mean_squared_error: 2.5428\n",
            "Epoch 180: val_loss did not improve from 2.50744\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5379 - mean_absolute_error: 1.1489 - mean_squared_error: 2.5379 - val_loss: 2.5092 - val_mean_absolute_error: 1.1427 - val_mean_squared_error: 2.5092\n",
            "Epoch 181/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.5164 - mean_absolute_error: 1.1503 - mean_squared_error: 2.5164\n",
            "Epoch 181: val_loss did not improve from 2.50744\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5396 - mean_absolute_error: 1.1541 - mean_squared_error: 2.5396 - val_loss: 2.5107 - val_mean_absolute_error: 1.1365 - val_mean_squared_error: 2.5107\n",
            "Epoch 182/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.5074 - mean_absolute_error: 1.1475 - mean_squared_error: 2.5074\n",
            "Epoch 182: val_loss improved from 2.50744 to 2.50692, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5387 - mean_absolute_error: 1.1517 - mean_squared_error: 2.5387 - val_loss: 2.5069 - val_mean_absolute_error: 1.1379 - val_mean_squared_error: 2.5069\n",
            "Epoch 183/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.5515 - mean_absolute_error: 1.1543 - mean_squared_error: 2.5515\n",
            "Epoch 183: val_loss improved from 2.50692 to 2.50558, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5354 - mean_absolute_error: 1.1516 - mean_squared_error: 2.5354 - val_loss: 2.5056 - val_mean_absolute_error: 1.1422 - val_mean_squared_error: 2.5056\n",
            "Epoch 184/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.5374 - mean_absolute_error: 1.1492 - mean_squared_error: 2.5374\n",
            "Epoch 184: val_loss did not improve from 2.50558\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5363 - mean_absolute_error: 1.1492 - mean_squared_error: 2.5363 - val_loss: 2.5057 - val_mean_absolute_error: 1.1467 - val_mean_squared_error: 2.5057\n",
            "Epoch 185/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.5214 - mean_absolute_error: 1.1451 - mean_squared_error: 2.5214\n",
            "Epoch 185: val_loss did not improve from 2.50558\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5362 - mean_absolute_error: 1.1490 - mean_squared_error: 2.5362 - val_loss: 2.5072 - val_mean_absolute_error: 1.1473 - val_mean_squared_error: 2.5072\n",
            "Epoch 186/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.5348 - mean_absolute_error: 1.1570 - mean_squared_error: 2.5348\n",
            "Epoch 186: val_loss improved from 2.50558 to 2.50490, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5367 - mean_absolute_error: 1.1573 - mean_squared_error: 2.5367 - val_loss: 2.5049 - val_mean_absolute_error: 1.1434 - val_mean_squared_error: 2.5049\n",
            "Epoch 187/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.5419 - mean_absolute_error: 1.1523 - mean_squared_error: 2.5419\n",
            "Epoch 187: val_loss did not improve from 2.50490\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5337 - mean_absolute_error: 1.1509 - mean_squared_error: 2.5337 - val_loss: 2.5197 - val_mean_absolute_error: 1.1486 - val_mean_squared_error: 2.5197\n",
            "Epoch 188/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.5378 - mean_absolute_error: 1.1570 - mean_squared_error: 2.5378\n",
            "Epoch 188: val_loss did not improve from 2.50490\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5346 - mean_absolute_error: 1.1553 - mean_squared_error: 2.5346 - val_loss: 2.5051 - val_mean_absolute_error: 1.1378 - val_mean_squared_error: 2.5051\n",
            "Epoch 189/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.5586 - mean_absolute_error: 1.1530 - mean_squared_error: 2.5586\n",
            "Epoch 189: val_loss improved from 2.50490 to 2.50342, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 6ms/step - loss: 2.5343 - mean_absolute_error: 1.1489 - mean_squared_error: 2.5343 - val_loss: 2.5034 - val_mean_absolute_error: 1.1423 - val_mean_squared_error: 2.5034\n",
            "Epoch 190/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.5237 - mean_absolute_error: 1.1496 - mean_squared_error: 2.5237\n",
            "Epoch 190: val_loss improved from 2.50342 to 2.50139, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 6ms/step - loss: 2.5323 - mean_absolute_error: 1.1506 - mean_squared_error: 2.5323 - val_loss: 2.5014 - val_mean_absolute_error: 1.1414 - val_mean_squared_error: 2.5014\n",
            "Epoch 191/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.5052 - mean_absolute_error: 1.1450 - mean_squared_error: 2.5052\n",
            "Epoch 191: val_loss did not improve from 2.50139\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5308 - mean_absolute_error: 1.1512 - mean_squared_error: 2.5308 - val_loss: 2.5023 - val_mean_absolute_error: 1.1435 - val_mean_squared_error: 2.5023\n",
            "Epoch 192/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.5317 - mean_absolute_error: 1.1560 - mean_squared_error: 2.5317\n",
            "Epoch 192: val_loss did not improve from 2.50139\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5328 - mean_absolute_error: 1.1550 - mean_squared_error: 2.5328 - val_loss: 2.5058 - val_mean_absolute_error: 1.1405 - val_mean_squared_error: 2.5058\n",
            "Epoch 193/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.5160 - mean_absolute_error: 1.1446 - mean_squared_error: 2.5160\n",
            "Epoch 193: val_loss improved from 2.50139 to 2.50060, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5328 - mean_absolute_error: 1.1491 - mean_squared_error: 2.5328 - val_loss: 2.5006 - val_mean_absolute_error: 1.1422 - val_mean_squared_error: 2.5006\n",
            "Epoch 194/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.5135 - mean_absolute_error: 1.1489 - mean_squared_error: 2.5135\n",
            "Epoch 194: val_loss did not improve from 2.50060\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5321 - mean_absolute_error: 1.1524 - mean_squared_error: 2.5321 - val_loss: 2.5012 - val_mean_absolute_error: 1.1437 - val_mean_squared_error: 2.5012\n",
            "Epoch 195/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.5415 - mean_absolute_error: 1.1553 - mean_squared_error: 2.5415\n",
            "Epoch 195: val_loss improved from 2.50060 to 2.50037, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5314 - mean_absolute_error: 1.1531 - mean_squared_error: 2.5314 - val_loss: 2.5004 - val_mean_absolute_error: 1.1444 - val_mean_squared_error: 2.5004\n",
            "Epoch 196/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.5313 - mean_absolute_error: 1.1514 - mean_squared_error: 2.5313\n",
            "Epoch 196: val_loss did not improve from 2.50037\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5313 - mean_absolute_error: 1.1514 - mean_squared_error: 2.5313 - val_loss: 2.5026 - val_mean_absolute_error: 1.1453 - val_mean_squared_error: 2.5026\n",
            "Epoch 197/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.5363 - mean_absolute_error: 1.1534 - mean_squared_error: 2.5363\n",
            "Epoch 197: val_loss improved from 2.50037 to 2.49882, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5302 - mean_absolute_error: 1.1521 - mean_squared_error: 2.5302 - val_loss: 2.4988 - val_mean_absolute_error: 1.1407 - val_mean_squared_error: 2.4988\n",
            "Epoch 198/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.5286 - mean_absolute_error: 1.1517 - mean_squared_error: 2.5286\n",
            "Epoch 198: val_loss improved from 2.49882 to 2.49869, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5291 - mean_absolute_error: 1.1512 - mean_squared_error: 2.5291 - val_loss: 2.4987 - val_mean_absolute_error: 1.1403 - val_mean_squared_error: 2.4987\n",
            "Epoch 199/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.5612 - mean_absolute_error: 1.1566 - mean_squared_error: 2.5612\n",
            "Epoch 199: val_loss improved from 2.49869 to 2.49847, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5292 - mean_absolute_error: 1.1504 - mean_squared_error: 2.5292 - val_loss: 2.4985 - val_mean_absolute_error: 1.1391 - val_mean_squared_error: 2.4985\n",
            "Epoch 200/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.5321 - mean_absolute_error: 1.1558 - mean_squared_error: 2.5321\n",
            "Epoch 200: val_loss did not improve from 2.49847\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5288 - mean_absolute_error: 1.1541 - mean_squared_error: 2.5288 - val_loss: 2.5056 - val_mean_absolute_error: 1.1381 - val_mean_squared_error: 2.5056\n",
            "Epoch 201/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.5279 - mean_absolute_error: 1.1459 - mean_squared_error: 2.5279\n",
            "Epoch 201: val_loss improved from 2.49847 to 2.49552, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5265 - mean_absolute_error: 1.1457 - mean_squared_error: 2.5265 - val_loss: 2.4955 - val_mean_absolute_error: 1.1447 - val_mean_squared_error: 2.4955\n",
            "Epoch 202/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.5249 - mean_absolute_error: 1.1509 - mean_squared_error: 2.5249\n",
            "Epoch 202: val_loss improved from 2.49552 to 2.49543, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5276 - mean_absolute_error: 1.1506 - mean_squared_error: 2.5276 - val_loss: 2.4954 - val_mean_absolute_error: 1.1463 - val_mean_squared_error: 2.4954\n",
            "Epoch 203/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.5347 - mean_absolute_error: 1.1540 - mean_squared_error: 2.5347\n",
            "Epoch 203: val_loss did not improve from 2.49543\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5299 - mean_absolute_error: 1.1533 - mean_squared_error: 2.5299 - val_loss: 2.5001 - val_mean_absolute_error: 1.1394 - val_mean_squared_error: 2.5001\n",
            "Epoch 204/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.5149 - mean_absolute_error: 1.1521 - mean_squared_error: 2.5149\n",
            "Epoch 204: val_loss did not improve from 2.49543\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5276 - mean_absolute_error: 1.1514 - mean_squared_error: 2.5276 - val_loss: 2.4985 - val_mean_absolute_error: 1.1399 - val_mean_squared_error: 2.4985\n",
            "Epoch 205/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.5293 - mean_absolute_error: 1.1537 - mean_squared_error: 2.5293\n",
            "Epoch 205: val_loss did not improve from 2.49543\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5255 - mean_absolute_error: 1.1521 - mean_squared_error: 2.5255 - val_loss: 2.5043 - val_mean_absolute_error: 1.1407 - val_mean_squared_error: 2.5043\n",
            "Epoch 206/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.5264 - mean_absolute_error: 1.1508 - mean_squared_error: 2.5264\n",
            "Epoch 206: val_loss improved from 2.49543 to 2.49526, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5270 - mean_absolute_error: 1.1512 - mean_squared_error: 2.5270 - val_loss: 2.4953 - val_mean_absolute_error: 1.1387 - val_mean_squared_error: 2.4953\n",
            "Epoch 207/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.5269 - mean_absolute_error: 1.1475 - mean_squared_error: 2.5269\n",
            "Epoch 207: val_loss improved from 2.49526 to 2.49447, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5256 - mean_absolute_error: 1.1475 - mean_squared_error: 2.5256 - val_loss: 2.4945 - val_mean_absolute_error: 1.1453 - val_mean_squared_error: 2.4945\n",
            "Epoch 208/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.5409 - mean_absolute_error: 1.1583 - mean_squared_error: 2.5409\n",
            "Epoch 208: val_loss did not improve from 2.49447\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5259 - mean_absolute_error: 1.1552 - mean_squared_error: 2.5259 - val_loss: 2.5030 - val_mean_absolute_error: 1.1416 - val_mean_squared_error: 2.5030\n",
            "Epoch 209/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.5292 - mean_absolute_error: 1.1525 - mean_squared_error: 2.5292\n",
            "Epoch 209: val_loss improved from 2.49447 to 2.49256, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5259 - mean_absolute_error: 1.1519 - mean_squared_error: 2.5259 - val_loss: 2.4926 - val_mean_absolute_error: 1.1362 - val_mean_squared_error: 2.4926\n",
            "Epoch 210/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.5027 - mean_absolute_error: 1.1420 - mean_squared_error: 2.5027\n",
            "Epoch 210: val_loss did not improve from 2.49256\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5241 - mean_absolute_error: 1.1462 - mean_squared_error: 2.5241 - val_loss: 2.4932 - val_mean_absolute_error: 1.1461 - val_mean_squared_error: 2.4932\n",
            "Epoch 211/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.5200 - mean_absolute_error: 1.1485 - mean_squared_error: 2.5200\n",
            "Epoch 211: val_loss did not improve from 2.49256\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5247 - mean_absolute_error: 1.1500 - mean_squared_error: 2.5247 - val_loss: 2.4942 - val_mean_absolute_error: 1.1437 - val_mean_squared_error: 2.4942\n",
            "Epoch 212/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.5379 - mean_absolute_error: 1.1591 - mean_squared_error: 2.5379\n",
            "Epoch 212: val_loss did not improve from 2.49256\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5218 - mean_absolute_error: 1.1554 - mean_squared_error: 2.5218 - val_loss: 2.5046 - val_mean_absolute_error: 1.1338 - val_mean_squared_error: 2.5046\n",
            "Epoch 213/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.5147 - mean_absolute_error: 1.1474 - mean_squared_error: 2.5147\n",
            "Epoch 213: val_loss did not improve from 2.49256\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5229 - mean_absolute_error: 1.1488 - mean_squared_error: 2.5229 - val_loss: 2.4957 - val_mean_absolute_error: 1.1427 - val_mean_squared_error: 2.4957\n",
            "Epoch 214/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.5168 - mean_absolute_error: 1.1472 - mean_squared_error: 2.5168\n",
            "Epoch 214: val_loss improved from 2.49256 to 2.48985, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5253 - mean_absolute_error: 1.1492 - mean_squared_error: 2.5253 - val_loss: 2.4898 - val_mean_absolute_error: 1.1398 - val_mean_squared_error: 2.4898\n",
            "Epoch 215/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.5395 - mean_absolute_error: 1.1545 - mean_squared_error: 2.5395\n",
            "Epoch 215: val_loss did not improve from 2.48985\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5239 - mean_absolute_error: 1.1522 - mean_squared_error: 2.5239 - val_loss: 2.4935 - val_mean_absolute_error: 1.1372 - val_mean_squared_error: 2.4935\n",
            "Epoch 216/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.5044 - mean_absolute_error: 1.1446 - mean_squared_error: 2.5044\n",
            "Epoch 216: val_loss did not improve from 2.48985\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5233 - mean_absolute_error: 1.1478 - mean_squared_error: 2.5233 - val_loss: 2.4932 - val_mean_absolute_error: 1.1460 - val_mean_squared_error: 2.4932\n",
            "Epoch 217/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.4949 - mean_absolute_error: 1.1463 - mean_squared_error: 2.4949\n",
            "Epoch 217: val_loss did not improve from 2.48985\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5222 - mean_absolute_error: 1.1512 - mean_squared_error: 2.5222 - val_loss: 2.4914 - val_mean_absolute_error: 1.1398 - val_mean_squared_error: 2.4914\n",
            "Epoch 218/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.5223 - mean_absolute_error: 1.1519 - mean_squared_error: 2.5223\n",
            "Epoch 218: val_loss did not improve from 2.48985\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5216 - mean_absolute_error: 1.1520 - mean_squared_error: 2.5216 - val_loss: 2.4930 - val_mean_absolute_error: 1.1379 - val_mean_squared_error: 2.4930\n",
            "Epoch 219/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.5422 - mean_absolute_error: 1.1543 - mean_squared_error: 2.5422\n",
            "Epoch 219: val_loss did not improve from 2.48985\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5220 - mean_absolute_error: 1.1495 - mean_squared_error: 2.5220 - val_loss: 2.4946 - val_mean_absolute_error: 1.1379 - val_mean_squared_error: 2.4946\n",
            "Epoch 220/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.5326 - mean_absolute_error: 1.1542 - mean_squared_error: 2.5326\n",
            "Epoch 220: val_loss did not improve from 2.48985\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5203 - mean_absolute_error: 1.1512 - mean_squared_error: 2.5203 - val_loss: 2.4938 - val_mean_absolute_error: 1.1344 - val_mean_squared_error: 2.4938\n",
            "Epoch 221/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.5206 - mean_absolute_error: 1.1476 - mean_squared_error: 2.5206\n",
            "Epoch 221: val_loss did not improve from 2.48985\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5206 - mean_absolute_error: 1.1476 - mean_squared_error: 2.5206 - val_loss: 2.4927 - val_mean_absolute_error: 1.1392 - val_mean_squared_error: 2.4927\n",
            "Epoch 222/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.5512 - mean_absolute_error: 1.1605 - mean_squared_error: 2.5512\n",
            "Epoch 222: val_loss did not improve from 2.48985\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5207 - mean_absolute_error: 1.1512 - mean_squared_error: 2.5207 - val_loss: 2.4906 - val_mean_absolute_error: 1.1408 - val_mean_squared_error: 2.4906\n",
            "Epoch 223/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.5167 - mean_absolute_error: 1.1486 - mean_squared_error: 2.5167\n",
            "Epoch 223: val_loss did not improve from 2.48985\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5199 - mean_absolute_error: 1.1508 - mean_squared_error: 2.5199 - val_loss: 2.4963 - val_mean_absolute_error: 1.1369 - val_mean_squared_error: 2.4963\n",
            "Epoch 224/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.4940 - mean_absolute_error: 1.1419 - mean_squared_error: 2.4940\n",
            "Epoch 224: val_loss improved from 2.48985 to 2.48707, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5208 - mean_absolute_error: 1.1479 - mean_squared_error: 2.5208 - val_loss: 2.4871 - val_mean_absolute_error: 1.1436 - val_mean_squared_error: 2.4871\n",
            "Epoch 225/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.5153 - mean_absolute_error: 1.1480 - mean_squared_error: 2.5153\n",
            "Epoch 225: val_loss improved from 2.48707 to 2.48593, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5206 - mean_absolute_error: 1.1500 - mean_squared_error: 2.5206 - val_loss: 2.4859 - val_mean_absolute_error: 1.1446 - val_mean_squared_error: 2.4859\n",
            "Epoch 226/1000\n",
            "225/245 [==========================>...] - ETA: 0s - loss: 2.5034 - mean_absolute_error: 1.1510 - mean_squared_error: 2.5034\n",
            "Epoch 226: val_loss did not improve from 2.48593\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5197 - mean_absolute_error: 1.1543 - mean_squared_error: 2.5197 - val_loss: 2.4894 - val_mean_absolute_error: 1.1334 - val_mean_squared_error: 2.4894\n",
            "Epoch 227/1000\n",
            "226/245 [==========================>...] - ETA: 0s - loss: 2.4951 - mean_absolute_error: 1.1421 - mean_squared_error: 2.4951\n",
            "Epoch 227: val_loss did not improve from 2.48593\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5181 - mean_absolute_error: 1.1478 - mean_squared_error: 2.5181 - val_loss: 2.4970 - val_mean_absolute_error: 1.1386 - val_mean_squared_error: 2.4970\n",
            "Epoch 228/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.5363 - mean_absolute_error: 1.1503 - mean_squared_error: 2.5363\n",
            "Epoch 228: val_loss did not improve from 2.48593\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5189 - mean_absolute_error: 1.1494 - mean_squared_error: 2.5189 - val_loss: 2.4920 - val_mean_absolute_error: 1.1412 - val_mean_squared_error: 2.4920\n",
            "Epoch 229/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.5000 - mean_absolute_error: 1.1466 - mean_squared_error: 2.5000\n",
            "Epoch 229: val_loss improved from 2.48593 to 2.48444, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5193 - mean_absolute_error: 1.1477 - mean_squared_error: 2.5193 - val_loss: 2.4844 - val_mean_absolute_error: 1.1423 - val_mean_squared_error: 2.4844\n",
            "Epoch 230/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.4755 - mean_absolute_error: 1.1440 - mean_squared_error: 2.4755\n",
            "Epoch 230: val_loss did not improve from 2.48444\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5194 - mean_absolute_error: 1.1509 - mean_squared_error: 2.5194 - val_loss: 2.5019 - val_mean_absolute_error: 1.1435 - val_mean_squared_error: 2.5019\n",
            "Epoch 231/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.5168 - mean_absolute_error: 1.1483 - mean_squared_error: 2.5168\n",
            "Epoch 231: val_loss did not improve from 2.48444\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5195 - mean_absolute_error: 1.1500 - mean_squared_error: 2.5195 - val_loss: 2.4950 - val_mean_absolute_error: 1.1434 - val_mean_squared_error: 2.4950\n",
            "Epoch 232/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.5260 - mean_absolute_error: 1.1531 - mean_squared_error: 2.5260\n",
            "Epoch 232: val_loss did not improve from 2.48444\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5180 - mean_absolute_error: 1.1527 - mean_squared_error: 2.5180 - val_loss: 2.4889 - val_mean_absolute_error: 1.1380 - val_mean_squared_error: 2.4889\n",
            "Epoch 233/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.5408 - mean_absolute_error: 1.1567 - mean_squared_error: 2.5408\n",
            "Epoch 233: val_loss did not improve from 2.48444\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5158 - mean_absolute_error: 1.1504 - mean_squared_error: 2.5158 - val_loss: 2.4880 - val_mean_absolute_error: 1.1366 - val_mean_squared_error: 2.4880\n",
            "Epoch 234/1000\n",
            "228/245 [==========================>...] - ETA: 0s - loss: 2.4762 - mean_absolute_error: 1.1422 - mean_squared_error: 2.4762\n",
            "Epoch 234: val_loss did not improve from 2.48444\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5188 - mean_absolute_error: 1.1486 - mean_squared_error: 2.5188 - val_loss: 2.4936 - val_mean_absolute_error: 1.1378 - val_mean_squared_error: 2.4936\n",
            "Epoch 235/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.5068 - mean_absolute_error: 1.1469 - mean_squared_error: 2.5068\n",
            "Epoch 235: val_loss did not improve from 2.48444\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5161 - mean_absolute_error: 1.1493 - mean_squared_error: 2.5161 - val_loss: 2.4879 - val_mean_absolute_error: 1.1385 - val_mean_squared_error: 2.4879\n",
            "Epoch 236/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.5191 - mean_absolute_error: 1.1498 - mean_squared_error: 2.5191\n",
            "Epoch 236: val_loss did not improve from 2.48444\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5168 - mean_absolute_error: 1.1495 - mean_squared_error: 2.5168 - val_loss: 2.4884 - val_mean_absolute_error: 1.1405 - val_mean_squared_error: 2.4884\n",
            "Epoch 237/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.5145 - mean_absolute_error: 1.1490 - mean_squared_error: 2.5145\n",
            "Epoch 237: val_loss did not improve from 2.48444\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5185 - mean_absolute_error: 1.1504 - mean_squared_error: 2.5185 - val_loss: 2.4860 - val_mean_absolute_error: 1.1399 - val_mean_squared_error: 2.4860\n",
            "Epoch 238/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.5123 - mean_absolute_error: 1.1545 - mean_squared_error: 2.5123\n",
            "Epoch 238: val_loss did not improve from 2.48444\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5170 - mean_absolute_error: 1.1529 - mean_squared_error: 2.5170 - val_loss: 2.4848 - val_mean_absolute_error: 1.1371 - val_mean_squared_error: 2.4848\n",
            "Epoch 239/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.5206 - mean_absolute_error: 1.1481 - mean_squared_error: 2.5206\n",
            "Epoch 239: val_loss improved from 2.48444 to 2.48359, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5143 - mean_absolute_error: 1.1480 - mean_squared_error: 2.5143 - val_loss: 2.4836 - val_mean_absolute_error: 1.1408 - val_mean_squared_error: 2.4836\n",
            "Epoch 240/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.5267 - mean_absolute_error: 1.1599 - mean_squared_error: 2.5267\n",
            "Epoch 240: val_loss did not improve from 2.48359\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5154 - mean_absolute_error: 1.1533 - mean_squared_error: 2.5154 - val_loss: 2.4896 - val_mean_absolute_error: 1.1336 - val_mean_squared_error: 2.4896\n",
            "Epoch 241/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.5131 - mean_absolute_error: 1.1488 - mean_squared_error: 2.5131\n",
            "Epoch 241: val_loss did not improve from 2.48359\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5161 - mean_absolute_error: 1.1496 - mean_squared_error: 2.5161 - val_loss: 2.4877 - val_mean_absolute_error: 1.1372 - val_mean_squared_error: 2.4877\n",
            "Epoch 242/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.5056 - mean_absolute_error: 1.1422 - mean_squared_error: 2.5056\n",
            "Epoch 242: val_loss did not improve from 2.48359\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5159 - mean_absolute_error: 1.1438 - mean_squared_error: 2.5159 - val_loss: 2.4867 - val_mean_absolute_error: 1.1462 - val_mean_squared_error: 2.4867\n",
            "Epoch 243/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.4881 - mean_absolute_error: 1.1488 - mean_squared_error: 2.4881\n",
            "Epoch 243: val_loss did not improve from 2.48359\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.5141 - mean_absolute_error: 1.1533 - mean_squared_error: 2.5141 - val_loss: 2.4920 - val_mean_absolute_error: 1.1384 - val_mean_squared_error: 2.4920\n",
            "Epoch 244/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.4972 - mean_absolute_error: 1.1402 - mean_squared_error: 2.4972\n",
            "Epoch 244: val_loss did not improve from 2.48359\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5154 - mean_absolute_error: 1.1449 - mean_squared_error: 2.5154 - val_loss: 2.4850 - val_mean_absolute_error: 1.1423 - val_mean_squared_error: 2.4850\n",
            "Epoch 245/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.5069 - mean_absolute_error: 1.1505 - mean_squared_error: 2.5069\n",
            "Epoch 245: val_loss did not improve from 2.48359\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5129 - mean_absolute_error: 1.1515 - mean_squared_error: 2.5129 - val_loss: 2.4914 - val_mean_absolute_error: 1.1420 - val_mean_squared_error: 2.4914\n",
            "Epoch 246/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.4981 - mean_absolute_error: 1.1464 - mean_squared_error: 2.4981\n",
            "Epoch 246: val_loss did not improve from 2.48359\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5194 - mean_absolute_error: 1.1510 - mean_squared_error: 2.5194 - val_loss: 2.4883 - val_mean_absolute_error: 1.1433 - val_mean_squared_error: 2.4883\n",
            "Epoch 247/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.5205 - mean_absolute_error: 1.1514 - mean_squared_error: 2.5205\n",
            "Epoch 247: val_loss did not improve from 2.48359\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5169 - mean_absolute_error: 1.1508 - mean_squared_error: 2.5169 - val_loss: 2.4841 - val_mean_absolute_error: 1.1414 - val_mean_squared_error: 2.4841\n",
            "Epoch 248/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.5020 - mean_absolute_error: 1.1470 - mean_squared_error: 2.5020\n",
            "Epoch 248: val_loss improved from 2.48359 to 2.48146, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5143 - mean_absolute_error: 1.1492 - mean_squared_error: 2.5143 - val_loss: 2.4815 - val_mean_absolute_error: 1.1415 - val_mean_squared_error: 2.4815\n",
            "Epoch 249/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.5255 - mean_absolute_error: 1.1535 - mean_squared_error: 2.5255\n",
            "Epoch 249: val_loss did not improve from 2.48146\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5130 - mean_absolute_error: 1.1491 - mean_squared_error: 2.5130 - val_loss: 2.4816 - val_mean_absolute_error: 1.1461 - val_mean_squared_error: 2.4816\n",
            "Epoch 250/1000\n",
            "227/245 [==========================>...] - ETA: 0s - loss: 2.5247 - mean_absolute_error: 1.1542 - mean_squared_error: 2.5247\n",
            "Epoch 250: val_loss did not improve from 2.48146\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5152 - mean_absolute_error: 1.1502 - mean_squared_error: 2.5152 - val_loss: 2.4844 - val_mean_absolute_error: 1.1433 - val_mean_squared_error: 2.4844\n",
            "Epoch 251/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.5164 - mean_absolute_error: 1.1498 - mean_squared_error: 2.5164\n",
            "Epoch 251: val_loss did not improve from 2.48146\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5152 - mean_absolute_error: 1.1497 - mean_squared_error: 2.5152 - val_loss: 2.4828 - val_mean_absolute_error: 1.1387 - val_mean_squared_error: 2.4828\n",
            "Epoch 252/1000\n",
            "232/245 [===========================>..] - ETA: 0s - loss: 2.4992 - mean_absolute_error: 1.1484 - mean_squared_error: 2.4992\n",
            "Epoch 252: val_loss did not improve from 2.48146\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5119 - mean_absolute_error: 1.1506 - mean_squared_error: 2.5119 - val_loss: 2.4830 - val_mean_absolute_error: 1.1384 - val_mean_squared_error: 2.4830\n",
            "Epoch 253/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.5115 - mean_absolute_error: 1.1492 - mean_squared_error: 2.5115\n",
            "Epoch 253: val_loss did not improve from 2.48146\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5126 - mean_absolute_error: 1.1479 - mean_squared_error: 2.5126 - val_loss: 2.4841 - val_mean_absolute_error: 1.1377 - val_mean_squared_error: 2.4841\n",
            "Epoch 254/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.5148 - mean_absolute_error: 1.1504 - mean_squared_error: 2.5148\n",
            "Epoch 254: val_loss did not improve from 2.48146\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5148 - mean_absolute_error: 1.1504 - mean_squared_error: 2.5148 - val_loss: 2.4828 - val_mean_absolute_error: 1.1360 - val_mean_squared_error: 2.4828\n",
            "Epoch 255/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.5086 - mean_absolute_error: 1.1464 - mean_squared_error: 2.5086\n",
            "Epoch 255: val_loss did not improve from 2.48146\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5139 - mean_absolute_error: 1.1484 - mean_squared_error: 2.5139 - val_loss: 2.4883 - val_mean_absolute_error: 1.1406 - val_mean_squared_error: 2.4883\n",
            "Epoch 256/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.5105 - mean_absolute_error: 1.1459 - mean_squared_error: 2.5105\n",
            "Epoch 256: val_loss did not improve from 2.48146\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5105 - mean_absolute_error: 1.1459 - mean_squared_error: 2.5105 - val_loss: 2.5023 - val_mean_absolute_error: 1.1533 - val_mean_squared_error: 2.5023\n",
            "Epoch 257/1000\n",
            "239/245 [============================>.] - ETA: 0s - loss: 2.5217 - mean_absolute_error: 1.1542 - mean_squared_error: 2.5217\n",
            "Epoch 257: val_loss improved from 2.48146 to 2.48032, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5134 - mean_absolute_error: 1.1529 - mean_squared_error: 2.5134 - val_loss: 2.4803 - val_mean_absolute_error: 1.1405 - val_mean_squared_error: 2.4803\n",
            "Epoch 258/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.5087 - mean_absolute_error: 1.1482 - mean_squared_error: 2.5087\n",
            "Epoch 258: val_loss did not improve from 2.48032\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5121 - mean_absolute_error: 1.1495 - mean_squared_error: 2.5121 - val_loss: 2.4837 - val_mean_absolute_error: 1.1358 - val_mean_squared_error: 2.4837\n",
            "Epoch 259/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.4984 - mean_absolute_error: 1.1446 - mean_squared_error: 2.4984\n",
            "Epoch 259: val_loss did not improve from 2.48032\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5108 - mean_absolute_error: 1.1472 - mean_squared_error: 2.5108 - val_loss: 2.4821 - val_mean_absolute_error: 1.1375 - val_mean_squared_error: 2.4821\n",
            "Epoch 260/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.5318 - mean_absolute_error: 1.1557 - mean_squared_error: 2.5318\n",
            "Epoch 260: val_loss improved from 2.48032 to 2.47895, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.5116 - mean_absolute_error: 1.1508 - mean_squared_error: 2.5116 - val_loss: 2.4789 - val_mean_absolute_error: 1.1392 - val_mean_squared_error: 2.4789\n",
            "Epoch 261/1000\n",
            "245/245 [==============================] - ETA: 0s - loss: 2.5133 - mean_absolute_error: 1.1502 - mean_squared_error: 2.5133\n",
            "Epoch 261: val_loss improved from 2.47895 to 2.47885, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.5133 - mean_absolute_error: 1.1502 - mean_squared_error: 2.5133 - val_loss: 2.4789 - val_mean_absolute_error: 1.1406 - val_mean_squared_error: 2.4789\n",
            "Epoch 262/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.5121 - mean_absolute_error: 1.1493 - mean_squared_error: 2.5121\n",
            "Epoch 262: val_loss did not improve from 2.47885\n",
            "245/245 [==============================] - 1s 5ms/step - loss: 2.5110 - mean_absolute_error: 1.1505 - mean_squared_error: 2.5110 - val_loss: 2.4834 - val_mean_absolute_error: 1.1350 - val_mean_squared_error: 2.4834\n",
            "Epoch 263/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.5317 - mean_absolute_error: 1.1533 - mean_squared_error: 2.5317\n",
            "Epoch 263: val_loss did not improve from 2.47885\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5100 - mean_absolute_error: 1.1493 - mean_squared_error: 2.5100 - val_loss: 2.4849 - val_mean_absolute_error: 1.1437 - val_mean_squared_error: 2.4849\n",
            "Epoch 264/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.5002 - mean_absolute_error: 1.1443 - mean_squared_error: 2.5002\n",
            "Epoch 264: val_loss did not improve from 2.47885\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5113 - mean_absolute_error: 1.1461 - mean_squared_error: 2.5113 - val_loss: 2.4791 - val_mean_absolute_error: 1.1410 - val_mean_squared_error: 2.4791\n",
            "Epoch 265/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.4971 - mean_absolute_error: 1.1508 - mean_squared_error: 2.4971\n",
            "Epoch 265: val_loss did not improve from 2.47885\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5129 - mean_absolute_error: 1.1541 - mean_squared_error: 2.5129 - val_loss: 2.4806 - val_mean_absolute_error: 1.1350 - val_mean_squared_error: 2.4806\n",
            "Epoch 266/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.5172 - mean_absolute_error: 1.1511 - mean_squared_error: 2.5172\n",
            "Epoch 266: val_loss did not improve from 2.47885\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5133 - mean_absolute_error: 1.1515 - mean_squared_error: 2.5133 - val_loss: 2.4823 - val_mean_absolute_error: 1.1330 - val_mean_squared_error: 2.4823\n",
            "Epoch 267/1000\n",
            "236/245 [===========================>..] - ETA: 0s - loss: 2.5023 - mean_absolute_error: 1.1442 - mean_squared_error: 2.5023\n",
            "Epoch 267: val_loss did not improve from 2.47885\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5087 - mean_absolute_error: 1.1453 - mean_squared_error: 2.5087 - val_loss: 2.4934 - val_mean_absolute_error: 1.1410 - val_mean_squared_error: 2.4934\n",
            "Epoch 268/1000\n",
            "233/245 [===========================>..] - ETA: 0s - loss: 2.5141 - mean_absolute_error: 1.1507 - mean_squared_error: 2.5141\n",
            "Epoch 268: val_loss did not improve from 2.47885\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5127 - mean_absolute_error: 1.1515 - mean_squared_error: 2.5127 - val_loss: 2.4803 - val_mean_absolute_error: 1.1352 - val_mean_squared_error: 2.4803\n",
            "Epoch 269/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.5234 - mean_absolute_error: 1.1541 - mean_squared_error: 2.5234\n",
            "Epoch 269: val_loss did not improve from 2.47885\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5136 - mean_absolute_error: 1.1519 - mean_squared_error: 2.5136 - val_loss: 2.4822 - val_mean_absolute_error: 1.1330 - val_mean_squared_error: 2.4822\n",
            "Epoch 270/1000\n",
            "243/245 [============================>.] - ETA: 0s - loss: 2.5022 - mean_absolute_error: 1.1451 - mean_squared_error: 2.5022\n",
            "Epoch 270: val_loss did not improve from 2.47885\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5109 - mean_absolute_error: 1.1471 - mean_squared_error: 2.5109 - val_loss: 2.4878 - val_mean_absolute_error: 1.1453 - val_mean_squared_error: 2.4878\n",
            "Epoch 271/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.5162 - mean_absolute_error: 1.1539 - mean_squared_error: 2.5162\n",
            "Epoch 271: val_loss improved from 2.47885 to 2.47638, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5107 - mean_absolute_error: 1.1522 - mean_squared_error: 2.5107 - val_loss: 2.4764 - val_mean_absolute_error: 1.1380 - val_mean_squared_error: 2.4764\n",
            "Epoch 272/1000\n",
            "235/245 [===========================>..] - ETA: 0s - loss: 2.4985 - mean_absolute_error: 1.1488 - mean_squared_error: 2.4985\n",
            "Epoch 272: val_loss did not improve from 2.47638\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5093 - mean_absolute_error: 1.1507 - mean_squared_error: 2.5093 - val_loss: 2.4791 - val_mean_absolute_error: 1.1362 - val_mean_squared_error: 2.4791\n",
            "Epoch 273/1000\n",
            "234/245 [===========================>..] - ETA: 0s - loss: 2.4981 - mean_absolute_error: 1.1476 - mean_squared_error: 2.4981\n",
            "Epoch 273: val_loss did not improve from 2.47638\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5122 - mean_absolute_error: 1.1484 - mean_squared_error: 2.5122 - val_loss: 2.4813 - val_mean_absolute_error: 1.1368 - val_mean_squared_error: 2.4813\n",
            "Epoch 274/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.5188 - mean_absolute_error: 1.1509 - mean_squared_error: 2.5188\n",
            "Epoch 274: val_loss improved from 2.47638 to 2.47633, saving model to best_model11.h5\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5096 - mean_absolute_error: 1.1493 - mean_squared_error: 2.5096 - val_loss: 2.4763 - val_mean_absolute_error: 1.1367 - val_mean_squared_error: 2.4763\n",
            "Epoch 275/1000\n",
            "238/245 [============================>.] - ETA: 0s - loss: 2.4829 - mean_absolute_error: 1.1415 - mean_squared_error: 2.4829\n",
            "Epoch 275: val_loss did not improve from 2.47633\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5107 - mean_absolute_error: 1.1482 - mean_squared_error: 2.5107 - val_loss: 2.4850 - val_mean_absolute_error: 1.1392 - val_mean_squared_error: 2.4850\n",
            "Epoch 276/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.5067 - mean_absolute_error: 1.1493 - mean_squared_error: 2.5067\n",
            "Epoch 276: val_loss did not improve from 2.47633\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5100 - mean_absolute_error: 1.1497 - mean_squared_error: 2.5100 - val_loss: 2.4765 - val_mean_absolute_error: 1.1397 - val_mean_squared_error: 2.4765\n",
            "Epoch 277/1000\n",
            "240/245 [============================>.] - ETA: 0s - loss: 2.5179 - mean_absolute_error: 1.1495 - mean_squared_error: 2.5179\n",
            "Epoch 277: val_loss did not improve from 2.47633\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5090 - mean_absolute_error: 1.1478 - mean_squared_error: 2.5090 - val_loss: 2.4913 - val_mean_absolute_error: 1.1421 - val_mean_squared_error: 2.4913\n",
            "Epoch 278/1000\n",
            "237/245 [============================>.] - ETA: 0s - loss: 2.5138 - mean_absolute_error: 1.1578 - mean_squared_error: 2.5138\n",
            "Epoch 278: val_loss did not improve from 2.47633\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5085 - mean_absolute_error: 1.1544 - mean_squared_error: 2.5085 - val_loss: 2.4822 - val_mean_absolute_error: 1.1297 - val_mean_squared_error: 2.4822\n",
            "Epoch 279/1000\n",
            "230/245 [===========================>..] - ETA: 0s - loss: 2.4953 - mean_absolute_error: 1.1396 - mean_squared_error: 2.4953\n",
            "Epoch 279: val_loss did not improve from 2.47633\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5081 - mean_absolute_error: 1.1438 - mean_squared_error: 2.5081 - val_loss: 2.4768 - val_mean_absolute_error: 1.1410 - val_mean_squared_error: 2.4768\n",
            "Epoch 280/1000\n",
            "242/245 [============================>.] - ETA: 0s - loss: 2.5125 - mean_absolute_error: 1.1522 - mean_squared_error: 2.5125\n",
            "Epoch 280: val_loss did not improve from 2.47633\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5088 - mean_absolute_error: 1.1515 - mean_squared_error: 2.5088 - val_loss: 2.4899 - val_mean_absolute_error: 1.1399 - val_mean_squared_error: 2.4899\n",
            "Epoch 281/1000\n",
            "241/245 [============================>.] - ETA: 0s - loss: 2.5144 - mean_absolute_error: 1.1489 - mean_squared_error: 2.5144\n",
            "Epoch 281: val_loss did not improve from 2.47633\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5073 - mean_absolute_error: 1.1468 - mean_squared_error: 2.5073 - val_loss: 2.4833 - val_mean_absolute_error: 1.1391 - val_mean_squared_error: 2.4833\n",
            "Epoch 282/1000\n",
            "244/245 [============================>.] - ETA: 0s - loss: 2.5090 - mean_absolute_error: 1.1510 - mean_squared_error: 2.5090\n",
            "Epoch 282: val_loss did not improve from 2.47633\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5116 - mean_absolute_error: 1.1518 - mean_squared_error: 2.5116 - val_loss: 2.4804 - val_mean_absolute_error: 1.1433 - val_mean_squared_error: 2.4804\n",
            "Epoch 283/1000\n",
            "229/245 [===========================>..] - ETA: 0s - loss: 2.5282 - mean_absolute_error: 1.1552 - mean_squared_error: 2.5282\n",
            "Epoch 283: val_loss did not improve from 2.47633\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 2.5084 - mean_absolute_error: 1.1497 - mean_squared_error: 2.5084 - val_loss: 2.4849 - val_mean_absolute_error: 1.1433 - val_mean_squared_error: 2.4849\n",
            "Epoch 284/1000\n",
            "231/245 [===========================>..] - ETA: 0s - loss: 2.4958 - mean_absolute_error: 1.1455 - mean_squared_error: 2.4958\n",
            "Epoch 284: val_loss did not improve from 2.47633\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 2.5074 - mean_absolute_error: 1.1489 - mean_squared_error: 2.5074 - val_loss: 2.4826 - val_mean_absolute_error: 1.1400 - val_mean_squared_error: 2.4826\n",
            "Epoch 284: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f848b137cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = load_model('best_model11.h5')\n",
        "\n",
        "z_predict_test11 = model11.predict(Z_test)\n",
        "\n",
        "plt.plot(z_predict_test11,z_test,'.')\n",
        "\n",
        "print('MSE:', mean_squared_error(z_test, z_predict_test11))\n",
        "print('MAE:', mean_absolute_error(z_test, z_predict_test11))\n",
        "print('RMSE:', mean_squared_error(z_test, z_predict_test11)**0.5)\n",
        "print('Spearman R:', spearmanr(z_test, z_predict_test11))\n",
        "print('R2:', r2_score(z_test, z_predict_test11))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "B0YK6L202ix0",
        "outputId": "c3e19cf0-6065-4012-b639-4ebf5ba35a44"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 0s 1ms/step\n",
            "MSE: 2.476598285923006\n",
            "MAE: 1.1388485949025353\n",
            "RMSE: 1.5737211588852091\n",
            "Spearman R: SpearmanrResult(correlation=0.6025964215658073, pvalue=4.6032560446269607e-296)\n",
            "R2: 0.30547456187173394\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCcwsRB8SCFH"
      },
      "source": [
        "\n",
        "\n",
        "10. Conclusiones Finales"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tabla comparativa\n",
        "from tabulate import tabulate\n",
        "data = [[1,5,21,1000,1.55,0.90,1.24,0.81,0.57],\n",
        "[1,10,41,1000,0.99,0.72,1.00,0.86,0.72],\n",
        "[1,50,201,1000,0.93,0.68,0.96,0.86,0.74],\n",
        "[1,100,401,19,3.03,1.23,1.74,0.53,0.15],\n",
        "[1,1000,4001,22,3.03,1.23,1.74,0.53,0.15],\n",
        "[2,5,51,1000,0.29,0.39,0.54,0.90,0.92],\n",
        "[3,5,81,1000,0.56,0.41,0.75,0.93,0.84],\n",
        "[5,5,141,876,0.041,0.15,0.20,0.97,0.99],\n",
        "[10,5,291,248,2.48,1.39,1.57,0.60,0.31]\n",
        "]\n",
        "print (tabulate(data, headers=[\"Capas ocultas\", \"Neuronas por capa oculta\", \"Parámetros\", \"Épocas\", \"MSE\", \"MAE\", \"RMSE\", \"Spearman\",\"R2\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgA9DOTB3V_U",
        "outputId": "7f04c736-3e49-4742-bf29-feb33c4a970a"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Capas ocultas    Neuronas por capa oculta    Parámetros    Épocas    MSE    MAE    RMSE    Spearman    R2\n",
            "---------------  --------------------------  ------------  --------  -----  -----  ------  ----------  ----\n",
            "              1                           5            21      1000  1.55    0.9     1.24        0.81  0.57\n",
            "              1                          10            41      1000  0.99    0.72    1           0.86  0.72\n",
            "              1                          50           201      1000  0.93    0.68    0.96        0.86  0.74\n",
            "              1                         100           401        19  3.03    1.23    1.74        0.53  0.15\n",
            "              1                        1000          4001        22  3.03    1.23    1.74        0.53  0.15\n",
            "              2                           5            51      1000  0.29    0.39    0.54        0.9   0.92\n",
            "              3                           5            81      1000  0.56    0.41    0.75        0.93  0.84\n",
            "              5                           5           141       876  0.041   0.15    0.2         0.97  0.99\n",
            "             10                           5           291       248  2.48    1.39    1.57        0.6   0.31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuF9aRWLSCFI"
      },
      "source": [
        "<font color='#086F0C'>Sobre el mismo conjunto de datos de prueba, la tabla resume los resultados, medidos en indicadores de error (MSE, MAE y RMSE) y otros de ajuste (Correlación de Spearman y $R^2$) al comparar la predicción efectuada por la red neuronal entrenada, con arquitectura variable, versus el valor real de la función. Notar que además se han incorporado la cantidad de parámetros involucrada en cada diseño y las épocas utilizadas en iterar, aunque todas las configuraciones se probaron con un mecanismo de parada temprana (paciencia = 10) y 1000 épocas disponibles.</font>\n",
        "\n",
        "<font color='#086F0C'>Como se puede apreciar, para un número fijo de capas ocultas (1), el aumentar las neuronas en la capa mejora los índices de error y ajuste, sin embargo, no sucede de manera indefinida: al alcanzar 100 y 1000 neuronas se activa el criterio de parada temprana y los índices resultan virtualmente iguales entre sí (varían en decimales a partir de la tercera posición en algunos casos). Es decir, aumentar el número de neuronas en la única capa oculta, no necesariamente garantiza un mejor modelo, en particular si se busca una solución práctica.</font>\n",
        "\n",
        "<font color='#086F0C'>Situación similar ocurre con el número de capas, en donde el mejor desempeño se observa al alcanzar 5 capas ocultas con 5 neuronas cada una, iterando en 876 épocas de un total de 1000. Notar que con 10 capas los resultados vuelven a empeorar.\n",
        "\n",
        "\n",
        "Estos resultados refuerzan la idea de que no existe un mecanismo que garantice la configuración del \"mejor modelo\", así como también levantan una alerta de que, al construir una red con una arquitectura más compleja (más capas o más neuronas), lo que repercute en un mayor número de parámetros a estimar, no es sinónimo de lograr un mejor modelo siempre, si el objetivo es implementar una solución práctica.</font>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Referencias\n",
        "\n",
        "\n",
        "*   Goodfellow, I., Bengio, Y. y Courville, A. (2016). *Deep Learning*. MIT Press. http://www.deeplearningbook.org\n",
        "\n"
      ],
      "metadata": {
        "id": "BH-bQx2o_Ujn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E8hLEOLVDMTg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3-final"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}